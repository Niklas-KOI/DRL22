Starting process id: 82684
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntReacherEnv-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fef99c5da70>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [11.75 11.75  0.5   3.    3.  ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 1192.96. Rollout time: 645.94, Training time: 546.80
Evaluating epoch 0
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 91096.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -25.35228074497357     |
| test_1/avg_q              | -20.25020794615119     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -11.161075430238009    |
| train_0/current_q         | -6.089219269569937     |
| train_0/fw_bonus          | -0.995986008644104     |
| train_0/fw_loss           | 0.03159215124323964    |
| train_0/mu_grads          | -0.004520158481318504  |
| train_0/mu_grads_std      | 0.15722398050129413    |
| train_0/mu_loss           | 6.192540265336865      |
| train_0/next_q            | -6.057053979047624     |
| train_0/q_grads           | -0.0026191006152657794 |
| train_0/q_grads_std       | 0.10942068751901388    |
| train_0/q_loss            | 0.6025235266892526     |
| train_0/reward            | -0.6237035356476553    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0043701171875        |
| train_0/target_q          | -6.269136403325443     |
| train_1/avg_q             | -14.450006916108162    |
| train_1/current_q         | -11.574550221043205    |
| train_1/fw_bonus          | -0.9927203252911567    |
| train_1/fw_loss           | 0.07369800806045532    |
| train_1/mu_grads          | 0.0037844592821784317  |
| train_1/mu_grads_std      | 0.11736048925668001    |
| train_1/mu_loss           | 12.50196936443304      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -11.424839547713642    |
| train_1/q_grads           | 0.02301487382501364    |
| train_1/q_grads_std       | 0.14042388461530209    |
| train_1/q_loss            | 2.31764628598777       |
| train_1/reward            | -2.6452870132063255    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0083984375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0007407407407407407  |
| train_1/target_q          | -11.57384441025988     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 1005.68. Rollout time: 616.61, Training time: 388.92
Evaluating epoch 1
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 180291.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.454314026813925    |
| test_1/avg_q              | -20.45187280538142     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -18.867704451931594    |
| train_0/current_q         | -7.798808793044057     |
| train_0/fw_bonus          | -0.9978243768215179    |
| train_0/fw_loss           | 0.017384572769515216   |
| train_0/mu_grads          | -0.009945090534165502  |
| train_0/mu_grads_std      | 0.20513661615550519    |
| train_0/mu_loss           | 7.672106872226015      |
| train_0/next_q            | -7.6892957315129795    |
| train_0/q_grads           | -0.0039050923951435834 |
| train_0/q_grads_std       | 0.13104429095983505    |
| train_0/q_loss            | 0.3972007765152039     |
| train_0/reward            | -0.6147515041313454    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0188720703125        |
| train_0/target_q          | -7.908065394286416     |
| train_1/avg_q             | -21.3476971796284      |
| train_1/current_q         | -10.705338265292037    |
| train_1/fw_bonus          | -0.9911117881536484    |
| train_1/fw_loss           | 0.08707946818321943    |
| train_1/mu_grads          | 0.0024819089216180147  |
| train_1/mu_grads_std      | 0.12220337782055139    |
| train_1/mu_loss           | 11.50909076723936      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -10.40725328660898     |
| train_1/q_grads           | 0.01413796932902187    |
| train_1/q_grads_std       | 0.15768657103180886    |
| train_1/q_loss            | 2.1286136130511295     |
| train_1/reward            | -2.580266959202345     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0042724609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.032962962962962965   |
| train_1/target_q          | -10.629385940344076    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 1143.39. Rollout time: 746.61, Training time: 396.60
Evaluating epoch 2
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 271416.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99993784682029     |
| test_1/avg_q              | -22.943240155616508    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.748490902807355    |
| train_0/current_q         | -8.32668072089418      |
| train_0/fw_bonus          | -0.9982804402709007    |
| train_0/fw_loss           | 0.013859938131645322   |
| train_0/mu_grads          | -0.010944958892650902  |
| train_0/mu_grads_std      | 0.24324593022465707    |
| train_0/mu_loss           | 8.223070487044756      |
| train_0/next_q            | -8.220463957147583     |
| train_0/q_grads           | -0.0030467275413684548 |
| train_0/q_grads_std       | 0.1426440730690956     |
| train_0/q_loss            | 0.35244502617671586    |
| train_0/reward            | -0.6206516525635379    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0321533203125        |
| train_0/target_q          | -8.430856541414022     |
| train_1/avg_q             | -20.930092661967926    |
| train_1/current_q         | -8.866978227286655     |
| train_1/fw_bonus          | -0.9905671417713166    |
| train_1/fw_loss           | 0.09161039851605893    |
| train_1/mu_grads          | 0.0017773725936422124  |
| train_1/mu_grads_std      | 0.12830449156463147    |
| train_1/mu_loss           | 9.377518963528502      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.114331171573344     |
| train_1/q_grads           | -0.0010129085188964383 |
| train_1/q_grads_std       | 0.17178361117839813    |
| train_1/q_loss            | 3.903409399194527      |
| train_1/reward            | -2.612595396377583     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0040283203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -8.84896908102376      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 933.02. Rollout time: 556.89, Training time: 375.91
Evaluating epoch 3
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-------------------------------------------------------
| epoch                     | 3                       |
| policy/steps              | 362482.0                |
| test/episodes             | 100.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -26.547177149900822     |
| test_1/avg_q              | -21.55879278536841      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 400.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -25.94687377264105      |
| train_0/current_q         | -7.745786450041986      |
| train_0/fw_bonus          | -0.9984431341290474     |
| train_0/fw_loss           | 0.012602554867044091    |
| train_0/mu_grads          | -0.01780144702643156    |
| train_0/mu_grads_std      | 0.2741324707865715      |
| train_0/mu_loss           | 7.65831538662282        |
| train_0/next_q            | -7.6424534458293865     |
| train_0/q_grads           | -0.004750353703275323   |
| train_0/q_grads_std       | 0.15557432509958743     |
| train_0/q_loss            | 0.3694237927701281      |
| train_0/reward            | -0.6191359300035402     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.028515625             |
| train_0/target_q          | -7.861596974994216      |
| train_1/avg_q             | -22.325136836069        |
| train_1/current_q         | -20.380982350622123     |
| train_1/fw_bonus          | -0.9894698083400726     |
| train_1/fw_loss           | 0.10073913540691137     |
| train_1/mu_grads          | -1.1787559125764347e-05 |
| train_1/mu_grads_std      | 0.1252404611557722      |
| train_1/mu_loss           | 24.72130474599073       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -23.587089823346467     |
| train_1/q_grads           | -0.010109232109971344   |
| train_1/q_grads_std       | 0.18962504118680953     |
| train_1/q_loss            | 9.236767710153606       |
| train_1/reward            | -2.5501933787279993     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00341796875           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0014814814814814814   |
| train_1/target_q          | -20.296342738300712     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 2976.49. Rollout time: 2529.89, Training time: 446.45
Evaluating epoch 4
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 452846.0              |
| test/episodes             | 125.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.196158758420292   |
| test_1/avg_q              | -20.121731838287396   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.20968688895253    |
| train_0/current_q         | -8.940392446762484    |
| train_0/fw_bonus          | -0.9986189350485801   |
| train_0/fw_loss           | 0.011244002263993025  |
| train_0/mu_grads          | -0.02189881457015872  |
| train_0/mu_grads_std      | 0.2919007338583469    |
| train_0/mu_loss           | 8.862308230593873     |
| train_0/next_q            | -8.863488011010476    |
| train_0/q_grads           | -0.004924296366516501 |
| train_0/q_grads_std       | 0.16453258469700813   |
| train_0/q_loss            | 0.3262222528472181    |
| train_0/reward            | -0.6171107849670079   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0701416015625       |
| train_0/target_q          | -9.05614755961679     |
| train_1/avg_q             | -22.989218018587326   |
| train_1/current_q         | -11.126641834367197   |
| train_1/fw_bonus          | -0.9880969360470772   |
| train_1/fw_loss           | 0.11216002311557531   |
| train_1/mu_grads          | -0.001411211656522937 |
| train_1/mu_grads_std      | 0.11880674492567778   |
| train_1/mu_loss           | 11.959946991702925    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -10.968287898411756   |
| train_1/q_grads           | -0.014982420578598976 |
| train_1/q_grads_std       | 0.19992153234779836   |
| train_1/q_loss            | 5.445974079754486     |
| train_1/reward            | -2.602401433624982    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002587890625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.014814814814814815  |
| train_1/target_q          | -11.415658593337174   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 1091.69. Rollout time: 685.01, Training time: 406.52
Evaluating epoch 5
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 540886.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -22.975382682761797    |
| test_1/avg_q              | -20.60137818703813     |
| test_1/n_subgoals         | 669.0                  |
| test_1/subgoal_succ_rate  | 0.02242152466367713    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -24.32059126879914     |
| train_0/current_q         | -9.195800499394071     |
| train_0/fw_bonus          | -0.9986680209636688    |
| train_0/fw_loss           | 0.010864525637589394   |
| train_0/mu_grads          | -0.024332255870103837  |
| train_0/mu_grads_std      | 0.3081756949424744     |
| train_0/mu_loss           | 9.127062282405518      |
| train_0/next_q            | -9.130793514708426     |
| train_0/q_grads           | -0.005157324450556189  |
| train_0/q_grads_std       | 0.16976748406887054    |
| train_0/q_loss            | 0.41859089594883636    |
| train_0/reward            | -0.6199611951433326    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0975341796875        |
| train_0/target_q          | -9.328143239371181     |
| train_1/avg_q             | -20.4139860227942      |
| train_1/current_q         | -12.187347754742358    |
| train_1/fw_bonus          | -0.9868379250168801    |
| train_1/fw_loss           | 0.12263393606990576    |
| train_1/mu_grads          | -0.0010510514199268072 |
| train_1/mu_grads_std      | 0.11754318978637457    |
| train_1/mu_loss           | 13.40477801063459      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -12.333553391694483    |
| train_1/q_grads           | -0.018837127974256872  |
| train_1/q_grads_std       | 0.20864841975271703    |
| train_1/q_loss            | 3.1064405209698265     |
| train_1/reward            | -2.5769462955751807    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002587890625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.044444444444444446   |
| train_1/target_q          | -12.331013562711439    |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 6
Time for epoch 6: 909.29. Rollout time: 566.18, Training time: 342.93
Evaluating epoch 6
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 630300.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999995697284913    |
| test_1/avg_q              | -20.43711374552935     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -23.94229423806555     |
| train_0/current_q         | -3.7793726937532512    |
| train_0/fw_bonus          | -0.9985079959034919    |
| train_0/fw_loss           | 0.012101326487027109   |
| train_0/mu_grads          | -0.0273567418102175    |
| train_0/mu_grads_std      | 0.32756529971957205    |
| train_0/mu_loss           | 3.709554059449554      |
| train_0/next_q            | -3.7108224859064407    |
| train_0/q_grads           | -0.009916701703332365  |
| train_0/q_grads_std       | 0.17743157185614108    |
| train_0/q_loss            | 0.6241806554247175     |
| train_0/reward            | -0.6407036576070823    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0931884765625        |
| train_0/target_q          | -4.019808583763765     |
| train_1/avg_q             | -20.412599719653837    |
| train_1/current_q         | -2.787996926465385     |
| train_1/fw_bonus          | -0.9854581475257873    |
| train_1/fw_loss           | 0.13411230742931365    |
| train_1/mu_grads          | 0.00024410695987171495 |
| train_1/mu_grads_std      | 0.12015538234263659    |
| train_1/mu_loss           | 1.2601694660999283     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.26304903989767026   |
| train_1/q_grads           | -0.02303829537704587   |
| train_1/q_grads_std       | 0.21820561401546001    |
| train_1/q_loss            | 2.550563441414004      |
| train_1/reward            | -2.6497336767111848    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002099609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.03259259259259259    |
| train_1/target_q          | -2.83988463563923      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 7
Time for epoch 7: 1007.14. Rollout time: 626.06, Training time: 380.90
Evaluating epoch 7
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 721425.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.229529434369738   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.998906960208128   |
| train_0/current_q         | -9.314180298321478    |
| train_0/fw_bonus          | -0.9986137092113495   |
| train_0/fw_loss           | 0.011284272535704076  |
| train_0/mu_grads          | -0.0293255299795419   |
| train_0/mu_grads_std      | 0.33377342000603677   |
| train_0/mu_loss           | 9.262426846938283     |
| train_0/next_q            | -9.255668227431157    |
| train_0/q_grads           | -0.010571060888469219 |
| train_0/q_grads_std       | 0.17897602468729018   |
| train_0/q_loss            | 0.46049601423128134   |
| train_0/reward            | -0.6314466405256098   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.109326171875        |
| train_0/target_q          | -9.427785186418728    |
| train_1/avg_q             | -19.3359753237749     |
| train_1/current_q         | -2.722459041198774    |
| train_1/fw_bonus          | -0.9868071034550667   |
| train_1/fw_loss           | 0.12289021220058202   |
| train_1/mu_grads          | 0.006492876331321895  |
| train_1/mu_grads_std      | 0.12767378017306327   |
| train_1/mu_loss           | 1.142675568312099     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.1430422474234898   |
| train_1/q_grads           | -0.026365998573601244 |
| train_1/q_grads_std       | 0.23558298237621783   |
| train_1/q_loss            | 0.8600688576860686    |
| train_1/reward            | -2.611032831406919    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002587890625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.7220120694503245   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 8
Time for epoch 8: 1120.05. Rollout time: 719.75, Training time: 400.12
Evaluating epoch 8
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 812550.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.30358915078074    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.192210047808322    |
| train_0/fw_bonus          | -0.9987600699067116   |
| train_0/fw_loss           | 0.010153078753501178  |
| train_0/mu_grads          | -0.030703648971393705 |
| train_0/mu_grads_std      | 0.34295598939061167   |
| train_0/mu_loss           | 9.138706031243425     |
| train_0/next_q            | -9.138131067406528    |
| train_0/q_grads           | -0.011407937854528427 |
| train_0/q_grads_std       | 0.18049610517919062   |
| train_0/q_loss            | 0.4264166968979244    |
| train_0/reward            | -0.6254590626715071   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0987548828125       |
| train_0/target_q          | -9.321970863817844    |
| train_1/avg_q             | -19.701771282673278   |
| train_1/current_q         | -2.6267520790980834   |
| train_1/fw_bonus          | -0.9874879032373428   |
| train_1/fw_loss           | 0.11722677182406187   |
| train_1/mu_grads          | 0.013661079644225537  |
| train_1/mu_grads_std      | 0.1430802769958973    |
| train_1/mu_loss           | 1.0313572601261065    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.03111680339253336  |
| train_1/q_grads           | -0.03211935656145215  |
| train_1/q_grads_std       | 0.2528808631002903    |
| train_1/q_loss            | 0.4241197508587555    |
| train_1/reward            | -2.6053436534344656   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0024169921875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.6292898113380034   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 9
Time for epoch 9: 6110.80. Rollout time: 3934.89, Training time: 2175.73
Evaluating epoch 9
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 903675.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.449584384003593    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.372387067789711     |
| train_0/fw_bonus          | -0.9988997772336006    |
| train_0/fw_loss           | 0.009073310601525008   |
| train_0/mu_grads          | -0.03274634527042508   |
| train_0/mu_grads_std      | 0.35148511826992035    |
| train_0/mu_loss           | 9.32276051697608       |
| train_0/next_q            | -9.320437134310003     |
| train_0/q_grads           | -0.011353398580104113  |
| train_0/q_grads_std       | 0.18289396464824675    |
| train_0/q_loss            | 0.3883485947601663     |
| train_0/reward            | -0.6133540986444131    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1275146484375        |
| train_0/target_q          | -9.499630585260892     |
| train_1/avg_q             | -19.724648743644345    |
| train_1/current_q         | -2.606661334857575     |
| train_1/fw_bonus          | -0.9875175565481186    |
| train_1/fw_loss           | 0.11697996724396945    |
| train_1/mu_grads          | 0.02174542360007763    |
| train_1/mu_grads_std      | 0.1659720443189144     |
| train_1/mu_loss           | 1.0069877203354056     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.0068733724896505475 |
| train_1/q_grads           | -0.03725657342001796   |
| train_1/q_grads_std       | 0.26902679428458215    |
| train_1/q_loss            | 0.2827348748103834     |
| train_1/reward            | -2.6060285589868726    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004150390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.611092452698869     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 1108.81. Rollout time: 683.77, Training time: 424.88
Evaluating epoch 10
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 994800.0              |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.636760803265446   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.140924348353902    |
| train_0/fw_bonus          | -0.9990805312991142   |
| train_0/fw_loss           | 0.007676524680573493  |
| train_0/mu_grads          | -0.030846458720043303 |
| train_0/mu_grads_std      | 0.36047621369361876   |
| train_0/mu_loss           | 9.075973797288942     |
| train_0/next_q            | -9.078804255471413    |
| train_0/q_grads           | -0.014100775658152997 |
| train_0/q_grads_std       | 0.1858630247414112    |
| train_0/q_loss            | 0.3311222202618397    |
| train_0/reward            | -0.6030172020949977   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1404052734375       |
| train_0/target_q          | -9.273284901285383    |
| train_1/avg_q             | -20.72372305500855    |
| train_1/current_q         | -21.074419577825566   |
| train_1/fw_bonus          | -0.9879549607634545   |
| train_1/fw_loss           | 0.1133412042632699    |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0373745528049767   |
| train_1/q_grads_std       | 0.28587141558527945   |
| train_1/q_loss            | 6.000619261039162     |
| train_1/reward            | -2.5907570508588833   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.005615234375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.354359589921398   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 1141.72. Rollout time: 723.16, Training time: 418.39
Evaluating epoch 11
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1085925.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.287708865811965   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.34200756592563     |
| train_0/fw_bonus          | -0.9993200615048409   |
| train_0/fw_loss           | 0.005825260642450303  |
| train_0/mu_grads          | -0.030339712789282203 |
| train_0/mu_grads_std      | 0.3624263033270836    |
| train_0/mu_loss           | 9.29022796585692      |
| train_0/next_q            | -9.288653475131449    |
| train_0/q_grads           | -0.014488805597648025 |
| train_0/q_grads_std       | 0.18796401433646678   |
| train_0/q_loss            | 0.17391675284639369   |
| train_0/reward            | -0.5739450070137536   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.113818359375        |
| train_0/target_q          | -9.494906835394422    |
| train_1/avg_q             | -20.67897257103848    |
| train_1/current_q         | -20.54457029699187    |
| train_1/fw_bonus          | -0.9892422005534172   |
| train_1/fw_loss           | 0.10263260919600725   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.03887533852830529  |
| train_1/q_grads_std       | 0.3013469196856022    |
| train_1/q_loss            | 4.579896852838199     |
| train_1/reward            | -2.6107260769880667   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006005859375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -20.846549807456828   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 1062.91. Rollout time: 658.57, Training time: 404.07
Evaluating epoch 12
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1177050.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.4020299420362     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.259518722674496    |
| train_0/fw_bonus          | -0.9993458315730095   |
| train_0/fw_loss           | 0.005626136192586273  |
| train_0/mu_grads          | -0.029801688389852643 |
| train_0/mu_grads_std      | 0.3658324234187603    |
| train_0/mu_loss           | 9.197116083245033     |
| train_0/next_q            | -9.19565460755457     |
| train_0/q_grads           | -0.014375579124316574 |
| train_0/q_grads_std       | 0.18960047252476214   |
| train_0/q_loss            | 0.15468922503858532   |
| train_0/reward            | -0.570600618289609    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1302978515625       |
| train_0/target_q          | -9.412968293844765    |
| train_1/avg_q             | -20.60354240177549    |
| train_1/current_q         | -20.73513018646935    |
| train_1/fw_bonus          | -0.9902402386069298   |
| train_1/fw_loss           | 0.09432985093444586   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04128930261358619  |
| train_1/q_grads_std       | 0.3137863799929619    |
| train_1/q_loss            | 3.3762186780934087    |
| train_1/reward            | -2.5852126471683734   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0062744140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.045843018262136   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 1157.90. Rollout time: 738.94, Training time: 418.71
Evaluating epoch 13
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1268175.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.645446077483452   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.250859590135935    |
| train_0/fw_bonus          | -0.9992925599217415   |
| train_0/fw_loss           | 0.0060377050307579335 |
| train_0/mu_grads          | -0.03173749297857285  |
| train_0/mu_grads_std      | 0.3710001684725285    |
| train_0/mu_loss           | 9.18389215146125      |
| train_0/next_q            | -9.183140208217276    |
| train_0/q_grads           | -0.01456135706976056  |
| train_0/q_grads_std       | 0.19384108036756514   |
| train_0/q_loss            | 0.17809528792032778   |
| train_0/reward            | -0.5797242676257156   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0974853515625       |
| train_0/target_q          | -9.402675661499831    |
| train_1/avg_q             | -20.65539225946307    |
| train_1/current_q         | -21.1313145619993     |
| train_1/fw_bonus          | -0.9909481123089791   |
| train_1/fw_loss           | 0.08844105247408152   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04380815327167511  |
| train_1/q_grads_std       | 0.3252043522894382    |
| train_1/q_loss            | 3.424177329829243     |
| train_1/reward            | -2.5810866384024846   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0067626953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.448048552464996   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 1117.00. Rollout time: 700.60, Training time: 416.20
Evaluating epoch 14
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 14                   |
| policy/steps              | 1359300.0            |
| test/episodes             | 375.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -20.813706404547396  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 1500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.421881399718316   |
| train_0/fw_bonus          | -0.999247120320797   |
| train_0/fw_loss           | 0.006389077112544328 |
| train_0/mu_grads          | -0.0302487688139081  |
| train_0/mu_grads_std      | 0.3779016859829426   |
| train_0/mu_loss           | 9.33983594981479     |
| train_0/next_q            | -9.33781896362862    |
| train_0/q_grads           | -0.0149004181381315  |
| train_0/q_grads_std       | 0.19868081174790858  |
| train_0/q_loss            | 0.19450369993308678  |
| train_0/reward            | -0.5934641221858328  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.1411376953125      |
| train_0/target_q          | -9.56970597156845    |
| train_1/avg_q             | -20.83035912737875   |
| train_1/current_q         | -21.625367796871945  |
| train_1/fw_bonus          | -0.9915064632892608  |
| train_1/fw_loss           | 0.08379612378776073  |
| train_1/mu_grads          | 0.024516167119145393 |
| train_1/mu_grads_std      | 0.17343875765800476  |
| train_1/mu_loss           | 28.0                 |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -27.0                |
| train_1/q_grads           | -0.04536921456456185 |
| train_1/q_grads_std       | 0.3361605629324913   |
| train_1/q_loss            | 2.7960589381200855   |
| train_1/reward            | -2.5979986848382395  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00576171875        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -21.969483548119502  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 913.60. Rollout time: 585.31, Training time: 328.19
Evaluating epoch 15
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1450425.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.709499002427382   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.455357939652561    |
| train_0/fw_bonus          | -0.9992211252450943   |
| train_0/fw_loss           | 0.006589957629330456  |
| train_0/mu_grads          | -0.02862651888281107  |
| train_0/mu_grads_std      | 0.3868317298591137    |
| train_0/mu_loss           | 9.354855243335015     |
| train_0/next_q            | -9.35272403871609     |
| train_0/q_grads           | -0.015199855226092041 |
| train_0/q_grads_std       | 0.2036869704723358    |
| train_0/q_loss            | 0.20404619534431187   |
| train_0/reward            | -0.607831403354794    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.137841796875        |
| train_0/target_q          | -9.60739340552983     |
| train_1/avg_q             | -20.809354755020177   |
| train_1/current_q         | -22.16103498574835    |
| train_1/fw_bonus          | -0.9920130163431168   |
| train_1/fw_loss           | 0.07958210650831461   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04708886221051216  |
| train_1/q_grads_std       | 0.34738724008202554   |
| train_1/q_loss            | 2.056446646248536     |
| train_1/reward            | -2.6446890431350765   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0050537109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.50777693376009    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 1953.33. Rollout time: 1618.04, Training time: 335.17
Evaluating epoch 16
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1541550.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.235877060127518   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.467771655108075    |
| train_0/fw_bonus          | -0.9991663560271263   |
| train_0/fw_loss           | 0.007013298489619046  |
| train_0/mu_grads          | -0.02401155363768339  |
| train_0/mu_grads_std      | 0.3969531588256359    |
| train_0/mu_loss           | 9.350071964570034     |
| train_0/next_q            | -9.34517889688694     |
| train_0/q_grads           | -0.015392031543888152 |
| train_0/q_grads_std       | 0.209860260412097     |
| train_0/q_loss            | 0.20833073645013825   |
| train_0/reward            | -0.6234549159657036   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1142822265625       |
| train_0/target_q          | -9.623531875296521    |
| train_1/avg_q             | -20.85552360743145    |
| train_1/current_q         | -22.70087227527544    |
| train_1/fw_bonus          | -0.9923361286520958   |
| train_1/fw_loss           | 0.07689412496984005   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.047911429591476914 |
| train_1/q_grads_std       | 0.3587656930088997    |
| train_1/q_loss            | 2.093341642224684     |
| train_1/reward            | -2.6296270000009825   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006787109375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.03987358203225    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 1062.01. Rollout time: 659.34, Training time: 402.41
Evaluating epoch 17
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1632675.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.6742884762296     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.585451023930016    |
| train_0/fw_bonus          | -0.9992037951946259   |
| train_0/fw_loss           | 0.006723780371248722  |
| train_0/mu_grads          | -0.022038204688578845 |
| train_0/mu_grads_std      | 0.4058915786445141    |
| train_0/mu_loss           | 9.454575439598049     |
| train_0/next_q            | -9.448751775058255    |
| train_0/q_grads           | -0.01600554254837334  |
| train_0/q_grads_std       | 0.21543701216578484   |
| train_0/q_loss            | 0.20550525268007647   |
| train_0/reward            | -0.6372887441724743   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1128173828125       |
| train_0/target_q          | -9.741548006639734    |
| train_1/avg_q             | -20.66286636770276    |
| train_1/current_q         | -23.0737132135701     |
| train_1/fw_bonus          | -0.9930105924606323   |
| train_1/fw_loss           | 0.07128311321139336   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04843514421954751  |
| train_1/q_grads_std       | 0.3701070658862591    |
| train_1/q_loss            | 1.7017063940954742    |
| train_1/reward            | -2.6644025528868953   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0086181640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.42348702554316    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 1368.58. Rollout time: 822.43, Training time: 545.86
Evaluating epoch 18
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 1723800.0             |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.609524645391964   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.662217095914128    |
| train_0/fw_bonus          | -0.9992123588919639   |
| train_0/fw_loss           | 0.006657729460857809  |
| train_0/mu_grads          | -0.018632234493270516 |
| train_0/mu_grads_std      | 0.41409771144390106   |
| train_0/mu_loss           | 9.530426806673367     |
| train_0/next_q            | -9.525799264702574    |
| train_0/q_grads           | -0.016456323442980647 |
| train_0/q_grads_std       | 0.22096516266465188   |
| train_0/q_loss            | 0.23759749991814352   |
| train_0/reward            | -0.642234728627227    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1258056640625       |
| train_0/target_q          | -9.814416374614147    |
| train_1/avg_q             | -20.71935411144318    |
| train_1/current_q         | -23.206376709339047   |
| train_1/fw_bonus          | -0.9931551724672317   |
| train_1/fw_loss           | 0.07008043769747019   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04815467596054077  |
| train_1/q_grads_std       | 0.3803149312734604    |
| train_1/q_loss            | 1.3112447088620347    |
| train_1/reward            | -2.6871803928264852   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0080810546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.5683581272015     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 1191.80. Rollout time: 742.00, Training time: 449.62
Evaluating epoch 19
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1814925.0             |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.75595634314835    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.589923038989124    |
| train_0/fw_bonus          | -0.9991927966475487   |
| train_0/fw_loss           | 0.006808857235591858  |
| train_0/mu_grads          | -0.01571130200754851  |
| train_0/mu_grads_std      | 0.42153096944093704   |
| train_0/mu_loss           | 9.443074803495037     |
| train_0/next_q            | -9.43753993090689     |
| train_0/q_grads           | -0.017383747594431044 |
| train_0/q_grads_std       | 0.22634342387318612   |
| train_0/q_loss            | 0.2576134410463839    |
| train_0/reward            | -0.6510921446515567   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1107421875          |
| train_0/target_q          | -9.742179926074797    |
| train_1/avg_q             | -20.795300557765696   |
| train_1/current_q         | -23.221485313629294   |
| train_1/fw_bonus          | -0.9932784333825111   |
| train_1/fw_loss           | 0.06905494797974825   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04992322912439704  |
| train_1/q_grads_std       | 0.3905924059450626    |
| train_1/q_loss            | 1.609921021682426     |
| train_1/reward            | -2.6669231252959436   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0087158203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.58233865263971    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 1899.58. Rollout time: 1077.58, Training time: 821.12
Evaluating epoch 20
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1906050.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.614428765646917   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.621302255644045    |
| train_0/fw_bonus          | -0.9992064714431763   |
| train_0/fw_loss           | 0.0067031701328232884 |
| train_0/mu_grads          | -0.010934213502332568 |
| train_0/mu_grads_std      | 0.42680180817842484   |
| train_0/mu_loss           | 9.471199530059511     |
| train_0/next_q            | -9.466279069028133    |
| train_0/q_grads           | -0.018180593382567167 |
| train_0/q_grads_std       | 0.23213158473372458   |
| train_0/q_loss            | 0.2384166518252603    |
| train_0/reward            | -0.6514617741482652   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1044677734375       |
| train_0/target_q          | -9.774491192024973    |
| train_1/avg_q             | -20.774911467429877   |
| train_1/current_q         | -23.246856608764908   |
| train_1/fw_bonus          | -0.9933286726474762   |
| train_1/fw_loss           | 0.06863713413476943   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05083812838420272  |
| train_1/q_grads_std       | 0.39925968945026397   |
| train_1/q_loss            | 1.6858686442789559    |
| train_1/reward            | -2.6828109264086377   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0084228515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.6176063365649     |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 1740.45. Rollout time: 1001.21, Training time: 738.67
Evaluating epoch 21
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 1997175.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.46529201661629    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.52907099997537     |
| train_0/fw_bonus          | -0.99921695291996     |
| train_0/fw_loss           | 0.006622143334243447  |
| train_0/mu_grads          | -0.009852189826779068 |
| train_0/mu_grads_std      | 0.43134242594242095   |
| train_0/mu_loss           | 9.38498844640748      |
| train_0/next_q            | -9.37697405015823     |
| train_0/q_grads           | -0.01897739302366972  |
| train_0/q_grads_std       | 0.23674122542142867   |
| train_0/q_loss            | 0.22501996308151365   |
| train_0/reward            | -0.6480037019533483   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.135400390625        |
| train_0/target_q          | -9.685509552094837    |
| train_1/avg_q             | -20.78944251038469    |
| train_1/current_q         | -22.930301573675642   |
| train_1/fw_bonus          | -0.9933254361152649   |
| train_1/fw_loss           | 0.06866398882120847   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05115958424285054  |
| train_1/q_grads_std       | 0.40838234797120093   |
| train_1/q_loss            | 1.676828922782521     |
| train_1/reward            | -2.664719299571152    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.008251953125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.292666565196164   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 1159.65. Rollout time: 709.89, Training time: 449.45
Evaluating epoch 22
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 2088300.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.619640492519203   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.585808746668947    |
| train_0/fw_bonus          | -0.9992209315299988   |
| train_0/fw_loss           | 0.006591402064077556  |
| train_0/mu_grads          | -0.00843460876494646  |
| train_0/mu_grads_std      | 0.4358275420963764    |
| train_0/mu_loss           | 9.433729901762817     |
| train_0/next_q            | -9.43037373155454     |
| train_0/q_grads           | -0.018709541624411942 |
| train_0/q_grads_std       | 0.24096973724663256   |
| train_0/q_loss            | 0.23286612587729305   |
| train_0/reward            | -0.6463384366998071   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.12373046875         |
| train_0/target_q          | -9.739256063331917    |
| train_1/avg_q             | -20.789437367983197   |
| train_1/current_q         | -23.032283089423352   |
| train_1/fw_bonus          | -0.9932337284088135   |
| train_1/fw_loss           | 0.06942689185962081   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.052891612704843285 |
| train_1/q_grads_std       | 0.415568894892931     |
| train_1/q_loss            | 1.8566471640467852    |
| train_1/reward            | -2.6084280609797132   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00810546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.396582357854733   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 1061.62. Rollout time: 668.26, Training time: 393.07
Evaluating epoch 23
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 2179425.0             |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.80121047432399    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.542058093894141    |
| train_0/fw_bonus          | -0.9992278292775154   |
| train_0/fw_loss           | 0.006538151169661432  |
| train_0/mu_grads          | -0.006883579795248807 |
| train_0/mu_grads_std      | 0.44118779301643374   |
| train_0/mu_loss           | 9.393113078822484     |
| train_0/next_q            | -9.384399486741907    |
| train_0/q_grads           | -0.019347369810566305 |
| train_0/q_grads_std       | 0.24586928486824036   |
| train_0/q_loss            | 0.22945526054145676   |
| train_0/reward            | -0.6490501200201834   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0750732421875       |
| train_0/target_q          | -9.698265108451796    |
| train_1/avg_q             | -20.711325058849493   |
| train_1/current_q         | -23.002562942451288   |
| train_1/fw_bonus          | -0.9928205668926239   |
| train_1/fw_loss           | 0.07286406327039004   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.053133551683276894 |
| train_1/q_grads_std       | 0.42301119565963746   |
| train_1/q_loss            | 1.3910992191012261    |
| train_1/reward            | -2.704729798350672    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0081787109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.353348938975685   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 1027.61. Rollout time: 635.62, Training time: 391.84
Evaluating epoch 24
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2270550.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.645108203730143   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.539504685836402    |
| train_0/fw_bonus          | -0.9991882190108299   |
| train_0/fw_loss           | 0.006844273372553289  |
| train_0/mu_grads          | -0.00615377762587741  |
| train_0/mu_grads_std      | 0.44549084156751634   |
| train_0/mu_loss           | 9.394208889581979     |
| train_0/next_q            | -9.3868184540622      |
| train_0/q_grads           | -0.019769560685381292 |
| train_0/q_grads_std       | 0.25022856146097183   |
| train_0/q_loss            | 0.24148985679077625   |
| train_0/reward            | -0.644444270236636    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1000244140625       |
| train_0/target_q          | -9.694992158450834    |
| train_1/avg_q             | -20.761943270643854   |
| train_1/current_q         | -23.012884488707066   |
| train_1/fw_bonus          | -0.992776845395565    |
| train_1/fw_loss           | 0.07322765029966831   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05458830343559384  |
| train_1/q_grads_std       | 0.430267670750618     |
| train_1/q_loss            | 1.505943549137454     |
| train_1/reward            | -2.666925904484015    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00810546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.360118775577778   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 1020.23. Rollout time: 633.63, Training time: 386.25
Evaluating epoch 25
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2361675.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.551828087578862   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.692896303908535    |
| train_0/fw_bonus          | -0.9991909429430962   |
| train_0/fw_loss           | 0.006823150860145688  |
| train_0/mu_grads          | -0.006497715425211936 |
| train_0/mu_grads_std      | 0.4503080390393734    |
| train_0/mu_loss           | 9.548844489872597     |
| train_0/next_q            | -9.542171178811616    |
| train_0/q_grads           | -0.020462656766176222 |
| train_0/q_grads_std       | 0.2548489935696125    |
| train_0/q_loss            | 0.23500063567549317   |
| train_0/reward            | -0.649187385269397    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1248779296875       |
| train_0/target_q          | -9.849135772458604    |
| train_1/avg_q             | -20.797910810002136   |
| train_1/current_q         | -22.95600009302384    |
| train_1/fw_bonus          | -0.9922982916235924   |
| train_1/fw_loss           | 0.07720887139439583   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05628357995301485  |
| train_1/q_grads_std       | 0.4363770060241222    |
| train_1/q_loss            | 1.9699994481764573    |
| train_1/reward            | -2.653055039758692    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0084228515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.314594102258706   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 1014.76. Rollout time: 633.58, Training time: 380.79
Evaluating epoch 26
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2452800.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.499346687036187   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.556452790694403    |
| train_0/fw_bonus          | -0.9991766020655632   |
| train_0/fw_loss           | 0.006934063171502203  |
| train_0/mu_grads          | -0.005919206130784005 |
| train_0/mu_grads_std      | 0.45578955560922624   |
| train_0/mu_loss           | 9.415230043214663     |
| train_0/next_q            | -9.406760171872847    |
| train_0/q_grads           | -0.021882294863462447 |
| train_0/q_grads_std       | 0.2601378999650478    |
| train_0/q_loss            | 0.22554707012859065   |
| train_0/reward            | -0.6466386313230033   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1012939453125       |
| train_0/target_q          | -9.71015120661375     |
| train_1/avg_q             | -20.72104079574657    |
| train_1/current_q         | -23.119028731441787   |
| train_1/fw_bonus          | -0.9917800351977348   |
| train_1/fw_loss           | 0.08152028787881135   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05805657310411334  |
| train_1/q_grads_std       | 0.44309078603982927   |
| train_1/q_loss            | 1.6213298244808438    |
| train_1/reward            | -2.6681049192855424   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0076416015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.481453063816808   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 1018.04. Rollout time: 633.91, Training time: 383.94
Evaluating epoch 27
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2543925.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.408515654056053   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.556337705490728    |
| train_0/fw_bonus          | -0.9991377994418145   |
| train_0/fw_loss           | 0.007233854744117707  |
| train_0/mu_grads          | -0.005144187214318663 |
| train_0/mu_grads_std      | 0.4619659692049026    |
| train_0/mu_loss           | 9.413538985027017     |
| train_0/next_q            | -9.408050865164425    |
| train_0/q_grads           | -0.022649047384038567 |
| train_0/q_grads_std       | 0.26670135334134104   |
| train_0/q_loss            | 0.26087861785879535   |
| train_0/reward            | -0.6486980254725495   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.096435546875        |
| train_0/target_q          | -9.710624653908543    |
| train_1/avg_q             | -20.731887730347765   |
| train_1/current_q         | -23.253404768512077   |
| train_1/fw_bonus          | -0.9905943498015404   |
| train_1/fw_loss           | 0.0913839703425765    |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0590297088958323   |
| train_1/q_grads_std       | 0.4497307017445564    |
| train_1/q_loss            | 1.648144521617337     |
| train_1/reward            | -2.6476119678816756   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0074462890625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.62052114756919    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 1027.07. Rollout time: 639.24, Training time: 387.50
Evaluating epoch 28
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 2635050.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.509975121852754    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.9999999999301      |
| train_0/current_q         | -9.585764322915573     |
| train_0/fw_bonus          | -0.9991139322519302    |
| train_0/fw_loss           | 0.007418349850922823   |
| train_0/mu_grads          | -0.0034993374429177493 |
| train_0/mu_grads_std      | 0.4680224873125553     |
| train_0/mu_loss           | 9.441061100729891      |
| train_0/next_q            | -9.433275471648134     |
| train_0/q_grads           | -0.023673561913892627  |
| train_0/q_grads_std       | 0.2719609379768372     |
| train_0/q_loss            | 0.23581173608162417    |
| train_0/reward            | -0.6484906413323188    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1259033203125        |
| train_0/target_q          | -9.740263678159568     |
| train_1/avg_q             | -20.667087699615973    |
| train_1/current_q         | -23.310854144408143    |
| train_1/fw_bonus          | -0.9898771360516548    |
| train_1/fw_loss           | 0.09735052213072777    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.05980019401758909   |
| train_1/q_grads_std       | 0.45652989149093626    |
| train_1/q_loss            | 1.3116737972934591     |
| train_1/reward            | -2.691139939007553     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078125              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.67115507572632     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 1032.72. Rollout time: 649.10, Training time: 383.38
Evaluating epoch 29
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2726175.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.54174432349505    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999991438   |
| train_0/current_q         | -9.620540375088819    |
| train_0/fw_bonus          | -0.9991653487086296   |
| train_0/fw_loss           | 0.0070209612371399995 |
| train_0/mu_grads          | -0.00323528153821826  |
| train_0/mu_grads_std      | 0.4738317415118217    |
| train_0/mu_loss           | 9.473545490582449     |
| train_0/next_q            | -9.467053653046       |
| train_0/q_grads           | -0.02448305543512106  |
| train_0/q_grads_std       | 0.27827357724308965   |
| train_0/q_loss            | 0.2578367765691456    |
| train_0/reward            | -0.6534473439223802   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.10185546875         |
| train_0/target_q          | -9.775346313907574    |
| train_1/avg_q             | -20.74403321776514    |
| train_1/current_q         | -23.448336424924992   |
| train_1/fw_bonus          | -0.9900674685835839   |
| train_1/fw_loss           | 0.09576724637299776   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.061437458358705045 |
| train_1/q_grads_std       | 0.46354955807328224   |
| train_1/q_loss            | 1.2417657800596071    |
| train_1/reward            | -2.597968524793032    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0072265625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.8299221380743     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 1079.63. Rollout time: 674.96, Training time: 404.24
Evaluating epoch 30
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2817300.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999995     |
| test_1/avg_q              | -20.989010568109364    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999986394     |
| train_0/current_q         | -9.61156463458641      |
| train_0/fw_bonus          | -0.9991921469569206    |
| train_0/fw_loss           | 0.006813895201776177   |
| train_0/mu_grads          | -0.0031661442364566026 |
| train_0/mu_grads_std      | 0.4776628464460373     |
| train_0/mu_loss           | 9.466472263437982      |
| train_0/next_q            | -9.45849864977101      |
| train_0/q_grads           | -0.024688212107867     |
| train_0/q_grads_std       | 0.2840674176812172     |
| train_0/q_loss            | 0.24851935486466817    |
| train_0/reward            | -0.6530512100158375    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.099560546875         |
| train_0/target_q          | -9.76680202882459      |
| train_1/avg_q             | -20.712282012435445    |
| train_1/current_q         | -23.548486825613374    |
| train_1/fw_bonus          | -0.990561380982399     |
| train_1/fw_loss           | 0.09165831450372934    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.06378214508295059   |
| train_1/q_grads_std       | 0.4696009702980518     |
| train_1/q_loss            | 1.6920302982614401     |
| train_1/reward            | -2.658974571351064     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007421875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.92839595806983     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 1035.21. Rollout time: 647.39, Training time: 387.59
Evaluating epoch 31
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2908425.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.487648412284685   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999638   |
| train_0/current_q         | -9.568831363464898    |
| train_0/fw_bonus          | -0.9991782575845718   |
| train_0/fw_loss           | 0.006921243690885604  |
| train_0/mu_grads          | -0.003932655893731862 |
| train_0/mu_grads_std      | 0.48081138730049133   |
| train_0/mu_loss           | 9.403570101292294     |
| train_0/next_q            | -9.39828783529694     |
| train_0/q_grads           | -0.02534985593520105  |
| train_0/q_grads_std       | 0.2907974749803543    |
| train_0/q_loss            | 0.2549932802115932    |
| train_0/reward            | -0.6640889973517915   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0732177734375       |
| train_0/target_q          | -9.723297072098628    |
| train_1/avg_q             | -20.846477266250673   |
| train_1/current_q         | -23.54967717504879    |
| train_1/fw_bonus          | -0.9897048801183701   |
| train_1/fw_loss           | 0.09878349956125021   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06522737573832274  |
| train_1/q_grads_std       | 0.4753131665289402    |
| train_1/q_loss            | 1.314646586006862     |
| train_1/reward            | -2.616902537150236    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0065185546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.92702167777525    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 1050.74. Rollout time: 658.19, Training time: 392.16
Evaluating epoch 32
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 2999550.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.589025423778097   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999999999964     |
| train_0/current_q         | -9.650969738038963    |
| train_0/fw_bonus          | -0.9991620570421219   |
| train_0/fw_loss           | 0.007046480884309858  |
| train_0/mu_grads          | -0.002876291872235015 |
| train_0/mu_grads_std      | 0.4863642491400242    |
| train_0/mu_loss           | 9.48320875350255      |
| train_0/next_q            | -9.476318356142814    |
| train_0/q_grads           | -0.026154246740043165 |
| train_0/q_grads_std       | 0.2957866176962852    |
| train_0/q_loss            | 0.24960202590443376   |
| train_0/reward            | -0.6698344577496755   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0656494140625       |
| train_0/target_q          | -9.805959634996801    |
| train_1/avg_q             | -20.767240848277584   |
| train_1/current_q         | -23.499824419743145   |
| train_1/fw_bonus          | -0.9898931160569191   |
| train_1/fw_loss           | 0.09721762705594302   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06596919465810061  |
| train_1/q_grads_std       | 0.4810089595615864    |
| train_1/q_loss            | 1.214349418212955     |
| train_1/reward            | -2.5953248399884616   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0070556640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.875082164207225   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 1081.26. Rollout time: 680.17, Training time: 400.83
Evaluating epoch 33
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 3090675.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.378841435146196   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.629585633002032    |
| train_0/fw_bonus          | -0.9991745606064797   |
| train_0/fw_loss           | 0.006949712871573865  |
| train_0/mu_grads          | -0.002925580972805619 |
| train_0/mu_grads_std      | 0.4902889184653759    |
| train_0/mu_loss           | 9.4603387292423       |
| train_0/next_q            | -9.451251082693679    |
| train_0/q_grads           | -0.02717019463889301  |
| train_0/q_grads_std       | 0.3002058893442154    |
| train_0/q_loss            | 0.24780032848858288   |
| train_0/reward            | -0.669947451398184    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0645751953125       |
| train_0/target_q          | -9.782648901160002    |
| train_1/avg_q             | -20.79703695647663    |
| train_1/current_q         | -23.55327298640551    |
| train_1/fw_bonus          | -0.9902631655335427   |
| train_1/fw_loss           | 0.09413897823542357   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0668803296983242   |
| train_1/q_grads_std       | 0.4867404416203499    |
| train_1/q_loss            | 1.843394271263239     |
| train_1/reward            | -2.5942088628929922   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0065673828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.93598181211176    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 1099.70. Rollout time: 685.60, Training time: 413.79
Evaluating epoch 34
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 3181800.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.46990621926749    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999999998    |
| train_0/current_q         | -9.670723506978746    |
| train_0/fw_bonus          | -0.99914420992136     |
| train_0/fw_loss           | 0.007184418046381325  |
| train_0/mu_grads          | -0.003142009803559631 |
| train_0/mu_grads_std      | 0.4955215871334076    |
| train_0/mu_loss           | 9.49527753385036      |
| train_0/next_q            | -9.491518792575667    |
| train_0/q_grads           | -0.02776168640702963  |
| train_0/q_grads_std       | 0.304800296574831     |
| train_0/q_loss            | 0.2508861157464377    |
| train_0/reward            | -0.6750485016167659   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.075244140625        |
| train_0/target_q          | -9.825341683791596    |
| train_1/avg_q             | -20.707631847173136   |
| train_1/current_q         | -23.5237758171902     |
| train_1/fw_bonus          | -0.990220907330513    |
| train_1/fw_loss           | 0.0944908007979393    |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06780416704714298  |
| train_1/q_grads_std       | 0.49184418842196465   |
| train_1/q_loss            | 1.1045454094135558    |
| train_1/reward            | -2.621499315172332    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006396484375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.897380662828596   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 1056.94. Rollout time: 669.58, Training time: 387.11
Evaluating epoch 35
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 3272925.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999325   |
| test_1/avg_q              | -20.53680296272631    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999794   |
| train_0/current_q         | -9.673831983732526    |
| train_0/fw_bonus          | -0.9991317763924599   |
| train_0/fw_loss           | 0.007280427252408117  |
| train_0/mu_grads          | -0.002254867018200457 |
| train_0/mu_grads_std      | 0.501009675860405     |
| train_0/mu_loss           | 9.500414575381843     |
| train_0/next_q            | -9.493097182772871    |
| train_0/q_grads           | -0.028371293423697354 |
| train_0/q_grads_std       | 0.3092107705771923    |
| train_0/q_loss            | 0.25600200714487964   |
| train_0/reward            | -0.6727748883316963   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.08076171875         |
| train_0/target_q          | -9.824322241177757    |
| train_1/avg_q             | -20.757052382764495   |
| train_1/current_q         | -23.501089165104002   |
| train_1/fw_bonus          | -0.9894925788044929   |
| train_1/fw_loss           | 0.10054958686232567   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06765765994787216  |
| train_1/q_grads_std       | 0.4966695196926594    |
| train_1/q_loss            | 1.6097829229601888    |
| train_1/reward            | -2.6062842808933055   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064453125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.87505967151832    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 1065.38. Rollout time: 663.80, Training time: 401.39
Evaluating epoch 36
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 3364050.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.55017468680236    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999998675   |
| train_0/current_q         | -9.716645722251181    |
| train_0/fw_bonus          | -0.9991370469331742   |
| train_0/fw_loss           | 0.007239632389973849  |
| train_0/mu_grads          | -0.001346730414661579 |
| train_0/mu_grads_std      | 0.5051910251379013    |
| train_0/mu_loss           | 9.545916932225877     |
| train_0/next_q            | -9.537021976089187    |
| train_0/q_grads           | -0.02823438639752567  |
| train_0/q_grads_std       | 0.31422116458415983   |
| train_0/q_loss            | 0.24614550672385044   |
| train_0/reward            | -0.6736917351252487   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0893798828125       |
| train_0/target_q          | -9.869152597646949    |
| train_1/avg_q             | -20.887316187728487   |
| train_1/current_q         | -23.307566095762365   |
| train_1/fw_bonus          | -0.9891004741191864   |
| train_1/fw_loss           | 0.10381157733500004   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0687144985422492   |
| train_1/q_grads_std       | 0.5019208177924156    |
| train_1/q_loss            | 0.9790915865603775    |
| train_1/reward            | -2.6669223367094674   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006689453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.671485324990734   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 1044.56. Rollout time: 638.11, Training time: 406.26
Evaluating epoch 37
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 3455175.0              |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999705     |
| test_1/avg_q              | -20.445622675836894    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999999005    |
| train_0/current_q         | -9.707088641415686     |
| train_0/fw_bonus          | -0.9991523578763009    |
| train_0/fw_loss           | 0.007121403736528009   |
| train_0/mu_grads          | -0.0013716116081923246 |
| train_0/mu_grads_std      | 0.5086901322007179     |
| train_0/mu_loss           | 9.538682906741602      |
| train_0/next_q            | -9.530683097915235     |
| train_0/q_grads           | -0.02888390263542533   |
| train_0/q_grads_std       | 0.31904617995023726    |
| train_0/q_loss            | 0.25525532488729574    |
| train_0/reward            | -0.6729448272453737    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0939208984375        |
| train_0/target_q          | -9.858694399922465     |
| train_1/avg_q             | -20.774474619815937    |
| train_1/current_q         | -23.272135514353355    |
| train_1/fw_bonus          | -0.9891789048910141    |
| train_1/fw_loss           | 0.1031590910628438     |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.0697987575083971    |
| train_1/q_grads_std       | 0.5072940483689308     |
| train_1/q_loss            | 1.1413197725629767     |
| train_1/reward            | -2.673716847275864     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.63822807774463     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 867.96. Rollout time: 541.92, Training time: 325.91
Evaluating epoch 38
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 3546300.0              |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.454117100290695    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999939032    |
| train_0/current_q         | -9.77587963566759      |
| train_0/fw_bonus          | -0.9991402491927147    |
| train_0/fw_loss           | 0.007214957091491669   |
| train_0/mu_grads          | -0.0006833780033048242 |
| train_0/mu_grads_std      | 0.5121624812483787     |
| train_0/mu_loss           | 9.613642171279734      |
| train_0/next_q            | -9.602153207918189     |
| train_0/q_grads           | -0.029457171075046064  |
| train_0/q_grads_std       | 0.32479509711265564    |
| train_0/q_loss            | 0.26984384804422906    |
| train_0/reward            | -0.6744798867945064    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.08193359375          |
| train_0/target_q          | -9.930078044569019     |
| train_1/avg_q             | -20.748662586038236    |
| train_1/current_q         | -23.30703216276937     |
| train_1/fw_bonus          | -0.9891291648149491    |
| train_1/fw_loss           | 0.10357298720628023    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.07164138313382865   |
| train_1/q_grads_std       | 0.5114907801151276     |
| train_1/q_loss            | 0.8773708461148064     |
| train_1/reward            | -2.7023787242138497    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071044921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.666889954682617    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 766.49. Rollout time: 497.34, Training time: 269.03
Evaluating epoch 39
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-------------------------------------------------------
| epoch                     | 39                      |
| policy/steps              | 3637425.0               |
| test/episodes             | 1000.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -20.977983985007043     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.999999999995993     |
| train_0/current_q         | -9.586245447894518      |
| train_0/fw_bonus          | -0.9991877272725105     |
| train_0/fw_loss           | 0.006847971200477332    |
| train_0/mu_grads          | -0.00047572655530530027 |
| train_0/mu_grads_std      | 0.5160114511847496      |
| train_0/mu_loss           | 9.423957001025357       |
| train_0/next_q            | -9.414229713559044      |
| train_0/q_grads           | -0.029922467796131967   |
| train_0/q_grads_std       | 0.33020271733403206     |
| train_0/q_loss            | 0.24212604523434447     |
| train_0/reward            | -0.6645308205170295     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0867431640625         |
| train_0/target_q          | -9.744458948591355      |
| train_1/avg_q             | -20.81726205750633      |
| train_1/current_q         | -23.311126717430007     |
| train_1/fw_bonus          | -0.9896161884069443     |
| train_1/fw_loss           | 0.09952138625085354     |
| train_1/mu_grads          | 0.024516167119145393    |
| train_1/mu_grads_std      | 0.17343875765800476     |
| train_1/mu_loss           | 28.0                    |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -27.0                   |
| train_1/q_grads           | -0.07340550124645233    |
| train_1/q_grads_std       | 0.516415137052536       |
| train_1/q_loss            | 1.263746667245656       |
| train_1/reward            | -2.610654778737808      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0075927734375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -23.683693352956574     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 754.25. Rollout time: 485.20, Training time: 268.94
Evaluating epoch 40
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 3728550.0              |
| test/episodes             | 1025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.532049602648687    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999980414    |
| train_0/current_q         | -9.521626286059774     |
| train_0/fw_bonus          | -0.9992117628455162    |
| train_0/fw_loss           | 0.006662257190328091   |
| train_0/mu_grads          | -7.312823827305692e-05 |
| train_0/mu_grads_std      | 0.5192272245883942     |
| train_0/mu_loss           | 9.365913658371957      |
| train_0/next_q            | -9.358518055295807     |
| train_0/q_grads           | -0.031011990597471596  |
| train_0/q_grads_std       | 0.33413114994764326    |
| train_0/q_loss            | 0.24071264596440428    |
| train_0/reward            | -0.658384484374983     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0645751953125        |
| train_0/target_q          | -9.67424827435379      |
| train_1/avg_q             | -20.889689222579857    |
| train_1/current_q         | -23.42835765952139     |
| train_1/fw_bonus          | -0.9903863683342934    |
| train_1/fw_loss           | 0.09311415590345859    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.0742735555395484    |
| train_1/q_grads_std       | 0.5208354517817497     |
| train_1/q_loss            | 0.8320334717979906     |
| train_1/reward            | -2.6437879991626687    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076416015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.797576085100182    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 762.94. Rollout time: 479.61, Training time: 283.19
Evaluating epoch 41
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 3819675.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999999996    |
| test_1/avg_q              | -20.59846357736626     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999999994     |
| train_0/current_q         | -9.483597541451257     |
| train_0/fw_bonus          | -0.9992327585816383    |
| train_0/fw_loss           | 0.00650006189243868    |
| train_0/mu_grads          | -0.0007560987272881903 |
| train_0/mu_grads_std      | 0.5226626068353653     |
| train_0/mu_loss           | 9.325787170144196      |
| train_0/next_q            | -9.317079504063017     |
| train_0/q_grads           | -0.031947999726980925  |
| train_0/q_grads_std       | 0.33919735103845594    |
| train_0/q_loss            | 0.22081824551195584    |
| train_0/reward            | -0.6557530123594916    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.08603515625          |
| train_0/target_q          | -9.63598578057488      |
| train_1/avg_q             | -20.792748610681866    |
| train_1/current_q         | -23.294015383639042    |
| train_1/fw_bonus          | -0.9910755529999733    |
| train_1/fw_loss           | 0.08738091513514519    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.07536537200212479   |
| train_1/q_grads_std       | 0.5256168156862259     |
| train_1/q_loss            | 0.8904701870577432     |
| train_1/reward            | -2.663222986654728     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007763671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.65938802571724     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 763.82. Rollout time: 485.19, Training time: 278.52
Evaluating epoch 42
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3910800.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999993662    |
| test_1/avg_q              | -20.655201753243347    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999999602    |
| train_0/current_q         | -9.575140822728429     |
| train_0/fw_bonus          | -0.9992938682436943    |
| train_0/fw_loss           | 0.006027794769033789   |
| train_0/mu_grads          | -0.0022038188704755156 |
| train_0/mu_grads_std      | 0.5252209097146988     |
| train_0/mu_loss           | 9.420061480689515      |
| train_0/next_q            | -9.415238105787518     |
| train_0/q_grads           | -0.032449960988014934  |
| train_0/q_grads_std       | 0.3438067831099033     |
| train_0/q_loss            | 0.2153386371506199     |
| train_0/reward            | -0.6486454867088469    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.060009765625         |
| train_0/target_q          | -9.734961874988018     |
| train_1/avg_q             | -20.730769647012085    |
| train_1/current_q         | -23.200349598282102    |
| train_1/fw_bonus          | -0.991692116856575     |
| train_1/fw_loss           | 0.0822516655549407     |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.07687850706279278   |
| train_1/q_grads_std       | 0.5312676146626473     |
| train_1/q_loss            | 1.4113632687290925     |
| train_1/reward            | -2.6740888001073473    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00751953125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.559788507138613    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 766.79. Rollout time: 483.26, Training time: 283.39
Evaluating epoch 43
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 4001925.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.45390108252676     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999994045     |
| train_0/current_q         | -9.49852968683016      |
| train_0/fw_bonus          | -0.9993369773030281    |
| train_0/fw_loss           | 0.005694511253386736   |
| train_0/mu_grads          | -0.0030622185731772333 |
| train_0/mu_grads_std      | 0.5266122087836266     |
| train_0/mu_loss           | 9.343460891311725      |
| train_0/next_q            | -9.339918232851332     |
| train_0/q_grads           | -0.032907499186694625  |
| train_0/q_grads_std       | 0.34702095612883566    |
| train_0/q_loss            | 0.21095432458766053    |
| train_0/reward            | -0.6424306818167679    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0601318359375        |
| train_0/target_q          | -9.651627814836697     |
| train_1/avg_q             | -20.789221548502006    |
| train_1/current_q         | -23.14989449945599     |
| train_1/fw_bonus          | -0.9920341238379479    |
| train_1/fw_loss           | 0.07940648030489683    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.07796797566115857   |
| train_1/q_grads_std       | 0.5362316086888314     |
| train_1/q_loss            | 2.6170493821426835     |
| train_1/reward            | -2.7458417816676954    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008642578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.526244125417712    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 773.63. Rollout time: 483.05, Training time: 290.38
Evaluating epoch 44
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 4093050.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999999996    |
| test_1/avg_q              | -20.231386565149       |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999998458    |
| train_0/current_q         | -9.635280382643156     |
| train_0/fw_bonus          | -0.9993418663740158    |
| train_0/fw_loss           | 0.005656906100921333   |
| train_0/mu_grads          | -0.0037855775910429655 |
| train_0/mu_grads_std      | 0.5287181749939919     |
| train_0/mu_loss           | 9.483533513269535      |
| train_0/next_q            | -9.478836853253553     |
| train_0/q_grads           | -0.03359257197007537   |
| train_0/q_grads_std       | 0.3512146040797234     |
| train_0/q_loss            | 0.22204049578595023    |
| train_0/reward            | -0.64743067756026      |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0659912109375        |
| train_0/target_q          | -9.792572844983226     |
| train_1/avg_q             | -20.707982455043886    |
| train_1/current_q         | -23.07609267514142     |
| train_1/fw_bonus          | -0.9924380719661713    |
| train_1/fw_loss           | 0.07604600843042135    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.07899871319532395   |
| train_1/q_grads_std       | 0.5404762849211693     |
| train_1/q_loss            | 1.777280704820265      |
| train_1/reward            | -2.723054584242709     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008349609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.44596327564897     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 765.27. Rollout time: 481.74, Training time: 283.42
Evaluating epoch 45
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 4184175.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.376946458871316   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999414   |
| train_0/current_q         | -9.37570812915773     |
| train_0/fw_bonus          | -0.9993978992104531   |
| train_0/fw_loss           | 0.005223727540578693  |
| train_0/mu_grads          | -0.004586034885141999 |
| train_0/mu_grads_std      | 0.5310182496905327    |
| train_0/mu_loss           | 9.21842979259471      |
| train_0/next_q            | -9.216511299551774    |
| train_0/q_grads           | -0.0339440381154418   |
| train_0/q_grads_std       | 0.3558709889650345    |
| train_0/q_loss            | 0.19496053015162682   |
| train_0/reward            | -0.6400289186600275   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.036865234375        |
| train_0/target_q          | -9.527782355849851    |
| train_1/avg_q             | -20.644698154517638   |
| train_1/current_q         | -23.08854539437396    |
| train_1/fw_bonus          | -0.9928928419947625   |
| train_1/fw_loss           | 0.07226269785314798   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.08103957306593657  |
| train_1/q_grads_std       | 0.544572502374649     |
| train_1/q_loss            | 1.6563954961357616    |
| train_1/reward            | -2.666405585217217    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00888671875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.46231183521723    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 806.65. Rollout time: 509.91, Training time: 296.59
Evaluating epoch 46
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 4275300.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.624824788762446   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.48466147522665     |
| train_0/fw_bonus          | -0.9994396075606347   |
| train_0/fw_loss           | 0.004901421815156936  |
| train_0/mu_grads          | -0.004419328109361231 |
| train_0/mu_grads_std      | 0.5329507440328598    |
| train_0/mu_loss           | 9.326931909606534     |
| train_0/next_q            | -9.323629992958763    |
| train_0/q_grads           | -0.034666864201426506 |
| train_0/q_grads_std       | 0.35961688831448557   |
| train_0/q_loss            | 0.18904500864176757   |
| train_0/reward            | -0.6384646375441662   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0300537109375       |
| train_0/target_q          | -9.638287707542474    |
| train_1/avg_q             | -20.609583716825384   |
| train_1/current_q         | -23.035137058231545   |
| train_1/fw_bonus          | -0.9930982559919357   |
| train_1/fw_loss           | 0.07055397350341082   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.08082473948597908  |
| train_1/q_grads_std       | 0.5485937863588333    |
| train_1/q_loss            | 1.5803507452175842    |
| train_1/reward            | -2.6775531254705127   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0072998046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.41144375047053    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 778.86. Rollout time: 495.49, Training time: 283.24
Evaluating epoch 47
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 4366425.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999998914    |
| test_1/avg_q              | -20.461231038498365   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.369193660937645    |
| train_0/fw_bonus          | -0.9994704231619835   |
| train_0/fw_loss           | 0.004663246788550168  |
| train_0/mu_grads          | -0.005585754604544491 |
| train_0/mu_grads_std      | 0.5352048426866531    |
| train_0/mu_loss           | 9.208294538476832     |
| train_0/next_q            | -9.204957592235667    |
| train_0/q_grads           | -0.035088838264346126 |
| train_0/q_grads_std       | 0.36348006278276446   |
| train_0/q_loss            | 0.16733051308820235   |
| train_0/reward            | -0.6377765413373708   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0534423828125       |
| train_0/target_q          | -9.522704592762835    |
| train_1/avg_q             | -20.704920349107176   |
| train_1/current_q         | -22.963962975920342   |
| train_1/fw_bonus          | -0.9934734895825386   |
| train_1/fw_loss           | 0.06743231760337949   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.08325068112462759  |
| train_1/q_grads_std       | 0.5520399585366249    |
| train_1/q_loss            | 1.9000016429930269    |
| train_1/reward            | -2.66248580478059     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00654296875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.332422816499353   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 765.68. Rollout time: 488.22, Training time: 277.36
Evaluating epoch 48
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4457550.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.492513538503143   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999999999843     |
| train_0/current_q         | -9.519003782060505    |
| train_0/fw_bonus          | -0.9995025530457496   |
| train_0/fw_loss           | 0.004414924496086314  |
| train_0/mu_grads          | -0.005927172116935253 |
| train_0/mu_grads_std      | 0.5376410573720932    |
| train_0/mu_loss           | 9.350218249347321     |
| train_0/next_q            | -9.34628231476685     |
| train_0/q_grads           | -0.03547320850193501  |
| train_0/q_grads_std       | 0.36743210554122924   |
| train_0/q_loss            | 0.17065147464817873   |
| train_0/reward            | -0.6394508339260938   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0294921875          |
| train_0/target_q          | -9.675046516294973    |
| train_1/avg_q             | -20.642965148085537   |
| train_1/current_q         | -22.864844064027004   |
| train_1/fw_bonus          | -0.993761932849884    |
| train_1/fw_loss           | 0.06503275549039245   |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.08343159276992082  |
| train_1/q_grads_std       | 0.5564355760812759    |
| train_1/q_loss            | 1.4974344868740754    |
| train_1/reward            | -2.639303520903195    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.005908203125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.23882695840321    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 7493.01. Rollout time: 7197.99, Training time: 294.86
Evaluating epoch 49
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 4548675.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.612695779336065   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999993403    |
| train_0/current_q         | -9.577845203606184    |
| train_0/fw_bonus          | -0.9994924083352089   |
| train_0/fw_loss           | 0.004493307950906455  |
| train_0/mu_grads          | -0.007366784883197397 |
| train_0/mu_grads_std      | 0.5389407768845558    |
| train_0/mu_loss           | 9.39557786145121      |
| train_0/next_q            | -9.391689032151255    |
| train_0/q_grads           | -0.03637890163809061  |
| train_0/q_grads_std       | 0.37069632187485696   |
| train_0/q_loss            | 0.15696947895794003   |
| train_0/reward            | -0.6421399487106101   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0435302734375       |
| train_0/target_q          | -9.731856280976167    |
| train_1/avg_q             | -20.69526293344073    |
| train_1/current_q         | -22.75621713060553    |
| train_1/fw_bonus          | -0.9938781872391701   |
| train_1/fw_loss           | 0.0640655935741961    |
| train_1/mu_grads          | 0.024516167119145393  |
| train_1/mu_grads_std      | 0.17343875765800476   |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.08466387633234262  |
| train_1/q_grads_std       | 0.5599902644753456    |
| train_1/q_loss            | 1.9101429853199605    |
| train_1/reward            | -2.654914859022756    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0048828125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -23.123947085585268   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 1212.07. Rollout time: 794.88, Training time: 417.03
Evaluating epoch 50
Data_dir: data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 50                     |
| policy/steps              | 4639800.0              |
| test/episodes             | 1275.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -20.43370720905222     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999998593    |
| train_0/current_q         | -9.52783877453739      |
| train_0/fw_bonus          | -0.9994699403643608    |
| train_0/fw_loss           | 0.004666957969311625   |
| train_0/mu_grads          | -0.0063881146372295914 |
| train_0/mu_grads_std      | 0.5412819907069206     |
| train_0/mu_loss           | 9.357230863884519      |
| train_0/next_q            | -9.351089919876284     |
| train_0/q_grads           | -0.03701958451420069   |
| train_0/q_grads_std       | 0.3735838770866394     |
| train_0/q_loss            | 0.16602077609456564    |
| train_0/reward            | -0.6405779350818193    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.039892578125         |
| train_0/target_q          | -9.684937270500138     |
| train_1/avg_q             | -20.702662390809877    |
| train_1/current_q         | -22.8629521270216      |
| train_1/fw_bonus          | -0.9938576474785805    |
| train_1/fw_loss           | 0.06423642234876752    |
| train_1/mu_grads          | 0.024516167119145393   |
| train_1/mu_grads_std      | 0.17343875765800476    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.08561463374644518   |
| train_1/q_grads_std       | 0.5636965349316597     |
| train_1/q_loss            | 1.5713531770515439     |
| train_1/reward            | -2.6671411711446127    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0049072265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -23.236302792238376    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntReacherEnv-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
