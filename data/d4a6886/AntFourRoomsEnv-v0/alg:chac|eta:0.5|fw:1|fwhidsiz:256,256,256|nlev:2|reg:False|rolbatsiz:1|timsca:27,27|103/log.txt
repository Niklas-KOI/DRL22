Starting process id: 5358
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fbe10c9e050>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 405.92. Rollout time: 225.17, Training time: 180.72
Evaluating epoch 0
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 91125.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.764951381648281   |
| test_1/avg_q              | -8.364738032266535    |
| test_1/n_subgoals         | 1351.0                |
| test_1/subgoal_succ_rate  | 0.5196150999259808    |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -8.128136610485887    |
| train_0/current_q         | -8.071140624818284    |
| train_0/fw_bonus          | -0.9935825914144516   |
| train_0/fw_loss           | 0.028588433703407645  |
| train_0/mu_grads          | -0.00443147246260196  |
| train_0/mu_grads_std      | 0.1418863721191883    |
| train_0/mu_loss           | 8.027875428010292     |
| train_0/next_q            | -8.009540749341493    |
| train_0/q_grads           | 0.0060517149977386    |
| train_0/q_grads_std       | 0.12228604424744845   |
| train_0/q_loss            | 0.5458713563988249    |
| train_0/reward            | -0.7168840726095368   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 2.44140625e-05        |
| train_0/target_q          | -8.192211342092671    |
| train_1/avg_q             | -6.749707711598989    |
| train_1/current_q         | -5.843881200373616    |
| train_1/fw_bonus          | -0.9867507293820381   |
| train_1/fw_loss           | 0.06565083945170044   |
| train_1/mu_grads          | -0.004192145622801036 |
| train_1/mu_grads_std      | 0.1288153413683176    |
| train_1/mu_loss           | 4.890107565405366     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -4.874924830317383    |
| train_1/q_grads           | 0.02232911977916956   |
| train_1/q_grads_std       | 0.10934648904949426   |
| train_1/q_loss            | 0.7934362287659715    |
| train_1/reward            | -2.098172726303164    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00078125            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -5.826307536685339    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 341.63. Rollout time: 204.54, Training time: 137.07
Evaluating epoch 1
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 181863.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -21.063245035003305   |
| test_1/avg_q              | -11.948052135248652   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -23.81781276087998    |
| train_0/current_q         | -8.77455888024648     |
| train_0/fw_bonus          | -0.9962511926889419   |
| train_0/fw_loss           | 0.016860424890182912  |
| train_0/mu_grads          | -0.008258425688836724 |
| train_0/mu_grads_std      | 0.18493100814521313   |
| train_0/mu_loss           | 8.721341314448747     |
| train_0/next_q            | -8.715128163605623    |
| train_0/q_grads           | 0.007452698959968984  |
| train_0/q_grads_std       | 0.13107691779732705   |
| train_0/q_loss            | 0.5054152456553768    |
| train_0/reward            | -0.7163629010996374   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0005859375          |
| train_0/target_q          | -8.86236208663149     |
| train_1/avg_q             | -12.555317830580833   |
| train_1/current_q         | -6.214080153843256    |
| train_1/fw_bonus          | -0.9845459684729576   |
| train_1/fw_loss           | 0.07531667295843363   |
| train_1/mu_grads          | -0.011947082332335412 |
| train_1/mu_grads_std      | 0.16230046264827253   |
| train_1/mu_loss           | 5.393056697224547     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.383790641189499    |
| train_1/q_grads           | 0.018400171725079417  |
| train_1/q_grads_std       | 0.11208862829953432   |
| train_1/q_loss            | 0.5863619970768513    |
| train_1/reward            | -2.0419311833647953   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001220703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.007037037037037037  |
| train_1/target_q          | -6.192687382647116    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 400.00. Rollout time: 235.21, Training time: 164.77
Evaluating epoch 2
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 272882.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.985921164886125   |
| test_1/avg_q              | -10.871258382450453   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.323114838640727   |
| train_0/current_q         | -9.325548492089649    |
| train_0/fw_bonus          | -0.996841587126255    |
| train_0/fw_loss           | 0.014265722129493952  |
| train_0/mu_grads          | -0.013797140517272054 |
| train_0/mu_grads_std      | 0.21217308342456817   |
| train_0/mu_loss           | 9.28157483183518      |
| train_0/next_q            | -9.266182921128387    |
| train_0/q_grads           | 0.006793589482549578  |
| train_0/q_grads_std       | 0.13389343582093716   |
| train_0/q_loss            | 0.36351512871200864   |
| train_0/reward            | -0.7195267533381411   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0001953125          |
| train_0/target_q          | -9.469411750918777    |
| train_1/avg_q             | -13.147357104984527   |
| train_1/current_q         | -6.41425717185823     |
| train_1/fw_bonus          | -0.9811573669314384   |
| train_1/fw_loss           | 0.09017247259616852   |
| train_1/mu_grads          | -0.018496893951669334 |
| train_1/mu_grads_std      | 0.18780584931373595   |
| train_1/mu_loss           | 5.621786461520078     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.611560609729639    |
| train_1/q_grads           | 0.011850537359714508  |
| train_1/q_grads_std       | 0.11999143157154321   |
| train_1/q_loss            | 0.48856220099614944   |
| train_1/reward            | -2.1174829812080134   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0025925925925925925 |
| train_1/target_q          | -6.399587863254304    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 390.23. Rollout time: 228.98, Training time: 161.22
Evaluating epoch 3
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 363948.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.87570904221967    |
| test_1/avg_q              | -13.192076706538797   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.647951474057873   |
| train_0/current_q         | -8.976687039023295    |
| train_0/fw_bonus          | -0.9972265839576722   |
| train_0/fw_loss           | 0.012573761492967605  |
| train_0/mu_grads          | -0.01861117868684232  |
| train_0/mu_grads_std      | 0.23920583240687848   |
| train_0/mu_loss           | 8.91632341781631      |
| train_0/next_q            | -8.903153253855276    |
| train_0/q_grads           | 0.0062012634938582775 |
| train_0/q_grads_std       | 0.1379546072334051    |
| train_0/q_loss            | 0.29629640092727394   |
| train_0/reward            | -0.7215380954250576   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0029052734375       |
| train_0/target_q          | -9.123680939372822    |
| train_1/avg_q             | -13.064314353388973   |
| train_1/current_q         | -6.547739627703931    |
| train_1/fw_bonus          | -0.9796809166669845   |
| train_1/fw_loss           | 0.09664537012577057   |
| train_1/mu_grads          | -0.02172618042677641  |
| train_1/mu_grads_std      | 0.20048669241368772   |
| train_1/mu_loss           | 5.796200421897861     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.770411007183416    |
| train_1/q_grads           | 0.0028407130332197992 |
| train_1/q_grads_std       | 0.12959479354321957   |
| train_1/q_loss            | 0.2143104063879009    |
| train_1/reward            | -2.110458129559265    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0014814814814814814 |
| train_1/target_q          | -6.541588220858991    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 411.94. Rollout time: 239.61, Training time: 172.30
Evaluating epoch 4
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 454865.0              |
| test/episodes             | 125.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -22.035400689741      |
| test_1/avg_q              | -12.40718097094442    |
| test_1/n_subgoals         | 683.0                 |
| test_1/subgoal_succ_rate  | 0.016105417276720352  |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.341740536070873   |
| train_0/current_q         | -9.287491873526731    |
| train_0/fw_bonus          | -0.9973937258124351   |
| train_0/fw_loss           | 0.011839199997484683  |
| train_0/mu_grads          | -0.019563856115564705 |
| train_0/mu_grads_std      | 0.26248234435915946   |
| train_0/mu_loss           | 9.233579056828901     |
| train_0/next_q            | -9.22796799363189     |
| train_0/q_grads           | 0.006728085456416011  |
| train_0/q_grads_std       | 0.144613553583622     |
| train_0/q_loss            | 0.33720801682498697   |
| train_0/reward            | -0.7190581899456447   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.002734375           |
| train_0/target_q          | -9.436022010353755    |
| train_1/avg_q             | -13.594482107761198   |
| train_1/current_q         | -6.378836317487087    |
| train_1/fw_bonus          | -0.9777913108468056   |
| train_1/fw_loss           | 0.1049294477328658    |
| train_1/mu_grads          | -0.02612793571315706  |
| train_1/mu_grads_std      | 0.21522128023207188   |
| train_1/mu_loss           | 5.599025536424625     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.59170451122426     |
| train_1/q_grads           | -0.005486787052359432 |
| train_1/q_grads_std       | 0.1394399669021368    |
| train_1/q_loss            | 0.18518644341206666   |
| train_1/reward            | -2.098893217407749    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0044444444444444444 |
| train_1/target_q          | -6.378166691478957    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 401.95. Rollout time: 231.87, Training time: 170.05
Evaluating epoch 5
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 545563.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.819452794987248   |
| test_1/avg_q              | -10.768575078951983   |
| test_1/n_subgoals         | 1078.0                |
| test_1/subgoal_succ_rate  | 0.39332096474953615   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.96624323525275    |
| train_0/current_q         | -9.396072488564197    |
| train_0/fw_bonus          | -0.9972514703869819   |
| train_0/fw_loss           | 0.012464374932460488  |
| train_0/mu_grads          | -0.025820729648694397 |
| train_0/mu_grads_std      | 0.2873198248445988    |
| train_0/mu_loss           | 9.348113414556583     |
| train_0/next_q            | -9.340772663419532    |
| train_0/q_grads           | 0.005496298964135349  |
| train_0/q_grads_std       | 0.15039059482514858   |
| train_0/q_loss            | 0.42397520053376425   |
| train_0/reward            | -0.7269216340995627   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00673828125         |
| train_0/target_q          | -9.540838293823098    |
| train_1/avg_q             | -13.374133851930866   |
| train_1/current_q         | -5.831607226609535    |
| train_1/fw_bonus          | -0.9752172067761421   |
| train_1/fw_loss           | 0.11621448546648025   |
| train_1/mu_grads          | -0.028658288484439253 |
| train_1/mu_grads_std      | 0.22115452960133553   |
| train_1/mu_loss           | 4.871248067096433     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -4.869532009308031    |
| train_1/q_grads           | -0.013921349612064659 |
| train_1/q_grads_std       | 0.1554027423262596    |
| train_1/q_loss            | 0.19006624051056903   |
| train_1/reward            | -2.1125963994629275   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 7.32421875e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.01037037037037037   |
| train_1/target_q          | -5.833944586970854    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 396.38. Rollout time: 223.39, Training time: 172.96
Evaluating epoch 6
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 635612.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -18.005588859938676   |
| test_1/avg_q              | -10.279613245783576   |
| test_1/n_subgoals         | 684.0                 |
| test_1/subgoal_succ_rate  | 0.02046783625730994   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.26837591992015    |
| train_0/current_q         | -9.38076965768783     |
| train_0/fw_bonus          | -0.9970728024840355   |
| train_0/fw_loss           | 0.013249593600630761  |
| train_0/mu_grads          | -0.027924937102943657 |
| train_0/mu_grads_std      | 0.31151309236884117   |
| train_0/mu_loss           | 9.316660914564327     |
| train_0/next_q            | -9.30002101839814     |
| train_0/q_grads           | 0.006300704984460026  |
| train_0/q_grads_std       | 0.15731177665293217   |
| train_0/q_loss            | 0.4818020971595155    |
| train_0/reward            | -0.736805444318452    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0174560546875       |
| train_0/target_q          | -9.535941451514168    |
| train_1/avg_q             | -13.10168876123308    |
| train_1/current_q         | -5.652534008797862    |
| train_1/fw_bonus          | -0.9726334184408187   |
| train_1/fw_loss           | 0.12754203770309686   |
| train_1/mu_grads          | -0.03002726649865508  |
| train_1/mu_grads_std      | 0.22638153694570065   |
| train_1/mu_loss           | 4.64673914458732      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -4.625118037494632    |
| train_1/q_grads           | -0.0228084912057966   |
| train_1/q_grads_std       | 0.1759828392416239    |
| train_1/q_loss            | 0.189291928374703     |
| train_1/reward            | -2.1133064517729507   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.02148148148148148   |
| train_1/target_q          | -5.655045201570794    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 401.50. Rollout time: 227.40, Training time: 174.07
Evaluating epoch 7
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 7                    |
| policy/steps              | 725671.0             |
| test/episodes             | 200.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -16.467621270771286  |
| test_1/avg_q              | -7.356425126902909   |
| test_1/n_subgoals         | 685.0                |
| test_1/subgoal_succ_rate  | 0.016058394160583942 |
| train/episodes            | 800.0                |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -24.836132428651478  |
| train_0/current_q         | -9.56223090885652    |
| train_0/fw_bonus          | -0.9968398660421371  |
| train_0/fw_loss           | 0.014273328194394707 |
| train_0/mu_grads          | -0.03532216101884842 |
| train_0/mu_grads_std      | 0.3350006267428398   |
| train_0/mu_loss           | 9.482219361457286    |
| train_0/next_q            | -9.460525145113632   |
| train_0/q_grads           | 0.005789119633845985 |
| train_0/q_grads_std       | 0.16654655374586583  |
| train_0/q_loss            | 0.613287110310149    |
| train_0/reward            | -0.7498359463425004  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0130859375         |
| train_0/target_q          | -9.691780788312967   |
| train_1/avg_q             | -13.083450020400514  |
| train_1/current_q         | -5.0978355203116     |
| train_1/fw_bonus          | -0.9719143509864807  |
| train_1/fw_loss           | 0.13069440014660358  |
| train_1/mu_grads          | -0.03158565144985914 |
| train_1/mu_grads_std      | 0.22803048975765705  |
| train_1/mu_loss           | 3.9106277606902773   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -3.890150170195271   |
| train_1/q_grads           | -0.03184038167819381 |
| train_1/q_grads_std       | 0.19766404666006565  |
| train_1/q_loss            | 0.19432331944838843  |
| train_1/reward            | -2.0991407743946184  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 4.8828125e-05        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.022222222222222223 |
| train_1/target_q          | -5.096187878267193   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 398.31. Rollout time: 224.26, Training time: 174.02
Evaluating epoch 8
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 814284.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -12.989612372720345   |
| test_1/avg_q              | -7.885843284184483    |
| test_1/n_subgoals         | 1379.0                |
| test_1/subgoal_succ_rate  | 0.5474981870920957    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -24.071727701354735   |
| train_0/current_q         | -9.37996694223374     |
| train_0/fw_bonus          | -0.9963972106575966   |
| train_0/fw_loss           | 0.016218699142336847  |
| train_0/mu_grads          | -0.03929590824991465  |
| train_0/mu_grads_std      | 0.35633460357785224   |
| train_0/mu_loss           | 9.258759523514223     |
| train_0/next_q            | -9.230136143940246    |
| train_0/q_grads           | 0.00425944288726896   |
| train_0/q_grads_std       | 0.17481642141938208   |
| train_0/q_loss            | 0.6320275764481087    |
| train_0/reward            | -0.7630301486213285   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005322265625        |
| train_0/target_q          | -9.506614478152263    |
| train_1/avg_q             | -12.563196064726167   |
| train_1/current_q         | -4.9486874043587505   |
| train_1/fw_bonus          | -0.9691735982894898   |
| train_1/fw_loss           | 0.1427100721746683    |
| train_1/mu_grads          | -0.03321203952655196  |
| train_1/mu_grads_std      | 0.2320980079472065    |
| train_1/mu_loss           | 3.712168173313427     |
| train_1/n_subgoals        | 2699.0                |
| train_1/next_q            | -3.70027208312676     |
| train_1/q_grads           | -0.039813284575939176 |
| train_1/q_grads_std       | 0.22005810737609863   |
| train_1/q_loss            | 0.2761197311497662    |
| train_1/reward            | -2.0901654118439184   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.041126343090033345  |
| train_1/target_q          | -4.950219342468156    |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 9
Time for epoch 9: 399.90. Rollout time: 221.16, Training time: 178.71
Evaluating epoch 9
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 901413.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.469313536436609   |
| test_1/avg_q              | -6.976700268582843    |
| test_1/n_subgoals         | 698.0                 |
| test_1/subgoal_succ_rate  | 0.04011461318051576   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.06                  |
| train_0/avg_q             | -23.023275565568305   |
| train_0/current_q         | -9.365503050928135    |
| train_0/fw_bonus          | -0.9957930788397789   |
| train_0/fw_loss           | 0.01887380345724523   |
| train_0/mu_grads          | -0.04442071784287691  |
| train_0/mu_grads_std      | 0.37672172114253044   |
| train_0/mu_loss           | 9.241678369918606     |
| train_0/next_q            | -9.197327698760997    |
| train_0/q_grads           | 0.0029495009512174875 |
| train_0/q_grads_std       | 0.182686797529459     |
| train_0/q_loss            | 0.8045704841839644    |
| train_0/reward            | -0.7816123542623246   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0094482421875       |
| train_0/target_q          | -9.483834913264099    |
| train_1/avg_q             | -12.145318355226784   |
| train_1/current_q         | -4.840462445724491    |
| train_1/fw_bonus          | -0.9656407982110977   |
| train_1/fw_loss           | 0.15819808319211007   |
| train_1/mu_grads          | -0.03437747620046139  |
| train_1/mu_grads_std      | 0.23547051660716534   |
| train_1/mu_loss           | 3.5335981392297726    |
| train_1/n_subgoals        | 2640.0                |
| train_1/next_q            | -3.5162309756889925   |
| train_1/q_grads           | -0.04766482133418322  |
| train_1/q_grads_std       | 0.24617692418396472   |
| train_1/q_loss            | 0.44548714880976653   |
| train_1/reward            | -2.1085772364385775   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.05303030303030303   |
| train_1/target_q          | -4.844552646469154    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 10
Time for epoch 10: 394.45. Rollout time: 221.99, Training time: 172.43
Evaluating epoch 10
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 10                   |
| policy/steps              | 988454.0             |
| test/episodes             | 275.0                |
| test/success_rate         | 0.04                 |
| test_0/avg_q              | -16.48157371078254   |
| test_1/avg_q              | -4.565811475864211   |
| test_1/n_subgoals         | 694.0                |
| test_1/subgoal_succ_rate  | 0.05043227665706052  |
| train/episodes            | 1100.0               |
| train/success_rate        | 0.05                 |
| train_0/avg_q             | -22.745408543798565  |
| train_0/current_q         | -9.60099476918354    |
| train_0/fw_bonus          | -0.9950513571500779  |
| train_0/fw_loss           | 0.022133516147732735 |
| train_0/mu_grads          | -0.04901415146887302 |
| train_0/mu_grads_std      | 0.3934456527233124   |
| train_0/mu_loss           | 9.45104735936658     |
| train_0/next_q            | -9.402652550434444   |
| train_0/q_grads           | 0.002485095750307664 |
| train_0/q_grads_std       | 0.1910936411470175   |
| train_0/q_loss            | 0.9280835826774215   |
| train_0/reward            | -0.8004309493189794  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0065673828125      |
| train_0/target_q          | -9.705818778572318   |
| train_1/avg_q             | -11.655238894810989  |
| train_1/current_q         | -4.881441601169927   |
| train_1/fw_bonus          | -0.9608736127614975  |
| train_1/fw_loss           | 0.17909776605665684  |
| train_1/mu_grads          | -0.03563023237511516 |
| train_1/mu_grads_std      | 0.24158712662756443  |
| train_1/mu_loss           | 3.565563931395535    |
| train_1/n_subgoals        | 2667.0               |
| train_1/next_q            | -3.553190820665751   |
| train_1/q_grads           | -0.05468195164576173 |
| train_1/q_grads_std       | 0.2714759796857834   |
| train_1/q_loss            | 0.649486697904805    |
| train_1/reward            | -2.1112717630545377  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 2.44140625e-05       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.06749156355455568  |
| train_1/target_q          | -4.876768732120452   |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_10.pkl ...
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 11
Time for epoch 11: 390.79. Rollout time: 213.59, Training time: 177.18
Evaluating epoch 11
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1070202.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -11.544521277643595   |
| test_1/avg_q              | -7.1145787030645895   |
| test_1/n_subgoals         | 1770.0                |
| test_1/subgoal_succ_rate  | 0.7209039548022599    |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.14                  |
| train_0/avg_q             | -22.288849833688325   |
| train_0/current_q         | -9.377571602639652    |
| train_0/fw_bonus          | -0.9945944815874099   |
| train_0/fw_loss           | 0.02414140650071204   |
| train_0/mu_grads          | -0.049292806070297956 |
| train_0/mu_grads_std      | 0.4098645806312561    |
| train_0/mu_loss           | 9.192387933504332     |
| train_0/next_q            | -9.131120046406163    |
| train_0/q_grads           | 0.0011661567550618201 |
| train_0/q_grads_std       | 0.19981739185750486   |
| train_0/q_loss            | 0.9656963935108436    |
| train_0/reward            | -0.8118846401339397   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020263671875       |
| train_0/target_q          | -9.46437384985499     |
| train_1/avg_q             | -11.02955644653225    |
| train_1/current_q         | -4.678162612620904    |
| train_1/fw_bonus          | -0.9583059698343277   |
| train_1/fw_loss           | 0.19035443030297755   |
| train_1/mu_grads          | -0.03752596648409963  |
| train_1/mu_grads_std      | 0.24670329466462135   |
| train_1/mu_loss           | 3.305377102795885     |
| train_1/n_subgoals        | 2574.0                |
| train_1/next_q            | -3.293117941264616    |
| train_1/q_grads           | -0.06065489528700709  |
| train_1/q_grads_std       | 0.29534086138010024   |
| train_1/q_loss            | 0.8379092464722053    |
| train_1/reward            | -2.0659449777231202   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.07886557886557886   |
| train_1/target_q          | -4.675231419828061    |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 12
Time for epoch 12: 383.57. Rollout time: 209.29, Training time: 174.25
Evaluating epoch 12
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1150895.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -11.163322915116296   |
| test_1/avg_q              | -2.5537519181327695   |
| test_1/n_subgoals         | 1155.0                |
| test_1/subgoal_succ_rate  | 0.529004329004329     |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.16                  |
| train_0/avg_q             | -21.351146831055075   |
| train_0/current_q         | -9.235804414531163    |
| train_0/fw_bonus          | -0.99404985755682     |
| train_0/fw_loss           | 0.02653488740324974   |
| train_0/mu_grads          | -0.05145301036536694  |
| train_0/mu_grads_std      | 0.42616624385118484   |
| train_0/mu_loss           | 9.027500636206721     |
| train_0/next_q            | -8.949475702765902    |
| train_0/q_grads           | 0.0004478030117752496 |
| train_0/q_grads_std       | 0.20977651625871657   |
| train_0/q_loss            | 1.0343966192894722    |
| train_0/reward            | -0.8256260056354222   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.001123046875        |
| train_0/target_q          | -9.312658142927157    |
| train_1/avg_q             | -10.796315864270184   |
| train_1/current_q         | -4.576546760199134    |
| train_1/fw_bonus          | -0.9542029544711113   |
| train_1/fw_loss           | 0.20834233313798906   |
| train_1/mu_grads          | -0.039672178123146294 |
| train_1/mu_grads_std      | 0.2520847827196121    |
| train_1/mu_loss           | 3.155053317731949     |
| train_1/n_subgoals        | 2565.0                |
| train_1/next_q            | -3.136849224371222    |
| train_1/q_grads           | -0.06736052129417658  |
| train_1/q_grads_std       | 0.3143428035080433    |
| train_1/q_loss            | 1.0852240342839985    |
| train_1/reward            | -2.071425204375555    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11228070175438597   |
| train_1/target_q          | -4.57702060630406     |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.11000000000000001
Training epoch 13
Time for epoch 13: 390.43. Rollout time: 210.25, Training time: 180.16
Evaluating epoch 13
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1228674.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -13.708981811457129   |
| test_1/avg_q              | -4.873302773162016    |
| test_1/n_subgoals         | 501.0                 |
| test_1/subgoal_succ_rate  | 0.08383233532934131   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.17                  |
| train_0/avg_q             | -21.255961769332302   |
| train_0/current_q         | -9.350356488424534    |
| train_0/fw_bonus          | -0.9937355577945709   |
| train_0/fw_loss           | 0.02791622020304203   |
| train_0/mu_grads          | -0.05546764703467488  |
| train_0/mu_grads_std      | 0.4408307269215584    |
| train_0/mu_loss           | 9.13610887533472      |
| train_0/next_q            | -9.04179850126619     |
| train_0/q_grads           | 0.0014710990770254284 |
| train_0/q_grads_std       | 0.21945250667631627   |
| train_0/q_loss            | 1.1123088487136203    |
| train_0/reward            | -0.8345752966131841   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00068359375         |
| train_0/target_q          | -9.430456438015693    |
| train_1/avg_q             | -10.649889502058752   |
| train_1/current_q         | -4.645696730280468    |
| train_1/fw_bonus          | -0.9517682448029519   |
| train_1/fw_loss           | 0.21901624724268914   |
| train_1/mu_grads          | -0.04040557276457548  |
| train_1/mu_grads_std      | 0.25746083036065104   |
| train_1/mu_loss           | 3.2600335958599063    |
| train_1/n_subgoals        | 2569.0                |
| train_1/next_q            | -3.234855255445022    |
| train_1/q_grads           | -0.07311689164489507  |
| train_1/q_grads_std       | 0.3313164830207825    |
| train_1/q_loss            | 1.2435882591027825    |
| train_1/reward            | -2.037859219054371    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11794472557415336   |
| train_1/target_q          | -4.6510858770113135   |
-----------------------------------------------------
New best value for test/success_rate: 0.4. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.21000000000000002
Training epoch 14
Time for epoch 14: 371.23. Rollout time: 191.07, Training time: 180.14
Evaluating epoch 14
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 1302694.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -11.226008356284096   |
| test_1/avg_q              | -2.4704661753797996   |
| test_1/n_subgoals         | 1159.0                |
| test_1/subgoal_succ_rate  | 0.6125970664365833    |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.32                  |
| train_0/avg_q             | -21.326980431275075   |
| train_0/current_q         | -9.299780972330066    |
| train_0/fw_bonus          | -0.9933498620986938   |
| train_0/fw_loss           | 0.029611261421814562  |
| train_0/mu_grads          | -0.05837311903014779  |
| train_0/mu_grads_std      | 0.45356611907482147   |
| train_0/mu_loss           | 9.0564074029141       |
| train_0/next_q            | -8.972304501916701    |
| train_0/q_grads           | 0.0015931256377371028 |
| train_0/q_grads_std       | 0.22756510972976685   |
| train_0/q_loss            | 1.1205243645327059    |
| train_0/reward            | -0.8384351857530419   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00078125            |
| train_0/target_q          | -9.375691770233628    |
| train_1/avg_q             | -10.536122493417352   |
| train_1/current_q         | -4.400782253249884    |
| train_1/fw_bonus          | -0.9502194330096245   |
| train_1/fw_loss           | 0.225806325674057     |
| train_1/mu_grads          | -0.04110744213685393  |
| train_1/mu_grads_std      | 0.2621648110449314    |
| train_1/mu_loss           | 2.972771592408294     |
| train_1/n_subgoals        | 2383.0                |
| train_1/next_q            | -2.946483911695722    |
| train_1/q_grads           | -0.07752051614224911  |
| train_1/q_grads_std       | 0.3469452053308487    |
| train_1/q_loss            | 1.2660054318213827    |
| train_1/reward            | -1.9733274896192596   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11372219890893831   |
| train_1/target_q          | -4.393706684421168    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.28
Training epoch 15
Time for epoch 15: 374.05. Rollout time: 193.94, Training time: 180.08
Evaluating epoch 15
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1376988.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -9.513571415707476    |
| test_1/avg_q              | -4.785097213955667    |
| test_1/n_subgoals         | 685.0                 |
| test_1/subgoal_succ_rate  | 0.29927007299270075   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.36                  |
| train_0/avg_q             | -21.026129978611145   |
| train_0/current_q         | -9.313064120182588    |
| train_0/fw_bonus          | -0.9930693581700325   |
| train_0/fw_loss           | 0.030844022613018753  |
| train_0/mu_grads          | -0.0601853447034955   |
| train_0/mu_grads_std      | 0.4655206650495529    |
| train_0/mu_loss           | 9.06842764040029      |
| train_0/next_q            | -8.973039193035962    |
| train_0/q_grads           | 0.0013249478448415174 |
| train_0/q_grads_std       | 0.23551741875708104   |
| train_0/q_loss            | 1.1832307395430095    |
| train_0/reward            | -0.8435195436548384   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0006103515625       |
| train_0/target_q          | -9.391766454326568    |
| train_1/avg_q             | -10.242440067708806   |
| train_1/current_q         | -4.2603542787200865   |
| train_1/fw_bonus          | -0.9469719037413598   |
| train_1/fw_loss           | 0.24004372134804725   |
| train_1/mu_grads          | -0.04341331133618951  |
| train_1/mu_grads_std      | 0.2684099331498146    |
| train_1/mu_loss           | 2.780950356388197     |
| train_1/n_subgoals        | 2396.0                |
| train_1/next_q            | -2.7428748975434316   |
| train_1/q_grads           | -0.08262875434011221  |
| train_1/q_grads_std       | 0.36422637924551965   |
| train_1/q_loss            | 1.3420156129510705    |
| train_1/reward            | -1.9982051868777488   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1131051752921536    |
| train_1/target_q          | -4.255388041578885    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.31000000000000005
Training epoch 16
Time for epoch 16: 358.84. Rollout time: 184.22, Training time: 174.59
Evaluating epoch 16
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 16                      |
| policy/steps              | 1448820.0               |
| test/episodes             | 425.0                   |
| test/success_rate         | 0.24                    |
| test_0/avg_q              | -11.19869040068187      |
| test_1/avg_q              | -2.7471580770487307     |
| test_1/n_subgoals         | 1208.0                  |
| test_1/subgoal_succ_rate  | 0.5860927152317881      |
| train/episodes            | 1700.0                  |
| train/success_rate        | 0.43                    |
| train_0/avg_q             | -20.59383192975136      |
| train_0/current_q         | -9.266831644901226      |
| train_0/fw_bonus          | -0.9926268339157105     |
| train_0/fw_loss           | 0.03278885665349662     |
| train_0/mu_grads          | -0.060553945787251      |
| train_0/mu_grads_std      | 0.47567516192793846     |
| train_0/mu_loss           | 9.022483375425901       |
| train_0/next_q            | -8.925622327713139      |
| train_0/q_grads           | -0.00024969757978396954 |
| train_0/q_grads_std       | 0.242570224404335       |
| train_0/q_loss            | 1.150509016907648       |
| train_0/reward            | -0.8450072640393046     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0003173828125         |
| train_0/target_q          | -9.346041766199278      |
| train_1/avg_q             | -9.804954758519164      |
| train_1/current_q         | -4.230308339106388      |
| train_1/fw_bonus          | -0.9453803643584251     |
| train_1/fw_loss           | 0.24702106453478337     |
| train_1/mu_grads          | -0.04533146498724818    |
| train_1/mu_grads_std      | 0.27528067752718927     |
| train_1/mu_loss           | 2.7492442335756744      |
| train_1/n_subgoals        | 2271.0                  |
| train_1/next_q            | -2.698638539089212      |
| train_1/q_grads           | -0.08760343790054322    |
| train_1/q_grads_std       | 0.38014047518372535     |
| train_1/q_loss            | 1.6081743297067064      |
| train_1/reward            | -2.0032321779741324     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.1210920299427565      |
| train_1/target_q          | -4.223381661068634      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.32
Training epoch 17
Time for epoch 17: 355.37. Rollout time: 178.99, Training time: 176.35
Evaluating epoch 17
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1514959.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.64                   |
| test_0/avg_q              | -14.184135633032993    |
| test_1/avg_q              | -4.3253185621509695    |
| test_1/n_subgoals         | 432.0                  |
| test_1/subgoal_succ_rate  | 0.18287037037037038    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -20.117620798783044    |
| train_0/current_q         | -9.464740159000767     |
| train_0/fw_bonus          | -0.9923719391226768    |
| train_0/fw_loss           | 0.03390908492729068    |
| train_0/mu_grads          | -0.06210304014384747   |
| train_0/mu_grads_std      | 0.4850745819509029     |
| train_0/mu_loss           | 9.242035905167466      |
| train_0/next_q            | -9.121711552616565     |
| train_0/q_grads           | -0.0016306520585203544 |
| train_0/q_grads_std       | 0.2491945017129183     |
| train_0/q_loss            | 1.2472261478927882     |
| train_0/reward            | -0.8497382138033572    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0005859375           |
| train_0/target_q          | -9.53066554314682      |
| train_1/avg_q             | -9.5404144739967       |
| train_1/current_q         | -4.102581097022885     |
| train_1/fw_bonus          | -0.944768163561821     |
| train_1/fw_loss           | 0.2497049681842327     |
| train_1/mu_grads          | -0.04753587078303099   |
| train_1/mu_grads_std      | 0.28214816749095917    |
| train_1/mu_loss           | 2.6111526431641776     |
| train_1/n_subgoals        | 2213.0                 |
| train_1/next_q            | -2.5566903535014047    |
| train_1/q_grads           | -0.0937898013740778    |
| train_1/q_grads_std       | 0.3946056418120861     |
| train_1/q_loss            | 1.7543436225671762     |
| train_1/reward            | -1.9918420965979748    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12697695436059647    |
| train_1/target_q          | -4.1014184656516495    |
------------------------------------------------------
New best value for test/success_rate: 0.64. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 18
Time for epoch 18: 345.88. Rollout time: 173.70, Training time: 172.16
Evaluating epoch 18
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1579143.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.52                   |
| test_0/avg_q              | -11.868300190500056    |
| test_1/avg_q              | -1.7745227038938582    |
| test_1/n_subgoals         | 1567.0                 |
| test_1/subgoal_succ_rate  | 0.788130185067007      |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -20.66945671961754     |
| train_0/current_q         | -9.383288439839443     |
| train_0/fw_bonus          | -0.9922177508473397    |
| train_0/fw_loss           | 0.03458666685037315    |
| train_0/mu_grads          | -0.06316488087177277   |
| train_0/mu_grads_std      | 0.49377828612923624    |
| train_0/mu_loss           | 9.15084868884538       |
| train_0/next_q            | -9.032898113284217     |
| train_0/q_grads           | -0.0027798826224170623 |
| train_0/q_grads_std       | 0.2547566920518875     |
| train_0/q_loss            | 1.160388449678212      |
| train_0/reward            | -0.8523100510094082    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000341796875         |
| train_0/target_q          | -9.459844392426362     |
| train_1/avg_q             | -9.477382010295969     |
| train_1/current_q         | -4.026880355691824     |
| train_1/fw_bonus          | -0.9442117005586624    |
| train_1/fw_loss           | 0.25214458666741846    |
| train_1/mu_grads          | -0.05005107382312417   |
| train_1/mu_grads_std      | 0.28826354518532754    |
| train_1/mu_loss           | 2.5565486688899153     |
| train_1/n_subgoals        | 2131.0                 |
| train_1/next_q            | -2.520004447161516     |
| train_1/q_grads           | -0.09878593292087316   |
| train_1/q_grads_std       | 0.40792726203799246    |
| train_1/q_loss            | 1.7464409087182589     |
| train_1/reward            | -1.9317982342596225    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12810886907555138    |
| train_1/target_q          | -4.03126470361792      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.43000000000000005
Training epoch 19
Time for epoch 19: 350.83. Rollout time: 175.38, Training time: 175.41
Evaluating epoch 19
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1642381.0             |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -12.981004123553877   |
| test_1/avg_q              | -3.395665468928121    |
| test_1/n_subgoals         | 388.0                 |
| test_1/subgoal_succ_rate  | 0.20876288659793815   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.52                  |
| train_0/avg_q             | -20.537008607719258   |
| train_0/current_q         | -9.339813256293926    |
| train_0/fw_bonus          | -0.9919481605291367   |
| train_0/fw_loss           | 0.035771471355110405  |
| train_0/mu_grads          | -0.06333037056028842  |
| train_0/mu_grads_std      | 0.5017591819167138    |
| train_0/mu_loss           | 9.109262572562168     |
| train_0/next_q            | -8.983696539443098    |
| train_0/q_grads           | -0.004599361075088381 |
| train_0/q_grads_std       | 0.25975102186203003   |
| train_0/q_loss            | 1.1328103394101365    |
| train_0/reward            | -0.8564355094655184   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000390625           |
| train_0/target_q          | -9.408284165990967    |
| train_1/avg_q             | -9.55432928831475     |
| train_1/current_q         | -3.8964596424290745   |
| train_1/fw_bonus          | -0.9418674215674401   |
| train_1/fw_loss           | 0.2624220550060272    |
| train_1/mu_grads          | -0.052589208167046306 |
| train_1/mu_grads_std      | 0.29407191202044486   |
| train_1/mu_loss           | 2.437585602027295     |
| train_1/n_subgoals        | 2144.0                |
| train_1/next_q            | -2.383710807635208    |
| train_1/q_grads           | -0.10250700134783983  |
| train_1/q_grads_std       | 0.42001268118619917   |
| train_1/q_loss            | 1.8401596067964938    |
| train_1/reward            | -1.887022579285258    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12779850746268656   |
| train_1/target_q          | -3.8848468963462297   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 20
Time for epoch 20: 349.96. Rollout time: 173.77, Training time: 176.17
Evaluating epoch 20
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1709421.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.28                  |
| test_0/avg_q              | -15.19187611377507    |
| test_1/avg_q              | -4.013997408080065    |
| test_1/n_subgoals         | 555.0                 |
| test_1/subgoal_succ_rate  | 0.06846846846846846   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.47                  |
| train_0/avg_q             | -21.02486584184603    |
| train_0/current_q         | -9.46985453922537     |
| train_0/fw_bonus          | -0.9916899114847183   |
| train_0/fw_loss           | 0.03690644130110741   |
| train_0/mu_grads          | -0.06403711251914501  |
| train_0/mu_grads_std      | 0.5085710689425469    |
| train_0/mu_loss           | 9.244241727281088     |
| train_0/next_q            | -9.114646873544018    |
| train_0/q_grads           | -0.005962348054163158 |
| train_0/q_grads_std       | 0.26554538309574127   |
| train_0/q_loss            | 1.1713162011934533    |
| train_0/reward            | -0.8565749384761148   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00029296875         |
| train_0/target_q          | -9.543486921117593    |
| train_1/avg_q             | -9.388267344801257    |
| train_1/current_q         | -3.8887054450109018   |
| train_1/fw_bonus          | -0.9421707913279533   |
| train_1/fw_loss           | 0.26109210811555383   |
| train_1/mu_grads          | -0.05455204779282212  |
| train_1/mu_grads_std      | 0.29929308593273163   |
| train_1/mu_loss           | 2.3938986777730156    |
| train_1/n_subgoals        | 2103.0                |
| train_1/next_q            | -2.3376892163768126   |
| train_1/q_grads           | -0.10551007315516472  |
| train_1/q_grads_std       | 0.4309384822845459    |
| train_1/q_loss            | 1.9100824869829864    |
| train_1/reward            | -1.9444862707416177   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1312410841654779    |
| train_1/target_q          | -3.882871158983627    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 21
Time for epoch 21: 342.24. Rollout time: 166.87, Training time: 175.34
Evaluating epoch 21
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 1769617.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.64                  |
| test_0/avg_q              | -11.631902903157423   |
| test_1/avg_q              | -1.4209727915612511   |
| test_1/n_subgoals         | 1065.0                |
| test_1/subgoal_succ_rate  | 0.7605633802816901    |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.51                  |
| train_0/avg_q             | -20.218170356701524   |
| train_0/current_q         | -9.52907114190079     |
| train_0/fw_bonus          | -0.9917006865143776   |
| train_0/fw_loss           | 0.0368591639213264    |
| train_0/mu_grads          | -0.06599924452602864  |
| train_0/mu_grads_std      | 0.514955087006092     |
| train_0/mu_loss           | 9.296902511730668     |
| train_0/next_q            | -9.15517997587052     |
| train_0/q_grads           | -0.006840681447647512 |
| train_0/q_grads_std       | 0.27115782126784327   |
| train_0/q_loss            | 1.1307338758352112    |
| train_0/reward            | -0.8623542427892972   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00048828125         |
| train_0/target_q          | -9.601899068248354    |
| train_1/avg_q             | -9.046318511172958    |
| train_1/current_q         | -3.8658311178822276   |
| train_1/fw_bonus          | -0.9409210413694382   |
| train_1/fw_loss           | 0.2665710777044296    |
| train_1/mu_grads          | -0.05585470600053668  |
| train_1/mu_grads_std      | 0.3040642574429512    |
| train_1/mu_loss           | 2.4011292940894835    |
| train_1/n_subgoals        | 2083.0                |
| train_1/next_q            | -2.3534435937774605   |
| train_1/q_grads           | -0.10920513607561588  |
| train_1/q_grads_std       | 0.44043674021959306   |
| train_1/q_loss            | 1.9589071579020245    |
| train_1/reward            | -1.9155532904966095   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13970235237638023   |
| train_1/target_q          | -3.8680044201462813   |
-----------------------------------------------------
New best value for test/success_rate: 0.64. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 22
Time for epoch 22: 337.36. Rollout time: 168.98, Training time: 168.36
Evaluating epoch 22
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 1832647.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -10.817999148302327   |
| test_1/avg_q              | -1.8222385928696851   |
| test_1/n_subgoals         | 1028.0                |
| test_1/subgoal_succ_rate  | 0.7071984435797666    |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -20.766860594642328   |
| train_0/current_q         | -9.405692961807755    |
| train_0/fw_bonus          | -0.9918612226843834   |
| train_0/fw_loss           | 0.03615357847884297   |
| train_0/mu_grads          | -0.06719671208411455  |
| train_0/mu_grads_std      | 0.5215127274394036    |
| train_0/mu_loss           | 9.180671292163174     |
| train_0/next_q            | -9.050069212446695    |
| train_0/q_grads           | -0.007879872457124293 |
| train_0/q_grads_std       | 0.27602552622556686   |
| train_0/q_loss            | 1.0474503452351944    |
| train_0/reward            | -0.8597001423077018   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0004150390625       |
| train_0/target_q          | -9.489637877137       |
| train_1/avg_q             | -9.39732966987271     |
| train_1/current_q         | -3.8217260005039746   |
| train_1/fw_bonus          | -0.9411892771720887   |
| train_1/fw_loss           | 0.2653950970619917    |
| train_1/mu_grads          | -0.058171296305954454 |
| train_1/mu_grads_std      | 0.30968757569789884   |
| train_1/mu_loss           | 2.363626251341679     |
| train_1/n_subgoals        | 2118.0                |
| train_1/next_q            | -2.3203130875726927   |
| train_1/q_grads           | -0.11325613372027873  |
| train_1/q_grads_std       | 0.4504946701228619    |
| train_1/q_loss            | 1.965732262424919     |
| train_1/reward            | -1.8987806740078668   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11898016997167139   |
| train_1/target_q          | -3.822918821942708    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.52
Training epoch 23
Time for epoch 23: 337.01. Rollout time: 166.82, Training time: 170.17
Evaluating epoch 23
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 23                   |
| policy/steps              | 1894733.0            |
| test/episodes             | 600.0                |
| test/success_rate         | 0.48                 |
| test_0/avg_q              | -13.26119887299133   |
| test_1/avg_q              | -1.5891953252585282  |
| test_1/n_subgoals         | 1634.0               |
| test_1/subgoal_succ_rate  | 0.8011015911872705   |
| train/episodes            | 2400.0               |
| train/success_rate        | 0.52                 |
| train_0/avg_q             | -20.637625144099292  |
| train_0/current_q         | -9.602869339291251   |
| train_0/fw_bonus          | -0.9918208301067353  |
| train_0/fw_loss           | 0.036331129167228936 |
| train_0/mu_grads          | -0.06835352461785078 |
| train_0/mu_grads_std      | 0.5272270202636719   |
| train_0/mu_loss           | 9.370809877656107    |
| train_0/next_q            | -9.250744904518854   |
| train_0/q_grads           | -0.0085635642753914  |
| train_0/q_grads_std       | 0.280845707654953    |
| train_0/q_loss            | 1.2351891516125677   |
| train_0/reward            | -0.8594724231421423  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0005859375         |
| train_0/target_q          | -9.67488728220496    |
| train_1/avg_q             | -9.498868580475008   |
| train_1/current_q         | -3.8771573035457956  |
| train_1/fw_bonus          | -0.9409205555915833  |
| train_1/fw_loss           | 0.2665731780230999   |
| train_1/mu_grads          | -0.0596940778195858  |
| train_1/mu_grads_std      | 0.31534114107489586  |
| train_1/mu_loss           | 2.4110739410727797   |
| train_1/n_subgoals        | 2035.0               |
| train_1/next_q            | -2.3672777406263856  |
| train_1/q_grads           | -0.11690299771726131 |
| train_1/q_grads_std       | 0.4601603582501411   |
| train_1/q_loss            | 2.0872676059468547   |
| train_1/reward            | -1.916334303298936   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0                  |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.12088452088452088  |
| train_1/target_q          | -3.875478907293066   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.49
Training epoch 24
Time for epoch 24: 341.98. Rollout time: 174.09, Training time: 167.86
Evaluating epoch 24
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 1957817.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -11.102257612584813   |
| test_1/avg_q              | -1.1762071340665539   |
| test_1/n_subgoals         | 2108.0                |
| test_1/subgoal_succ_rate  | 0.8809297912713473    |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.52                  |
| train_0/avg_q             | -20.424850332275323   |
| train_0/current_q         | -9.662241694513309    |
| train_0/fw_bonus          | -0.9918437466025353   |
| train_0/fw_loss           | 0.036230366211384535  |
| train_0/mu_grads          | -0.07118812836706638  |
| train_0/mu_grads_std      | 0.5329117432236672    |
| train_0/mu_loss           | 9.443946514681684     |
| train_0/next_q            | -9.301238156399979    |
| train_0/q_grads           | -0.008845589566044509 |
| train_0/q_grads_std       | 0.28487303480505943   |
| train_0/q_loss            | 1.1016296114150155    |
| train_0/reward            | -0.8591909181675874   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -9.734808974210456    |
| train_1/avg_q             | -9.027346862177398    |
| train_1/current_q         | -3.8158259212018146   |
| train_1/fw_bonus          | -0.9402029827237129   |
| train_1/fw_loss           | 0.2697190947830677    |
| train_1/mu_grads          | -0.062335163820534945 |
| train_1/mu_grads_std      | 0.3218880519270897    |
| train_1/mu_loss           | 2.327006667234566     |
| train_1/n_subgoals        | 2158.0                |
| train_1/next_q            | -2.297188990505508    |
| train_1/q_grads           | -0.12033312171697616  |
| train_1/q_grads_std       | 0.47016367092728617   |
| train_1/q_loss            | 2.0464991125761736    |
| train_1/reward            | -1.9008998282122775   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13901760889712697   |
| train_1/target_q          | -3.8108415157697153   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 25
Time for epoch 25: 336.30. Rollout time: 163.19, Training time: 173.08
Evaluating epoch 25
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2017726.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -13.647482507072896   |
| test_1/avg_q              | -2.178329641574754    |
| test_1/n_subgoals         | 1063.0                |
| test_1/subgoal_succ_rate  | 0.6274694261523989    |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.6                   |
| train_0/avg_q             | -20.84699785578388    |
| train_0/current_q         | -9.456807481779318    |
| train_0/fw_bonus          | -0.9918000385165214   |
| train_0/fw_loss           | 0.03642243556678295   |
| train_0/mu_grads          | -0.07129512783139944  |
| train_0/mu_grads_std      | 0.5375817701220512    |
| train_0/mu_loss           | 9.230644467665693     |
| train_0/next_q            | -9.095767092514894    |
| train_0/q_grads           | -0.009879290801472962 |
| train_0/q_grads_std       | 0.2888510927557945    |
| train_0/q_loss            | 1.1381837831693336    |
| train_0/reward            | -0.8582047109019186   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0004150390625       |
| train_0/target_q          | -9.536028612497502    |
| train_1/avg_q             | -9.289599246202743    |
| train_1/current_q         | -3.811889531251873    |
| train_1/fw_bonus          | -0.9409583806991577   |
| train_1/fw_loss           | 0.2664073549211025    |
| train_1/mu_grads          | -0.06471931003034115  |
| train_1/mu_grads_std      | 0.32760089710354806   |
| train_1/mu_loss           | 2.3454303839788713    |
| train_1/n_subgoals        | 1922.0                |
| train_1/next_q            | -2.306009655280273    |
| train_1/q_grads           | -0.12550238966941835  |
| train_1/q_grads_std       | 0.4797822743654251    |
| train_1/q_loss            | 2.209249475965308     |
| train_1/reward            | -1.8961139569204533   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12695109261186263   |
| train_1/target_q          | -3.8095188117144887   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 26
Time for epoch 26: 331.19. Rollout time: 161.69, Training time: 169.47
Evaluating epoch 26
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2077239.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.52                  |
| test_0/avg_q              | -10.731404603727468   |
| test_1/avg_q              | -4.213975720768469    |
| test_1/n_subgoals         | 2383.0                |
| test_1/subgoal_succ_rate  | 0.8850188837599664    |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -20.87901572484095    |
| train_0/current_q         | -9.5751537964783      |
| train_0/fw_bonus          | -0.991849584877491    |
| train_0/fw_loss           | 0.03620476704090834   |
| train_0/mu_grads          | -0.07157919723540544  |
| train_0/mu_grads_std      | 0.5426764443516732    |
| train_0/mu_loss           | 9.342466434088811     |
| train_0/next_q            | -9.227338353941994    |
| train_0/q_grads           | -0.011149317538365722 |
| train_0/q_grads_std       | 0.2937560275197029    |
| train_0/q_loss            | 1.126183934210937     |
| train_0/reward            | -0.8533588694772334   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 9.765625e-05          |
| train_0/target_q          | -9.664042280751888    |
| train_1/avg_q             | -8.939573089780914    |
| train_1/current_q         | -3.776178167215362    |
| train_1/fw_bonus          | -0.940700787305832    |
| train_1/fw_loss           | 0.26753665059804915   |
| train_1/mu_grads          | -0.06559513173997403  |
| train_1/mu_grads_std      | 0.33254535049200057   |
| train_1/mu_loss           | 2.318396147470966     |
| train_1/n_subgoals        | 1964.0                |
| train_1/next_q            | -2.2845686598503065   |
| train_1/q_grads           | -0.12950857654213904  |
| train_1/q_grads_std       | 0.487879554182291     |
| train_1/q_loss            | 2.2050672898632455    |
| train_1/reward            | -1.8893689496086155   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13085539714867617   |
| train_1/target_q          | -3.7783377976239385   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 27
Time for epoch 27: 317.49. Rollout time: 156.14, Training time: 161.32
Evaluating epoch 27
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2132850.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.68                  |
| test_0/avg_q              | -14.72742844154441    |
| test_1/avg_q              | -1.7425092825047979   |
| test_1/n_subgoals         | 927.0                 |
| test_1/subgoal_succ_rate  | 0.7443365695792881    |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -20.406007596898096   |
| train_0/current_q         | -9.465417705044837    |
| train_0/fw_bonus          | -0.9917488873004914   |
| train_0/fw_loss           | 0.03664726624265313   |
| train_0/mu_grads          | -0.07236624322831631  |
| train_0/mu_grads_std      | 0.5466922953724861    |
| train_0/mu_loss           | 9.237085591179738     |
| train_0/next_q            | -9.110922756066914    |
| train_0/q_grads           | -0.011728064296767116 |
| train_0/q_grads_std       | 0.2972904406487942    |
| train_0/q_loss            | 1.1031521947374066    |
| train_0/reward            | -0.8516239562159171   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -9.544713241634387    |
| train_1/avg_q             | -9.047261592146537    |
| train_1/current_q         | -3.7452212848534545   |
| train_1/fw_bonus          | -0.94005067050457     |
| train_1/fw_loss           | 0.2703867837786674    |
| train_1/mu_grads          | -0.06649136003106833  |
| train_1/mu_grads_std      | 0.3372174896299839    |
| train_1/mu_loss           | 2.267904723788436     |
| train_1/n_subgoals        | 1929.0                |
| train_1/next_q            | -2.2461176769398348   |
| train_1/q_grads           | -0.13328789211809636  |
| train_1/q_grads_std       | 0.4957284018397331    |
| train_1/q_loss            | 2.160275597020811     |
| train_1/reward            | -1.8847714330957388   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13478486262312078   |
| train_1/target_q          | -3.7436465302883257   |
-----------------------------------------------------
New best value for test/success_rate: 0.68. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.55
Training epoch 28
Time for epoch 28: 300.72. Rollout time: 140.62, Training time: 160.08
Evaluating epoch 28
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2184054.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -14.020141992113498   |
| test_1/avg_q              | -1.4537595852881693   |
| test_1/n_subgoals         | 1580.0                |
| test_1/subgoal_succ_rate  | 0.8449367088607594    |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -20.44769103379338    |
| train_0/current_q         | -9.3720810320058      |
| train_0/fw_bonus          | -0.9919831424951553   |
| train_0/fw_loss           | 0.035617747250944375  |
| train_0/mu_grads          | -0.07332404721528292  |
| train_0/mu_grads_std      | 0.5517682731151581    |
| train_0/mu_loss           | 9.15791221920647      |
| train_0/next_q            | -9.017013072397955    |
| train_0/q_grads           | -0.012809752579778432 |
| train_0/q_grads_std       | 0.3014343462884426    |
| train_0/q_loss            | 0.9879149756492882    |
| train_0/reward            | -0.851191768222634    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00029296875         |
| train_0/target_q          | -9.452470833140058    |
| train_1/avg_q             | -8.89716404193609     |
| train_1/current_q         | -3.695881478844494    |
| train_1/fw_bonus          | -0.940702348947525    |
| train_1/fw_loss           | 0.2675298422574997    |
| train_1/mu_grads          | -0.06807981394231319  |
| train_1/mu_grads_std      | 0.34193659722805025   |
| train_1/mu_loss           | 2.238731982142223     |
| train_1/n_subgoals        | 1718.0                |
| train_1/next_q            | -2.206052873632644    |
| train_1/q_grads           | -0.13837189115583898  |
| train_1/q_grads_std       | 0.5040156245231628    |
| train_1/q_loss            | 2.3340252054387904    |
| train_1/reward            | -1.9071065426302085   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14318975552968569   |
| train_1/target_q          | -3.7099945611568557   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 29
Time for epoch 29: 319.28. Rollout time: 155.54, Training time: 163.70
Evaluating epoch 29
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2241259.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -8.358257074735716    |
| test_1/avg_q              | -1.9326801522115058   |
| test_1/n_subgoals         | 1247.0                |
| test_1/subgoal_succ_rate  | 0.7129109863672815    |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.61                  |
| train_0/avg_q             | -20.822922692394524   |
| train_0/current_q         | -9.092873629647062    |
| train_0/fw_bonus          | -0.9919446364045144   |
| train_0/fw_loss           | 0.03578698905184865   |
| train_0/mu_grads          | -0.07508878670632839  |
| train_0/mu_grads_std      | 0.5566843539476395    |
| train_0/mu_loss           | 8.880360912501093     |
| train_0/next_q            | -8.735436926298764    |
| train_0/q_grads           | -0.013711007731035351 |
| train_0/q_grads_std       | 0.3054558105766773    |
| train_0/q_loss            | 1.2548789606384572    |
| train_0/reward            | -0.8503546423642547   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000390625           |
| train_0/target_q          | -9.192638114478374    |
| train_1/avg_q             | -9.09069784117775     |
| train_1/current_q         | -3.7301472005810665   |
| train_1/fw_bonus          | -0.9396867334842682   |
| train_1/fw_loss           | 0.27198235020041467   |
| train_1/mu_grads          | -0.0694099696353078   |
| train_1/mu_grads_std      | 0.34761355593800547   |
| train_1/mu_loss           | 2.275383904664838     |
| train_1/n_subgoals        | 1846.0                |
| train_1/next_q            | -2.2335964081147175   |
| train_1/q_grads           | -0.1427344985306263   |
| train_1/q_grads_std       | 0.5130179271101951    |
| train_1/q_loss            | 2.2794615925231705    |
| train_1/reward            | -1.8895455135629162   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12838569880823403   |
| train_1/target_q          | -3.7259664234529652   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5700000000000001
Training epoch 30
Time for epoch 30: 312.22. Rollout time: 146.70, Training time: 165.49
Evaluating epoch 30
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 30                    |
| policy/steps              | 2292420.0             |
| test/episodes             | 775.0                 |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -12.31985842530215    |
| test_1/avg_q              | -5.823225242318394    |
| test_1/n_subgoals         | 844.0                 |
| test_1/subgoal_succ_rate  | 0.7962085308056872    |
| train/episodes            | 3100.0                |
| train/success_rate        | 0.66                  |
| train_0/avg_q             | -19.730672056595047   |
| train_0/current_q         | -9.584294518300808    |
| train_0/fw_bonus          | -0.991884671151638    |
| train_0/fw_loss           | 0.036050516087561844  |
| train_0/mu_grads          | -0.0766680296510458   |
| train_0/mu_grads_std      | 0.5606066524982453    |
| train_0/mu_loss           | 9.350047203027298     |
| train_0/next_q            | -9.227276800073266    |
| train_0/q_grads           | -0.012670126650482416 |
| train_0/q_grads_std       | 0.3091157615184784    |
| train_0/q_loss            | 1.0424851269195254    |
| train_0/reward            | -0.8537548367276031   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000390625           |
| train_0/target_q          | -9.667452512429039    |
| train_1/avg_q             | -8.799779050030303    |
| train_1/current_q         | -3.5200990966475607   |
| train_1/fw_bonus          | -0.9380331873893738   |
| train_1/fw_loss           | 0.2792315810918808    |
| train_1/mu_grads          | -0.07125859223306179  |
| train_1/mu_grads_std      | 0.35285810977220533   |
| train_1/mu_loss           | 2.0735085541737925    |
| train_1/n_subgoals        | 1821.0                |
| train_1/next_q            | -2.0415286249126696   |
| train_1/q_grads           | -0.14697716310620307  |
| train_1/q_grads_std       | 0.5240636005997658    |
| train_1/q_loss            | 2.0587005460831262    |
| train_1/reward            | -1.827366204133432    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13948380010982978   |
| train_1/target_q          | -3.518580912473722    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_30.pkl ...
New best value for test/success_rate: 0.8. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.64
Training epoch 31
Time for epoch 31: 322.25. Rollout time: 162.20, Training time: 160.03
Evaluating epoch 31
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2350377.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -14.032828863258677   |
| test_1/avg_q              | -5.577527056458872    |
| test_1/n_subgoals         | 513.0                 |
| test_1/subgoal_succ_rate  | 0.43664717348927873   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -20.660992016345556   |
| train_0/current_q         | -9.474292054207636    |
| train_0/fw_bonus          | -0.9919489428400994   |
| train_0/fw_loss           | 0.03576807323843241   |
| train_0/mu_grads          | -0.0766513416543603   |
| train_0/mu_grads_std      | 0.5650603875517846    |
| train_0/mu_loss           | 9.254534438832405     |
| train_0/next_q            | -9.130648410107282    |
| train_0/q_grads           | -0.012611443898640573 |
| train_0/q_grads_std       | 0.3127184592187405    |
| train_0/q_loss            | 1.0054643543606965    |
| train_0/reward            | -0.8522488842863822   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0005126953125       |
| train_0/target_q          | -9.577471840140758    |
| train_1/avg_q             | -8.894196573892895    |
| train_1/current_q         | -3.5112278529715093   |
| train_1/fw_bonus          | -0.9380563959479332   |
| train_1/fw_loss           | 0.2791298784315586    |
| train_1/mu_grads          | -0.07260990533977747  |
| train_1/mu_grads_std      | 0.35783216208219526   |
| train_1/mu_loss           | 2.0590228154108123    |
| train_1/n_subgoals        | 1967.0                |
| train_1/next_q            | -2.043593912941592    |
| train_1/q_grads           | -0.15157357156276702  |
| train_1/q_grads_std       | 0.5354943245649337    |
| train_1/q_loss            | 2.0326411875192028    |
| train_1/reward            | -1.8342015343463571   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1392984239959329    |
| train_1/target_q          | -3.517443368326714    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.62
Training epoch 32
Time for epoch 32: 308.37. Rollout time: 146.00, Training time: 162.34
Evaluating epoch 32
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 2401873.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -10.516843292540416   |
| test_1/avg_q              | -3.811893026039786    |
| test_1/n_subgoals         | 276.0                 |
| test_1/subgoal_succ_rate  | 0.20652173913043478   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.64                  |
| train_0/avg_q             | -20.586119809848135   |
| train_0/current_q         | -9.418652522909651    |
| train_0/fw_bonus          | -0.9920805811882019   |
| train_0/fw_loss           | 0.035189542546868326  |
| train_0/mu_grads          | -0.07871615458279849  |
| train_0/mu_grads_std      | 0.5696493729948997    |
| train_0/mu_loss           | 9.20445357568         |
| train_0/next_q            | -9.061025907169098    |
| train_0/q_grads           | -0.012001038459129632 |
| train_0/q_grads_std       | 0.317491065710783     |
| train_0/q_loss            | 0.9381923529926155    |
| train_0/reward            | -0.851972906949959    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0006103515625       |
| train_0/target_q          | -9.521531035159768    |
| train_1/avg_q             | -8.92724674397906     |
| train_1/current_q         | -3.50230915746029     |
| train_1/fw_bonus          | -0.9385159581899643   |
| train_1/fw_loss           | 0.27711508572101595   |
| train_1/mu_grads          | -0.07433172259479762  |
| train_1/mu_grads_std      | 0.361584597080946     |
| train_1/mu_loss           | 2.0661587129720944    |
| train_1/n_subgoals        | 1804.0                |
| train_1/next_q            | -2.034310814577117    |
| train_1/q_grads           | -0.15574151054024696  |
| train_1/q_grads_std       | 0.5445959165692329    |
| train_1/q_loss            | 1.9641254643268682    |
| train_1/reward            | -1.8215773153613555   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12583148558758314   |
| train_1/target_q          | -3.5033789651632974   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6599999999999999
Training epoch 33
Time for epoch 33: 318.32. Rollout time: 150.60, Training time: 167.69
Evaluating epoch 33
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 2455607.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.64                  |
| test_0/avg_q              | -17.334976191710382   |
| test_1/avg_q              | -2.121404108262975    |
| test_1/n_subgoals         | 805.0                 |
| test_1/subgoal_succ_rate  | 0.6857142857142857    |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.62                  |
| train_0/avg_q             | -20.555284438229403   |
| train_0/current_q         | -9.749441472066255    |
| train_0/fw_bonus          | -0.9922379717230797   |
| train_0/fw_loss           | 0.03449785839766264   |
| train_0/mu_grads          | -0.07870714608579873  |
| train_0/mu_grads_std      | 0.5743817374110222    |
| train_0/mu_loss           | 9.529920280088007     |
| train_0/next_q            | -9.404141053703537    |
| train_0/q_grads           | -0.012000333331525326 |
| train_0/q_grads_std       | 0.3223076552152634    |
| train_0/q_loss            | 1.0075053128585576    |
| train_0/reward            | -0.8534920297817734   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0006591796875       |
| train_0/target_q          | -9.847308759097965    |
| train_1/avg_q             | -8.966229942359522    |
| train_1/current_q         | -3.518923832277809    |
| train_1/fw_bonus          | -0.9377507090568542   |
| train_1/fw_loss           | 0.28047002404928206   |
| train_1/mu_grads          | -0.07603230252861977  |
| train_1/mu_grads_std      | 0.3660547524690628    |
| train_1/mu_loss           | 2.052897140782315     |
| train_1/n_subgoals        | 1837.0                |
| train_1/next_q            | -2.0096806694111984   |
| train_1/q_grads           | -0.1605364117771387   |
| train_1/q_grads_std       | 0.5532168433070183    |
| train_1/q_loss            | 1.879694365875277     |
| train_1/reward            | -1.8489534750566237   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12738160043549265   |
| train_1/target_q          | -3.5180723857265632   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7000000000000001
Training epoch 34
Time for epoch 34: 306.34. Rollout time: 138.33, Training time: 167.98
Evaluating epoch 34
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 34                   |
| policy/steps              | 2504686.0            |
| test/episodes             | 875.0                |
| test/success_rate         | 0.76                 |
| test_0/avg_q              | -14.415640342415829  |
| test_1/avg_q              | -2.813202431801637   |
| test_1/n_subgoals         | 258.0                |
| test_1/subgoal_succ_rate  | 0.2054263565891473   |
| train/episodes            | 3500.0               |
| train/success_rate        | 0.72                 |
| train_0/avg_q             | -20.60084419341931   |
| train_0/current_q         | -9.666916921481356   |
| train_0/fw_bonus          | -0.9921345293521882  |
| train_0/fw_loss           | 0.034952464140951635 |
| train_0/mu_grads          | -0.07998424377292394 |
| train_0/mu_grads_std      | 0.5793239891529083   |
| train_0/mu_loss           | 9.450997308007828    |
| train_0/next_q            | -9.313126229504643   |
| train_0/q_grads           | -0.01288367824163288 |
| train_0/q_grads_std       | 0.3271579585969448   |
| train_0/q_loss            | 1.013465870131808    |
| train_0/reward            | -0.8578226332800114  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0010009765625      |
| train_0/target_q          | -9.75820539544494    |
| train_1/avg_q             | -8.635561476129586   |
| train_1/current_q         | -3.5637401270093902  |
| train_1/fw_bonus          | -0.9384251922369004  |
| train_1/fw_loss           | 0.2775130167603493   |
| train_1/mu_grads          | -0.07724170405417681 |
| train_1/mu_grads_std      | 0.36998080313205717  |
| train_1/mu_loss           | 2.086953932147926    |
| train_1/n_subgoals        | 1738.0               |
| train_1/next_q            | -2.0458648818621423  |
| train_1/q_grads           | -0.16458001174032688 |
| train_1/q_grads_std       | 0.5628323927521706   |
| train_1/q_loss            | 1.911064592844566    |
| train_1/reward            | -1.8702746087292326  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0                  |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.14672036823935558  |
| train_1/target_q          | -3.5667892021115564  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.69
Training epoch 35
Time for epoch 35: 317.54. Rollout time: 152.63, Training time: 164.88
Evaluating epoch 35
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 2558039.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -16.434779703949076   |
| test_1/avg_q              | -1.940329444046871    |
| test_1/n_subgoals         | 855.0                 |
| test_1/subgoal_succ_rate  | 0.7976608187134503    |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -21.807518302850085   |
| train_0/current_q         | -9.740081792820357    |
| train_0/fw_bonus          | -0.9921734616160393   |
| train_0/fw_loss           | 0.03478134740144014   |
| train_0/mu_grads          | -0.0800903221592307   |
| train_0/mu_grads_std      | 0.584034013748169     |
| train_0/mu_loss           | 9.535466731055255     |
| train_0/next_q            | -9.386028779217629    |
| train_0/q_grads           | -0.012532086833380163 |
| train_0/q_grads_std       | 0.33147330954670906   |
| train_0/q_loss            | 0.9969955780203257    |
| train_0/reward            | -0.8558767691960384   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000537109375        |
| train_0/target_q          | -9.822643850069188    |
| train_1/avg_q             | -9.151601251231382    |
| train_1/current_q         | -3.5406670259209627   |
| train_1/fw_bonus          | -0.9366953492164611   |
| train_1/fw_loss           | 0.2850967556238174    |
| train_1/mu_grads          | -0.08006608989089728  |
| train_1/mu_grads_std      | 0.3740195848047733    |
| train_1/mu_loss           | 2.069488861434883     |
| train_1/n_subgoals        | 1876.0                |
| train_1/next_q            | -2.0442837866090544   |
| train_1/q_grads           | -0.16830392107367514  |
| train_1/q_grads_std       | 0.5710112288594246    |
| train_1/q_loss            | 2.182102568438171     |
| train_1/reward            | -1.8436894707992906   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11353944562899787   |
| train_1/target_q          | -3.5457086990746047   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.73
Training epoch 36
Time for epoch 36: 312.99. Rollout time: 146.54, Training time: 166.42
Evaluating epoch 36
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 2606725.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -14.533415859636785   |
| test_1/avg_q              | -4.487548639109659    |
| test_1/n_subgoals         | 238.0                 |
| test_1/subgoal_succ_rate  | 0.24369747899159663   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.64                  |
| train_0/avg_q             | -21.52266259181636    |
| train_0/current_q         | -9.744029339222447    |
| train_0/fw_bonus          | -0.9922633364796638   |
| train_0/fw_loss           | 0.03438633284531534   |
| train_0/mu_grads          | -0.08184043057262898  |
| train_0/mu_grads_std      | 0.5884898602962494    |
| train_0/mu_loss           | 9.539348579845603     |
| train_0/next_q            | -9.40013948884231     |
| train_0/q_grads           | -0.012119080312550068 |
| train_0/q_grads_std       | 0.3354917883872986    |
| train_0/q_loss            | 0.935790605826627     |
| train_0/reward            | -0.8572034485172481   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000634765625        |
| train_0/target_q          | -9.858864062122489    |
| train_1/avg_q             | -9.073893455895343    |
| train_1/current_q         | -3.534941573055731    |
| train_1/fw_bonus          | -0.9350620463490487   |
| train_1/fw_loss           | 0.292257259786129     |
| train_1/mu_grads          | -0.08223597183823586  |
| train_1/mu_grads_std      | 0.379376233369112     |
| train_1/mu_loss           | 2.0389850778527516    |
| train_1/n_subgoals        | 1729.0                |
| train_1/next_q            | -2.02276456546634     |
| train_1/q_grads           | -0.17181951440870763  |
| train_1/q_grads_std       | 0.5783481106162072    |
| train_1/q_loss            | 2.212590892929883     |
| train_1/reward            | -1.8702776050398824   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1307113938692886    |
| train_1/target_q          | -3.5395847667886984   |
-----------------------------------------------------
New best value for test/success_rate: 0.8. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.74
Training epoch 37
Time for epoch 37: 316.85. Rollout time: 150.43, Training time: 166.39
Evaluating epoch 37
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 2660671.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.72                  |
| test_0/avg_q              | -14.411051986931943   |
| test_1/avg_q              | -6.410163537592436    |
| test_1/n_subgoals         | 757.0                 |
| test_1/subgoal_succ_rate  | 0.726552179656539     |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.63                  |
| train_0/avg_q             | -21.519394380773463   |
| train_0/current_q         | -9.972664454192865    |
| train_0/fw_bonus          | -0.9922872200608254   |
| train_0/fw_loss           | 0.034281381778419016  |
| train_0/mu_grads          | -0.08213215786963701  |
| train_0/mu_grads_std      | 0.5924384012818337    |
| train_0/mu_loss           | 9.759940177684149     |
| train_0/next_q            | -9.62341993475954     |
| train_0/q_grads           | -0.011892167711630463 |
| train_0/q_grads_std       | 0.3391971543431282    |
| train_0/q_loss            | 0.9673709372972666    |
| train_0/reward            | -0.8569102128712984   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000439453125        |
| train_0/target_q          | -10.05768908504295    |
| train_1/avg_q             | -8.977503321613321    |
| train_1/current_q         | -3.5034314605833723   |
| train_1/fw_bonus          | -0.9338292375206947   |
| train_1/fw_loss           | 0.29766196087002755   |
| train_1/mu_grads          | -0.08354964647442102  |
| train_1/mu_grads_std      | 0.38376395106315614   |
| train_1/mu_loss           | 2.043086513200472     |
| train_1/n_subgoals        | 1882.0                |
| train_1/next_q            | -2.035053229746862    |
| train_1/q_grads           | -0.17545193433761597  |
| train_1/q_grads_std       | 0.5860448256134987    |
| train_1/q_loss            | 2.1441589395119776    |
| train_1/reward            | -1.822517646644701    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12699256110520724   |
| train_1/target_q          | -3.5105698836964443   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.76
Training epoch 38
Time for epoch 38: 292.80. Rollout time: 129.72, Training time: 163.05
Evaluating epoch 38
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 2707093.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -21.011417826420576   |
| test_1/avg_q              | -5.461494207436559    |
| test_1/n_subgoals         | 252.0                 |
| test_1/subgoal_succ_rate  | 0.23809523809523808   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.75                  |
| train_0/avg_q             | -20.872322049941598   |
| train_0/current_q         | -9.73235819225145     |
| train_0/fw_bonus          | -0.9923326849937439   |
| train_0/fw_loss           | 0.034081549383699894  |
| train_0/mu_grads          | -0.08385142497718334  |
| train_0/mu_grads_std      | 0.5963411137461663    |
| train_0/mu_loss           | 9.515519519462018     |
| train_0/next_q            | -9.38092943201498     |
| train_0/q_grads           | -0.012236049794591964 |
| train_0/q_grads_std       | 0.3428075842559338    |
| train_0/q_loss            | 0.884873677266911     |
| train_0/reward            | -0.8565423229323642   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00048828125         |
| train_0/target_q          | -9.821538641211575    |
| train_1/avg_q             | -8.589146795499115    |
| train_1/current_q         | -3.526039993305156    |
| train_1/fw_bonus          | -0.9336505576968193   |
| train_1/fw_loss           | 0.29844529256224633   |
| train_1/mu_grads          | -0.08521556090563535  |
| train_1/mu_grads_std      | 0.38871968984603883   |
| train_1/mu_loss           | 2.010586445075313     |
| train_1/n_subgoals        | 1645.0                |
| train_1/next_q            | -1.9968222034322047   |
| train_1/q_grads           | -0.17879093773663043  |
| train_1/q_grads_std       | 0.5946118026971817    |
| train_1/q_loss            | 2.1658330412357345    |
| train_1/reward            | -1.8892862193613837   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.15987841945288753   |
| train_1/target_q          | -3.5267967540812877   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.76
Training epoch 39
Time for epoch 39: 308.57. Rollout time: 142.60, Training time: 165.95
Evaluating epoch 39
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 2761167.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -13.787999294172678   |
| test_1/avg_q              | -1.302774589706728    |
| test_1/n_subgoals         | 2244.0                |
| test_1/subgoal_succ_rate  | 0.8587344028520499    |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.66                  |
| train_0/avg_q             | -21.30691503157131    |
| train_0/current_q         | -9.795745357040289    |
| train_0/fw_bonus          | -0.9924111545085907   |
| train_0/fw_loss           | 0.03373668389394879   |
| train_0/mu_grads          | -0.08488583192229271  |
| train_0/mu_grads_std      | 0.6001032084226608    |
| train_0/mu_loss           | 9.557077035074965     |
| train_0/next_q            | -9.438825913880105    |
| train_0/q_grads           | -0.012825947301462293 |
| train_0/q_grads_std       | 0.34644853621721267   |
| train_0/q_loss            | 0.9327025925147161    |
| train_0/reward            | -0.8550434724478692   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000439453125        |
| train_0/target_q          | -9.877645391003004    |
| train_1/avg_q             | -8.858022924941997    |
| train_1/current_q         | -3.449443367683931    |
| train_1/fw_bonus          | -0.9328991025686264   |
| train_1/fw_loss           | 0.3017397277057171    |
| train_1/mu_grads          | -0.08578432966023683  |
| train_1/mu_grads_std      | 0.3927945241332054    |
| train_1/mu_loss           | 1.9394792925364492    |
| train_1/n_subgoals        | 1730.0                |
| train_1/next_q            | -1.927210441716695    |
| train_1/q_grads           | -0.1814285062253475   |
| train_1/q_grads_std       | 0.6015336260199546    |
| train_1/q_loss            | 1.9220839602494215    |
| train_1/reward            | -1.8664739662570355   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1393063583815029    |
| train_1/target_q          | -3.455106270326259    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.68
Training epoch 40
Time for epoch 40: 295.97. Rollout time: 125.54, Training time: 170.40
Evaluating epoch 40
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 40                   |
| policy/steps              | 2808044.0            |
| test/episodes             | 1025.0               |
| test/success_rate         | 0.6                  |
| test_0/avg_q              | -12.339385936741389  |
| test_1/avg_q              | -0.9792974999823466  |
| test_1/n_subgoals         | 1614.0               |
| test_1/subgoal_succ_rate  | 0.8413878562577447   |
| train/episodes            | 4100.0               |
| train/success_rate        | 0.74                 |
| train_0/avg_q             | -21.036637217802305  |
| train_0/current_q         | -9.884624652832198   |
| train_0/fw_bonus          | -0.992439828813076   |
| train_0/fw_loss           | 0.033610724424943325 |
| train_0/mu_grads          | -0.08621509429067373 |
| train_0/mu_grads_std      | 0.6046634837985039   |
| train_0/mu_loss           | 9.668282898184309    |
| train_0/next_q            | -9.540095652791313   |
| train_0/q_grads           | -0.01201802035793662 |
| train_0/q_grads_std       | 0.3508478827774525   |
| train_0/q_loss            | 0.9585022640504152   |
| train_0/reward            | -0.8557291895645903  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0007080078125      |
| train_0/target_q          | -9.990141224597046   |
| train_1/avg_q             | -8.578050387964652   |
| train_1/current_q         | -3.4673805943345366  |
| train_1/fw_bonus          | -0.9338917702436447  |
| train_1/fw_loss           | 0.2973878152668476   |
| train_1/mu_grads          | -0.08656897768378258 |
| train_1/mu_grads_std      | 0.39636135548353196  |
| train_1/mu_loss           | 1.9649548324718011   |
| train_1/n_subgoals        | 1533.0               |
| train_1/next_q            | -1.9530547842226038  |
| train_1/q_grads           | -0.18447360433638096 |
| train_1/q_grads_std       | 0.6089710012078285   |
| train_1/q_loss            | 2.039355461388618    |
| train_1/reward            | -1.8625757676716603  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0                  |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.14285714285714285  |
| train_1/target_q          | -3.4680910760515724  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.63
Training epoch 41
Time for epoch 41: 306.98. Rollout time: 139.95, Training time: 167.01
Evaluating epoch 41
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 41                   |
| policy/steps              | 2862092.0            |
| test/episodes             | 1050.0               |
| test/success_rate         | 0.44                 |
| test_0/avg_q              | -10.189123433886754  |
| test_1/avg_q              | -1.2513204884473415  |
| test_1/n_subgoals         | 1124.0               |
| test_1/subgoal_succ_rate  | 0.6832740213523132   |
| train/episodes            | 4200.0               |
| train/success_rate        | 0.62                 |
| train_0/avg_q             | -21.54384391525184   |
| train_0/current_q         | -9.825302351704305   |
| train_0/fw_bonus          | -0.9923633232712745  |
| train_0/fw_loss           | 0.03394694989547133  |
| train_0/mu_grads          | -0.08827633913606406 |
| train_0/mu_grads_std      | 0.6087670981884002   |
| train_0/mu_loss           | 9.609689758577016    |
| train_0/next_q            | -9.471963275215568   |
| train_0/q_grads           | -0.01230353037826717 |
| train_0/q_grads_std       | 0.35472418591380117  |
| train_0/q_loss            | 0.9324432512859872   |
| train_0/reward            | -0.8524194528166845  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00068359375        |
| train_0/target_q          | -9.92358062689525    |
| train_1/avg_q             | -8.981617367266434   |
| train_1/current_q         | -3.4537094190806754  |
| train_1/fw_bonus          | -0.9307700753211975  |
| train_1/fw_loss           | 0.31107352748513223  |
| train_1/mu_grads          | -0.08790322467684746 |
| train_1/mu_grads_std      | 0.3994784288108349   |
| train_1/mu_loss           | 1.9872403860994035   |
| train_1/n_subgoals        | 1701.0               |
| train_1/next_q            | -1.9713863225250563  |
| train_1/q_grads           | -0.18817532286047936 |
| train_1/q_grads_std       | 0.6163701757788658   |
| train_1/q_loss            | 2.1871535896870666   |
| train_1/reward            | -1.8561931427037053  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0                  |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.11992945326278659  |
| train_1/target_q          | -3.460726031013074   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5599999999999999
Training epoch 42
Time for epoch 42: 300.30. Rollout time: 135.47, Training time: 164.80
Evaluating epoch 42
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 42                    |
| policy/steps              | 2914140.0             |
| test/episodes             | 1075.0                |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -4.418088040666623    |
| test_1/avg_q              | -0.8050318944957989   |
| test_1/n_subgoals         | 1642.0                |
| test_1/subgoal_succ_rate  | 0.8057247259439708    |
| train/episodes            | 4300.0                |
| train/success_rate        | 0.66                  |
| train_0/avg_q             | -21.41739494796263    |
| train_0/current_q         | -9.870787046107296    |
| train_0/fw_bonus          | -0.992440614104271    |
| train_0/fw_loss           | 0.033607226656749846  |
| train_0/mu_grads          | -0.08833986204117536  |
| train_0/mu_grads_std      | 0.6132174670696259    |
| train_0/mu_loss           | 9.653539998145595     |
| train_0/next_q            | -9.530520993579438    |
| train_0/q_grads           | -0.012340449844487011 |
| train_0/q_grads_std       | 0.35926144048571584   |
| train_0/q_loss            | 0.9368384929317415    |
| train_0/reward            | -0.8470870091550751   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -9.97991866732924     |
| train_1/avg_q             | -8.705471823444189    |
| train_1/current_q         | -3.424387004473516    |
| train_1/fw_bonus          | -0.930009911954403    |
| train_1/fw_loss           | 0.3144061781466007    |
| train_1/mu_grads          | -0.08978409674018621  |
| train_1/mu_grads_std      | 0.4026071526110172    |
| train_1/mu_loss           | 1.973958638395524     |
| train_1/n_subgoals        | 1663.0                |
| train_1/next_q            | -1.96160660840613     |
| train_1/q_grads           | -0.19054401405155658  |
| train_1/q_grads_std       | 0.622095274925232     |
| train_1/q_loss            | 2.119632428747805     |
| train_1/reward            | -1.8435816104029072   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1238725195429946    |
| train_1/target_q          | -3.4327839310660755   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.49
Training epoch 43
Time for epoch 43: 313.10. Rollout time: 142.87, Training time: 170.20
Evaluating epoch 43
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 43                    |
| policy/steps              | 2963772.0             |
| test/episodes             | 1100.0                |
| test/success_rate         | 0.72                  |
| test_0/avg_q              | -15.346182160556422   |
| test_1/avg_q              | -0.9967186960896487   |
| test_1/n_subgoals         | 1537.0                |
| test_1/subgoal_succ_rate  | 0.8809368900455433    |
| train/episodes            | 4400.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -21.003597318958565   |
| train_0/current_q         | -9.890364842388198    |
| train_0/fw_bonus          | -0.9925607204437256   |
| train_0/fw_loss           | 0.03307942403480411   |
| train_0/mu_grads          | -0.0898177322000265   |
| train_0/mu_grads_std      | 0.6174228593707085    |
| train_0/mu_loss           | 9.696558332909799     |
| train_0/next_q            | -9.552445190674609    |
| train_0/q_grads           | -0.012283695279620588 |
| train_0/q_grads_std       | 0.3635044775903225    |
| train_0/q_loss            | 0.9122722187393105    |
| train_0/reward            | -0.85093123747356     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00048828125         |
| train_0/target_q          | -9.999764803133884    |
| train_1/avg_q             | -8.517180368662329    |
| train_1/current_q         | -3.5480591282374876   |
| train_1/fw_bonus          | -0.9296115040779114   |
| train_1/fw_loss           | 0.3161527387797832    |
| train_1/mu_grads          | -0.09113895315676927  |
| train_1/mu_grads_std      | 0.40650550052523615   |
| train_1/mu_loss           | 2.0993202954504873    |
| train_1/n_subgoals        | 1705.0                |
| train_1/next_q            | -2.0898758191992335   |
| train_1/q_grads           | -0.19316178634762765  |
| train_1/q_grads_std       | 0.6282453566789628    |
| train_1/q_loss            | 2.412790367301872     |
| train_1/reward            | -1.8573350531376491   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12551319648093842   |
| train_1/target_q          | -3.547138836848982    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 44
Time for epoch 44: 316.14. Rollout time: 145.47, Training time: 170.64
Evaluating epoch 44
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 3016089.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.68                  |
| test_0/avg_q              | -9.57782235141588     |
| test_1/avg_q              | -2.527184927263617    |
| test_1/n_subgoals         | 320.0                 |
| test_1/subgoal_succ_rate  | 0.20625               |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -21.45017683821649    |
| train_0/current_q         | -9.941270934637267    |
| train_0/fw_bonus          | -0.992534202337265    |
| train_0/fw_loss           | 0.03319593016058207   |
| train_0/mu_grads          | -0.09025168810039759  |
| train_0/mu_grads_std      | 0.6212891176342964    |
| train_0/mu_loss           | 9.723520054089303     |
| train_0/next_q            | -9.597283708602742    |
| train_0/q_grads           | -0.012239226535893977 |
| train_0/q_grads_std       | 0.36763536632061006   |
| train_0/q_loss            | 0.900677700419274     |
| train_0/reward            | -0.8483178846297961   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0003173828125       |
| train_0/target_q          | -10.043615843351485   |
| train_1/avg_q             | -8.828362356137632    |
| train_1/current_q         | -3.583784004845731    |
| train_1/fw_bonus          | -0.9273338556289673   |
| train_1/fw_loss           | 0.3261381134390831    |
| train_1/mu_grads          | -0.092747706733644    |
| train_1/mu_grads_std      | 0.41003101468086245   |
| train_1/mu_loss           | 2.1606703838537964    |
| train_1/n_subgoals        | 1782.0                |
| train_1/next_q            | -2.1562582341800445   |
| train_1/q_grads           | -0.19507818706333638  |
| train_1/q_grads_std       | 0.6343410819768905    |
| train_1/q_loss            | 2.5307386830644156    |
| train_1/reward            | -1.8464306032175954   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12794612794612795   |
| train_1/target_q          | -3.5940790116755266   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.58
Training epoch 45
Time for epoch 45: 304.47. Rollout time: 138.39, Training time: 166.05
Evaluating epoch 45
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 3064842.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -18.37226769024407    |
| test_1/avg_q              | -1.9132888291224819   |
| test_1/n_subgoals         | 860.0                 |
| test_1/subgoal_succ_rate  | 0.7848837209302325    |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.68                  |
| train_0/avg_q             | -21.532505343021338   |
| train_0/current_q         | -10.0633554264476     |
| train_0/fw_bonus          | -0.9923212200403213   |
| train_0/fw_loss           | 0.03413196504116058   |
| train_0/mu_grads          | -0.09101033098995685  |
| train_0/mu_grads_std      | 0.6244314521551132    |
| train_0/mu_loss           | 9.862647163327214     |
| train_0/next_q            | -9.72006371249172     |
| train_0/q_grads           | -0.012654576497152448 |
| train_0/q_grads_std       | 0.37102620005607606   |
| train_0/q_loss            | 0.9223250947952222    |
| train_0/reward            | -0.8503598292125389   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0001708984375       |
| train_0/target_q          | -10.150844083689478   |
| train_1/avg_q             | -8.804496766705244    |
| train_1/current_q         | -3.5644100962003122   |
| train_1/fw_bonus          | -0.9307542234659195   |
| train_1/fw_loss           | 0.3111430689692497    |
| train_1/mu_grads          | -0.09436602126806974  |
| train_1/mu_grads_std      | 0.41274585351347925   |
| train_1/mu_loss           | 2.1619412667590323    |
| train_1/n_subgoals        | 1707.0                |
| train_1/next_q            | -2.156707147856213    |
| train_1/q_grads           | -0.19794515818357467  |
| train_1/q_grads_std       | 0.6415358081459999    |
| train_1/q_loss            | 2.282745960220743     |
| train_1/reward            | -1.8172814033809117   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1347393087287639    |
| train_1/target_q          | -3.571893451952993    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6599999999999999
Training epoch 46
Time for epoch 46: 333.16. Rollout time: 170.25, Training time: 162.89
Evaluating epoch 46
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 3135693.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -23.12093210970528    |
| test_1/avg_q              | -4.276694612358735    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.48                  |
| train_0/avg_q             | -16.320997455379743   |
| train_0/current_q         | -10.211961598137346   |
| train_0/fw_bonus          | -0.992690908908844    |
| train_0/fw_loss           | 0.03250728687271476   |
| train_0/mu_grads          | -0.08926415834575892  |
| train_0/mu_grads_std      | 0.6276458874344826    |
| train_0/mu_loss           | 10.226179472047187    |
| train_0/next_q            | -10.054497848635165   |
| train_0/q_grads           | -0.015862116613425313 |
| train_0/q_grads_std       | 0.3711598999798298    |
| train_0/q_loss            | 1.980159941924769     |
| train_0/reward            | -0.84075463021436     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0026123046875       |
| train_0/target_q          | -10.233817734756675   |
| train_1/avg_q             | -8.584686920855543    |
| train_1/current_q         | -3.7740468810261816   |
| train_1/fw_bonus          | -0.9301539599895478   |
| train_1/fw_loss           | 0.3137746647000313    |
| train_1/mu_grads          | -0.09659929350018501  |
| train_1/mu_grads_std      | 0.41564160734415057   |
| train_1/mu_loss           | 2.4240168326880207    |
| train_1/n_subgoals        | 2049.0                |
| train_1/next_q            | -2.3741932209862093   |
| train_1/q_grads           | -0.20033196173608303  |
| train_1/q_grads_std       | 0.648251649737358     |
| train_1/q_loss            | 2.556966112330805     |
| train_1/reward            | -1.841517404517799    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.08394338701805759   |
| train_1/target_q          | -3.7744534484731718   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.54
Training epoch 47
Time for epoch 47: 353.64. Rollout time: 195.81, Training time: 157.80
Evaluating epoch 47
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
----------------------------------------------------
| epoch                     | 47                   |
| policy/steps              | 3211428.0            |
| test/episodes             | 1200.0               |
| test/success_rate         | 0.28                 |
| test_0/avg_q              | -17.42762994524883   |
| test_1/avg_q              | -2.2611070873064185  |
| test_1/n_subgoals         | 1183.0               |
| test_1/subgoal_succ_rate  | 0.5967878275570583   |
| train/episodes            | 4800.0               |
| train/success_rate        | 0.33                 |
| train_0/avg_q             | -21.78526203874461   |
| train_0/current_q         | -9.706330750709501   |
| train_0/fw_bonus          | -0.9931972533464432  |
| train_0/fw_loss           | 0.030281924409791827 |
| train_0/mu_grads          | -0.08430800661444664 |
| train_0/mu_grads_std      | 0.6338324278593064   |
| train_0/mu_loss           | 9.529000667664814    |
| train_0/next_q            | -9.406037363654324   |
| train_0/q_grads           | -0.01297033354640007 |
| train_0/q_grads_std       | 0.373335225880146    |
| train_0/q_loss            | 1.0150551489507587   |
| train_0/reward            | -0.8280317356242449  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0048095703125      |
| train_0/target_q          | -9.800247293067459   |
| train_1/avg_q             | -8.738428855343496   |
| train_1/current_q         | -3.8672742684025065  |
| train_1/fw_bonus          | -0.9334374278783798  |
| train_1/fw_loss           | 0.29937967881560323  |
| train_1/mu_grads          | -0.09894509371370078 |
| train_1/mu_grads_std      | 0.4178055807948112   |
| train_1/mu_loss           | 2.469461632357884    |
| train_1/n_subgoals        | 2361.0               |
| train_1/next_q            | -2.437416685443261   |
| train_1/q_grads           | -0.2027197763323784  |
| train_1/q_grads_std       | 0.6536441430449486   |
| train_1/q_loss            | 2.4217893193424667   |
| train_1/reward            | -1.8840526984793542  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0                  |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.04362558238034731  |
| train_1/target_q          | -3.8588385753295436  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.43
Training epoch 48
Time for epoch 48: 329.64. Rollout time: 168.15, Training time: 161.46
Evaluating epoch 48
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 3272279.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.52                  |
| test_0/avg_q              | -12.576556501770389   |
| test_1/avg_q              | -2.957094639238498    |
| test_1/n_subgoals         | 1112.0                |
| test_1/subgoal_succ_rate  | 0.7005395683453237    |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -21.26041532402348    |
| train_0/current_q         | -9.889908610023557    |
| train_0/fw_bonus          | -0.9932569265365601   |
| train_0/fw_loss           | 0.030019707791507245  |
| train_0/mu_grads          | -0.08504566214978695  |
| train_0/mu_grads_std      | 0.6376965567469597    |
| train_0/mu_loss           | 9.702105778913118     |
| train_0/next_q            | -9.590206594751503    |
| train_0/q_grads           | -0.010107161989435554 |
| train_0/q_grads_std       | 0.37741918340325353   |
| train_0/q_loss            | 0.9340340319129433    |
| train_0/reward            | -0.8305151815104181   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0051025390625       |
| train_0/target_q          | -9.988626919958188    |
| train_1/avg_q             | -9.088424131513952    |
| train_1/current_q         | -3.95937961555465     |
| train_1/fw_bonus          | -0.9331681117415428   |
| train_1/fw_loss           | 0.3005603514611721    |
| train_1/mu_grads          | -0.10065644569694995  |
| train_1/mu_grads_std      | 0.4204273037612438    |
| train_1/mu_loss           | 2.593415445766376     |
| train_1/n_subgoals        | 1977.0                |
| train_1/next_q            | -2.53603060701936     |
| train_1/q_grads           | -0.20494173914194108  |
| train_1/q_grads_std       | 0.6582589358091354    |
| train_1/q_loss            | 2.413463912238858     |
| train_1/reward            | -1.9029121849584043   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.07738998482549317   |
| train_1/target_q          | -3.9653481842711926   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.39
Training epoch 49
Time for epoch 49: 320.50. Rollout time: 157.73, Training time: 162.75
Evaluating epoch 49
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 3325271.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.84                  |
| test_0/avg_q              | -19.64045078626103    |
| test_1/avg_q              | -5.867363501094671    |
| test_1/n_subgoals         | 213.0                 |
| test_1/subgoal_succ_rate  | 0.2676056338028169    |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -22.461450670548395   |
| train_0/current_q         | -9.644346275244413    |
| train_0/fw_bonus          | -0.99342060983181     |
| train_0/fw_loss           | 0.029300337517634036  |
| train_0/mu_grads          | -0.08742487449198962  |
| train_0/mu_grads_std      | 0.6411685734987259    |
| train_0/mu_loss           | 9.46576757674173      |
| train_0/next_q            | -9.347690840443615    |
| train_0/q_grads           | -0.008965812087990344 |
| train_0/q_grads_std       | 0.3813158608973026    |
| train_0/q_loss            | 0.8462706301699587    |
| train_0/reward            | -0.825238137665292    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004833984375        |
| train_0/target_q          | -9.77070103170052     |
| train_1/avg_q             | -10.252688173155327   |
| train_1/current_q         | -3.9397909128720245   |
| train_1/fw_bonus          | -0.9319050714373589   |
| train_1/fw_loss           | 0.30609761998057367   |
| train_1/mu_grads          | -0.10204364638775587  |
| train_1/mu_grads_std      | 0.42275695204734803   |
| train_1/mu_loss           | 2.5352521581620713    |
| train_1/n_subgoals        | 1885.0                |
| train_1/next_q            | -2.4911740618564764   |
| train_1/q_grads           | -0.20824659280478955  |
| train_1/q_grads_std       | 0.6638123974204063    |
| train_1/q_loss            | 2.324869974177994     |
| train_1/reward            | -1.9073587880811829   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.09496021220159151   |
| train_1/target_q          | -3.9419138593443193   |
-----------------------------------------------------
New best value for test/success_rate: 0.84. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.41000000000000003
Training epoch 50
Time for epoch 50: 305.37. Rollout time: 144.60, Training time: 160.75
Evaluating epoch 50
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 3377351.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.72                  |
| test_0/avg_q              | -13.272500651558953   |
| test_1/avg_q              | -4.009651561713156    |
| test_1/n_subgoals         | 312.0                 |
| test_1/subgoal_succ_rate  | 0.2564102564102564    |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.64                  |
| train_0/avg_q             | -21.86038111234563    |
| train_0/current_q         | -9.615518341916683    |
| train_0/fw_bonus          | -0.9933646202087403   |
| train_0/fw_loss           | 0.02954644514247775   |
| train_0/mu_grads          | -0.08955885004252195  |
| train_0/mu_grads_std      | 0.644846896827221     |
| train_0/mu_loss           | 9.438683295374009     |
| train_0/next_q            | -9.312203651061106    |
| train_0/q_grads           | -0.007263864309061318 |
| train_0/q_grads_std       | 0.3840363726019859    |
| train_0/q_loss            | 0.8680343440164447    |
| train_0/reward            | -0.8269191223531379   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006396484375        |
| train_0/target_q          | -9.731054977489086    |
| train_1/avg_q             | -9.336931520658302    |
| train_1/current_q         | -4.002182799432608    |
| train_1/fw_bonus          | -0.9313677534461021   |
| train_1/fw_loss           | 0.30845321118831637   |
| train_1/mu_grads          | -0.10359529703855515  |
| train_1/mu_grads_std      | 0.4260880820453167    |
| train_1/mu_loss           | 2.6169054207805598    |
| train_1/n_subgoals        | 1797.0                |
| train_1/next_q            | -2.5602778799556356   |
| train_1/q_grads           | -0.21062738373875617  |
| train_1/q_grads_std       | 0.66776093095541      |
| train_1/q_loss            | 2.3998110565376054    |
| train_1/reward            | -1.9296975541386927   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11908736783528102   |
| train_1/target_q          | -4.002470836773414    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5900000000000001
Training epoch 51
Time for epoch 51: 326.96. Rollout time: 148.97, Training time: 177.96
Evaluating epoch 51
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 3430899.0              |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.6                    |
| test_0/avg_q              | -15.925317748402824    |
| test_1/avg_q              | -5.617018558728025     |
| test_1/n_subgoals         | 369.0                  |
| test_1/subgoal_succ_rate  | 0.13550135501355012    |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -22.377892262618353    |
| train_0/current_q         | -9.733854293456215     |
| train_0/fw_bonus          | -0.9932658538222313    |
| train_0/fw_loss           | 0.029980488261207937   |
| train_0/mu_grads          | -0.09052508939057588   |
| train_0/mu_grads_std      | 0.648033544421196      |
| train_0/mu_loss           | 9.557624490319723      |
| train_0/next_q            | -9.443440076739787     |
| train_0/q_grads           | -0.0059809392900206145 |
| train_0/q_grads_std       | 0.3879526123404503     |
| train_0/q_loss            | 0.8701189064746468     |
| train_0/reward            | -0.8248922021448379    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00693359375          |
| train_0/target_q          | -9.841706636317546     |
| train_1/avg_q             | -9.475492316233465     |
| train_1/current_q         | -3.9589475410325776    |
| train_1/fw_bonus          | -0.9301910012960434    |
| train_1/fw_loss           | 0.3136121861636639     |
| train_1/mu_grads          | -0.10557726509869099   |
| train_1/mu_grads_std      | 0.42933218404650686    |
| train_1/mu_loss           | 2.5314683218915994     |
| train_1/n_subgoals        | 1767.0                 |
| train_1/next_q            | -2.5023950517133557    |
| train_1/q_grads           | -0.2136243972927332    |
| train_1/q_grads_std       | 0.6718652307987213     |
| train_1/q_loss            | 2.3807910143362387     |
| train_1/reward            | -1.9409744107731968    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.10752688172043011    |
| train_1/target_q          | -3.9568663200098286    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.67
Training epoch 52
Time for epoch 52: 323.36. Rollout time: 148.92, Training time: 174.41
Evaluating epoch 52
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 3485636.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -18.006661098348413   |
| test_1/avg_q              | -8.9878257707175      |
| test_1/n_subgoals         | 384.0                 |
| test_1/subgoal_succ_rate  | 0.23697916666666666   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.58                  |
| train_0/avg_q             | -21.663819222991624   |
| train_0/current_q         | -9.750470944555193    |
| train_0/fw_bonus          | -0.9933162346482277   |
| train_0/fw_loss           | 0.02975909006781876   |
| train_0/mu_grads          | -0.09264314770698548  |
| train_0/mu_grads_std      | 0.6512317821383476    |
| train_0/mu_loss           | 9.551292193489749     |
| train_0/next_q            | -9.457277420152272    |
| train_0/q_grads           | -0.005741243588272482 |
| train_0/q_grads_std       | 0.39115693271160124   |
| train_0/q_loss            | 0.8724954112123562    |
| train_0/reward            | -0.8224515704489022   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0064697265625       |
| train_0/target_q          | -9.847333205311022    |
| train_1/avg_q             | -9.28761204817854     |
| train_1/current_q         | -4.009042394126405    |
| train_1/fw_bonus          | -0.9295323058962822   |
| train_1/fw_loss           | 0.31649999096989634   |
| train_1/mu_grads          | -0.10770105831325054  |
| train_1/mu_grads_std      | 0.43236714899539946   |
| train_1/mu_loss           | 2.5926484405373826    |
| train_1/n_subgoals        | 1824.0                |
| train_1/next_q            | -2.546618948421588    |
| train_1/q_grads           | -0.21741598844528198  |
| train_1/q_grads_std       | 0.6762197554111481    |
| train_1/q_loss            | 2.450789125134096     |
| train_1/reward            | -1.9667070707764651   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11896929824561403   |
| train_1/target_q          | -4.013470365194965    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 53
Time for epoch 53: 340.82. Rollout time: 168.32, Training time: 172.47
Evaluating epoch 53
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 53                    |
| policy/steps              | 3542556.0             |
| test/episodes             | 1350.0                |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -12.193488114597534   |
| test_1/avg_q              | -1.4887494753520327   |
| test_1/n_subgoals         | 747.0                 |
| test_1/subgoal_succ_rate  | 0.7831325301204819    |
| train/episodes            | 5400.0                |
| train/success_rate        | 0.52                  |
| train_0/avg_q             | -21.844178891953085   |
| train_0/current_q         | -9.686523836110656    |
| train_0/fw_bonus          | -0.9932389333844185   |
| train_0/fw_loss           | 0.030098763993009925  |
| train_0/mu_grads          | -0.0930912358686328   |
| train_0/mu_grads_std      | 0.6543101102113724    |
| train_0/mu_loss           | 9.50332151400236      |
| train_0/next_q            | -9.397625140527023    |
| train_0/q_grads           | -0.005388541228603572 |
| train_0/q_grads_std       | 0.39485731199383733   |
| train_0/q_loss            | 0.8054546845988677    |
| train_0/reward            | -0.8212410505839216   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0056396484375       |
| train_0/target_q          | -9.788074366150676    |
| train_1/avg_q             | -9.665528217377732    |
| train_1/current_q         | -4.062964117549933    |
| train_1/fw_bonus          | -0.9272254765033722   |
| train_1/fw_loss           | 0.3266132242977619    |
| train_1/mu_grads          | -0.10951707791537046  |
| train_1/mu_grads_std      | 0.4364451915025711    |
| train_1/mu_loss           | 2.6275543914675588    |
| train_1/n_subgoals        | 2053.0                |
| train_1/next_q            | -2.6260513099645975   |
| train_1/q_grads           | -0.2199548900127411   |
| train_1/q_grads_std       | 0.6810505583882331    |
| train_1/q_loss            | 2.5107803527230113    |
| train_1/reward            | -1.9500141110103868   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13151485630784218   |
| train_1/target_q          | -4.060384907329247    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6799999999999999
Training epoch 54
Time for epoch 54: 314.63. Rollout time: 139.43, Training time: 175.17
Evaluating epoch 54
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 3594274.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -5.909131977944109    |
| test_1/avg_q              | -2.7902360871686986   |
| test_1/n_subgoals         | 2660.0                |
| test_1/subgoal_succ_rate  | 0.9176691729323309    |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -21.545817376799675   |
| train_0/current_q         | -9.938145354546558    |
| train_0/fw_bonus          | -0.9926795586943626   |
| train_0/fw_loss           | 0.032557117938995364  |
| train_0/mu_grads          | -0.0945469994097948   |
| train_0/mu_grads_std      | 0.6581737071275711    |
| train_0/mu_loss           | 9.749046214495058     |
| train_0/next_q            | -9.629164533471496    |
| train_0/q_grads           | -0.004342924617230892 |
| train_0/q_grads_std       | 0.3988819994032383    |
| train_0/q_loss            | 0.9553038446370881    |
| train_0/reward            | -0.8373309919472376   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00078125            |
| train_0/target_q          | -10.031803131492762   |
| train_1/avg_q             | -9.12912424713316     |
| train_1/current_q         | -3.9501004719877586   |
| train_1/fw_bonus          | -0.9261537149548531   |
| train_1/fw_loss           | 0.3313119664788246    |
| train_1/mu_grads          | -0.11076179035007953  |
| train_1/mu_grads_std      | 0.4400970108807087    |
| train_1/mu_loss           | 2.546836370615375     |
| train_1/n_subgoals        | 1721.0                |
| train_1/next_q            | -2.512597648712192    |
| train_1/q_grads           | -0.22229757830500602  |
| train_1/q_grads_std       | 0.68634592294693      |
| train_1/q_loss            | 2.3981404686418553    |
| train_1/reward            | -1.9188141590675514   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1464264962231261    |
| train_1/target_q          | -3.952649356811983    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.64
Training epoch 55
Time for epoch 55: 300.03. Rollout time: 121.02, Training time: 178.98
Evaluating epoch 55
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 3640358.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -13.225958729579524   |
| test_1/avg_q              | -1.3442690409167588   |
| test_1/n_subgoals         | 1523.0                |
| test_1/subgoal_succ_rate  | 0.8443860801050558    |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -21.214875760141048   |
| train_0/current_q         | -9.916281787455816    |
| train_0/fw_bonus          | -0.9924540251493454   |
| train_0/fw_loss           | 0.03354827449657023   |
| train_0/mu_grads          | -0.09363235682249069  |
| train_0/mu_grads_std      | 0.6611636057496071    |
| train_0/mu_loss           | 9.727929691820437     |
| train_0/next_q            | -9.604493011078464    |
| train_0/q_grads           | -0.003198166360380128 |
| train_0/q_grads_std       | 0.4015954740345478    |
| train_0/q_loss            | 0.9332292754512947    |
| train_0/reward            | -0.8389882475479681   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0004150390625       |
| train_0/target_q          | -10.02542282329476    |
| train_1/avg_q             | -8.847923106291564    |
| train_1/current_q         | -3.803727783963777    |
| train_1/fw_bonus          | -0.9270261391997338   |
| train_1/fw_loss           | 0.3274872176349163    |
| train_1/mu_grads          | -0.11225616261363029  |
| train_1/mu_grads_std      | 0.44364172369241717   |
| train_1/mu_loss           | 2.4281148410399473    |
| train_1/n_subgoals        | 1521.0                |
| train_1/next_q            | -2.370144527602956    |
| train_1/q_grads           | -0.22459180280566216  |
| train_1/q_grads_std       | 0.6930234223604202    |
| train_1/q_loss            | 2.2759787419343924    |
| train_1/reward            | -1.8804564234589634   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13675213675213677   |
| train_1/target_q          | -3.8005736432370627   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.64
Training epoch 56
Time for epoch 56: 312.53. Rollout time: 138.25, Training time: 174.25
Evaluating epoch 56
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 3689610.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.72                   |
| test_0/avg_q              | -11.582329236281378    |
| test_1/avg_q              | -3.2028421860295366    |
| test_1/n_subgoals         | 282.0                  |
| test_1/subgoal_succ_rate  | 0.25886524822695034    |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -21.675197603194814    |
| train_0/current_q         | -9.907225605175851     |
| train_0/fw_bonus          | -0.9925292953848839    |
| train_0/fw_loss           | 0.03321751081384718    |
| train_0/mu_grads          | -0.0937694577500224    |
| train_0/mu_grads_std      | 0.6641957625746727     |
| train_0/mu_loss           | 9.731895211861026      |
| train_0/next_q            | -9.60224372098872      |
| train_0/q_grads           | -0.0026438756322022527 |
| train_0/q_grads_std       | 0.4059101305902004     |
| train_0/q_loss            | 0.8809234739497922     |
| train_0/reward            | -0.8386108396625787    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001220703125        |
| train_0/target_q          | -10.031316568090144    |
| train_1/avg_q             | -9.215241040878187     |
| train_1/current_q         | -3.7135129655726034    |
| train_1/fw_bonus          | -0.9252173662185669    |
| train_1/fw_loss           | 0.33541690856218337    |
| train_1/mu_grads          | -0.11424635201692582   |
| train_1/mu_grads_std      | 0.4476686105132103     |
| train_1/mu_loss           | 2.3439284161074108     |
| train_1/n_subgoals        | 1721.0                 |
| train_1/next_q            | -2.3054268730165903    |
| train_1/q_grads           | -0.22760050892829894   |
| train_1/q_grads_std       | 0.7006650894880295     |
| train_1/q_loss            | 2.195712700044047      |
| train_1/reward            | -1.8501697225765383    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.13654851830331202    |
| train_1/target_q          | -3.7160826016292803    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6699999999999999
Training epoch 57
Time for epoch 57: 315.61. Rollout time: 139.14, Training time: 176.44
Evaluating epoch 57
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 3741812.0              |
| test/episodes             | 1450.0                 |
| test/success_rate         | 0.6                    |
| test_0/avg_q              | -14.087428335232707    |
| test_1/avg_q              | -10.664813038321673    |
| test_1/n_subgoals         | 826.0                  |
| test_1/subgoal_succ_rate  | 0.6585956416464891     |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -21.59423065164426     |
| train_0/current_q         | -9.950570777788462     |
| train_0/fw_bonus          | -0.9926700532436371    |
| train_0/fw_loss           | 0.03259887113235891    |
| train_0/mu_grads          | -0.09397525619715452   |
| train_0/mu_grads_std      | 0.6673555806279182     |
| train_0/mu_loss           | 9.759969180763807      |
| train_0/next_q            | -9.643633470810013     |
| train_0/q_grads           | -0.0014649445482064038 |
| train_0/q_grads_std       | 0.4103603482246399     |
| train_0/q_loss            | 0.8824037180033333     |
| train_0/reward            | -0.8362642301151937    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00048828125          |
| train_0/target_q          | -10.055237563352765    |
| train_1/avg_q             | -9.003728140504299     |
| train_1/current_q         | -3.8220275952325844    |
| train_1/fw_bonus          | -0.9250169485807419    |
| train_1/fw_loss           | 0.33629558980464935    |
| train_1/mu_grads          | -0.11589134968817234   |
| train_1/mu_grads_std      | 0.45206706747412684    |
| train_1/mu_loss           | 2.428911540988916      |
| train_1/n_subgoals        | 1758.0                 |
| train_1/next_q            | -2.3851898485196337    |
| train_1/q_grads           | -0.2305917676538229    |
| train_1/q_grads_std       | 0.707384106516838      |
| train_1/q_loss            | 2.3446902659974134     |
| train_1/reward            | -1.8901818136888324    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.149032992036405      |
| train_1/target_q          | -3.8152693450969215    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.62
Training epoch 58
Time for epoch 58: 316.95. Rollout time: 136.98, Training time: 179.94
Evaluating epoch 58
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 3788626.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.8                    |
| test_0/avg_q              | -12.455080873654511    |
| test_1/avg_q              | -4.859212259046264     |
| test_1/n_subgoals         | 230.0                  |
| test_1/subgoal_succ_rate  | 0.24782608695652175    |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -21.57415659278401     |
| train_0/current_q         | -9.880093464186487     |
| train_0/fw_bonus          | -0.9927411705255509    |
| train_0/fw_loss           | 0.032286332361400126   |
| train_0/mu_grads          | -0.09659093767404556   |
| train_0/mu_grads_std      | 0.6702396109700203     |
| train_0/mu_loss           | 9.690065571295726      |
| train_0/next_q            | -9.56184450623471      |
| train_0/q_grads           | -0.0007585494007798843 |
| train_0/q_grads_std       | 0.41367768347263334    |
| train_0/q_loss            | 0.8752193827066609     |
| train_0/reward            | -0.8383749830318266    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -9.999775248284706     |
| train_1/avg_q             | -8.910516823843436     |
| train_1/current_q         | -3.646435415295329     |
| train_1/fw_bonus          | -0.9262304708361626    |
| train_1/fw_loss           | 0.3309754699468613     |
| train_1/mu_grads          | -0.1177935715764761    |
| train_1/mu_grads_std      | 0.456815155595541      |
| train_1/mu_loss           | 2.2717424979360508     |
| train_1/n_subgoals        | 1664.0                 |
| train_1/next_q            | -2.2117092374184226    |
| train_1/q_grads           | -0.23374028243124484   |
| train_1/q_grads_std       | 0.7131718695163727     |
| train_1/q_loss            | 2.256246491601558      |
| train_1/reward            | -1.8402758758558775    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12980769230769232    |
| train_1/target_q          | -3.6415416323181717    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6799999999999999
Training epoch 59
Time for epoch 59: 316.58. Rollout time: 146.20, Training time: 170.35
Evaluating epoch 59
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 3841518.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -15.54940020944136     |
| test_1/avg_q              | -1.5864441371831313    |
| test_1/n_subgoals         | 1415.0                 |
| test_1/subgoal_succ_rate  | 0.8459363957597174     |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.67                   |
| train_0/avg_q             | -21.744032993378227    |
| train_0/current_q         | -9.843613942370514     |
| train_0/fw_bonus          | -0.9929111555218697    |
| train_0/fw_loss           | 0.03153929486870766    |
| train_0/mu_grads          | -0.09581367820501327   |
| train_0/mu_grads_std      | 0.6736530587077141     |
| train_0/mu_loss           | 9.647774707992562      |
| train_0/next_q            | -9.51813016943888      |
| train_0/q_grads           | -0.0011021812722901813 |
| train_0/q_grads_std       | 0.4163507379591465     |
| train_0/q_loss            | 0.8466824795301845     |
| train_0/reward            | -0.8360307744529564    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0007080078125        |
| train_0/target_q          | -9.920667872181289     |
| train_1/avg_q             | -8.954665147520005     |
| train_1/current_q         | -3.712514632684429     |
| train_1/fw_bonus          | -0.9259059011936188    |
| train_1/fw_loss           | 0.3323983572423458     |
| train_1/mu_grads          | -0.11905173491686583   |
| train_1/mu_grads_std      | 0.46050046384334564    |
| train_1/mu_loss           | 2.3522034449604536     |
| train_1/n_subgoals        | 1807.0                 |
| train_1/next_q            | -2.3061326301770633    |
| train_1/q_grads           | -0.23678743951022624   |
| train_1/q_grads_std       | 0.7186275199055672     |
| train_1/q_loss            | 2.143746104222965      |
| train_1/reward            | -1.8250867424489114    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.13724405091311567    |
| train_1/target_q          | -3.7017471894228535    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7000000000000001
Training epoch 60
Time for epoch 60: 306.70. Rollout time: 137.01, Training time: 169.66
Evaluating epoch 60
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 60                      |
| policy/steps              | 3893062.0               |
| test/episodes             | 1525.0                  |
| test/success_rate         | 0.56                    |
| test_0/avg_q              | -11.43502812447647      |
| test_1/avg_q              | -1.869734298121167      |
| test_1/n_subgoals         | 1037.0                  |
| test_1/subgoal_succ_rate  | 0.71648987463838        |
| train/episodes            | 6100.0                  |
| train/success_rate        | 0.66                    |
| train_0/avg_q             | -21.215716206585416     |
| train_0/current_q         | -9.844644623793851      |
| train_0/fw_bonus          | -0.9929597407579422     |
| train_0/fw_loss           | 0.03132577715441585     |
| train_0/mu_grads          | -0.09738021790981292    |
| train_0/mu_grads_std      | 0.6762505441904068      |
| train_0/mu_loss           | 9.660073993597466       |
| train_0/next_q            | -9.524196040346434      |
| train_0/q_grads           | -0.00019527819641211862 |
| train_0/q_grads_std       | 0.4203920722007751      |
| train_0/q_loss            | 0.8301590763226596      |
| train_0/reward            | -0.8369950077307294     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00068359375           |
| train_0/target_q          | -9.957594367114321      |
| train_1/avg_q             | -8.831263529734722      |
| train_1/current_q         | -3.738925078316311      |
| train_1/fw_bonus          | -0.9274830937385559     |
| train_1/fw_loss           | 0.3254838600754738      |
| train_1/mu_grads          | -0.12022852189838887    |
| train_1/mu_grads_std      | 0.4647866152226925      |
| train_1/mu_loss           | 2.3949917022984155      |
| train_1/n_subgoals        | 1714.0                  |
| train_1/next_q            | -2.3475123493954313     |
| train_1/q_grads           | -0.23997930139303209    |
| train_1/q_grads_std       | 0.7241014584898948      |
| train_1/q_loss            | 2.1922011841100266      |
| train_1/reward            | -1.8286219178669854     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.15402567094515754     |
| train_1/target_q          | -3.7313833228133504     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.66
Training epoch 61
Time for epoch 61: 309.20. Rollout time: 140.20, Training time: 168.97
Evaluating epoch 61
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 3942717.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.68                  |
| test_0/avg_q              | -20.649800204155643   |
| test_1/avg_q              | -5.585030957344288    |
| test_1/n_subgoals         | 306.0                 |
| test_1/subgoal_succ_rate  | 0.1830065359477124    |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.63                  |
| train_0/avg_q             | -22.441586902051725   |
| train_0/current_q         | -9.746942410653263    |
| train_0/fw_bonus          | -0.9930679440498352   |
| train_0/fw_loss           | 0.030850233929231762  |
| train_0/mu_grads          | -0.09828692059963942  |
| train_0/mu_grads_std      | 0.6793927237391472    |
| train_0/mu_loss           | 9.571495695384305     |
| train_0/next_q            | -9.436781260805228    |
| train_0/q_grads           | 0.0004582167654007208 |
| train_0/q_grads_std       | 0.4234855815768242    |
| train_0/q_loss            | 0.8450384812247084    |
| train_0/reward            | -0.83380204014029     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000634765625        |
| train_0/target_q          | -9.853516497080648    |
| train_1/avg_q             | -9.51364500999105     |
| train_1/current_q         | -3.5856490319665797   |
| train_1/fw_bonus          | -0.9282133996486663   |
| train_1/fw_loss           | 0.32228210419416425   |
| train_1/mu_grads          | -0.12282844372093678  |
| train_1/mu_grads_std      | 0.4688150674104691    |
| train_1/mu_loss           | 2.255452669834132     |
| train_1/n_subgoals        | 1692.0                |
| train_1/next_q            | -2.2297521881731606   |
| train_1/q_grads           | -0.24288365803658962  |
| train_1/q_grads_std       | 0.7298135876655578    |
| train_1/q_loss            | 2.0009651372870194    |
| train_1/reward            | -1.7746535801357823   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.12706855791962174   |
| train_1/target_q          | -3.5900990687043945   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.68
Training epoch 62
Time for epoch 62: 302.54. Rollout time: 132.58, Training time: 169.93
Evaluating epoch 62
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 62                     |
| policy/steps              | 3987441.0              |
| test/episodes             | 1575.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -14.653851215587364    |
| test_1/avg_q              | -9.35099140517248      |
| test_1/n_subgoals         | 540.0                  |
| test_1/subgoal_succ_rate  | 0.8203703703703704     |
| train/episodes            | 6300.0                 |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -21.927503244503708    |
| train_0/current_q         | -9.839356326859669     |
| train_0/fw_bonus          | -0.99311183989048      |
| train_0/fw_loss           | 0.030657331040129066   |
| train_0/mu_grads          | -0.09743943624198437   |
| train_0/mu_grads_std      | 0.6830422088503838     |
| train_0/mu_loss           | 9.649555718340661      |
| train_0/next_q            | -9.520392930788242     |
| train_0/q_grads           | 0.00020046052104589763 |
| train_0/q_grads_std       | 0.426837133616209      |
| train_0/q_loss            | 0.8308274695795145     |
| train_0/reward            | -0.8344099243549863    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0007568359375        |
| train_0/target_q          | -9.931074639172516     |
| train_1/avg_q             | -9.266877656391403     |
| train_1/current_q         | -3.593738020030126     |
| train_1/fw_bonus          | -0.9259333357214927    |
| train_1/fw_loss           | 0.33227812573313714    |
| train_1/mu_grads          | -0.1258631583303213    |
| train_1/mu_grads_std      | 0.4726862445473671     |
| train_1/mu_loss           | 2.2551010451827063     |
| train_1/n_subgoals        | 1660.0                 |
| train_1/next_q            | -2.2318885163802045    |
| train_1/q_grads           | -0.2465576369315386    |
| train_1/q_grads_std       | 0.7352424025535583     |
| train_1/q_loss            | 1.9914830774205363     |
| train_1/reward            | -1.7951566052230192    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14156626506024098    |
| train_1/target_q          | -3.59436847638442      |
------------------------------------------------------
New best value for test/success_rate: 0.88. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.7000000000000001
Training epoch 63
Time for epoch 63: 306.31. Rollout time: 139.09, Training time: 167.20
Evaluating epoch 63
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 63                      |
| policy/steps              | 4038604.0               |
| test/episodes             | 1600.0                  |
| test/success_rate         | 0.64                    |
| test_0/avg_q              | -17.878239993212524     |
| test_1/avg_q              | -8.782067838293356      |
| test_1/n_subgoals         | 318.0                   |
| test_1/subgoal_succ_rate  | 0.16981132075471697     |
| train/episodes            | 6400.0                  |
| train/success_rate        | 0.64                    |
| train_0/avg_q             | -21.848788522820957     |
| train_0/current_q         | -9.97083421074343       |
| train_0/fw_bonus          | -0.9932695925235748     |
| train_0/fw_loss           | 0.02996405684389174     |
| train_0/mu_grads          | -0.09925266094505787    |
| train_0/mu_grads_std      | 0.6856766983866691      |
| train_0/mu_loss           | 9.779868515477409       |
| train_0/next_q            | -9.65288199511879       |
| train_0/q_grads           | -0.00013367667943384732 |
| train_0/q_grads_std       | 0.4297743678092957      |
| train_0/q_loss            | 0.8522594017972762      |
| train_0/reward            | -0.8341470011335332     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0006103515625         |
| train_0/target_q          | -10.105982224561131     |
| train_1/avg_q             | -8.969567100275414      |
| train_1/current_q         | -3.707268393935517      |
| train_1/fw_bonus          | -0.9236033201217652     |
| train_1/fw_loss           | 0.3424930237233639      |
| train_1/mu_grads          | -0.12791411206126213    |
| train_1/mu_grads_std      | 0.47633477076888087     |
| train_1/mu_loss           | 2.3729057849551927      |
| train_1/n_subgoals        | 1741.0                  |
| train_1/next_q            | -2.369281173413952      |
| train_1/q_grads           | -0.24938239082694053    |
| train_1/q_grads_std       | 0.7412536442279816      |
| train_1/q_loss            | 2.2273647687057396      |
| train_1/reward            | -1.8012914053884743     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.13555427914991383     |
| train_1/target_q          | -3.707207012177296      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 64
Time for epoch 64: 292.99. Rollout time: 123.92, Training time: 169.04
Evaluating epoch 64
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 4082044.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.72                   |
| test_0/avg_q              | -14.873421304285918    |
| test_1/avg_q              | -1.4478159399770016    |
| test_1/n_subgoals         | 1593.0                 |
| test_1/subgoal_succ_rate  | 0.8926553672316384     |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -20.869454136031464    |
| train_0/current_q         | -9.834426064562221     |
| train_0/fw_bonus          | -0.9931931287050247    |
| train_0/fw_loss           | 0.030300124501809477   |
| train_0/mu_grads          | -0.0985222265124321    |
| train_0/mu_grads_std      | 0.6883353844285012     |
| train_0/mu_loss           | 9.645787747110345      |
| train_0/next_q            | -9.51917479675814      |
| train_0/q_grads           | -0.0005751725642767269 |
| train_0/q_grads_std       | 0.4331329889595509     |
| train_0/q_loss            | 0.8507020586344245     |
| train_0/reward            | -0.8323875751928427    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0006103515625        |
| train_0/target_q          | -9.940006733618953     |
| train_1/avg_q             | -8.820947291441758     |
| train_1/current_q         | -3.61534744334118      |
| train_1/fw_bonus          | -0.9253790780901909    |
| train_1/fw_loss           | 0.3347079873085022     |
| train_1/mu_grads          | -0.12924617528915405   |
| train_1/mu_grads_std      | 0.4797633163630962     |
| train_1/mu_loss           | 2.2943251586658944     |
| train_1/n_subgoals        | 1499.0                 |
| train_1/next_q            | -2.2687966544562466    |
| train_1/q_grads           | -0.2523727394640446    |
| train_1/q_grads_std       | 0.7468591198325157     |
| train_1/q_loss            | 2.0646203603302036     |
| train_1/reward            | -1.7736758676132012    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1494329553035357     |
| train_1/target_q          | -3.6161640547349476    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.73
Training epoch 65
Time for epoch 65: 302.15. Rollout time: 128.62, Training time: 173.49
Evaluating epoch 65
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 65                      |
| policy/steps              | 4129443.0               |
| test/episodes             | 1650.0                  |
| test/success_rate         | 0.64                    |
| test_0/avg_q              | -17.437697153187226     |
| test_1/avg_q              | -2.357667561281269      |
| test_1/n_subgoals         | 949.0                   |
| test_1/subgoal_succ_rate  | 0.7323498419388831      |
| train/episodes            | 6600.0                  |
| train/success_rate        | 0.7                     |
| train_0/avg_q             | -21.567327641646546     |
| train_0/current_q         | -9.830464746108596      |
| train_0/fw_bonus          | -0.9929299414157867     |
| train_0/fw_loss           | 0.031456731958314776    |
| train_0/mu_grads          | -0.09955336395651102    |
| train_0/mu_grads_std      | 0.6915457233786583      |
| train_0/mu_loss           | 9.641495624271844       |
| train_0/next_q            | -9.518912273104585      |
| train_0/q_grads           | -0.00016572508648096118 |
| train_0/q_grads_std       | 0.436011965572834       |
| train_0/q_loss            | 0.8890794542605139      |
| train_0/reward            | -0.8346729802025947     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0005126953125         |
| train_0/target_q          | -9.92214366140191       |
| train_1/avg_q             | -9.394161261930972      |
| train_1/current_q         | -3.6846237267424238     |
| train_1/fw_bonus          | -0.9241856977343559     |
| train_1/fw_loss           | 0.3399398155510426      |
| train_1/mu_grads          | -0.13056462369859217    |
| train_1/mu_grads_std      | 0.4819521866738796      |
| train_1/mu_loss           | 2.3388109796337684      |
| train_1/n_subgoals        | 1569.0                  |
| train_1/next_q            | -2.3381814145430404     |
| train_1/q_grads           | -0.25507236272096634    |
| train_1/q_grads_std       | 0.7522484987974167      |
| train_1/q_loss            | 2.1315070813834134      |
| train_1/reward            | -1.7899615047914268     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.12555768005098789     |
| train_1/target_q          | -3.6823547852963285     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7200000000000001
Training epoch 66
Time for epoch 66: 312.28. Rollout time: 141.73, Training time: 170.51
Evaluating epoch 66
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 4179156.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -15.107612395498787   |
| test_1/avg_q              | -2.5178740349568485   |
| test_1/n_subgoals         | 872.0                 |
| test_1/subgoal_succ_rate  | 0.8084862385321101    |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.63                  |
| train_0/avg_q             | -21.809299072616614   |
| train_0/current_q         | -9.994921205513142    |
| train_0/fw_bonus          | -0.9929267972707748   |
| train_0/fw_loss           | 0.031470569083467126  |
| train_0/mu_grads          | -0.10074882265180349  |
| train_0/mu_grads_std      | 0.6943713128566742    |
| train_0/mu_loss           | 9.809336476180174     |
| train_0/next_q            | -9.681807360357201    |
| train_0/q_grads           | 0.0005225855275057256 |
| train_0/q_grads_std       | 0.4395540677011013    |
| train_0/q_loss            | 0.8980356909881564    |
| train_0/reward            | -0.8349155462579801   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000634765625        |
| train_0/target_q          | -10.08363763014302    |
| train_1/avg_q             | -9.301745293845862    |
| train_1/current_q         | -3.738273362997475    |
| train_1/fw_bonus          | -0.9226007506251335   |
| train_1/fw_loss           | 0.34688838571310043   |
| train_1/mu_grads          | -0.13214196749031543  |
| train_1/mu_grads_std      | 0.48553560972213744   |
| train_1/mu_loss           | 2.408331060792027     |
| train_1/n_subgoals        | 1760.0                |
| train_1/next_q            | -2.3959860310968972   |
| train_1/q_grads           | -0.2572054825723171   |
| train_1/q_grads_std       | 0.7557733550667762    |
| train_1/q_loss            | 1.957063520878501     |
| train_1/reward            | -1.819564533153607    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.13693181818181818   |
| train_1/target_q          | -3.741615344303136    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.69
Training epoch 67
Time for epoch 67: 305.54. Rollout time: 136.32, Training time: 169.20
Evaluating epoch 67
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 4230732.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.56                   |
| test_0/avg_q              | -15.25583846842146     |
| test_1/avg_q              | -5.602774152201204     |
| test_1/n_subgoals         | 1556.0                 |
| test_1/subgoal_succ_rate  | 0.8245501285347043     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -21.730823470828636    |
| train_0/current_q         | -9.984097435821884     |
| train_0/fw_bonus          | -0.9929171577095985    |
| train_0/fw_loss           | 0.03151297075673938    |
| train_0/mu_grads          | -0.1001934776082635    |
| train_0/mu_grads_std      | 0.6972158178687096     |
| train_0/mu_loss           | 9.797597285365416      |
| train_0/next_q            | -9.67035047404072      |
| train_0/q_grads           | 0.00037228193032206035 |
| train_0/q_grads_std       | 0.44251665100455284    |
| train_0/q_loss            | 0.8346599104195483     |
| train_0/reward            | -0.8363633592249243    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -10.08959881468637     |
| train_1/avg_q             | -9.273569954567748     |
| train_1/current_q         | -3.7687641270880037    |
| train_1/fw_bonus          | -0.9212176665663719    |
| train_1/fw_loss           | 0.3529518932104111     |
| train_1/mu_grads          | -0.13415309451520444   |
| train_1/mu_grads_std      | 0.4894475370645523     |
| train_1/mu_loss           | 2.439446211329355      |
| train_1/n_subgoals        | 1696.0                 |
| train_1/next_q            | -2.4421831463195725    |
| train_1/q_grads           | -0.26005821377038957   |
| train_1/q_grads_std       | 0.7593659535050392     |
| train_1/q_loss            | 2.2500735051718896     |
| train_1/reward            | -1.8271005322800193    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12853773584905662    |
| train_1/target_q          | -3.7786580422766933    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.67
Training epoch 68
Time for epoch 68: 315.22. Rollout time: 146.77, Training time: 168.42
Evaluating epoch 68
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 4282107.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.72                   |
| test_0/avg_q              | -11.22550479358494     |
| test_1/avg_q              | -2.9494117903536927    |
| test_1/n_subgoals         | 2603.0                 |
| test_1/subgoal_succ_rate  | 0.9508259700345755     |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -22.067763245587408    |
| train_0/current_q         | -9.902354074992624     |
| train_0/fw_bonus          | -0.9928350776433945    |
| train_0/fw_loss           | 0.031873656809329985   |
| train_0/mu_grads          | -0.09994023647159338   |
| train_0/mu_grads_std      | 0.7002675086259842     |
| train_0/mu_loss           | 9.716359261946582      |
| train_0/next_q            | -9.591989053550517     |
| train_0/q_grads           | 2.5652027034084313e-05 |
| train_0/q_grads_std       | 0.4460259735584259     |
| train_0/q_loss            | 0.8859266553612075     |
| train_0/reward            | -0.836773983979947     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0004150390625        |
| train_0/target_q          | -10.021121234660349    |
| train_1/avg_q             | -9.252139953931115     |
| train_1/current_q         | -3.7338674651248622    |
| train_1/fw_bonus          | -0.919567409157753     |
| train_1/fw_loss           | 0.36018677726387976    |
| train_1/mu_grads          | -0.13587568663060665   |
| train_1/mu_grads_std      | 0.49411874637007713    |
| train_1/mu_loss           | 2.4112568890443127     |
| train_1/n_subgoals        | 1767.0                 |
| train_1/next_q            | -2.4075047084237458    |
| train_1/q_grads           | -0.2625291384756565    |
| train_1/q_grads_std       | 0.7639820069074631     |
| train_1/q_loss            | 2.06862038385725       |
| train_1/reward            | -1.8009702215917058    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11488398415393322    |
| train_1/target_q          | -3.7365252727369667    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6699999999999999
Training epoch 69
Time for epoch 69: 298.59. Rollout time: 131.10, Training time: 167.46
Evaluating epoch 69
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 4333953.0             |
| test/episodes             | 1750.0                |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -15.781522266755461   |
| test_1/avg_q              | -1.7814982673644462   |
| test_1/n_subgoals         | 1927.0                |
| test_1/subgoal_succ_rate  | 0.839647119875454     |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.71                  |
| train_0/avg_q             | -21.38149983721371    |
| train_0/current_q         | -9.939007430354632    |
| train_0/fw_bonus          | -0.9928765445947647   |
| train_0/fw_loss           | 0.0316914192866534    |
| train_0/mu_grads          | -0.10166096296161413  |
| train_0/mu_grads_std      | 0.7028632223606109    |
| train_0/mu_loss           | 9.754543369955092     |
| train_0/next_q            | -9.622000779366923    |
| train_0/q_grads           | 0.0006945311237359419 |
| train_0/q_grads_std       | 0.4498722903430462    |
| train_0/q_loss            | 0.9007654375743307    |
| train_0/reward            | -0.8389309477744973   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000390625           |
| train_0/target_q          | -10.046207239364705   |
| train_1/avg_q             | -8.931289776727684    |
| train_1/current_q         | -3.7610353062138264   |
| train_1/fw_bonus          | -0.919880947470665    |
| train_1/fw_loss           | 0.35881214365363123   |
| train_1/mu_grads          | -0.13773166872560977  |
| train_1/mu_grads_std      | 0.4980441741645336    |
| train_1/mu_loss           | 2.4157759211396854    |
| train_1/n_subgoals        | 1663.0                |
| train_1/next_q            | -2.393193523163174    |
| train_1/q_grads           | -0.2659295678138733   |
| train_1/q_grads_std       | 0.7698727861046791    |
| train_1/q_loss            | 2.1279428441119803    |
| train_1/reward            | -1.837894576727558    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1407095610342754    |
| train_1/target_q          | -3.76546937328756     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.63
Training epoch 70
Time for epoch 70: 293.81. Rollout time: 129.00, Training time: 164.78
Evaluating epoch 70
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 4383646.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.52                   |
| test_0/avg_q              | -14.1806374905524      |
| test_1/avg_q              | -5.525951187774485     |
| test_1/n_subgoals         | 400.0                  |
| test_1/subgoal_succ_rate  | 0.125                  |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -21.222982258657172    |
| train_0/current_q         | -10.082770724250903    |
| train_0/fw_bonus          | -0.9928008243441582    |
| train_0/fw_loss           | 0.03202423141337931    |
| train_0/mu_grads          | -0.10164869744330644   |
| train_0/mu_grads_std      | 0.7058849215507508     |
| train_0/mu_loss           | 9.889079462675207      |
| train_0/next_q            | -9.75588824061297      |
| train_0/q_grads           | 0.00029932963807368653 |
| train_0/q_grads_std       | 0.4529065445065498     |
| train_0/q_loss            | 0.869873078813075      |
| train_0/reward            | -0.8428969898195646    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0005126953125        |
| train_0/target_q          | -10.181579325641913    |
| train_1/avg_q             | -8.880423203732732     |
| train_1/current_q         | -3.7649712530266326    |
| train_1/fw_bonus          | -0.918490506708622     |
| train_1/fw_loss           | 0.36490794345736505    |
| train_1/mu_grads          | -0.13893865533173083   |
| train_1/mu_grads_std      | 0.5007207483053208     |
| train_1/mu_loss           | 2.3963637904222357     |
| train_1/n_subgoals        | 1592.0                 |
| train_1/next_q            | -2.3843056454768017    |
| train_1/q_grads           | -0.268923906236887     |
| train_1/q_grads_std       | 0.7747956708073616     |
| train_1/q_loss            | 2.19971142336766       |
| train_1/reward            | -1.8711959363565256    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1300251256281407     |
| train_1/target_q          | -3.7637410720070874    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5700000000000001
Training epoch 71
Time for epoch 71: 303.98. Rollout time: 138.20, Training time: 165.75
Evaluating epoch 71
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 4429353.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.84                   |
| test_0/avg_q              | -13.667918315108862    |
| test_1/avg_q              | -3.7828723120193124    |
| test_1/n_subgoals         | 1308.0                 |
| test_1/subgoal_succ_rate  | 0.9120795107033639     |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -22.359342024095067    |
| train_0/current_q         | -10.1837077271163      |
| train_0/fw_bonus          | -0.9927291259169578    |
| train_0/fw_loss           | 0.03233926179818809    |
| train_0/mu_grads          | -0.10075340364128352   |
| train_0/mu_grads_std      | 0.709290899336338      |
| train_0/mu_loss           | 9.978322723420208      |
| train_0/next_q            | -9.854110623913893     |
| train_0/q_grads           | -0.0004869253680226393 |
| train_0/q_grads_std       | 0.4560477390885353     |
| train_0/q_loss            | 0.9370170475221122     |
| train_0/reward            | -0.8452415199106327    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0005126953125        |
| train_0/target_q          | -10.267538773539458    |
| train_1/avg_q             | -9.474475733757815     |
| train_1/current_q         | -3.694040775259478     |
| train_1/fw_bonus          | -0.9191056907176971    |
| train_1/fw_loss           | 0.362210888415575      |
| train_1/mu_grads          | -0.1400784771889448    |
| train_1/mu_grads_std      | 0.50463947057724       |
| train_1/mu_loss           | 2.355841482642833      |
| train_1/n_subgoals        | 1635.0                 |
| train_1/next_q            | -2.3475589290163943    |
| train_1/q_grads           | -0.27182096168398856   |
| train_1/q_grads_std       | 0.7800367385149002     |
| train_1/q_loss            | 1.9450730672252867     |
| train_1/reward            | -1.816754996322561     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11131498470948012    |
| train_1/target_q          | -3.6998095666452215    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.64
Training epoch 72
Time for epoch 72: 293.38. Rollout time: 128.78, Training time: 164.57
Evaluating epoch 72
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 72                      |
| policy/steps              | 4477326.0               |
| test/episodes             | 1825.0                  |
| test/success_rate         | 0.6                     |
| test_0/avg_q              | -14.658316170060244     |
| test_1/avg_q              | -8.849500950627453      |
| test_1/n_subgoals         | 550.0                   |
| test_1/subgoal_succ_rate  | 0.4763636363636364      |
| train/episodes            | 7300.0                  |
| train/success_rate        | 0.74                    |
| train_0/avg_q             | -21.883763030623193     |
| train_0/current_q         | -10.051924731513889     |
| train_0/fw_bonus          | -0.9927358582615853     |
| train_0/fw_loss           | 0.03230973067693412     |
| train_0/mu_grads          | -0.10173453576862812    |
| train_0/mu_grads_std      | 0.7121332660317421      |
| train_0/mu_loss           | 9.86901554774459        |
| train_0/next_q            | -9.728999722224088      |
| train_0/q_grads           | -0.00042586928539094514 |
| train_0/q_grads_std       | 0.4590755499899387      |
| train_0/q_loss            | 0.9017076044919528      |
| train_0/reward            | -0.8442927313226392     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00029296875           |
| train_0/target_q          | -10.168138369168187     |
| train_1/avg_q             | -9.424580324601408      |
| train_1/current_q         | -3.724066745399527      |
| train_1/fw_bonus          | -0.9178755551576614     |
| train_1/fw_loss           | 0.3676038756966591      |
| train_1/mu_grads          | -0.1418497983366251     |
| train_1/mu_grads_std      | 0.5086096420884132      |
| train_1/mu_loss           | 2.3795425475366985      |
| train_1/n_subgoals        | 1571.0                  |
| train_1/next_q            | -2.3786339295986663     |
| train_1/q_grads           | -0.2745725281536579     |
| train_1/q_grads_std       | 0.7854025781154632      |
| train_1/q_loss            | 2.016512588733424       |
| train_1/reward            | -1.8248801643887418     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.11139401654996817     |
| train_1/target_q          | -3.7233466012912        |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.61
Training epoch 73
Time for epoch 73: 286.67. Rollout time: 124.13, Training time: 162.51
Evaluating epoch 73
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 73                     |
| policy/steps              | 4523887.0              |
| test/episodes             | 1850.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -15.751206643979456    |
| test_1/avg_q              | -10.541615667440556    |
| test_1/n_subgoals         | 1206.0                 |
| test_1/subgoal_succ_rate  | 0.8150912106135987     |
| train/episodes            | 7400.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -22.206187202050376    |
| train_0/current_q         | -10.091136126906108    |
| train_0/fw_bonus          | -0.9927472352981568    |
| train_0/fw_loss           | 0.03225974100641906    |
| train_0/mu_grads          | -0.10296662002801896   |
| train_0/mu_grads_std      | 0.7151607587933541     |
| train_0/mu_loss           | 9.88713261914451       |
| train_0/next_q            | -9.760534153222697     |
| train_0/q_grads           | -0.0007104928634362295 |
| train_0/q_grads_std       | 0.462266356498003      |
| train_0/q_loss            | 0.8747442103827613     |
| train_0/reward            | -0.8426748832462181    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00048828125          |
| train_0/target_q          | -10.199534640621303    |
| train_1/avg_q             | -9.409997120269313     |
| train_1/current_q         | -3.7127153482191106    |
| train_1/fw_bonus          | -0.9187271356582641    |
| train_1/fw_loss           | 0.3638705417513847     |
| train_1/mu_grads          | -0.14302468709647656   |
| train_1/mu_grads_std      | 0.5117153793573379     |
| train_1/mu_loss           | 2.3506525841348997     |
| train_1/n_subgoals        | 1554.0                 |
| train_1/next_q            | -2.347555238472031     |
| train_1/q_grads           | -0.2777895465493202    |
| train_1/q_grads_std       | 0.7903451949357987     |
| train_1/q_loss            | 1.8950952130070924     |
| train_1/reward            | -1.8215950120844355    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11647361647361647    |
| train_1/target_q          | -3.715668505661486     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.66
Training epoch 74
Time for epoch 74: 301.42. Rollout time: 135.03, Training time: 166.36
Evaluating epoch 74
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 74                      |
| policy/steps              | 4568731.0               |
| test/episodes             | 1875.0                  |
| test/success_rate         | 0.88                    |
| test_0/avg_q              | -16.324659721324597     |
| test_1/avg_q              | -6.726423030061315      |
| test_1/n_subgoals         | 179.0                   |
| test_1/subgoal_succ_rate  | 0.35195530726256985     |
| train/episodes            | 7500.0                  |
| train/success_rate        | 0.68                    |
| train_0/avg_q             | -21.93299769607886      |
| train_0/current_q         | -9.925709230659098      |
| train_0/fw_bonus          | -0.9928713545203209     |
| train_0/fw_loss           | 0.03171421592123806     |
| train_0/mu_grads          | -0.1033645074814558     |
| train_0/mu_grads_std      | 0.7184734389185905      |
| train_0/mu_loss           | 9.732805878768186       |
| train_0/next_q            | -9.604239231258267      |
| train_0/q_grads           | -0.00024021212957450188 |
| train_0/q_grads_std       | 0.4653997339308262      |
| train_0/q_loss            | 0.8258732658778236      |
| train_0/reward            | -0.8405152682396875     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.000341796875          |
| train_0/target_q          | -10.013722797785652     |
| train_1/avg_q             | -9.477195520082065      |
| train_1/current_q         | -3.7063016106184947     |
| train_1/fw_bonus          | -0.9183889463543892     |
| train_1/fw_loss           | 0.36535312086343763     |
| train_1/mu_grads          | -0.1443808637559414     |
| train_1/mu_grads_std      | 0.5150177374482154      |
| train_1/mu_loss           | 2.384350373007191       |
| train_1/n_subgoals        | 1659.0                  |
| train_1/next_q            | -2.3752207270313463     |
| train_1/q_grads           | -0.2814558111131191     |
| train_1/q_grads_std       | 0.7949033841490746      |
| train_1/q_loss            | 1.9760578148758803      |
| train_1/reward            | -1.8094386183169262     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.13682941531042797     |
| train_1/target_q          | -3.717640361633434      |
-------------------------------------------------------
New best value for test/success_rate: 0.88. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.75
Training epoch 75
Time for epoch 75: 303.49. Rollout time: 136.01, Training time: 167.45
Evaluating epoch 75
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 4618684.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -18.780110232904256   |
| test_1/avg_q              | -8.017840924958422    |
| test_1/n_subgoals         | 352.0                 |
| test_1/subgoal_succ_rate  | 0.15056818181818182   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.62                  |
| train_0/avg_q             | -22.65043765822754    |
| train_0/current_q         | -10.20089012297235    |
| train_0/fw_bonus          | -0.9928758382797241   |
| train_0/fw_loss           | 0.0316945911385119    |
| train_0/mu_grads          | -0.1026695778593421   |
| train_0/mu_grads_std      | 0.7215937539935112    |
| train_0/mu_loss           | 10.011064343769377    |
| train_0/next_q            | -9.88686198073534     |
| train_0/q_grads           | 0.0009276998898712918 |
| train_0/q_grads_std       | 0.4685559533536434    |
| train_0/q_loss            | 0.8387361548706724    |
| train_0/reward            | -0.839736250826536    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0005126953125       |
| train_0/target_q          | -10.307946246004411   |
| train_1/avg_q             | -9.850810593474367    |
| train_1/current_q         | -3.6505724538984134   |
| train_1/fw_bonus          | -0.9154368743300438   |
| train_1/fw_loss           | 0.37829522117972375   |
| train_1/mu_grads          | -0.14553687497973442  |
| train_1/mu_grads_std      | 0.517795878648758     |
| train_1/mu_loss           | 2.3347398307982266    |
| train_1/n_subgoals        | 1641.0                |
| train_1/next_q            | -2.330611990658993    |
| train_1/q_grads           | -0.2854284726083279   |
| train_1/q_grads_std       | 0.8008437007665634    |
| train_1/q_loss            | 1.9306385554843835    |
| train_1/reward            | -1.7979283990986006   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11090798293723339   |
| train_1/target_q          | -3.655933506324138    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 76
Time for epoch 76: 301.68. Rollout time: 137.98, Training time: 163.66
Evaluating epoch 76
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 4665426.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -20.077743052942893   |
| test_1/avg_q              | -6.251364910151035    |
| test_1/n_subgoals         | 245.0                 |
| test_1/subgoal_succ_rate  | 0.1673469387755102    |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.65                  |
| train_0/avg_q             | -22.837608322771562   |
| train_0/current_q         | -9.979148956521595    |
| train_0/fw_bonus          | -0.9929616630077363   |
| train_0/fw_loss           | 0.0313173973467201    |
| train_0/mu_grads          | -0.10340409725904465  |
| train_0/mu_grads_std      | 0.725130146741867     |
| train_0/mu_loss           | 9.781606839142775     |
| train_0/next_q            | -9.664879764346358    |
| train_0/q_grads           | 0.0003995890867372509 |
| train_0/q_grads_std       | 0.47099960744380953   |
| train_0/q_loss            | 0.854043071135907     |
| train_0/reward            | -0.8370814101857832   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0001953125          |
| train_0/target_q          | -10.09033868251382    |
| train_1/avg_q             | -10.324360801971315   |
| train_1/current_q         | -3.6296918955528654   |
| train_1/fw_bonus          | -0.9164092674851417   |
| train_1/fw_loss           | 0.37403216361999514   |
| train_1/mu_grads          | -0.14765252806246282  |
| train_1/mu_grads_std      | 0.5218440651893616    |
| train_1/mu_loss           | 2.2934509536706087    |
| train_1/n_subgoals        | 1612.0                |
| train_1/next_q            | -2.300305452900136    |
| train_1/q_grads           | -0.2881766200065613   |
| train_1/q_grads_std       | 0.8061560854315758    |
| train_1/q_loss            | 1.9163879887714959    |
| train_1/reward            | -1.7983657723372743   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10421836228287841   |
| train_1/target_q          | -3.636540611418808    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.73
Training epoch 77
Time for epoch 77: 295.28. Rollout time: 129.12, Training time: 166.12
Evaluating epoch 77
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 4711286.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -15.920281679932712   |
| test_1/avg_q              | -1.3914707914069502   |
| test_1/n_subgoals         | 1508.0                |
| test_1/subgoal_succ_rate  | 0.9038461538461539    |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -21.18411301754565    |
| train_0/current_q         | -10.259855349173998   |
| train_0/fw_bonus          | -0.9929340198636055   |
| train_0/fw_loss           | 0.031438820995390415  |
| train_0/mu_grads          | -0.10346211101859808  |
| train_0/mu_grads_std      | 0.7284856483340263    |
| train_0/mu_loss           | 10.073128671678504    |
| train_0/next_q            | -9.943605748358621    |
| train_0/q_grads           | 0.0003025878580956487 |
| train_0/q_grads_std       | 0.4737434186041355    |
| train_0/q_loss            | 0.8824958115953685    |
| train_0/reward            | -0.8422311701418949   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0002197265625       |
| train_0/target_q          | -10.35871204608101    |
| train_1/avg_q             | -9.005778703333746    |
| train_1/current_q         | -3.5996230136999996   |
| train_1/fw_bonus          | -0.9137067213654518   |
| train_1/fw_loss           | 0.3858803533017635    |
| train_1/mu_grads          | -0.14931393675506116  |
| train_1/mu_grads_std      | 0.5259108617901802    |
| train_1/mu_loss           | 2.2961095151233395    |
| train_1/n_subgoals        | 1615.0                |
| train_1/next_q            | -2.3000854346826842   |
| train_1/q_grads           | -0.2919973857700825   |
| train_1/q_grads_std       | 0.8108845844864845    |
| train_1/q_loss            | 1.8228663412651946    |
| train_1/reward            | -1.771318691077613    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1417956656346749    |
| train_1/target_q          | -3.6095175488343516   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.75
Training epoch 78
Time for epoch 78: 297.77. Rollout time: 131.07, Training time: 166.67
Evaluating epoch 78
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 4759904.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -22.67469362044052    |
| test_1/avg_q              | -11.454954182936065   |
| test_1/n_subgoals         | 837.0                 |
| test_1/subgoal_succ_rate  | 0.6630824372759857    |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -22.67441461460715    |
| train_0/current_q         | -10.320553027202374   |
| train_0/fw_bonus          | -0.9929693162441253   |
| train_0/fw_loss           | 0.03128369310870767   |
| train_0/mu_grads          | -0.10276345871388912  |
| train_0/mu_grads_std      | 0.7316283971071244    |
| train_0/mu_loss           | 10.130157655766993    |
| train_0/next_q            | -10.015788851197103   |
| train_0/q_grads           | 0.0003046636360522825 |
| train_0/q_grads_std       | 0.4769516192376614    |
| train_0/q_loss            | 0.8910494262735963    |
| train_0/reward            | -0.8400027254429006   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000341796875        |
| train_0/target_q          | -10.413249455779805   |
| train_1/avg_q             | -9.752538093347411    |
| train_1/current_q         | -3.744339323066778    |
| train_1/fw_bonus          | -0.9118472963571549   |
| train_1/fw_loss           | 0.3940321758389473    |
| train_1/mu_grads          | -0.15075970478355885  |
| train_1/mu_grads_std      | 0.528362886607647     |
| train_1/mu_loss           | 2.4464032012126933    |
| train_1/n_subgoals        | 1591.0                |
| train_1/next_q            | -2.444922995094234    |
| train_1/q_grads           | -0.2950249776244164   |
| train_1/q_grads_std       | 0.8155497193336487    |
| train_1/q_loss            | 1.9402478389305933    |
| train_1/reward            | -1.8121492337377276   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10433689503456946   |
| train_1/target_q          | -3.7482997717898443   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.68
Training epoch 79
Time for epoch 79: 296.66. Rollout time: 129.17, Training time: 167.46
Evaluating epoch 79
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 4809804.0              |
| test/episodes             | 2000.0                 |
| test/success_rate         | 0.64                   |
| test_0/avg_q              | -19.689392709386606    |
| test_1/avg_q              | -2.99161770715894      |
| test_1/n_subgoals         | 950.0                  |
| test_1/subgoal_succ_rate  | 0.7326315789473684     |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -21.97768211073898     |
| train_0/current_q         | -10.259616215029114    |
| train_0/fw_bonus          | -0.9931296095252037    |
| train_0/fw_loss           | 0.030579249653965235   |
| train_0/mu_grads          | -0.1045139417052269    |
| train_0/mu_grads_std      | 0.7344185888767243     |
| train_0/mu_loss           | 10.089907844675114     |
| train_0/next_q            | -9.967422448024621     |
| train_0/q_grads           | 0.00011006829556663434 |
| train_0/q_grads_std       | 0.48025406822562217    |
| train_0/q_loss            | 0.9413974154646791     |
| train_0/reward            | -0.8376414638485585    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0002685546875        |
| train_0/target_q          | -10.377332371842352    |
| train_1/avg_q             | -9.237301163052425     |
| train_1/current_q         | -3.708785834969377     |
| train_1/fw_bonus          | -0.9125453606247902    |
| train_1/fw_loss           | 0.3909718431532383     |
| train_1/mu_grads          | -0.15205611772835254   |
| train_1/mu_grads_std      | 0.5320480734109878     |
| train_1/mu_loss           | 2.393058191495297      |
| train_1/n_subgoals        | 1670.0                 |
| train_1/next_q            | -2.3956203553649735    |
| train_1/q_grads           | -0.29841553047299385   |
| train_1/q_grads_std       | 0.8211066082119942     |
| train_1/q_loss            | 1.8795511386052666     |
| train_1/reward            | -1.8109357639441441    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1251497005988024     |
| train_1/target_q          | -3.7134514206373206    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 80
Time for epoch 80: 278.08. Rollout time: 117.67, Training time: 160.38
Evaluating epoch 80
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 4854364.0              |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.6                    |
| test_0/avg_q              | -17.48301624087211     |
| test_1/avg_q              | -10.561936728107424    |
| test_1/n_subgoals         | 686.0                  |
| test_1/subgoal_succ_rate  | 0.5889212827988338     |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -21.563675150807537    |
| train_0/current_q         | -10.099861279209199    |
| train_0/fw_bonus          | -0.9929966121912003    |
| train_0/fw_loss           | 0.031163750542327763   |
| train_0/mu_grads          | -0.10642493981868029   |
| train_0/mu_grads_std      | 0.7367905825376511     |
| train_0/mu_loss           | 9.920954105119318      |
| train_0/next_q            | -9.79691437774079      |
| train_0/q_grads           | -0.0006012569472659379 |
| train_0/q_grads_std       | 0.4832284614443779     |
| train_0/q_loss            | 0.8592390917100623     |
| train_0/reward            | -0.8370134417105873    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -10.202650665839647    |
| train_1/avg_q             | -9.052136713396804     |
| train_1/current_q         | -3.677688026464387     |
| train_1/fw_bonus          | -0.9121032997965812    |
| train_1/fw_loss           | 0.3929098255932331     |
| train_1/mu_grads          | -0.15371445268392564   |
| train_1/mu_grads_std      | 0.5360330060124397     |
| train_1/mu_loss           | 2.382848390780837      |
| train_1/n_subgoals        | 1443.0                 |
| train_1/next_q            | -2.3710961114799325    |
| train_1/q_grads           | -0.3014401994645596    |
| train_1/q_grads_std       | 0.8258139878511429     |
| train_1/q_loss            | 1.8752728321816954     |
| train_1/reward            | -1.8020233295144863    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12058212058212059    |
| train_1/target_q          | -3.6788874190162533    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.65
Training epoch 81
Time for epoch 81: 304.84. Rollout time: 136.43, Training time: 168.38
Evaluating epoch 81
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 81                     |
| policy/steps              | 4899131.0              |
| test/episodes             | 2050.0                 |
| test/success_rate         | 0.92                   |
| test_0/avg_q              | -15.379219123628163    |
| test_1/avg_q              | -6.679924192866087     |
| test_1/n_subgoals         | 200.0                  |
| test_1/subgoal_succ_rate  | 0.445                  |
| train/episodes            | 8200.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -22.614957122660172    |
| train_0/current_q         | -10.215636182369272    |
| train_0/fw_bonus          | -0.9929712221026421    |
| train_0/fw_loss           | 0.03127535693347454    |
| train_0/mu_grads          | -0.10549528263509274   |
| train_0/mu_grads_std      | 0.7394641920924186     |
| train_0/mu_loss           | 10.0376191587193       |
| train_0/next_q            | -9.910852508492907     |
| train_0/q_grads           | -0.0013949070271337405 |
| train_0/q_grads_std       | 0.485989398509264      |
| train_0/q_loss            | 0.8521105063802832     |
| train_0/reward            | -0.8363781855754496    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -10.31380492615612     |
| train_1/avg_q             | -9.765204280241704     |
| train_1/current_q         | -3.7411907660909636    |
| train_1/fw_bonus          | -0.9103453859686852    |
| train_1/fw_loss           | 0.40061662197113035    |
| train_1/mu_grads          | -0.15465719290077687   |
| train_1/mu_grads_std      | 0.5397445529699325     |
| train_1/mu_loss           | 2.4303975179618313     |
| train_1/n_subgoals        | 1610.0                 |
| train_1/next_q            | -2.421008053573352     |
| train_1/q_grads           | -0.3047306090593338    |
| train_1/q_grads_std       | 0.8314104303717613     |
| train_1/q_loss            | 1.8858781150274164     |
| train_1/reward            | -1.8413665431711705    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.09254658385093167    |
| train_1/target_q          | -3.745867715477624     |
------------------------------------------------------
New best value for test/success_rate: 0.92. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.69
Training epoch 82
Time for epoch 82: 284.98. Rollout time: 121.23, Training time: 163.72
Evaluating epoch 82
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 82                     |
| policy/steps              | 4941961.0              |
| test/episodes             | 2075.0                 |
| test/success_rate         | 0.76                   |
| test_0/avg_q              | -14.51208826363886     |
| test_1/avg_q              | -6.940653272973847     |
| test_1/n_subgoals         | 724.0                  |
| test_1/subgoal_succ_rate  | 0.744475138121547      |
| train/episodes            | 8300.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -22.023716061888862    |
| train_0/current_q         | -10.114374490803673    |
| train_0/fw_bonus          | -0.993201294541359     |
| train_0/fw_loss           | 0.03026422318071127    |
| train_0/mu_grads          | -0.10594102200120688   |
| train_0/mu_grads_std      | 0.7421992659568787     |
| train_0/mu_loss           | 9.933711489469818      |
| train_0/next_q            | -9.807025446055386     |
| train_0/q_grads           | -0.0015879900485742838 |
| train_0/q_grads_std       | 0.4890082634985447     |
| train_0/q_loss            | 0.841831743956466      |
| train_0/reward            | -0.8349307223339565    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -10.233084657591338    |
| train_1/avg_q             | -9.122431223816095     |
| train_1/current_q         | -3.7097054552941175    |
| train_1/fw_bonus          | -0.9121838599443436    |
| train_1/fw_loss           | 0.39255666062235833    |
| train_1/mu_grads          | -0.15570571050047874   |
| train_1/mu_grads_std      | 0.542020796239376      |
| train_1/mu_loss           | 2.40156061112902       |
| train_1/n_subgoals        | 1463.0                 |
| train_1/next_q            | -2.3918929675817777    |
| train_1/q_grads           | -0.30820527374744416   |
| train_1/q_grads_std       | 0.8372510582208633     |
| train_1/q_loss            | 1.8877693334473293     |
| train_1/reward            | -1.8360479864117223    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.09979494190020506    |
| train_1/target_q          | -3.714153999192839     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.73
Training epoch 83
Time for epoch 83: 290.65. Rollout time: 122.40, Training time: 168.23
Evaluating epoch 83
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 83                     |
| policy/steps              | 4984100.0              |
| test/episodes             | 2100.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -12.795661969966423    |
| test_1/avg_q              | -9.765004067521097     |
| test_1/n_subgoals         | 1116.0                 |
| test_1/subgoal_succ_rate  | 0.9041218637992832     |
| train/episodes            | 8400.0                 |
| train/success_rate        | 0.74                   |
| train_0/avg_q             | -21.706037262381493    |
| train_0/current_q         | -10.169853672115718    |
| train_0/fw_bonus          | -0.993273264169693     |
| train_0/fw_loss           | 0.029947922704741357   |
| train_0/mu_grads          | -0.10450751334428787   |
| train_0/mu_grads_std      | 0.7449363961815834     |
| train_0/mu_loss           | 10.000379013448377     |
| train_0/next_q            | -9.87311460584697      |
| train_0/q_grads           | -0.0018239382305182516 |
| train_0/q_grads_std       | 0.491427705436945      |
| train_0/q_loss            | 0.8494737457424911     |
| train_0/reward            | -0.8344906337835709    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -10.280530091000491    |
| train_1/avg_q             | -9.19044953628343      |
| train_1/current_q         | -3.6845783012309057    |
| train_1/fw_bonus          | -0.9122758433222771    |
| train_1/fw_loss           | 0.3921533919870853     |
| train_1/mu_grads          | -0.15703325010836125   |
| train_1/mu_grads_std      | 0.5452937602996826     |
| train_1/mu_loss           | 2.395084780977936      |
| train_1/n_subgoals        | 1508.0                 |
| train_1/next_q            | -2.3857364185793157    |
| train_1/q_grads           | -0.31204622983932495   |
| train_1/q_grads_std       | 0.8424070164561271     |
| train_1/q_loss            | 2.118795048880183      |
| train_1/reward            | -1.809372785272717     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1306366047745358     |
| train_1/target_q          | -3.6956346355972656    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.79
Training epoch 84
Time for epoch 84: 286.79. Rollout time: 116.77, Training time: 169.98
Evaluating epoch 84
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 5023040.0              |
| test/episodes             | 2125.0                 |
| test/success_rate         | 0.92                   |
| test_0/avg_q              | -17.768427400410093    |
| test_1/avg_q              | -5.104888633309045     |
| test_1/n_subgoals         | 153.0                  |
| test_1/subgoal_succ_rate  | 0.33986928104575165    |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -21.429044568843377    |
| train_0/current_q         | -10.114009169624774    |
| train_0/fw_bonus          | -0.9931171983480453    |
| train_0/fw_loss           | 0.030633790558204053   |
| train_0/mu_grads          | -0.10501099564135075   |
| train_0/mu_grads_std      | 0.7474428847432136     |
| train_0/mu_loss           | 9.932184607895072      |
| train_0/next_q            | -9.80698239778243      |
| train_0/q_grads           | -0.0020439417799934744 |
| train_0/q_grads_std       | 0.49468776807188986    |
| train_0/q_loss            | 0.8716001269267366     |
| train_0/reward            | -0.8405405319943384    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0002197265625        |
| train_0/target_q          | -10.22311445403961     |
| train_1/avg_q             | -8.883229526782154     |
| train_1/current_q         | -3.6563442736336995    |
| train_1/fw_bonus          | -0.9132038190960884    |
| train_1/fw_loss           | 0.3880850926041603     |
| train_1/mu_grads          | -0.15895018503069877   |
| train_1/mu_grads_std      | 0.5493745595216751     |
| train_1/mu_loss           | 2.356799018009305      |
| train_1/n_subgoals        | 1429.0                 |
| train_1/next_q            | -2.332871126997013     |
| train_1/q_grads           | -0.31501092612743375   |
| train_1/q_grads_std       | 0.8475840240716934     |
| train_1/q_loss            | 1.9662904807410009     |
| train_1/reward            | -1.7993875547668723    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1224632610216935     |
| train_1/target_q          | -3.6602582247019884    |
------------------------------------------------------
New best value for test/success_rate: 0.92. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.87
Training epoch 85
Time for epoch 85: 273.52. Rollout time: 105.99, Training time: 167.51
Evaluating epoch 85
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 85                     |
| policy/steps              | 5059852.0              |
| test/episodes             | 2150.0                 |
| test/success_rate         | 0.92                   |
| test_0/avg_q              | -14.298410554275549    |
| test_1/avg_q              | -4.61292081904157      |
| test_1/n_subgoals         | 169.0                  |
| test_1/subgoal_succ_rate  | 0.47928994082840237    |
| train/episodes            | 8600.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -20.81339049582297     |
| train_0/current_q         | -10.30059829494562     |
| train_0/fw_bonus          | -0.993003997206688     |
| train_0/fw_loss           | 0.031131263868883253   |
| train_0/mu_grads          | -0.10605110619217158   |
| train_0/mu_grads_std      | 0.750478558242321      |
| train_0/mu_loss           | 10.103050362114281     |
| train_0/next_q            | -9.979641147182543     |
| train_0/q_grads           | -0.0023849766119383277 |
| train_0/q_grads_std       | 0.49837080389261246    |
| train_0/q_loss            | 0.8402282818130953     |
| train_0/reward            | -0.8446465320172137    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0002685546875        |
| train_0/target_q          | -10.399607985590565    |
| train_1/avg_q             | -8.520344401139424     |
| train_1/current_q         | -3.598501805816549     |
| train_1/fw_bonus          | -0.9138785570859909    |
| train_1/fw_loss           | 0.38512696847319605    |
| train_1/mu_grads          | -0.16084781773388385   |
| train_1/mu_grads_std      | 0.5534281969070435     |
| train_1/mu_loss           | 2.267313610187487      |
| train_1/n_subgoals        | 1386.0                 |
| train_1/next_q            | -2.2500064725833817    |
| train_1/q_grads           | -0.31973445490002633   |
| train_1/q_grads_std       | 0.8546486139297486     |
| train_1/q_loss            | 1.894883516152845      |
| train_1/reward            | -1.8155086166188994    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.15728715728715728    |
| train_1/target_q          | -3.60242279957264      |
------------------------------------------------------
New best value for test/success_rate: 0.92. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.87
Training epoch 86
Time for epoch 86: 302.17. Rollout time: 134.90, Training time: 167.24
Evaluating epoch 86
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 5105011.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.84                  |
| test_0/avg_q              | -16.2827262575032     |
| test_1/avg_q              | -3.2480982664798965   |
| test_1/n_subgoals         | 488.0                 |
| test_1/subgoal_succ_rate  | 0.7069672131147541    |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.7                   |
| train_0/avg_q             | -21.949522567001647   |
| train_0/current_q         | -10.26171155390074    |
| train_0/fw_bonus          | -0.9932628914713859   |
| train_0/fw_loss           | 0.029993547778576612  |
| train_0/mu_grads          | -0.10678293537348509  |
| train_0/mu_grads_std      | 0.7539671331644058    |
| train_0/mu_loss           | 10.080762531051764    |
| train_0/next_q            | -9.946221228320727    |
| train_0/q_grads           | -0.002171097480459139 |
| train_0/q_grads_std       | 0.5027149632573128    |
| train_0/q_loss            | 0.8686334318232142    |
| train_0/reward            | -0.8424444272808614   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0002197265625       |
| train_0/target_q          | -10.378594752147857   |
| train_1/avg_q             | -9.365851555850329    |
| train_1/current_q         | -3.6201213293271324   |
| train_1/fw_bonus          | -0.9119496360421181   |
| train_1/fw_loss           | 0.3935835286974907    |
| train_1/mu_grads          | -0.1621706925332546   |
| train_1/mu_grads_std      | 0.5571574285626412    |
| train_1/mu_loss           | 2.2898264302401774    |
| train_1/n_subgoals        | 1619.0                |
| train_1/next_q            | -2.2855154073316215   |
| train_1/q_grads           | -0.3228331983089447   |
| train_1/q_grads_std       | 0.8590367898344994    |
| train_1/q_loss            | 1.9676775586074036    |
| train_1/reward            | -1.8027277470180707   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14638665843113033   |
| train_1/target_q          | -3.6195385481027955   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.89
Training epoch 87
Time for epoch 87: 282.55. Rollout time: 116.75, Training time: 165.77
Evaluating epoch 87
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 5145342.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.88                  |
| test_0/avg_q              | -12.746679456602282   |
| test_1/avg_q              | -1.432357845035296    |
| test_1/n_subgoals         | 733.0                 |
| test_1/subgoal_succ_rate  | 0.8335607094133697    |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.76                  |
| train_0/avg_q             | -22.42478917160255    |
| train_0/current_q         | -10.255873625516      |
| train_0/fw_bonus          | -0.9933610126376152   |
| train_0/fw_loss           | 0.02956224591471255   |
| train_0/mu_grads          | -0.10803191978484392  |
| train_0/mu_grads_std      | 0.7569608077406883    |
| train_0/mu_loss           | 10.048010336995738    |
| train_0/next_q            | -9.932369175367883    |
| train_0/q_grads           | -0.002454668818973005 |
| train_0/q_grads_std       | 0.5054278954863548    |
| train_0/q_loss            | 0.8282456843836451    |
| train_0/reward            | -0.8440193752918276   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0001708984375       |
| train_0/target_q          | -10.360139307206286   |
| train_1/avg_q             | -9.44889603734528     |
| train_1/current_q         | -3.5888005668521066   |
| train_1/fw_bonus          | -0.9118759781122208   |
| train_1/fw_loss           | 0.3939064420759678    |
| train_1/mu_grads          | -0.163858887180686    |
| train_1/mu_grads_std      | 0.5606495842337609    |
| train_1/mu_loss           | 2.1928431397848387    |
| train_1/n_subgoals        | 1439.0                |
| train_1/next_q            | -2.193381796292727    |
| train_1/q_grads           | -0.32517115995287893  |
| train_1/q_grads_std       | 0.8626810565590859    |
| train_1/q_loss            | 1.877893544999178     |
| train_1/reward            | -1.8550590821207151   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11744266851980542   |
| train_1/target_q          | -3.5925514834342778   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.89
Training epoch 88
Time for epoch 88: 270.71. Rollout time: 121.58, Training time: 149.10
Evaluating epoch 88
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 88                     |
| policy/steps              | 5191455.0              |
| test/episodes             | 2225.0                 |
| test/success_rate         | 0.8                    |
| test_0/avg_q              | -16.491413020683577    |
| test_1/avg_q              | -7.045816917016667     |
| test_1/n_subgoals         | 229.0                  |
| test_1/subgoal_succ_rate  | 0.2052401746724891     |
| train/episodes            | 8900.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -22.06527356650631     |
| train_0/current_q         | -10.324205941604045    |
| train_0/fw_bonus          | -0.9932590529322625    |
| train_0/fw_loss           | 0.030010323971509933   |
| train_0/mu_grads          | -0.1080362431704998    |
| train_0/mu_grads_std      | 0.7596266031265259     |
| train_0/mu_loss           | 10.132822393281844     |
| train_0/next_q            | -9.99341594452218      |
| train_0/q_grads           | -0.0018380477034952492 |
| train_0/q_grads_std       | 0.509405942261219      |
| train_0/q_loss            | 0.9051453324120411     |
| train_0/reward            | -0.845848280381324     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -10.408856067179693    |
| train_1/avg_q             | -9.489609603146189     |
| train_1/current_q         | -3.639357557190807     |
| train_1/fw_bonus          | -0.9114284068346024    |
| train_1/fw_loss           | 0.39586861431598663    |
| train_1/mu_grads          | -0.16551261506974696   |
| train_1/mu_grads_std      | 0.5643368691205979     |
| train_1/mu_loss           | 2.2938254490462064     |
| train_1/n_subgoals        | 1618.0                 |
| train_1/next_q            | -2.267677018109076     |
| train_1/q_grads           | -0.3282866768538952    |
| train_1/q_grads_std       | 0.8665412113070488     |
| train_1/q_loss            | 1.7694367938435733     |
| train_1/reward            | -1.8357190851595078    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11928306551297899    |
| train_1/target_q          | -3.6477620115419285    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8600000000000001
Training epoch 89
Time for epoch 89: 277.56. Rollout time: 114.12, Training time: 163.41
Evaluating epoch 89
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 5235108.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.72                  |
| test_0/avg_q              | -10.749782704648387   |
| test_1/avg_q              | -0.9364174493266598   |
| test_1/n_subgoals         | 1578.0                |
| test_1/subgoal_succ_rate  | 0.8713561470215463    |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -21.693984662893453   |
| train_0/current_q         | -10.234463328027413   |
| train_0/fw_bonus          | -0.9933547645807266   |
| train_0/fw_loss           | 0.029589692084118723  |
| train_0/mu_grads          | -0.10867581050843     |
| train_0/mu_grads_std      | 0.7618476942181587    |
| train_0/mu_loss           | 10.02838060560235     |
| train_0/next_q            | -9.90786012605383     |
| train_0/q_grads           | -0.001220502587966621 |
| train_0/q_grads_std       | 0.5124607011675835    |
| train_0/q_loss            | 0.9265870703295537    |
| train_0/reward            | -0.847019182593067    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -10.338920347880645   |
| train_1/avg_q             | -9.084388943648978    |
| train_1/current_q         | -3.6383506381611914   |
| train_1/fw_bonus          | -0.9143716514110565   |
| train_1/fw_loss           | 0.3829652816057205    |
| train_1/mu_grads          | -0.16759903281927108  |
| train_1/mu_grads_std      | 0.568396782875061     |
| train_1/mu_loss           | 2.264914908039289     |
| train_1/n_subgoals        | 1449.0                |
| train_1/next_q            | -2.2701791621083083   |
| train_1/q_grads           | -0.3311875149607658   |
| train_1/q_grads_std       | 0.8701651126146317    |
| train_1/q_loss            | 1.9250626447840293    |
| train_1/reward            | -1.8192951960758363   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.11594202898550725   |
| train_1/target_q          | -3.6353386351666344   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.81
Training epoch 90
Time for epoch 90: 342.45. Rollout time: 158.45, Training time: 183.97
Evaluating epoch 90
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 90                     |
| policy/steps              | 5279327.0              |
| test/episodes             | 2275.0                 |
| test/success_rate         | 1.0                    |
| test_0/avg_q              | -11.451591649788813    |
| test_1/avg_q              | -2.132014373936417     |
| test_1/n_subgoals         | 90.0                   |
| test_1/subgoal_succ_rate  | 0.36666666666666664    |
| train/episodes            | 9100.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -21.792321463055853    |
| train_0/current_q         | -10.112869448923755    |
| train_0/fw_bonus          | -0.9933075353503227    |
| train_0/fw_loss           | 0.029797294409945607   |
| train_0/mu_grads          | -0.10872007738798857   |
| train_0/mu_grads_std      | 0.7647175952792168     |
| train_0/mu_loss           | 9.902400355761241      |
| train_0/next_q            | -9.783250396021295     |
| train_0/q_grads           | -0.0014666363917058335 |
| train_0/q_grads_std       | 0.5155546635389328     |
| train_0/q_loss            | 0.8422718996017251     |
| train_0/reward            | -0.8475815012621751    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -10.208427722476099    |
| train_1/avg_q             | -9.069749616145918     |
| train_1/current_q         | -3.62629211120137      |
| train_1/fw_bonus          | -0.9126015976071358    |
| train_1/fw_loss           | 0.3907252810895443     |
| train_1/mu_grads          | -0.16859088614583015   |
| train_1/mu_grads_std      | 0.5709068924188614     |
| train_1/mu_loss           | 2.245434282123786      |
| train_1/n_subgoals        | 1686.0                 |
| train_1/next_q            | -2.234265347843854     |
| train_1/q_grads           | -0.33447340950369836   |
| train_1/q_grads_std       | 0.8737504377961158     |
| train_1/q_loss            | 2.0177970873557407     |
| train_1/reward            | -1.836342300526303     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1257413997627521     |
| train_1/target_q          | -3.6271346420924004    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_90.pkl ...
New best value for test/success_rate: 1.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.8500000000000001
Training epoch 91
Time for epoch 91: 300.79. Rollout time: 139.78, Training time: 160.98
Evaluating epoch 91
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 91                     |
| policy/steps              | 5324703.0              |
| test/episodes             | 2300.0                 |
| test/success_rate         | 0.8                    |
| test_0/avg_q              | -11.976450965655966    |
| test_1/avg_q              | -5.117308784031863     |
| test_1/n_subgoals         | 236.0                  |
| test_1/subgoal_succ_rate  | 0.2754237288135593     |
| train/episodes            | 9200.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -22.16218544264145     |
| train_0/current_q         | -10.32051713987704     |
| train_0/fw_bonus          | -0.9932533666491509    |
| train_0/fw_loss           | 0.030035301763564348   |
| train_0/mu_grads          | -0.10889503881335258   |
| train_0/mu_grads_std      | 0.767017263174057      |
| train_0/mu_loss           | 10.122094684403837     |
| train_0/next_q            | -9.990806352209422     |
| train_0/q_grads           | -0.0006592466059373691 |
| train_0/q_grads_std       | 0.5188274085521698     |
| train_0/q_loss            | 0.8913129030747207     |
| train_0/reward            | -0.8501178993654321    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0004638671875        |
| train_0/target_q          | -10.407160141575966    |
| train_1/avg_q             | -9.837161118839903     |
| train_1/current_q         | -3.5658194808733183    |
| train_1/fw_bonus          | -0.9117071807384491    |
| train_1/fw_loss           | 0.3946464523673058     |
| train_1/mu_grads          | -0.170165578648448     |
| train_1/mu_grads_std      | 0.5736877620220184     |
| train_1/mu_loss           | 2.2491690474403496     |
| train_1/n_subgoals        | 1586.0                 |
| train_1/next_q            | -2.2272525539104553    |
| train_1/q_grads           | -0.33734514340758326   |
| train_1/q_grads_std       | 0.87809107452631       |
| train_1/q_loss            | 1.8175388481799424     |
| train_1/reward            | -1.797626050421968     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11223203026481715    |
| train_1/target_q          | -3.5674906201809313    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8300000000000001
Training epoch 92
Time for epoch 92: 267.67. Rollout time: 122.62, Training time: 145.03
Evaluating epoch 92
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 92                     |
| policy/steps              | 5369151.0              |
| test/episodes             | 2325.0                 |
| test/success_rate         | 0.84                   |
| test_0/avg_q              | -13.411413524647267    |
| test_1/avg_q              | -6.6014881798458696    |
| test_1/n_subgoals         | 580.0                  |
| test_1/subgoal_succ_rate  | 0.7862068965517242     |
| train/episodes            | 9300.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -21.25537532883695     |
| train_0/current_q         | -10.363369270291528    |
| train_0/fw_bonus          | -0.9931530401110649    |
| train_0/fw_loss           | 0.030476232850924136   |
| train_0/mu_grads          | -0.10910378620028496   |
| train_0/mu_grads_std      | 0.7701064676046372     |
| train_0/mu_loss           | 10.170638381166857     |
| train_0/next_q            | -10.034395744366732    |
| train_0/q_grads           | -0.0007181665147072636 |
| train_0/q_grads_std       | 0.521532067656517      |
| train_0/q_loss            | 0.8833070459303516     |
| train_0/reward            | -0.8516790630150354    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -10.460103775614972    |
| train_1/avg_q             | -9.199096839579704     |
| train_1/current_q         | -3.609841602360401     |
| train_1/fw_bonus          | -0.9118665635585785    |
| train_1/fw_loss           | 0.39394769743084906    |
| train_1/mu_grads          | -0.17152688689529896   |
| train_1/mu_grads_std      | 0.5758921384811402     |
| train_1/mu_loss           | 2.2060404730782004     |
| train_1/n_subgoals        | 1607.0                 |
| train_1/next_q            | -2.2090421834060536    |
| train_1/q_grads           | -0.3412413753569126    |
| train_1/q_grads_std       | 0.8829302325844764     |
| train_1/q_loss            | 1.9446353249443056     |
| train_1/reward            | -1.839209649545228     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12756689483509645    |
| train_1/target_q          | -3.6151474170018334    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.84
Training epoch 93
Time for epoch 93: 273.04. Rollout time: 127.31, Training time: 145.71
Evaluating epoch 93
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 5417305.0              |
| test/episodes             | 2350.0                 |
| test/success_rate         | 0.76                   |
| test_0/avg_q              | -15.474055083432278    |
| test_1/avg_q              | -2.390999570879529     |
| test_1/n_subgoals         | 910.0                  |
| test_1/subgoal_succ_rate  | 0.8285714285714286     |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -22.068047980774153    |
| train_0/current_q         | -10.184494711171533    |
| train_0/fw_bonus          | -0.9933372646570205    |
| train_0/fw_loss           | 0.029666689364239572   |
| train_0/mu_grads          | -0.1102449456229806    |
| train_0/mu_grads_std      | 0.7725711032748223     |
| train_0/mu_loss           | 9.979324116819459      |
| train_0/next_q            | -9.854518563837733     |
| train_0/q_grads           | -0.0008555133579648099 |
| train_0/q_grads_std       | 0.5238763451576233     |
| train_0/q_loss            | 0.8474371207284352     |
| train_0/reward            | -0.8477916726616967    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -10.276645011613267    |
| train_1/avg_q             | -9.586495825346217     |
| train_1/current_q         | -3.69081350019304      |
| train_1/fw_bonus          | -0.9105358570814133    |
| train_1/fw_loss           | 0.39978157430887223    |
| train_1/mu_grads          | -0.1730195116251707    |
| train_1/mu_grads_std      | 0.5778673931956291     |
| train_1/mu_loss           | 2.3391434826878927     |
| train_1/n_subgoals        | 1697.0                 |
| train_1/next_q            | -2.3350881663162       |
| train_1/q_grads           | -0.34433070495724677   |
| train_1/q_grads_std       | 0.8880187302827836     |
| train_1/q_loss            | 2.2677505011547865     |
| train_1/reward            | -1.8157415658621177    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11667648791985857    |
| train_1/target_q          | -3.6882251085459563    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8500000000000001
Training epoch 94
Time for epoch 94: 349.69. Rollout time: 157.89, Training time: 191.76
Evaluating epoch 94
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 94                     |
| policy/steps              | 5464610.0              |
| test/episodes             | 2375.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -17.91992829679914     |
| test_1/avg_q              | -6.702930727681191     |
| test_1/n_subgoals         | 211.0                  |
| test_1/subgoal_succ_rate  | 0.4075829383886256     |
| train/episodes            | 9500.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -22.062693278657488    |
| train_0/current_q         | -10.192112737625717    |
| train_0/fw_bonus          | -0.9933024302124978    |
| train_0/fw_loss           | 0.029819689970463515   |
| train_0/mu_grads          | -0.11180126424878836   |
| train_0/mu_grads_std      | 0.7754589155316353     |
| train_0/mu_loss           | 9.99920923425454       |
| train_0/next_q            | -9.869904204125124     |
| train_0/q_grads           | -0.0009030382570927031 |
| train_0/q_grads_std       | 0.5270484864711762     |
| train_0/q_loss            | 0.8492249702672698     |
| train_0/reward            | -0.8450398905042675    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -10.29700225284586     |
| train_1/avg_q             | -9.574918312206666     |
| train_1/current_q         | -3.665994260262212     |
| train_1/fw_bonus          | -0.9096944108605385    |
| train_1/fw_loss           | 0.4034705363214016     |
| train_1/mu_grads          | -0.1737058449536562    |
| train_1/mu_grads_std      | 0.5786300390958786     |
| train_1/mu_loss           | 2.31122311698197       |
| train_1/n_subgoals        | 1723.0                 |
| train_1/next_q            | -2.3128822391085215    |
| train_1/q_grads           | -0.3466029897332191    |
| train_1/q_grads_std       | 0.8922253429889679     |
| train_1/q_loss            | 1.9690847052188531     |
| train_1/reward            | -1.8176157622350728    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12304120719674985    |
| train_1/target_q          | -3.6668983488150966    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8200000000000001
Training epoch 95
Time for epoch 95: 357.46. Rollout time: 167.36, Training time: 190.07
Evaluating epoch 95
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 5512980.0              |
| test/episodes             | 2400.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -18.75971170444047     |
| test_1/avg_q              | -6.123426734745158     |
| test_1/n_subgoals         | 183.0                  |
| test_1/subgoal_succ_rate  | 0.3442622950819672     |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -22.563529137057426    |
| train_0/current_q         | -10.285992050165941    |
| train_0/fw_bonus          | -0.9933154255151748    |
| train_0/fw_loss           | 0.02976261414587498    |
| train_0/mu_grads          | -0.11330807078629732   |
| train_0/mu_grads_std      | 0.778813561797142      |
| train_0/mu_loss           | 10.084686233406185     |
| train_0/next_q            | -9.975292295568016     |
| train_0/q_grads           | 2.1287754088916698e-05 |
| train_0/q_grads_std       | 0.5303723827004433     |
| train_0/q_loss            | 0.8732933208539417     |
| train_0/reward            | -0.8436669898459513    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000341796875         |
| train_0/target_q          | -10.392535887284135    |
| train_1/avg_q             | -9.619713950434706     |
| train_1/current_q         | -3.7577640987704584    |
| train_1/fw_bonus          | -0.9085636213421822    |
| train_1/fw_loss           | 0.408428019285202      |
| train_1/mu_grads          | -0.17502810321748258   |
| train_1/mu_grads_std      | 0.5813631132245064     |
| train_1/mu_loss           | 2.3882752662718874     |
| train_1/n_subgoals        | 1758.0                 |
| train_1/next_q            | -2.3789689098168822    |
| train_1/q_grads           | -0.3486707732081413    |
| train_1/q_grads_std       | 0.8964244589209557     |
| train_1/q_loss            | 2.186348762165534      |
| train_1/reward            | -1.8773408930050208    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.10352673492605233    |
| train_1/target_q          | -3.760261636237297     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.84
Training epoch 96
Time for epoch 96: 359.80. Rollout time: 152.32, Training time: 207.45
Evaluating epoch 96
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 5555977.0              |
| test/episodes             | 2425.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -18.315248069194844    |
| test_1/avg_q              | -5.056149192835883     |
| test_1/n_subgoals         | 188.0                  |
| test_1/subgoal_succ_rate  | 0.35106382978723405    |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.74                   |
| train_0/avg_q             | -22.048783193127193    |
| train_0/current_q         | -10.325802866769148    |
| train_0/fw_bonus          | -0.9933649227023125    |
| train_0/fw_loss           | 0.029545060871168972   |
| train_0/mu_grads          | -0.11264676321297884   |
| train_0/mu_grads_std      | 0.7814087122678757     |
| train_0/mu_loss           | 10.146115626155568     |
| train_0/next_q            | -10.014184838110895    |
| train_0/q_grads           | -0.0007551477334345691 |
| train_0/q_grads_std       | 0.5332750901579857     |
| train_0/q_loss            | 0.8714320943590212     |
| train_0/reward            | -0.8439236744212394    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -10.417071320646427    |
| train_1/avg_q             | -9.209805549118672     |
| train_1/current_q         | -3.746202457914206     |
| train_1/fw_bonus          | -0.9085819140076637    |
| train_1/fw_loss           | 0.4083478473126888     |
| train_1/mu_grads          | -0.17623332738876343   |
| train_1/mu_grads_std      | 0.5833291441202164     |
| train_1/mu_loss           | 2.3433048612970757     |
| train_1/n_subgoals        | 1557.0                 |
| train_1/next_q            | -2.356753179315402     |
| train_1/q_grads           | -0.35185239017009734   |
| train_1/q_grads_std       | 0.9005323395133018     |
| train_1/q_loss            | 2.070961702526356      |
| train_1/reward            | -1.8709047237141931    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11753371868978806    |
| train_1/target_q          | -3.7503752520848628    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.85
Training epoch 97
Time for epoch 97: 337.23. Rollout time: 143.67, Training time: 193.53
Evaluating epoch 97
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 97                     |
| policy/steps              | 5601424.0              |
| test/episodes             | 2450.0                 |
| test/success_rate         | 0.72                   |
| test_0/avg_q              | -19.75806212528808     |
| test_1/avg_q              | -7.388715414960293     |
| test_1/n_subgoals         | 304.0                  |
| test_1/subgoal_succ_rate  | 0.29276315789473684    |
| train/episodes            | 9800.0                 |
| train/success_rate        | 0.77                   |
| train_0/avg_q             | -21.517948004070988    |
| train_0/current_q         | -10.364786018554616    |
| train_0/fw_bonus          | -0.9933026120066643    |
| train_0/fw_loss           | 0.029818883864209056   |
| train_0/mu_grads          | -0.11384601015597581   |
| train_0/mu_grads_std      | 0.7844552978873253     |
| train_0/mu_loss           | 10.176007629425243     |
| train_0/next_q            | -10.048168620767592    |
| train_0/q_grads           | -0.0006810353603214026 |
| train_0/q_grads_std       | 0.5363222837448121     |
| train_0/q_loss            | 0.9207650135216273     |
| train_0/reward            | -0.8462728923710529    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003662109375        |
| train_0/target_q          | -10.457270658564529    |
| train_1/avg_q             | -8.939510803645236     |
| train_1/current_q         | -3.7232522614603227    |
| train_1/fw_bonus          | -0.9095970287919044    |
| train_1/fw_loss           | 0.4038974970579147     |
| train_1/mu_grads          | -0.1765454813838005    |
| train_1/mu_grads_std      | 0.5858330130577087     |
| train_1/mu_loss           | 2.348031453767807      |
| train_1/n_subgoals        | 1573.0                 |
| train_1/next_q            | -2.3707740878400556    |
| train_1/q_grads           | -0.3554781384766102    |
| train_1/q_grads_std       | 0.9053078889846802     |
| train_1/q_loss            | 2.0595289297660764     |
| train_1/reward            | -1.8410289827974338    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12841703750794659    |
| train_1/target_q          | -3.7194902461685246    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8400000000000001
Training epoch 98
Time for epoch 98: 350.15. Rollout time: 147.67, Training time: 202.46
Evaluating epoch 98
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 5643918.0              |
| test/episodes             | 2475.0                 |
| test/success_rate         | 0.84                   |
| test_0/avg_q              | -13.964659773495496    |
| test_1/avg_q              | -6.00591388066584      |
| test_1/n_subgoals         | 196.0                  |
| test_1/subgoal_succ_rate  | 0.24489795918367346    |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -22.612662450592104    |
| train_0/current_q         | -10.294553022532742    |
| train_0/fw_bonus          | -0.9933806210756302    |
| train_0/fw_loss           | 0.02947609364055097    |
| train_0/mu_grads          | -0.11283049434423446   |
| train_0/mu_grads_std      | 0.7870356515049934     |
| train_0/mu_loss           | 10.092298668941595     |
| train_0/next_q            | -9.977025694025501     |
| train_0/q_grads           | -0.0009841777398833073 |
| train_0/q_grads_std       | 0.5393125385046005     |
| train_0/q_loss            | 0.9010379994577203     |
| train_0/reward            | -0.8442366965624387    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000634765625         |
| train_0/target_q          | -10.374409511235822    |
| train_1/avg_q             | -9.543960159113091     |
| train_1/current_q         | -3.8051984901248317    |
| train_1/fw_bonus          | -0.9084048941731453    |
| train_1/fw_loss           | 0.4091239243745804     |
| train_1/mu_grads          | -0.17772413827478886   |
| train_1/mu_grads_std      | 0.5879777655005455     |
| train_1/mu_loss           | 2.4733029806775795     |
| train_1/n_subgoals        | 1506.0                 |
| train_1/next_q            | -2.4881792843506902    |
| train_1/q_grads           | -0.35913432389497757   |
| train_1/q_grads_std       | 0.9092452108860016     |
| train_1/q_loss            | 2.0911824970679658     |
| train_1/reward            | -1.825674610666465     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.10292164674634795    |
| train_1/target_q          | -3.803440173975298     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.83
Training epoch 99
Time for epoch 99: 339.46. Rollout time: 139.51, Training time: 199.91
Evaluating epoch 99
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-------------------------------------------------------
| epoch                     | 99                      |
| policy/steps              | 5689961.0               |
| test/episodes             | 2500.0                  |
| test/success_rate         | 0.68                    |
| test_0/avg_q              | -16.31323068566697      |
| test_1/avg_q              | -2.6085093926238216     |
| test_1/n_subgoals         | 920.0                   |
| test_1/subgoal_succ_rate  | 0.758695652173913       |
| train/episodes            | 10000.0                 |
| train/success_rate        | 0.71                    |
| train_0/avg_q             | -21.93785369814755      |
| train_0/current_q         | -10.368619072662502     |
| train_0/fw_bonus          | -0.9933997735381126     |
| train_0/fw_loss           | 0.02939192377962172     |
| train_0/mu_grads          | -0.11342813540250063    |
| train_0/mu_grads_std      | 0.7890055164694786      |
| train_0/mu_loss           | 10.18612508289176       |
| train_0/next_q            | -10.056718964029141     |
| train_0/q_grads           | -0.00021004798616672816 |
| train_0/q_grads_std       | 0.5425860017538071      |
| train_0/q_loss            | 0.8722183905962669      |
| train_0/reward            | -0.8396442218734592     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.000634765625          |
| train_0/target_q          | -10.458989718854744     |
| train_1/avg_q             | -9.394901764375696      |
| train_1/current_q         | -3.8744601423293843     |
| train_1/fw_bonus          | -0.9103988811373711     |
| train_1/fw_loss           | 0.40038207471370696     |
| train_1/mu_grads          | -0.17810557149350642    |
| train_1/mu_grads_std      | 0.590215477347374       |
| train_1/mu_loss           | 2.528990966145301       |
| train_1/n_subgoals        | 1549.0                  |
| train_1/next_q            | -2.5544565992871897     |
| train_1/q_grads           | -0.3611008532345295     |
| train_1/q_grads_std       | 0.9130520418286323      |
| train_1/q_loss            | 2.1575252524233672      |
| train_1/reward            | -1.866185774125188      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0                     |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.12201420271142673     |
| train_1/target_q          | -3.87728944851989       |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.78
All epochs are finished. Stopping the training now.
