Starting process id: 8648
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f94c9ad2680>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 15,15
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 15
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 15
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 240.70. Rollout time: 73.62, Training time: 167.05
Evaluating epoch 0
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 28125.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -14.999999999999998    |
| test_1/avg_q              | -8.140167319776468     |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -9.918452918979893     |
| train_0/current_q         | -5.4074683586162235    |
| train_0/fw_bonus          | -0.9948932930827141    |
| train_0/fw_loss           | 0.02602881332859397    |
| train_0/mu_grads          | -0.0007036485025309957 |
| train_0/mu_grads_std      | 0.17054423540830613    |
| train_0/mu_loss           | 5.319307673392157      |
| train_0/next_q            | -5.316604478117093     |
| train_0/q_grads           | 0.02827400667592883    |
| train_0/q_grads_std       | 0.10795293357223272    |
| train_0/q_loss            | 0.20244707568102407    |
| train_0/reward            | -0.6970438129610557    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.011474609375         |
| train_0/target_q          | -5.6400769074254615    |
| train_1/avg_q             | -5.162948046742859     |
| train_1/current_q         | -2.30866276544715      |
| train_1/fw_bonus          | -0.9954885110259056    |
| train_1/fw_loss           | 0.042519119661301376   |
| train_1/mu_grads          | -0.0009075367022887803 |
| train_1/mu_grads_std      | 0.2514435715973377     |
| train_1/mu_loss           | 2.1434713692471172     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -1.1411527454854422    |
| train_1/q_grads           | 0.021840674662962557   |
| train_1/q_grads_std       | 0.1114209234714508     |
| train_1/q_loss            | 0.16885189440491283    |
| train_1/reward            | -1.5312159375571355    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0025146484375        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.2997761997242834    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 242.69. Rollout time: 70.26, Training time: 172.40
Evaluating epoch 1
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 56250.0               |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.994411113026198   |
| test_1/avg_q              | -7.791626729079721    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.993429047616372   |
| train_0/current_q         | -5.463528977315809    |
| train_0/fw_bonus          | -0.9968130558729171   |
| train_0/fw_loss           | 0.016703656618483366  |
| train_0/mu_grads          | -0.013992789224721492 |
| train_0/mu_grads_std      | 0.20971323288977145   |
| train_0/mu_loss           | 5.40693241268535      |
| train_0/next_q            | -5.404819196484478    |
| train_0/q_grads           | 0.026528106117621065  |
| train_0/q_grads_std       | 0.1197755966335535    |
| train_0/q_loss            | 0.21514292924078302   |
| train_0/reward            | -0.6974543840595289   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0133056640625       |
| train_0/target_q          | -5.7017634528518695   |
| train_1/avg_q             | -7.775846613319646    |
| train_1/current_q         | -3.298172281920157    |
| train_1/fw_bonus          | -0.993615573644638    |
| train_1/fw_loss           | 0.05167763167992234   |
| train_1/mu_grads          | -0.013212375389412046 |
| train_1/mu_grads_std      | 0.27272539064288137   |
| train_1/mu_loss           | 3.509336197905685     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -2.4966886675790447   |
| train_1/q_grads           | 0.013479434768669307  |
| train_1/q_grads_std       | 0.1270400106906891    |
| train_1/q_loss            | 0.34671997190239684   |
| train_1/reward            | -1.52103875102257     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002734375           |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.2847492541103924   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 234.60. Rollout time: 70.53, Training time: 164.04
Evaluating epoch 2
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 84375.0                |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -8.028596581360027     |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -14.982166233505092    |
| train_0/current_q         | -5.426185935979855     |
| train_0/fw_bonus          | -0.9975409269332886    |
| train_0/fw_loss           | 0.013168142666108907   |
| train_0/mu_grads          | -0.0176782819442451    |
| train_0/mu_grads_std      | 0.23462543971836566    |
| train_0/mu_loss           | 5.372558904451556      |
| train_0/next_q            | -5.3695563947920055    |
| train_0/q_grads           | 0.02292471956461668    |
| train_0/q_grads_std       | 0.13377190083265306    |
| train_0/q_loss            | 0.21997402698388538    |
| train_0/reward            | -0.700308547392342     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.012744140625         |
| train_0/target_q          | -5.661506055104732     |
| train_1/avg_q             | -7.697671718224493     |
| train_1/current_q         | -3.4973683228471097    |
| train_1/fw_bonus          | -0.9938297525048256    |
| train_1/fw_loss           | 0.050630437396466735   |
| train_1/mu_grads          | -0.017047977587208153  |
| train_1/mu_grads_std      | 0.28952764347195625    |
| train_1/mu_loss           | 3.8150735987571722     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -2.7988563932856136    |
| train_1/q_grads           | -0.0004885999267571605 |
| train_1/q_grads_std       | 0.13552075996994972    |
| train_1/q_loss            | 0.3591426138288956     |
| train_1/reward            | -1.5307405537081649    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0032470703125        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -3.48165949178278      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 252.45. Rollout time: 71.78, Training time: 180.64
Evaluating epoch 3
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 112500.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -5.003185524779155e-10 |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.478235580710384     |
| train_0/fw_bonus          | -0.9980290159583092    |
| train_0/fw_loss           | 0.010797323985025286   |
| train_0/mu_grads          | -0.021679577743634583  |
| train_0/mu_grads_std      | 0.25135946795344355    |
| train_0/mu_loss           | 5.416534037896463      |
| train_0/next_q            | -5.4112214123387865    |
| train_0/q_grads           | 0.0216973508708179     |
| train_0/q_grads_std       | 0.1478301677852869     |
| train_0/q_loss            | 0.21943799023939556    |
| train_0/reward            | -0.7058382328839798    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0114013671875        |
| train_0/target_q          | -5.714109281435534     |
| train_1/avg_q             | -8.085363010637808     |
| train_1/current_q         | -6.922743593448892e-08 |
| train_1/fw_bonus          | -0.993135741353035     |
| train_1/fw_loss           | 0.05402407292276621    |
| train_1/mu_grads          | -0.01581735722720623   |
| train_1/mu_grads_std      | 0.29260489344596863    |
| train_1/mu_loss           | 1.0                    |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -8.62458641592755e-26  |
| train_1/q_grads           | -0.009829375892877579  |
| train_1/q_grads_std       | 0.1613212525844574     |
| train_1/q_loss            | 6.636550833130562      |
| train_1/reward            | -1.519089841505047     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00341796875          |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.519089841505047     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 261.58. Rollout time: 70.38, Training time: 191.17
Evaluating epoch 4
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 4                       |
| policy/steps              | 140625.0                |
| test/episodes             | 125.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -3.941363371590002e-08  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 500.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.401594155776299      |
| train_0/fw_bonus          | -0.9982390761375427     |
| train_0/fw_loss           | 0.009776872745715082    |
| train_0/mu_grads          | -0.020442737406119703   |
| train_0/mu_grads_std      | 0.264297866076231       |
| train_0/mu_loss           | 5.340177695110579       |
| train_0/next_q            | -5.335367317063073      |
| train_0/q_grads           | 0.01865834235213697     |
| train_0/q_grads_std       | 0.15627568103373052     |
| train_0/q_loss            | 0.21628835243137612     |
| train_0/reward            | -0.7028671011656116     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0127197265625         |
| train_0/target_q          | -5.632836842537212      |
| train_1/avg_q             | -2.762753518329558e-08  |
| train_1/current_q         | -7.407063318669073e-08  |
| train_1/fw_bonus          | -0.9925471484661103     |
| train_1/fw_loss           | 0.056902225594967604    |
| train_1/mu_grads          | -0.01581735722720623    |
| train_1/mu_grads_std      | 0.29260489344596863     |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -2.9342004364645657e-25 |
| train_1/q_grads           | -0.009829539083875715   |
| train_1/q_grads_std       | 0.16132117956876754     |
| train_1/q_loss            | 6.683515745557512       |
| train_1/reward            | -1.5227140048278671     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0025146484375         |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5227140048278671     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 263.17. Rollout time: 69.83, Training time: 193.31
Evaluating epoch 5
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 5                       |
| policy/steps              | 168750.0                |
| test/episodes             | 150.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -4.0332600484365e-08    |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 600.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.479484277077467      |
| train_0/fw_bonus          | -0.998424519598484      |
| train_0/fw_loss           | 0.008876169240102172    |
| train_0/mu_grads          | -0.022201573848724364   |
| train_0/mu_grads_std      | 0.2707085654139519      |
| train_0/mu_loss           | 5.417031699089651       |
| train_0/next_q            | -5.4110777378194514     |
| train_0/q_grads           | 0.011837824434041976    |
| train_0/q_grads_std       | 0.163278328999877       |
| train_0/q_loss            | 0.22344030289345035     |
| train_0/reward            | -0.706805030326359      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.01064453125           |
| train_0/target_q          | -5.712630010203393      |
| train_1/avg_q             | -9.425733943440768e-08  |
| train_1/current_q         | -1.0511662071570729e-07 |
| train_1/fw_bonus          | -0.9925364062190056     |
| train_1/fw_loss           | 0.056954729557037356    |
| train_1/mu_grads          | -0.01581735722720623    |
| train_1/mu_grads_std      | 0.29260489344596863     |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -1.2902674621184802e-24 |
| train_1/q_grads           | -0.00983102130703628    |
| train_1/q_grads_std       | 0.16132039502263068     |
| train_1/q_loss            | 6.544215196340824       |
| train_1/reward            | -1.5084386167742196     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002392578125          |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5084386167742196     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 268.60. Rollout time: 70.04, Training time: 198.53
Evaluating epoch 6
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 6                       |
| policy/steps              | 196875.0                |
| test/episodes             | 175.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -2.7020855211961685e-08 |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 700.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.49045068821823       |
| train_0/fw_bonus          | -0.9985166549682617     |
| train_0/fw_loss           | 0.008428549987729638    |
| train_0/mu_grads          | -0.02199702481739223    |
| train_0/mu_grads_std      | 0.2814356401562691      |
| train_0/mu_loss           | 5.428052432320472       |
| train_0/next_q            | -5.423396261732506      |
| train_0/q_grads           | 0.010984502732753754    |
| train_0/q_grads_std       | 0.17325204983353615     |
| train_0/q_loss            | 0.22190685798169668     |
| train_0/reward            | -0.7092803053332318     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00908203125           |
| train_0/target_q          | -5.724805758571689      |
| train_1/avg_q             | -7.14567074777206e-08   |
| train_1/current_q         | -1.314549962581636e-07  |
| train_1/fw_bonus          | -0.9936189264059067     |
| train_1/fw_loss           | 0.05166128892451525     |
| train_1/mu_grads          | -0.01581735722720623    |
| train_1/mu_grads_std      | 0.29260489344596863     |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -1.577783712943998e-24  |
| train_1/q_grads           | -0.009841154841706157   |
| train_1/q_grads_std       | 0.16131545044481754     |
| train_1/q_loss            | 6.728402761650193       |
| train_1/reward            | -1.5318314376432682     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0025390625            |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5318314376432682     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 254.99. Rollout time: 68.05, Training time: 186.91
Evaluating epoch 7
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 225000.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -3.595136326110351e-08 |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.455914246428563     |
| train_0/fw_bonus          | -0.9987107366323471    |
| train_0/fw_loss           | 0.007485853030811995   |
| train_0/mu_grads          | -0.02115902677178383   |
| train_0/mu_grads_std      | 0.29200202971696854    |
| train_0/mu_loss           | 5.3888481621736375     |
| train_0/next_q            | -5.385551889139716     |
| train_0/q_grads           | 0.0079903180943802     |
| train_0/q_grads_std       | 0.18051531948149205    |
| train_0/q_loss            | 0.21503218469721058    |
| train_0/reward            | -0.7069725571607706    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0083984375           |
| train_0/target_q          | -5.689871817722894     |
| train_1/avg_q             | -7.858396645144449e-08 |
| train_1/current_q         | -3.385231868802638e-07 |
| train_1/fw_bonus          | -0.9948533564805985    |
| train_1/fw_loss           | 0.04562495667487383    |
| train_1/mu_grads          | -0.01581735722720623   |
| train_1/mu_grads_std      | 0.29260489344596863    |
| train_1/mu_loss           | 1.0                    |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -5.593624980322368e-24 |
| train_1/q_grads           | -0.009910895861685276  |
| train_1/q_grads_std       | 0.16128135547041894    |
| train_1/q_loss            | 6.8063857470862414     |
| train_1/reward            | -1.537929613644519     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020751953125        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.537929613644519     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 254.94. Rollout time: 71.86, Training time: 183.05
Evaluating epoch 8
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 253125.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.999999999995687   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.423760572184686    |
| train_0/fw_bonus          | -0.998824904859066    |
| train_0/fw_loss           | 0.00693130730651319   |
| train_0/mu_grads          | -0.02120681283995509  |
| train_0/mu_grads_std      | 0.3022693946957588    |
| train_0/mu_loss           | 5.356676832617028     |
| train_0/next_q            | -5.353745524377944    |
| train_0/q_grads           | 0.0060346178011968735 |
| train_0/q_grads_std       | 0.18844777829945086   |
| train_0/q_loss            | 0.20992330579242938   |
| train_0/reward            | -0.7049056156749429   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004736328125        |
| train_0/target_q          | -5.657036611756831    |
| train_1/avg_q             | -7.83225645927799     |
| train_1/current_q         | -11.09456669441803    |
| train_1/fw_bonus          | -0.9953349605202675   |
| train_1/fw_loss           | 0.043269979674369095  |
| train_1/mu_grads          | -0.005974332801997662 |
| train_1/mu_grads_std      | 0.3108692765235901    |
| train_1/mu_loss           | 16.0                  |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.019982831878587605 |
| train_1/q_grads_std       | 0.20764229595661163   |
| train_1/q_loss            | 7.02183606270106      |
| train_1/reward            | -1.5194570324856613   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0026611328125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.979710938735666   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 240.42. Rollout time: 67.72, Training time: 172.68
Evaluating epoch 9
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 281250.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -15.0                 |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4043041719385645   |
| train_0/fw_bonus          | -0.9989113703370094   |
| train_0/fw_loss           | 0.006511304574087262  |
| train_0/mu_grads          | -0.022123672254383563 |
| train_0/mu_grads_std      | 0.311699964851141     |
| train_0/mu_loss           | 5.340062765891105     |
| train_0/next_q            | -5.33678501818792     |
| train_0/q_grads           | 0.0034773638937622307 |
| train_0/q_grads_std       | 0.1964170392602682    |
| train_0/q_loss            | 0.2073789653958295    |
| train_0/reward            | -0.7024097863293719   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0035888671875       |
| train_0/target_q          | -5.6351089609933025   |
| train_1/avg_q             | -14.999999999193705   |
| train_1/current_q         | -11.107622181507372   |
| train_1/fw_bonus          | -0.9955504789948464   |
| train_1/fw_loss           | 0.04221615232527256   |
| train_1/mu_grads          | -0.005974354222416878 |
| train_1/mu_grads_std      | 0.3108692765235901    |
| train_1/mu_loss           | 16.0                  |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.02051134961657226  |
| train_1/q_grads_std       | 0.22485704980790616   |
| train_1/q_loss            | 5.728504275551323     |
| train_1/reward            | -1.501705900905654    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0026611328125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.045221525905658   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 247.46. Rollout time: 68.48, Training time: 178.96
Evaluating epoch 10
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 309375.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -7.016924913617049e-10 |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.504451855326076     |
| train_0/fw_bonus          | -0.9990148231387138    |
| train_0/fw_loss           | 0.006008817162364721   |
| train_0/mu_grads          | -0.022787920106202363  |
| train_0/mu_grads_std      | 0.3216749779880047     |
| train_0/mu_loss           | 5.4373037290380015     |
| train_0/next_q            | -5.434880898681525     |
| train_0/q_grads           | 0.0013973162276670337  |
| train_0/q_grads_std       | 0.20474707148969173    |
| train_0/q_loss            | 0.20776626262694647    |
| train_0/reward            | -0.7070879747589061    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0036865234375        |
| train_0/target_q          | -5.739653597465965     |
| train_1/avg_q             | -8.112760398310252     |
| train_1/current_q         | -3.111261900646515e-09 |
| train_1/fw_bonus          | -0.9955260649323463    |
| train_1/fw_loss           | 0.04233543379232287    |
| train_1/mu_grads          | -0.008799148723483086  |
| train_1/mu_grads_std      | 0.3170851469039917     |
| train_1/mu_loss           | 1.0                    |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.023026060312986374  |
| train_1/q_grads_std       | 0.2286742925643921     |
| train_1/q_loss            | 6.576486578156252      |
| train_1/reward            | -1.5079192907702237    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0029541015625        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5079192907702237    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 250.59. Rollout time: 69.32, Training time: 181.25
Evaluating epoch 11
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 11                      |
| policy/steps              | 337500.0                |
| test/episodes             | 300.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -5.116381706012255e-08  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.459949159083086      |
| train_0/fw_bonus          | -0.9991252765059471     |
| train_0/fw_loss           | 0.005472302634734661    |
| train_0/mu_grads          | -0.02397293415851891    |
| train_0/mu_grads_std      | 0.32882980853319166     |
| train_0/mu_loss           | 5.3930703569748015      |
| train_0/next_q            | -5.392126487861814      |
| train_0/q_grads           | 0.0006992041147896088   |
| train_0/q_grads_std       | 0.21329395584762095     |
| train_0/q_loss            | 0.2059434468925045      |
| train_0/reward            | -0.705507458926877      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.003271484375          |
| train_0/target_q          | -5.692864529814626      |
| train_1/avg_q             | -3.9582562596461e-09    |
| train_1/current_q         | -3.5589809849188083e-09 |
| train_1/fw_bonus          | -0.9958176538348198     |
| train_1/fw_loss           | 0.0409096241928637      |
| train_1/mu_grads          | -0.008799148723483086   |
| train_1/mu_grads_std      | 0.3170851469039917      |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.023026134818792343   |
| train_1/q_grads_std       | 0.2286742776632309      |
| train_1/q_loss            | 6.501719986752297       |
| train_1/reward            | -1.5027794359899418     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002685546875          |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5027794359899418     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 241.18. Rollout time: 68.87, Training time: 172.28
Evaluating epoch 12
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 12                      |
| policy/steps              | 365625.0                |
| test/episodes             | 325.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -5.477914575077453e-10  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.477294140926433      |
| train_0/fw_bonus          | -0.9991422310471535     |
| train_0/fw_loss           | 0.0053899131249636415   |
| train_0/mu_grads          | -0.025106959184631704   |
| train_0/mu_grads_std      | 0.3346632823348045      |
| train_0/mu_loss           | 5.410943729145662       |
| train_0/next_q            | -5.4086553872738765     |
| train_0/q_grads           | -0.0015509626682614908  |
| train_0/q_grads_std       | 0.2223719522356987      |
| train_0/q_loss            | 0.20796423531145153     |
| train_0/reward            | -0.7069197484379401     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0047119140625         |
| train_0/target_q          | -5.712400202784823      |
| train_1/avg_q             | -1.0772569401156173e-08 |
| train_1/current_q         | -1.7485285782351062e-09 |
| train_1/fw_bonus          | -0.9961433127522469     |
| train_1/fw_loss           | 0.03931723004207015     |
| train_1/mu_grads          | -0.008799148723483086   |
| train_1/mu_grads_std      | 0.3170851469039917      |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.023026584275066854   |
| train_1/q_grads_std       | 0.22867418825626373     |
| train_1/q_loss            | 6.626362197246214       |
| train_1/reward            | -1.517444212602277      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002490234375          |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.517444212602277      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 258.19. Rollout time: 72.60, Training time: 185.57
Evaluating epoch 13
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 13                      |
| policy/steps              | 393750.0                |
| test/episodes             | 350.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -5.674539397669068e-08  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.408656586267906      |
| train_0/fw_bonus          | -0.9991558134555817     |
| train_0/fw_loss           | 0.005323933984618634    |
| train_0/mu_grads          | -0.02501192898489535    |
| train_0/mu_grads_std      | 0.34028337374329565     |
| train_0/mu_loss           | 5.335117723232927       |
| train_0/next_q            | -5.3334812082485925     |
| train_0/q_grads           | -0.00368846669443883    |
| train_0/q_grads_std       | 0.23065066263079642     |
| train_0/q_loss            | 0.20114464728851478     |
| train_0/reward            | -0.7061941181062139     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.004296875             |
| train_0/target_q          | -5.64012402217106       |
| train_1/avg_q             | -1.5514199060781162e-08 |
| train_1/current_q         | -1.9039866005732427e-09 |
| train_1/fw_bonus          | -0.9965199008584023     |
| train_1/fw_loss           | 0.03747571054846048     |
| train_1/mu_grads          | -0.008799148723483086   |
| train_1/mu_grads_std      | 0.3170851469039917      |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.023028777912259102   |
| train_1/q_grads_std       | 0.2286734402179718      |
| train_1/q_loss            | 6.523082618470205       |
| train_1/reward            | -1.5106989155312476     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00234375              |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5106989155312476     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 246.25. Rollout time: 70.68, Training time: 175.55
Evaluating epoch 14
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
--------------------------------------------------------
| epoch                     | 14                       |
| policy/steps              | 421875.0                 |
| test/episodes             | 375.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -15.0                    |
| test_1/avg_q              | -3.13710091686962e-08    |
| test_1/n_subgoals         | 375.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 1500.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -15.0                    |
| train_0/current_q         | -5.458476756866852       |
| train_0/fw_bonus          | -0.9991019994020462      |
| train_0/fw_loss           | 0.005585299979429692     |
| train_0/mu_grads          | -0.024672300927340983    |
| train_0/mu_grads_std      | 0.34632319435477255      |
| train_0/mu_loss           | 5.389972056385277        |
| train_0/next_q            | -5.38679740994065        |
| train_0/q_grads           | -0.004835519182961434    |
| train_0/q_grads_std       | 0.2387784618884325       |
| train_0/q_loss            | 0.20709779708902443      |
| train_0/reward            | -0.7086574488894257      |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.004638671875           |
| train_0/target_q          | -5.693573935285654       |
| train_1/avg_q             | -3.419276997586922e-08   |
| train_1/current_q         | -3.0371027083425497e-09  |
| train_1/fw_bonus          | -0.9968130558729171      |
| train_1/fw_loss           | 0.036042194627225396     |
| train_1/mu_grads          | -0.008799148723483086    |
| train_1/mu_grads_std      | 0.3170851469039917       |
| train_1/mu_loss           | 1.0                      |
| train_1/n_subgoals        | 1500.0                   |
| train_1/next_q            | -1.5273011443590046e-307 |
| train_1/q_grads           | -0.023039271775633096    |
| train_1/q_grads_std       | 0.22866948023438455      |
| train_1/q_loss            | 6.69965369754739         |
| train_1/reward            | -1.5335993989705456      |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.002294921875           |
| train_1/reward_-15.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -1.5335993989705456      |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 253.27. Rollout time: 71.07, Training time: 182.17
Evaluating epoch 15
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-------------------------------------------------------
| epoch                     | 15                      |
| policy/steps              | 450000.0                |
| test/episodes             | 400.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -2.8611548600869155e-09 |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.392297463329231      |
| train_0/fw_bonus          | -0.99908557087183       |
| train_0/fw_loss           | 0.005665134266018867    |
| train_0/mu_grads          | -0.024597620591521263   |
| train_0/mu_grads_std      | 0.3529396913945675      |
| train_0/mu_loss           | 5.317849504712803       |
| train_0/next_q            | -5.315633465349552      |
| train_0/q_grads           | -0.006101694446988404   |
| train_0/q_grads_std       | 0.24614759013056756     |
| train_0/q_loss            | 0.2029599049721722      |
| train_0/reward            | -0.7059270629710227     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00400390625           |
| train_0/target_q          | -5.621091820217535      |
| train_1/avg_q             | -3.130482640759935e-08  |
| train_1/current_q         | -3.1674449008141454e-09 |
| train_1/fw_bonus          | -0.9965298876166344     |
| train_1/fw_loss           | 0.037426866963505744    |
| train_1/mu_grads          | -0.008799148723483086   |
| train_1/mu_grads_std      | 0.3170851469039917      |
| train_1/mu_loss           | 1.0                     |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -7.467815346610974e-307 |
| train_1/q_grads           | -0.02307718200609088    |
| train_1/q_grads_std       | 0.22865670099854468     |
| train_1/q_loss            | 6.534515019296288       |
| train_1/reward            | -1.51616045223127       |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001904296875          |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.51616045223127       |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 253.07. Rollout time: 69.84, Training time: 183.20
Evaluating epoch 16
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 478125.0              |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -0.11259525421687158  |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.440483917965816    |
| train_0/fw_bonus          | -0.9990808457136154   |
| train_0/fw_loss           | 0.005688104312866926  |
| train_0/mu_grads          | -0.025039993599057196 |
| train_0/mu_grads_std      | 0.35965005308389664   |
| train_0/mu_loss           | 5.37561175795304      |
| train_0/next_q            | -5.37423411445271     |
| train_0/q_grads           | -0.00765080654527992  |
| train_0/q_grads_std       | 0.2539165556430817    |
| train_0/q_loss            | 0.20489200601045932   |
| train_0/reward            | -0.7037762608466437   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046142578125       |
| train_0/target_q          | -5.67420245995995     |
| train_1/avg_q             | -1.9118327769367962   |
| train_1/current_q         | -0.09101487605124599  |
| train_1/fw_bonus          | -0.9965931490063668   |
| train_1/fw_loss           | 0.0371174942702055    |
| train_1/mu_grads          | -0.013297127187252044 |
| train_1/mu_grads_std      | 0.3331820383667946    |
| train_1/mu_loss           | 1.1098878980165907    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -0.1093426377995963   |
| train_1/q_grads           | -0.03224425697699189  |
| train_1/q_grads_std       | 0.23819337859749795   |
| train_1/q_loss            | 6.3561574263221114    |
| train_1/reward            | -1.5057794888285572   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0023193359375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.576123484197397    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 239.77. Rollout time: 68.77, Training time: 170.98
Evaluating epoch 17
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 506250.0              |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -1.7149524598024068   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.405920231432124    |
| train_0/fw_bonus          | -0.999079579114914    |
| train_0/fw_loss           | 0.00569421115797013   |
| train_0/mu_grads          | -0.024827551981434225 |
| train_0/mu_grads_std      | 0.3642249725759029    |
| train_0/mu_loss           | 5.336901880288529     |
| train_0/next_q            | -5.334742648140744    |
| train_0/q_grads           | -0.009162889560684562 |
| train_0/q_grads_std       | 0.26025294661521914   |
| train_0/q_loss            | 0.2031216034179113    |
| train_0/reward            | -0.704337155988469    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044921875          |
| train_0/target_q          | -5.634968260908957    |
| train_1/avg_q             | -0.3293607676049868   |
| train_1/current_q         | -1.666537513586753    |
| train_1/fw_bonus          | -0.9968915566802025   |
| train_1/fw_loss           | 0.035658312821760775  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 2.668888799340121     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -1.666537513586753    |
| train_1/q_grads           | -0.031682382617145774 |
| train_1/q_grads_std       | 0.24110027104616166   |
| train_1/q_loss            | 4.622299614793214     |
| train_1/reward            | -1.511104471662111    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020263671875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.5796033188224476   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 253.58. Rollout time: 71.93, Training time: 181.61
Evaluating epoch 18
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 534375.0              |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.130290464363339    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.443403266819615    |
| train_0/fw_bonus          | -0.999116051197052    |
| train_0/fw_loss           | 0.005517066293396056  |
| train_0/mu_grads          | -0.02422419497743249  |
| train_0/mu_grads_std      | 0.36873130053281783   |
| train_0/mu_loss           | 5.376187936661941     |
| train_0/next_q            | -5.374580577693813    |
| train_0/q_grads           | -0.011539488518610596 |
| train_0/q_grads_std       | 0.2672841474413872    |
| train_0/q_loss            | 0.19929475907132482   |
| train_0/reward            | -0.7045507026770792   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046875             |
| train_0/target_q          | -5.677916327187676    |
| train_1/avg_q             | -3.0449765165373703   |
| train_1/current_q         | -4.130139669217293    |
| train_1/fw_bonus          | -0.9964028701186181   |
| train_1/fw_loss           | 0.03804796505719423   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.1301748810479335    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.130139669217293    |
| train_1/q_grads           | -0.031579583790153264 |
| train_1/q_grads_std       | 0.24276370778679848   |
| train_1/q_loss            | 5.3231296506808805    |
| train_1/reward            | -1.502327413353487    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021728515625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.133126810998953    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 242.53. Rollout time: 67.47, Training time: 175.03
Evaluating epoch 19
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 562500.0              |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.201352190652714    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.459784711864623    |
| train_0/fw_bonus          | -0.9992295041680336   |
| train_0/fw_loss           | 0.004965875286143273  |
| train_0/mu_grads          | -0.0227063397411257   |
| train_0/mu_grads_std      | 0.37242078483104707   |
| train_0/mu_loss           | 5.391579607070402     |
| train_0/next_q            | -5.390105577501993    |
| train_0/q_grads           | -0.013241217681206762 |
| train_0/q_grads_std       | 0.27451635524630547   |
| train_0/q_loss            | 0.2003390679152674    |
| train_0/reward            | -0.7042412286944455   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004638671875        |
| train_0/target_q          | -5.694815513752052    |
| train_1/avg_q             | -4.17697356085337     |
| train_1/current_q         | -4.192947242818219    |
| train_1/fw_bonus          | -0.996524466574192    |
| train_1/fw_loss           | 0.03745338479056955   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.193264350426731     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.192947242818219    |
| train_1/q_grads           | -0.03157765241339803  |
| train_1/q_grads_std       | 0.24279935024678706   |
| train_1/q_loss            | 5.374893292701345     |
| train_1/reward            | -1.5270097922701098   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.206048365447091    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 245.50. Rollout time: 69.82, Training time: 175.65
Evaluating epoch 20
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 590625.0              |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.175706761640796    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.419317581148699    |
| train_0/fw_bonus          | -0.9992775321006775   |
| train_0/fw_loss           | 0.004732753697317094  |
| train_0/mu_grads          | -0.022328566946089267 |
| train_0/mu_grads_std      | 0.3760326825082302    |
| train_0/mu_loss           | 5.3518231131709655    |
| train_0/next_q            | -5.349046655416143    |
| train_0/q_grads           | -0.015131829073652625 |
| train_0/q_grads_std       | 0.2812210276722908    |
| train_0/q_loss            | 0.1982907748093285    |
| train_0/reward            | -0.7031055572799232   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050048828125       |
| train_0/target_q          | -5.651958319588873    |
| train_1/avg_q             | -4.17236539183265     |
| train_1/current_q         | -4.175328428773483    |
| train_1/fw_bonus          | -0.9966153025627136   |
| train_1/fw_loss           | 0.037009202595800164  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.175361724275497     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.175328428773483    |
| train_1/q_grads           | -0.03157819239422679  |
| train_1/q_grads_std       | 0.24278936982154847   |
| train_1/q_loss            | 5.38675198571639      |
| train_1/reward            | -1.5267256198414543   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.184303697279456    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 245.51. Rollout time: 69.29, Training time: 176.19
Evaluating epoch 21
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 618750.0              |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.3568167271004725   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.459682038184246    |
| train_0/fw_bonus          | -0.9993093937635422   |
| train_0/fw_loss           | 0.004577958688605577  |
| train_0/mu_grads          | -0.022250436572358014 |
| train_0/mu_grads_std      | 0.3812191255390644    |
| train_0/mu_loss           | 5.387895520694586     |
| train_0/next_q            | -5.385462818202205    |
| train_0/q_grads           | -0.01627553887665272  |
| train_0/q_grads_std       | 0.2864466071128845    |
| train_0/q_loss            | 0.19774382653361752   |
| train_0/reward            | -0.7066249093055376   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00537109375         |
| train_0/target_q          | -5.695463174834848    |
| train_1/avg_q             | -4.289009605246932    |
| train_1/current_q         | -4.370469058727666    |
| train_1/fw_bonus          | -0.9967081159353256   |
| train_1/fw_loss           | 0.03655537981539965   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.369985704862823     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.370469058727666    |
| train_1/q_grads           | -0.031572287902235985 |
| train_1/q_grads_std       | 0.24289921671152115   |
| train_1/q_loss            | 5.4499283205629805    |
| train_1/reward            | -1.5222188006729993   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.3575400610446      |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 241.94. Rollout time: 69.86, Training time: 172.05
Evaluating epoch 22
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 646875.0              |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.2683067506297965   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.47339435674741     |
| train_0/fw_bonus          | -0.9993482559919358   |
| train_0/fw_loss           | 0.004389111476484686  |
| train_0/mu_grads          | -0.02284757876768708  |
| train_0/mu_grads_std      | 0.3850104659795761    |
| train_0/mu_loss           | 5.402577594304587     |
| train_0/next_q            | -5.401851337247837    |
| train_0/q_grads           | -0.017253348138183355 |
| train_0/q_grads_std       | 0.2913393408060074    |
| train_0/q_loss            | 0.19885995286073482   |
| train_0/reward            | -0.7046790161504759   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0052978515625       |
| train_0/target_q          | -5.707869086569787    |
| train_1/avg_q             | -4.313419999439341    |
| train_1/current_q         | -4.275792680840313    |
| train_1/fw_bonus          | -0.9972168371081352   |
| train_1/fw_loss           | 0.03406776823103428   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.275416489683635     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.275792680840313    |
| train_1/q_grads           | -0.031616339832544325 |
| train_1/q_grads_std       | 0.2428862564265728    |
| train_1/q_loss            | 5.387378165472176     |
| train_1/reward            | -1.5078735512091952   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.266858774021831    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 241.73. Rollout time: 70.05, Training time: 171.65
Evaluating epoch 23
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 675000.0              |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.269754300160615    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4018569309955655   |
| train_0/fw_bonus          | -0.9993946895003318   |
| train_0/fw_loss           | 0.004163674934534356  |
| train_0/mu_grads          | -0.02458214610815048  |
| train_0/mu_grads_std      | 0.3878068171441555    |
| train_0/mu_loss           | 5.33388154240146      |
| train_0/next_q            | -5.3315955451433      |
| train_0/q_grads           | -0.018416491476818918 |
| train_0/q_grads_std       | 0.29610375836491587   |
| train_0/q_loss            | 0.19675634688682936   |
| train_0/reward            | -0.7026026122512121   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005078125           |
| train_0/target_q          | -5.633046455015946    |
| train_1/avg_q             | -4.26543136905218     |
| train_1/current_q         | -4.271472817438474    |
| train_1/fw_bonus          | -0.9973373383283615   |
| train_1/fw_loss           | 0.03347848011180758   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.2713777230994765    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.271472817438474    |
| train_1/q_grads           | -0.0316164705902338   |
| train_1/q_grads_std       | 0.2428838260471821    |
| train_1/q_loss            | 5.43281847200654      |
| train_1/reward            | -1.5272331229665723   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.267163016552763    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 241.79. Rollout time: 71.20, Training time: 170.56
Evaluating epoch 24
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 703125.0              |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.285685156761077    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.46229452838139     |
| train_0/fw_bonus          | -0.999338085949421    |
| train_0/fw_loss           | 0.004438557371031493  |
| train_0/mu_grads          | -0.02675101449713111  |
| train_0/mu_grads_std      | 0.3902514107525349    |
| train_0/mu_loss           | 5.393143976400952     |
| train_0/next_q            | -5.391386711971804    |
| train_0/q_grads           | -0.01909666880965233  |
| train_0/q_grads_std       | 0.3008215256035328    |
| train_0/q_loss            | 0.2035952325796706    |
| train_0/reward            | -0.7057969734574726   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.697189081154933    |
| train_1/avg_q             | -4.255080156368361    |
| train_1/current_q         | -4.2929109166614605   |
| train_1/fw_bonus          | -0.99674441665411     |
| train_1/fw_loss           | 0.03637782046571374   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.292913653577299     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.2929109166614605   |
| train_1/q_grads           | -0.031615822296589616 |
| train_1/q_grads_std       | 0.24289588294923306   |
| train_1/q_loss            | 5.456530062754444     |
| train_1/reward            | -1.5308062933836482   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.284691036783632    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 245.73. Rollout time: 70.31, Training time: 175.40
Evaluating epoch 25
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 731250.0              |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.270284462652662    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.446484413427259    |
| train_0/fw_bonus          | -0.999352103471756    |
| train_0/fw_loss           | 0.0043704763695131986 |
| train_0/mu_grads          | -0.029709585662931203 |
| train_0/mu_grads_std      | 0.3959907107055187    |
| train_0/mu_loss           | 5.369945220033998     |
| train_0/next_q            | -5.36920317201681     |
| train_0/q_grads           | -0.019972959207370876 |
| train_0/q_grads_std       | 0.30581955462694166   |
| train_0/q_loss            | 0.2062543920528091    |
| train_0/reward            | -0.7073054460168351   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0037841796875       |
| train_0/target_q          | -5.679373836124064    |
| train_1/avg_q             | -4.3281361429313385   |
| train_1/current_q         | -4.2658566881597535   |
| train_1/fw_bonus          | -0.9962405085563659   |
| train_1/fw_loss           | 0.038841931615024805  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.2660364074172765    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.2658566881597535   |
| train_1/q_grads           | -0.03161664018407464  |
| train_1/q_grads_std       | 0.24288066290318966   |
| train_1/q_loss            | 5.389329391341913     |
| train_1/reward            | -1.5185548230780115   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.266528156489318    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 234.95. Rollout time: 69.29, Training time: 165.64
Evaluating epoch 26
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 759375.0              |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.089225512660491    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.421349463949336    |
| train_0/fw_bonus          | -0.9993768036365509   |
| train_0/fw_loss           | 0.004250457580201328  |
| train_0/mu_grads          | -0.031173564167693256 |
| train_0/mu_grads_std      | 0.40085165575146675   |
| train_0/mu_loss           | 5.353670132317834     |
| train_0/next_q            | -5.350840698659115    |
| train_0/q_grads           | -0.02090057162567973  |
| train_0/q_grads_std       | 0.3116611659526825    |
| train_0/q_loss            | 0.20050758862073942   |
| train_0/reward            | -0.7039974878338399   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0036865234375       |
| train_0/target_q          | -5.655123275789839    |
| train_1/avg_q             | -4.1772066817330185   |
| train_1/current_q         | -4.073242697433062    |
| train_1/fw_bonus          | -0.9960264131426811   |
| train_1/fw_loss           | 0.03988881502300501   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.073981242973979     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.073242697433062    |
| train_1/q_grads           | -0.031622556038200855 |
| train_1/q_grads_std       | 0.24277142770588397   |
| train_1/q_loss            | 5.350623094473119     |
| train_1/reward            | -1.523794458739576    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.090946434953599    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 248.60. Rollout time: 70.73, Training time: 177.84
Evaluating epoch 27
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 787500.0              |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9638762239133456   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.481608714257407    |
| train_0/fw_bonus          | -0.999383382499218    |
| train_0/fw_loss           | 0.004218533268431202  |
| train_0/mu_grads          | -0.03179967887699604  |
| train_0/mu_grads_std      | 0.40424219369888303   |
| train_0/mu_loss           | 5.409927911027903     |
| train_0/next_q            | -5.408244551848108    |
| train_0/q_grads           | -0.023083579959347844 |
| train_0/q_grads_std       | 0.3163877263665199    |
| train_0/q_loss            | 0.2024376161353844    |
| train_0/reward            | -0.7068450122977084   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047607421875       |
| train_0/target_q          | -5.717122437191004    |
| train_1/avg_q             | -4.0048471509683194   |
| train_1/current_q         | -3.9682684861058704   |
| train_1/fw_bonus          | -0.9961117044091224   |
| train_1/fw_loss           | 0.039471714198589324  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.968237888945917     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9682684861058704   |
| train_1/q_grads           | -0.03162585366517305  |
| train_1/q_grads_std       | 0.24271119385957718   |
| train_1/q_loss            | 5.275503233632375     |
| train_1/reward            | -1.4877409161614197   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019775390625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9686162921288597   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 239.56. Rollout time: 67.90, Training time: 171.64
Evaluating epoch 28
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 815625.0              |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9101124027517296   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.442134982551975    |
| train_0/fw_bonus          | -0.99938053637743     |
| train_0/fw_loss           | 0.004232374823186546  |
| train_0/mu_grads          | -0.03394856434315443  |
| train_0/mu_grads_std      | 0.4076908819377422    |
| train_0/mu_loss           | 5.370387738707147     |
| train_0/next_q            | -5.36889827857348     |
| train_0/q_grads           | -0.024767753295600416 |
| train_0/q_grads_std       | 0.3224691316485405    |
| train_0/q_loss            | 0.2009318032717296    |
| train_0/reward            | -0.7049637045070994   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0040771484375       |
| train_0/target_q          | -5.675164827335996    |
| train_1/avg_q             | -3.949791698442265    |
| train_1/current_q         | -3.906017225657785    |
| train_1/fw_bonus          | -0.9958861500024796   |
| train_1/fw_loss           | 0.040574679151177406  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.9061904678942145    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.906017225657785    |
| train_1/q_grads           | -0.03162783561274409  |
| train_1/q_grads_std       | 0.2426752161234617    |
| train_1/q_loss            | 5.251070422072891     |
| train_1/reward            | -1.4843566526345966   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001806640625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.909690573682113    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 247.43. Rollout time: 71.39, Training time: 176.01
Evaluating epoch 29
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 843750.0              |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8274709959770727   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.360407080821662    |
| train_0/fw_bonus          | -0.9993883401155472   |
| train_0/fw_loss           | 0.004194459650898352  |
| train_0/mu_grads          | -0.03462613765150309  |
| train_0/mu_grads_std      | 0.4127333924174309    |
| train_0/mu_loss           | 5.297121561338774     |
| train_0/next_q            | -5.295285598526748    |
| train_0/q_grads           | -0.02576224678196013  |
| train_0/q_grads_std       | 0.3277279257774353    |
| train_0/q_loss            | 0.20019008401037888   |
| train_0/reward            | -0.7006463182275183   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00419921875         |
| train_0/target_q          | -5.58917865682456     |
| train_1/avg_q             | -3.8675197096569223   |
| train_1/current_q         | -3.8318819498027046   |
| train_1/fw_bonus          | -0.9955855831503868   |
| train_1/fw_loss           | 0.04204445872455835   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.8316632647946545    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8318819498027046   |
| train_1/q_grads           | -0.03163022277876735  |
| train_1/q_grads_std       | 0.2426321055740118    |
| train_1/q_loss            | 5.327111513605771     |
| train_1/reward            | -1.5058738471590913   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.836121218973311    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 243.14. Rollout time: 68.69, Training time: 174.42
Evaluating epoch 30
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 30                    |
| policy/steps              | 871875.0              |
| test/episodes             | 775.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.911240091013284    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4616117792322125   |
| train_0/fw_bonus          | -0.9994219481945038   |
| train_0/fw_loss           | 0.004031241912161932  |
| train_0/mu_grads          | -0.03438525041565299  |
| train_0/mu_grads_std      | 0.41707637831568717   |
| train_0/mu_loss           | 5.387715100883733     |
| train_0/next_q            | -5.385157860734493    |
| train_0/q_grads           | -0.026958621013909577 |
| train_0/q_grads_std       | 0.3328331135213375    |
| train_0/q_loss            | 0.20104081834777315   |
| train_0/reward            | -0.7064248380207573   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0040283203125       |
| train_0/target_q          | -5.696646013001486    |
| train_1/avg_q             | -3.835885405280341    |
| train_1/current_q         | -3.8999016837137455   |
| train_1/fw_bonus          | -0.9959049880504608   |
| train_1/fw_loss           | 0.040482604410499334  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.899953549171834     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8999016837137455   |
| train_1/q_grads           | -0.03162803174927831  |
| train_1/q_grads_std       | 0.24267166927456857   |
| train_1/q_loss            | 5.2184796557168855    |
| train_1/reward            | -1.4823641143993882   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9124017563706275   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 246.30. Rollout time: 71.70, Training time: 174.57
Evaluating epoch 31
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 900000.0              |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.178842669075482    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.456382331737247    |
| train_0/fw_bonus          | -0.999440298974514    |
| train_0/fw_loss           | 0.003942088392795995  |
| train_0/mu_grads          | -0.035904651321470735 |
| train_0/mu_grads_std      | 0.42075334414839743   |
| train_0/mu_loss           | 5.381209188273185     |
| train_0/next_q            | -5.380320119821047    |
| train_0/q_grads           | -0.028330713463947176 |
| train_0/q_grads_std       | 0.33787874281406405   |
| train_0/q_loss            | 0.20399239136400044   |
| train_0/reward            | -0.7086068666038046   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00439453125         |
| train_0/target_q          | -5.689866622584498    |
| train_1/avg_q             | -4.025273886442709    |
| train_1/current_q         | -4.190063411285865    |
| train_1/fw_bonus          | -0.9971825495362282   |
| train_1/fw_loss           | 0.03423537788912654   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.189790498752759     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.190063411285865    |
| train_1/q_grads           | -0.03161894865334034  |
| train_1/q_grads_std       | 0.2428378690034151    |
| train_1/q_loss            | 5.393420339427655     |
| train_1/reward            | -1.508271452293411    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.1777511646823715   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 245.31. Rollout time: 70.10, Training time: 175.18
Evaluating epoch 32
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 928125.0              |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.41300492310865     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.459899209468286    |
| train_0/fw_bonus          | -0.9994878381490707   |
| train_0/fw_loss           | 0.003711186960572377  |
| train_0/mu_grads          | -0.03600926212966442  |
| train_0/mu_grads_std      | 0.42410495281219485   |
| train_0/mu_loss           | 5.385152176793914     |
| train_0/next_q            | -5.38356544970969     |
| train_0/q_grads           | -0.02925844080746174  |
| train_0/q_grads_std       | 0.34315130636096003   |
| train_0/q_loss            | 0.20469999253853302   |
| train_0/reward            | -0.7093996774165134   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0036865234375       |
| train_0/target_q          | -5.694663259593012    |
| train_1/avg_q             | -4.283411040321901    |
| train_1/current_q         | -4.404597474768858    |
| train_1/fw_bonus          | -0.9974278643727302   |
| train_1/fw_loss           | 0.033035841025412085  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.404956626392486     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.404597474768858    |
| train_1/q_grads           | -0.03161247903481126  |
| train_1/q_grads_std       | 0.24295841120183467   |
| train_1/q_loss            | 5.322413125497004     |
| train_1/reward            | -1.509407290060335    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.419133257990341    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 240.44. Rollout time: 70.87, Training time: 169.54
Evaluating epoch 33
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 956250.0              |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.504835798866082    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4988997742016155   |
| train_0/fw_bonus          | -0.9995606034994126   |
| train_0/fw_loss           | 0.0033577538328245283 |
| train_0/mu_grads          | -0.03802373325452209  |
| train_0/mu_grads_std      | 0.4276966542005539    |
| train_0/mu_loss           | 5.413511347471696     |
| train_0/next_q            | -5.413001729032759    |
| train_0/q_grads           | -0.02992870509624481  |
| train_0/q_grads_std       | 0.34763193055987357   |
| train_0/q_loss            | 0.2086542560288282    |
| train_0/reward            | -0.7136718979367288   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004833984375        |
| train_0/target_q          | -5.732805005139602    |
| train_1/avg_q             | -4.454016461276289    |
| train_1/current_q         | -4.518306627029618    |
| train_1/fw_bonus          | -0.997939744591713    |
| train_1/fw_loss           | 0.030532695166766644  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.517864451311531     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.518306627029618    |
| train_1/q_grads           | -0.03160912534222007  |
| train_1/q_grads_std       | 0.24302161261439323   |
| train_1/q_loss            | 5.372531956904041     |
| train_1/reward            | -1.4977613824026776   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.510184669756259    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 251.56. Rollout time: 71.80, Training time: 179.73
Evaluating epoch 34
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 984375.0              |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.518818151266006    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.458840302532609    |
| train_0/fw_bonus          | -0.999560035765171    |
| train_0/fw_loss           | 0.003360456775408238  |
| train_0/mu_grads          | -0.03930565183982253  |
| train_0/mu_grads_std      | 0.4309700205922127    |
| train_0/mu_loss           | 5.3754410119774745    |
| train_0/next_q            | -5.373283419598596    |
| train_0/q_grads           | -0.03046693350188434  |
| train_0/q_grads_std       | 0.35233441963791845   |
| train_0/q_loss            | 0.20387332719382475   |
| train_0/reward            | -0.7114011120422219   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00498046875         |
| train_0/target_q          | -5.692526614514039    |
| train_1/avg_q             | -4.550979675451421    |
| train_1/current_q         | -4.515843921898595    |
| train_1/fw_bonus          | -0.9981906667351723   |
| train_1/fw_loss           | 0.029305791668593883  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.515752095805259     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.515843921898595    |
| train_1/q_grads           | -0.03160919742658734  |
| train_1/q_grads_std       | 0.24302024841308595   |
| train_1/q_loss            | 5.421865685297296     |
| train_1/reward            | -1.5213731625000946   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.513127272310145    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 239.19. Rollout time: 68.66, Training time: 170.50
Evaluating epoch 35
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 1012500.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.310562136179301    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.473800113217165    |
| train_0/fw_bonus          | -0.999581153690815    |
| train_0/fw_loss           | 0.0032578871119767427 |
| train_0/mu_grads          | -0.03861871724948287  |
| train_0/mu_grads_std      | 0.4341602481901646    |
| train_0/mu_loss           | 5.3791896079634665    |
| train_0/next_q            | -5.37693391992661     |
| train_0/q_grads           | -0.031721041072160006 |
| train_0/q_grads_std       | 0.3559365004301071    |
| train_0/q_loss            | 0.20398217872745175   |
| train_0/reward            | -0.7118267090030713   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004931640625        |
| train_0/target_q          | -5.707912603902076    |
| train_1/avg_q             | -4.427009752701076    |
| train_1/current_q         | -4.307420894388434    |
| train_1/fw_bonus          | -0.9982895508408547   |
| train_1/fw_loss           | 0.028822190267965196  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.307567750419049     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.307420894388434    |
| train_1/q_grads           | -0.031615385226905345 |
| train_1/q_grads_std       | 0.24290403313934802   |
| train_1/q_loss            | 5.382112608023562     |
| train_1/reward            | -1.520909915112861    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.313069105447077    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 244.98. Rollout time: 70.37, Training time: 174.59
Evaluating epoch 36
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 1040625.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.193500802641409    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.443410182619063    |
| train_0/fw_bonus          | -0.9995433330535889   |
| train_0/fw_loss           | 0.003441595833282918  |
| train_0/mu_grads          | -0.038185153156518936 |
| train_0/mu_grads_std      | 0.43869209513068197   |
| train_0/mu_loss           | 5.360105610534593     |
| train_0/next_q            | -5.358115941331098    |
| train_0/q_grads           | -0.03302375953644514  |
| train_0/q_grads_std       | 0.36011729165911677   |
| train_0/q_loss            | 0.19997380824602243   |
| train_0/reward            | -0.7078649278177181   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005029296875        |
| train_0/target_q          | -5.6760390745651375   |
| train_1/avg_q             | -4.2921672129681125   |
| train_1/current_q         | -4.204574142700698    |
| train_1/fw_bonus          | -0.9978133767843247   |
| train_1/fw_loss           | 0.03115069679915905   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.2042314805908205    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.204574142700698    |
| train_1/q_grads           | -0.03161850450560451  |
| train_1/q_grads_std       | 0.2428460817784071    |
| train_1/q_loss            | 5.429285035704739     |
| train_1/reward            | -1.5143241680860229   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.187513510915256    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 241.20. Rollout time: 68.61, Training time: 172.56
Evaluating epoch 37
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 1068750.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.99026821509601     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.444856269332432    |
| train_0/fw_bonus          | -0.9995477095246315   |
| train_0/fw_loss           | 0.0034203210030682384 |
| train_0/mu_grads          | -0.038847488909959794 |
| train_0/mu_grads_std      | 0.4440072558820248    |
| train_0/mu_loss           | 5.350991931849697     |
| train_0/next_q            | -5.349054890123794    |
| train_0/q_grads           | -0.03371963631361723  |
| train_0/q_grads_std       | 0.3638596601784229    |
| train_0/q_loss            | 0.1966526098471745    |
| train_0/reward            | -0.7063412390118173   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047607421875       |
| train_0/target_q          | -5.676962173746752    |
| train_1/avg_q             | -4.116869731456797    |
| train_1/current_q         | -3.9766948624215877   |
| train_1/fw_bonus          | -0.9972978383302689   |
| train_1/fw_loss           | 0.033671709382906555  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.976820257564897     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9766948624215877   |
| train_1/q_grads           | -0.03162558674812317  |
| train_1/q_grads_std       | 0.242716047167778     |
| train_1/q_loss            | 5.218459811416838     |
| train_1/reward            | -1.4840126812952803   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9921392647760996   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 247.51. Rollout time: 71.12, Training time: 176.36
Evaluating epoch 38
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 1096875.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.935703752680417    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.409490467397477    |
| train_0/fw_bonus          | -0.9995189055800437   |
| train_0/fw_loss           | 0.0035602166317403316 |
| train_0/mu_grads          | -0.04018022855743766  |
| train_0/mu_grads_std      | 0.4507267393171787    |
| train_0/mu_loss           | 5.327281354126238     |
| train_0/next_q            | -5.3259684699424      |
| train_0/q_grads           | -0.034844846464693546 |
| train_0/q_grads_std       | 0.3689668864011765    |
| train_0/q_loss            | 0.1959180167296711    |
| train_0/reward            | -0.7035680497116118   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004443359375        |
| train_0/target_q          | -5.641063373775706    |
| train_1/avg_q             | -3.950159299367156    |
| train_1/current_q         | -3.929032632501117    |
| train_1/fw_bonus          | -0.9964830204844475   |
| train_1/fw_loss           | 0.0376560315489769    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.929477479279614     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.929032632501117    |
| train_1/q_grads           | -0.03162710070610046  |
| train_1/q_grads_std       | 0.24268853925168515   |
| train_1/q_loss            | 5.329603277745859     |
| train_1/reward            | -1.511681453842175    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9394376481813147   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 250.10. Rollout time: 69.45, Training time: 180.62
Evaluating epoch 39
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 1125000.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8023009533025336   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.460338397287155    |
| train_0/fw_bonus          | -0.9995298072695732   |
| train_0/fw_loss           | 0.0035072583355940878 |
| train_0/mu_grads          | -0.041916347295045855 |
| train_0/mu_grads_std      | 0.4580693252384663    |
| train_0/mu_loss           | 5.392038705385487     |
| train_0/next_q            | -5.39089315590911     |
| train_0/q_grads           | -0.0358608559705317   |
| train_0/q_grads_std       | 0.37307404577732084   |
| train_0/q_loss            | 0.1961277462346817    |
| train_0/reward            | -0.7028044579303241   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.694225825624997    |
| train_1/avg_q             | -3.8739255202193794   |
| train_1/current_q         | -3.803883079563178    |
| train_1/fw_bonus          | -0.9961768239736557   |
| train_1/fw_loss           | 0.03915331764146686   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.803702174007475     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.803883079563178    |
| train_1/q_grads           | -0.031631131935864684 |
| train_1/q_grads_std       | 0.24261574931442736   |
| train_1/q_loss            | 5.315496990387286     |
| train_1/reward            | -1.4962329450070684   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.799526566228578    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 241.93. Rollout time: 69.19, Training time: 172.72
Evaluating epoch 40
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 1153125.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7569244384200084   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.379662684804673    |
| train_0/fw_bonus          | -0.9994941011071206   |
| train_0/fw_loss           | 0.0036806981835979967 |
| train_0/mu_grads          | -0.043024822138249874 |
| train_0/mu_grads_std      | 0.46276703625917437   |
| train_0/mu_loss           | 5.3128717196329545    |
| train_0/next_q            | -5.310721574220183    |
| train_0/q_grads           | -0.037938861455768344 |
| train_0/q_grads_std       | 0.37735331878066064   |
| train_0/q_loss            | 0.19126128040347035   |
| train_0/reward            | -0.6979282066808082   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004443359375        |
| train_0/target_q          | -5.612310334830124    |
| train_1/avg_q             | -3.777440451882337    |
| train_1/current_q         | -3.7541857149156916   |
| train_1/fw_bonus          | -0.9960476189851761   |
| train_1/fw_loss           | 0.039785105362534524  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.753912300823417     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7541857149156916   |
| train_1/q_grads           | -0.03163275793194771  |
| train_1/q_grads_std       | 0.24258660413324834   |
| train_1/q_loss            | 5.2336097849365615    |
| train_1/reward            | -1.4821668789649265   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7601276685689258   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 248.01. Rollout time: 69.62, Training time: 178.36
Evaluating epoch 41
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 1181250.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7882918602798683   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.396783925437255    |
| train_0/fw_bonus          | -0.9994392096996307   |
| train_0/fw_loss           | 0.003947401425102725  |
| train_0/mu_grads          | -0.04361034035682678  |
| train_0/mu_grads_std      | 0.46531972140073774   |
| train_0/mu_loss           | 5.332672931579941     |
| train_0/next_q            | -5.3299816089869045   |
| train_0/q_grads           | -0.03891528369858861  |
| train_0/q_grads_std       | 0.38026411458849907   |
| train_0/q_loss            | 0.1920763914681955    |
| train_0/reward            | -0.6988162803892919   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00517578125         |
| train_0/target_q          | -5.627689666970663    |
| train_1/avg_q             | -3.788077652763257    |
| train_1/current_q         | -3.7781245632283804   |
| train_1/fw_bonus          | -0.9949252739548683   |
| train_1/fw_loss           | 0.045273360516875985  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.778401117436576     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7781245632283804   |
| train_1/q_grads           | -0.03163197264075279  |
| train_1/q_grads_std       | 0.24260066114366055   |
| train_1/q_loss            | 5.147394343456969     |
| train_1/reward            | -1.4680925174616277   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7961146040542304   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 244.99. Rollout time: 68.94, Training time: 176.02
Evaluating epoch 42
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 42                    |
| policy/steps              | 1209375.0             |
| test/episodes             | 1075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.813775042199737    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.441426112218226    |
| train_0/fw_bonus          | -0.9994280070066452   |
| train_0/fw_loss           | 0.004001797770615667  |
| train_0/mu_grads          | -0.046069268882274625 |
| train_0/mu_grads_std      | 0.46786214858293534   |
| train_0/mu_loss           | 5.386399448567181     |
| train_0/next_q            | -5.38389189812387     |
| train_0/q_grads           | -0.040640611201524734 |
| train_0/q_grads_std       | 0.3836714930832386    |
| train_0/q_loss            | 0.1945298778646901    |
| train_0/reward            | -0.6979439820875996   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0045166015625       |
| train_0/target_q          | -5.676006776492065    |
| train_1/avg_q             | -3.815427014562602    |
| train_1/current_q         | -3.8174833790042606   |
| train_1/fw_bonus          | -0.9938822388648987   |
| train_1/fw_loss           | 0.05037371255457401   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.817434175197208     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8174833790042606   |
| train_1/q_grads           | -0.031630689650774    |
| train_1/q_grads_std       | 0.2426237002015114    |
| train_1/q_loss            | 5.217980881420658     |
| train_1/reward            | -1.469536334550503    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8132269384469084   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 251.10. Rollout time: 70.43, Training time: 180.65
Evaluating epoch 43
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 43                    |
| policy/steps              | 1237500.0             |
| test/episodes             | 1100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.721364383093046    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.407411662294617    |
| train_0/fw_bonus          | -0.9993677288293839   |
| train_0/fw_loss           | 0.004294616577681154  |
| train_0/mu_grads          | -0.04607928106561303  |
| train_0/mu_grads_std      | 0.4709146417677402    |
| train_0/mu_loss           | 5.359029387780538     |
| train_0/next_q            | -5.3570439805462495   |
| train_0/q_grads           | -0.04176090434193611  |
| train_0/q_grads_std       | 0.38711310252547265   |
| train_0/q_loss            | 0.19487631553554655   |
| train_0/reward            | -0.6956555396885961   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.003955078125        |
| train_0/target_q          | -5.642194971622532    |
| train_1/avg_q             | -3.789293463716577    |
| train_1/current_q         | -3.716870388978485    |
| train_1/fw_bonus          | -0.9922229707241058   |
| train_1/fw_loss           | 0.05848739566281438   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.7172636677625       |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.716870388978485    |
| train_1/q_grads           | -0.031633987184613944 |
| train_1/q_grads_std       | 0.24256462790071964   |
| train_1/q_loss            | 5.1614905683984205    |
| train_1/reward            | -1.459331705301156    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7183047171396852   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 244.58. Rollout time: 68.38, Training time: 176.17
Evaluating epoch 44
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 1265625.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.669630862538652    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.368496572734224    |
| train_0/fw_bonus          | -0.9993534609675407   |
| train_0/fw_loss           | 0.004363780957646668  |
| train_0/mu_grads          | -0.04764769310131669  |
| train_0/mu_grads_std      | 0.4739097818732262    |
| train_0/mu_loss           | 5.3185428677913436    |
| train_0/next_q            | -5.316689232911871    |
| train_0/q_grads           | -0.04170596497133374  |
| train_0/q_grads_std       | 0.39134790375828743   |
| train_0/q_loss            | 0.1888848552715888    |
| train_0/reward            | -0.6930971511275856   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004736328125        |
| train_0/target_q          | -5.599515038813746    |
| train_1/avg_q             | -3.6623396476477548   |
| train_1/current_q         | -3.663185118873531    |
| train_1/fw_bonus          | -0.99161307066679     |
| train_1/fw_loss           | 0.06146981418132782   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.663423449749382     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.663185118873531    |
| train_1/q_grads           | -0.03163577076047659  |
| train_1/q_grads_std       | 0.24253286831080914   |
| train_1/q_loss            | 5.179965998269081     |
| train_1/reward            | -1.4672909109838657   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.668830114152185    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 247.69. Rollout time: 70.23, Training time: 177.44
Evaluating epoch 45
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 1293750.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7187805399333542   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999858744   |
| train_0/current_q         | -5.40582938244073     |
| train_0/fw_bonus          | -0.9993316397070885   |
| train_0/fw_loss           | 0.004469887900631875  |
| train_0/mu_grads          | -0.04762840392068028  |
| train_0/mu_grads_std      | 0.47672922164201736   |
| train_0/mu_loss           | 5.354207928865243     |
| train_0/next_q            | -5.351302541586622    |
| train_0/q_grads           | -0.043085343297570945 |
| train_0/q_grads_std       | 0.3959708191454411    |
| train_0/q_loss            | 0.1937551713630835    |
| train_0/reward            | -0.6961257795192068   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044921875          |
| train_0/target_q          | -5.6384317849025205   |
| train_1/avg_q             | -3.6995185368226204   |
| train_1/current_q         | -3.7101291963830305   |
| train_1/fw_bonus          | -0.9907287418842315   |
| train_1/fw_loss           | 0.06579413637518883   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.71049353091446      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7101291963830305   |
| train_1/q_grads           | -0.03163420967757702  |
| train_1/q_grads_std       | 0.24256065040826796   |
| train_1/q_loss            | 5.231936280473365     |
| train_1/reward            | -1.483157339997706    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7196454353328874   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 242.15. Rollout time: 69.32, Training time: 172.80
Evaluating epoch 46
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 1321875.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7625977369970944   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.425095068578627    |
| train_0/fw_bonus          | -0.9993502482771873   |
| train_0/fw_loss           | 0.004379527876153588  |
| train_0/mu_grads          | -0.04797884486615658  |
| train_0/mu_grads_std      | 0.48048075586557387   |
| train_0/mu_loss           | 5.371171606159514     |
| train_0/next_q            | -5.368808963692719    |
| train_0/q_grads           | -0.04441041499376297  |
| train_0/q_grads_std       | 0.4011566497385502    |
| train_0/q_loss            | 0.19700356445627074   |
| train_0/reward            | -0.6981980689699412   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044677734375       |
| train_0/target_q          | -5.658671624100624    |
| train_1/avg_q             | -3.7017707040777594   |
| train_1/current_q         | -3.7533131114766767   |
| train_1/fw_bonus          | -0.9915996581315994   |
| train_1/fw_loss           | 0.0615354030393064    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.753890897820003     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7533131114766767   |
| train_1/q_grads           | -0.03163278615102172  |
| train_1/q_grads_std       | 0.2425860919058323    |
| train_1/q_loss            | 5.234693659748915     |
| train_1/reward            | -1.486046412200085    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.76526850379111     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 249.74. Rollout time: 71.27, Training time: 178.44
Evaluating epoch 47
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 1350000.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9607077618092745   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.398230735296901    |
| train_0/fw_bonus          | -0.9993867948651314   |
| train_0/fw_loss           | 0.00420198236242868   |
| train_0/mu_grads          | -0.04911183901131153  |
| train_0/mu_grads_std      | 0.4837003543972969    |
| train_0/mu_loss           | 5.334980206323766     |
| train_0/next_q            | -5.332230050314235    |
| train_0/q_grads           | -0.0453337574377656   |
| train_0/q_grads_std       | 0.406339131295681     |
| train_0/q_loss            | 0.19580560972906727   |
| train_0/reward            | -0.7003525753782014   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004345703125        |
| train_0/target_q          | -5.630925518385102    |
| train_1/avg_q             | -3.8223075675468117   |
| train_1/current_q         | -3.961802531493947    |
| train_1/fw_bonus          | -0.9915438130497932   |
| train_1/fw_loss           | 0.061808491311967376  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.961680516998511     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.961802531493947    |
| train_1/q_grads           | -0.03162605818361044  |
| train_1/q_grads_std       | 0.24270746484398842   |
| train_1/q_loss            | 5.294651924623652     |
| train_1/reward            | -1.4850541324252844   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014404296875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9530722647310284   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 249.41. Rollout time: 69.90, Training time: 179.48
Evaluating epoch 48
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 1378125.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.100084686959136    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.432326355659957    |
| train_0/fw_bonus          | -0.9993815034627914   |
| train_0/fw_loss           | 0.004227657197043299  |
| train_0/mu_grads          | -0.04917478039860725  |
| train_0/mu_grads_std      | 0.4873834431171417    |
| train_0/mu_loss           | 5.361320842631191     |
| train_0/next_q            | -5.359120796853907    |
| train_0/q_grads           | -0.04699867172166705  |
| train_0/q_grads_std       | 0.4114041097462177    |
| train_0/q_loss            | 0.20064159849559154   |
| train_0/reward            | -0.7028645805810811   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047119140625       |
| train_0/target_q          | -5.66660846081455     |
| train_1/avg_q             | -4.041801671078509    |
| train_1/current_q         | -4.108150456963758    |
| train_1/fw_bonus          | -0.9912532299757004   |
| train_1/fw_loss           | 0.06322943670675159   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.107537291576062     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.108150456963758    |
| train_1/q_grads           | -0.0316214713267982   |
| train_1/q_grads_std       | 0.2427913449704647    |
| train_1/q_loss            | 5.310643055570542     |
| train_1/reward            | -1.4898771010055498   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.1023556642727055   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 244.04. Rollout time: 69.15, Training time: 174.86
Evaluating epoch 49
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 1406250.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.179016609082056    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.420430346952169    |
| train_0/fw_bonus          | -0.9993586018681526   |
| train_0/fw_loss           | 0.0043389150057919325 |
| train_0/mu_grads          | -0.049205289036035535 |
| train_0/mu_grads_std      | 0.49271340668201447   |
| train_0/mu_loss           | 5.345281669855529     |
| train_0/next_q            | -5.340603393294623    |
| train_0/q_grads           | -0.047813852317631245 |
| train_0/q_grads_std       | 0.416190567612648     |
| train_0/q_loss            | 0.20214617043465571   |
| train_0/reward            | -0.70525791371183     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.003857421875        |
| train_0/target_q          | -5.65143600599565     |
| train_1/avg_q             | -4.181299778517134    |
| train_1/current_q         | -4.1893561345407875   |
| train_1/fw_bonus          | -0.9912624821066857   |
| train_1/fw_loss           | 0.06318415133282543   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.1889219490001235    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.1893561345407875   |
| train_1/q_grads           | -0.0316189699806273   |
| train_1/q_grads_std       | 0.2428374696522951    |
| train_1/q_loss            | 5.374582259569241     |
| train_1/reward            | -1.5116102475862134   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.18724110944232     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 253.13. Rollout time: 72.18, Training time: 180.91
Evaluating epoch 50
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 1434375.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.163940627880256    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.432230004824959    |
| train_0/fw_bonus          | -0.9994146957993507   |
| train_0/fw_loss           | 0.004066456854343414  |
| train_0/mu_grads          | -0.05099774831905961  |
| train_0/mu_grads_std      | 0.49867369830608366   |
| train_0/mu_loss           | 5.343537531279934     |
| train_0/next_q            | -5.34041299146044     |
| train_0/q_grads           | -0.04892124626785517  |
| train_0/q_grads_std       | 0.4205610670149326    |
| train_0/q_loss            | 0.20313902222314112   |
| train_0/reward            | -0.7039309787629463   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0034912109375       |
| train_0/target_q          | -5.66581196929147     |
| train_1/avg_q             | -4.179437514729295    |
| train_1/current_q         | -4.159338312794025    |
| train_1/fw_bonus          | -0.991469432413578    |
| train_1/fw_loss           | 0.06217220760881901   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.159322498360336     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.159338312794025    |
| train_1/q_grads           | -0.03161989115178585  |
| train_1/q_grads_std       | 0.24282045289874077   |
| train_1/q_loss            | 5.353738171387055     |
| train_1/reward            | -1.5096629385501728   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00126953125         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.161335518649238    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 242.93. Rollout time: 69.11, Training time: 173.79
Evaluating epoch 51
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 1462500.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.262644635966028    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.506012838503774    |
| train_0/fw_bonus          | -0.9994285494089127   |
| train_0/fw_loss           | 0.003999151173047721  |
| train_0/mu_grads          | -0.05073048174381256  |
| train_0/mu_grads_std      | 0.5030733570456505    |
| train_0/mu_loss           | 5.406293664532501     |
| train_0/next_q            | -5.402322490573127    |
| train_0/q_grads           | -0.05083512384444475  |
| train_0/q_grads_std       | 0.4248349189758301    |
| train_0/q_loss            | 0.2030444217606245    |
| train_0/reward            | -0.7095531411316187   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041259765625       |
| train_0/target_q          | -5.741371516993617    |
| train_1/avg_q             | -4.228971617621618    |
| train_1/current_q         | -4.26738795469349     |
| train_1/fw_bonus          | -0.9917423412203789   |
| train_1/fw_loss           | 0.06083762748166919   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.26705102608759      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.26738795469349     |
| train_1/q_grads           | -0.031616594083607195 |
| train_1/q_grads_std       | 0.24288152493536472   |
| train_1/q_loss            | 5.394336609810604     |
| train_1/reward            | -1.5109102410096966   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.259128810940104    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 256.12. Rollout time: 73.21, Training time: 182.88
Evaluating epoch 52
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 1490625.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.254687502723547    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.437468684241742    |
| train_0/fw_bonus          | -0.9994909331202507   |
| train_0/fw_loss           | 0.0036961368226911873 |
| train_0/mu_grads          | -0.05133165949955583  |
| train_0/mu_grads_std      | 0.5069225311279297    |
| train_0/mu_loss           | 5.358030512598587     |
| train_0/next_q            | -5.3551078746297565   |
| train_0/q_grads           | -0.05160395624116063  |
| train_0/q_grads_std       | 0.42886982709169386   |
| train_0/q_loss            | 0.20203874372192648   |
| train_0/reward            | -0.7071429258547142   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004248046875        |
| train_0/target_q          | -5.667400074853075    |
| train_1/avg_q             | -4.248757175232276    |
| train_1/current_q         | -4.261312336179179    |
| train_1/fw_bonus          | -0.9926461711525917   |
| train_1/fw_loss           | 0.05641806339845061   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.261436261953143     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.261312336179179    |
| train_1/q_grads           | -0.03161677801981568  |
| train_1/q_grads_std       | 0.24287810362875462   |
| train_1/q_loss            | 5.404207920455895     |
| train_1/reward            | -1.5127537457658036   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.251860984579681    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 246.16. Rollout time: 69.16, Training time: 176.98
Evaluating epoch 53
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 53                    |
| policy/steps              | 1518750.0             |
| test/episodes             | 1350.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.212398499754668    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.44997549952305     |
| train_0/fw_bonus          | -0.9995173051953316   |
| train_0/fw_loss           | 0.0035680057597346606 |
| train_0/mu_grads          | -0.052844783384352924 |
| train_0/mu_grads_std      | 0.5088463097810745    |
| train_0/mu_loss           | 5.360126044527748     |
| train_0/next_q            | -5.356674865166788    |
| train_0/q_grads           | -0.05288100270554423  |
| train_0/q_grads_std       | 0.43320009857416153   |
| train_0/q_loss            | 0.19910149058387855   |
| train_0/reward            | -0.7089505485833797   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0037841796875       |
| train_0/target_q          | -5.683802637721572    |
| train_1/avg_q             | -4.210692766712722    |
| train_1/current_q         | -4.22022405610913     |
| train_1/fw_bonus          | -0.9922383219003678   |
| train_1/fw_loss           | 0.05841241385787725   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.219984130322598     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.22022405610913     |
| train_1/q_grads           | -0.03161802673712373  |
| train_1/q_grads_std       | 0.24285492710769177   |
| train_1/q_loss            | 5.422190331755099     |
| train_1/reward            | -1.5188120288730715   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.210636341792717    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 244.80. Rollout time: 70.63, Training time: 174.14
Evaluating epoch 54
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 1546875.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.348800646004613    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.480270232877922    |
| train_0/fw_bonus          | -0.9995245650410652   |
| train_0/fw_loss           | 0.0035327764868270605 |
| train_0/mu_grads          | -0.05499548465013504  |
| train_0/mu_grads_std      | 0.5095727041363716    |
| train_0/mu_loss           | 5.390012940071521     |
| train_0/next_q            | -5.3874653718109      |
| train_0/q_grads           | -0.05356780095025897  |
| train_0/q_grads_std       | 0.43702612221241      |
| train_0/q_loss            | 0.20102552466436524   |
| train_0/reward            | -0.7105777101460262   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.003564453125        |
| train_0/target_q          | -5.714267538387807    |
| train_1/avg_q             | -4.285939404128942    |
| train_1/current_q         | -4.352929962954007    |
| train_1/fw_bonus          | -0.9929345905780792   |
| train_1/fw_loss           | 0.055007600132375954  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.352641353291374     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.352929962954007    |
| train_1/q_grads           | -0.03161401944234967  |
| train_1/q_grads_std       | 0.24292954318225385   |
| train_1/q_loss            | 5.400482490266962     |
| train_1/reward            | -1.512849137102603    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.346353948851498    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 244.08. Rollout time: 70.60, Training time: 173.45
Evaluating epoch 55
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 1575000.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.404723511773686    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4251344158116535   |
| train_0/fw_bonus          | -0.9995351344347      |
| train_0/fw_loss           | 0.003481353260576725  |
| train_0/mu_grads          | -0.0556525707244873   |
| train_0/mu_grads_std      | 0.5107361972332001    |
| train_0/mu_loss           | 5.337399328442284     |
| train_0/next_q            | -5.334946040986502    |
| train_0/q_grads           | -0.054054697323590514 |
| train_0/q_grads_std       | 0.44067531526088716   |
| train_0/q_loss            | 0.20062117632540205   |
| train_0/reward            | -0.7083979448216269   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0038330078125       |
| train_0/target_q          | -5.656982273476309    |
| train_1/avg_q             | -4.380226522707055    |
| train_1/current_q         | -4.405375372557293    |
| train_1/fw_bonus          | -0.9926951110363007   |
| train_1/fw_loss           | 0.05617874134331942   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.4054263635792745    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.405375372557293    |
| train_1/q_grads           | -0.03161245584487915  |
| train_1/q_grads_std       | 0.24295884594321251   |
| train_1/q_loss            | 5.428317900340596     |
| train_1/reward            | -1.528659563860856    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.40581893920992     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 241.66. Rollout time: 70.92, Training time: 170.72
Evaluating epoch 56
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 1603125.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.306438539177463    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999982   |
| train_0/current_q         | -5.427934249334999    |
| train_0/fw_bonus          | -0.999544021487236    |
| train_0/fw_loss           | 0.003438234416535124  |
| train_0/mu_grads          | -0.055439282488077876 |
| train_0/mu_grads_std      | 0.5118439853191376    |
| train_0/mu_loss           | 5.343252294508592     |
| train_0/next_q            | -5.340989428980306    |
| train_0/q_grads           | -0.05499232597649097  |
| train_0/q_grads_std       | 0.4443687409162521    |
| train_0/q_loss            | 0.20035496196574698   |
| train_0/reward            | -0.7085976954920625   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047119140625       |
| train_0/target_q          | -5.6594474253802005   |
| train_1/avg_q             | -4.36479726103464     |
| train_1/current_q         | -4.3065096083036325   |
| train_1/fw_bonus          | -0.9929486677050591   |
| train_1/fw_loss           | 0.054938823264092204  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.306426364837824     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.3065096083036325   |
| train_1/q_grads           | -0.03161541260778904  |
| train_1/q_grads_std       | 0.24290352165699006   |
| train_1/q_loss            | 5.467883569630574     |
| train_1/reward            | -1.5403219907871972   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.30499782660672     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 256.19. Rollout time: 71.82, Training time: 184.34
Evaluating epoch 57
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 1631250.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.206466828710673    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999896934   |
| train_0/current_q         | -5.417921846475798    |
| train_0/fw_bonus          | -0.9995420426130295   |
| train_0/fw_loss           | 0.0034478804853279145 |
| train_0/mu_grads          | -0.05660260496661067  |
| train_0/mu_grads_std      | 0.5145723730325699    |
| train_0/mu_loss           | 5.3427853142036765    |
| train_0/next_q            | -5.339993938186066    |
| train_0/q_grads           | -0.05640158541500569  |
| train_0/q_grads_std       | 0.447452637553215     |
| train_0/q_loss            | 0.19966228993219481   |
| train_0/reward            | -0.7052763903913728   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.003662109375        |
| train_0/target_q          | -5.651519526252601    |
| train_1/avg_q             | -4.272644039744285    |
| train_1/current_q         | -4.214278214482853    |
| train_1/fw_bonus          | -0.992451736330986    |
| train_1/fw_loss           | 0.05736879911273718   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.213989166071524     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.214278214482853    |
| train_1/q_grads           | -0.031618207972496745 |
| train_1/q_grads_std       | 0.24285156577825545   |
| train_1/q_loss            | 5.473880702739493     |
| train_1/reward            | -1.5400246959696233   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00107421875         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.210290783579792    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 246.20. Rollout time: 69.34, Training time: 176.84
Evaluating epoch 58
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 1659375.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.200058623775341    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.47554726483704     |
| train_0/fw_bonus          | -0.9995348289608955   |
| train_0/fw_loss           | 0.0034829311014618726 |
| train_0/mu_grads          | -0.0566641946323216   |
| train_0/mu_grads_std      | 0.517424239218235     |
| train_0/mu_loss           | 5.402312587592871     |
| train_0/next_q            | -5.399522798521419    |
| train_0/q_grads           | -0.05707129891961813  |
| train_0/q_grads_std       | 0.45046830400824545   |
| train_0/q_loss            | 0.19934597449862318   |
| train_0/reward            | -0.7071282509728917   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004345703125        |
| train_0/target_q          | -5.710680489207277    |
| train_1/avg_q             | -4.205999977939872    |
| train_1/current_q         | -4.185939067835443    |
| train_1/fw_bonus          | -0.9917700543999672   |
| train_1/fw_loss           | 0.060702205542474984  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.1864805351111105    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.185939067835443    |
| train_1/q_grads           | -0.031619074195623396 |
| train_1/q_grads_std       | 0.242835533618927     |
| train_1/q_loss            | 5.3700925826766825    |
| train_1/reward            | -1.5271594391400867   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.201394120886851    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 251.43. Rollout time: 70.62, Training time: 180.78
Evaluating epoch 59
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 1687500.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999999999998   |
| test_1/avg_q              | -4.155858607263817    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.488731580100645    |
| train_0/fw_bonus          | -0.9995163813233375   |
| train_0/fw_loss           | 0.003572449798230082  |
| train_0/mu_grads          | -0.057904186099767684 |
| train_0/mu_grads_std      | 0.5203112661838531    |
| train_0/mu_loss           | 5.417648506127755     |
| train_0/next_q            | -5.416695580080477    |
| train_0/q_grads           | -0.05802890472114086  |
| train_0/q_grads_std       | 0.4538837164640427    |
| train_0/q_loss            | 0.19837818577568322   |
| train_0/reward            | -0.7081444270334032   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041015625          |
| train_0/target_q          | -5.724585490363711    |
| train_1/avg_q             | -4.164311487208915    |
| train_1/current_q         | -4.1589422049625675   |
| train_1/fw_bonus          | -0.9909183442592621   |
| train_1/fw_loss           | 0.06486697904765606   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.158662107875794     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.1589422049625675   |
| train_1/q_grads           | -0.03161990288645029  |
| train_1/q_grads_std       | 0.24282022900879383   |
| train_1/q_loss            | 5.343956017664954     |
| train_1/reward            | -1.4998537048137224   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.154173945522368    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 240.00. Rollout time: 67.90, Training time: 172.08
Evaluating epoch 60
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 1715625.0             |
| test/episodes             | 1525.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.161003719899709    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999993   |
| train_0/current_q         | -5.487054440101536    |
| train_0/fw_bonus          | -0.9994991391897201   |
| train_0/fw_loss           | 0.003656286146724597  |
| train_0/mu_grads          | -0.058099803142249586 |
| train_0/mu_grads_std      | 0.5222922638058662    |
| train_0/mu_loss           | 5.413173952507817     |
| train_0/next_q            | -5.411053007728244    |
| train_0/q_grads           | -0.05939000248908997  |
| train_0/q_grads_std       | 0.4575004778802395    |
| train_0/q_loss            | 0.1999785735347288    |
| train_0/reward            | -0.7091001528817287   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004248046875        |
| train_0/target_q          | -5.721784422056812    |
| train_1/avg_q             | -4.1758206871458095   |
| train_1/current_q         | -4.163344653060751    |
| train_1/fw_bonus          | -0.9903271332383156   |
| train_1/fw_loss           | 0.06775799151510001   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.163148477311725     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.163344653060751    |
| train_1/q_grads           | -0.031619767751544715 |
| train_1/q_grads_std       | 0.24282272532582283   |
| train_1/q_loss            | 5.395537706840061     |
| train_1/reward            | -1.518369131423242    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.161630221116374    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_60.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 249.92. Rollout time: 69.16, Training time: 180.73
Evaluating epoch 61
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 1743750.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.09916557441853     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999993   |
| train_0/current_q         | -5.460594432691648    |
| train_0/fw_bonus          | -0.9995185911655426   |
| train_0/fw_loss           | 0.003561800706665963  |
| train_0/mu_grads          | -0.05785043640062213  |
| train_0/mu_grads_std      | 0.5241899266839027    |
| train_0/mu_loss           | 5.388438341024122     |
| train_0/next_q            | -5.385607851024536    |
| train_0/q_grads           | -0.06065466916188598  |
| train_0/q_grads_std       | 0.46141197979450227   |
| train_0/q_loss            | 0.20044643359593817   |
| train_0/reward            | -0.7073398591463047   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004541015625        |
| train_0/target_q          | -5.694524330090481    |
| train_1/avg_q             | -4.132131649047945    |
| train_1/current_q         | -4.106707672296321    |
| train_1/fw_bonus          | -0.9898100405931473   |
| train_1/fw_loss           | 0.07028650445863605   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.106379748403185     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.106707672296321    |
| train_1/q_grads           | -0.03162151612341404  |
| train_1/q_grads_std       | 0.242790524661541     |
| train_1/q_loss            | 5.411583962559312     |
| train_1/reward            | -1.5150100043552812   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.095910319899166    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 246.11. Rollout time: 69.28, Training time: 176.81
Evaluating epoch 62
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 1771875.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.143873859916639    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999977   |
| train_0/current_q         | -5.474990590966915    |
| train_0/fw_bonus          | -0.9995501562952995   |
| train_0/fw_loss           | 0.0034084421931765974 |
| train_0/mu_grads          | -0.058277540002018215 |
| train_0/mu_grads_std      | 0.5263388723134994    |
| train_0/mu_loss           | 5.400765580999971     |
| train_0/next_q            | -5.39965600015897     |
| train_0/q_grads           | -0.06166214570403099  |
| train_0/q_grads_std       | 0.46488330960273744   |
| train_0/q_loss            | 0.19885595749037732   |
| train_0/reward            | -0.7084542779710319   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050537109375       |
| train_0/target_q          | -5.710517962410641    |
| train_1/avg_q             | -4.119933880077312    |
| train_1/current_q         | -4.1319162957696305   |
| train_1/fw_bonus          | -0.9902771264314651   |
| train_1/fw_loss           | 0.06800247225910425   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.132349691002989     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.1319162957696305   |
| train_1/q_grads           | -0.03162073586136103  |
| train_1/q_grads_std       | 0.24280487559735775   |
| train_1/q_loss            | 5.307471889777624     |
| train_1/reward            | -1.501779191451351    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.140720562697415    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 245.98. Rollout time: 70.32, Training time: 175.64
Evaluating epoch 63
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 1800000.0             |
| test/episodes             | 1600.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.170168565368656    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999343   |
| train_0/current_q         | -5.39243502286401     |
| train_0/fw_bonus          | -0.9995819509029389   |
| train_0/fw_loss           | 0.003254009532975033  |
| train_0/mu_grads          | -0.05759033039212227  |
| train_0/mu_grads_std      | 0.5299970835447312    |
| train_0/mu_loss           | 5.317287904980903     |
| train_0/next_q            | -5.314863473795308    |
| train_0/q_grads           | -0.06331723146140575  |
| train_0/q_grads_std       | 0.46824862584471705   |
| train_0/q_loss            | 0.19903692287004043   |
| train_0/reward            | -0.7070785731382785   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041748046875       |
| train_0/target_q          | -5.625823879146542    |
| train_1/avg_q             | -4.1410504353995465   |
| train_1/current_q         | -4.175321461312953    |
| train_1/fw_bonus          | -0.9906566634774208   |
| train_1/fw_loss           | 0.06614654650911689   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.175074777932838     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.175321461312953    |
| train_1/q_grads           | -0.03161939997226     |
| train_1/q_grads_std       | 0.242829517647624     |
| train_1/q_loss            | 5.401797508614462     |
| train_1/reward            | -1.5146032397977252   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00107421875         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.167790782539724    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 252.18. Rollout time: 70.01, Training time: 182.14
Evaluating epoch 64
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 1828125.0             |
| test/episodes             | 1625.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.211781703582738    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.368418484627134    |
| train_0/fw_bonus          | -0.9995955944061279   |
| train_0/fw_loss           | 0.0031877831963356583 |
| train_0/mu_grads          | -0.058534459117799996 |
| train_0/mu_grads_std      | 0.532319986820221     |
| train_0/mu_loss           | 5.289564381861673     |
| train_0/next_q            | -5.287858583785773    |
| train_0/q_grads           | -0.06527454014867544  |
| train_0/q_grads_std       | 0.47168915942311285   |
| train_0/q_loss            | 0.19680446438690263   |
| train_0/reward            | -0.7065116595440486   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044189453125       |
| train_0/target_q          | -5.598056524565484    |
| train_1/avg_q             | -4.182293163705614    |
| train_1/current_q         | -4.211544540940917    |
| train_1/fw_bonus          | -0.9926037654280663   |
| train_1/fw_loss           | 0.056625372543931005  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.211537571459084     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.211544540940917    |
| train_1/q_grads           | -0.03161829123273492  |
| train_1/q_grads_std       | 0.24285002276301385   |
| train_1/q_loss            | 5.431439057028419     |
| train_1/reward            | -1.531323855950177    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00078125            |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.212060796883106    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 250.96. Rollout time: 71.03, Training time: 179.90
Evaluating epoch 65
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 1856250.0             |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.286340591964724    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999812022   |
| train_0/current_q         | -5.458852651797027    |
| train_0/fw_bonus          | -0.9996336445212364   |
| train_0/fw_loss           | 0.0030030084133613856 |
| train_0/mu_grads          | -0.05932169016450643  |
| train_0/mu_grads_std      | 0.5327030688524246    |
| train_0/mu_loss           | 5.375767429956096     |
| train_0/next_q            | -5.3739889491307355   |
| train_0/q_grads           | -0.06564409807324409  |
| train_0/q_grads_std       | 0.4758212961256504    |
| train_0/q_loss            | 0.19897256770059737   |
| train_0/reward            | -0.7100707184341445   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005908203125        |
| train_0/target_q          | -5.693536073604714    |
| train_1/avg_q             | -4.231838648548559    |
| train_1/current_q         | -4.2842010218682045   |
| train_1/fw_bonus          | -0.9934692353010177   |
| train_1/fw_loss           | 0.052393303345888854  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.284510456879756     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.2842010218682045   |
| train_1/q_grads           | -0.031616085674613714 |
| train_1/q_grads_std       | 0.24289098531007766   |
| train_1/q_loss            | 5.412057884163252     |
| train_1/reward            | -1.5272399864341424   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.287022524534426    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 255.74. Rollout time: 70.42, Training time: 185.29
Evaluating epoch 66
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 1884375.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.267800032523985    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.99999999567906    |
| train_0/current_q         | -5.518101477054242    |
| train_0/fw_bonus          | -0.9996411189436912   |
| train_0/fw_loss           | 0.002966583735542372  |
| train_0/mu_grads          | -0.060052364505827426 |
| train_0/mu_grads_std      | 0.5341422617435455    |
| train_0/mu_loss           | 5.438357635512422     |
| train_0/next_q            | -5.437306286251529    |
| train_0/q_grads           | -0.06623436361551285  |
| train_0/q_grads_std       | 0.47881877720355986   |
| train_0/q_loss            | 0.20135771036393563   |
| train_0/reward            | -0.7114416552554758   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005224609375        |
| train_0/target_q          | -5.754089048500701    |
| train_1/avg_q             | -4.304046060519599    |
| train_1/current_q         | -4.266605586534473    |
| train_1/fw_bonus          | -0.9932984605431556   |
| train_1/fw_loss           | 0.053228380624204874  |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.26679353352621      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.266605586534473    |
| train_1/q_grads           | -0.03161661755293608  |
| train_1/q_grads_std       | 0.2428810853511095    |
| train_1/q_loss            | 5.39996955036941      |
| train_1/reward            | -1.5222839939553523   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.268285264392663    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 247.31. Rollout time: 70.44, Training time: 176.84
Evaluating epoch 67
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 1912500.0             |
| test/episodes             | 1700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.182191435131011    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999343   |
| train_0/current_q         | -5.426268046435533    |
| train_0/fw_bonus          | -0.9996048733592033   |
| train_0/fw_loss           | 0.0031426567933522166 |
| train_0/mu_grads          | -0.06017419286072254  |
| train_0/mu_grads_std      | 0.5356845512986184    |
| train_0/mu_loss           | 5.351561607192577     |
| train_0/next_q            | -5.349609892395115    |
| train_0/q_grads           | -0.06690314654260873  |
| train_0/q_grads_std       | 0.4820056617259979    |
| train_0/q_loss            | 0.19671481578305755   |
| train_0/reward            | -0.7061745078783133   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.659173405869671    |
| train_1/avg_q             | -4.252210375620607    |
| train_1/current_q         | -4.179274129557028    |
| train_1/fw_bonus          | -0.9904386594891548   |
| train_1/fw_loss           | 0.06721264012157917   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.179236803945329     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.179274129557028    |
| train_1/q_grads           | -0.031619278527796266 |
| train_1/q_grads_std       | 0.24283175878226756   |
| train_1/q_loss            | 5.337374980603859     |
| train_1/reward            | -1.5030562422711227   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.180540273861727    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 253.87. Rollout time: 71.07, Training time: 182.78
Evaluating epoch 68
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 1940625.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9764269568921713   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4702017187930165   |
| train_0/fw_bonus          | -0.9995511591434478   |
| train_0/fw_loss           | 0.0034035447693895548 |
| train_0/mu_grads          | -0.06127550350502133  |
| train_0/mu_grads_std      | 0.5368780598044396    |
| train_0/mu_loss           | 5.396070087614939     |
| train_0/next_q            | -5.395851179812494    |
| train_0/q_grads           | -0.06743046939373017  |
| train_0/q_grads_std       | 0.4853213429450989    |
| train_0/q_loss            | 0.2003371560198107    |
| train_0/reward            | -0.7072340789003647   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049072265625       |
| train_0/target_q          | -5.704593355755942    |
| train_1/avg_q             | -4.08203759763141     |
| train_1/current_q         | -3.9741787899915906   |
| train_1/fw_bonus          | -0.9879886850714683   |
| train_1/fw_loss           | 0.07919286079704761   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.974283647242359     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9741787899915906   |
| train_1/q_grads           | -0.031625666189938784 |
| train_1/q_grads_std       | 0.2427145976573229    |
| train_1/q_loss            | 5.296845484527499     |
| train_1/reward            | -1.4923952204400848   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007080078125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9749686929556534   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 252.06. Rollout time: 70.02, Training time: 182.02
Evaluating epoch 69
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 1968750.0             |
| test/episodes             | 1750.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9016366754040086   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.417428927539516    |
| train_0/fw_bonus          | -0.9995596200227738   |
| train_0/fw_loss           | 0.0033624617382884024 |
| train_0/mu_grads          | -0.06296060774475336  |
| train_0/mu_grads_std      | 0.539748951792717     |
| train_0/mu_loss           | 5.348519568653319     |
| train_0/next_q            | -5.347309603162991    |
| train_0/q_grads           | -0.06838149558752775  |
| train_0/q_grads_std       | 0.48916527107357977   |
| train_0/q_loss            | 0.19564064737805387   |
| train_0/reward            | -0.7041865501189022   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044189453125       |
| train_0/target_q          | -5.650180115058286    |
| train_1/avg_q             | -3.9621082698472723   |
| train_1/current_q         | -3.9108098982866366   |
| train_1/fw_bonus          | -0.9872350603342056   |
| train_1/fw_loss           | 0.08287809323519468   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.910382328591664     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9108098982866366   |
| train_1/q_grads           | -0.03162768241018057  |
| train_1/q_grads_std       | 0.24267799146473407   |
| train_1/q_loss            | 5.2890221050041415    |
| train_1/reward            | -1.4834612741600721   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009765625          |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.902956942456349    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 255.66. Rollout time: 70.95, Training time: 184.68
Evaluating epoch 70
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 70                    |
| policy/steps              | 1996875.0             |
| test/episodes             | 1775.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8551168110596374   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.439841986872305    |
| train_0/fw_bonus          | -0.9995320901274681   |
| train_0/fw_loss           | 0.003496192756574601  |
| train_0/mu_grads          | -0.06390957608819008  |
| train_0/mu_grads_std      | 0.5430845364928245    |
| train_0/mu_loss           | 5.36530667462889      |
| train_0/next_q            | -5.363802529211242    |
| train_0/q_grads           | -0.06917353440076113  |
| train_0/q_grads_std       | 0.4923659272491932    |
| train_0/q_loss            | 0.19732871027592686   |
| train_0/reward            | -0.7052347959994222   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0038330078125       |
| train_0/target_q          | -5.672802729959801    |
| train_1/avg_q             | -3.876099435679614    |
| train_1/current_q         | -3.84840088331048     |
| train_1/fw_bonus          | -0.9857592314481736   |
| train_1/fw_loss           | 0.09009476080536842   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.848888931155811     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.84840088331048     |
| train_1/q_grads           | -0.03162968847900629  |
| train_1/q_grads_std       | 0.24264173731207847   |
| train_1/q_loss            | 5.259147964713138     |
| train_1/reward            | -1.4891808838932774   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.858029161458778    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_70.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 247.52. Rollout time: 70.55, Training time: 176.94
Evaluating epoch 71
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 2025000.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8522861565915942   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.3866528044108835   |
| train_0/fw_bonus          | -0.9995168700814248   |
| train_0/fw_loss           | 0.003570124285761267  |
| train_0/mu_grads          | -0.0649380685761571   |
| train_0/mu_grads_std      | 0.5457121342420578    |
| train_0/mu_loss           | 5.319507045354419     |
| train_0/next_q            | -5.318175026524356    |
| train_0/q_grads           | -0.0692449415102601   |
| train_0/q_grads_std       | 0.4952692359685898    |
| train_0/q_loss            | 0.1961553202301955    |
| train_0/reward            | -0.7020533580791379   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0040771484375       |
| train_0/target_q          | -5.61855893788749     |
| train_1/avg_q             | -3.8311587036945407   |
| train_1/current_q         | -3.85039035479175     |
| train_1/fw_bonus          | -0.9850683510303497   |
| train_1/fw_loss           | 0.09347310736775398   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.8503952010258145    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.85039035479175     |
| train_1/q_grads           | -0.03162962421774864  |
| train_1/q_grads_std       | 0.2426428973674774    |
| train_1/q_loss            | 5.316836843497373     |
| train_1/reward            | -1.4983081019126985   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011962890625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.851416499526912    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 246.78. Rollout time: 70.41, Training time: 176.34
Evaluating epoch 72
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 2053125.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8219938973375576   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.466137178849172    |
| train_0/fw_bonus          | -0.9995502024888993   |
| train_0/fw_loss           | 0.003408280125586316  |
| train_0/mu_grads          | -0.0648286420851946   |
| train_0/mu_grads_std      | 0.5480260774493217    |
| train_0/mu_loss           | 5.400858632632854     |
| train_0/next_q            | -5.398865392568051    |
| train_0/q_grads           | -0.06993408314883709  |
| train_0/q_grads_std       | 0.4987837187945843    |
| train_0/q_loss            | 0.19631935191939395   |
| train_0/reward            | -0.7045114235224901   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041259765625       |
| train_0/target_q          | -5.702383008019796    |
| train_1/avg_q             | -3.819808180312026    |
| train_1/current_q         | -3.8130124936170136   |
| train_1/fw_bonus          | -0.9858691617846489   |
| train_1/fw_loss           | 0.08955723773688078   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.813485799468323     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8130124936170136   |
| train_1/q_grads           | -0.03163083512336016  |
| train_1/q_grads_std       | 0.2426210854202509    |
| train_1/q_loss            | 5.274597149271043     |
| train_1/reward            | -1.4911157290815027   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.819344594958964    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 244.42. Rollout time: 69.79, Training time: 174.60
Evaluating epoch 73
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 2081250.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.763831758118966    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.463025125422247    |
| train_0/fw_bonus          | -0.9995722934603691   |
| train_0/fw_loss           | 0.0033008762169629336 |
| train_0/mu_grads          | -0.06379442736506462  |
| train_0/mu_grads_std      | 0.5501081496477127    |
| train_0/mu_loss           | 5.388136821514123     |
| train_0/next_q            | -5.388119651552487    |
| train_0/q_grads           | -0.07190050333738326  |
| train_0/q_grads_std       | 0.503178459405899     |
| train_0/q_loss            | 0.1943980245474827    |
| train_0/reward            | -0.7037290220912837   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0042724609375       |
| train_0/target_q          | -5.697872448000029    |
| train_1/avg_q             | -3.806461576213675    |
| train_1/current_q         | -3.771481679708619    |
| train_1/fw_bonus          | -0.9870575442910194   |
| train_1/fw_loss           | 0.08374607767909766   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.77102620736025      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.771481679708619    |
| train_1/q_grads           | -0.031632190477102994 |
| train_1/q_grads_std       | 0.2425967626273632    |
| train_1/q_loss            | 5.296058216331934     |
| train_1/reward            | -1.4854355103059789   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.76225840877962     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 251.99. Rollout time: 71.83, Training time: 180.13
Evaluating epoch 74
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 2109375.0             |
| test/episodes             | 1875.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.742395804279333    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.408857955349104    |
| train_0/fw_bonus          | -0.9995377629995346   |
| train_0/fw_loss           | 0.0034686672152020037 |
| train_0/mu_grads          | -0.06444053445011377  |
| train_0/mu_grads_std      | 0.5521357178688049    |
| train_0/mu_loss           | 5.346887312388061     |
| train_0/next_q            | -5.344470451143093    |
| train_0/q_grads           | -0.07321745604276657  |
| train_0/q_grads_std       | 0.5082416430115699    |
| train_0/q_loss            | 0.19277703904427668   |
| train_0/reward            | -0.7004524734002189   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0039306640625       |
| train_0/target_q          | -5.640387270876584    |
| train_1/avg_q             | -3.7540694119617437   |
| train_1/current_q         | -3.7343278872023005   |
| train_1/fw_bonus          | -0.9856970623135567   |
| train_1/fw_loss           | 0.09039866272360086   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.73462395851061      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7343278872023005   |
| train_1/q_grads           | -0.031633411161601545 |
| train_1/q_grads_std       | 0.24257491976022721   |
| train_1/q_loss            | 5.229663209090241     |
| train_1/reward            | -1.4860248102253535   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.749694009420316    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 251.99. Rollout time: 70.55, Training time: 181.41
Evaluating epoch 75
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 2137500.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.686160484885449    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.442676224659233    |
| train_0/fw_bonus          | -0.9995263814926147   |
| train_0/fw_loss           | 0.0035239489283412696 |
| train_0/mu_grads          | -0.06406899597495794  |
| train_0/mu_grads_std      | 0.5548366338014603    |
| train_0/mu_loss           | 5.383857618945462     |
| train_0/next_q            | -5.381626088331094    |
| train_0/q_grads           | -0.07384078819304704  |
| train_0/q_grads_std       | 0.5124305188655853    |
| train_0/q_loss            | 0.1915643856948793    |
| train_0/reward            | -0.6997387751551287   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041259765625       |
| train_0/target_q          | -5.67593769720869     |
| train_1/avg_q             | -3.689765250923967    |
| train_1/current_q         | -3.675418476580609    |
| train_1/fw_bonus          | -0.9838918387889862   |
| train_1/fw_loss           | 0.0992262128740549    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.675811294755488     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.675418476580609    |
| train_1/q_grads           | -0.03163536284118891  |
| train_1/q_grads_std       | 0.24254012070596218   |
| train_1/q_loss            | 5.248734314909184     |
| train_1/reward            | -1.488979608137015    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.6893371395148096   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 246.10. Rollout time: 69.40, Training time: 176.67
Evaluating epoch 76
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 2165625.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.6253394504988052   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4628303534500215   |
| train_0/fw_bonus          | -0.9995393753051758   |
| train_0/fw_loss           | 0.003460824390640482  |
| train_0/mu_grads          | -0.06437149345874786  |
| train_0/mu_grads_std      | 0.5562329709529876    |
| train_0/mu_loss           | 5.404271561682355     |
| train_0/next_q            | -5.403761486538629    |
| train_0/q_grads           | -0.07556811701506376  |
| train_0/q_grads_std       | 0.5162229180335999    |
| train_0/q_loss            | 0.19372368697669565   |
| train_0/reward            | -0.699647616330185    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005419921875        |
| train_0/target_q          | -5.699968506975155    |
| train_1/avg_q             | -3.661833533245253    |
| train_1/current_q         | -3.621755600607277    |
| train_1/fw_bonus          | -0.984117041528225    |
| train_1/fw_loss           | 0.09812496267259121   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.6217580585016425    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.621755600607277    |
| train_1/q_grads           | -0.031637159362435344 |
| train_1/q_grads_std       | 0.2425082366913557    |
| train_1/q_loss            | 5.226590680543502     |
| train_1/reward            | -1.4742362546676304   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000732421875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.622804325215982    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 252.72. Rollout time: 70.35, Training time: 182.34
Evaluating epoch 77
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 2193750.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.646515551464947    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.372639260222473    |
| train_0/fw_bonus          | -0.9995225831866265   |
| train_0/fw_loss           | 0.0035424092260655017 |
| train_0/mu_grads          | -0.06562691479921341  |
| train_0/mu_grads_std      | 0.5578424841165542    |
| train_0/mu_loss           | 5.311028262345731     |
| train_0/next_q            | -5.309254006358065    |
| train_0/q_grads           | -0.07734814714640378  |
| train_0/q_grads_std       | 0.5187543302774429    |
| train_0/q_loss            | 0.18928089244969698   |
| train_0/reward            | -0.6962334567499056   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004931640625        |
| train_0/target_q          | -5.603748254680012    |
| train_1/avg_q             | -3.6328044887806925   |
| train_1/current_q         | -3.6549347024826737   |
| train_1/fw_bonus          | -0.9830026313662529   |
| train_1/fw_loss           | 0.10357441902160644   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.654630011576226     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.6549347024826737   |
| train_1/q_grads           | -0.03163604643195868  |
| train_1/q_grads_std       | 0.24252797178924085   |
| train_1/q_loss            | 5.258250976679905     |
| train_1/reward            | -1.4739720131110516   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00107421875         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.6443166884334417   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 249.37. Rollout time: 70.37, Training time: 178.97
Evaluating epoch 78
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 2221875.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7848161842077848   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999963052773   |
| train_0/current_q         | -5.4212151999852765   |
| train_0/fw_bonus          | -0.9995253056287765   |
| train_0/fw_loss           | 0.003529110021190718  |
| train_0/mu_grads          | -0.0666062843054533   |
| train_0/mu_grads_std      | 0.5589676856994629    |
| train_0/mu_loss           | 5.357303803289606     |
| train_0/next_q            | -5.355985066155293    |
| train_0/q_grads           | -0.07849336806684733  |
| train_0/q_grads_std       | 0.5221932172775269    |
| train_0/q_loss            | 0.19330928809806208   |
| train_0/reward            | -0.6983222279690381   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004296875           |
| train_0/target_q          | -5.65553283144133     |
| train_1/avg_q             | -3.704450943788203    |
| train_1/current_q         | -3.788042359148703    |
| train_1/fw_bonus          | -0.9823173671960831   |
| train_1/fw_loss           | 0.1069252636283636    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.788070389492596     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.788042359148703    |
| train_1/q_grads           | -0.03163164844736457  |
| train_1/q_grads_std       | 0.2426064744591713    |
| train_1/q_loss            | 5.2586106427820996    |
| train_1/reward            | -1.4798305589451046   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007080078125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7861239157203124   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 257.18. Rollout time: 70.27, Training time: 186.89
Evaluating epoch 79
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 2250000.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.645725954628411    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999916783   |
| train_0/current_q         | -5.442666608916154    |
| train_0/fw_bonus          | -0.9995331794023514   |
| train_0/fw_loss           | 0.0034908915811683984 |
| train_0/mu_grads          | -0.06810597181320191  |
| train_0/mu_grads_std      | 0.5603656679391861    |
| train_0/mu_loss           | 5.380406799603824     |
| train_0/next_q            | -5.378962155543659    |
| train_0/q_grads           | -0.07896102853119373  |
| train_0/q_grads_std       | 0.524648965895176     |
| train_0/q_loss            | 0.1914805422520507    |
| train_0/reward            | -0.6996445215721906   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0048095703125       |
| train_0/target_q          | -5.677685439564399    |
| train_1/avg_q             | -3.709597008902867    |
| train_1/current_q         | -3.6538638750835775   |
| train_1/fw_bonus          | -0.9823228344321251   |
| train_1/fw_loss           | 0.10689850207418203   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.6536385361781445    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.6538638750835775   |
| train_1/q_grads           | -0.03163608238101005  |
| train_1/q_grads_std       | 0.24252733513712882   |
| train_1/q_loss            | 5.179573772982396     |
| train_1/reward            | -1.4578484305624442   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.6495930361199327   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 248.65. Rollout time: 69.71, Training time: 178.92
Evaluating epoch 80
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 2278125.0             |
| test/episodes             | 2025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999998341936   |
| test_1/avg_q              | -3.7224198760490146   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.99999992661457    |
| train_0/current_q         | -5.38814633033609     |
| train_0/fw_bonus          | -0.9995091021060943   |
| train_0/fw_loss           | 0.003607886657118797  |
| train_0/mu_grads          | -0.06915783416479826  |
| train_0/mu_grads_std      | 0.5628407165408135    |
| train_0/mu_loss           | 5.326459400770381     |
| train_0/next_q            | -5.322383664525103    |
| train_0/q_grads           | -0.08043039217591286  |
| train_0/q_grads_std       | 0.5278980553150177    |
| train_0/q_loss            | 0.19208321884610657   |
| train_0/reward            | -0.6990099201146223   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0054931640625       |
| train_0/target_q          | -5.6192601633497565   |
| train_1/avg_q             | -3.676857108656496    |
| train_1/current_q         | -3.7098531804446297   |
| train_1/fw_bonus          | -0.983357971906662    |
| train_1/fw_loss           | 0.10183673948049546   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.710293400690135     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7098531804446297   |
| train_1/q_grads           | -0.03163421973586082  |
| train_1/q_grads_std       | 0.24256048686802387   |
| train_1/q_loss            | 5.215790565835602     |
| train_1/reward            | -1.4773235206164828   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.719337660842251    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_80.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 252.56. Rollout time: 70.86, Training time: 181.67
Evaluating epoch 81
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 2306250.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7281331554904367   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999998897017   |
| train_0/current_q         | -5.440723602888443    |
| train_0/fw_bonus          | -0.9995116025209427   |
| train_0/fw_loss           | 0.003595708147622645  |
| train_0/mu_grads          | -0.06925705764442683  |
| train_0/mu_grads_std      | 0.5659784972667694    |
| train_0/mu_loss           | 5.375146884058384     |
| train_0/next_q            | -5.372706652851238    |
| train_0/q_grads           | -0.08131041377782822  |
| train_0/q_grads_std       | 0.5309157177805901    |
| train_0/q_loss            | 0.1937357566345303    |
| train_0/reward            | -0.7018798260491167   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046142578125       |
| train_0/target_q          | -5.674781775219834    |
| train_1/avg_q             | -3.7361346734539342   |
| train_1/current_q         | -3.724829129827981    |
| train_1/fw_bonus          | -0.9829469949007035   |
| train_1/fw_loss           | 0.10384643878787755   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.725012458127181     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.724829129827981    |
| train_1/q_grads           | -0.031633724458515644 |
| train_1/q_grads_std       | 0.24256932251155378   |
| train_1/q_loss            | 5.19175965914164      |
| train_1/reward            | -1.4670472266559955   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.728801012143214    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 249.75. Rollout time: 68.42, Training time: 181.31
Evaluating epoch 82
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 2334375.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.99999999999416    |
| test_1/avg_q              | -3.946478807531107    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999993417   |
| train_0/current_q         | -5.367702777649931    |
| train_0/fw_bonus          | -0.9994780004024506   |
| train_0/fw_loss           | 0.003758942027343437  |
| train_0/mu_grads          | -0.07015296332538128  |
| train_0/mu_grads_std      | 0.5676687061786652    |
| train_0/mu_loss           | 5.298100111484141     |
| train_0/next_q            | -5.296268240074061    |
| train_0/q_grads           | -0.08269278947263956  |
| train_0/q_grads_std       | 0.5338454261422158    |
| train_0/q_loss            | 0.19392630437445157   |
| train_0/reward            | -0.7010573593557637   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050048828125       |
| train_0/target_q          | -5.598894303672545    |
| train_1/avg_q             | -3.831132598127498    |
| train_1/current_q         | -3.937339998267248    |
| train_1/fw_bonus          | -0.9820156097412109   |
| train_1/fw_loss           | 0.10840084627270699   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.937800251675966     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.937339998267248    |
| train_1/q_grads           | -0.03162683611735702  |
| train_1/q_grads_std       | 0.24269334301352502   |
| train_1/q_loss            | 5.2102406469425375    |
| train_1/reward            | -1.4746625884879905   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001171875           |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.9461659988400797   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 243.52. Rollout time: 69.55, Training time: 173.94
Evaluating epoch 83
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 2362500.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999999999973   |
| test_1/avg_q              | -4.182598460454351    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999873583599   |
| train_0/current_q         | -5.402012279393945    |
| train_0/fw_bonus          | -0.9995014742016792   |
| train_0/fw_loss           | 0.0036448883824050427 |
| train_0/mu_grads          | -0.06957978196442127  |
| train_0/mu_grads_std      | 0.5704604804515838    |
| train_0/mu_loss           | 5.321590339529752     |
| train_0/next_q            | -5.318844038083973    |
| train_0/q_grads           | -0.0838760519400239   |
| train_0/q_grads_std       | 0.5369883030653       |
| train_0/q_loss            | 0.1944616257246063    |
| train_0/reward            | -0.7032663650927133   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.634611896404032    |
| train_1/avg_q             | -4.048996537005968    |
| train_1/current_q         | -4.180237565631304    |
| train_1/fw_bonus          | -0.9820680603384971   |
| train_1/fw_loss           | 0.10814431440085173   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.1803746878075625    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.180237565631304    |
| train_1/q_grads           | -0.031619249191135165 |
| train_1/q_grads_std       | 0.24283230528235436   |
| train_1/q_loss            | 5.3412937478522675    |
| train_1/reward            | -1.5057679211953654   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.183377473505405    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 251.40. Rollout time: 70.43, Training time: 180.95
Evaluating epoch 84
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 2390625.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.562458317359974    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999419561908   |
| train_0/current_q         | -5.468875284420945    |
| train_0/fw_bonus          | -0.9994566649198532   |
| train_0/fw_loss           | 0.0038625414716079833 |
| train_0/mu_grads          | -0.06912736222147942  |
| train_0/mu_grads_std      | 0.5727799847722054    |
| train_0/mu_loss           | 5.36866636583527      |
| train_0/next_q            | -5.364583430092561    |
| train_0/q_grads           | -0.08525998909026385  |
| train_0/q_grads_std       | 0.5403658047318458    |
| train_0/q_loss            | 0.19948329109250906   |
| train_0/reward            | -0.7086516757553909   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006005859375        |
| train_0/target_q          | -5.7017345426927495   |
| train_1/avg_q             | -4.335003531961947    |
| train_1/current_q         | -4.555930623187182    |
| train_1/fw_bonus          | -0.9817319065332413   |
| train_1/fw_loss           | 0.1097881069406867    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.556558904017954     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.555930623187182    |
| train_1/q_grads           | -0.03160802600905299  |
| train_1/q_grads_std       | 0.243042429164052     |
| train_1/q_loss            | 5.308562976425579     |
| train_1/reward            | -1.5026091200154041   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.570736034084144    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 241.14. Rollout time: 69.24, Training time: 171.87
Evaluating epoch 85
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 2418750.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.6402903631980985   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999989983   |
| train_0/current_q         | -5.447456280207789    |
| train_0/fw_bonus          | -0.999466535449028    |
| train_0/fw_loss           | 0.0038145935453940184 |
| train_0/mu_grads          | -0.06973924748599529  |
| train_0/mu_grads_std      | 0.5744745209813118    |
| train_0/mu_loss           | 5.36387357708812      |
| train_0/next_q            | -5.363038664743127    |
| train_0/q_grads           | -0.08678949605673551  |
| train_0/q_grads_std       | 0.5439443960785866    |
| train_0/q_loss            | 0.2013910886689793    |
| train_0/reward            | -0.7062518261511286   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0062744140625       |
| train_0/target_q          | -5.679796901147617    |
| train_1/avg_q             | -4.620105927274753    |
| train_1/current_q         | -4.6334071548549485   |
| train_1/fw_bonus          | -0.9804217845201493   |
| train_1/fw_loss           | 0.1161945566534996    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.633796018748614     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.6334071548549485   |
| train_1/q_grads           | -0.031605778355151416 |
| train_1/q_grads_std       | 0.2430851548910141    |
| train_1/q_loss            | 5.376613502242234     |
| train_1/reward            | -1.5181649930804269   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010009765625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.642683927287776    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 245.33. Rollout time: 70.58, Training time: 174.72
Evaluating epoch 86
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 2446875.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.717515931219454    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.43641137573207     |
| train_0/fw_bonus          | -0.9994914457201958   |
| train_0/fw_loss           | 0.0036936266405973583 |
| train_0/mu_grads          | -0.07000698540359736  |
| train_0/mu_grads_std      | 0.576758137345314     |
| train_0/mu_loss           | 5.360690865111368     |
| train_0/next_q            | -5.358300922215696    |
| train_0/q_grads           | -0.08740235343575478  |
| train_0/q_grads_std       | 0.5467172622680664    |
| train_0/q_loss            | 0.19593074332631982   |
| train_0/reward            | -0.7049215045350138   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0057861328125       |
| train_0/target_q          | -5.669217847662786    |
| train_1/avg_q             | -4.673324242104421    |
| train_1/current_q         | -4.71638531716748     |
| train_1/fw_bonus          | -0.9801215633749962   |
| train_1/fw_loss           | 0.1176626218482852    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.716813461309544     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.71638531716748     |
| train_1/q_grads           | -0.031603395193815234 |
| train_1/q_grads_std       | 0.24313071593642235   |
| train_1/q_loss            | 5.4004827310590375    |
| train_1/reward            | -1.513144277268293    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007568359375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.71627578758122     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 237.72. Rollout time: 69.76, Training time: 167.93
Evaluating epoch 87
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 2475000.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.574085252155108    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.449257744162569    |
| train_0/fw_bonus          | -0.999547490477562    |
| train_0/fw_loss           | 0.0034213638107758017 |
| train_0/mu_grads          | -0.07125771827995778  |
| train_0/mu_grads_std      | 0.5784283757209778    |
| train_0/mu_loss           | 5.386037965499777     |
| train_0/next_q            | -5.385040200941563    |
| train_0/q_grads           | -0.08851119261234999  |
| train_0/q_grads_std       | 0.5495158895850182    |
| train_0/q_loss            | 0.1962635163115123    |
| train_0/reward            | -0.7010799009942275   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0060546875          |
| train_0/target_q          | -5.685551563570968    |
| train_1/avg_q             | -4.642941059962342    |
| train_1/current_q         | -4.5782009471658025   |
| train_1/fw_bonus          | -0.980167044699192    |
| train_1/fw_loss           | 0.11744019649922847   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.578090704658717     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.5782009471658025   |
| train_1/q_grads           | -0.03160737780854106  |
| train_1/q_grads_std       | 0.24305473119020463   |
| train_1/q_loss            | 5.336347818108685     |
| train_1/reward            | -1.4923784460581373   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.5778093381653      |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 246.10. Rollout time: 71.31, Training time: 174.76
Evaluating epoch 88
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 2503125.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.297672026629714    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.418484689920413    |
| train_0/fw_bonus          | -0.9995433107018471   |
| train_0/fw_loss           | 0.003441738500259817  |
| train_0/mu_grads          | -0.07274527363479137  |
| train_0/mu_grads_std      | 0.5794342637062073    |
| train_0/mu_loss           | 5.357277396746026     |
| train_0/next_q            | -5.356712089293923    |
| train_0/q_grads           | -0.08941764123737812  |
| train_0/q_grads_std       | 0.5524851083755493    |
| train_0/q_loss            | 0.19210257678577322   |
| train_0/reward            | -0.6992345418279001   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0063720703125       |
| train_0/target_q          | -5.651046456136597    |
| train_1/avg_q             | -4.438564937297231    |
| train_1/current_q         | -4.303101354329774    |
| train_1/fw_bonus          | -0.9797706082463264   |
| train_1/fw_loss           | 0.11937869805842638   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.30302413649376      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.303101354329774    |
| train_1/q_grads           | -0.03161551542580128  |
| train_1/q_grads_std       | 0.2429016064852476    |
| train_1/q_loss            | 5.30368273746093      |
| train_1/reward            | -1.491215876960632    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008544921875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.305899026590607    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 244.57. Rollout time: 70.29, Training time: 174.25
Evaluating epoch 89
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 2531250.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -4.14831572799879     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4024772502905405   |
| train_0/fw_bonus          | -0.9995803013443947   |
| train_0/fw_loss           | 0.0032620686339214443 |
| train_0/mu_grads          | -0.07510347347706556  |
| train_0/mu_grads_std      | 0.5831687763333321    |
| train_0/mu_loss           | 5.329949401925752     |
| train_0/next_q            | -5.3270599120302915   |
| train_0/q_grads           | -0.09065972175449133  |
| train_0/q_grads_std       | 0.555555047094822     |
| train_0/q_loss            | 0.18863318369438437   |
| train_0/reward            | -0.6966285247086489   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00537109375         |
| train_0/target_q          | -5.635591288490815    |
| train_1/avg_q             | -4.23940869265624     |
| train_1/current_q         | -4.144428984355035    |
| train_1/fw_bonus          | -0.9797908723354339   |
| train_1/fw_loss           | 0.11927962191402912   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 5.144898810349392     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.144428984355035    |
| train_1/q_grads           | -0.03162035020068288  |
| train_1/q_grads_std       | 0.2428119856864214    |
| train_1/q_loss            | 5.271747525204592     |
| train_1/reward            | -1.485598566878616    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.14927545595683     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 242.54. Rollout time: 68.66, Training time: 173.85
Evaluating epoch 90
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 2559375.0             |
| test/episodes             | 2275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9675068654127803   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.393329668178505    |
| train_0/fw_bonus          | -0.9995416656136513   |
| train_0/fw_loss           | 0.0034496807085815815 |
| train_0/mu_grads          | -0.07534309811890125  |
| train_0/mu_grads_std      | 0.5862407997250557    |
| train_0/mu_loss           | 5.330753082922828     |
| train_0/next_q            | -5.32961327937325     |
| train_0/q_grads           | -0.09143678080290556  |
| train_0/q_grads_std       | 0.5580940619111061    |
| train_0/q_loss            | 0.19040370796234926   |
| train_0/reward            | -0.6968167323990201   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00556640625         |
| train_0/target_q          | -5.626057845765051    |
| train_1/avg_q             | -4.070829878973587    |
| train_1/current_q         | -3.9694667635449186   |
| train_1/fw_bonus          | -0.9797045737504959   |
| train_1/fw_loss           | 0.11970163322985172   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.96938360160317      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9694667635449186   |
| train_1/q_grads           | -0.03162581529468298  |
| train_1/q_grads_std       | 0.24271188378334047   |
| train_1/q_loss            | 5.253903879008448     |
| train_1/reward            | -1.469222408119822    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.958925522921075    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_90.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 243.17. Rollout time: 69.79, Training time: 173.35
Evaluating epoch 91
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 2587500.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8625364841511685   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.396764774051108    |
| train_0/fw_bonus          | -0.9995729595422744   |
| train_0/fw_loss           | 0.0032977457623928784 |
| train_0/mu_grads          | -0.0765488788485527   |
| train_0/mu_grads_std      | 0.5898748964071274    |
| train_0/mu_loss           | 5.330278645871399     |
| train_0/next_q            | -5.328980740485442    |
| train_0/q_grads           | -0.09390179775655269  |
| train_0/q_grads_std       | 0.5607459992170334    |
| train_0/q_loss            | 0.19426930060332817   |
| train_0/reward            | -0.6978089342897874   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00546875            |
| train_0/target_q          | -5.628815123567106    |
| train_1/avg_q             | -3.899029095498621    |
| train_1/current_q         | -3.8478745059747097   |
| train_1/fw_bonus          | -0.980019673705101    |
| train_1/fw_loss           | 0.1181609071791172    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.8483381560502155    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8478745059747097   |
| train_1/q_grads           | -0.03162970552220941  |
| train_1/q_grads_std       | 0.24264142997562885   |
| train_1/q_loss            | 5.236646996966906     |
| train_1/reward            | -1.4862988937355113   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8630030578700243   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 241.85. Rollout time: 70.14, Training time: 171.69
Evaluating epoch 92
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 2615625.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7162165618491234   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.414241222296779    |
| train_0/fw_bonus          | -0.9995649367570877   |
| train_0/fw_loss           | 0.003336721519008279  |
| train_0/mu_grads          | -0.07847769502550364  |
| train_0/mu_grads_std      | 0.592588460445404     |
| train_0/mu_loss           | 5.333230081702974     |
| train_0/next_q            | -5.331557597073115    |
| train_0/q_grads           | -0.09603466223925353  |
| train_0/q_grads_std       | 0.5636006444692612    |
| train_0/q_loss            | 0.19478041048042685   |
| train_0/reward            | -0.6997702543056221   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0055419921875       |
| train_0/target_q          | -5.648594002390427    |
| train_1/avg_q             | -3.7955909349531174   |
| train_1/current_q         | -3.706647825059645    |
| train_1/fw_bonus          | -0.9808776617050171   |
| train_1/fw_loss           | 0.11396532692015171   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.7067965427784975    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.706647825059645    |
| train_1/q_grads           | -0.031634325813502076 |
| train_1/q_grads_std       | 0.24255859442055225   |
| train_1/q_loss            | 5.2047174132325695    |
| train_1/reward            | -1.4755950829698121   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.718776324687094    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 249.65. Rollout time: 71.49, Training time: 178.12
Evaluating epoch 93
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 93                    |
| policy/steps              | 2643750.0             |
| test/episodes             | 2350.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.668056901262275    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.498051242466129    |
| train_0/fw_bonus          | -0.999573615193367    |
| train_0/fw_loss           | 0.003294529882259667  |
| train_0/mu_grads          | -0.07937998864799738  |
| train_0/mu_grads_std      | 0.5952443540096283    |
| train_0/mu_loss           | 5.428193696357918     |
| train_0/next_q            | -5.4263691831535334   |
| train_0/q_grads           | -0.09714513588696719  |
| train_0/q_grads_std       | 0.5667925611138344    |
| train_0/q_loss            | 0.19482429902819812   |
| train_0/reward            | -0.7027897339183256   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0053466796875       |
| train_0/target_q          | -5.735519385730146    |
| train_1/avg_q             | -3.6999633711147695   |
| train_1/current_q         | -3.686020215986251    |
| train_1/fw_bonus          | -0.9811673298478126   |
| train_1/fw_loss           | 0.11254895739257335   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.685109908554274     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.686020215986251    |
| train_1/q_grads           | -0.03163501070812345  |
| train_1/q_grads_std       | 0.24254639446735382   |
| train_1/q_loss            | 5.2566355092292225    |
| train_1/reward            | -1.4632643210374225   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.6620234673689582   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 245.74. Rollout time: 69.62, Training time: 176.09
Evaluating epoch 94
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 94                    |
| policy/steps              | 2671875.0             |
| test/episodes             | 2375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.672686257785744    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999282025   |
| train_0/current_q         | -5.489294044931055    |
| train_0/fw_bonus          | -0.9995573073625564   |
| train_0/fw_loss           | 0.003373703098623082  |
| train_0/mu_grads          | -0.08005735464394093  |
| train_0/mu_grads_std      | 0.5976224467158318    |
| train_0/mu_loss           | 5.420637713297157     |
| train_0/next_q            | -5.420112157395552    |
| train_0/q_grads           | -0.09908820558339357  |
| train_0/q_grads_std       | 0.5694267630577088    |
| train_0/q_loss            | 0.19854718789866194   |
| train_0/reward            | -0.703697111565998    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0042236328125       |
| train_0/target_q          | -5.7255336633915395   |
| train_1/avg_q             | -3.667029308403649    |
| train_1/current_q         | -3.6812615167839366   |
| train_1/fw_bonus          | -0.9814851343631744   |
| train_1/fw_loss           | 0.11099491231143474   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.6811379077851685    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.6812615167839366   |
| train_1/q_grads           | -0.031635168567299844 |
| train_1/q_grads_std       | 0.24254358261823655   |
| train_1/q_loss            | 5.22432687044626      |
| train_1/reward            | -1.4685257625525991   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.676162197222111    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 252.51. Rollout time: 70.85, Training time: 181.63
Evaluating epoch 95
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 95                    |
| policy/steps              | 2700000.0             |
| test/episodes             | 2400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8487882944960607   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.465392662280686    |
| train_0/fw_bonus          | -0.9995631292462349   |
| train_0/fw_loss           | 0.0033454223826993256 |
| train_0/mu_grads          | -0.08138369619846345  |
| train_0/mu_grads_std      | 0.5996458113193512    |
| train_0/mu_loss           | 5.400278342308307     |
| train_0/next_q            | -5.399566302434925    |
| train_0/q_grads           | -0.10021337457001209  |
| train_0/q_grads_std       | 0.5726884886622429    |
| train_0/q_loss            | 0.19495412205232415   |
| train_0/reward            | -0.70385871420076     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0055419921875       |
| train_0/target_q          | -5.700817384260519    |
| train_1/avg_q             | -3.76300056741504     |
| train_1/current_q         | -3.8376797680220713   |
| train_1/fw_bonus          | -0.9813466385006905   |
| train_1/fw_loss           | 0.11167207714170217   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.8381252658350835    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8376797680220713   |
| train_1/q_grads           | -0.03163003521040082  |
| train_1/q_grads_std       | 0.24263548851013184   |
| train_1/q_loss            | 5.305606425225676     |
| train_1/reward            | -1.5030268345253717   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8496358501348618   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 250.70. Rollout time: 69.14, Training time: 181.54
Evaluating epoch 96
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 96                    |
| policy/steps              | 2728125.0             |
| test/episodes             | 2425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7728773486432994   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.436032836365314    |
| train_0/fw_bonus          | -0.9995155990123749   |
| train_0/fw_loss           | 0.0035762589890509845 |
| train_0/mu_grads          | -0.07966328579932451  |
| train_0/mu_grads_std      | 0.6021884769201279    |
| train_0/mu_loss           | 5.370836034855104     |
| train_0/next_q            | -5.3691879774602      |
| train_0/q_grads           | -0.1018973832949996   |
| train_0/q_grads_std       | 0.5756850615143776    |
| train_0/q_loss            | 0.19561395135150966   |
| train_0/reward            | -0.7026874920229602   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0054443359375       |
| train_0/target_q          | -5.669415649311719    |
| train_1/avg_q             | -3.8285055871320406   |
| train_1/current_q         | -3.7791512795593976   |
| train_1/fw_bonus          | -0.9799481019377708   |
| train_1/fw_loss           | 0.11851081363856793   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.778732900877562     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7791512795593976   |
| train_1/q_grads           | -0.031631939392536876 |
| train_1/q_grads_std       | 0.24260126277804375   |
| train_1/q_loss            | 5.336265063573514     |
| train_1/reward            | -1.4914388964236422   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7663749062585268   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 249.07. Rollout time: 70.29, Training time: 178.75
Evaluating epoch 97
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 97                    |
| policy/steps              | 2756250.0             |
| test/episodes             | 2450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8239390284700225   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.414362969411798    |
| train_0/fw_bonus          | -0.9995172768831253   |
| train_0/fw_loss           | 0.0035681741836015137 |
| train_0/mu_grads          | -0.07958457916975022  |
| train_0/mu_grads_std      | 0.6031913191080094    |
| train_0/mu_loss           | 5.347206515241524     |
| train_0/next_q            | -5.346451739781412    |
| train_0/q_grads           | -0.10346536543220282  |
| train_0/q_grads_std       | 0.578692838549614     |
| train_0/q_loss            | 0.19328619527614951   |
| train_0/reward            | -0.701662933651096    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004931640625        |
| train_0/target_q          | -5.645933417062433    |
| train_1/avg_q             | -3.7810236942257545   |
| train_1/current_q         | -3.8316963992854496   |
| train_1/fw_bonus          | -0.9793499305844307   |
| train_1/fw_loss           | 0.12143586501479149   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.8314890033443225    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8316963992854496   |
| train_1/q_grads           | -0.03163022892549634  |
| train_1/q_grads_std       | 0.2426319982856512    |
| train_1/q_loss            | 5.346262617919661     |
| train_1/reward            | -1.4969869761807786   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8227156551630435   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 252.61. Rollout time: 70.35, Training time: 182.23
Evaluating epoch 98
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 2784375.0             |
| test/episodes             | 2475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.8463916252992125   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.419308279595027    |
| train_0/fw_bonus          | -0.9994736909866333   |
| train_0/fw_loss           | 0.003779832855798304  |
| train_0/mu_grads          | -0.07923509441316127  |
| train_0/mu_grads_std      | 0.6035824522376061    |
| train_0/mu_loss           | 5.345188105931941     |
| train_0/next_q            | -5.3446734326758545   |
| train_0/q_grads           | -0.10518305283039808  |
| train_0/q_grads_std       | 0.5823788434267044    |
| train_0/q_loss            | 0.194756734320293     |
| train_0/reward            | -0.7027397790399845   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005029296875        |
| train_0/target_q          | -5.651044267916295    |
| train_1/avg_q             | -3.8519443325550613   |
| train_1/current_q         | -3.8314490610676915   |
| train_1/fw_bonus          | -0.9779321640729904   |
| train_1/fw_loss           | 0.1283686736598611    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.832058393118456     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8314490610676915   |
| train_1/q_grads           | -0.03163023693487048  |
| train_1/q_grads_std       | 0.24263185411691665   |
| train_1/q_loss            | 5.262605390553611     |
| train_1/reward            | -1.495679946650489    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8497915189976544   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 246.66. Rollout time: 69.62, Training time: 177.00
Evaluating epoch 99
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 2812500.0             |
| test/episodes             | 2500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7183751311599287   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.415411104426923    |
| train_0/fw_bonus          | -0.9994598895311355   |
| train_0/fw_loss           | 0.0038468625920359046 |
| train_0/mu_grads          | -0.08028938863426446  |
| train_0/mu_grads_std      | 0.6058646306395531    |
| train_0/mu_loss           | 5.347767849658505     |
| train_0/next_q            | -5.34585539834589     |
| train_0/q_grads           | -0.10628107283264399  |
| train_0/q_grads_std       | 0.5860198974609375    |
| train_0/q_loss            | 0.19558236455304423   |
| train_0/reward            | -0.7018661803806026   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049072265625       |
| train_0/target_q          | -5.6503200126969535   |
| train_1/avg_q             | -3.808729994762559    |
| train_1/current_q         | -3.712046509630312    |
| train_1/fw_bonus          | -0.9774119406938553   |
| train_1/fw_loss           | 0.1309125056490302    |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.7124361188357025    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.712046509630312    |
| train_1/q_grads           | -0.031634146627038714 |
| train_1/q_grads_std       | 0.24256178140640258   |
| train_1/q_loss            | 5.309675858430142     |
| train_1/reward            | -1.5010106580644789   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.722517418800765    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 100
Time for epoch 100: 257.99. Rollout time: 72.45, Training time: 185.52
Evaluating epoch 100
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 100                   |
| policy/steps              | 2840625.0             |
| test/episodes             | 2525.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.669461682752533    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10100.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.44078036385006     |
| train_0/fw_bonus          | -0.9994545444846153   |
| train_0/fw_loss           | 0.003872889030026272  |
| train_0/mu_grads          | -0.08016523029655218  |
| train_0/mu_grads_std      | 0.6069725677371025    |
| train_0/mu_loss           | 5.381288293790243     |
| train_0/next_q            | -5.379392442209261    |
| train_0/q_grads           | -0.10676467139273882  |
| train_0/q_grads_std       | 0.5893923193216324    |
| train_0/q_loss            | 0.19803927401593469   |
| train_0/reward            | -0.7007892826004536   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004248046875        |
| train_0/target_q          | -5.676160028809561    |
| train_1/avg_q             | -3.6935351030649      |
| train_1/current_q         | -3.67754111427642     |
| train_1/fw_bonus          | -0.9773351565003395   |
| train_1/fw_loss           | 0.13128800075501204   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.677234664172245     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.67754111427642     |
| train_1/q_grads           | -0.03163529224693775  |
| train_1/q_grads_std       | 0.2425413779914379    |
| train_1/q_loss            | 5.186697677608212     |
| train_1/reward            | -1.4558672830338764   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.669458973004603    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_100.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 101
Time for epoch 101: 251.26. Rollout time: 69.23, Training time: 182.00
Evaluating epoch 101
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 101                   |
| policy/steps              | 2868750.0             |
| test/episodes             | 2550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.752327380816361    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10200.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.453007921347741    |
| train_0/fw_bonus          | -0.9994401186704636   |
| train_0/fw_loss           | 0.003942937182728201  |
| train_0/mu_grads          | -0.08035360928624868  |
| train_0/mu_grads_std      | 0.6079269081354142    |
| train_0/mu_loss           | 5.386694448414731     |
| train_0/next_q            | -5.384624584491019    |
| train_0/q_grads           | -0.1074607152491808   |
| train_0/q_grads_std       | 0.5925173565745354    |
| train_0/q_loss            | 0.1990518027160043    |
| train_0/reward            | -0.7032967206403555   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00380859375         |
| train_0/target_q          | -5.687902780424679    |
| train_1/avg_q             | -3.69045929105365     |
| train_1/current_q         | -3.740966394521119    |
| train_1/fw_bonus          | -0.9782597467303276   |
| train_1/fw_loss           | 0.12676678635179997   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.741590218299315     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.740966394521119    |
| train_1/q_grads           | -0.03163319239392877  |
| train_1/q_grads_std       | 0.24257882833480834   |
| train_1/q_loss            | 5.2571171478521785    |
| train_1/reward            | -1.4939760647474032   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.7599699417874306   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 102
Time for epoch 102: 253.13. Rollout time: 71.01, Training time: 182.10
Evaluating epoch 102
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 102                   |
| policy/steps              | 2896875.0             |
| test/episodes             | 2575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.6286058770863137   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10300.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.405584332604885    |
| train_0/fw_bonus          | -0.9994594067335129   |
| train_0/fw_loss           | 0.0038491986109875143 |
| train_0/mu_grads          | -0.08105235360562801  |
| train_0/mu_grads_std      | 0.6100025355815888    |
| train_0/mu_loss           | 5.338909871429439     |
| train_0/next_q            | -5.335732021804867    |
| train_0/q_grads           | -0.10759619008749724  |
| train_0/q_grads_std       | 0.5960840582847595    |
| train_0/q_loss            | 0.19460919695208914   |
| train_0/reward            | -0.7007673069849261   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004248046875        |
| train_0/target_q          | -5.637861544432478    |
| train_1/avg_q             | -3.7113092440886284   |
| train_1/current_q         | -3.6309158734926568   |
| train_1/fw_bonus          | -0.9772583782672882   |
| train_1/fw_loss           | 0.13166344128549098   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.630898918776376     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.6309158734926568   |
| train_1/q_grads           | -0.031636851746588944 |
| train_1/q_grads_std       | 0.2425136923789978    |
| train_1/q_loss            | 5.2213489475267965    |
| train_1/reward            | -1.4711609249701723   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.6315891943644116   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 103
Time for epoch 103: 248.72. Rollout time: 70.18, Training time: 178.52
Evaluating epoch 103
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 103                   |
| policy/steps              | 2925000.0             |
| test/episodes             | 2600.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.7644461805173703   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10400.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.42769389343008     |
| train_0/fw_bonus          | -0.9994417801499367   |
| train_0/fw_loss           | 0.003934900311287492  |
| train_0/mu_grads          | -0.08062222395092249  |
| train_0/mu_grads_std      | 0.6128047347068787    |
| train_0/mu_loss           | 5.350807375195371     |
| train_0/next_q            | -5.348423235067285    |
| train_0/q_grads           | -0.1089032132178545   |
| train_0/q_grads_std       | 0.5987983733415604    |
| train_0/q_loss            | 0.19733101066297512   |
| train_0/reward            | -0.7036149306077277   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050048828125       |
| train_0/target_q          | -5.661640049626759    |
| train_1/avg_q             | -3.6736778921197466   |
| train_1/current_q         | -3.7680920572792616   |
| train_1/fw_bonus          | -0.9764002367854119   |
| train_1/fw_loss           | 0.13585966341197492   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.768099149561185     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.7680920572792616   |
| train_1/q_grads           | -0.03163230130448937  |
| train_1/q_grads_std       | 0.24259477369487287   |
| train_1/q_loss            | 5.242606276952634     |
| train_1/reward            | -1.4766034413849412   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.768769360814852    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 104
Time for epoch 104: 250.75. Rollout time: 71.32, Training time: 179.40
Evaluating epoch 104
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 104                   |
| policy/steps              | 2953125.0             |
| test/episodes             | 2625.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9159047230837425   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10500.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999998856   |
| train_0/current_q         | -5.435016981061887    |
| train_0/fw_bonus          | -0.9994300395250321   |
| train_0/fw_loss           | 0.003991905151633546  |
| train_0/mu_grads          | -0.0813973929733038   |
| train_0/mu_grads_std      | 0.615043367445469     |
| train_0/mu_loss           | 5.356589787560031     |
| train_0/next_q            | -5.353610143933018    |
| train_0/q_grads           | -0.10889434292912484  |
| train_0/q_grads_std       | 0.6011175855994224    |
| train_0/q_loss            | 0.19850819448436482   |
| train_0/reward            | -0.7062579884019214   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0048583984375       |
| train_0/target_q          | -5.668473739789604    |
| train_1/avg_q             | -3.811012651552326    |
| train_1/current_q         | -3.9078412309107593   |
| train_1/fw_bonus          | -0.9747459173202515   |
| train_1/fw_loss           | 0.14394918754696845   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.908193114182643     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.9078412309107593   |
| train_1/q_grads           | -0.03162777721881867  |
| train_1/q_grads_std       | 0.24267627149820328   |
| train_1/q_loss            | 5.210219217305443     |
| train_1/reward            | -1.4686839951878938   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.910740614590604    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 105
Time for epoch 105: 250.01. Rollout time: 70.93, Training time: 179.05
Evaluating epoch 105
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 105                   |
| policy/steps              | 2981250.0             |
| test/episodes             | 2650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.895148478996895    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10600.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999999797   |
| train_0/current_q         | -5.432781173303591    |
| train_0/fw_bonus          | -0.9994377225637436   |
| train_0/fw_loss           | 0.003954629955114797  |
| train_0/mu_grads          | -0.0827537963166833   |
| train_0/mu_grads_std      | 0.6171219915151596    |
| train_0/mu_loss           | 5.352697779601207     |
| train_0/next_q            | -5.350378397232798    |
| train_0/q_grads           | -0.10921248700469732  |
| train_0/q_grads_std       | 0.6037702783942223    |
| train_0/q_loss            | 0.19733687512616505   |
| train_0/reward            | -0.7068721773081051   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046630859375       |
| train_0/target_q          | -5.664794331283839    |
| train_1/avg_q             | -3.862166156509703    |
| train_1/current_q         | -3.887326774840557    |
| train_1/fw_bonus          | -0.9747968256473541   |
| train_1/fw_loss           | 0.14370025619864463   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.88761446621802      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.887326774840557    |
| train_1/q_grads           | -0.03162843463942409  |
| train_1/q_grads_std       | 0.2426643744111061    |
| train_1/q_loss            | 5.183887585063706     |
| train_1/reward            | -1.4647177503356943   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8942423259166645   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 106
Time for epoch 106: 245.58. Rollout time: 69.78, Training time: 175.77
Evaluating epoch 106
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 106                   |
| policy/steps              | 3009375.0             |
| test/episodes             | 2675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999999980227   |
| test_1/avg_q              | -3.8384284055282345   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10700.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999998975172   |
| train_0/current_q         | -5.431651454082834    |
| train_0/fw_bonus          | -0.9994552105665206   |
| train_0/fw_loss           | 0.0038696870789863167 |
| train_0/mu_grads          | -0.08443308435380459  |
| train_0/mu_grads_std      | 0.6172040358185769    |
| train_0/mu_loss           | 5.348693681018512     |
| train_0/next_q            | -5.3451967323580885   |
| train_0/q_grads           | -0.10918332114815713  |
| train_0/q_grads_std       | 0.605230237543583     |
| train_0/q_loss            | 0.19619004262649978   |
| train_0/reward            | -0.707576721618534    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0054931640625       |
| train_0/target_q          | -5.663552738187919    |
| train_1/avg_q             | -3.8751111382363432   |
| train_1/current_q         | -3.8307922360708546   |
| train_1/fw_bonus          | -0.9749260127544404   |
| train_1/fw_loss           | 0.14306860603392124   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.830674176462135     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8307922360708546   |
| train_1/q_grads           | -0.031630258448421954 |
| train_1/q_grads_std       | 0.2426314704120159    |
| train_1/q_loss            | 5.127302099975568     |
| train_1/reward            | -1.4479854608325695   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.8356639406511652   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 107
Time for epoch 107: 255.12. Rollout time: 71.97, Training time: 183.12
Evaluating epoch 107
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102
-----------------------------------------------------
| epoch                     | 107                   |
| policy/steps              | 3037500.0             |
| test/episodes             | 2700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.832385883108993    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10800.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999954177   |
| train_0/current_q         | -5.471662163922359    |
| train_0/fw_bonus          | -0.9994679406285286   |
| train_0/fw_loss           | 0.003807817952474579  |
| train_0/mu_grads          | -0.08614374324679375  |
| train_0/mu_grads_std      | 0.6181398972868919    |
| train_0/mu_loss           | 5.389284563931073     |
| train_0/next_q            | -5.386584103858628    |
| train_0/q_grads           | -0.11043112762272358  |
| train_0/q_grads_std       | 0.6080084249377251    |
| train_0/q_loss            | 0.1968460318667388    |
| train_0/reward            | -0.7081934412257397   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0056640625          |
| train_0/target_q          | -5.7058999872641305   |
| train_1/avg_q             | -3.850700169259072    |
| train_1/current_q         | -3.8297075419050883   |
| train_1/fw_bonus          | -0.9751178026199341   |
| train_1/fw_loss           | 0.14213071949779987   |
| train_1/mu_grads          | -0.013251317664980888 |
| train_1/mu_grads_std      | 0.33318838477134705   |
| train_1/mu_loss           | 4.829924520995393     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.8297075419050883   |
| train_1/q_grads           | -0.0316302933730185   |
| train_1/q_grads_std       | 0.2426308397203684    |
| train_1/q_loss            | 5.140909486285496     |
| train_1/reward            | -1.4511697402071149   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -3.833882297808521    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 108
