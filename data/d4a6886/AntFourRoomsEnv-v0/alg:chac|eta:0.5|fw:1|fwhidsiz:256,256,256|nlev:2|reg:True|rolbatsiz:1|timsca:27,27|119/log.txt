Starting process id: 69568
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f8d517faf80>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 427.82. Rollout time: 219.16, Training time: 208.63
Evaluating epoch 0
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 91034.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -14.045993060628776    |
| test_1/avg_q              | -7.773105468590419     |
| test_1/n_subgoals         | 676.0                  |
| test_1/subgoal_succ_rate  | 0.0014792899408284023  |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -6.462801542151963     |
| train_0/current_q         | -6.237643967065814     |
| train_0/fw_bonus          | -0.9938208237290382    |
| train_0/fw_loss           | 0.029486463451758028   |
| train_0/mu_grads          | -0.0005330625601345674 |
| train_0/mu_grads_std      | 0.152187467738986      |
| train_0/mu_loss           | 6.0882932561891865     |
| train_0/next_q            | -6.077803174396797     |
| train_0/q_grads           | -0.0028035697294399144 |
| train_0/q_grads_std       | 0.11191075835376978    |
| train_0/q_loss            | 0.2444858679963752     |
| train_0/reward            | -0.7182116805561236    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0002685546875        |
| train_0/target_q          | -6.353142919413011     |
| train_1/avg_q             | -6.920903153696193     |
| train_1/current_q         | -6.013244820287429     |
| train_1/fw_bonus          | -0.9888451918959618    |
| train_1/fw_loss           | 0.063260892406106      |
| train_1/mu_grads          | -0.01158533412963152   |
| train_1/mu_grads_std      | 0.13372812382876872    |
| train_1/mu_loss           | 4.626260059286338      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.081597520129838     |
| train_1/q_grads           | 0.017821823619306086   |
| train_1/q_grads_std       | 0.109865996055305      |
| train_1/q_loss            | 1.5368309272545482     |
| train_1/reward            | -2.1161755231354618    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0045166015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0014814814814814814  |
| train_1/target_q          | -5.980570671900412     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 373.62. Rollout time: 210.20, Training time: 163.39
Evaluating epoch 1
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 181999.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -25.897282494961726    |
| test_1/avg_q              | -9.839608626873684     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -19.914741079272172    |
| train_0/current_q         | -8.240169792459092     |
| train_0/fw_bonus          | -0.9963364973664284    |
| train_0/fw_loss           | 0.017720269877463578   |
| train_0/mu_grads          | -0.010509287472814322  |
| train_0/mu_grads_std      | 0.19701174162328244    |
| train_0/mu_loss           | 8.138607212671184      |
| train_0/next_q            | -8.134918444932287     |
| train_0/q_grads           | -0.0014654757222160697 |
| train_0/q_grads_std       | 0.12805283591151237    |
| train_0/q_loss            | 0.31598864040809466    |
| train_0/reward            | -0.7165886584116379    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0015869140625        |
| train_0/target_q          | -8.324245695112056     |
| train_1/avg_q             | -11.75441930474679     |
| train_1/current_q         | -6.623340021629244     |
| train_1/fw_bonus          | -0.9865525662899017    |
| train_1/fw_loss           | 0.07260858491063119    |
| train_1/mu_grads          | -0.02321584546007216   |
| train_1/mu_grads_std      | 0.15565636157989501    |
| train_1/mu_loss           | 5.209130048228256      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.818351991738444     |
| train_1/q_grads           | 0.009069431805983186   |
| train_1/q_grads_std       | 0.12254650015383958    |
| train_1/q_loss            | 0.8381473574138528     |
| train_1/reward            | -2.1747826331666147    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0024658203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.003703703703703704   |
| train_1/target_q          | -6.604539461579376     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 371.23. Rollout time: 208.25, Training time: 162.96
Evaluating epoch 2
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 273062.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.904393521821966    |
| test_1/avg_q              | -12.137602125443001    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -22.88292838206293     |
| train_0/current_q         | -7.123315678883758     |
| train_0/fw_bonus          | -0.9972598269581795    |
| train_0/fw_loss           | 0.013401769567281008   |
| train_0/mu_grads          | -0.009325070632621646  |
| train_0/mu_grads_std      | 0.23097399696707727    |
| train_0/mu_loss           | 7.034750631809364      |
| train_0/next_q            | -7.039825108338422     |
| train_0/q_grads           | -0.003467475844081491  |
| train_0/q_grads_std       | 0.13853755220770836    |
| train_0/q_loss            | 0.294468536567854      |
| train_0/reward            | -0.7151948488237394    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00546875             |
| train_0/target_q          | -7.270169549204842     |
| train_1/avg_q             | -13.206669378901463    |
| train_1/current_q         | -7.583889161287397     |
| train_1/fw_bonus          | -0.9844155535101891    |
| train_1/fw_loss           | 0.08132188823074102    |
| train_1/mu_grads          | -0.03314443388953805   |
| train_1/mu_grads_std      | 0.18122028075158597    |
| train_1/mu_loss           | 6.024205312601059      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.1505905898331275    |
| train_1/q_grads           | -0.0004936467055813409 |
| train_1/q_grads_std       | 0.13357595093548297    |
| train_1/q_loss            | 0.786821791352752      |
| train_1/reward            | -2.1016193938710783    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001806640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0011111111111111111  |
| train_1/target_q          | -7.587644936861014     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 364.98. Rollout time: 208.70, Training time: 156.26
Evaluating epoch 3
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 364187.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999985812796    |
| test_1/avg_q              | -13.292026693774392    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.73962899512755     |
| train_0/current_q         | -8.87437482579313      |
| train_0/fw_bonus          | -0.9978304296731949    |
| train_0/fw_loss           | 0.010732928104698659   |
| train_0/mu_grads          | -0.011206770176067948  |
| train_0/mu_grads_std      | 0.24921258129179477    |
| train_0/mu_loss           | 8.827979907025286      |
| train_0/next_q            | -8.832187117913186     |
| train_0/q_grads           | -0.0007266817294294015 |
| train_0/q_grads_std       | 0.1520645823329687     |
| train_0/q_loss            | 0.24020125368130354    |
| train_0/reward            | -0.7091202918483759    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0233154296875        |
| train_0/target_q          | -9.009059643309199     |
| train_1/avg_q             | -13.29590212402496     |
| train_1/current_q         | -7.2756544255766915    |
| train_1/fw_bonus          | -0.9833136051893234    |
| train_1/fw_loss           | 0.08581479210406542    |
| train_1/mu_grads          | -0.03930192403495312   |
| train_1/mu_grads_std      | 0.20368259251117707    |
| train_1/mu_loss           | 5.749649626365564      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.754625983746922     |
| train_1/q_grads           | -0.006318218575324863  |
| train_1/q_grads_std       | 0.14528644755482673    |
| train_1/q_loss            | 0.40860163557481516    |
| train_1/reward            | -2.090033273069275     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0012939453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.276367577277417     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 370.09. Rollout time: 207.18, Training time: 162.88
Evaluating epoch 4
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 455312.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -10.2660122063856      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.913105166251626    |
| train_0/current_q         | -8.735883349008068     |
| train_0/fw_bonus          | -0.9980840757489204    |
| train_0/fw_loss           | 0.009546575602144003   |
| train_0/mu_grads          | -0.009727422008290887  |
| train_0/mu_grads_std      | 0.26475696712732316    |
| train_0/mu_loss           | 8.693989733608921      |
| train_0/next_q            | -8.689215284719433     |
| train_0/q_grads           | -0.0006603476052987389 |
| train_0/q_grads_std       | 0.1572927739471197     |
| train_0/q_loss            | 0.19359913744090718    |
| train_0/reward            | -0.7051699675823329    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0283447265625        |
| train_0/target_q          | -8.85204569854504      |
| train_1/avg_q             | -12.251237489635312    |
| train_1/current_q         | -3.192512949583404     |
| train_1/fw_bonus          | -0.9819376230239868    |
| train_1/fw_loss           | 0.09142516143620014    |
| train_1/mu_grads          | -0.04513242095708847   |
| train_1/mu_grads_std      | 0.2127980377525091     |
| train_1/mu_loss           | 11.200141746448308     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.180078776230614     |
| train_1/q_grads           | -0.03363671144470572   |
| train_1/q_grads_std       | 0.17460935637354852    |
| train_1/q_loss            | 15.209495190940197     |
| train_1/reward            | -2.098427305057703     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013671875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -5.118322971080998     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 373.95. Rollout time: 207.14, Training time: 166.79
Evaluating epoch 5
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 546437.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -26.999999982065503    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.137066544672907     |
| train_0/fw_bonus          | -0.9983925670385361    |
| train_0/fw_loss           | 0.008103753870818764   |
| train_0/mu_grads          | -0.009533321508206427  |
| train_0/mu_grads_std      | 0.2761270999908447     |
| train_0/mu_loss           | 9.102719073513565      |
| train_0/next_q            | -9.101818934525475     |
| train_0/q_grads           | -0.0016665018163621425 |
| train_0/q_grads_std       | 0.16035147830843927    |
| train_0/q_loss            | 0.15545396822540714    |
| train_0/reward            | -0.699904287289246     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0495361328125        |
| train_0/target_q          | -9.265562544536582     |
| train_1/avg_q             | -18.232588740577015    |
| train_1/current_q         | -22.47148565518478     |
| train_1/fw_bonus          | -0.9804091066122055    |
| train_1/fw_loss           | 0.09765738882124424    |
| train_1/mu_grads          | -0.044165775179862976  |
| train_1/mu_grads_std      | 0.21337169408798218    |
| train_1/mu_loss           | 26.999226569611245     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -25.096811488161343    |
| train_1/q_grads           | -0.03983096927404404   |
| train_1/q_grads_std       | 0.20232378803193568    |
| train_1/q_loss            | 61.35967352859173      |
| train_1/reward            | -2.1104560153980856    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00146484375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -20.206242133628827    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 377.07. Rollout time: 207.50, Training time: 169.54
Evaluating epoch 6
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 637562.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -27.0                  |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.33524920188828      |
| train_0/fw_bonus          | -0.9985469788312912    |
| train_0/fw_loss           | 0.007381495891604572   |
| train_0/mu_grads          | -0.014563356526196003  |
| train_0/mu_grads_std      | 0.28544820174574853    |
| train_0/mu_loss           | 9.309084441249242      |
| train_0/next_q            | -9.307704195196042     |
| train_0/q_grads           | -0.0015297852078219876 |
| train_0/q_grads_std       | 0.16436331048607827    |
| train_0/q_loss            | 0.14832487623876495    |
| train_0/reward            | -0.6988096233850228    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0468017578125        |
| train_0/target_q          | -9.486567560605554     |
| train_1/avg_q             | -25.582685306913206    |
| train_1/current_q         | -22.212958701746306    |
| train_1/fw_bonus          | -0.981805944442749     |
| train_1/fw_loss           | 0.09196202531456947    |
| train_1/mu_grads          | -0.04416188597679138   |
| train_1/mu_grads_std      | 0.21337299048900604    |
| train_1/mu_loss           | 27.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -26.99987354201367     |
| train_1/q_grads           | -0.03673357646912336   |
| train_1/q_grads_std       | 0.21585394032299518    |
| train_1/q_loss            | 20.686676456180386     |
| train_1/reward            | -2.0717745550173277    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010009765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -21.37080805147961     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 374.10. Rollout time: 206.97, Training time: 167.10
Evaluating epoch 7
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 728193.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -23.08976393289857    |
| test_1/avg_q              | -4.606947957724318    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.820001893884857   |
| train_0/current_q         | -9.386611067395654    |
| train_0/fw_bonus          | -0.9986407101154328   |
| train_0/fw_loss           | 0.006943098956253379  |
| train_0/mu_grads          | -0.019274961855262517 |
| train_0/mu_grads_std      | 0.2966943718492985    |
| train_0/mu_loss           | 9.366525553505321     |
| train_0/next_q            | -9.365860146642785    |
| train_0/q_grads           | -0.003942466911394149 |
| train_0/q_grads_std       | 0.16711458303034304   |
| train_0/q_loss            | 0.16778970810004584   |
| train_0/reward            | -0.7001870555453934   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0590576171875       |
| train_0/target_q          | -9.533320600746178    |
| train_1/avg_q             | -24.52210062350874    |
| train_1/current_q         | -5.607244760960343    |
| train_1/fw_bonus          | -0.9831055641174317   |
| train_1/fw_loss           | 0.08666309975087642   |
| train_1/mu_grads          | -0.0536325647495687   |
| train_1/mu_grads_std      | 0.21558546349406243   |
| train_1/mu_loss           | 3.8449266492190235    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -4.589305485564175    |
| train_1/q_grads           | -0.0363738258369267   |
| train_1/q_grads_std       | 0.22283474318683147   |
| train_1/q_loss            | 2.2065258328524537    |
| train_1/reward            | -2.0877563934314822   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0077777777777777776 |
| train_1/target_q          | -5.56365790807161     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 370.78. Rollout time: 201.45, Training time: 169.30
Evaluating epoch 8
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 817653.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -24.430119686148384    |
| test_1/avg_q              | -9.777109247179256     |
| test_1/n_subgoals         | 698.0                  |
| test_1/subgoal_succ_rate  | 0.03581661891117478    |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -24.28647766871095     |
| train_0/current_q         | -9.263511590154755     |
| train_0/fw_bonus          | -0.9985793024301529    |
| train_0/fw_loss           | 0.007230306859128177   |
| train_0/mu_grads          | -0.02150923372246325   |
| train_0/mu_grads_std      | 0.3117763355374336     |
| train_0/mu_loss           | 9.243598417204547      |
| train_0/next_q            | -9.24139260539562      |
| train_0/q_grads           | -0.0037501580372918397 |
| train_0/q_grads_std       | 0.1717089582234621     |
| train_0/q_loss            | 0.18412623225226551    |
| train_0/reward            | -0.7024878953408915    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0358642578125        |
| train_0/target_q          | -9.424383966992803     |
| train_1/avg_q             | -10.665436059244863    |
| train_1/current_q         | -6.686622702592203     |
| train_1/fw_bonus          | -0.9836368441581727    |
| train_1/fw_loss           | 0.08449688851833344    |
| train_1/mu_grads          | -0.050669058412313464  |
| train_1/mu_grads_std      | 0.2395270373672247     |
| train_1/mu_loss           | 4.267625985746017      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.828660972410805     |
| train_1/q_grads           | -0.03648690516129136   |
| train_1/q_grads_std       | 0.22333268821239471    |
| train_1/q_loss            | 1.7197221515318493     |
| train_1/reward            | -2.1025361961932503    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001220703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.02925925925925926    |
| train_1/target_q          | -6.679230422132084     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 372.80. Rollout time: 205.72, Training time: 167.05
Evaluating epoch 9
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 907825.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -0.5084423225018037   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.225736110836817   |
| train_0/current_q         | -9.194156060700536    |
| train_0/fw_bonus          | -0.9984811887145042   |
| train_0/fw_loss           | 0.00768920686095953   |
| train_0/mu_grads          | -0.01941222567111254  |
| train_0/mu_grads_std      | 0.324005164206028     |
| train_0/mu_loss           | 9.150254671890163     |
| train_0/next_q            | -9.148202275658207    |
| train_0/q_grads           | -0.004330920311622322 |
| train_0/q_grads_std       | 0.17578954584896564   |
| train_0/q_loss            | 0.19565307906866347   |
| train_0/reward            | -0.7057713573194633   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.044189453125        |
| train_0/target_q          | -9.324975784301165    |
| train_1/avg_q             | -11.119907178293598   |
| train_1/current_q         | -1.5518092496190001   |
| train_1/fw_bonus          | -0.983901233971119    |
| train_1/fw_loss           | 0.08341893516480922   |
| train_1/mu_grads          | -0.05314690219238401  |
| train_1/mu_grads_std      | 0.2485022831708193    |
| train_1/mu_loss           | 0.15402023751037702   |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.050247007576999105 |
| train_1/q_grads           | -0.04006552193313837  |
| train_1/q_grads_std       | 0.22614422850310803   |
| train_1/q_loss            | 5.329358994309088     |
| train_1/reward            | -2.151826099806203    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.016666666666666666  |
| train_1/target_q          | -2.1885589381259525   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 369.73. Rollout time: 207.75, Training time: 161.95
Evaluating epoch 10
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 998950.0              |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.853333723369383    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.143250364477703    |
| train_0/fw_bonus          | -0.9984387859702111   |
| train_0/fw_loss           | 0.007887567579746246  |
| train_0/mu_grads          | -0.020621465146541597 |
| train_0/mu_grads_std      | 0.3321733847260475    |
| train_0/mu_loss           | 9.092247373840449     |
| train_0/next_q            | -9.090054734677201    |
| train_0/q_grads           | -0.005151213239878416 |
| train_0/q_grads_std       | 0.18049854524433612   |
| train_0/q_loss            | 0.18534930401334004   |
| train_0/reward            | -0.7077398979214194   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.051806640625        |
| train_0/target_q          | -9.286377702332114    |
| train_1/avg_q             | -8.189562488075753    |
| train_1/current_q         | -2.1048994123790257   |
| train_1/fw_bonus          | -0.9850062847137451   |
| train_1/fw_loss           | 0.07891327496618032   |
| train_1/mu_grads          | -0.05181652596220374  |
| train_1/mu_grads_std      | 0.25533509999513626   |
| train_1/mu_loss           | 2.844505045046659     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.01942429701226005  |
| train_1/q_grads           | -0.042732886224985125 |
| train_1/q_grads_std       | 0.23343471772968769   |
| train_1/q_loss            | 0.7667426399396036    |
| train_1/reward            | -2.1200788245303555   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.135089059232178    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 373.06. Rollout time: 207.60, Training time: 165.44
Evaluating epoch 11
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 1090075.0              |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -2.639376908337492     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.320431258262392     |
| train_0/fw_bonus          | -0.9985139667987823    |
| train_0/fw_loss           | 0.007535902946256101   |
| train_0/mu_grads          | -0.02258610804565251   |
| train_0/mu_grads_std      | 0.34193616807460786    |
| train_0/mu_loss           | 9.275214003035796      |
| train_0/next_q            | -9.26790520004548      |
| train_0/q_grads           | -0.0056931838858872656 |
| train_0/q_grads_std       | 0.18618786782026292    |
| train_0/q_loss            | 0.22013177454547037    |
| train_0/reward            | -0.7116593277438369    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0496826171875        |
| train_0/target_q          | -9.453074899349351     |
| train_1/avg_q             | -11.186928723281973    |
| train_1/current_q         | -2.1002265174102783    |
| train_1/fw_bonus          | -0.9847507581114769    |
| train_1/fw_loss           | 0.07995515074580908    |
| train_1/mu_grads          | -0.0540378843434155    |
| train_1/mu_grads_std      | 0.260252483189106      |
| train_1/mu_loss           | 2.081490911988552      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.00932014214702179   |
| train_1/q_grads           | -0.04464053837582469   |
| train_1/q_grads_std       | 0.24270244911313058    |
| train_1/q_loss            | 0.6036128473295612     |
| train_1/reward            | -2.104350473793602     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001318359375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1107503740156304    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 445.55. Rollout time: 239.11, Training time: 206.40
Evaluating epoch 12
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1181200.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -3.854909449383736    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.388794437268956    |
| train_0/fw_bonus          | -0.9984149634838104   |
| train_0/fw_loss           | 0.007998964877333491  |
| train_0/mu_grads          | -0.02540113739669323  |
| train_0/mu_grads_std      | 0.3511407598853111    |
| train_0/mu_loss           | 9.34431407581727      |
| train_0/next_q            | -9.343713932645837    |
| train_0/q_grads           | -0.006539799203164875 |
| train_0/q_grads_std       | 0.1902415845543146    |
| train_0/q_loss            | 0.21307165717311224   |
| train_0/reward            | -0.7124521104509768   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.03935546875         |
| train_0/target_q          | -9.54246512690853     |
| train_1/avg_q             | -11.632282504911393   |
| train_1/current_q         | -2.1326444067651353   |
| train_1/fw_bonus          | -0.9854464367032051   |
| train_1/fw_loss           | 0.07711864486336709   |
| train_1/mu_grads          | -0.055995217990130186 |
| train_1/mu_grads_std      | 0.26290991008281706   |
| train_1/mu_loss           | 1.8165955653512083    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.06605269254774482  |
| train_1/q_grads           | -0.04642420904710889  |
| train_1/q_grads_std       | 0.2531696118414402    |
| train_1/q_loss            | 1.0302989328073768    |
| train_1/reward            | -2.085789623394521    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.131393811685203    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 414.82. Rollout time: 231.89, Training time: 182.90
Evaluating epoch 13
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1272325.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.996322510995032   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.445003538962418    |
| train_0/fw_bonus          | -0.9985856115818024   |
| train_0/fw_loss           | 0.007200845389161259  |
| train_0/mu_grads          | -0.028069601906463505 |
| train_0/mu_grads_std      | 0.35750954374670985   |
| train_0/mu_loss           | 9.39760558554049      |
| train_0/next_q            | -9.392242436068113    |
| train_0/q_grads           | -0.006314513157121837 |
| train_0/q_grads_std       | 0.1935282289981842    |
| train_0/q_loss            | 0.17523032608455513   |
| train_0/reward            | -0.7103889939673536   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0380859375          |
| train_0/target_q          | -9.593300973152884    |
| train_1/avg_q             | -17.421776673286352   |
| train_1/current_q         | -26.999300596645547   |
| train_1/fw_bonus          | -0.9867073431611061   |
| train_1/fw_loss           | 0.07197754606604576   |
| train_1/mu_grads          | -0.055226737167686224 |
| train_1/mu_grads_std      | 0.2688740685582161    |
| train_1/mu_loss           | 26.992708500760216    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0490440271794796   |
| train_1/q_grads_std       | 0.25921092480421065   |
| train_1/q_loss            | 123.9982193381954     |
| train_1/reward            | -2.075030915284151    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.079591950440413   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 431.85. Rollout time: 246.42, Training time: 185.40
Evaluating epoch 14
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 1363450.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999999873102766   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.527501415581101    |
| train_0/fw_bonus          | -0.9987091004848481   |
| train_0/fw_loss           | 0.006623236718587578  |
| train_0/mu_grads          | -0.030245287390425802 |
| train_0/mu_grads_std      | 0.3608773350715637    |
| train_0/mu_loss           | 9.476271037081068     |
| train_0/next_q            | -9.471137591156886    |
| train_0/q_grads           | -0.006481393123976886 |
| train_0/q_grads_std       | 0.1950999304652214    |
| train_0/q_loss            | 0.16339996876617954   |
| train_0/reward            | -0.7101455662705121   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0317138671875       |
| train_0/target_q          | -9.67778281983485     |
| train_1/avg_q             | -26.996642902947986   |
| train_1/current_q         | -22.754904353770044   |
| train_1/fw_bonus          | -0.987462368607521    |
| train_1/fw_loss           | 0.0688991203904152    |
| train_1/mu_grads          | -0.05623630378395319  |
| train_1/mu_grads_std      | 0.2688129246234894    |
| train_1/mu_loss           | 13.502648143701965    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0499464325606823   |
| train_1/q_grads_std       | 0.26393557637929915   |
| train_1/q_loss            | 26.828070974805303    |
| train_1/reward            | -2.1257868410735683   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00234375            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.86613547388608    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 410.42. Rollout time: 231.22, Training time: 179.17
Evaluating epoch 15
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1454575.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999927023622142   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.447964726182203    |
| train_0/fw_bonus          | -0.9987807661294937   |
| train_0/fw_loss           | 0.006288064795080572  |
| train_0/mu_grads          | -0.030111441295593976 |
| train_0/mu_grads_std      | 0.3669747181236744    |
| train_0/mu_loss           | 9.402683903397392     |
| train_0/next_q            | -9.398428445108829    |
| train_0/q_grads           | -0.006993867561686784 |
| train_0/q_grads_std       | 0.19709866642951965   |
| train_0/q_loss            | 0.16271921662905522   |
| train_0/reward            | -0.7064094244487933   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0514404296875       |
| train_0/target_q          | -9.596699027131198    |
| train_1/avg_q             | -26.999998813032665   |
| train_1/current_q         | -22.71055192822985    |
| train_1/fw_bonus          | -0.9883386790752411   |
| train_1/fw_loss           | 0.06532606752589346   |
| train_1/mu_grads          | -0.05650608399882913  |
| train_1/mu_grads_std      | 0.26894297227263453   |
| train_1/mu_loss           | 13.423959785066092    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.050142515916377306 |
| train_1/q_grads_std       | 0.26960494443774224   |
| train_1/q_loss            | 20.863930889715142    |
| train_1/reward            | -2.1121625040301297   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019775390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.91065078528014    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 493.87. Rollout time: 270.05, Training time: 223.78
Evaluating epoch 16
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1545700.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -18.114430212170685   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.42568295073377     |
| train_0/fw_bonus          | -0.9988720268011093   |
| train_0/fw_loss           | 0.005861203360836953  |
| train_0/mu_grads          | -0.031405070703476666 |
| train_0/mu_grads_std      | 0.37288172692060473   |
| train_0/mu_loss           | 9.374944987577889     |
| train_0/next_q            | -9.371668663550162    |
| train_0/q_grads           | -0.006721132819075137 |
| train_0/q_grads_std       | 0.1995235849171877    |
| train_0/q_loss            | 0.16258036557722572   |
| train_0/reward            | -0.7064794711543072   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0191162109375       |
| train_0/target_q          | -9.575852024099147    |
| train_1/avg_q             | -26.968331356625143   |
| train_1/current_q         | -22.760753739409406   |
| train_1/fw_bonus          | -0.9892146676778794   |
| train_1/fw_loss           | 0.06175444982945919   |
| train_1/mu_grads          | -0.05870707528665662  |
| train_1/mu_grads_std      | 0.27027731463313104   |
| train_1/mu_loss           | 10.380330652374756    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.050039672292768955 |
| train_1/q_grads_std       | 0.2745369881391525    |
| train_1/q_loss            | 19.102296030666245    |
| train_1/reward            | -2.096731350600021    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.997287014662533   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 493.61. Rollout time: 272.55, Training time: 221.03
Evaluating epoch 17
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1636825.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -17.687930472542508   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.479485466265302    |
| train_0/fw_bonus          | -0.9988917306065559   |
| train_0/fw_loss           | 0.0057690600398927925 |
| train_0/mu_grads          | -0.03166467044502497  |
| train_0/mu_grads_std      | 0.3782814905047417    |
| train_0/mu_loss           | 9.420496863272714     |
| train_0/next_q            | -9.416344964439364    |
| train_0/q_grads           | -0.006531944777816534 |
| train_0/q_grads_std       | 0.20259114503860473   |
| train_0/q_loss            | 0.15125949401596447   |
| train_0/reward            | -0.7098096336652816   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01806640625         |
| train_0/target_q          | -9.633422190705186    |
| train_1/avg_q             | -25.63968899637231    |
| train_1/current_q         | -22.506416723125525   |
| train_1/fw_bonus          | -0.9900024488568306   |
| train_1/fw_loss           | 0.05854237023741007   |
| train_1/mu_grads          | -0.06162835219874978  |
| train_1/mu_grads_std      | 0.2739794202148914    |
| train_1/mu_loss           | 8.472044183806155     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05092773688957095  |
| train_1/q_grads_std       | 0.2812542900443077    |
| train_1/q_loss            | 15.419031317516106    |
| train_1/reward            | -2.0755065961770014   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.035493900864516   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 459.41. Rollout time: 254.15, Training time: 205.23
Evaluating epoch 18
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 1727950.0             |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -10.91675828782396    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.469597840832833    |
| train_0/fw_bonus          | -0.9988982021808624   |
| train_0/fw_loss           | 0.00573877525748685   |
| train_0/mu_grads          | -0.03139844634570181  |
| train_0/mu_grads_std      | 0.3829836532473564    |
| train_0/mu_loss           | 9.40913955424189      |
| train_0/next_q            | -9.40661880280758     |
| train_0/q_grads           | -0.006439256959129125 |
| train_0/q_grads_std       | 0.20599024444818498   |
| train_0/q_loss            | 0.1433219832279044    |
| train_0/reward            | -0.7074935352931788   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.016259765625        |
| train_0/target_q          | -9.62158182520692     |
| train_1/avg_q             | -19.87186461144913    |
| train_1/current_q         | -22.304418873661778   |
| train_1/fw_bonus          | -0.990201561152935    |
| train_1/fw_loss           | 0.057730582635849716  |
| train_1/mu_grads          | -0.06232537878677249  |
| train_1/mu_grads_std      | 0.27774614542722703   |
| train_1/mu_loss           | 9.049635665183143     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.053215714171528816 |
| train_1/q_grads_std       | 0.28920046910643576   |
| train_1/q_loss            | 10.96829768267472     |
| train_1/reward            | -2.1208454028557755   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00205078125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.15512225832454    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 442.74. Rollout time: 244.86, Training time: 197.85
Evaluating epoch 19
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1819075.0             |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -9.912216827975156    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.466371163676044    |
| train_0/fw_bonus          | -0.9988818362355232   |
| train_0/fw_loss           | 0.005815261241514236  |
| train_0/mu_grads          | -0.030783481104299425 |
| train_0/mu_grads_std      | 0.3865417420864105    |
| train_0/mu_loss           | 9.404041090796886     |
| train_0/next_q            | -9.40051075710135     |
| train_0/q_grads           | -0.006849248800426722 |
| train_0/q_grads_std       | 0.20896315276622773   |
| train_0/q_loss            | 0.1385737182286936    |
| train_0/reward            | -0.7082666089110716   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0167236328125       |
| train_0/target_q          | -9.62022937285197     |
| train_1/avg_q             | -16.658975191615582   |
| train_1/current_q         | -14.293546909487134   |
| train_1/fw_bonus          | -0.9906455978751183   |
| train_1/fw_loss           | 0.05592006724327803   |
| train_1/mu_grads          | -0.06249995743855834  |
| train_1/mu_grads_std      | 0.2797248922288418    |
| train_1/mu_loss           | 5.420790593891533     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -16.394115141663775   |
| train_1/q_grads           | -0.05646082498133183  |
| train_1/q_grads_std       | 0.29309999868273734   |
| train_1/q_loss            | 2.2098939747110675    |
| train_1/reward            | -2.090793988720543    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021484375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -14.257153348634745   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 413.18. Rollout time: 225.98, Training time: 187.17
Evaluating epoch 20
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1910200.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.396623780826495   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.495780279135056    |
| train_0/fw_bonus          | -0.9988262295722962   |
| train_0/fw_loss           | 0.006075428507756442  |
| train_0/mu_grads          | -0.02890296233817935  |
| train_0/mu_grads_std      | 0.39432215839624407   |
| train_0/mu_loss           | 9.430941653239383     |
| train_0/next_q            | -9.427724516741176    |
| train_0/q_grads           | -0.007203480997122824 |
| train_0/q_grads_std       | 0.21252970322966575   |
| train_0/q_loss            | 0.14162205109482967   |
| train_0/reward            | -0.7087881128820299   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0254638671875       |
| train_0/target_q          | -9.65106035059003     |
| train_1/avg_q             | -15.882592163507711   |
| train_1/current_q         | -12.490090513383002   |
| train_1/fw_bonus          | -0.9901531904935836   |
| train_1/fw_loss           | 0.05792779810726643   |
| train_1/mu_grads          | -0.06026639342308045  |
| train_1/mu_grads_std      | 0.2784330204129219    |
| train_1/mu_loss           | 5.82858335182893      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.193728914069515   |
| train_1/q_grads           | -0.05926196603104472  |
| train_1/q_grads_std       | 0.2962274745106697    |
| train_1/q_loss            | 1.7634081060461653    |
| train_1/reward            | -2.0751303001517956   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.491016919561018   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 434.70. Rollout time: 242.44, Training time: 192.23
Evaluating epoch 21
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 2001325.0              |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -12.322437677650065    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.515785646120168     |
| train_0/fw_bonus          | -0.9988574758172035    |
| train_0/fw_loss           | 0.005929271806962788   |
| train_0/mu_grads          | -0.02792060780338943   |
| train_0/mu_grads_std      | 0.40199385210871696    |
| train_0/mu_loss           | 9.454831776104642      |
| train_0/next_q            | -9.452582268330683     |
| train_0/q_grads           | -0.0073983326321467755 |
| train_0/q_grads_std       | 0.21544289514422416    |
| train_0/q_loss            | 0.1362275977825492     |
| train_0/reward            | -0.7073877214948879    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.012353515625         |
| train_0/target_q          | -9.671417445544597     |
| train_1/avg_q             | -14.196522100803659    |
| train_1/current_q         | -12.362471294172627    |
| train_1/fw_bonus          | -0.9896908730268479    |
| train_1/fw_loss           | 0.059812744800001386   |
| train_1/mu_grads          | -0.06004791855812073   |
| train_1/mu_grads_std      | 0.27907398492097857    |
| train_1/mu_loss           | 5.214161297608442      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.055235296028979    |
| train_1/q_grads           | -0.05960204768925905   |
| train_1/q_grads_std       | 0.2969845175743103     |
| train_1/q_loss            | 1.3329887390150883     |
| train_1/reward            | -2.130026102998818     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015625              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.373670342282765    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 445.61. Rollout time: 248.45, Training time: 197.13
Evaluating epoch 22
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 2092450.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.20207787697184    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.391688481797846    |
| train_0/fw_bonus          | -0.9988432839512825   |
| train_0/fw_loss           | 0.005995658587198705  |
| train_0/mu_grads          | -0.026746969437226653 |
| train_0/mu_grads_std      | 0.4075410827994347    |
| train_0/mu_loss           | 9.332195580344496     |
| train_0/next_q            | -9.329490251491713    |
| train_0/q_grads           | -0.007752383186016232 |
| train_0/q_grads_std       | 0.21718543395400047   |
| train_0/q_loss            | 0.13426866092067402   |
| train_0/reward            | -0.7041701756432304   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0236083984375       |
| train_0/target_q          | -9.543790174503988    |
| train_1/avg_q             | -14.154099161223787   |
| train_1/current_q         | -12.322493862508987   |
| train_1/fw_bonus          | -0.989212018251419    |
| train_1/fw_loss           | 0.06176521517336368   |
| train_1/mu_grads          | -0.059784418623894456 |
| train_1/mu_grads_std      | 0.28070091381669043   |
| train_1/mu_loss           | 5.070098159611644     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.027257217754743   |
| train_1/q_grads           | -0.06027587801218033  |
| train_1/q_grads_std       | 0.2990859590470791    |
| train_1/q_loss            | 1.0285016641896216    |
| train_1/reward            | -2.101661671619513    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.313647912607529   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 432.14. Rollout time: 243.39, Training time: 188.73
Evaluating epoch 23
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 2183575.0             |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.687613170159702   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.444096747377518    |
| train_0/fw_bonus          | -0.9989273026585579   |
| train_0/fw_loss           | 0.005602719006128609  |
| train_0/mu_grads          | -0.027385458489879964 |
| train_0/mu_grads_std      | 0.4132468789815903    |
| train_0/mu_loss           | 9.382987007718564     |
| train_0/next_q            | -9.378730321854885    |
| train_0/q_grads           | -0.008484961534850299 |
| train_0/q_grads_std       | 0.21912496387958527   |
| train_0/q_loss            | 0.12232751795364352   |
| train_0/reward            | -0.7056404043454677   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010986328125        |
| train_0/target_q          | -9.598789268472022    |
| train_1/avg_q             | -14.09303551107579    |
| train_1/current_q         | -12.301876460303651   |
| train_1/fw_bonus          | -0.9888590708374977   |
| train_1/fw_loss           | 0.06320423819124699   |
| train_1/mu_grads          | -0.06019448405131698  |
| train_1/mu_grads_std      | 0.2812783867120743    |
| train_1/mu_loss           | 5.37149706070335      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.016359108594617   |
| train_1/q_grads           | -0.06139925718307495  |
| train_1/q_grads_std       | 0.3020076647400856    |
| train_1/q_loss            | 0.9215762845714245    |
| train_1/reward            | -2.1112752426131918   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.302833133627257   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 380.03. Rollout time: 211.20, Training time: 168.80
Evaluating epoch 24
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2274700.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.227756882216184   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.437822487293333    |
| train_0/fw_bonus          | -0.9989480957388878   |
| train_0/fw_loss           | 0.005505430977791548  |
| train_0/mu_grads          | -0.02742022960446775  |
| train_0/mu_grads_std      | 0.41838953718543054   |
| train_0/mu_loss           | 9.369199784826638     |
| train_0/next_q            | -9.366384479391495    |
| train_0/q_grads           | -0.008631580322980881 |
| train_0/q_grads_std       | 0.22190517894923686   |
| train_0/q_loss            | 0.12801943253613263   |
| train_0/reward            | -0.7080067618575413   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0117919921875       |
| train_0/target_q          | -9.591537906031206    |
| train_1/avg_q             | -13.993133725567095   |
| train_1/current_q         | -12.42188909696173    |
| train_1/fw_bonus          | -0.9888038635253906   |
| train_1/fw_loss           | 0.06342934463173151   |
| train_1/mu_grads          | -0.06058991318568587  |
| train_1/mu_grads_std      | 0.2802256040275097    |
| train_1/mu_loss           | 5.614193462674799     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.033601344636754   |
| train_1/q_grads           | -0.062315710633993146 |
| train_1/q_grads_std       | 0.30444061383605003   |
| train_1/q_loss            | 0.7012606128708272    |
| train_1/reward            | -2.122917559844791    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.40338773194208    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 383.46. Rollout time: 210.31, Training time: 173.12
Evaluating epoch 25
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2365825.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.216603274912773   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.482023636775494    |
| train_0/fw_bonus          | -0.998976257443428    |
| train_0/fw_loss           | 0.00537368276854977   |
| train_0/mu_grads          | -0.02633689669892192  |
| train_0/mu_grads_std      | 0.42497758492827414   |
| train_0/mu_loss           | 9.41052880640498      |
| train_0/next_q            | -9.406813200942404    |
| train_0/q_grads           | -0.008742246613837778 |
| train_0/q_grads_std       | 0.22432637959718704   |
| train_0/q_loss            | 0.125583593809291     |
| train_0/reward            | -0.7099739709381538   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01025390625         |
| train_0/target_q          | -9.634420806215154    |
| train_1/avg_q             | -13.981725030214465   |
| train_1/current_q         | -12.520187618823716   |
| train_1/fw_bonus          | -0.9887696534395218   |
| train_1/fw_loss           | 0.06356880068778992   |
| train_1/mu_grads          | -0.06013486906886101  |
| train_1/mu_grads_std      | 0.2820580653846264    |
| train_1/mu_loss           | 5.261398915210013     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.024169751757094   |
| train_1/q_grads           | -0.06332221478223801  |
| train_1/q_grads_std       | 0.3069770157337189    |
| train_1/q_loss            | 0.943572697606014     |
| train_1/reward            | -2.129040595005063    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.516721860440239   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 380.65. Rollout time: 206.34, Training time: 174.29
Evaluating epoch 26
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2456950.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.29948438108301    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.53219238634291     |
| train_0/fw_bonus          | -0.9988605722784996   |
| train_0/fw_loss           | 0.005914773605763912  |
| train_0/mu_grads          | -0.025138452649116516 |
| train_0/mu_grads_std      | 0.4303526677191257    |
| train_0/mu_loss           | 9.459614367112223     |
| train_0/next_q            | -9.455332202556097    |
| train_0/q_grads           | -0.009548860508948565 |
| train_0/q_grads_std       | 0.2267354667186737    |
| train_0/q_loss            | 0.1327269331163145    |
| train_0/reward            | -0.7135172012007388   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0218505859375       |
| train_0/target_q          | -9.684681142841004    |
| train_1/avg_q             | -14.072872805987146   |
| train_1/current_q         | -12.56684766939836    |
| train_1/fw_bonus          | -0.9881924137473106   |
| train_1/fw_loss           | 0.06592244720086456   |
| train_1/mu_grads          | -0.05955293281003833  |
| train_1/mu_grads_std      | 0.28487704545259473   |
| train_1/mu_loss           | 5.628870959042262     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.06108816655689    |
| train_1/q_grads           | -0.06418295055627823  |
| train_1/q_grads_std       | 0.3102444909512997    |
| train_1/q_loss            | 0.8022303760439478    |
| train_1/reward            | -2.106559585427749    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.56405725822403    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 378.96. Rollout time: 204.63, Training time: 174.30
Evaluating epoch 27
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2548075.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.057950015517509   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.502241556022856    |
| train_0/fw_bonus          | -0.998773169517517    |
| train_0/fw_loss           | 0.006323580117896199  |
| train_0/mu_grads          | -0.024609355488792062 |
| train_0/mu_grads_std      | 0.4346353456377983    |
| train_0/mu_loss           | 9.426365351069084     |
| train_0/next_q            | -9.421047154459064    |
| train_0/q_grads           | -0.010072934348136187 |
| train_0/q_grads_std       | 0.22947358340024948   |
| train_0/q_loss            | 0.14030961786444862   |
| train_0/reward            | -0.7157195923136896   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0220703125          |
| train_0/target_q          | -9.65758376680933     |
| train_1/avg_q             | -14.055944737833322   |
| train_1/current_q         | -12.57054859899774    |
| train_1/fw_bonus          | -0.9876050174236297   |
| train_1/fw_loss           | 0.06831744126975536   |
| train_1/mu_grads          | -0.05942995008081198  |
| train_1/mu_grads_std      | 0.28578960299491885   |
| train_1/mu_loss           | 5.325022668354488     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.00529703961912    |
| train_1/q_grads           | -0.06491574794054031  |
| train_1/q_grads_std       | 0.31353367641568186   |
| train_1/q_loss            | 1.0430196611512745    |
| train_1/reward            | -2.102261980708863    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.580608894824666   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 380.67. Rollout time: 205.96, Training time: 174.68
Evaluating epoch 28
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2639200.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.462771537912621   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.544024812475673    |
| train_0/fw_bonus          | -0.9987694218754768   |
| train_0/fw_loss           | 0.00634115053107962   |
| train_0/mu_grads          | -0.02284041503444314  |
| train_0/mu_grads_std      | 0.43879972472786904   |
| train_0/mu_loss           | 9.463527260556337     |
| train_0/next_q            | -9.459149000431434    |
| train_0/q_grads           | -0.010368963051587344 |
| train_0/q_grads_std       | 0.23312002904713153   |
| train_0/q_loss            | 0.13993941674850374   |
| train_0/reward            | -0.7171581438087742   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0104736328125       |
| train_0/target_q          | -9.695711872822766    |
| train_1/avg_q             | -14.109720343172397   |
| train_1/current_q         | -12.634095583637961   |
| train_1/fw_bonus          | -0.9869027450680733   |
| train_1/fw_loss           | 0.07118081031367182   |
| train_1/mu_grads          | -0.059192629810422656 |
| train_1/mu_grads_std      | 0.2877979472279549    |
| train_1/mu_loss           | 5.202791801971289     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.058248628665051   |
| train_1/q_grads           | -0.06602295022457838  |
| train_1/q_grads_std       | 0.3162865094840527    |
| train_1/q_loss            | 1.0103100890058183    |
| train_1/reward            | -2.048419634248421    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.664830047687756   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 384.11. Rollout time: 208.01, Training time: 176.07
Evaluating epoch 29
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 29                   |
| policy/steps              | 2730325.0            |
| test/episodes             | 750.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.070052989128028  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.652214045833299   |
| train_0/fw_bonus          | -0.9986752852797508  |
| train_0/fw_loss           | 0.006781356746796518 |
| train_0/mu_grads          | -0.02294137361459434 |
| train_0/mu_grads_std      | 0.4430643916130066   |
| train_0/mu_loss           | 9.5705665368985      |
| train_0/next_q            | -9.56782919775021    |
| train_0/q_grads           | -0.01025555431842804 |
| train_0/q_grads_std       | 0.23744406066834928  |
| train_0/q_loss            | 0.14202502517117788  |
| train_0/reward            | -0.7200773932774609  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0190673828125      |
| train_0/target_q          | -9.807816587212775   |
| train_1/avg_q             | -14.207458286583407  |
| train_1/current_q         | -12.5101169693473    |
| train_1/fw_bonus          | -0.9861514255404472  |
| train_1/fw_loss           | 0.07424413599073887  |
| train_1/mu_grads          | -0.05875479765236378 |
| train_1/mu_grads_std      | 0.2901420257985592   |
| train_1/mu_loss           | 4.838236630598712    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.027479012296169  |
| train_1/q_grads           | -0.0669887688010931  |
| train_1/q_grads_std       | 0.31863848865032196  |
| train_1/q_loss            | 0.6634851508758783   |
| train_1/reward            | -2.0505464195353853  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001318359375       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.52126642102569   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 383.26. Rollout time: 204.96, Training time: 178.27
Evaluating epoch 30
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 30                    |
| policy/steps              | 2821450.0             |
| test/episodes             | 775.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.435564482495668   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.498004514149322    |
| train_0/fw_bonus          | -0.998647989332676    |
| train_0/fw_loss           | 0.006909093714784831  |
| train_0/mu_grads          | -0.023478011088445782 |
| train_0/mu_grads_std      | 0.4470564007759094    |
| train_0/mu_loss           | 9.412951478374513     |
| train_0/next_q            | -9.409808558795847    |
| train_0/q_grads           | -0.010475776181556285 |
| train_0/q_grads_std       | 0.24110388047993184   |
| train_0/q_loss            | 0.14041300717877997   |
| train_0/reward            | -0.7176223313574155   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0150634765625       |
| train_0/target_q          | -9.650376336327922    |
| train_1/avg_q             | -14.134769415368856   |
| train_1/current_q         | -12.41279690444886    |
| train_1/fw_bonus          | -0.9858620733022689   |
| train_1/fw_loss           | 0.07542396243661642   |
| train_1/mu_grads          | -0.05883748047053814  |
| train_1/mu_grads_std      | 0.29223098158836364   |
| train_1/mu_loss           | 5.010896028769731     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.031212350153112   |
| train_1/q_grads           | -0.06823800057172776  |
| train_1/q_grads_std       | 0.3207721158862114    |
| train_1/q_loss            | 0.5273327833556671    |
| train_1/reward            | -2.0353992963864584   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.431624348094875   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 384.86. Rollout time: 209.55, Training time: 175.28
Evaluating epoch 31
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2912519.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.693773495058467   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.588610502750978    |
| train_0/fw_bonus          | -0.9986908450722695   |
| train_0/fw_loss           | 0.006708658882416785  |
| train_0/mu_grads          | -0.025392612908035517 |
| train_0/mu_grads_std      | 0.45165884867310524   |
| train_0/mu_loss           | 9.506610355767979     |
| train_0/next_q            | -9.500945685039621    |
| train_0/q_grads           | -0.010667747422121465 |
| train_0/q_grads_std       | 0.24456552043557167   |
| train_0/q_loss            | 0.14394858452881612   |
| train_0/reward            | -0.7195358485565521   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0141845703125       |
| train_0/target_q          | -9.740118277966047    |
| train_1/avg_q             | -14.08906594591546    |
| train_1/current_q         | -12.41842767184622    |
| train_1/fw_bonus          | -0.9852498680353164   |
| train_1/fw_loss           | 0.07792007438838482   |
| train_1/mu_grads          | -0.05901961904019117  |
| train_1/mu_grads_std      | 0.29418778941035273   |
| train_1/mu_loss           | 4.601144084206385     |
| train_1/n_subgoals        | 2698.0                |
| train_1/next_q            | -14.040864032111937   |
| train_1/q_grads           | -0.06886091679334641  |
| train_1/q_grads_std       | 0.32209992334246634   |
| train_1/q_loss            | 0.6995864735128081    |
| train_1/reward            | -2.073069272788416    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.42383314689324    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 383.14. Rollout time: 205.40, Training time: 177.72
Evaluating epoch 32
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 3003644.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.094291143941692   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.602974499008585    |
| train_0/fw_bonus          | -0.9986883968114852   |
| train_0/fw_loss           | 0.006720024556852877  |
| train_0/mu_grads          | -0.023564424458891155 |
| train_0/mu_grads_std      | 0.45560548529028894   |
| train_0/mu_loss           | 9.524879446591976     |
| train_0/next_q            | -9.519549729685709    |
| train_0/q_grads           | -0.011063286382704974 |
| train_0/q_grads_std       | 0.24728335551917552   |
| train_0/q_loss            | 0.14484511471562728   |
| train_0/reward            | -0.7177401999761059   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01337890625         |
| train_0/target_q          | -9.754059286675409    |
| train_1/avg_q             | -14.123472727324627   |
| train_1/current_q         | -12.35698630942848    |
| train_1/fw_bonus          | -0.9845171332359314   |
| train_1/fw_loss           | 0.08090766444802285   |
| train_1/mu_grads          | -0.05934515120461583  |
| train_1/mu_grads_std      | 0.2957367777824402    |
| train_1/mu_loss           | 4.794748434821039     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.983506129752266   |
| train_1/q_grads           | -0.06976127605885267  |
| train_1/q_grads_std       | 0.3235484264791012    |
| train_1/q_loss            | 0.8575293872047235    |
| train_1/reward            | -2.0697976317555002   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.380162590334411   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 383.21. Rollout time: 204.74, Training time: 178.45
Evaluating epoch 33
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 3094769.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.519087479840678   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.558851336643164    |
| train_0/fw_bonus          | -0.9987457111477852   |
| train_0/fw_loss           | 0.006451991305220872  |
| train_0/mu_grads          | -0.023895115265622734 |
| train_0/mu_grads_std      | 0.4613670513033867    |
| train_0/mu_loss           | 9.481172641494794     |
| train_0/next_q            | -9.475635135239653    |
| train_0/q_grads           | -0.011585565167479217 |
| train_0/q_grads_std       | 0.25024153888225553   |
| train_0/q_loss            | 0.13521748607796194   |
| train_0/reward            | -0.717012017248635    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0188720703125       |
| train_0/target_q          | -9.712792301027854    |
| train_1/avg_q             | -14.053674641487378   |
| train_1/current_q         | -12.367993464262534   |
| train_1/fw_bonus          | -0.9841284483671189   |
| train_1/fw_loss           | 0.08249247074127197   |
| train_1/mu_grads          | -0.05946036530658603  |
| train_1/mu_grads_std      | 0.2965079821646214    |
| train_1/mu_loss           | 5.128816086157333     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.018082420876652   |
| train_1/q_grads           | -0.07076300755143165  |
| train_1/q_grads_std       | 0.32565731927752495   |
| train_1/q_loss            | 0.6052629844537385    |
| train_1/reward            | -2.0733874673787795   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.368003251754404   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 377.22. Rollout time: 203.58, Training time: 173.61
Evaluating epoch 34
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 3185894.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.060923874361368   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.622303324130426    |
| train_0/fw_bonus          | -0.998770321905613    |
| train_0/fw_loss           | 0.00633686437504366   |
| train_0/mu_grads          | -0.02437630146741867  |
| train_0/mu_grads_std      | 0.4661417841911316    |
| train_0/mu_loss           | 9.547412985368975     |
| train_0/next_q            | -9.54189628670051     |
| train_0/q_grads           | -0.011705985106527806 |
| train_0/q_grads_std       | 0.2526285633444786    |
| train_0/q_loss            | 0.13324725400930987   |
| train_0/reward            | -0.7167557697044685   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01552734375         |
| train_0/target_q          | -9.776490869932918    |
| train_1/avg_q             | -14.066943540376519   |
| train_1/current_q         | -12.336876475049703   |
| train_1/fw_bonus          | -0.984458789229393    |
| train_1/fw_loss           | 0.08114566057920455   |
| train_1/mu_grads          | -0.059793466608971356 |
| train_1/mu_grads_std      | 0.2978265084326267    |
| train_1/mu_loss           | 5.163276653534102     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.99626174316839    |
| train_1/q_grads           | -0.07172509394586087  |
| train_1/q_grads_std       | 0.32805914878845216   |
| train_1/q_loss            | 0.6606037275628471    |
| train_1/reward            | -2.046428602279775    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.34077897175625    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 378.99. Rollout time: 204.53, Training time: 174.43
Evaluating epoch 35
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 3277019.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.405762468471776   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.581690559999117    |
| train_0/fw_bonus          | -0.9987594082951545   |
| train_0/fw_loss           | 0.006387949385680258  |
| train_0/mu_grads          | -0.025028690649196505 |
| train_0/mu_grads_std      | 0.47139219790697096   |
| train_0/mu_loss           | 9.504941599183137     |
| train_0/next_q            | -9.499567265770281    |
| train_0/q_grads           | -0.011813779245130718 |
| train_0/q_grads_std       | 0.25576846227049826   |
| train_0/q_loss            | 0.13674435707417254   |
| train_0/reward            | -0.7176048013017862   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0131103515625       |
| train_0/target_q          | -9.738043820489231    |
| train_1/avg_q             | -13.997732465059682   |
| train_1/current_q         | -12.450329762158223   |
| train_1/fw_bonus          | -0.9842223495244979   |
| train_1/fw_loss           | 0.08210962153971195   |
| train_1/mu_grads          | -0.06004726178944111  |
| train_1/mu_grads_std      | 0.2997314639389515    |
| train_1/mu_loss           | 5.01018946834313      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.99664537658063    |
| train_1/q_grads           | -0.07276157885789872  |
| train_1/q_grads_std       | 0.33061485514044764   |
| train_1/q_loss            | 0.5913589045307897    |
| train_1/reward            | -2.1080169340886643   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.458942441557276   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 385.74. Rollout time: 208.59, Training time: 177.12
Evaluating epoch 36
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 3368144.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.186709182193152   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.571057145247332    |
| train_0/fw_bonus          | -0.9987896054983139   |
| train_0/fw_loss           | 0.006246633699629456  |
| train_0/mu_grads          | -0.024688966991379856 |
| train_0/mu_grads_std      | 0.4759243972599506    |
| train_0/mu_loss           | 9.4926109628849       |
| train_0/next_q            | -9.488314717089555    |
| train_0/q_grads           | -0.012098019220866263 |
| train_0/q_grads_std       | 0.2585723131895065    |
| train_0/q_loss            | 0.13617638342515317   |
| train_0/reward            | -0.7168996931155561   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0117431640625       |
| train_0/target_q          | -9.724599972048633    |
| train_1/avg_q             | -14.100466165801906   |
| train_1/current_q         | -12.515725757741274   |
| train_1/fw_bonus          | -0.9850436925888062   |
| train_1/fw_loss           | 0.07876073196530342   |
| train_1/mu_grads          | -0.060289473831653596 |
| train_1/mu_grads_std      | 0.30239043682813643   |
| train_1/mu_loss           | 5.2382413083266535    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.075760505588676   |
| train_1/q_grads           | -0.0738005118444562   |
| train_1/q_grads_std       | 0.3323937483131886    |
| train_1/q_loss            | 0.6908677555514211    |
| train_1/reward            | -2.1159105197199097   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.512798277396788   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 383.99. Rollout time: 205.69, Training time: 178.27
Evaluating epoch 37
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 3459269.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.825119168153362   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.536059170093449    |
| train_0/fw_bonus          | -0.9987532794475555   |
| train_0/fw_loss           | 0.006416666891891509  |
| train_0/mu_grads          | -0.024410673044621946 |
| train_0/mu_grads_std      | 0.48040662705898285   |
| train_0/mu_loss           | 9.456984507892178     |
| train_0/next_q            | -9.452486301544045    |
| train_0/q_grads           | -0.01256415918469429  |
| train_0/q_grads_std       | 0.26153158470988275   |
| train_0/q_loss            | 0.14106333598866247   |
| train_0/reward            | -0.7175406959482643   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0121826171875       |
| train_0/target_q          | -9.691532593417598    |
| train_1/avg_q             | -13.971616807026267   |
| train_1/current_q         | -12.603685975856937   |
| train_1/fw_bonus          | -0.9854246705770493   |
| train_1/fw_loss           | 0.0772073669359088    |
| train_1/mu_grads          | -0.06023194212466478  |
| train_1/mu_grads_std      | 0.3033889576792717    |
| train_1/mu_loss           | 5.289583168229934     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.01303718624232    |
| train_1/q_grads           | -0.07434750702232122  |
| train_1/q_grads_std       | 0.3344167277216911    |
| train_1/q_loss            | 0.48368933336026404   |
| train_1/reward            | -2.0892333322699415   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.598157569049675   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 465.97. Rollout time: 253.62, Training time: 212.33
Evaluating epoch 38
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3550394.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.887311400281819   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.539933008620071    |
| train_0/fw_bonus          | -0.9987845838069915   |
| train_0/fw_loss           | 0.006270172994118184  |
| train_0/mu_grads          | -0.023609230853617193 |
| train_0/mu_grads_std      | 0.4863889366388321    |
| train_0/mu_loss           | 9.456923816951974     |
| train_0/next_q            | -9.453124396659394    |
| train_0/q_grads           | -0.013049423368647695 |
| train_0/q_grads_std       | 0.2649716757237911    |
| train_0/q_loss            | 0.1420120142057347    |
| train_0/reward            | -0.7182765716184804   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0111083984375       |
| train_0/target_q          | -9.692985300291852    |
| train_1/avg_q             | -13.98506788776684    |
| train_1/current_q         | -12.63643930355748    |
| train_1/fw_bonus          | -0.9849169194698334   |
| train_1/fw_loss           | 0.07927766088396311   |
| train_1/mu_grads          | -0.060858262982219455 |
| train_1/mu_grads_std      | 0.30367015972733497   |
| train_1/mu_loss           | 5.587349397298672     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.995989782862159   |
| train_1/q_grads           | -0.07517380267381668  |
| train_1/q_grads_std       | 0.3361387275159359    |
| train_1/q_loss            | 0.47617626795123014   |
| train_1/reward            | -2.066469686754863    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019775390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.632824444672618   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 475.77. Rollout time: 261.80, Training time: 213.94
Evaluating epoch 39
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 3641519.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.18197116445472    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.549351350216165    |
| train_0/fw_bonus          | -0.9987988516688346   |
| train_0/fw_loss           | 0.006203413917683065  |
| train_0/mu_grads          | -0.02367534674704075  |
| train_0/mu_grads_std      | 0.4916223086416721    |
| train_0/mu_loss           | 9.467764213453822     |
| train_0/next_q            | -9.463600846888074    |
| train_0/q_grads           | -0.013833711994811893 |
| train_0/q_grads_std       | 0.2678202077746391    |
| train_0/q_loss            | 0.14302558652257416   |
| train_0/reward            | -0.7182959148849477   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010498046875        |
| train_0/target_q          | -9.700860479251554    |
| train_1/avg_q             | -13.94398090518602    |
| train_1/current_q         | -12.697895947251416   |
| train_1/fw_bonus          | -0.9846433430910111   |
| train_1/fw_loss           | 0.08039312995970249   |
| train_1/mu_grads          | -0.06194630451500416  |
| train_1/mu_grads_std      | 0.3046395517885685    |
| train_1/mu_loss           | 5.044062296575142     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.047979450876516   |
| train_1/q_grads           | -0.07612845469266176  |
| train_1/q_grads_std       | 0.3377846986055374    |
| train_1/q_loss            | 0.5813914753099635    |
| train_1/reward            | -2.103954966679157    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.692582837320392   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 474.14. Rollout time: 254.55, Training time: 219.56
Evaluating epoch 40
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 3732644.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.877796408723365   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.571137044817059    |
| train_0/fw_bonus          | -0.9988021776080132   |
| train_0/fw_loss           | 0.006187888351269067  |
| train_0/mu_grads          | -0.02469084905460477  |
| train_0/mu_grads_std      | 0.4972547754645348    |
| train_0/mu_loss           | 9.494966776499078     |
| train_0/next_q            | -9.490073732399676    |
| train_0/q_grads           | -0.014163964800536633 |
| train_0/q_grads_std       | 0.27042815238237383   |
| train_0/q_loss            | 0.1389728823644621    |
| train_0/reward            | -0.7173210123262834   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.009326171875        |
| train_0/target_q          | -9.726453147900646    |
| train_1/avg_q             | -14.05081095593698    |
| train_1/current_q         | -12.634898662316294   |
| train_1/fw_bonus          | -0.9845243349671364   |
| train_1/fw_loss           | 0.08087832517921925   |
| train_1/mu_grads          | -0.06197202131152153  |
| train_1/mu_grads_std      | 0.30487938448786733   |
| train_1/mu_loss           | 4.8702116298249285    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.023639462452499   |
| train_1/q_grads           | -0.07644821852445602  |
| train_1/q_grads_std       | 0.3400114730000496    |
| train_1/q_loss            | 0.6255679546655327    |
| train_1/reward            | -2.050916952011903    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.633298871881143   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 460.04. Rollout time: 244.91, Training time: 215.10
Evaluating epoch 41
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 3823769.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.451677384117911   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.484288172162447    |
| train_0/fw_bonus          | -0.998819325864315    |
| train_0/fw_loss           | 0.0061077535734511915 |
| train_0/mu_grads          | -0.02408226397819817  |
| train_0/mu_grads_std      | 0.5010615155100823    |
| train_0/mu_loss           | 9.409463122789582     |
| train_0/next_q            | -9.403810624203533    |
| train_0/q_grads           | -0.014312411868013441 |
| train_0/q_grads_std       | 0.2728538282215595    |
| train_0/q_loss            | 0.13697093164136523   |
| train_0/reward            | -0.7146684459861717   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0176513671875       |
| train_0/target_q          | -9.635767145151394    |
| train_1/avg_q             | -14.08255004382642    |
| train_1/current_q         | -12.566070537104883   |
| train_1/fw_bonus          | -0.9838319048285484   |
| train_1/fw_loss           | 0.08370157144963741   |
| train_1/mu_grads          | -0.06258910559117795  |
| train_1/mu_grads_std      | 0.30636183768510816   |
| train_1/mu_loss           | 5.199065665765978     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.967323509142313   |
| train_1/q_grads           | -0.07723575215786696  |
| train_1/q_grads_std       | 0.34255404472351075   |
| train_1/q_loss            | 0.832644476239366     |
| train_1/reward            | -2.1136200540335266   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.574481621276641   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 436.23. Rollout time: 237.33, Training time: 198.86
Evaluating epoch 42
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 42                   |
| policy/steps              | 3914894.0            |
| test/episodes             | 1075.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -12.902920812336099  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 4300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.649786285253999   |
| train_0/fw_bonus          | -0.9988495066761971  |
| train_0/fw_loss           | 0.005966556002385914 |
| train_0/mu_grads          | -0.02260269713588059 |
| train_0/mu_grads_std      | 0.5054291680455207   |
| train_0/mu_loss           | 9.575432244130429    |
| train_0/next_q            | -9.571518731693029   |
| train_0/q_grads           | -0.01458699193317443 |
| train_0/q_grads_std       | 0.27591331079602244  |
| train_0/q_loss            | 0.1379770500210483   |
| train_0/reward            | -0.7157455521839438  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.01240234375        |
| train_0/target_q          | -9.805052824504795   |
| train_1/avg_q             | -14.029209929826223  |
| train_1/current_q         | -12.595507529600493  |
| train_1/fw_bonus          | -0.9833215549588203  |
| train_1/fw_loss           | 0.08578243050724269  |
| train_1/mu_grads          | -0.06344053521752357 |
| train_1/mu_grads_std      | 0.3077953696250916   |
| train_1/mu_loss           | 5.385167316291724    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.013137707156641  |
| train_1/q_grads           | -0.07822127770632506 |
| train_1/q_grads_std       | 0.344408094137907    |
| train_1/q_loss            | 0.5736629126454911   |
| train_1/reward            | -2.118601694237441   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001806640625       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.594658378560359  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 479.12. Rollout time: 264.92, Training time: 214.16
Evaluating epoch 43
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 43                    |
| policy/steps              | 4006019.0             |
| test/episodes             | 1100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.761208599589919   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.584964280135083    |
| train_0/fw_bonus          | -0.9988703697919845   |
| train_0/fw_loss           | 0.0058689889498054985 |
| train_0/mu_grads          | -0.022327724425122143 |
| train_0/mu_grads_std      | 0.5103764101862908    |
| train_0/mu_loss           | 9.514127568951121     |
| train_0/next_q            | -9.509147688805157    |
| train_0/q_grads           | -0.014316758909262716 |
| train_0/q_grads_std       | 0.2785007990896702    |
| train_0/q_loss            | 0.13076871680110724   |
| train_0/reward            | -0.7139737557190529   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0138427734375       |
| train_0/target_q          | -9.739801621240153    |
| train_1/avg_q             | -14.052802118936588   |
| train_1/current_q         | -12.559075035782797   |
| train_1/fw_bonus          | -0.9840964779257775   |
| train_1/fw_loss           | 0.08262288812547922   |
| train_1/mu_grads          | -0.06340298503637314  |
| train_1/mu_grads_std      | 0.3090176202356815    |
| train_1/mu_loss           | 5.173048349909737     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.012345033604737   |
| train_1/q_grads           | -0.07878053542226553  |
| train_1/q_grads_std       | 0.3465362057089806    |
| train_1/q_loss            | 0.4770178737940796    |
| train_1/reward            | -2.1626659069996093   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.561237765797127   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 390.41. Rollout time: 212.98, Training time: 177.40
Evaluating epoch 44
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 4097144.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.379772418734044   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.546753052754243    |
| train_0/fw_bonus          | -0.9988454893231392   |
| train_0/fw_loss           | 0.005985351593699307  |
| train_0/mu_grads          | -0.02257139664143324  |
| train_0/mu_grads_std      | 0.5142534777522088    |
| train_0/mu_loss           | 9.4703337953585       |
| train_0/next_q            | -9.466207715718781    |
| train_0/q_grads           | -0.014626553165726364 |
| train_0/q_grads_std       | 0.28059135377407074   |
| train_0/q_loss            | 0.1320358236227987    |
| train_0/reward            | -0.7152186404025997   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.018798828125        |
| train_0/target_q          | -9.702011153160408    |
| train_1/avg_q             | -13.96798798391541    |
| train_1/current_q         | -12.573218682912687   |
| train_1/fw_bonus          | -0.9854339614510537   |
| train_1/fw_loss           | 0.07716951314359903   |
| train_1/mu_grads          | -0.06383610181510449  |
| train_1/mu_grads_std      | 0.3087990559637547    |
| train_1/mu_loss           | 5.49947586282404      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.016857271537617   |
| train_1/q_grads           | -0.07954705357551575  |
| train_1/q_grads_std       | 0.3490021646022797    |
| train_1/q_loss            | 0.6709988486470205    |
| train_1/reward            | -2.137577817038982    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.574313012997523   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 4576.93. Rollout time: 228.08, Training time: 4348.82
Evaluating epoch 45
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 4188269.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.12117975076872    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.50118968417358     |
| train_0/fw_bonus          | -0.9988788276910782   |
| train_0/fw_loss           | 0.005829391465522349  |
| train_0/mu_grads          | -0.022963559394702314 |
| train_0/mu_grads_std      | 0.5190185979008675    |
| train_0/mu_loss           | 9.421653715520161     |
| train_0/next_q            | -9.416032923836399    |
| train_0/q_grads           | -0.014871923276223243 |
| train_0/q_grads_std       | 0.2832476235926151    |
| train_0/q_loss            | 0.1418716770497969    |
| train_0/reward            | -0.717054160736734    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0120361328125       |
| train_0/target_q          | -9.65495944203759     |
| train_1/avg_q             | -13.990384926358695   |
| train_1/current_q         | -12.67777532404622    |
| train_1/fw_bonus          | -0.9857736051082611   |
| train_1/fw_loss           | 0.07578468509018421   |
| train_1/mu_grads          | -0.06430844645947217  |
| train_1/mu_grads_std      | 0.3088491313159466    |
| train_1/mu_loss           | 5.235650470342961     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.986611221545564   |
| train_1/q_grads           | -0.08016476426273585  |
| train_1/q_grads_std       | 0.3514610730111599    |
| train_1/q_loss            | 0.39370865098214936   |
| train_1/reward            | -2.1213413903657057   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.682268892799964   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 478.78. Rollout time: 264.97, Training time: 213.79
Evaluating epoch 46
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 4279394.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.413592802974518   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.660505074907196    |
| train_0/fw_bonus          | -0.9988754197955132   |
| train_0/fw_loss           | 0.005845383810810745  |
| train_0/mu_grads          | -0.023757743556052445 |
| train_0/mu_grads_std      | 0.5232288926839829    |
| train_0/mu_loss           | 9.576321840262128     |
| train_0/next_q            | -9.571717500187528    |
| train_0/q_grads           | -0.014622949808835984 |
| train_0/q_grads_std       | 0.2850045472383499    |
| train_0/q_loss            | 0.1409038365826878    |
| train_0/reward            | -0.7205680762228439   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.011572265625        |
| train_0/target_q          | -9.815929574292083    |
| train_1/avg_q             | -14.155882793554122   |
| train_1/current_q         | -12.702169097757452   |
| train_1/fw_bonus          | -0.9855961859226227   |
| train_1/fw_loss           | 0.07650804705917835   |
| train_1/mu_grads          | -0.06472509335726499  |
| train_1/mu_grads_std      | 0.3089826740324497    |
| train_1/mu_loss           | 5.109543137831056     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.013027359830641   |
| train_1/q_grads           | -0.08045562598854303  |
| train_1/q_grads_std       | 0.3541173882782459    |
| train_1/q_loss            | 0.3474265437802449    |
| train_1/reward            | -2.132239012673381    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.698102159770764   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 430.22. Rollout time: 232.21, Training time: 197.99
Evaluating epoch 47
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 4370519.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.525416026639652   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.650173659562649    |
| train_0/fw_bonus          | -0.9989286944270134   |
| train_0/fw_loss           | 0.005596204963512719  |
| train_0/mu_grads          | -0.023618344916030765 |
| train_0/mu_grads_std      | 0.527390418946743     |
| train_0/mu_loss           | 9.56293428922509      |
| train_0/next_q            | -9.557356740585558    |
| train_0/q_grads           | -0.01454958172980696  |
| train_0/q_grads_std       | 0.28717506900429723   |
| train_0/q_loss            | 0.13938142436329753   |
| train_0/reward            | -0.7215346554228745   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0109375             |
| train_0/target_q          | -9.804945397399104    |
| train_1/avg_q             | -13.999271648946841   |
| train_1/current_q         | -12.749518382961867   |
| train_1/fw_bonus          | -0.9860409036278724   |
| train_1/fw_loss           | 0.07469477020204067   |
| train_1/mu_grads          | -0.064833895675838    |
| train_1/mu_grads_std      | 0.30992691218852997   |
| train_1/mu_loss           | 5.178162303820559     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.990417379539583   |
| train_1/q_grads           | -0.08112969696521759  |
| train_1/q_grads_std       | 0.3565723218023777    |
| train_1/q_loss            | 0.4035493142082963    |
| train_1/reward            | -2.0738065887075208   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.74937932999004    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 410.56. Rollout time: 224.18, Training time: 186.35
Evaluating epoch 48
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4461644.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.8072673848824     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.503822387945194    |
| train_0/fw_bonus          | -0.998870138823986    |
| train_0/fw_loss           | 0.005870016501285135  |
| train_0/mu_grads          | -0.024164215428754687 |
| train_0/mu_grads_std      | 0.5315738543868065    |
| train_0/mu_loss           | 9.416156372808858     |
| train_0/next_q            | -9.410625687766142    |
| train_0/q_grads           | -0.014909364678896964 |
| train_0/q_grads_std       | 0.28840507119894027   |
| train_0/q_loss            | 0.14240270624133472   |
| train_0/reward            | -0.7204799938917859   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01123046875         |
| train_0/target_q          | -9.657624586953556    |
| train_1/avg_q             | -14.02687365752294    |
| train_1/current_q         | -12.724150719762854   |
| train_1/fw_bonus          | -0.9861237019300461   |
| train_1/fw_loss           | 0.07435720022767782   |
| train_1/mu_grads          | -0.0648411639034748   |
| train_1/mu_grads_std      | 0.3113334223628044    |
| train_1/mu_loss           | 5.1943199022992275    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.031397533370136   |
| train_1/q_grads           | -0.08145129084587097  |
| train_1/q_grads_std       | 0.35873331129550934   |
| train_1/q_loss            | 0.5220826179137072    |
| train_1/reward            | -2.0977249387069605   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.718288462493078   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 429.77. Rollout time: 228.87, Training time: 200.87
Evaluating epoch 49
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 4552769.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.463971279931476   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.497762857606599    |
| train_0/fw_bonus          | -0.9989066451787949   |
| train_0/fw_loss           | 0.005699248728342354  |
| train_0/mu_grads          | -0.023851835215464235 |
| train_0/mu_grads_std      | 0.5353713661432267    |
| train_0/mu_loss           | 9.406313302473281     |
| train_0/next_q            | -9.40149351102652     |
| train_0/q_grads           | -0.015374198392964899 |
| train_0/q_grads_std       | 0.29037341848015785   |
| train_0/q_loss            | 0.13885583252738357   |
| train_0/reward            | -0.7204982493203715   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00986328125         |
| train_0/target_q          | -9.648912945585398    |
| train_1/avg_q             | -14.101569604970425   |
| train_1/current_q         | -12.736656196439787   |
| train_1/fw_bonus          | -0.9847352728247643   |
| train_1/fw_loss           | 0.08001829478889703   |
| train_1/mu_grads          | -0.0649246122688055   |
| train_1/mu_grads_std      | 0.31255693435668946   |
| train_1/mu_loss           | 4.814986148423932     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.009650962881114   |
| train_1/q_grads           | -0.08185377176851034  |
| train_1/q_grads_std       | 0.3610015377402306    |
| train_1/q_loss            | 0.5078885713373106    |
| train_1/reward            | -2.1127533747363487   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.741451919852741   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 454.92. Rollout time: 248.13, Training time: 206.75
Evaluating epoch 50
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 4643894.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.788988836571276   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.552624783376748    |
| train_0/fw_bonus          | -0.9988691478967666   |
| train_0/fw_loss           | 0.005874653614591807  |
| train_0/mu_grads          | -0.023509791074320673 |
| train_0/mu_grads_std      | 0.53865537494421      |
| train_0/mu_loss           | 9.464459617515065     |
| train_0/next_q            | -9.458686392365642    |
| train_0/q_grads           | -0.015288059436716139 |
| train_0/q_grads_std       | 0.29207516461610794   |
| train_0/q_loss            | 0.13887624088668754   |
| train_0/reward            | -0.7212851620839501   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01220703125         |
| train_0/target_q          | -9.705994641511868    |
| train_1/avg_q             | -14.064788064299764   |
| train_1/current_q         | -12.66356575034284    |
| train_1/fw_bonus          | -0.9842430457472802   |
| train_1/fw_loss           | 0.08202523458749056   |
| train_1/mu_grads          | -0.06503002624958754  |
| train_1/mu_grads_std      | 0.31328642591834066   |
| train_1/mu_loss           | 4.8319427664756045    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.984007232065062   |
| train_1/q_grads           | -0.08275077007710933  |
| train_1/q_grads_std       | 0.36404137387871743   |
| train_1/q_loss            | 0.5663155895223007    |
| train_1/reward            | -2.1290966188018503   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.668887183407577   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 533.90. Rollout time: 298.95, Training time: 234.90
Evaluating epoch 51
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 4735019.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.54270604839333    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.578642642641102    |
| train_0/fw_bonus          | -0.9989112302660942   |
| train_0/fw_loss           | 0.005677836399991065  |
| train_0/mu_grads          | -0.02400782094337046  |
| train_0/mu_grads_std      | 0.541294576227665     |
| train_0/mu_loss           | 9.491107790374093     |
| train_0/next_q            | -9.486668268071757    |
| train_0/q_grads           | -0.015302621014416217 |
| train_0/q_grads_std       | 0.2939627081155777    |
| train_0/q_loss            | 0.14475658412117012   |
| train_0/reward            | -0.7218433114889194   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010986328125        |
| train_0/target_q          | -9.732463483957435    |
| train_1/avg_q             | -13.944122632008996   |
| train_1/current_q         | -12.701567904412153   |
| train_1/fw_bonus          | -0.98400127440691     |
| train_1/fw_loss           | 0.08301097638905049   |
| train_1/mu_grads          | -0.06577521432191133  |
| train_1/mu_grads_std      | 0.3135076276957989    |
| train_1/mu_loss           | 5.044439431141829     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.011598581565963   |
| train_1/q_grads           | -0.08341254964470864  |
| train_1/q_grads_std       | 0.3681019261479378    |
| train_1/q_loss            | 0.539528304096281     |
| train_1/reward            | -2.1099938038059918   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.701524019215048   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 434.21. Rollout time: 239.82, Training time: 194.36
Evaluating epoch 52
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 4826144.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.661264033328356   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.529979046228314    |
| train_0/fw_bonus          | -0.9989030838012696   |
| train_0/fw_loss           | 0.00571601465344429   |
| train_0/mu_grads          | -0.023876850493252277 |
| train_0/mu_grads_std      | 0.5435575366020202    |
| train_0/mu_loss           | 9.447898680264984     |
| train_0/next_q            | -9.441832134421176    |
| train_0/q_grads           | -0.015113886701874435 |
| train_0/q_grads_std       | 0.29597226455807685   |
| train_0/q_loss            | 0.1445758348791928    |
| train_0/reward            | -0.7193001679392182   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0120849609375       |
| train_0/target_q          | -9.684194723836827    |
| train_1/avg_q             | -14.051418666076907   |
| train_1/current_q         | -12.718923767557417   |
| train_1/fw_bonus          | -0.9834661677479744   |
| train_1/fw_loss           | 0.08519278448075056   |
| train_1/mu_grads          | -0.06611230373382568  |
| train_1/mu_grads_std      | 0.31415165662765504   |
| train_1/mu_loss           | 5.199333693751816     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.041775306859497   |
| train_1/q_grads           | -0.0841340871527791   |
| train_1/q_grads_std       | 0.3722736217081547    |
| train_1/q_loss            | 0.4641289314020508    |
| train_1/reward            | -2.1449435334252485   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.712365331811304   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 475.67. Rollout time: 260.50, Training time: 215.13
Evaluating epoch 53
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 53                   |
| policy/steps              | 4917269.0            |
| test/episodes             | 1350.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.14930445893879   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.495663402094637   |
| train_0/fw_bonus          | -0.9989402085542679  |
| train_0/fw_loss           | 0.005542320292443037 |
| train_0/mu_grads          | -0.02427402432076633 |
| train_0/mu_grads_std      | 0.5467390075325966   |
| train_0/mu_loss           | 9.412313378710753    |
| train_0/next_q            | -9.407841586036994   |
| train_0/q_grads           | -0.01503574016969651 |
| train_0/q_grads_std       | 0.2977367050945759   |
| train_0/q_loss            | 0.14094708295925712  |
| train_0/reward            | -0.7184154158087039  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0100341796875      |
| train_0/target_q          | -9.646983835286354   |
| train_1/avg_q             | -13.959925363758993  |
| train_1/current_q         | -12.733185728078917  |
| train_1/fw_bonus          | -0.9830210536718369  |
| train_1/fw_loss           | 0.0870076309889555   |
| train_1/mu_grads          | -0.06620193365961313 |
| train_1/mu_grads_std      | 0.3151144340634346   |
| train_1/mu_loss           | 5.31002543541464     |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.031621352300888  |
| train_1/q_grads           | -0.08480584789067507 |
| train_1/q_grads_std       | 0.37675648778676984  |
| train_1/q_loss            | 0.5304388387180002   |
| train_1/reward            | -2.1182073081414274  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015625            |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.729393563207598  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 426.31. Rollout time: 233.88, Training time: 192.40
Evaluating epoch 54
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 5008394.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.988346496824482   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.608545779355579    |
| train_0/fw_bonus          | -0.9988864630460739   |
| train_0/fw_loss           | 0.0057936882483772935 |
| train_0/mu_grads          | -0.025264511210843922 |
| train_0/mu_grads_std      | 0.5500793695449829    |
| train_0/mu_loss           | 9.524774399136053     |
| train_0/next_q            | -9.522168237028865    |
| train_0/q_grads           | -0.015491983341053128 |
| train_0/q_grads_std       | 0.2988434612751007    |
| train_0/q_loss            | 0.14634736026118364   |
| train_0/reward            | -0.7209276063869765   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01240234375         |
| train_0/target_q          | -9.761342866636983    |
| train_1/avg_q             | -13.901450205828274   |
| train_1/current_q         | -12.685463986852394   |
| train_1/fw_bonus          | -0.9837297767400741   |
| train_1/fw_loss           | 0.08411798924207688   |
| train_1/mu_grads          | -0.06647202111780644  |
| train_1/mu_grads_std      | 0.3149142235517502    |
| train_1/mu_loss           | 5.531418988964893     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.980056297304838   |
| train_1/q_grads           | -0.08541454263031482  |
| train_1/q_grads_std       | 0.38084213361144065   |
| train_1/q_loss            | 0.7408142505831032    |
| train_1/reward            | -2.1238228949507176   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.694580039289395   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 476.27. Rollout time: 257.76, Training time: 218.48
Evaluating epoch 55
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 5099519.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -10.228277850517975   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.34988569496285     |
| train_0/fw_bonus          | -0.9989087969064713   |
| train_0/fw_loss           | 0.005689244694076478  |
| train_0/mu_grads          | -0.025315663125365973 |
| train_0/mu_grads_std      | 0.5529136210680008    |
| train_0/mu_loss           | 9.268305444909348     |
| train_0/next_q            | -9.263272374522328    |
| train_0/q_grads           | -0.01572269485332072  |
| train_0/q_grads_std       | 0.30013188272714614   |
| train_0/q_loss            | 0.13563353957381233   |
| train_0/reward            | -0.7157507832460397   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0124755859375       |
| train_0/target_q          | -9.500726108495352    |
| train_1/avg_q             | -13.99923017518589    |
| train_1/current_q         | -12.647665902941277   |
| train_1/fw_bonus          | -0.9826735556125641   |
| train_1/fw_loss           | 0.0884245153516531    |
| train_1/mu_grads          | -0.06581518109887838  |
| train_1/mu_grads_std      | 0.3156777903437614    |
| train_1/mu_loss           | 4.809964488250169     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.995129189796279   |
| train_1/q_grads           | -0.08595816381275653  |
| train_1/q_grads_std       | 0.3846967130899429    |
| train_1/q_loss            | 0.5202228847330982    |
| train_1/reward            | -2.069327500004147    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.644682131380572   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 490.73. Rollout time: 268.40, Training time: 222.29
Evaluating epoch 56
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 5190644.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -10.55466583277371    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.530903257151897    |
| train_0/fw_bonus          | -0.9989456906914711   |
| train_0/fw_loss           | 0.0055166563717648385 |
| train_0/mu_grads          | -0.02535087438300252  |
| train_0/mu_grads_std      | 0.5553439259529114    |
| train_0/mu_loss           | 9.444196028077295     |
| train_0/next_q            | -9.439919599432455    |
| train_0/q_grads           | -0.016309176618233324 |
| train_0/q_grads_std       | 0.301742872595787     |
| train_0/q_loss            | 0.13172990326387785   |
| train_0/reward            | -0.7183693312494143   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010791015625        |
| train_0/target_q          | -9.685065115451698    |
| train_1/avg_q             | -13.983624702862155   |
| train_1/current_q         | -12.645674679016334   |
| train_1/fw_bonus          | -0.9828198611736297   |
| train_1/fw_loss           | 0.08782799430191517   |
| train_1/mu_grads          | -0.06656277589499951  |
| train_1/mu_grads_std      | 0.3165339224040508    |
| train_1/mu_loss           | 5.339059406617736     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.040738582992441   |
| train_1/q_grads           | -0.08674456104636193  |
| train_1/q_grads_std       | 0.3885772660374641    |
| train_1/q_loss            | 0.3236886575968151    |
| train_1/reward            | -2.080753190643736    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.64004195174636    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 455.45. Rollout time: 246.73, Training time: 208.69
Evaluating epoch 57
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 5281769.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.99912103167527    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.473560480443107    |
| train_0/fw_bonus          | -0.9989344865083695   |
| train_0/fw_loss           | 0.005569091055076569  |
| train_0/mu_grads          | -0.02592972028069198  |
| train_0/mu_grads_std      | 0.5582229241728782    |
| train_0/mu_loss           | 9.394514894755947     |
| train_0/next_q            | -9.389178339373185    |
| train_0/q_grads           | -0.016714653186500072 |
| train_0/q_grads_std       | 0.3030306167900562    |
| train_0/q_loss            | 0.1369567648685593    |
| train_0/reward            | -0.717533647880191    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0117919921875       |
| train_0/target_q          | -9.626318082139335    |
| train_1/avg_q             | -14.01526895730619    |
| train_1/current_q         | -12.584427702755928   |
| train_1/fw_bonus          | -0.9834366202354431   |
| train_1/fw_loss           | 0.08531326334923506   |
| train_1/mu_grads          | -0.06662530340254307  |
| train_1/mu_grads_std      | 0.3164385795593262    |
| train_1/mu_loss           | 5.403149638915835     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.033567924238739   |
| train_1/q_grads           | -0.08774616494774819  |
| train_1/q_grads_std       | 0.3930427424609661    |
| train_1/q_loss            | 0.42404202244594263   |
| train_1/reward            | -2.079792040427128    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.580916676814041   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 480.13. Rollout time: 251.88, Training time: 228.22
Evaluating epoch 58
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 5372894.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.672191830103415   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.62894793649368     |
| train_0/fw_bonus          | -0.9989023402333259   |
| train_0/fw_loss           | 0.005719449138268828  |
| train_0/mu_grads          | -0.025532133085653184 |
| train_0/mu_grads_std      | 0.5612950295209884    |
| train_0/mu_loss           | 9.540754896658056     |
| train_0/next_q            | -9.536710939694414    |
| train_0/q_grads           | -0.016971152229234576 |
| train_0/q_grads_std       | 0.3052257761359215    |
| train_0/q_loss            | 0.13793156840687998   |
| train_0/reward            | -0.7214238238353573   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0099853515625       |
| train_0/target_q          | -9.783281140124018    |
| train_1/avg_q             | -14.00029900720434    |
| train_1/current_q         | -12.588394794515995   |
| train_1/fw_bonus          | -0.9827632084488869   |
| train_1/fw_loss           | 0.08805900681763887   |
| train_1/mu_grads          | -0.06695416942238808  |
| train_1/mu_grads_std      | 0.31679894030094147   |
| train_1/mu_loss           | 5.51151217615582      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.019376372523407   |
| train_1/q_grads           | -0.0893289502710104   |
| train_1/q_grads_std       | 0.3974432870745659    |
| train_1/q_loss            | 0.5082908351784718    |
| train_1/reward            | -2.0905637281684903   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.587635932632091   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 481.36. Rollout time: 260.58, Training time: 220.75
Evaluating epoch 59
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 5464019.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.205657725664404   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.550931337221012    |
| train_0/fw_bonus          | -0.9989050671458244   |
| train_0/fw_loss           | 0.005706654267851263  |
| train_0/mu_grads          | -0.026250735437497497 |
| train_0/mu_grads_std      | 0.5639063194394112    |
| train_0/mu_loss           | 9.465962259691441     |
| train_0/next_q            | -9.461318153914402    |
| train_0/q_grads           | -0.017298586666584015 |
| train_0/q_grads_std       | 0.30798865109682083   |
| train_0/q_loss            | 0.13664515753182907   |
| train_0/reward            | -0.7198748988485022   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0094482421875       |
| train_0/target_q          | -9.705110281264222    |
| train_1/avg_q             | -14.110342963950114   |
| train_1/current_q         | -12.662513167980388   |
| train_1/fw_bonus          | -0.9821179494261741   |
| train_1/fw_loss           | 0.09068988338112831   |
| train_1/mu_grads          | -0.06641254536807537  |
| train_1/mu_grads_std      | 0.3171654805541039    |
| train_1/mu_loss           | 5.430073724701587     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.02755858230601    |
| train_1/q_grads           | -0.09009274169802665  |
| train_1/q_grads_std       | 0.40211174786090853   |
| train_1/q_loss            | 0.5412119003421125    |
| train_1/reward            | -2.0738348546103227   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.669774560588824   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 550.12. Rollout time: 297.98, Training time: 252.10
Evaluating epoch 60
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 5555144.0             |
| test/episodes             | 1525.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.985900851532879   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.59937283346478     |
| train_0/fw_bonus          | -0.9989071011543273   |
| train_0/fw_loss           | 0.005697164812590927  |
| train_0/mu_grads          | -0.02698926697485149  |
| train_0/mu_grads_std      | 0.5671756267547607    |
| train_0/mu_loss           | 9.512185793747369     |
| train_0/next_q            | -9.50830021302626     |
| train_0/q_grads           | -0.017376453196629883 |
| train_0/q_grads_std       | 0.31059489995241163   |
| train_0/q_loss            | 0.1399740461562519    |
| train_0/reward            | -0.7215848976768029   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0089111328125       |
| train_0/target_q          | -9.7543536233027      |
| train_1/avg_q             | -14.101795801943293   |
| train_1/current_q         | -12.652894053039443   |
| train_1/fw_bonus          | -0.9819974184036255   |
| train_1/fw_loss           | 0.0911813497543335    |
| train_1/mu_grads          | -0.06568860076367855  |
| train_1/mu_grads_std      | 0.3177292250096798    |
| train_1/mu_loss           | 5.379273076302077     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.003848454224089   |
| train_1/q_grads           | -0.09037021528929472  |
| train_1/q_grads_std       | 0.4060736566781998    |
| train_1/q_loss            | 0.4794314102923865    |
| train_1/reward            | -2.0462843516244904   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.656360314594128   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_60.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 502.64. Rollout time: 273.76, Training time: 228.85
Evaluating epoch 61
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 5646269.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.018775484945412   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.549665900745353    |
| train_0/fw_bonus          | -0.9988977566361428   |
| train_0/fw_loss           | 0.005740879545919597  |
| train_0/mu_grads          | -0.026850501215085386 |
| train_0/mu_grads_std      | 0.5701133519411087    |
| train_0/mu_loss           | 9.465211133257796     |
| train_0/next_q            | -9.459795140369824    |
| train_0/q_grads           | -0.01720045884139836  |
| train_0/q_grads_std       | 0.31256781369447706   |
| train_0/q_loss            | 0.13422225595172804   |
| train_0/reward            | -0.7195782713592053   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0110595703125       |
| train_0/target_q          | -9.705182234130628    |
| train_1/avg_q             | -14.045723303929526   |
| train_1/current_q         | -12.68153514848591    |
| train_1/fw_bonus          | -0.9810461387038231   |
| train_1/fw_loss           | 0.09505995735526085   |
| train_1/mu_grads          | -0.0654955854639411   |
| train_1/mu_grads_std      | 0.31897937655448916   |
| train_1/mu_loss           | 5.3532814890766955    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.0254433252825     |
| train_1/q_grads           | -0.09046790059655904  |
| train_1/q_grads_std       | 0.4110609859228134    |
| train_1/q_loss            | 0.604085632214233     |
| train_1/reward            | -2.0854693622524794   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.678694287222111   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 526.17. Rollout time: 278.71, Training time: 247.42
Evaluating epoch 62
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 5737394.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.26011200283336    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.495622061392034    |
| train_0/fw_bonus          | -0.9989096477627755   |
| train_0/fw_loss           | 0.005685199250001461  |
| train_0/mu_grads          | -0.02670208397321403  |
| train_0/mu_grads_std      | 0.573089848458767     |
| train_0/mu_loss           | 9.413313310042005     |
| train_0/next_q            | -9.407547770263037    |
| train_0/q_grads           | -0.017251713387668132 |
| train_0/q_grads_std       | 0.3147402085363865    |
| train_0/q_loss            | 0.1404214936508353    |
| train_0/reward            | -0.7190959424573521   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0093994140625       |
| train_0/target_q          | -9.647556076326444    |
| train_1/avg_q             | -14.017297427877597   |
| train_1/current_q         | -12.739413605943836   |
| train_1/fw_bonus          | -0.9802660629153251   |
| train_1/fw_loss           | 0.09824060052633285   |
| train_1/mu_grads          | -0.0652866505086422   |
| train_1/mu_grads_std      | 0.3195322029292583    |
| train_1/mu_loss           | 5.39110305345706      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.98547524809191    |
| train_1/q_grads           | -0.09112255442887544  |
| train_1/q_grads_std       | 0.4149695925414562    |
| train_1/q_loss            | 0.5732100150314734    |
| train_1/reward            | -2.1126183822649183   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.743657487975065   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 541.74. Rollout time: 295.31, Training time: 246.39
Evaluating epoch 63
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 5828519.0             |
| test/episodes             | 1600.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.314197471215866   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.543024699008464    |
| train_0/fw_bonus          | -0.998898196220398    |
| train_0/fw_loss           | 0.0057387832668609915 |
| train_0/mu_grads          | -0.026374516915529965 |
| train_0/mu_grads_std      | 0.5756965488195419    |
| train_0/mu_loss           | 9.4599365170282       |
| train_0/next_q            | -9.457185493842472    |
| train_0/q_grads           | -0.017631202191114425 |
| train_0/q_grads_std       | 0.3172077611088753    |
| train_0/q_loss            | 0.13259945236034282   |
| train_0/reward            | -0.7172347453662951   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00986328125         |
| train_0/target_q          | -9.694571950024418    |
| train_1/avg_q             | -14.014674374893733   |
| train_1/current_q         | -12.701590501210674   |
| train_1/fw_bonus          | -0.9798598036170005   |
| train_1/fw_loss           | 0.09989699069410563   |
| train_1/mu_grads          | -0.06662228293716907  |
| train_1/mu_grads_std      | 0.32155297696590424   |
| train_1/mu_loss           | 5.045237345184179     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.039340844042036   |
| train_1/q_grads           | -0.09170064926147461  |
| train_1/q_grads_std       | 0.4180748127400875    |
| train_1/q_loss            | 0.6036679539337223    |
| train_1/reward            | -2.1090827405008894   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.698691635170963   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 584.26. Rollout time: 316.43, Training time: 267.79
Evaluating epoch 64
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 5919644.0             |
| test/episodes             | 1625.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.495075725541133   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.521940866889107    |
| train_0/fw_bonus          | -0.9989216655492783   |
| train_0/fw_loss           | 0.0056290556211024525 |
| train_0/mu_grads          | -0.026110964873805643 |
| train_0/mu_grads_std      | 0.5776875257492066    |
| train_0/mu_loss           | 9.441397137180193     |
| train_0/next_q            | -9.435232867494955    |
| train_0/q_grads           | -0.01793646034784615  |
| train_0/q_grads_std       | 0.3193608053028584    |
| train_0/q_loss            | 0.13592370675131007   |
| train_0/reward            | -0.7180521398004203   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0074462890625       |
| train_0/target_q          | -9.675682285081       |
| train_1/avg_q             | -13.991177177332068   |
| train_1/current_q         | -12.63785248749498    |
| train_1/fw_bonus          | -0.9788783863186836   |
| train_1/fw_loss           | 0.10389861110597849   |
| train_1/mu_grads          | -0.06662466377019882  |
| train_1/mu_grads_std      | 0.32209145948290824   |
| train_1/mu_loss           | 5.280284368429655     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.008691127873481   |
| train_1/q_grads           | -0.09202228635549545  |
| train_1/q_grads_std       | 0.4215099163353443    |
| train_1/q_loss            | 0.5022041207465214    |
| train_1/reward            | -2.1080549125188552   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.63362304387646    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 567.15. Rollout time: 323.94, Training time: 243.17
Evaluating epoch 65
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 6010769.0             |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.86146006237446    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.378935392929463    |
| train_0/fw_bonus          | -0.9988585814833641   |
| train_0/fw_loss           | 0.0059241491835564375 |
| train_0/mu_grads          | -0.027508208900690077 |
| train_0/mu_grads_std      | 0.5795131370425224    |
| train_0/mu_loss           | 9.293553406794206     |
| train_0/next_q            | -9.288806442644367    |
| train_0/q_grads           | -0.0189461053814739   |
| train_0/q_grads_std       | 0.3215057007968426    |
| train_0/q_loss            | 0.13212762536771247   |
| train_0/reward            | -0.7170196166494861   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0108642578125       |
| train_0/target_q          | -9.531726787925345    |
| train_1/avg_q             | -14.034181865962083   |
| train_1/current_q         | -12.65631154844945    |
| train_1/fw_bonus          | -0.979316908121109    |
| train_1/fw_loss           | 0.1021106194704771    |
| train_1/mu_grads          | -0.06611051168292761  |
| train_1/mu_grads_std      | 0.322449603676796     |
| train_1/mu_loss           | 5.000807127220088     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.031791314166544   |
| train_1/q_grads           | -0.09294356666505336  |
| train_1/q_grads_std       | 0.4245870605111122    |
| train_1/q_loss            | 0.47443479364379815   |
| train_1/reward            | -2.106076907431998    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001806640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.651669124945514   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 493.21. Rollout time: 271.80, Training time: 221.37
Evaluating epoch 66
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 6101894.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.268128128328854   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.558358153094199    |
| train_0/fw_bonus          | -0.9988718286156655   |
| train_0/fw_loss           | 0.005862128466833383  |
| train_0/mu_grads          | -0.027625833777710794 |
| train_0/mu_grads_std      | 0.5805540844798088    |
| train_0/mu_loss           | 9.468972974751248     |
| train_0/next_q            | -9.463801371366364    |
| train_0/q_grads           | -0.018583450373262166 |
| train_0/q_grads_std       | 0.3237581841647625    |
| train_0/q_loss            | 0.13863835202221378   |
| train_0/reward            | -0.7217869893444003   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0107421875          |
| train_0/target_q          | -9.71384003665805     |
| train_1/avg_q             | -13.941422390987405   |
| train_1/current_q         | -12.590114177374762   |
| train_1/fw_bonus          | -0.9793199732899666   |
| train_1/fw_loss           | 0.1020980978384614    |
| train_1/mu_grads          | -0.06634342130273581  |
| train_1/mu_grads_std      | 0.32273833751678466   |
| train_1/mu_loss           | 4.842471756304053     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.009256081145498   |
| train_1/q_grads           | -0.09367902968078852  |
| train_1/q_grads_std       | 0.42730254828929903   |
| train_1/q_loss            | 0.5027204072009852    |
| train_1/reward            | -2.0782708265862313   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.593330313729316   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 442.67. Rollout time: 249.84, Training time: 192.81
Evaluating epoch 67
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 6193019.0             |
| test/episodes             | 1700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.557376395578993   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.556694602728019    |
| train_0/fw_bonus          | -0.9988932266831398   |
| train_0/fw_loss           | 0.005762004293501377  |
| train_0/mu_grads          | -0.028094923589378595 |
| train_0/mu_grads_std      | 0.5822398200631141    |
| train_0/mu_loss           | 9.468835092975883     |
| train_0/next_q            | -9.462506474071589    |
| train_0/q_grads           | -0.019148073438555003 |
| train_0/q_grads_std       | 0.3268030874431133    |
| train_0/q_loss            | 0.13675789457392926   |
| train_0/reward            | -0.7213460325496271   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0134765625          |
| train_0/target_q          | -9.713547615163506    |
| train_1/avg_q             | -14.022713484429097   |
| train_1/current_q         | -12.657320088889149   |
| train_1/fw_bonus          | -0.9790548339486123   |
| train_1/fw_loss           | 0.10317914113402367   |
| train_1/mu_grads          | -0.06637731213122607  |
| train_1/mu_grads_std      | 0.3234045349061489    |
| train_1/mu_loss           | 5.259322579837429     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.023805326111903   |
| train_1/q_grads           | -0.09449823424220086  |
| train_1/q_grads_std       | 0.4300901547074318    |
| train_1/q_loss            | 0.37218447277012123   |
| train_1/reward            | -2.0806162851593397   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.657097240573421   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 437.73. Rollout time: 242.71, Training time: 194.99
Evaluating epoch 68
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 68                   |
| policy/steps              | 6284144.0            |
| test/episodes             | 1725.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.69192030779722   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6900.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.64215452832175    |
| train_0/fw_bonus          | -0.9989105060696601  |
| train_0/fw_loss           | 0.005681203072890639 |
| train_0/mu_grads          | -0.02857161797583103 |
| train_0/mu_grads_std      | 0.5841663792729378   |
| train_0/mu_loss           | 9.551413350812306    |
| train_0/next_q            | -9.54531983318949    |
| train_0/q_grads           | -0.01947459443472326 |
| train_0/q_grads_std       | 0.3293190270662308   |
| train_0/q_loss            | 0.14207630073775313  |
| train_0/reward            | -0.7240035965056449  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0076904296875      |
| train_0/target_q          | -9.797507208231043   |
| train_1/avg_q             | -14.012140055038227  |
| train_1/current_q         | -12.71904050760015   |
| train_1/fw_bonus          | -0.9791532590985298  |
| train_1/fw_loss           | 0.10277782622724771  |
| train_1/mu_grads          | -0.06647743862122298 |
| train_1/mu_grads_std      | 0.32386588007211686  |
| train_1/mu_loss           | 5.224584967465395    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.019475486066398  |
| train_1/q_grads           | -0.09504513088613749 |
| train_1/q_grads_std       | 0.4335197612643242   |
| train_1/q_loss            | 0.39083171339698425  |
| train_1/reward            | -2.090919404009037   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013427734375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.719741499098152  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 440.32. Rollout time: 246.27, Training time: 194.02
Evaluating epoch 69
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 6375269.0             |
| test/episodes             | 1750.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.514859573145602   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.557852074587611    |
| train_0/fw_bonus          | -0.9989099055528641   |
| train_0/fw_loss           | 0.0056840547826141116 |
| train_0/mu_grads          | -0.028387391287833453 |
| train_0/mu_grads_std      | 0.5865075901150704    |
| train_0/mu_loss           | 9.468189046637251     |
| train_0/next_q            | -9.462833488367332    |
| train_0/q_grads           | -0.019754095701500773 |
| train_0/q_grads_std       | 0.33142743557691573   |
| train_0/q_loss            | 0.14166638636211845   |
| train_0/reward            | -0.7221966506825993   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0094970703125       |
| train_0/target_q          | -9.710827580975774    |
| train_1/avg_q             | -14.079764103183187   |
| train_1/current_q         | -12.716104967314882   |
| train_1/fw_bonus          | -0.9799685031175613   |
| train_1/fw_loss           | 0.09945382550358772   |
| train_1/mu_grads          | -0.06654018238186836  |
| train_1/mu_grads_std      | 0.3250076562166214    |
| train_1/mu_loss           | 5.128492182757851     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.038264882886233   |
| train_1/q_grads           | -0.09572985116392374  |
| train_1/q_grads_std       | 0.43681113943457606   |
| train_1/q_loss            | 0.4348906641148611    |
| train_1/reward            | -2.137005737272557    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.712891643753924   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 438.86. Rollout time: 243.40, Training time: 195.43
Evaluating epoch 70
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 70                   |
| policy/steps              | 6466394.0            |
| test/episodes             | 1775.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.165269332143264  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.524416807608855   |
| train_0/fw_bonus          | -0.9989445701241493  |
| train_0/fw_loss           | 0.005521912011317909 |
| train_0/mu_grads          | -0.0286311415489763  |
| train_0/mu_grads_std      | 0.5897334739565849   |
| train_0/mu_loss           | 9.432564248625615    |
| train_0/next_q            | -9.428633973144485   |
| train_0/q_grads           | -0.02051157345995307 |
| train_0/q_grads_std       | 0.3342660889029503   |
| train_0/q_loss            | 0.13782658925223715  |
| train_0/reward            | -0.7209200388366298  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.008349609375       |
| train_0/target_q          | -9.677548851635853   |
| train_1/avg_q             | -14.014474721244333  |
| train_1/current_q         | -12.653924542409948  |
| train_1/fw_bonus          | -0.9804882377386093  |
| train_1/fw_loss           | 0.09733471591025591  |
| train_1/mu_grads          | -0.06669615749269724 |
| train_1/mu_grads_std      | 0.3254757270216942   |
| train_1/mu_loss           | 5.066880613121828    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.017980702094723  |
| train_1/q_grads           | -0.09630407486110926 |
| train_1/q_grads_std       | 0.4407855808734894   |
| train_1/q_loss            | 0.3414736339354476   |
| train_1/reward            | -2.086435526254354   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00146484375        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.6539427566853    |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_70.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 440.55. Rollout time: 248.27, Training time: 192.26
Evaluating epoch 71
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 6557519.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.07579915351514    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.495160005521836    |
| train_0/fw_bonus          | -0.9989256098866462   |
| train_0/fw_loss           | 0.005610615957994014  |
| train_0/mu_grads          | -0.028919546166434884 |
| train_0/mu_grads_std      | 0.5920441150665283    |
| train_0/mu_loss           | 9.405119117223107     |
| train_0/next_q            | -9.401468840936253    |
| train_0/q_grads           | -0.02057737852446735  |
| train_0/q_grads_std       | 0.3358925387263298    |
| train_0/q_loss            | 0.13932811701965228   |
| train_0/reward            | -0.7206908295811445   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007470703125        |
| train_0/target_q          | -9.647208407791078    |
| train_1/avg_q             | -14.047649654429094   |
| train_1/current_q         | -12.682688488903594   |
| train_1/fw_bonus          | -0.9806569933891296   |
| train_1/fw_loss           | 0.09664660524576903   |
| train_1/mu_grads          | -0.06747537441551685  |
| train_1/mu_grads_std      | 0.32562684267759323   |
| train_1/mu_loss           | 5.301833825371366     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.064600859301606   |
| train_1/q_grads           | -0.09739580973982812  |
| train_1/q_grads_std       | 0.44444807395339014   |
| train_1/q_loss            | 0.3069894529797691    |
| train_1/reward            | -2.0913050646020563   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021484375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.68127290798517    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 435.73. Rollout time: 244.31, Training time: 191.40
Evaluating epoch 72
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 6648644.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.515193475853497   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.460308551627088    |
| train_0/fw_bonus          | -0.9989397972822189   |
| train_0/fw_loss           | 0.005544236570131034  |
| train_0/mu_grads          | -0.029259550012648107 |
| train_0/mu_grads_std      | 0.5945499762892723    |
| train_0/mu_loss           | 9.370773242828587     |
| train_0/next_q            | -9.365043346885857    |
| train_0/q_grads           | -0.02101878058165312  |
| train_0/q_grads_std       | 0.3380930468440056    |
| train_0/q_loss            | 0.13769039957175205   |
| train_0/reward            | -0.7206490976510395   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008251953125        |
| train_0/target_q          | -9.613945206321299    |
| train_1/avg_q             | -14.08372505930933    |
| train_1/current_q         | -12.636724493349572   |
| train_1/fw_bonus          | -0.9805399686098099   |
| train_1/fw_loss           | 0.0971238013356924    |
| train_1/mu_grads          | -0.06811788193881511  |
| train_1/mu_grads_std      | 0.32490269318223      |
| train_1/mu_loss           | 5.221493760392526     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.037777771062215   |
| train_1/q_grads           | -0.09807639829814434  |
| train_1/q_grads_std       | 0.4476627610623837    |
| train_1/q_loss            | 0.4123910007283237    |
| train_1/reward            | -2.0839467421312294   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.633605140886084   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 434.05. Rollout time: 240.00, Training time: 194.02
Evaluating epoch 73
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 6739769.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.671677860467769   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.554712387452897    |
| train_0/fw_bonus          | -0.9989375963807106   |
| train_0/fw_loss           | 0.005554494692478329  |
| train_0/mu_grads          | -0.0291630735155195   |
| train_0/mu_grads_std      | 0.5970246344804764    |
| train_0/mu_loss           | 9.466762973799227     |
| train_0/next_q            | -9.461737355348225    |
| train_0/q_grads           | -0.021456063818186523 |
| train_0/q_grads_std       | 0.34037310630083084   |
| train_0/q_loss            | 0.13535740504529964   |
| train_0/reward            | -0.7196714386198437   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00712890625         |
| train_0/target_q          | -9.708367275075691    |
| train_1/avg_q             | -14.044021972801797   |
| train_1/current_q         | -12.557161423041261   |
| train_1/fw_bonus          | -0.9801182717084884   |
| train_1/fw_loss           | 0.09884321335703135   |
| train_1/mu_grads          | -0.06833540871739388  |
| train_1/mu_grads_std      | 0.32511005029082296   |
| train_1/mu_loss           | 5.539996659890798     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.040238285079928   |
| train_1/q_grads           | -0.09870764855295419  |
| train_1/q_grads_std       | 0.45061948224902154   |
| train_1/q_loss            | 0.8067559107713851    |
| train_1/reward            | -2.052070851454482    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.557818390886677   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 437.97. Rollout time: 242.18, Training time: 195.75
Evaluating epoch 74
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 6830894.0             |
| test/episodes             | 1875.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.148449836838932   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.531035960785573    |
| train_0/fw_bonus          | -0.9989362955093384   |
| train_0/fw_loss           | 0.005560616229195148  |
| train_0/mu_grads          | -0.028360675321891904 |
| train_0/mu_grads_std      | 0.6004031240940094    |
| train_0/mu_loss           | 9.439837853251438     |
| train_0/next_q            | -9.435482794739974    |
| train_0/q_grads           | -0.02169328392483294  |
| train_0/q_grads_std       | 0.3427950099110603    |
| train_0/q_loss            | 0.1399692182968945    |
| train_0/reward            | -0.721282112296467    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008642578125        |
| train_0/target_q          | -9.685279159374474    |
| train_1/avg_q             | -14.006358139509185   |
| train_1/current_q         | -12.564812052639326   |
| train_1/fw_bonus          | -0.9792644485831261   |
| train_1/fw_loss           | 0.10232443828135729   |
| train_1/mu_grads          | -0.06869641710072756  |
| train_1/mu_grads_std      | 0.32579429894685746   |
| train_1/mu_loss           | 5.461856718870708     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.014117548681218   |
| train_1/q_grads           | -0.09941804315894842  |
| train_1/q_grads_std       | 0.4528901405632496    |
| train_1/q_loss            | 0.5481168322497151    |
| train_1/reward            | -2.0996786174095177   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.565071875702664   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 447.19. Rollout time: 255.19, Training time: 191.98
Evaluating epoch 75
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 75                   |
| policy/steps              | 6922019.0            |
| test/episodes             | 1900.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.586205484448648  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.566024423104661   |
| train_0/fw_bonus          | -0.9989463075995445  |
| train_0/fw_loss           | 0.005513878772035241 |
| train_0/mu_grads          | -0.02859493251889944 |
| train_0/mu_grads_std      | 0.6026919096708298   |
| train_0/mu_loss           | 9.478753205535664    |
| train_0/next_q            | -9.475651665186536   |
| train_0/q_grads           | -0.02216919343918562 |
| train_0/q_grads_std       | 0.3452580042183399   |
| train_0/q_loss            | 0.13908423947231102  |
| train_0/reward            | -0.7200297843948646  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0081787109375      |
| train_0/target_q          | -9.72155093495254    |
| train_1/avg_q             | -14.08335180667201   |
| train_1/current_q         | -12.58312153482288   |
| train_1/fw_bonus          | -0.9793101370334625  |
| train_1/fw_loss           | 0.10213821157813072  |
| train_1/mu_grads          | -0.06969078481197358 |
| train_1/mu_grads_std      | 0.326155736297369    |
| train_1/mu_loss           | 5.376597158333743    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.040820742755878  |
| train_1/q_grads           | -0.1006222814321518  |
| train_1/q_grads_std       | 0.4541151523590088   |
| train_1/q_loss            | 0.5626905752366923   |
| train_1/reward            | -2.0477849500101     |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00126953125        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.582711534188055  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 440.36. Rollout time: 241.92, Training time: 198.41
Evaluating epoch 76
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 7013144.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.595716893322216   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.555406774173473    |
| train_0/fw_bonus          | -0.9989547193050384   |
| train_0/fw_loss           | 0.005474451428744942  |
| train_0/mu_grads          | -0.02764616082422435  |
| train_0/mu_grads_std      | 0.604471142590046     |
| train_0/mu_loss           | 9.465784665649954     |
| train_0/next_q            | -9.46176873259661     |
| train_0/q_grads           | -0.022487337794154884 |
| train_0/q_grads_std       | 0.3467306919395924    |
| train_0/q_loss            | 0.13468789050435964   |
| train_0/reward            | -0.7202048979357641   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0068115234375       |
| train_0/target_q          | -9.710791488393138    |
| train_1/avg_q             | -13.99872096734645    |
| train_1/current_q         | -12.564037789560226   |
| train_1/fw_bonus          | -0.979545584321022    |
| train_1/fw_loss           | 0.10117821730673313   |
| train_1/mu_grads          | -0.07064558956772089  |
| train_1/mu_grads_std      | 0.32806306183338163   |
| train_1/mu_loss           | 5.381840393425407     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.050627476752448   |
| train_1/q_grads           | -0.10104965642094613  |
| train_1/q_grads_std       | 0.45533930584788324   |
| train_1/q_loss            | 0.49713813423269937   |
| train_1/reward            | -2.063368982008251    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00126953125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.559732647780226   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 438.18. Rollout time: 242.49, Training time: 195.66
Evaluating epoch 77
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 7104269.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -11.09621823025176    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.4690114833829      |
| train_0/fw_bonus          | -0.998993793129921    |
| train_0/fw_loss           | 0.005291693506296724  |
| train_0/mu_grads          | -0.026758756022900343 |
| train_0/mu_grads_std      | 0.6064645975828171    |
| train_0/mu_loss           | 9.379889563270975     |
| train_0/next_q            | -9.374859335133856    |
| train_0/q_grads           | -0.022853329312056303 |
| train_0/q_grads_std       | 0.3487007364630699    |
| train_0/q_loss            | 0.137139621608695     |
| train_0/reward            | -0.7203953333730169   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007470703125        |
| train_0/target_q          | -9.621578891067134    |
| train_1/avg_q             | -14.055731129300504   |
| train_1/current_q         | -12.535425503669114   |
| train_1/fw_bonus          | -0.9807263389229774   |
| train_1/fw_loss           | 0.09636391010135412   |
| train_1/mu_grads          | -0.07102125268429518  |
| train_1/mu_grads_std      | 0.3300318576395512    |
| train_1/mu_loss           | 5.225433534008208     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.028266541078352   |
| train_1/q_grads           | -0.10171765610575675  |
| train_1/q_grads_std       | 0.45722256153821944   |
| train_1/q_loss            | 0.5692667324149141    |
| train_1/reward            | -2.0379461776814423   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.536268894230147   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 442.28. Rollout time: 245.66, Training time: 196.59
Evaluating epoch 78
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 7195394.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.291572466221755   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.557793767762993    |
| train_0/fw_bonus          | -0.9989948019385337   |
| train_0/fw_loss           | 0.005286984145641327  |
| train_0/mu_grads          | -0.02700302884913981  |
| train_0/mu_grads_std      | 0.6082374066114425    |
| train_0/mu_loss           | 9.467596386057505     |
| train_0/next_q            | -9.462987972393028    |
| train_0/q_grads           | -0.023080963734537364 |
| train_0/q_grads_std       | 0.35074346959590913   |
| train_0/q_loss            | 0.1341344234506795    |
| train_0/reward            | -0.7211160518541874   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0071044921875       |
| train_0/target_q          | -9.712450261757215    |
| train_1/avg_q             | -14.061968620656483   |
| train_1/current_q         | -12.59655747596812    |
| train_1/fw_bonus          | -0.9797705739736557   |
| train_1/fw_loss           | 0.10026082657277584   |
| train_1/mu_grads          | -0.07132086232304573  |
| train_1/mu_grads_std      | 0.3306827828288078    |
| train_1/mu_loss           | 5.281937427555688     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.016532823401732   |
| train_1/q_grads           | -0.10304932612925768  |
| train_1/q_grads_std       | 0.4600078172981739    |
| train_1/q_loss            | 0.46608068341876596   |
| train_1/reward            | -2.069755896012066    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.595555727079757   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 443.26. Rollout time: 246.54, Training time: 196.69
Evaluating epoch 79
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 7286519.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.304046262791704   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.502867708161203    |
| train_0/fw_bonus          | -0.9990261480212211   |
| train_0/fw_loss           | 0.005140321364160627  |
| train_0/mu_grads          | -0.0274623220320791   |
| train_0/mu_grads_std      | 0.6102951809763908    |
| train_0/mu_loss           | 9.413037766447133     |
| train_0/next_q            | -9.407550503832521    |
| train_0/q_grads           | -0.023063292633742093 |
| train_0/q_grads_std       | 0.35338685363531114   |
| train_0/q_loss            | 0.13393807141794353   |
| train_0/reward            | -0.720533585807425    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0083251953125       |
| train_0/target_q          | -9.654349154605972    |
| train_1/avg_q             | -14.060766796836617   |
| train_1/current_q         | -12.564050923844363   |
| train_1/fw_bonus          | -0.9789935410022735   |
| train_1/fw_loss           | 0.10342907775193452   |
| train_1/mu_grads          | -0.0718929110094905   |
| train_1/mu_grads_std      | 0.3325706958770752    |
| train_1/mu_loss           | 5.301369883693536     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.008598061177555   |
| train_1/q_grads           | -0.10396664440631867  |
| train_1/q_grads_std       | 0.4630314461886883    |
| train_1/q_loss            | 0.40537186970732186   |
| train_1/reward            | -2.0795236242491226   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.560922897342243   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 449.14. Rollout time: 252.80, Training time: 196.30
Evaluating epoch 80
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 7377644.0             |
| test/episodes             | 2025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.901818518564703   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.535227179221621    |
| train_0/fw_bonus          | -0.9990101352334022   |
| train_0/fw_loss           | 0.005215243890415877  |
| train_0/mu_grads          | -0.027586252288892867 |
| train_0/mu_grads_std      | 0.612438015639782     |
| train_0/mu_loss           | 9.445656222450857     |
| train_0/next_q            | -9.442200134318027    |
| train_0/q_grads           | -0.0233581374399364   |
| train_0/q_grads_std       | 0.3560205861926079    |
| train_0/q_loss            | 0.12803242252515534   |
| train_0/reward            | -0.7185724513328751   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0076904296875       |
| train_0/target_q          | -9.687842744004296    |
| train_1/avg_q             | -13.99177160314094    |
| train_1/current_q         | -12.5958219015277     |
| train_1/fw_bonus          | -0.9777389660477638   |
| train_1/fw_loss           | 0.10854435190558434   |
| train_1/mu_grads          | -0.07241349238902331  |
| train_1/mu_grads_std      | 0.3343561589717865    |
| train_1/mu_loss           | 5.319841776100921     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.042361397337118   |
| train_1/q_grads           | -0.10481617748737335  |
| train_1/q_grads_std       | 0.46605757921934127   |
| train_1/q_loss            | 0.4851754090334719    |
| train_1/reward            | -2.1056053220730973   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.59466585948029    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_80.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 442.69. Rollout time: 245.65, Training time: 197.01
Evaluating epoch 81
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 7468685.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.703695627471467   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.496193457642967    |
| train_0/fw_bonus          | -0.9990344986319541   |
| train_0/fw_loss           | 0.005101300973910839  |
| train_0/mu_grads          | -0.027902185404673218 |
| train_0/mu_grads_std      | 0.6152067214250565    |
| train_0/mu_loss           | 9.407874671973888     |
| train_0/next_q            | -9.402880293249172    |
| train_0/q_grads           | -0.023759179236367344 |
| train_0/q_grads_std       | 0.358790522813797     |
| train_0/q_loss            | 0.1309106774727715    |
| train_0/reward            | -0.7189020149991847   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0067626953125       |
| train_0/target_q          | -9.6484027456824      |
| train_1/avg_q             | -13.992688323950889   |
| train_1/current_q         | -12.594123132337884   |
| train_1/fw_bonus          | -0.9777284547686577   |
| train_1/fw_loss           | 0.10858722869306803   |
| train_1/mu_grads          | -0.07338145673274994  |
| train_1/mu_grads_std      | 0.33405120968818663   |
| train_1/mu_loss           | 5.283620036141653     |
| train_1/n_subgoals        | 2697.0                |
| train_1/next_q            | -14.015621228926324   |
| train_1/q_grads           | -0.10582222044467926  |
| train_1/q_grads_std       | 0.4706213422119617    |
| train_1/q_loss            | 0.43386664104467043   |
| train_1/reward            | -2.0832611967489356   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.59967126976711    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 449.74. Rollout time: 252.05, Training time: 197.66
Evaluating epoch 82
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 82                   |
| policy/steps              | 7559810.0            |
| test/episodes             | 2075.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.729597393892833  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.606871538378343   |
| train_0/fw_bonus          | -0.9989971101284028  |
| train_0/fw_loss           | 0.00527618263149634  |
| train_0/mu_grads          | -0.02803151202388108 |
| train_0/mu_grads_std      | 0.6173706844449043   |
| train_0/mu_loss           | 9.518787532316287    |
| train_0/next_q            | -9.514273625489926   |
| train_0/q_grads           | -0.02423670985735953 |
| train_0/q_grads_std       | 0.36154474690556526  |
| train_0/q_loss            | 0.13554786592313767  |
| train_0/reward            | -0.7213491401213105  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.008251953125       |
| train_0/target_q          | -9.76094232478573    |
| train_1/avg_q             | -14.11528798326048   |
| train_1/current_q         | -12.5617512166098    |
| train_1/fw_bonus          | -0.9765669167041778  |
| train_1/fw_loss           | 0.11332313846796752  |
| train_1/mu_grads          | -0.07371009141206741 |
| train_1/mu_grads_std      | 0.33618256971240046  |
| train_1/mu_loss           | 5.560827959365611    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.007219946776024  |
| train_1/q_grads           | -0.10631460323929787 |
| train_1/q_grads_std       | 0.47459280118346214  |
| train_1/q_loss            | 0.677740682994124    |
| train_1/reward            | -2.087538829593541   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001611328125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.568257407390494  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 448.46. Rollout time: 248.31, Training time: 200.12
Evaluating epoch 83
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 83                   |
| policy/steps              | 7650935.0            |
| test/episodes             | 2100.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.868649611834984  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.51614259713447    |
| train_0/fw_bonus          | -0.9990141838788986  |
| train_0/fw_loss           | 0.005196341429837048 |
| train_0/mu_grads          | -0.02817790852859616 |
| train_0/mu_grads_std      | 0.6188355103135109   |
| train_0/mu_loss           | 9.426451957329991    |
| train_0/next_q            | -9.421987376283969   |
| train_0/q_grads           | -0.02437939718365669 |
| train_0/q_grads_std       | 0.36441655084490776  |
| train_0/q_loss            | 0.13465405689355053  |
| train_0/reward            | -0.7202224214313901  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007177734375       |
| train_0/target_q          | -9.668222675690757   |
| train_1/avg_q             | -14.062449936615595  |
| train_1/current_q         | -12.471978401979154  |
| train_1/fw_bonus          | -0.9764638260006905  |
| train_1/fw_loss           | 0.11374351792037488  |
| train_1/mu_grads          | -0.07402560543268918 |
| train_1/mu_grads_std      | 0.3377992555499077   |
| train_1/mu_loss           | 5.493601720799188    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.02943386046903   |
| train_1/q_grads           | -0.10723304655402899 |
| train_1/q_grads_std       | 0.4776303768157959   |
| train_1/q_loss            | 0.3836389358344533   |
| train_1/reward            | -2.091930639302882   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001220703125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.466635856578298  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 449.63. Rollout time: 249.94, Training time: 199.66
Evaluating epoch 84
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 7742060.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.165821490741763   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.547325207331514    |
| train_0/fw_bonus          | -0.9990007296204567   |
| train_0/fw_loss           | 0.0052592331310734155 |
| train_0/mu_grads          | -0.028334358474239707 |
| train_0/mu_grads_std      | 0.6217006176710129    |
| train_0/mu_loss           | 9.453735288729046     |
| train_0/next_q            | -9.449220126810943    |
| train_0/q_grads           | -0.024973488273099066 |
| train_0/q_grads_std       | 0.3668834127485752    |
| train_0/q_loss            | 0.13514552819145026   |
| train_0/reward            | -0.7218026122813171   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007568359375        |
| train_0/target_q          | -9.70127842533822     |
| train_1/avg_q             | -13.993704814481495   |
| train_1/current_q         | -12.359615975584074   |
| train_1/fw_bonus          | -0.9767216548323632   |
| train_1/fw_loss           | 0.11269225347787142   |
| train_1/mu_grads          | -0.07437387891113759  |
| train_1/mu_grads_std      | 0.3383893005549908    |
| train_1/mu_loss           | 5.33193794988985      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.007839857115673   |
| train_1/q_grads           | -0.10798043366521597  |
| train_1/q_grads_std       | 0.4822636038064957    |
| train_1/q_loss            | 0.5773854757745704    |
| train_1/reward            | -2.0908144383312903   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.361399926163347   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 457.35. Rollout time: 254.10, Training time: 203.23
Evaluating epoch 85
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 7833185.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.047495802438423   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.545375648002903    |
| train_0/fw_bonus          | -0.9989251345396042   |
| train_0/fw_loss           | 0.005612819106318057  |
| train_0/mu_grads          | -0.02932255370542407  |
| train_0/mu_grads_std      | 0.6248427614569664    |
| train_0/mu_loss           | 9.448385023631229     |
| train_0/next_q            | -9.44489115295662     |
| train_0/q_grads           | -0.025143693992868067 |
| train_0/q_grads_std       | 0.36945396587252616   |
| train_0/q_loss            | 0.1392597687354381    |
| train_0/reward            | -0.7236446955474094   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0089111328125       |
| train_0/target_q          | -9.695705072055905    |
| train_1/avg_q             | -14.06192883601533    |
| train_1/current_q         | -12.432428705504858   |
| train_1/fw_bonus          | -0.9764290094375611   |
| train_1/fw_loss           | 0.11388542372733354   |
| train_1/mu_grads          | -0.07438672501593828  |
| train_1/mu_grads_std      | 0.33822434321045874   |
| train_1/mu_loss           | 5.416134663057286     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.032771834523453   |
| train_1/q_grads           | -0.10868211947381497  |
| train_1/q_grads_std       | 0.4855239748954773    |
| train_1/q_loss            | 0.33198645599036974   |
| train_1/reward            | -2.0506778853312424   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.427112035963166   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 451.54. Rollout time: 248.22, Training time: 203.29
Evaluating epoch 86
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 7924310.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.830529954235493   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.548357710096196    |
| train_0/fw_bonus          | -0.9989429697394371   |
| train_0/fw_loss           | 0.005529383721295744  |
| train_0/mu_grads          | -0.02966918391175568  |
| train_0/mu_grads_std      | 0.6275591239333153    |
| train_0/mu_loss           | 9.452262059679489     |
| train_0/next_q            | -9.447900594826212    |
| train_0/q_grads           | -0.025043568341061473 |
| train_0/q_grads_std       | 0.3722951225936413    |
| train_0/q_loss            | 0.13482364764911936   |
| train_0/reward            | -0.7235193379659904   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008935546875        |
| train_0/target_q          | -9.69979476080889     |
| train_1/avg_q             | -14.087479090100175   |
| train_1/current_q         | -12.43381089492276    |
| train_1/fw_bonus          | -0.9771084457635879   |
| train_1/fw_loss           | 0.1111151723191142    |
| train_1/mu_grads          | -0.07453282047063112  |
| train_1/mu_grads_std      | 0.33989426493644714   |
| train_1/mu_loss           | 5.453424042263778     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.008478159774238   |
| train_1/q_grads           | -0.10881692301481963  |
| train_1/q_grads_std       | 0.48798864260315894   |
| train_1/q_loss            | 0.4255852110532218    |
| train_1/reward            | -2.073808128014207    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.433143639685813   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 449.35. Rollout time: 245.69, Training time: 203.63
Evaluating epoch 87
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 8015435.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.478913066509797   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.57574496631712     |
| train_0/fw_bonus          | -0.9989296048879623   |
| train_0/fw_loss           | 0.00559196398826316   |
| train_0/mu_grads          | -0.030779228126630188 |
| train_0/mu_grads_std      | 0.6306763052940368    |
| train_0/mu_loss           | 9.474095276521876     |
| train_0/next_q            | -9.469951037944432    |
| train_0/q_grads           | -0.025366314593702553 |
| train_0/q_grads_std       | 0.37552802786231043   |
| train_0/q_loss            | 0.14341760291042185   |
| train_0/reward            | -0.7262958512350451   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0091796875          |
| train_0/target_q          | -9.726028577902289    |
| train_1/avg_q             | -13.966654489801519   |
| train_1/current_q         | -12.508121698065281   |
| train_1/fw_bonus          | -0.9765017285943032   |
| train_1/fw_loss           | 0.11358897313475609   |
| train_1/mu_grads          | -0.07468919176608324  |
| train_1/mu_grads_std      | 0.34165889024734497   |
| train_1/mu_loss           | 5.417324651443267     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.035737735144622   |
| train_1/q_grads           | -0.10868062693625688  |
| train_1/q_grads_std       | 0.4907071366906166    |
| train_1/q_loss            | 0.4850324480635207    |
| train_1/reward            | -2.0889710754112456   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.504472143023966   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 446.18. Rollout time: 240.31, Training time: 205.84
Evaluating epoch 88
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 8106560.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.316669458880467   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.527939222780926    |
| train_0/fw_bonus          | -0.9989501252770424   |
| train_0/fw_loss           | 0.005495950207114219  |
| train_0/mu_grads          | -0.031874922756105664 |
| train_0/mu_grads_std      | 0.6338547512888908    |
| train_0/mu_loss           | 9.42886223869137      |
| train_0/next_q            | -9.42333049524179     |
| train_0/q_grads           | -0.02588719977065921  |
| train_0/q_grads_std       | 0.3793700337409973    |
| train_0/q_loss            | 0.14463584307934158   |
| train_0/reward            | -0.7258666618952703   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010595703125        |
| train_0/target_q          | -9.680601991610313    |
| train_1/avg_q             | -14.046045171056418   |
| train_1/current_q         | -12.585762125151467   |
| train_1/fw_bonus          | -0.9772081673145294   |
| train_1/fw_loss           | 0.11070858798921109   |
| train_1/mu_grads          | -0.07464967127889395  |
| train_1/mu_grads_std      | 0.3434730291366577    |
| train_1/mu_loss           | 5.528702935490892     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.049256822464361   |
| train_1/q_grads           | -0.10858009699732066  |
| train_1/q_grads_std       | 0.49313291236758233   |
| train_1/q_loss            | 0.5536184115881526    |
| train_1/reward            | -2.0787652147686457   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010009765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.585300760708042   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 450.56. Rollout time: 249.50, Training time: 201.03
Evaluating epoch 89
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 8197685.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.323976009186415   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999999993    |
| train_0/current_q         | -9.467849047128258    |
| train_0/fw_bonus          | -0.9989329665899277   |
| train_0/fw_loss           | 0.0055762596311979    |
| train_0/mu_grads          | -0.031020723935216665 |
| train_0/mu_grads_std      | 0.6368859991431236    |
| train_0/mu_loss           | 9.367806533365755     |
| train_0/next_q            | -9.36281665327412     |
| train_0/q_grads           | -0.025694039929658175 |
| train_0/q_grads_std       | 0.3818001501262188    |
| train_0/q_loss            | 0.14887959793684485   |
| train_0/reward            | -0.72626090876729     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007177734375        |
| train_0/target_q          | -9.616958441785247    |
| train_1/avg_q             | -14.15893124637762    |
| train_1/current_q         | -12.676308007916575   |
| train_1/fw_bonus          | -0.9768575161695481   |
| train_1/fw_loss           | 0.11213832516223192   |
| train_1/mu_grads          | -0.07482129186391831  |
| train_1/mu_grads_std      | 0.34494818821549417   |
| train_1/mu_loss           | 5.669434355655794     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.995218523708564   |
| train_1/q_grads           | -0.10832696594297886  |
| train_1/q_grads_std       | 0.4953356638550758    |
| train_1/q_loss            | 0.5100479218426773    |
| train_1/reward            | -2.087708538783045    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.677205771582635   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 448.00. Rollout time: 244.85, Training time: 203.12
Evaluating epoch 90
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 8288810.0             |
| test/episodes             | 2275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.698709657728733   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.672657635403912    |
| train_0/fw_bonus          | -0.9989881560206413   |
| train_0/fw_loss           | 0.005317980842664838  |
| train_0/mu_grads          | -0.03088847054168582  |
| train_0/mu_grads_std      | 0.6391804277896881    |
| train_0/mu_loss           | 9.57574124991331      |
| train_0/next_q            | -9.57020596384358     |
| train_0/q_grads           | -0.025504458276554943 |
| train_0/q_grads_std       | 0.3841054141521454    |
| train_0/q_loss            | 0.13899211235453426   |
| train_0/reward            | -0.7285956483596238   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0080078125          |
| train_0/target_q          | -9.830362760790198    |
| train_1/avg_q             | -13.98677549529905    |
| train_1/current_q         | -12.617568892226775   |
| train_1/fw_bonus          | -0.9759394064545631   |
| train_1/fw_loss           | 0.1158817021176219    |
| train_1/mu_grads          | -0.07486397270113229  |
| train_1/mu_grads_std      | 0.34608895257115363   |
| train_1/mu_loss           | 5.646310459144256     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.027970862647518   |
| train_1/q_grads           | -0.10839815009385348  |
| train_1/q_grads_std       | 0.49835995137691497   |
| train_1/q_loss            | 0.487128427747742     |
| train_1/reward            | -2.086761207044765    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.61525074988573    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_90.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 444.22. Rollout time: 245.20, Training time: 199.00
Evaluating epoch 91
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 91                   |
| policy/steps              | 8379935.0            |
| test/episodes             | 2300.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.729724075780547  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9200.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999999291695  |
| train_0/current_q         | -9.553404502445108   |
| train_0/fw_bonus          | -0.9990149781107902  |
| train_0/fw_loss           | 0.005192569771315903 |
| train_0/mu_grads          | -0.03124946793541312 |
| train_0/mu_grads_std      | 0.6426663562655449   |
| train_0/mu_loss           | 9.457497939939987    |
| train_0/next_q            | -9.452124357721178   |
| train_0/q_grads           | -0.02540975669398904 |
| train_0/q_grads_std       | 0.38627198040485383  |
| train_0/q_loss            | 0.14186197114394106  |
| train_0/reward            | -0.7249835668342712  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007373046875       |
| train_0/target_q          | -9.70430730373125    |
| train_1/avg_q             | -14.09797546237974   |
| train_1/current_q         | -12.611095452036992  |
| train_1/fw_bonus          | -0.9767810240387916  |
| train_1/fw_loss           | 0.11245015896856785  |
| train_1/mu_grads          | -0.07499700766056776 |
| train_1/mu_grads_std      | 0.3472553864121437   |
| train_1/mu_loss           | 5.733714765103002    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.989343467895532  |
| train_1/q_grads           | -0.10856984984129667 |
| train_1/q_grads_std       | 0.5020555347204209   |
| train_1/q_loss            | 0.5705789949076713   |
| train_1/reward            | -2.108117075748305   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015625            |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.613134874284745  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 445.45. Rollout time: 246.29, Training time: 199.13
Evaluating epoch 92
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 8471060.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.229957233623718   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.543290669087352    |
| train_0/fw_bonus          | -0.9990058720111847   |
| train_0/fw_loss           | 0.0052351901773363355 |
| train_0/mu_grads          | -0.031470663379877806 |
| train_0/mu_grads_std      | 0.6446686968207359    |
| train_0/mu_loss           | 9.449192486717658     |
| train_0/next_q            | -9.44424770486897     |
| train_0/q_grads           | -0.0253683568444103   |
| train_0/q_grads_std       | 0.38921964392066      |
| train_0/q_loss            | 0.1404332977825998    |
| train_0/reward            | -0.7245395574187569   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0077880859375       |
| train_0/target_q          | -9.696513631519078    |
| train_1/avg_q             | -14.144217987348698   |
| train_1/current_q         | -12.614130918012957   |
| train_1/fw_bonus          | -0.9758066177368164   |
| train_1/fw_loss           | 0.1164231039583683    |
| train_1/mu_grads          | -0.07510927841067314  |
| train_1/mu_grads_std      | 0.3489375650882721    |
| train_1/mu_loss           | 5.822166009693382     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.021932200265468   |
| train_1/q_grads           | -0.10819268394261598  |
| train_1/q_grads_std       | 0.5044108018279075    |
| train_1/q_loss            | 0.5589792671938181    |
| train_1/reward            | -2.0955204983511067   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.617627115281872   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 444.44. Rollout time: 244.66, Training time: 199.74
Evaluating epoch 93
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 93                    |
| policy/steps              | 8562185.0             |
| test/episodes             | 2350.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.973659688998875   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.5659682082334      |
| train_0/fw_bonus          | -0.9990183725953102   |
| train_0/fw_loss           | 0.005176722968462855  |
| train_0/mu_grads          | -0.03128307508304715  |
| train_0/mu_grads_std      | 0.6458631604909897    |
| train_0/mu_loss           | 9.472990034075135     |
| train_0/next_q            | -9.467345262756666    |
| train_0/q_grads           | -0.025532801961526276 |
| train_0/q_grads_std       | 0.39145110696554186   |
| train_0/q_loss            | 0.137477543829627     |
| train_0/reward            | -0.7252171945612644   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00673828125         |
| train_0/target_q          | -9.720155969019004    |
| train_1/avg_q             | -14.108635487433702   |
| train_1/current_q         | -12.615177729372892   |
| train_1/fw_bonus          | -0.976744145154953    |
| train_1/fw_loss           | 0.11260051652789116   |
| train_1/mu_grads          | -0.07553081735968589  |
| train_1/mu_grads_std      | 0.3509008787572384    |
| train_1/mu_loss           | 5.702254606255764     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.034293104148759   |
| train_1/q_grads           | -0.1086432807147503   |
| train_1/q_grads_std       | 0.506864732503891     |
| train_1/q_loss            | 0.4335106649248945    |
| train_1/reward            | -2.1153740277404722   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.608885987169439   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 447.92. Rollout time: 246.92, Training time: 200.97
Evaluating epoch 94
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 94                    |
| policy/steps              | 8653310.0             |
| test/episodes             | 2375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.948166538329058   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.63995553661672     |
| train_0/fw_bonus          | -0.998979178071022    |
| train_0/fw_loss           | 0.0053600497543811795 |
| train_0/mu_grads          | -0.031390663050115106 |
| train_0/mu_grads_std      | 0.6472318440675735    |
| train_0/mu_loss           | 9.545227673968535     |
| train_0/next_q            | -9.54103959735138     |
| train_0/q_grads           | -0.025260456558316945 |
| train_0/q_grads_std       | 0.3934989169239998    |
| train_0/q_loss            | 0.14094861358331282   |
| train_0/reward            | -0.7256614633450227   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0068359375          |
| train_0/target_q          | -9.794286974211934    |
| train_1/avg_q             | -14.053594950857153   |
| train_1/current_q         | -12.55197226998757    |
| train_1/fw_bonus          | -0.976744233071804    |
| train_1/fw_loss           | 0.11260019466280938   |
| train_1/mu_grads          | -0.07539018858224153  |
| train_1/mu_grads_std      | 0.35362596735358237   |
| train_1/mu_loss           | 5.6054222179589335    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.029147559626395   |
| train_1/q_grads           | -0.10988325607031584  |
| train_1/q_grads_std       | 0.5088569283485412    |
| train_1/q_loss            | 0.7027065811039129    |
| train_1/reward            | -2.0824883259105262   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.547553980293467   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 443.04. Rollout time: 245.09, Training time: 197.92
Evaluating epoch 95
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 95                    |
| policy/steps              | 8744435.0             |
| test/episodes             | 2400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.949909608121924   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.50662236084516     |
| train_0/fw_bonus          | -0.9989926621317864   |
| train_0/fw_loss           | 0.0052969819982536135 |
| train_0/mu_grads          | -0.03287195507436991  |
| train_0/mu_grads_std      | 0.6484981417655945    |
| train_0/mu_loss           | 9.41148854763543      |
| train_0/next_q            | -9.407364634291362    |
| train_0/q_grads           | -0.025193809205666183 |
| train_0/q_grads_std       | 0.39484830647706987   |
| train_0/q_loss            | 0.14648495816277668   |
| train_0/reward            | -0.7240324634505668   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0063720703125       |
| train_0/target_q          | -9.65741399839914     |
| train_1/avg_q             | -13.89022652916579    |
| train_1/current_q         | -12.621221347765879   |
| train_1/fw_bonus          | -0.9759910017251968   |
| train_1/fw_loss           | 0.11567132826894522   |
| train_1/mu_grads          | -0.0751302856951952   |
| train_1/mu_grads_std      | 0.35574338734149935   |
| train_1/mu_loss           | 5.547306316490973     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.022387046149863   |
| train_1/q_grads           | -0.11066287234425545  |
| train_1/q_grads_std       | 0.511059345304966     |
| train_1/q_loss            | 0.6279301618186672    |
| train_1/reward            | -2.1239207942606297   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.627093908309698   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 435.11. Rollout time: 239.51, Training time: 195.57
Evaluating epoch 96
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
----------------------------------------------------
| epoch                     | 96                   |
| policy/steps              | 8835560.0            |
| test/episodes             | 2425.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.107233368601344  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9700.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.543605265489518   |
| train_0/fw_bonus          | -0.9990007400512695  |
| train_0/fw_loss           | 0.005259139684494585 |
| train_0/mu_grads          | -0.0332044031471014  |
| train_0/mu_grads_std      | 0.6493020609021187   |
| train_0/mu_loss           | 9.450179702118046    |
| train_0/next_q            | -9.445817915554937   |
| train_0/q_grads           | -0.02538555394858122 |
| train_0/q_grads_std       | 0.3961477354168892   |
| train_0/q_loss            | 0.1359853729574081   |
| train_0/reward            | -0.7238411965699925  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0072509765625      |
| train_0/target_q          | -9.69820908843695    |
| train_1/avg_q             | -14.087421173708004  |
| train_1/current_q         | -12.602226046244809  |
| train_1/fw_bonus          | -0.9745514154434204  |
| train_1/fw_loss           | 0.12154094893485308  |
| train_1/mu_grads          | -0.07535751145333051 |
| train_1/mu_grads_std      | 0.35735866576433184  |
| train_1/mu_loss           | 5.63597499533724     |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.069790052271737  |
| train_1/q_grads           | -0.11138691660016775 |
| train_1/q_grads_std       | 0.5139992952346801   |
| train_1/q_loss            | 0.5438762747290304   |
| train_1/reward            | -2.1210159445239696  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0010009765625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.600034366453809  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 439.25. Rollout time: 243.38, Training time: 195.84
Evaluating epoch 97
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 97                    |
| policy/steps              | 8926685.0             |
| test/episodes             | 2450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.526826376668375   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.488146766877781    |
| train_0/fw_bonus          | -0.9990066424012184   |
| train_0/fw_loss           | 0.005231636622920632  |
| train_0/mu_grads          | -0.033399622049182655 |
| train_0/mu_grads_std      | 0.651285819709301     |
| train_0/mu_loss           | 9.397861255924928     |
| train_0/next_q            | -9.39256561812837     |
| train_0/q_grads           | -0.025998438615351914 |
| train_0/q_grads_std       | 0.39767749384045603   |
| train_0/q_loss            | 0.13400612819247054   |
| train_0/reward            | -0.7208900350538897   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0070556640625       |
| train_0/target_q          | -9.64207340737023     |
| train_1/avg_q             | -14.069393334249376   |
| train_1/current_q         | -12.604907053874559   |
| train_1/fw_bonus          | -0.9735538527369499   |
| train_1/fw_loss           | 0.1256083333864808    |
| train_1/mu_grads          | -0.07577729001641273  |
| train_1/mu_grads_std      | 0.35885502174496653   |
| train_1/mu_loss           | 5.662262136097596     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.035841224278688   |
| train_1/q_grads           | -0.11159527655690908  |
| train_1/q_grads_std       | 0.5167964100837708    |
| train_1/q_loss            | 0.4059128691474861    |
| train_1/reward            | -2.1087984099867754   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.602343215370755   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 439.57. Rollout time: 242.29, Training time: 197.26
Evaluating epoch 98
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 9017810.0             |
| test/episodes             | 2475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.090060251461619   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.591952637710696    |
| train_0/fw_bonus          | -0.99892787784338     |
| train_0/fw_loss           | 0.005600018030963838  |
| train_0/mu_grads          | -0.03391804341226816  |
| train_0/mu_grads_std      | 0.65357306599617      |
| train_0/mu_loss           | 9.501934317759076     |
| train_0/next_q            | -9.497069493906887    |
| train_0/q_grads           | -0.026197574380785228 |
| train_0/q_grads_std       | 0.39965754821896554   |
| train_0/q_loss            | 0.13562947358362676   |
| train_0/reward            | -0.7231821968372969   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007568359375        |
| train_0/target_q          | -9.747284186169598    |
| train_1/avg_q             | -14.035752717292285   |
| train_1/current_q         | -12.58207915354004    |
| train_1/fw_bonus          | -0.9724749401211739   |
| train_1/fw_loss           | 0.13000737745314836   |
| train_1/mu_grads          | -0.07608609609305858  |
| train_1/mu_grads_std      | 0.35936888977885245   |
| train_1/mu_loss           | 5.720789383138535     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.02984017500826    |
| train_1/q_grads           | -0.11195365898311138  |
| train_1/q_grads_std       | 0.5195653393864632    |
| train_1/q_loss            | 0.48312613227643675   |
| train_1/reward            | -2.112714521866292    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.579685415116305   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 445.29. Rollout time: 246.84, Training time: 198.42
Evaluating epoch 99
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 9108935.0             |
| test/episodes             | 2500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.481596732221494   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.555273120308795    |
| train_0/fw_bonus          | -0.9989286318421364   |
| train_0/fw_loss           | 0.005596431810408831  |
| train_0/mu_grads          | -0.03362931264564395  |
| train_0/mu_grads_std      | 0.6553221583366394    |
| train_0/mu_loss           | 9.46669260984674      |
| train_0/next_q            | -9.46273794669057     |
| train_0/q_grads           | -0.026159265963360667 |
| train_0/q_grads_std       | 0.40124149471521375   |
| train_0/q_loss            | 0.136645944963792     |
| train_0/reward            | -0.7196303344215267   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0088623046875       |
| train_0/target_q          | -9.70971024716618     |
| train_1/avg_q             | -14.075860309887613   |
| train_1/current_q         | -12.540852019915246   |
| train_1/fw_bonus          | -0.9734270974993706   |
| train_1/fw_loss           | 0.12612518519163132   |
| train_1/mu_grads          | -0.07628685515373945  |
| train_1/mu_grads_std      | 0.36014637649059295   |
| train_1/mu_loss           | 5.744709584300043     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.022665135414295   |
| train_1/q_grads           | -0.11224710308015347  |
| train_1/q_grads_std       | 0.5209536075592041    |
| train_1/q_loss            | 0.41590654785139514   |
| train_1/reward            | -2.102680341100495    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.538071203443355   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|119/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
