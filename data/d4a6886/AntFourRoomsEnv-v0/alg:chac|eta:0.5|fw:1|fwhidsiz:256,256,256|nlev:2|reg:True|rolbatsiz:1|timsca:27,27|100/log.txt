Starting process id: 12324
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fafd9ccc950>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 501.99. Rollout time: 260.58, Training time: 241.34
Evaluating epoch 0
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 91125.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -24.14507478898445    |
| test_1/avg_q              | -11.506292468127048   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -7.164213573850961    |
| train_0/current_q         | -8.233130906699675    |
| train_0/fw_bonus          | -0.993210457265377    |
| train_0/fw_loss           | 0.031844587391242386  |
| train_0/mu_grads          | -0.013035593111999333 |
| train_0/mu_grads_std      | 0.17278935723006725   |
| train_0/mu_loss           | 8.108912094806564     |
| train_0/next_q            | -8.110299891933703    |
| train_0/q_grads           | 0.003614643536275253  |
| train_0/q_grads_std       | 0.11870178747922182   |
| train_0/q_loss            | 0.3851486594112884    |
| train_0/reward            | -0.7222399904349004   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 2.44140625e-05        |
| train_0/target_q          | -8.395596119658805    |
| train_1/avg_q             | -8.123021893625026    |
| train_1/current_q         | -8.735278882544165    |
| train_1/fw_bonus          | -0.9898226648569107   |
| train_1/fw_loss           | 0.06439923560246825   |
| train_1/mu_grads          | -0.02341611813753843  |
| train_1/mu_grads_std      | 0.14182107336819172   |
| train_1/mu_loss           | 7.0114208374525955    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.425637281056037    |
| train_1/q_grads           | 0.012178802536800504  |
| train_1/q_grads_std       | 0.1090306406840682    |
| train_1/q_loss            | 1.7265525551777174    |
| train_1/reward            | -2.102699423068407    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0035888671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.697616728098458    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 428.50. Rollout time: 240.73, Training time: 187.75
Evaluating epoch 1
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 182173.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.258960421328492   |
| test_1/avg_q              | -12.114488137373272   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -17.258101992400682   |
| train_0/current_q         | -5.9171301897773985   |
| train_0/fw_bonus          | -0.9964592322707176   |
| train_0/fw_loss           | 0.0168206688715145    |
| train_0/mu_grads          | -0.017340553784742953 |
| train_0/mu_grads_std      | 0.21066686660051345   |
| train_0/mu_loss           | 5.8257287540674465    |
| train_0/next_q            | -5.81670324276895     |
| train_0/q_grads           | 0.0027073041070252656 |
| train_0/q_grads_std       | 0.13457384780049325   |
| train_0/q_loss            | 0.3678032586348864    |
| train_0/reward            | -0.7199825447503827   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0009765625          |
| train_0/target_q          | -6.02162104109766     |
| train_1/avg_q             | -13.169543472669252   |
| train_1/current_q         | -7.999409519995865    |
| train_1/fw_bonus          | -0.9877501800656319   |
| train_1/fw_loss           | 0.07393106892704963   |
| train_1/mu_grads          | -0.03540917346253991  |
| train_1/mu_grads_std      | 0.1779649518430233    |
| train_1/mu_loss           | 6.141082982563479     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.567246223657584    |
| train_1/q_grads           | 0.005910036212299019  |
| train_1/q_grads_std       | 0.1209089120849967    |
| train_1/q_loss            | 0.7900162290186545    |
| train_1/reward            | -2.08435361013544     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.001851851851851852  |
| train_1/target_q          | -7.972496269616616    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 428.43. Rollout time: 240.02, Training time: 188.38
Evaluating epoch 2
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 273298.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.987546533288366   |
| test_1/avg_q              | -13.450754265779432   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -23.928810694021497   |
| train_0/current_q         | -9.149262731935071    |
| train_0/fw_bonus          | -0.9974288195371628   |
| train_0/fw_loss           | 0.01233685719780624   |
| train_0/mu_grads          | -0.019093468179926278 |
| train_0/mu_grads_std      | 0.22942412607371807   |
| train_0/mu_loss           | 9.101885820784153     |
| train_0/next_q            | -9.10706315430323     |
| train_0/q_grads           | 0.004469393054023385  |
| train_0/q_grads_std       | 0.1478368304669857    |
| train_0/q_loss            | 0.42723041196965494   |
| train_0/reward            | -0.7203086444780638   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0052490234375       |
| train_0/target_q          | -9.32849437777325     |
| train_1/avg_q             | -13.41226782549309    |
| train_1/current_q         | -8.873694027711867    |
| train_1/fw_bonus          | -0.9867547124624252   |
| train_1/fw_loss           | 0.0785094840452075    |
| train_1/mu_grads          | -0.045981279015541075 |
| train_1/mu_grads_std      | 0.20403351448476315   |
| train_1/mu_loss           | 6.445564933590577     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.636651811764674    |
| train_1/q_grads           | -0.006624646915588528 |
| train_1/q_grads_std       | 0.1390024222433567    |
| train_1/q_loss            | 1.4223097731194578    |
| train_1/reward            | -2.1052914199099177   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.892481157590904    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 424.91. Rollout time: 236.84, Training time: 188.04
Evaluating epoch 3
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 364423.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.8506267386523     |
| test_1/avg_q              | -12.969472209440031   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -24.62929424343264    |
| train_0/current_q         | -7.556109802524579    |
| train_0/fw_bonus          | -0.997706413269043    |
| train_0/fw_loss           | 0.011053098086267709  |
| train_0/mu_grads          | -0.017302733892574907 |
| train_0/mu_grads_std      | 0.25085852667689323   |
| train_0/mu_loss           | 7.448867750465448     |
| train_0/next_q            | -7.441017393413508    |
| train_0/q_grads           | 0.004263878485653549  |
| train_0/q_grads_std       | 0.15902562402188777   |
| train_0/q_loss            | 0.36292167920341095   |
| train_0/reward            | -0.7184454917201947   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02080078125         |
| train_0/target_q          | -7.679924996164068    |
| train_1/avg_q             | -13.641199766879563   |
| train_1/current_q         | -9.828811547498432    |
| train_1/fw_bonus          | -0.9852735444903373   |
| train_1/fw_loss           | 0.08532174695283175   |
| train_1/mu_grads          | -0.049399508722126485 |
| train_1/mu_grads_std      | 0.22791586704552175   |
| train_1/mu_loss           | 7.383179398855901     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.732016261035376    |
| train_1/q_grads           | -0.015503701753914356 |
| train_1/q_grads_std       | 0.1565469790250063    |
| train_1/q_loss            | 2.7702359307254034    |
| train_1/reward            | -2.09775151409267     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.779276344289409    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 426.22. Rollout time: 237.01, Training time: 189.18
Evaluating epoch 4
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 455036.0              |
| test/episodes             | 125.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999839169917134   |
| test_1/avg_q              | -13.192853928004357   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.695132420271847   |
| train_0/current_q         | -6.612015167534702    |
| train_0/fw_bonus          | -0.9978503242135048   |
| train_0/fw_loss           | 0.010387541982345283  |
| train_0/mu_grads          | -0.017112523131072522 |
| train_0/mu_grads_std      | 0.2699414402246475    |
| train_0/mu_loss           | 6.628850388286267     |
| train_0/next_q            | -6.563977141480423    |
| train_0/q_grads           | 0.004080941097345203  |
| train_0/q_grads_std       | 0.16637465544044971   |
| train_0/q_loss            | 0.5233961871058168    |
| train_0/reward            | -0.715661006479786    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02451171875         |
| train_0/target_q          | -6.890269956184286    |
| train_1/avg_q             | -13.375541857192536   |
| train_1/current_q         | -7.869852734775016    |
| train_1/fw_bonus          | -0.9835501000285148   |
| train_1/fw_loss           | 0.09324824623763561   |
| train_1/mu_grads          | -0.0474307251162827   |
| train_1/mu_grads_std      | 0.24017228409647942   |
| train_1/mu_loss           | 6.236593983248184     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.325337823131875    |
| train_1/q_grads           | -0.025954277301207185 |
| train_1/q_grads_std       | 0.16853295192122458   |
| train_1/q_loss            | 1.227201822157106     |
| train_1/reward            | -2.106631005639065    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0077777777777777776 |
| train_1/target_q          | -7.871097205221811    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 431.49. Rollout time: 237.41, Training time: 194.05
Evaluating epoch 5
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 546145.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999998388358    |
| test_1/avg_q              | -13.78819173516064     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.47984816387296     |
| train_0/current_q         | -9.193079729730057     |
| train_0/fw_bonus          | -0.9980164304375648    |
| train_0/fw_loss           | 0.009619417507201434   |
| train_0/mu_grads          | -0.01650650557130575   |
| train_0/mu_grads_std      | 0.28172875121235846    |
| train_0/mu_loss           | 9.157696296740589      |
| train_0/next_q            | -9.169116368232169     |
| train_0/q_grads           | 0.007254147436469793   |
| train_0/q_grads_std       | 0.17396471947431563    |
| train_0/q_loss            | 0.2427225387139722     |
| train_0/reward            | -0.7133392711621127    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03857421875          |
| train_0/target_q          | -9.378339986496758     |
| train_1/avg_q             | -13.710835358868415    |
| train_1/current_q         | -7.604175423295854     |
| train_1/fw_bonus          | -0.9828022435307503    |
| train_1/fw_loss           | 0.09668778777122497    |
| train_1/mu_grads          | -0.04484526626765728   |
| train_1/mu_grads_std      | 0.2592265710234642     |
| train_1/mu_loss           | 6.07303711679787       |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.068945115590192     |
| train_1/q_grads           | -0.027266420284286143  |
| train_1/q_grads_std       | 0.1837259579449892     |
| train_1/q_loss            | 0.36383979476227285    |
| train_1/reward            | -2.0795969235194205    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001513671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -7.597764965961517     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 425.83. Rollout time: 237.00, Training time: 188.80
Evaluating epoch 6
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 636839.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.985003660524775   |
| test_1/avg_q              | -12.946088979367916   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.05164002914205    |
| train_0/current_q         | -9.20541618201464     |
| train_0/fw_bonus          | -0.9980863854289055   |
| train_0/fw_loss           | 0.009295942261815071  |
| train_0/mu_grads          | -0.013222882593981921 |
| train_0/mu_grads_std      | 0.2953219644725323    |
| train_0/mu_loss           | 9.172690113638593     |
| train_0/next_q            | -9.171148308733976    |
| train_0/q_grads           | 0.007499764545354992  |
| train_0/q_grads_std       | 0.17745518870651722   |
| train_0/q_loss            | 0.20635837772194385   |
| train_0/reward            | -0.7128371361177415   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.052783203125        |
| train_0/target_q          | -9.341262641655488    |
| train_1/avg_q             | -13.920217617905305   |
| train_1/current_q         | -11.055342380111009   |
| train_1/fw_bonus          | -0.9829320758581161   |
| train_1/fw_loss           | 0.0960906632244587    |
| train_1/mu_grads          | -0.04713285882025957  |
| train_1/mu_grads_std      | 0.2725668095052242    |
| train_1/mu_loss           | 6.955370518797333     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -11.20777267302348    |
| train_1/q_grads           | -0.04013184728100896  |
| train_1/q_grads_std       | 0.19182783290743827   |
| train_1/q_loss            | 6.514746758017644     |
| train_1/reward            | -2.079320042485051    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.008518518518518519  |
| train_1/target_q          | -11.156701544463555   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 423.09. Rollout time: 233.65, Training time: 189.41
Evaluating epoch 7
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 727380.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999357   |
| test_1/avg_q              | -13.98868933652968    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.366483288889206   |
| train_0/current_q         | -9.334380248176066    |
| train_0/fw_bonus          | -0.9980255097150803   |
| train_0/fw_loss           | 0.009577458584681153  |
| train_0/mu_grads          | -0.009517875965684652 |
| train_0/mu_grads_std      | 0.3106355361640453    |
| train_0/mu_loss           | 9.305106954673587     |
| train_0/next_q            | -9.299382035342964    |
| train_0/q_grads           | 0.008694475167430937  |
| train_0/q_grads_std       | 0.18167137242853643   |
| train_0/q_loss            | 0.21810341973299302   |
| train_0/reward            | -0.7140029875830806   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0426025390625       |
| train_0/target_q          | -9.49400991131138     |
| train_1/avg_q             | -13.972325589409927   |
| train_1/current_q         | -9.311410468827168    |
| train_1/fw_bonus          | -0.9832372173666954   |
| train_1/fw_loss           | 0.09468716476112604   |
| train_1/mu_grads          | -0.04745877385139465  |
| train_1/mu_grads_std      | 0.2759043976664543    |
| train_1/mu_loss           | 6.386751937943676     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.10425502754487     |
| train_1/q_grads           | -0.043795618787407876 |
| train_1/q_grads_std       | 0.20390369817614556   |
| train_1/q_loss            | 0.8292508543800267    |
| train_1/reward            | -2.065886197182408    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.01037037037037037   |
| train_1/target_q          | -9.299413710866824    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 424.34. Rollout time: 234.78, Training time: 189.53
Evaluating epoch 8
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 818324.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99112817965382    |
| test_1/avg_q              | -11.534327001575493   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.538482677269204   |
| train_0/current_q         | -9.492665784965952    |
| train_0/fw_bonus          | -0.9980187505483628   |
| train_0/fw_loss           | 0.009608703362755478  |
| train_0/mu_grads          | -0.01002751726191491  |
| train_0/mu_grads_std      | 0.3233814790844917    |
| train_0/mu_loss           | 9.49207031436753      |
| train_0/next_q            | -9.484461545189442    |
| train_0/q_grads           | 0.008201313391327857  |
| train_0/q_grads_std       | 0.1854338377714157    |
| train_0/q_loss            | 0.4635673021455708    |
| train_0/reward            | -0.7163921874300285   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04609375            |
| train_0/target_q          | -9.615381625883881    |
| train_1/avg_q             | -13.93071318333794    |
| train_1/current_q         | -8.866258307740083    |
| train_1/fw_bonus          | -0.9831063687801361   |
| train_1/fw_loss           | 0.09528907518833876   |
| train_1/mu_grads          | -0.047731944173574445 |
| train_1/mu_grads_std      | 0.2798458352684975    |
| train_1/mu_loss           | 5.471673473001447     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.315964905444925    |
| train_1/q_grads           | -0.04908171333372593  |
| train_1/q_grads_std       | 0.21014125049114227   |
| train_1/q_loss            | 1.6729735923201576    |
| train_1/reward            | -2.0886601158395934   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.004074074074074074  |
| train_1/target_q          | -8.882957120993964    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 425.21. Rollout time: 236.93, Training time: 188.25
Evaluating epoch 9
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 909153.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.944735563489537   |
| test_1/avg_q              | -13.941723539934362   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.763319270993      |
| train_0/current_q         | -9.41201610449404     |
| train_0/fw_bonus          | -0.9980325043201447   |
| train_0/fw_loss           | 0.009545097872614861  |
| train_0/mu_grads          | -0.010231189639307558 |
| train_0/mu_grads_std      | 0.33270488753914834   |
| train_0/mu_loss           | 9.381120057387932     |
| train_0/next_q            | -9.379090157521661    |
| train_0/q_grads           | 0.008479502866975963  |
| train_0/q_grads_std       | 0.18987097814679146   |
| train_0/q_loss            | 0.2247693611972963    |
| train_0/reward            | -0.7149098064721329   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0484619140625       |
| train_0/target_q          | -9.589523692450895    |
| train_1/avg_q             | -13.54403287506421    |
| train_1/current_q         | -9.273974382201526    |
| train_1/fw_bonus          | -0.9831893503665924   |
| train_1/fw_loss           | 0.0949074300006032    |
| train_1/mu_grads          | -0.050767840910702945 |
| train_1/mu_grads_std      | 0.2844970218837261    |
| train_1/mu_loss           | 6.1775609615824765    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.845672207507283    |
| train_1/q_grads           | -0.05071382196620107  |
| train_1/q_grads_std       | 0.2180498618632555    |
| train_1/q_loss            | 1.5919414216952146    |
| train_1/reward            | -2.120525336126593    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.005185185185185185  |
| train_1/target_q          | -9.286886110964328    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 430.96. Rollout time: 236.63, Training time: 194.30
Evaluating epoch 10
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 1000235.0             |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99995705960712    |
| test_1/avg_q              | -13.593730983416117   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.507289233467496   |
| train_0/current_q         | -9.30264746157496     |
| train_0/fw_bonus          | -0.9981379419565201   |
| train_0/fw_loss           | 0.009057485114317388  |
| train_0/mu_grads          | -0.011410459387116134 |
| train_0/mu_grads_std      | 0.34225805997848513   |
| train_0/mu_loss           | 9.3229279934136       |
| train_0/next_q            | -9.328503034795617    |
| train_0/q_grads           | 0.009978738124482333  |
| train_0/q_grads_std       | 0.19905574731528758   |
| train_0/q_loss            | 0.6704015225052196    |
| train_0/reward            | -0.7149381134433497   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0482177734375       |
| train_0/target_q          | -9.480633513603896    |
| train_1/avg_q             | -14.037044587529522   |
| train_1/current_q         | -8.601088261457665    |
| train_1/fw_bonus          | -0.984286867082119    |
| train_1/fw_loss           | 0.08985967356711626   |
| train_1/mu_grads          | -0.05009454591199756  |
| train_1/mu_grads_std      | 0.2873716399073601    |
| train_1/mu_loss           | 6.240428216943845     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.173620809760195    |
| train_1/q_grads           | -0.05103180045261979  |
| train_1/q_grads_std       | 0.22554521933197974   |
| train_1/q_loss            | 1.2606763819938416    |
| train_1/reward            | -2.137224000506831    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0011111111111111111 |
| train_1/target_q          | -8.593028384512522    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 424.49. Rollout time: 234.15, Training time: 190.31
Evaluating epoch 11
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1091360.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.606532070464588   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.873503094239148   |
| train_0/current_q         | -9.387622421243284    |
| train_0/fw_bonus          | -0.9982904687523841   |
| train_0/fw_loss           | 0.008352158160414546  |
| train_0/mu_grads          | -0.011705938796512782 |
| train_0/mu_grads_std      | 0.3455432802438736    |
| train_0/mu_loss           | 9.372114928948644     |
| train_0/next_q            | -9.37152005141084     |
| train_0/q_grads           | 0.011183466436341405  |
| train_0/q_grads_std       | 0.2045600775629282    |
| train_0/q_loss            | 0.3015057613046298    |
| train_0/reward            | -0.7134396665736858   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0556640625          |
| train_0/target_q          | -9.542543931590053    |
| train_1/avg_q             | -13.847827351693923   |
| train_1/current_q         | -8.85590339472353     |
| train_1/fw_bonus          | -0.9850408911705018   |
| train_1/fw_loss           | 0.08639174327254295   |
| train_1/mu_grads          | -0.051450252253562215 |
| train_1/mu_grads_std      | 0.2912359036505222    |
| train_1/mu_loss           | 6.689254915823797     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.440887386752145    |
| train_1/q_grads           | -0.05091131003573537  |
| train_1/q_grads_std       | 0.22880389876663684   |
| train_1/q_loss            | 1.4104616214395103    |
| train_1/reward            | -2.1207064811758753   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00126953125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.821716304884966    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 424.68. Rollout time: 239.05, Training time: 185.61
Evaluating epoch 12
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1182485.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.020116142666025   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999764665468   |
| train_0/current_q         | -9.346894842226419    |
| train_0/fw_bonus          | -0.998417267203331    |
| train_0/fw_loss           | 0.0077657419024035335 |
| train_0/mu_grads          | -0.011949452199041843 |
| train_0/mu_grads_std      | 0.3519599616527557    |
| train_0/mu_loss           | 9.317066666339585     |
| train_0/next_q            | -9.318122080541059    |
| train_0/q_grads           | 0.010158118861727416  |
| train_0/q_grads_std       | 0.2076008517295122    |
| train_0/q_loss            | 0.21094810336476275   |
| train_0/reward            | -0.7083639099189896   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0570068359375       |
| train_0/target_q          | -9.49525212091693     |
| train_1/avg_q             | -13.856889247088402   |
| train_1/current_q         | -8.214090563470887    |
| train_1/fw_bonus          | -0.9857742264866829   |
| train_1/fw_loss           | 0.0830189848318696    |
| train_1/mu_grads          | -0.051585400756448505 |
| train_1/mu_grads_std      | 0.29277454912662504   |
| train_1/mu_loss           | 6.056516429787931     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.690271423672255    |
| train_1/q_grads           | -0.0531668234616518   |
| train_1/q_grads_std       | 0.2348772134631872    |
| train_1/q_loss            | 0.5734226591871223    |
| train_1/reward            | -2.108609767933376    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.208030965394663    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 424.40. Rollout time: 237.60, Training time: 186.77
Evaluating epoch 13
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1273610.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.857471923047385   |
| test_1/avg_q              | -15.420745520442004   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.996065584454694   |
| train_0/current_q         | -9.373606259336219    |
| train_0/fw_bonus          | -0.9985615238547325   |
| train_0/fw_loss           | 0.007098646648228168  |
| train_0/mu_grads          | -0.009317228593863547 |
| train_0/mu_grads_std      | 0.3606776177883148    |
| train_0/mu_loss           | 9.354545674467241     |
| train_0/next_q            | -9.356441232617392    |
| train_0/q_grads           | 0.010753068863414228  |
| train_0/q_grads_std       | 0.21355044208467006   |
| train_0/q_loss            | 0.24137051340351273   |
| train_0/reward            | -0.7091806653581443   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.041357421875        |
| train_0/target_q          | -9.513131919529922    |
| train_1/avg_q             | -13.954832160737473   |
| train_1/current_q         | -8.285769726899966    |
| train_1/fw_bonus          | -0.9871787324547767   |
| train_1/fw_loss           | 0.07655938137322664   |
| train_1/mu_grads          | -0.052078538481146096 |
| train_1/mu_grads_std      | 0.2973521687090397    |
| train_1/mu_loss           | 6.07282697763294      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.825432744417853    |
| train_1/q_grads           | -0.052552445884794    |
| train_1/q_grads_std       | 0.24111848138272762   |
| train_1/q_loss            | 0.9204576581325788    |
| train_1/reward            | -2.1323955114923594   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.294602652826232    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 427.34. Rollout time: 236.36, Training time: 190.95
Evaluating epoch 14
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 1364366.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.749357764739235   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.545945481298173   |
| train_0/current_q         | -9.479430094290496    |
| train_0/fw_bonus          | -0.9985920444130898   |
| train_0/fw_loss           | 0.006957528938073665  |
| train_0/mu_grads          | -0.01031577552203089  |
| train_0/mu_grads_std      | 0.36608507484197617   |
| train_0/mu_loss           | 9.45279346291675      |
| train_0/next_q            | -9.451477444371784    |
| train_0/q_grads           | 0.011140371160581707  |
| train_0/q_grads_std       | 0.2185330107808113    |
| train_0/q_loss            | 0.21999291230817394   |
| train_0/reward            | -0.7093424073151254   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.061865234375        |
| train_0/target_q          | -9.632999473690841    |
| train_1/avg_q             | -14.235259392280158   |
| train_1/current_q         | -7.657662081865103    |
| train_1/fw_bonus          | -0.988108967244625    |
| train_1/fw_loss           | 0.07228095792233943   |
| train_1/mu_grads          | -0.052718343865126374 |
| train_1/mu_grads_std      | 0.30276959761977196   |
| train_1/mu_loss           | 5.758412709780185     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.087247333052832    |
| train_1/q_grads           | -0.05709104854613543  |
| train_1/q_grads_std       | 0.24837316572666168   |
| train_1/q_loss            | 0.9555070753604239    |
| train_1/reward            | -2.106859660011833    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.008888888888888889  |
| train_1/target_q          | -7.6567185774490145   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 423.76. Rollout time: 235.66, Training time: 188.06
Evaluating epoch 15
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1455427.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999991985   |
| test_1/avg_q              | -13.411743015432      |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.6892822805423     |
| train_0/current_q         | -9.545891401890245    |
| train_0/fw_bonus          | -0.9985869243741036   |
| train_0/fw_loss           | 0.006981187080964446  |
| train_0/mu_grads          | -0.008532004803419114 |
| train_0/mu_grads_std      | 0.37379988506436346   |
| train_0/mu_loss           | 9.529989714928927     |
| train_0/next_q            | -9.523830065024839    |
| train_0/q_grads           | 0.010427049337886274  |
| train_0/q_grads_std       | 0.22230151817202567   |
| train_0/q_loss            | 0.2917802107567093    |
| train_0/reward            | -0.7106826229086437   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.056591796875        |
| train_0/target_q          | -9.684805511150284    |
| train_1/avg_q             | -13.889336218323669   |
| train_1/current_q         | -6.615276679220427    |
| train_1/fw_bonus          | -0.9888888001441956   |
| train_1/fw_loss           | 0.06869432050734758   |
| train_1/mu_grads          | -0.05384639399126172  |
| train_1/mu_grads_std      | 0.30819932371377945   |
| train_1/mu_loss           | 5.237029232620479     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.485208983122663    |
| train_1/q_grads           | -0.05701333777979016  |
| train_1/q_grads_std       | 0.25642334669828415   |
| train_1/q_loss            | 3.7670002927736705    |
| train_1/reward            | -2.0995103187779023   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019775390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0011111111111111111 |
| train_1/target_q          | -7.0927995779682576   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 419.34. Rollout time: 233.46, Training time: 185.85
Evaluating epoch 16
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1546472.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99816862527866    |
| test_1/avg_q              | -13.49197935175071    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.803280687451256   |
| train_0/current_q         | -9.569365217294798    |
| train_0/fw_bonus          | -0.9984493166208267   |
| train_0/fw_loss           | 0.007617562892846763  |
| train_0/mu_grads          | -0.007742032536771149 |
| train_0/mu_grads_std      | 0.37961906641721727   |
| train_0/mu_loss           | 9.55418909671011      |
| train_0/next_q            | -9.550166810053238    |
| train_0/q_grads           | 0.007829937722999603  |
| train_0/q_grads_std       | 0.22576983831822872   |
| train_0/q_loss            | 0.32202272316213004   |
| train_0/reward            | -0.71530131773834     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0541259765625       |
| train_0/target_q          | -9.707533632070598    |
| train_1/avg_q             | -14.594418199244446   |
| train_1/current_q         | -8.928510336758988    |
| train_1/fw_bonus          | -0.9883992910385132   |
| train_1/fw_loss           | 0.07094575092196465   |
| train_1/mu_grads          | -0.05413676388561726  |
| train_1/mu_grads_std      | 0.3082334890961647    |
| train_1/mu_loss           | 6.32599503811108      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.588498424242449    |
| train_1/q_grads           | -0.05696363346651197  |
| train_1/q_grads_std       | 0.2620038352906704    |
| train_1/q_loss            | 0.963841165333089     |
| train_1/reward            | -2.1221415350111785   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017578125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0014814814814814814 |
| train_1/target_q          | -8.93435203431389     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 423.66. Rollout time: 237.14, Training time: 186.50
Evaluating epoch 17
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1637502.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999998099955    |
| test_1/avg_q              | -13.668829631573354    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.57746711789618     |
| train_0/current_q         | -9.528264008074169     |
| train_0/fw_bonus          | -0.9984517797827721    |
| train_0/fw_loss           | 0.007606182619929314   |
| train_0/mu_grads          | -0.0072559565189294515 |
| train_0/mu_grads_std      | 0.38613411113619805    |
| train_0/mu_loss           | 9.481837559228271      |
| train_0/next_q            | -9.47800673274339      |
| train_0/q_grads           | 0.008786493656225502   |
| train_0/q_grads_std       | 0.22965926565229894    |
| train_0/q_loss            | 0.2693559820525443     |
| train_0/reward            | -0.7181345795899687    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0575439453125        |
| train_0/target_q          | -9.680837163092352     |
| train_1/avg_q             | -13.955527708432491    |
| train_1/current_q         | -8.916320899947253     |
| train_1/fw_bonus          | -0.9891455292701721    |
| train_1/fw_loss           | 0.06751364674419165    |
| train_1/mu_grads          | -0.05582552496343851   |
| train_1/mu_grads_std      | 0.3106475695967674     |
| train_1/mu_loss           | 6.136720158918811      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.609436957121071     |
| train_1/q_grads           | -0.05813931142911315   |
| train_1/q_grads_std       | 0.2679919384419918     |
| train_1/q_loss            | 1.118311349261033      |
| train_1/reward            | -2.090275882267451     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002001953125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.001851851851851852   |
| train_1/target_q          | -8.903128253975197     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 429.22. Rollout time: 240.63, Training time: 188.56
Evaluating epoch 18
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 1728259.0             |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999557516112   |
| test_1/avg_q              | -14.288748677037347   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.45465512327247    |
| train_0/current_q         | -9.623122997017248    |
| train_0/fw_bonus          | -0.9983841747045517   |
| train_0/fw_loss           | 0.007918849959969521  |
| train_0/mu_grads          | -0.007696507987566293 |
| train_0/mu_grads_std      | 0.3905368968844414    |
| train_0/mu_loss           | 9.615088750823363     |
| train_0/next_q            | -9.608964844223       |
| train_0/q_grads           | 0.009715266013517975  |
| train_0/q_grads_std       | 0.238921719416976     |
| train_0/q_loss            | 0.39694958468527475   |
| train_0/reward            | -0.7202614183443075   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0535400390625       |
| train_0/target_q          | -9.756810676945566    |
| train_1/avg_q             | -14.052367287571428   |
| train_1/current_q         | -9.179605973844424    |
| train_1/fw_bonus          | -0.987634451687336    |
| train_1/fw_loss           | 0.0744633438065648    |
| train_1/mu_grads          | -0.05614408627152443  |
| train_1/mu_grads_std      | 0.3131671562790871    |
| train_1/mu_loss           | 6.268916433494708     |
| train_1/n_subgoals        | 2687.0                |
| train_1/next_q            | -8.922619576138358    |
| train_1/q_grads           | -0.05854722270742059  |
| train_1/q_grads_std       | 0.27490062117576597   |
| train_1/q_loss            | 1.6053504585857943    |
| train_1/reward            | -2.091668792354176    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.190506322408496    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 424.83. Rollout time: 237.72, Training time: 187.09
Evaluating epoch 19
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1819368.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999916     |
| test_1/avg_q              | -14.0417834612186      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99991756136925     |
| train_0/current_q         | -9.477490050309212     |
| train_0/fw_bonus          | -0.9983920201659202    |
| train_0/fw_loss           | 0.00788253661012277    |
| train_0/mu_grads          | -0.006213282246608287  |
| train_0/mu_grads_std      | 0.3939444400370121     |
| train_0/mu_loss           | 9.453826825312827      |
| train_0/next_q            | -9.43139731506313      |
| train_0/q_grads           | 0.0093609016854316     |
| train_0/q_grads_std       | 0.2416113756597042     |
| train_0/q_loss            | 0.35581068168027574    |
| train_0/reward            | -0.7226945438742405    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.058642578125         |
| train_0/target_q          | -9.635985504464047     |
| train_1/avg_q             | -14.114938558799789    |
| train_1/current_q         | -8.41527358021096      |
| train_1/fw_bonus          | -0.9881189137697219    |
| train_1/fw_loss           | 0.07223522458225488    |
| train_1/mu_grads          | -0.05591046884655952   |
| train_1/mu_grads_std      | 0.31497262567281725    |
| train_1/mu_loss           | 6.189494251846391      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.969554203247933     |
| train_1/q_grads           | -0.059671548660844564  |
| train_1/q_grads_std       | 0.28037782162427904    |
| train_1/q_loss            | 0.8077274543859272     |
| train_1/reward            | -2.09188660529544      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0012451171875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -8.417079467274789     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 423.40. Rollout time: 238.72, Training time: 184.65
Evaluating epoch 20
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1910493.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.933371631168217   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999554101236104   |
| train_0/current_q         | -9.631455250836686    |
| train_0/fw_bonus          | -0.9984273493289948   |
| train_0/fw_loss           | 0.007719135982915759  |
| train_0/mu_grads          | -0.005081025150138885 |
| train_0/mu_grads_std      | 0.39942051395773887   |
| train_0/mu_loss           | 9.590106325151226     |
| train_0/next_q            | -9.585623885510426    |
| train_0/q_grads           | 0.009772777440957725  |
| train_0/q_grads_std       | 0.2455860275775194    |
| train_0/q_loss            | 0.2940078696748591    |
| train_0/reward            | -0.7258127964007144   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0536865234375       |
| train_0/target_q          | -9.781542614552512    |
| train_1/avg_q             | -14.01551072635502    |
| train_1/current_q         | -8.907203923047781    |
| train_1/fw_bonus          | -0.9881437838077545   |
| train_1/fw_loss           | 0.0721208618953824    |
| train_1/mu_grads          | -0.0555601286701858   |
| train_1/mu_grads_std      | 0.3173356853425503    |
| train_1/mu_loss           | 6.292886244251754     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.500340853950167    |
| train_1/q_grads           | -0.06090542860329151  |
| train_1/q_grads_std       | 0.2852778725326061    |
| train_1/q_loss            | 0.8841449000005717    |
| train_1/reward            | -2.0965377096705198   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.899075172230578    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 421.90. Rollout time: 236.52, Training time: 185.35
Evaluating epoch 21
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 2000730.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.89752602885699    |
| test_1/avg_q              | -14.182980039453765   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.478410402183094   |
| train_0/current_q         | -9.594627922933894    |
| train_0/fw_bonus          | -0.9984926268458366   |
| train_0/fw_loss           | 0.007417278771754354  |
| train_0/mu_grads          | -0.00703658745624125  |
| train_0/mu_grads_std      | 0.40614586770534516   |
| train_0/mu_loss           | 9.548774104112471     |
| train_0/next_q            | -9.541758492539582    |
| train_0/q_grads           | 0.008560664160177112  |
| train_0/q_grads_std       | 0.24908797033131122   |
| train_0/q_loss            | 0.30344120687166115   |
| train_0/reward            | -0.7266510974448466   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.048974609375        |
| train_0/target_q          | -9.74791746763903     |
| train_1/avg_q             | -14.61084400282409    |
| train_1/current_q         | -8.298603034616205    |
| train_1/fw_bonus          | -0.9878049403429031   |
| train_1/fw_loss           | 0.07367924451828003   |
| train_1/mu_grads          | -0.05687522366642952  |
| train_1/mu_grads_std      | 0.3194371692836285    |
| train_1/mu_loss           | 6.226483838271999     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.916000857242773    |
| train_1/q_grads           | -0.061460772436112164 |
| train_1/q_grads_std       | 0.28874360769987106   |
| train_1/q_loss            | 0.9565580826250549    |
| train_1/reward            | -2.089886357514479    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.014074074074074074  |
| train_1/target_q          | -8.286019038755038    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 428.45. Rollout time: 243.52, Training time: 184.90
Evaluating epoch 22
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 2091807.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999997443368137   |
| test_1/avg_q              | -13.18151339936558    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.78612405731782    |
| train_0/current_q         | -9.61506393322669     |
| train_0/fw_bonus          | -0.9985552683472634   |
| train_0/fw_loss           | 0.007127546495757997  |
| train_0/mu_grads          | -0.009218366839922965 |
| train_0/mu_grads_std      | 0.41195452958345413   |
| train_0/mu_loss           | 9.565708082829296     |
| train_0/next_q            | -9.558973024288267    |
| train_0/q_grads           | 0.006922614225186407  |
| train_0/q_grads_std       | 0.2525556594133377    |
| train_0/q_loss            | 0.2510696279121832    |
| train_0/reward            | -0.7262917983447551   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04150390625         |
| train_0/target_q          | -9.770638241380478    |
| train_1/avg_q             | -14.371125480161847   |
| train_1/current_q         | -8.550650144395552    |
| train_1/fw_bonus          | -0.9882167354226112   |
| train_1/fw_loss           | 0.07178532313555479   |
| train_1/mu_grads          | -0.05668508317321539  |
| train_1/mu_grads_std      | 0.3226857729256153    |
| train_1/mu_loss           | 6.098504069149172     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.148031621509565    |
| train_1/q_grads           | -0.06350410841405392  |
| train_1/q_grads_std       | 0.2904182031750679    |
| train_1/q_loss            | 1.1925645615309435    |
| train_1/reward            | -2.083122039338923    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0007407407407407407 |
| train_1/target_q          | -8.532961358095285    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 425.18. Rollout time: 238.07, Training time: 187.08
Evaluating epoch 23
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 2182917.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999990087724072    |
| test_1/avg_q              | -14.092457046665029    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.893742426154592    |
| train_0/current_q         | -9.557431005655664     |
| train_0/fw_bonus          | -0.9986190244555473    |
| train_0/fw_loss           | 0.006832753808703273   |
| train_0/mu_grads          | -0.012249208171851933  |
| train_0/mu_grads_std      | 0.4175510726869106     |
| train_0/mu_loss           | 9.495611756124216      |
| train_0/next_q            | -9.486386711316765     |
| train_0/q_grads           | 0.007163854688405991   |
| train_0/q_grads_std       | 0.2553268499672413     |
| train_0/q_loss            | 0.22305691664870525    |
| train_0/reward            | -0.7250419332682213    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.033837890625         |
| train_0/target_q          | -9.714065622467725     |
| train_1/avg_q             | -13.93732536167199     |
| train_1/current_q         | -8.593273372199707     |
| train_1/fw_bonus          | -0.9877207443118096    |
| train_1/fw_loss           | 0.07406648304313421    |
| train_1/mu_grads          | -0.05760991415008902   |
| train_1/mu_grads_std      | 0.32223243564367293    |
| train_1/mu_loss           | 6.156736522116564      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.233898236293486     |
| train_1/q_grads           | -0.06414815299212932   |
| train_1/q_grads_std       | 0.29284770116209985    |
| train_1/q_loss            | 0.9392760119769109     |
| train_1/reward            | -2.11141408347612      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001611328125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -8.575559640694369     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 422.26. Rollout time: 236.37, Training time: 185.85
Evaluating epoch 24
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2272931.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.941143232244073   |
| test_1/avg_q              | -13.611012465212998   |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.537525151177487   |
| train_0/current_q         | -9.604944527080743    |
| train_0/fw_bonus          | -0.9985698595643043   |
| train_0/fw_loss           | 0.0070600814069621265 |
| train_0/mu_grads          | -0.012700255960226059 |
| train_0/mu_grads_std      | 0.42303092777729034   |
| train_0/mu_loss           | 9.591105281877393     |
| train_0/next_q            | -9.579415887102632    |
| train_0/q_grads           | 0.0063919599982909855 |
| train_0/q_grads_std       | 0.26031263172626495   |
| train_0/q_loss            | 0.4032231044618223    |
| train_0/reward            | -0.7269826865951472   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0344970703125       |
| train_0/target_q          | -9.73878156558651     |
| train_1/avg_q             | -13.992720701743567   |
| train_1/current_q         | -8.31818416568018     |
| train_1/fw_bonus          | -0.9870074048638344   |
| train_1/fw_loss           | 0.07734728753566741   |
| train_1/mu_grads          | -0.056019235868006945 |
| train_1/mu_grads_std      | 0.3232113793492317    |
| train_1/mu_loss           | 5.816281088365075     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.831248827463787    |
| train_1/q_grads           | -0.0661233801394701   |
| train_1/q_grads_std       | 0.29661920443177225   |
| train_1/q_loss            | 1.1381992819201208    |
| train_1/reward            | -2.1163796816588727   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.017037037037037038  |
| train_1/target_q          | -8.32133476896173     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 423.60. Rollout time: 238.26, Training time: 185.31
Evaluating epoch 25
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2363728.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.60835649442487    |
| test_1/avg_q              | -14.130443778097124   |
| test_1/n_subgoals         | 677.0                 |
| test_1/subgoal_succ_rate  | 0.0029542097488921715 |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.821512577789875   |
| train_0/current_q         | -9.354957176189341    |
| train_0/fw_bonus          | -0.9985342234373092   |
| train_0/fw_loss           | 0.007224921265151352  |
| train_0/mu_grads          | -0.013493398018181325 |
| train_0/mu_grads_std      | 0.42806645631790163   |
| train_0/mu_loss           | 9.317468843229292     |
| train_0/next_q            | -9.31341992678369     |
| train_0/q_grads           | 0.008487154310569168  |
| train_0/q_grads_std       | 0.2679650291800499    |
| train_0/q_loss            | 0.3416369039944008    |
| train_0/reward            | -0.7242060748234508   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0364013671875       |
| train_0/target_q          | -9.475978564039721    |
| train_1/avg_q             | -13.964482988998133   |
| train_1/current_q         | -9.565919393152223    |
| train_1/fw_bonus          | -0.9853225946426392   |
| train_1/fw_loss           | 0.08509608879685401   |
| train_1/mu_grads          | -0.05657553216442466  |
| train_1/mu_grads_std      | 0.32713606432080267   |
| train_1/mu_loss           | 6.630603055637531     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.329627222022891    |
| train_1/q_grads           | -0.06610079240053893  |
| train_1/q_grads_std       | 0.30058033391833305   |
| train_1/q_loss            | 2.3551390728109323    |
| train_1/reward            | -2.1097999733457984   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.005925925925925926  |
| train_1/target_q          | -9.633922203922292    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 423.69. Rollout time: 236.82, Training time: 186.84
Evaluating epoch 26
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2454536.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999978404599464   |
| test_1/avg_q              | -13.485494034256648   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.985689708490774   |
| train_0/current_q         | -9.491783226814912    |
| train_0/fw_bonus          | -0.998555725812912    |
| train_0/fw_loss           | 0.007125439739320427  |
| train_0/mu_grads          | -0.014247659267857671 |
| train_0/mu_grads_std      | 0.43369490578770636   |
| train_0/mu_loss           | 9.448104043979857     |
| train_0/next_q            | -9.441841056900993    |
| train_0/q_grads           | 0.00908688681665808   |
| train_0/q_grads_std       | 0.2717637218534946    |
| train_0/q_loss            | 0.2741350375372303    |
| train_0/reward            | -0.7239726904168492   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0330322265625       |
| train_0/target_q          | -9.657581248127851    |
| train_1/avg_q             | -13.948912807357507   |
| train_1/current_q         | -8.863051083778874    |
| train_1/fw_bonus          | -0.984245066344738    |
| train_1/fw_loss           | 0.0900518972426653    |
| train_1/mu_grads          | -0.05633148020133376  |
| train_1/mu_grads_std      | 0.32795793041586874   |
| train_1/mu_loss           | 6.1530764093218355    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.489162396160761    |
| train_1/q_grads           | -0.06776195149868727  |
| train_1/q_grads_std       | 0.3007196128368378    |
| train_1/q_loss            | 1.3622634085975336    |
| train_1/reward            | -2.1291464615373115   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.005555555555555556  |
| train_1/target_q          | -8.887556406333262    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 426.63. Rollout time: 237.15, Training time: 189.45
Evaluating epoch 27
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2545661.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.998641166700494   |
| test_1/avg_q              | -13.973114474922266   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999376840809052   |
| train_0/current_q         | -9.575718334918735    |
| train_0/fw_bonus          | -0.9985534176230431   |
| train_0/fw_loss           | 0.007136151357553899  |
| train_0/mu_grads          | -0.014083414315246045 |
| train_0/mu_grads_std      | 0.43737453073263166   |
| train_0/mu_loss           | 9.516228077414388     |
| train_0/next_q            | -9.510002180800232    |
| train_0/q_grads           | 0.009397333930246532  |
| train_0/q_grads_std       | 0.2753242693841457    |
| train_0/q_loss            | 0.33434012780585187   |
| train_0/reward            | -0.7273895008795079   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.032666015625        |
| train_0/target_q          | -9.724996886008048    |
| train_1/avg_q             | -13.190704664061734   |
| train_1/current_q         | -9.120724283583096    |
| train_1/fw_bonus          | -0.9835273787379265   |
| train_1/fw_loss           | 0.09335272908210754   |
| train_1/mu_grads          | -0.0573967082425952   |
| train_1/mu_grads_std      | 0.3289251372218132    |
| train_1/mu_loss           | 6.7766926137423935    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.327955962714322    |
| train_1/q_grads           | -0.06503624469041824  |
| train_1/q_grads_std       | 0.3056300587952137    |
| train_1/q_loss            | 2.0172915532181115    |
| train_1/reward            | -2.087234881461336    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.290132920298305    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 424.19. Rollout time: 236.08, Training time: 188.08
Evaluating epoch 28
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2635896.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.750416046307173   |
| test_1/avg_q              | -13.178450875619049   |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.20584013753262    |
| train_0/current_q         | -9.596705335446504    |
| train_0/fw_bonus          | -0.9985167950391769   |
| train_0/fw_loss           | 0.007305522263050079  |
| train_0/mu_grads          | -0.015127566712908446 |
| train_0/mu_grads_std      | 0.4435614377260208    |
| train_0/mu_loss           | 9.551001482267107     |
| train_0/next_q            | -9.543430851045972    |
| train_0/q_grads           | 0.010292132059112192  |
| train_0/q_grads_std       | 0.27910605520009996   |
| train_0/q_loss            | 0.32167709257775107   |
| train_0/reward            | -0.7252715790506045   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0331298828125       |
| train_0/target_q          | -9.747714064392097    |
| train_1/avg_q             | -14.29904120337879    |
| train_1/current_q         | -8.630085672836751    |
| train_1/fw_bonus          | -0.9832117974758148   |
| train_1/fw_loss           | 0.09480423275381326   |
| train_1/mu_grads          | -0.057527077943086626 |
| train_1/mu_grads_std      | 0.33246041685342786   |
| train_1/mu_loss           | 6.335287068767376     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.277065964816575    |
| train_1/q_grads           | -0.06623756140470505  |
| train_1/q_grads_std       | 0.30592000037431716   |
| train_1/q_loss            | 1.5366458621717094    |
| train_1/reward            | -2.07143987570671     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.015555555555555555  |
| train_1/target_q          | -8.621808576443936    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 416.30. Rollout time: 228.81, Training time: 187.46
Evaluating epoch 29
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2724005.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.463218959271984   |
| test_1/avg_q              | -13.483746247531986   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.00804898673347    |
| train_0/current_q         | -9.504864566547457    |
| train_0/fw_bonus          | -0.9985824644565582   |
| train_0/fw_loss           | 0.007001772220246494  |
| train_0/mu_grads          | -0.015257896506227553 |
| train_0/mu_grads_std      | 0.44902867302298544   |
| train_0/mu_loss           | 9.535334611551436     |
| train_0/next_q            | -9.517418730949416    |
| train_0/q_grads           | 0.005746750184334815  |
| train_0/q_grads_std       | 0.28560312315821645   |
| train_0/q_loss            | 0.7024102696098179    |
| train_0/reward            | -0.7233268815180054   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0253173828125       |
| train_0/target_q          | -9.644877478746679    |
| train_1/avg_q             | -13.66961206754087    |
| train_1/current_q         | -9.463299607268661    |
| train_1/fw_bonus          | -0.9822632536292076   |
| train_1/fw_loss           | 0.0991667203605175    |
| train_1/mu_grads          | -0.0582275340333581   |
| train_1/mu_grads_std      | 0.33675043359398843   |
| train_1/mu_loss           | 7.448925295474015     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.388217607103076    |
| train_1/q_grads           | -0.06303860265761614  |
| train_1/q_grads_std       | 0.3077940545976162    |
| train_1/q_loss            | 2.4962248096802795    |
| train_1/reward            | -2.09485477240014     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.04777777777777778   |
| train_1/target_q          | -9.488936691448977    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 427.82. Rollout time: 238.64, Training time: 189.15
Evaluating epoch 30
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 30                    |
| policy/steps              | 2814045.0             |
| test/episodes             | 775.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.95955286125953    |
| test_1/avg_q              | -12.55537384294379    |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 3100.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.45882036311989    |
| train_0/current_q         | -9.561435076680862    |
| train_0/fw_bonus          | -0.9985846355557442   |
| train_0/fw_loss           | 0.006991689279675484  |
| train_0/mu_grads          | -0.012531296350061893 |
| train_0/mu_grads_std      | 0.4542178101837635    |
| train_0/mu_loss           | 9.528447189193988     |
| train_0/next_q            | -9.517001865445396    |
| train_0/q_grads           | 0.007280762132722884  |
| train_0/q_grads_std       | 0.2897139012813568    |
| train_0/q_loss            | 0.29947861093147843   |
| train_0/reward            | -0.7233523856906686   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.031201171875        |
| train_0/target_q          | -9.714878009437241    |
| train_1/avg_q             | -14.532957062068965   |
| train_1/current_q         | -7.293373484411516    |
| train_1/fw_bonus          | -0.9820887252688408   |
| train_1/fw_loss           | 0.09996945150196553   |
| train_1/mu_grads          | -0.05800460921600461  |
| train_1/mu_grads_std      | 0.33928307741880415   |
| train_1/mu_loss           | 5.610102183740105     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.70713478080994     |
| train_1/q_grads           | -0.0649813462048769   |
| train_1/q_grads_std       | 0.30913683772087097   |
| train_1/q_loss            | 0.8284698255025322    |
| train_1/reward            | -2.0753583253557735   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.017777777777777778  |
| train_1/target_q          | -7.297308852208516    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 424.41. Rollout time: 235.45, Training time: 188.93
Evaluating epoch 31
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2905058.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.354129629338146   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.95300486149856    |
| train_0/current_q         | -9.464515053182883    |
| train_0/fw_bonus          | -0.99865243434906     |
| train_0/fw_loss           | 0.00667818485526368   |
| train_0/mu_grads          | -0.014103913633152842 |
| train_0/mu_grads_std      | 0.4597043626010418    |
| train_0/mu_loss           | 9.416101623771759     |
| train_0/next_q            | -9.40858801789577     |
| train_0/q_grads           | 0.006593069422524423  |
| train_0/q_grads_std       | 0.2921172991394997    |
| train_0/q_loss            | 0.2613257912665173    |
| train_0/reward            | -0.7209204615297494   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.03203125            |
| train_0/target_q          | -9.610598882676172    |
| train_1/avg_q             | -13.275054427950893   |
| train_1/current_q         | -7.380288954002362    |
| train_1/fw_bonus          | -0.9834347113966941   |
| train_1/fw_loss           | 0.09377894084900618   |
| train_1/mu_grads          | -0.05641511604189873  |
| train_1/mu_grads_std      | 0.3433700442314148    |
| train_1/mu_loss           | 6.081692689252452     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.9053229756156655   |
| train_1/q_grads           | -0.06490937806665897  |
| train_1/q_grads_std       | 0.310232375562191     |
| train_1/q_loss            | 0.37782726624317264   |
| train_1/reward            | -2.1061948932299854   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.001851851851851852  |
| train_1/target_q          | -7.389698450846531    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 422.63. Rollout time: 235.81, Training time: 186.80
Evaluating epoch 32
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 32                   |
| policy/steps              | 2996183.0            |
| test/episodes             | 825.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.577988388243412  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999543467275  |
| train_0/current_q         | -9.573385684207915   |
| train_0/fw_bonus          | -0.99869764149189    |
| train_0/fw_loss           | 0.006469203473534435 |
| train_0/mu_grads          | -0.01487934305332601 |
| train_0/mu_grads_std      | 0.46415898501873015  |
| train_0/mu_loss           | 9.527384642032107    |
| train_0/next_q            | -9.51845532426959    |
| train_0/q_grads           | 0.005752496898639947 |
| train_0/q_grads_std       | 0.2946802146732807   |
| train_0/q_loss            | 0.3109408569916153   |
| train_0/reward            | -0.7229694239962555  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.023583984375       |
| train_0/target_q          | -9.723838416652438   |
| train_1/avg_q             | -14.159045503784172  |
| train_1/current_q         | -12.35834217385325   |
| train_1/fw_bonus          | -0.9840126991271972  |
| train_1/fw_loss           | 0.09112064372748137  |
| train_1/mu_grads          | -0.05648270100355148 |
| train_1/mu_grads_std      | 0.3456150755286217   |
| train_1/mu_loss           | 6.882022277873571    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.655210280998933  |
| train_1/q_grads           | -0.06974456198513508 |
| train_1/q_grads_std       | 0.31668535619974136  |
| train_1/q_loss            | 1.8184209739500692   |
| train_1/reward            | -2.0729511721321616  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001611328125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.373001708031692  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 425.64. Rollout time: 238.28, Training time: 187.34
Evaluating epoch 33
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 3087308.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.808313642667937   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.462017386467533    |
| train_0/fw_bonus          | -0.9987514153122902   |
| train_0/fw_loss           | 0.00622051142854616   |
| train_0/mu_grads          | -0.017429585568606853 |
| train_0/mu_grads_std      | 0.46980836763978007   |
| train_0/mu_loss           | 9.40849912724681      |
| train_0/next_q            | -9.401947708090164    |
| train_0/q_grads           | 0.004758630564901977  |
| train_0/q_grads_std       | 0.2968921609222889    |
| train_0/q_loss            | 0.26461957077356274   |
| train_0/reward            | -0.7206037343254138   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.022119140625        |
| train_0/target_q          | -9.601892950521702    |
| train_1/avg_q             | -13.714276119511773   |
| train_1/current_q         | -12.370738886097483   |
| train_1/fw_bonus          | -0.9849287614226341   |
| train_1/fw_loss           | 0.0869074746966362    |
| train_1/mu_grads          | -0.056633409671485425 |
| train_1/mu_grads_std      | 0.34684942215681075   |
| train_1/mu_loss           | 6.719966953632715     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.735576894527668   |
| train_1/q_grads           | -0.07092711795121431  |
| train_1/q_grads_std       | 0.3234902389347553    |
| train_1/q_loss            | 1.452685991333129     |
| train_1/reward            | -2.0551596911223897   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.420718152838699   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 427.31. Rollout time: 238.79, Training time: 188.48
Evaluating epoch 34
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 3178433.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.046544646041834   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999675783   |
| train_0/current_q         | -9.554852102912148    |
| train_0/fw_bonus          | -0.9988308921456337   |
| train_0/fw_loss           | 0.005852959607727826  |
| train_0/mu_grads          | -0.018091369466856123 |
| train_0/mu_grads_std      | 0.4739147171378136    |
| train_0/mu_loss           | 9.501571461113292     |
| train_0/next_q            | -9.496273138564337    |
| train_0/q_grads           | 0.004779377020895481  |
| train_0/q_grads_std       | 0.2993990987539291    |
| train_0/q_loss            | 0.2700780253657415    |
| train_0/reward            | -0.7217421070017735   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0247314453125       |
| train_0/target_q          | -9.705271168619316    |
| train_1/avg_q             | -13.870289045833372   |
| train_1/current_q         | -12.63526495965459    |
| train_1/fw_bonus          | -0.9864299789071083   |
| train_1/fw_loss           | 0.0800030279904604    |
| train_1/mu_grads          | -0.056848936900496486 |
| train_1/mu_grads_std      | 0.3486856073141098    |
| train_1/mu_loss           | 6.657907617615971     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.951356364842496   |
| train_1/q_grads           | -0.07231350895017385  |
| train_1/q_grads_std       | 0.3309761993587017    |
| train_1/q_loss            | 0.9647156548500433    |
| train_1/reward            | -2.1082540505150975   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.681232158786585   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 398.58. Rollout time: 222.89, Training time: 175.66
Evaluating epoch 35
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 3269558.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.066048678314447   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.547611517237087    |
| train_0/fw_bonus          | -0.9988524422049523   |
| train_0/fw_loss           | 0.005753352330066264  |
| train_0/mu_grads          | -0.015915891528129576 |
| train_0/mu_grads_std      | 0.4766081839799881    |
| train_0/mu_loss           | 9.490090728661908     |
| train_0/next_q            | -9.483129656252562    |
| train_0/q_grads           | 0.0054856653674505654 |
| train_0/q_grads_std       | 0.301364279538393     |
| train_0/q_loss            | 0.21538639248206765   |
| train_0/reward            | -0.7214110799664922   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.025390625           |
| train_0/target_q          | -9.700548954999402    |
| train_1/avg_q             | -14.040588219667612   |
| train_1/current_q         | -12.576694444908608   |
| train_1/fw_bonus          | -0.9877954259514808   |
| train_1/fw_loss           | 0.07372299563139677   |
| train_1/mu_grads          | -0.05748370690271258  |
| train_1/mu_grads_std      | 0.35054826736450195   |
| train_1/mu_loss           | 6.48557237937157      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.998414368489637   |
| train_1/q_grads           | -0.07371678296476603  |
| train_1/q_grads_std       | 0.3380967766046524    |
| train_1/q_loss            | 0.9302404814085381    |
| train_1/reward            | -2.1015026948138256   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.61367772794853    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 394.84. Rollout time: 218.10, Training time: 176.71
Evaluating epoch 36
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 3360683.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.829885851130173   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.583011130703568    |
| train_0/fw_bonus          | -0.9988559126853943   |
| train_0/fw_loss           | 0.005737229925580322  |
| train_0/mu_grads          | -0.017758697643876074 |
| train_0/mu_grads_std      | 0.4792873851954937    |
| train_0/mu_loss           | 9.52285674231167      |
| train_0/next_q            | -9.5152621436266      |
| train_0/q_grads           | 0.0045758171938359736 |
| train_0/q_grads_std       | 0.30216175988316535   |
| train_0/q_loss            | 0.2065561597617666    |
| train_0/reward            | -0.723036358167883    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023095703125        |
| train_0/target_q          | -9.738146907108781    |
| train_1/avg_q             | -14.062754354040026   |
| train_1/current_q         | -12.529113624067643   |
| train_1/fw_bonus          | -0.9872067913413047   |
| train_1/fw_loss           | 0.07643035091459752   |
| train_1/mu_grads          | -0.05785374213010073  |
| train_1/mu_grads_std      | 0.3513952001929283    |
| train_1/mu_loss           | 6.330939021542097     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.001899097608106   |
| train_1/q_grads           | -0.07394217699766159  |
| train_1/q_grads_std       | 0.34426032230257986   |
| train_1/q_loss            | 0.9083709153549279    |
| train_1/reward            | -2.118542351878568    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.549251356520617   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 393.22. Rollout time: 218.46, Training time: 174.74
Evaluating epoch 37
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 3451808.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.038726320986294   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.513208365904049    |
| train_0/fw_bonus          | -0.9988180220127105   |
| train_0/fw_loss           | 0.005912494857329875  |
| train_0/mu_grads          | -0.018809205619618297 |
| train_0/mu_grads_std      | 0.4829367272555828    |
| train_0/mu_loss           | 9.45083025328953      |
| train_0/next_q            | -9.444465116385254    |
| train_0/q_grads           | 0.003783990751253441  |
| train_0/q_grads_std       | 0.30327521488070486   |
| train_0/q_loss            | 0.20191879766067844   |
| train_0/reward            | -0.7190989517061098   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02509765625         |
| train_0/target_q          | -9.666324629413463    |
| train_1/avg_q             | -13.986418646586703   |
| train_1/current_q         | -12.498184862792716   |
| train_1/fw_bonus          | -0.9859572812914849   |
| train_1/fw_loss           | 0.08217707723379135   |
| train_1/mu_grads          | -0.05852345414459705  |
| train_1/mu_grads_std      | 0.35197112187743185   |
| train_1/mu_loss           | 6.530785060239074     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.993463398973077   |
| train_1/q_grads           | -0.0734897980466485   |
| train_1/q_grads_std       | 0.3506523832678795    |
| train_1/q_loss            | 0.7805320300338593    |
| train_1/reward            | -2.077317017759924    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.500459294258567   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 394.75. Rollout time: 219.37, Training time: 175.35
Evaluating epoch 38
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3542933.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.098772819855672   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.579031916018163    |
| train_0/fw_bonus          | -0.998802250623703    |
| train_0/fw_loss           | 0.005985415901523084  |
| train_0/mu_grads          | -0.018538086395710706 |
| train_0/mu_grads_std      | 0.48653908893465997   |
| train_0/mu_loss           | 9.519706512414393     |
| train_0/next_q            | -9.513136536410684    |
| train_0/q_grads           | 0.0034172952990047635 |
| train_0/q_grads_std       | 0.3046508997678757    |
| train_0/q_loss            | 0.20840338088190064   |
| train_0/reward            | -0.719664797680889    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.021044921875        |
| train_0/target_q          | -9.729755330952328    |
| train_1/avg_q             | -14.04359915097186    |
| train_1/current_q         | -12.529819328667674   |
| train_1/fw_bonus          | -0.9851473078131676   |
| train_1/fw_loss           | 0.08590227980166673   |
| train_1/mu_grads          | -0.058507961314171554 |
| train_1/mu_grads_std      | 0.3535384461283684    |
| train_1/mu_loss           | 6.320442580382102     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.99828318397663    |
| train_1/q_grads           | -0.0738554859533906   |
| train_1/q_grads_std       | 0.3570629574358463    |
| train_1/q_loss            | 0.5801979145178684    |
| train_1/reward            | -2.1249344971001847   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.539540176620191   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 398.22. Rollout time: 220.17, Training time: 178.03
Evaluating epoch 39
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 3634058.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.056705027001552   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999815   |
| train_0/current_q         | -9.59398501504352     |
| train_0/fw_bonus          | -0.9987192451953888   |
| train_0/fw_loss           | 0.0063692601164802905 |
| train_0/mu_grads          | -0.018646612530574203 |
| train_0/mu_grads_std      | 0.48960357457399367   |
| train_0/mu_loss           | 9.536288220750304     |
| train_0/next_q            | -9.528229489176388    |
| train_0/q_grads           | 0.0028707972553092985 |
| train_0/q_grads_std       | 0.3064250871539116    |
| train_0/q_loss            | 0.19843961567994903   |
| train_0/reward            | -0.7205266168151866   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0317138671875       |
| train_0/target_q          | -9.747509513652503    |
| train_1/avg_q             | -14.064649180551722   |
| train_1/current_q         | -12.532866450332456   |
| train_1/fw_bonus          | -0.9850211292505264   |
| train_1/fw_loss           | 0.0864826099947095    |
| train_1/mu_grads          | -0.05904832594096661  |
| train_1/mu_grads_std      | 0.3548104576766491    |
| train_1/mu_loss           | 6.171103892769021     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.993688138944673   |
| train_1/q_grads           | -0.07478606626391411  |
| train_1/q_grads_std       | 0.3629606865346432    |
| train_1/q_loss            | 0.6671929310917297    |
| train_1/reward            | -2.0991511921522035   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.536531768084453   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 390.49. Rollout time: 213.90, Training time: 176.56
Evaluating epoch 40
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 3725183.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.037630505326169   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999995753531284   |
| train_0/current_q         | -9.62047513482443     |
| train_0/fw_bonus          | -0.9986774384975433   |
| train_0/fw_loss           | 0.006562621635384858  |
| train_0/mu_grads          | -0.0195021559484303   |
| train_0/mu_grads_std      | 0.4925507105886936    |
| train_0/mu_loss           | 9.54924428233016      |
| train_0/next_q            | -9.542279061536044    |
| train_0/q_grads           | 0.0023188975581433626 |
| train_0/q_grads_std       | 0.30835446789860727   |
| train_0/q_loss            | 0.18278338882237563   |
| train_0/reward            | -0.7235086403445166   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.020751953125        |
| train_0/target_q          | -9.773608562082831    |
| train_1/avg_q             | -14.04014462810594    |
| train_1/current_q         | -12.53380367994808    |
| train_1/fw_bonus          | -0.9835325419902802   |
| train_1/fw_loss           | 0.09332897681742906   |
| train_1/mu_grads          | -0.05955217052251101  |
| train_1/mu_grads_std      | 0.3564259998500347    |
| train_1/mu_loss           | 5.984448488625335     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.009673756299389   |
| train_1/q_grads           | -0.07445693034678698  |
| train_1/q_grads_std       | 0.3681830711662769    |
| train_1/q_loss            | 0.4906452226001689    |
| train_1/reward            | -2.094610510549683    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.538453137790317   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 390.85. Rollout time: 217.43, Training time: 173.38
Evaluating epoch 41
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 3816297.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.967397374024866   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.999956314309664   |
| train_0/current_q         | -9.58270268568837     |
| train_0/fw_bonus          | -0.9986078858375549   |
| train_0/fw_loss           | 0.006884250056464225  |
| train_0/mu_grads          | -0.020055784936994316 |
| train_0/mu_grads_std      | 0.4961415447294712    |
| train_0/mu_loss           | 9.508123273864376     |
| train_0/next_q            | -9.501013539771119    |
| train_0/q_grads           | 0.0012039239692967385 |
| train_0/q_grads_std       | 0.31107315570116045   |
| train_0/q_loss            | 0.19104547325733878   |
| train_0/reward            | -0.724743396670965    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023583984375        |
| train_0/target_q          | -9.738391950933172    |
| train_1/avg_q             | -14.037837608630884   |
| train_1/current_q         | -12.625622764321164   |
| train_1/fw_bonus          | -0.9829147934913636   |
| train_1/fw_loss           | 0.0961701525375247    |
| train_1/mu_grads          | -0.05980039071291685  |
| train_1/mu_grads_std      | 0.35785160437226293   |
| train_1/mu_loss           | 6.04341720834556      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.001819179796183   |
| train_1/q_grads           | -0.07546060010790825  |
| train_1/q_grads_std       | 0.373661694675684     |
| train_1/q_loss            | 0.37482925150113405   |
| train_1/reward            | -2.0603905028809093   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.625532186299306   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 392.32. Rollout time: 218.91, Training time: 173.37
Evaluating epoch 42
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3907422.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999913     |
| test_1/avg_q              | -14.054552183963645    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999999993    |
| train_0/current_q         | -9.555459621128595     |
| train_0/fw_bonus          | -0.9985641568899155    |
| train_0/fw_loss           | 0.007086470152717084   |
| train_0/mu_grads          | -0.021245171222835778  |
| train_0/mu_grads_std      | 0.5009313240647316     |
| train_0/mu_loss           | 9.475522504754249      |
| train_0/next_q            | -9.46707281830256      |
| train_0/q_grads           | -9.690034603409004e-05 |
| train_0/q_grads_std       | 0.31380755752325057    |
| train_0/q_loss            | 0.19905587106572936    |
| train_0/reward            | -0.7283958490654185    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.023779296875         |
| train_0/target_q          | -9.708873892553946     |
| train_1/avg_q             | -14.012195441587224    |
| train_1/current_q         | -12.683759632872619    |
| train_1/fw_bonus          | -0.9814684420824051    |
| train_1/fw_loss           | 0.10282224081456662    |
| train_1/mu_grads          | -0.05992138031870127   |
| train_1/mu_grads_std      | 0.3588909551501274     |
| train_1/mu_loss           | 6.002309314511304      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.026383220108219    |
| train_1/q_grads           | -0.0764759287238121    |
| train_1/q_grads_std       | 0.3777232699096203     |
| train_1/q_loss            | 0.4119453508320509     |
| train_1/reward            | -2.1059075612305604    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013671875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.683131088837944    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 391.28. Rollout time: 215.72, Training time: 175.54
Evaluating epoch 43
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 3998547.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.893759003131636    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999975638915     |
| train_0/current_q         | -9.647378924532823     |
| train_0/fw_bonus          | -0.9985712096095085    |
| train_0/fw_loss           | 0.007053870987147093   |
| train_0/mu_grads          | -0.02189570488408208   |
| train_0/mu_grads_std      | 0.505067552626133      |
| train_0/mu_loss           | 9.561041292635068      |
| train_0/next_q            | -9.553901965902048     |
| train_0/q_grads           | -0.0006594000617042184 |
| train_0/q_grads_std       | 0.3166400268673897     |
| train_0/q_loss            | 0.19179003432452918    |
| train_0/reward            | -0.7316098229297495    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0192138671875        |
| train_0/target_q          | -9.799347630824778     |
| train_1/avg_q             | -14.040269111584935    |
| train_1/current_q         | -12.688538366052054    |
| train_1/fw_bonus          | -0.9818124875426293    |
| train_1/fw_loss           | 0.10123994816094636    |
| train_1/mu_grads          | -0.06021629134193063   |
| train_1/mu_grads_std      | 0.35930401384830474    |
| train_1/mu_loss           | 5.976966164899588      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.02895592040736     |
| train_1/q_grads           | -0.07751738838851452   |
| train_1/q_grads_std       | 0.381653305888176      |
| train_1/q_loss            | 0.8121018535520117     |
| train_1/reward            | -2.077466297688079     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013916015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.693782709202974    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 387.99. Rollout time: 216.48, Training time: 171.48
Evaluating epoch 44
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 4089672.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999993943   |
| test_1/avg_q              | -13.974350845802606   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999996255   |
| train_0/current_q         | -9.662785843893289    |
| train_0/fw_bonus          | -0.9986059546470643   |
| train_0/fw_loss           | 0.006893167574889958  |
| train_0/mu_grads          | -0.022107034083455802 |
| train_0/mu_grads_std      | 0.5083168968558311    |
| train_0/mu_loss           | 9.574047759735176     |
| train_0/next_q            | -9.56651800443499     |
| train_0/q_grads           | -0.001006839473848231 |
| train_0/q_grads_std       | 0.31918189078569414   |
| train_0/q_loss            | 0.20583359650461527   |
| train_0/reward            | -0.7349963385640876   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0187744140625       |
| train_0/target_q          | -9.813365812606984    |
| train_1/avg_q             | -13.993224996327761   |
| train_1/current_q         | -12.82464667602375    |
| train_1/fw_bonus          | -0.9815715238451957   |
| train_1/fw_loss           | 0.1023480698466301    |
| train_1/mu_grads          | -0.06002956060692668  |
| train_1/mu_grads_std      | 0.35956117436289786   |
| train_1/mu_loss           | 5.878170997919438     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.08435151939934    |
| train_1/q_grads           | -0.0781966658309102   |
| train_1/q_grads_std       | 0.3847597874701023    |
| train_1/q_loss            | 0.503948526208923     |
| train_1/reward            | -2.0837056927543016   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.82711691824024    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 386.41. Rollout time: 217.37, Training time: 169.01
Evaluating epoch 45
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 4180797.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999754192    |
| test_1/avg_q              | -13.76795730922137    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99884793284618    |
| train_0/current_q         | -9.599738264136288    |
| train_0/fw_bonus          | -0.9986608162522316   |
| train_0/fw_loss           | 0.006639514421112836  |
| train_0/mu_grads          | -0.024591231625527142 |
| train_0/mu_grads_std      | 0.5107502326369285    |
| train_0/mu_loss           | 9.503504274163504     |
| train_0/next_q            | -9.497958138607633    |
| train_0/q_grads           | -0.002330370288109407 |
| train_0/q_grads_std       | 0.3214421160519123    |
| train_0/q_loss            | 0.1981956523913097    |
| train_0/reward            | -0.7341570647200569   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0179931640625       |
| train_0/target_q          | -9.751766271410185    |
| train_1/avg_q             | -14.024683983053478   |
| train_1/current_q         | -12.764121283436339   |
| train_1/fw_bonus          | -0.9818215891718864   |
| train_1/fw_loss           | 0.10119804851710797   |
| train_1/mu_grads          | -0.06001422042027116  |
| train_1/mu_grads_std      | 0.36037266403436663   |
| train_1/mu_loss           | 5.9687784514880295    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.026320492974497   |
| train_1/q_grads           | -0.07912806589156389  |
| train_1/q_grads_std       | 0.38813715651631353   |
| train_1/q_loss            | 0.5369992159271182    |
| train_1/reward            | -2.0929249544104094   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.762521910671378   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 387.18. Rollout time: 217.07, Training time: 170.08
Evaluating epoch 46
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 4271922.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.993400063471231    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.997323373902134    |
| train_0/current_q         | -9.66510866307509      |
| train_0/fw_bonus          | -0.9986627668142318    |
| train_0/fw_loss           | 0.006630462035536766   |
| train_0/mu_grads          | -0.026937220897525548  |
| train_0/mu_grads_std      | 0.5131354063749314     |
| train_0/mu_loss           | 9.575654148755135      |
| train_0/next_q            | -9.569598048875111     |
| train_0/q_grads           | -0.0027688580157700926 |
| train_0/q_grads_std       | 0.32417619600892067    |
| train_0/q_loss            | 0.18902575879198671    |
| train_0/reward            | -0.7312893907132093    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0283203125           |
| train_0/target_q          | -9.82330684421761      |
| train_1/avg_q             | -13.958000666045148    |
| train_1/current_q         | -12.782718892698579    |
| train_1/fw_bonus          | -0.9814055785536766    |
| train_1/fw_loss           | 0.10311135966330767    |
| train_1/mu_grads          | -0.06038753092288971   |
| train_1/mu_grads_std      | 0.3622898057103157     |
| train_1/mu_loss           | 5.883938721449992      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.034659538962137    |
| train_1/q_grads           | -0.08005619570612907   |
| train_1/q_grads_std       | 0.3904822334647179     |
| train_1/q_loss            | 0.516334550858768      |
| train_1/reward            | -2.1336105054018843    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0014404296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.784093786471228    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 390.63. Rollout time: 218.38, Training time: 172.23
Evaluating epoch 47
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 4363047.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.96715371422232    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999899828   |
| train_0/current_q         | -9.567050635968199    |
| train_0/fw_bonus          | -0.9985534742474556   |
| train_0/fw_loss           | 0.007135902449954301  |
| train_0/mu_grads          | -0.027999781398102642 |
| train_0/mu_grads_std      | 0.5157907605171204    |
| train_0/mu_loss           | 9.477795794751087     |
| train_0/next_q            | -9.469963141393151    |
| train_0/q_grads           | -0.003209731093375012 |
| train_0/q_grads_std       | 0.32645485177636147   |
| train_0/q_loss            | 0.1898091123293573    |
| train_0/reward            | -0.7298431411058118   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023046875           |
| train_0/target_q          | -9.725358951567745    |
| train_1/avg_q             | -14.031858675287674   |
| train_1/current_q         | -12.76053494487126    |
| train_1/fw_bonus          | -0.9804464325308799   |
| train_1/fw_loss           | 0.10752271302044392   |
| train_1/mu_grads          | -0.061131418123841284 |
| train_1/mu_grads_std      | 0.36292590796947477   |
| train_1/mu_loss           | 5.900886314671672     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.03691233221376    |
| train_1/q_grads           | -0.08056804277002812  |
| train_1/q_grads_std       | 0.3929157227277756    |
| train_1/q_loss            | 0.5443527954539569    |
| train_1/reward            | -2.11980085230316     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.758548832076153   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 393.59. Rollout time: 221.58, Training time: 171.99
Evaluating epoch 48
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4454172.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.909944117027276   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.699462321249825    |
| train_0/fw_bonus          | -0.9985337078571319   |
| train_0/fw_loss           | 0.007227273005992174  |
| train_0/mu_grads          | -0.02738310624845326  |
| train_0/mu_grads_std      | 0.5200925916433334    |
| train_0/mu_loss           | 9.6122745216968       |
| train_0/next_q            | -9.604479252124591    |
| train_0/q_grads           | -0.003422736341599375 |
| train_0/q_grads_std       | 0.3281648069620132    |
| train_0/q_loss            | 0.20084421576380515   |
| train_0/reward            | -0.7312858986930223   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0251953125          |
| train_0/target_q          | -9.855265354047566    |
| train_1/avg_q             | -14.088968863087572   |
| train_1/current_q         | -12.66728571787084    |
| train_1/fw_bonus          | -0.9803668409585953   |
| train_1/fw_loss           | 0.10788870994001627   |
| train_1/mu_grads          | -0.06136400364339352  |
| train_1/mu_grads_std      | 0.362872414290905     |
| train_1/mu_loss           | 5.774604458746526     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.013590205510264   |
| train_1/q_grads           | -0.08104271050542593  |
| train_1/q_grads_std       | 0.39600107818841934   |
| train_1/q_loss            | 0.36668061151928616   |
| train_1/reward            | -2.058799149133847    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.671154798964261   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 392.35. Rollout time: 222.15, Training time: 170.17
Evaluating epoch 49
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 4545297.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.166065069383432   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.707804451663094    |
| train_0/fw_bonus          | -0.9984935954213142   |
| train_0/fw_loss           | 0.007412790018133819  |
| train_0/mu_grads          | -0.028637246880680322 |
| train_0/mu_grads_std      | 0.5246006131172181    |
| train_0/mu_loss           | 9.623573640999723     |
| train_0/next_q            | -9.617430248643686    |
| train_0/q_grads           | -0.003980526747182011 |
| train_0/q_grads_std       | 0.3305533841252327    |
| train_0/q_loss            | 0.18918101071070254   |
| train_0/reward            | -0.7307043172288104   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0273681640625       |
| train_0/target_q          | -9.864976844974526    |
| train_1/avg_q             | -13.986329485493146   |
| train_1/current_q         | -12.721469739603819   |
| train_1/fw_bonus          | -0.9794931367039681   |
| train_1/fw_loss           | 0.11190713047981263   |
| train_1/mu_grads          | -0.061541303619742395 |
| train_1/mu_grads_std      | 0.3628935530781746    |
| train_1/mu_loss           | 5.922877791327894     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.028662485881673   |
| train_1/q_grads           | -0.08137333691120148  |
| train_1/q_grads_std       | 0.399469206482172     |
| train_1/q_loss            | 0.7473252339118204    |
| train_1/reward            | -2.082935044787155    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014404296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.730478748294235   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 389.50. Rollout time: 218.19, Training time: 171.28
Evaluating epoch 50
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 4636422.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.448068427317288   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999954394493     |
| train_0/current_q         | -9.612153068821108    |
| train_0/fw_bonus          | -0.9985294133424759   |
| train_0/fw_loss           | 0.007247169350739569  |
| train_0/mu_grads          | -0.028472178522497414 |
| train_0/mu_grads_std      | 0.5283655107021332    |
| train_0/mu_loss           | 9.52886892118308      |
| train_0/next_q            | -9.521668653318214    |
| train_0/q_grads           | -0.00407518184510991  |
| train_0/q_grads_std       | 0.3330888494849205    |
| train_0/q_loss            | 0.18597636902252848   |
| train_0/reward            | -0.727939021151542    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01533203125         |
| train_0/target_q          | -9.765720090602358    |
| train_1/avg_q             | -14.080663292473952   |
| train_1/current_q         | -12.773027172993398   |
| train_1/fw_bonus          | -0.978988665342331    |
| train_1/fw_loss           | 0.11422731056809425   |
| train_1/mu_grads          | -0.061517699528485535 |
| train_1/mu_grads_std      | 0.3640769340097904    |
| train_1/mu_loss           | 5.800497905492027     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.008688881292079   |
| train_1/q_grads           | -0.08230077475309372  |
| train_1/q_grads_std       | 0.4026975594460964    |
| train_1/q_loss            | 0.30787455133128605   |
| train_1/reward            | -2.0650802704287345   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.775035534580542   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 392.73. Rollout time: 219.43, Training time: 173.27
Evaluating epoch 51
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 4727547.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.914632532979448   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999964836336     |
| train_0/current_q         | -9.530099271169414    |
| train_0/fw_bonus          | -0.998505811393261    |
| train_0/fw_loss           | 0.007356267329305411  |
| train_0/mu_grads          | -0.027807232970371843 |
| train_0/mu_grads_std      | 0.532884205877781     |
| train_0/mu_loss           | 9.4437191146369       |
| train_0/next_q            | -9.43532561591556     |
| train_0/q_grads           | -0.005215081770438701 |
| train_0/q_grads_std       | 0.3361046493053436    |
| train_0/q_loss            | 0.19748916093431315   |
| train_0/reward            | -0.728977030045644    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.021337890625        |
| train_0/target_q          | -9.68177195310415     |
| train_1/avg_q             | -14.016111277852302   |
| train_1/current_q         | -12.70713527959331    |
| train_1/fw_bonus          | -0.9788922965526581   |
| train_1/fw_loss           | 0.11467053908854723   |
| train_1/mu_grads          | -0.06205710098147392  |
| train_1/mu_grads_std      | 0.3649944797158241    |
| train_1/mu_loss           | 5.795182464315663     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.989142390206212   |
| train_1/q_grads           | -0.08287430927157402  |
| train_1/q_grads_std       | 0.40603546500205995   |
| train_1/q_loss            | 0.24402688990086813   |
| train_1/reward            | -2.0916434122787906   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.711634100859985   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 397.59. Rollout time: 221.22, Training time: 176.34
Evaluating epoch 52
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 4818672.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999996   |
| test_1/avg_q              | -14.083449292036217   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999926317   |
| train_0/current_q         | -9.6449718780754      |
| train_0/fw_bonus          | -0.9986329361796379   |
| train_0/fw_loss           | 0.006768393598031252  |
| train_0/mu_grads          | -0.029020504280924796 |
| train_0/mu_grads_std      | 0.5372049763798714    |
| train_0/mu_loss           | 9.551851913257524     |
| train_0/next_q            | -9.546126148020928    |
| train_0/q_grads           | -0.005738350306637585 |
| train_0/q_grads_std       | 0.33878335580229757   |
| train_0/q_loss            | 0.18425370280863576   |
| train_0/reward            | -0.7296265285141998   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0159423828125       |
| train_0/target_q          | -9.799686355536897    |
| train_1/avg_q             | -13.991382507934823   |
| train_1/current_q         | -12.771192799203007   |
| train_1/fw_bonus          | -0.9791734963655472   |
| train_1/fw_loss           | 0.11337727066129447   |
| train_1/mu_grads          | -0.06207897812128067  |
| train_1/mu_grads_std      | 0.3655622623860836    |
| train_1/mu_loss           | 5.921986634487483     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.01084719993013    |
| train_1/q_grads           | -0.08330677151679992  |
| train_1/q_grads_std       | 0.40970766097307204   |
| train_1/q_loss            | 0.38885342682245144   |
| train_1/reward            | -2.118456372224318    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.772539071440349   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 388.55. Rollout time: 217.66, Training time: 170.86
Evaluating epoch 53
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 53                    |
| policy/steps              | 4909797.0             |
| test/episodes             | 1350.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.909294548137217   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999675573   |
| train_0/current_q         | -9.601834644989058    |
| train_0/fw_bonus          | -0.9986941203474998   |
| train_0/fw_loss           | 0.00648550963960588   |
| train_0/mu_grads          | -0.029211716447025537 |
| train_0/mu_grads_std      | 0.5404948905110359    |
| train_0/mu_loss           | 9.512344417944496     |
| train_0/next_q            | -9.504351537781698    |
| train_0/q_grads           | -0.006074245320633054 |
| train_0/q_grads_std       | 0.34163741394877434   |
| train_0/q_loss            | 0.18292494963550304   |
| train_0/reward            | -0.7289124853938119   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0194580078125       |
| train_0/target_q          | -9.757815146419322    |
| train_1/avg_q             | -14.059078468903554   |
| train_1/current_q         | -12.850867880176562   |
| train_1/fw_bonus          | -0.9791426703333854   |
| train_1/fw_loss           | 0.11351898405700922   |
| train_1/mu_grads          | -0.06269625909626483  |
| train_1/mu_grads_std      | 0.36617670953273773   |
| train_1/mu_loss           | 5.948305671811207     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.02483171413283    |
| train_1/q_grads           | -0.08427789863198995  |
| train_1/q_grads_std       | 0.41292378306388855   |
| train_1/q_loss            | 0.5318974724940294    |
| train_1/reward            | -2.1235679197525315   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.857053291796039   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 386.82. Rollout time: 216.62, Training time: 170.17
Evaluating epoch 54
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 5000922.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999999986    |
| test_1/avg_q              | -14.105335445212232    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999989658    |
| train_0/current_q         | -9.656031925341603     |
| train_0/fw_bonus          | -0.9986824050545693    |
| train_0/fw_loss           | 0.006539631995838136   |
| train_0/mu_grads          | -0.02866480373777449   |
| train_0/mu_grads_std      | 0.5444883704185486     |
| train_0/mu_loss           | 9.566219997392661      |
| train_0/next_q            | -9.558477784535624     |
| train_0/q_grads           | -0.0073961346060968935 |
| train_0/q_grads_std       | 0.3440737873315811     |
| train_0/q_loss            | 0.17353079382932565    |
| train_0/reward            | -0.7290531179191021    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.017333984375         |
| train_0/target_q          | -9.812384842297295     |
| train_1/avg_q             | -13.993362876000406    |
| train_1/current_q         | -12.761510694761657    |
| train_1/fw_bonus          | -0.9788154348731041    |
| train_1/fw_loss           | 0.11502402666956187    |
| train_1/mu_grads          | -0.0628852566704154    |
| train_1/mu_grads_std      | 0.36641440317034724    |
| train_1/mu_loss           | 5.879836729978354      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.007680854500512    |
| train_1/q_grads           | -0.08512329123914242   |
| train_1/q_grads_std       | 0.4168602220714092     |
| train_1/q_loss            | 0.4892040715095936     |
| train_1/reward            | -2.0628085976131842    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001708984375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.765921237115816    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 397.28. Rollout time: 226.70, Training time: 170.55
Evaluating epoch 55
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 5092047.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999999817    |
| test_1/avg_q              | -14.091070099581977   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999998933024   |
| train_0/current_q         | -9.706162332358591    |
| train_0/fw_bonus          | -0.9986498147249222   |
| train_0/fw_loss           | 0.006690356845501811  |
| train_0/mu_grads          | -0.028596623847261072 |
| train_0/mu_grads_std      | 0.5478465616703033    |
| train_0/mu_loss           | 9.619320992739564     |
| train_0/next_q            | -9.61245626769649     |
| train_0/q_grads           | -0.00788738583214581  |
| train_0/q_grads_std       | 0.34644277989864347   |
| train_0/q_loss            | 0.1845799238411941    |
| train_0/reward            | -0.728804887743172    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0211669921875       |
| train_0/target_q          | -9.858649052552712    |
| train_1/avg_q             | -14.063534534092303   |
| train_1/current_q         | -12.7580255496537     |
| train_1/fw_bonus          | -0.9791009977459908   |
| train_1/fw_loss           | 0.11371067408472299   |
| train_1/mu_grads          | -0.06345448270440102  |
| train_1/mu_grads_std      | 0.36735487580299375   |
| train_1/mu_loss           | 5.754321542499618     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.023214965724616   |
| train_1/q_grads           | -0.08582533728331328  |
| train_1/q_grads_std       | 0.41939196512103083   |
| train_1/q_loss            | 0.3550215746857408    |
| train_1/reward            | -2.129711631631653    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.759170293206179   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 391.69. Rollout time: 221.02, Training time: 170.64
Evaluating epoch 56
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 5183172.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.8338649159941     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999868116   |
| train_0/current_q         | -9.594455435759851    |
| train_0/fw_bonus          | -0.9985591009259224   |
| train_0/fw_loss           | 0.007109888724517077  |
| train_0/mu_grads          | -0.026697626803070307 |
| train_0/mu_grads_std      | 0.5513985991477967    |
| train_0/mu_loss           | 9.507363731037692     |
| train_0/next_q            | -9.498450344665477    |
| train_0/q_grads           | -0.008608499797992409 |
| train_0/q_grads_std       | 0.3486853830516338    |
| train_0/q_loss            | 0.1754302324165724    |
| train_0/reward            | -0.7286862856017251   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01962890625         |
| train_0/target_q          | -9.751050508317986    |
| train_1/avg_q             | -14.036762020857857   |
| train_1/current_q         | -12.857498053777224   |
| train_1/fw_bonus          | -0.979196646809578    |
| train_1/fw_loss           | 0.11327077616006136   |
| train_1/mu_grads          | -0.06413303557783365  |
| train_1/mu_grads_std      | 0.3677040807902813    |
| train_1/mu_loss           | 5.696361296924168     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.984668943204099   |
| train_1/q_grads           | -0.08640527855604888  |
| train_1/q_grads_std       | 0.42293053716421125   |
| train_1/q_loss            | 0.2776964375917629    |
| train_1/reward            | -2.1437365040241274   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.856205989015333   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 389.38. Rollout time: 218.91, Training time: 170.45
Evaluating epoch 57
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 5274297.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.00900185853583    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999606   |
| train_0/current_q         | -9.531765064511578    |
| train_0/fw_bonus          | -0.9985616266727447   |
| train_0/fw_loss           | 0.007098173059057444  |
| train_0/mu_grads          | -0.026928140409290792 |
| train_0/mu_grads_std      | 0.5548868477344513    |
| train_0/mu_loss           | 9.439633338203752     |
| train_0/next_q            | -9.433704065738642    |
| train_0/q_grads           | -0.009139853063970804 |
| train_0/q_grads_std       | 0.3510890819132328    |
| train_0/q_loss            | 0.17924804104185768   |
| train_0/reward            | -0.7281138220016146   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0248046875          |
| train_0/target_q          | -9.686084625483616    |
| train_1/avg_q             | -13.982548920941701   |
| train_1/current_q         | -12.823430587072172   |
| train_1/fw_bonus          | -0.9783347532153129   |
| train_1/fw_loss           | 0.1172347605228424    |
| train_1/mu_grads          | -0.06426425166428089  |
| train_1/mu_grads_std      | 0.36809793785214423   |
| train_1/mu_loss           | 5.64906280028342      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.98545328518997    |
| train_1/q_grads           | -0.08768703863024711  |
| train_1/q_grads_std       | 0.42669221609830854   |
| train_1/q_loss            | 0.3814309398354904    |
| train_1/reward            | -2.112433982719085    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.828560978085056   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 386.20. Rollout time: 219.35, Training time: 166.82
Evaluating epoch 58
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 5365422.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.091869390112802   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999957723   |
| train_0/current_q         | -9.587163812537472    |
| train_0/fw_bonus          | -0.9984904497861862   |
| train_0/fw_loss           | 0.007427305250894278  |
| train_0/mu_grads          | -0.026319337729364633 |
| train_0/mu_grads_std      | 0.558382298052311     |
| train_0/mu_loss           | 9.49460772380945      |
| train_0/next_q            | -9.484378486186737    |
| train_0/q_grads           | -0.008619275502860546 |
| train_0/q_grads_std       | 0.35342912152409556   |
| train_0/q_loss            | 0.17993577224684879   |
| train_0/reward            | -0.7308248182089301   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.021826171875        |
| train_0/target_q          | -9.742455670152575    |
| train_1/avg_q             | -14.044056269554885   |
| train_1/current_q         | -12.7977253477262     |
| train_1/fw_bonus          | -0.9773154214024544   |
| train_1/fw_loss           | 0.12192293517291546   |
| train_1/mu_grads          | -0.06504634637385606  |
| train_1/mu_grads_std      | 0.3687977589666843    |
| train_1/mu_loss           | 5.656417036882531     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.974081677959935   |
| train_1/q_grads           | -0.0886617636308074   |
| train_1/q_grads_std       | 0.4304483994841576    |
| train_1/q_loss            | 0.29772495048040304   |
| train_1/reward            | -2.0898662064646487   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00185546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.806759755816477   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 386.69. Rollout time: 216.45, Training time: 170.22
Evaluating epoch 59
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 5456547.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.821123343763988   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999460506   |
| train_0/current_q         | -9.542651104467913    |
| train_0/fw_bonus          | -0.9985058903694153   |
| train_0/fw_loss           | 0.00735591824632138   |
| train_0/mu_grads          | -0.026622940413653852 |
| train_0/mu_grads_std      | 0.5626457273960114    |
| train_0/mu_loss           | 9.444934671406859     |
| train_0/next_q            | -9.435673164660336    |
| train_0/q_grads           | -0.009256063099019229 |
| train_0/q_grads_std       | 0.3561296209692955    |
| train_0/q_loss            | 0.17777688530666186   |
| train_0/reward            | -0.7311377124249703   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0210693359375       |
| train_0/target_q          | -9.698210910229065    |
| train_1/avg_q             | -14.064634306475822   |
| train_1/current_q         | -12.749236858574111   |
| train_1/fw_bonus          | -0.9772074848413468   |
| train_1/fw_loss           | 0.12241934854537248   |
| train_1/mu_grads          | -0.06523164492100478  |
| train_1/mu_grads_std      | 0.3695264600217342    |
| train_1/mu_loss           | 5.619173483267632     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.004259261135138   |
| train_1/q_grads           | -0.08891784660518169  |
| train_1/q_grads_std       | 0.43377226367592814   |
| train_1/q_loss            | 0.2749920697807623    |
| train_1/reward            | -2.112175522373582    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.751210144953536   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 389.24. Rollout time: 218.79, Training time: 170.42
Evaluating epoch 60
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 5547672.0             |
| test/episodes             | 1525.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999996   |
| test_1/avg_q              | -13.914661473508927   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999912017   |
| train_0/current_q         | -9.643169917620474    |
| train_0/fw_bonus          | -0.9984370812773704   |
| train_0/fw_loss           | 0.00767412077402696   |
| train_0/mu_grads          | -0.025674395635724066 |
| train_0/mu_grads_std      | 0.5663409322500229    |
| train_0/mu_loss           | 9.541910094323706     |
| train_0/next_q            | -9.53364438265208     |
| train_0/q_grads           | -0.009292917954735459 |
| train_0/q_grads_std       | 0.3594519831240177    |
| train_0/q_loss            | 0.1775663200491964    |
| train_0/reward            | -0.7326780153271102   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0189697265625       |
| train_0/target_q          | -9.799734113554354    |
| train_1/avg_q             | -13.975009743511231   |
| train_1/current_q         | -12.864992184905214   |
| train_1/fw_bonus          | -0.9761875331401825   |
| train_1/fw_loss           | 0.12711031418293714   |
| train_1/mu_grads          | -0.0654551638290286   |
| train_1/mu_grads_std      | 0.3705058291554451    |
| train_1/mu_loss           | 5.639582494902928     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.020876437339762   |
| train_1/q_grads           | -0.08977422267198562  |
| train_1/q_grads_std       | 0.4369111955165863    |
| train_1/q_loss            | 0.3334363502932175    |
| train_1/reward            | -2.1068437710622674   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.86140432388126    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_60.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 391.56. Rollout time: 220.48, Training time: 171.05
Evaluating epoch 61
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 5638797.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999999993    |
| test_1/avg_q              | -13.995910454839393   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999973053   |
| train_0/current_q         | -9.636780306212662    |
| train_0/fw_bonus          | -0.998525196313858    |
| train_0/fw_loss           | 0.007266683899797499  |
| train_0/mu_grads          | -0.025421398412436246 |
| train_0/mu_grads_std      | 0.5693146154284477    |
| train_0/mu_loss           | 9.534740010978865     |
| train_0/next_q            | -9.527342313826969    |
| train_0/q_grads           | -0.009603932732716203 |
| train_0/q_grads_std       | 0.3623866192996502    |
| train_0/q_loss            | 0.179415523311075     |
| train_0/reward            | -0.7315013641797122   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0185546875          |
| train_0/target_q          | -9.789263534985208    |
| train_1/avg_q             | -14.035874763528877   |
| train_1/current_q         | -12.815328071683462   |
| train_1/fw_bonus          | -0.976600855588913    |
| train_1/fw_loss           | 0.12520938236266374   |
| train_1/mu_grads          | -0.06540230438113212  |
| train_1/mu_grads_std      | 0.37210009768605234   |
| train_1/mu_loss           | 5.57726533746088      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.019120095092376   |
| train_1/q_grads           | -0.09070531465113163  |
| train_1/q_grads_std       | 0.4401353903114796    |
| train_1/q_loss            | 0.29689158280205336   |
| train_1/reward            | -2.120478163108783    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.81752932331359    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 385.71. Rollout time: 218.15, Training time: 167.54
Evaluating epoch 62
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 5729922.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999999975    |
| test_1/avg_q              | -13.989478513125146   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999997242    |
| train_0/current_q         | -9.662704431844109    |
| train_0/fw_bonus          | -0.9985345721244812   |
| train_0/fw_loss           | 0.0072232960956171155 |
| train_0/mu_grads          | -0.025931661343201996 |
| train_0/mu_grads_std      | 0.5729030191898346    |
| train_0/mu_loss           | 9.565411230543239     |
| train_0/next_q            | -9.557393325507524    |
| train_0/q_grads           | -0.009568508178927005 |
| train_0/q_grads_std       | 0.36485662385821344   |
| train_0/q_loss            | 0.17588986621016775   |
| train_0/reward            | -0.7316281256193179   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0181640625          |
| train_0/target_q          | -9.82001524843749     |
| train_1/avg_q             | -14.033850696311546   |
| train_1/current_q         | -12.712751440497936   |
| train_1/fw_bonus          | -0.9766044661402702   |
| train_1/fw_loss           | 0.12519280277192593   |
| train_1/mu_grads          | -0.06552115492522717  |
| train_1/mu_grads_std      | 0.3733145333826542    |
| train_1/mu_loss           | 5.487995555336503     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.011190437695555   |
| train_1/q_grads           | -0.09214035738259554  |
| train_1/q_grads_std       | 0.4432936072349548    |
| train_1/q_loss            | 0.44479977217222366   |
| train_1/reward            | -2.125460434082197    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.717761766018885   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 391.51. Rollout time: 221.20, Training time: 170.28
Evaluating epoch 63
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 5821047.0             |
| test/episodes             | 1600.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999979862    |
| test_1/avg_q              | -14.039928175146809   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999997051248   |
| train_0/current_q         | -9.57804513924982     |
| train_0/fw_bonus          | -0.9986013650894165   |
| train_0/fw_loss           | 0.00691445580450818   |
| train_0/mu_grads          | -0.025553330732509493 |
| train_0/mu_grads_std      | 0.576881366968155     |
| train_0/mu_loss           | 9.47811374006513      |
| train_0/next_q            | -9.46858708459053     |
| train_0/q_grads           | -0.009892623079940677 |
| train_0/q_grads_std       | 0.36790759637951853   |
| train_0/q_loss            | 0.1765479994208247    |
| train_0/reward            | -0.7309901308704866   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0184814453125       |
| train_0/target_q          | -9.730069511209802    |
| train_1/avg_q             | -14.002854946251876   |
| train_1/current_q         | -12.781363495201187   |
| train_1/fw_bonus          | -0.9771649360656738   |
| train_1/fw_loss           | 0.1226150281727314    |
| train_1/mu_grads          | -0.06576757822185755  |
| train_1/mu_grads_std      | 0.37429085150361063   |
| train_1/mu_loss           | 5.688883847173477     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.045655858994266   |
| train_1/q_grads           | -0.09436265900731086  |
| train_1/q_grads_std       | 0.4460564166307449    |
| train_1/q_loss            | 0.35082177549383686   |
| train_1/reward            | -2.1394247548763814   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.789645343595542   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 391.59. Rollout time: 219.77, Training time: 171.79
Evaluating epoch 64
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 5911966.0             |
| test/episodes             | 1625.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999066326   |
| test_1/avg_q              | -13.429005820092861   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.99999999923956    |
| train_0/current_q         | -9.572663404046878    |
| train_0/fw_bonus          | -0.9986020624637604   |
| train_0/fw_loss           | 0.006911202694755048  |
| train_0/mu_grads          | -0.02482460835017264  |
| train_0/mu_grads_std      | 0.5810165539383888    |
| train_0/mu_loss           | 9.47905125954777      |
| train_0/next_q            | -9.46942642426473     |
| train_0/q_grads           | -0.011639275238849223 |
| train_0/q_grads_std       | 0.3705876931548119    |
| train_0/q_loss            | 0.18447658302717987   |
| train_0/reward            | -0.7310759317675547   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0152587890625       |
| train_0/target_q          | -9.72441711452694     |
| train_1/avg_q             | -14.041467493157977   |
| train_1/current_q         | -12.739109547356687   |
| train_1/fw_bonus          | -0.9764930531382561   |
| train_1/fw_loss           | 0.12570522744208573   |
| train_1/mu_grads          | -0.06606492269784212  |
| train_1/mu_grads_std      | 0.3743556186556816    |
| train_1/mu_loss           | 5.3831674313457345    |
| train_1/n_subgoals        | 2693.0                |
| train_1/next_q            | -14.002975019564683   |
| train_1/q_grads           | -0.09536569491028786  |
| train_1/q_grads_std       | 0.44930473864078524   |
| train_1/q_loss            | 0.4188830862256707    |
| train_1/reward            | -2.0877826557618393   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.744784246775598   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 393.17. Rollout time: 222.91, Training time: 170.23
Evaluating epoch 65
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 6003091.0             |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.588975402864547   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999996115957   |
| train_0/current_q         | -9.63948657084833     |
| train_0/fw_bonus          | -0.9985990986227989   |
| train_0/fw_loss           | 0.0069249056745320555 |
| train_0/mu_grads          | -0.02616209238767624  |
| train_0/mu_grads_std      | 0.5848078995943069    |
| train_0/mu_loss           | 9.544139595973176     |
| train_0/next_q            | -9.535415102369011    |
| train_0/q_grads           | -0.010850462783128022 |
| train_0/q_grads_std       | 0.3723657429218292    |
| train_0/q_loss            | 0.19410270061161924   |
| train_0/reward            | -0.7316970087144      |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0183349609375       |
| train_0/target_q          | -9.793292673611578    |
| train_1/avg_q             | -13.980389378343297   |
| train_1/current_q         | -12.773383861606957   |
| train_1/fw_bonus          | -0.9753807038068771   |
| train_1/fw_loss           | 0.13082113675773144   |
| train_1/mu_grads          | -0.06631004437804222  |
| train_1/mu_grads_std      | 0.3745340399444103    |
| train_1/mu_loss           | 5.5562795899386       |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.032723360173794   |
| train_1/q_grads           | -0.09662224464118481  |
| train_1/q_grads_std       | 0.4531301274895668    |
| train_1/q_loss            | 0.5156186639293948    |
| train_1/reward            | -2.1410350797305      |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.787098529059918   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 391.60. Rollout time: 221.60, Training time: 169.97
Evaluating epoch 66
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 6094216.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999954   |
| test_1/avg_q              | -12.850080504435486   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999999976    |
| train_0/current_q         | -9.636308893662724    |
| train_0/fw_bonus          | -0.9985875606536865   |
| train_0/fw_loss           | 0.006978274218272418  |
| train_0/mu_grads          | -0.02584866709075868  |
| train_0/mu_grads_std      | 0.5882858321070671    |
| train_0/mu_loss           | 9.54040561463286      |
| train_0/next_q            | -9.529487861455948    |
| train_0/q_grads           | -0.010816249717026948 |
| train_0/q_grads_std       | 0.3748812362551689    |
| train_0/q_loss            | 0.18617955541817177   |
| train_0/reward            | -0.7321306919446215   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0192626953125       |
| train_0/target_q          | -9.785012692951213    |
| train_1/avg_q             | -14.074498209000538   |
| train_1/current_q         | -12.721450500936456   |
| train_1/fw_bonus          | -0.9743867740035057   |
| train_1/fw_loss           | 0.1353924497961998    |
| train_1/mu_grads          | -0.06603339519351721  |
| train_1/mu_grads_std      | 0.37593742832541466   |
| train_1/mu_loss           | 5.463565076122154     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.995750599150517   |
| train_1/q_grads           | -0.0976168766617775   |
| train_1/q_grads_std       | 0.4564134478569031    |
| train_1/q_loss            | 0.48134510601974634   |
| train_1/reward            | -2.113877957706427    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.742015085423816   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 387.15. Rollout time: 215.66, Training time: 171.46
Evaluating epoch 67
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 6185341.0             |
| test/episodes             | 1700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999844   |
| test_1/avg_q              | -14.024949381145785   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999555833   |
| train_0/current_q         | -9.596075277526634    |
| train_0/fw_bonus          | -0.9985413119196892   |
| train_0/fw_loss           | 0.007192106766160578  |
| train_0/mu_grads          | -0.027464229334145784 |
| train_0/mu_grads_std      | 0.5917869970202446    |
| train_0/mu_loss           | 9.490431147130804     |
| train_0/next_q            | -9.483180121060377    |
| train_0/q_grads           | -0.011448285030201077 |
| train_0/q_grads_std       | 0.37707103714346885   |
| train_0/q_loss            | 0.19288269736675967   |
| train_0/reward            | -0.7338653844330111   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.014306640625        |
| train_0/target_q          | -9.746522633877252    |
| train_1/avg_q             | -14.017568901029364   |
| train_1/current_q         | -12.804032820207556   |
| train_1/fw_bonus          | -0.973675525188446    |
| train_1/fw_loss           | 0.13866369482129812   |
| train_1/mu_grads          | -0.06610247679054737  |
| train_1/mu_grads_std      | 0.3765732876956463    |
| train_1/mu_loss           | 5.51984939520564      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.006217405184625   |
| train_1/q_grads           | -0.09918793719261884  |
| train_1/q_grads_std       | 0.4604717783629894    |
| train_1/q_loss            | 0.36332589801477005   |
| train_1/reward            | -2.1199066049899558   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.813092272939343   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 408.34. Rollout time: 225.79, Training time: 182.52
Evaluating epoch 68
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 6276466.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.501802879734681   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999995489603   |
| train_0/current_q         | -9.544182427238706    |
| train_0/fw_bonus          | -0.9985467121005058   |
| train_0/fw_loss           | 0.0071671222685836256 |
| train_0/mu_grads          | -0.028882093820720912 |
| train_0/mu_grads_std      | 0.5951597064733505    |
| train_0/mu_loss           | 9.444578950981548     |
| train_0/next_q            | -9.43841495075323     |
| train_0/q_grads           | -0.01153431327547878  |
| train_0/q_grads_std       | 0.3795199729502201    |
| train_0/q_loss            | 0.1989689096493092    |
| train_0/reward            | -0.7319515820323431   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01611328125         |
| train_0/target_q          | -9.695622234983464    |
| train_1/avg_q             | -14.034194733265716   |
| train_1/current_q         | -12.753771297721775   |
| train_1/fw_bonus          | -0.972426000237465    |
| train_1/fw_loss           | 0.1444105204194784    |
| train_1/mu_grads          | -0.06596551202237606  |
| train_1/mu_grads_std      | 0.37653604745864866   |
| train_1/mu_loss           | 5.446662980366422     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.015584494806575   |
| train_1/q_grads           | -0.09998166728764772  |
| train_1/q_grads_std       | 0.4643720045685768    |
| train_1/q_loss            | 0.31863273326636793   |
| train_1/reward            | -2.1315132902011102   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.760388086267138   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 422.62. Rollout time: 234.14, Training time: 188.45
Evaluating epoch 69
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 6367591.0             |
| test/episodes             | 1750.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999999894    |
| test_1/avg_q              | -14.005057045156954   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999972315    |
| train_0/current_q         | -9.617766995248118    |
| train_0/fw_bonus          | -0.998485055565834    |
| train_0/fw_loss           | 0.007452276267576963  |
| train_0/mu_grads          | -0.029653326561674475 |
| train_0/mu_grads_std      | 0.5979063540697098    |
| train_0/mu_loss           | 9.51227759943416      |
| train_0/next_q            | -9.503335434582501    |
| train_0/q_grads           | -0.012214610329829156 |
| train_0/q_grads_std       | 0.3821212388575077    |
| train_0/q_loss            | 0.18065291209892798   |
| train_0/reward            | -0.7360589347699715   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0187744140625       |
| train_0/target_q          | -9.769973431158128    |
| train_1/avg_q             | -14.041289659724557   |
| train_1/current_q         | -12.733457112222156   |
| train_1/fw_bonus          | -0.9723410040140152   |
| train_1/fw_loss           | 0.14480139799416064   |
| train_1/mu_grads          | -0.06605838723480702  |
| train_1/mu_grads_std      | 0.3766485683619976    |
| train_1/mu_loss           | 5.513113837316975     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.989273659693845   |
| train_1/q_grads           | -0.10122825223952532  |
| train_1/q_grads_std       | 0.46767742112278937   |
| train_1/q_loss            | 0.4979580701930855    |
| train_1/reward            | -2.130286715468537    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.743304654006263   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 431.34. Rollout time: 245.18, Training time: 186.13
Evaluating epoch 70
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 70                    |
| policy/steps              | 6458716.0             |
| test/episodes             | 1775.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999638707   |
| test_1/avg_q              | -14.02758145025919    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999940776533   |
| train_0/current_q         | -9.622026111090303    |
| train_0/fw_bonus          | -0.9984865739941597   |
| train_0/fw_loss           | 0.007445257832296192  |
| train_0/mu_grads          | -0.03065174613147974  |
| train_0/mu_grads_std      | 0.6009576112031937    |
| train_0/mu_loss           | 9.510653544631596     |
| train_0/next_q            | -9.503157720756477    |
| train_0/q_grads           | -0.013353325147181749 |
| train_0/q_grads_std       | 0.38454310819506643   |
| train_0/q_loss            | 0.18992800951959452   |
| train_0/reward            | -0.7371461194015865   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.020654296875        |
| train_0/target_q          | -9.774067695699248    |
| train_1/avg_q             | -14.056665525707084   |
| train_1/current_q         | -12.783576881228104   |
| train_1/fw_bonus          | -0.9709689289331436   |
| train_1/fw_loss           | 0.15111186876893043   |
| train_1/mu_grads          | -0.06603213716298342  |
| train_1/mu_grads_std      | 0.3771431490778923    |
| train_1/mu_loss           | 5.529082132376099     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.025952859520391   |
| train_1/q_grads           | -0.10241911802440881  |
| train_1/q_grads_std       | 0.4707010753452778    |
| train_1/q_loss            | 0.2814747426195524    |
| train_1/reward            | -2.0612168899206154   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.788267327948958   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_70.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 393.60. Rollout time: 220.26, Training time: 173.32
Evaluating epoch 71
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 6549841.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.8284061518743     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999994935223   |
| train_0/current_q         | -9.654055081335756    |
| train_0/fw_bonus          | -0.9985102921724319   |
| train_0/fw_loss           | 0.007335581153165549  |
| train_0/mu_grads          | -0.030537269404157998 |
| train_0/mu_grads_std      | 0.6041639164090157    |
| train_0/mu_loss           | 9.55088699505719      |
| train_0/next_q            | -9.541700684875178    |
| train_0/q_grads           | -0.013487386982887983 |
| train_0/q_grads_std       | 0.38739712461829184   |
| train_0/q_loss            | 0.19499495150950696   |
| train_0/reward            | -0.7375852235483762   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0175048828125       |
| train_0/target_q          | -9.809392796257082    |
| train_1/avg_q             | -14.048178660774063   |
| train_1/current_q         | -12.79026224767191    |
| train_1/fw_bonus          | -0.9698972046375275   |
| train_1/fw_loss           | 0.15604105032980442   |
| train_1/mu_grads          | -0.06641927640885115  |
| train_1/mu_grads_std      | 0.37770588919520376   |
| train_1/mu_loss           | 5.563291573782782     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.012650533382521   |
| train_1/q_grads           | -0.10295774843543767  |
| train_1/q_grads_std       | 0.4737222410738468    |
| train_1/q_loss            | 0.45405295163706166   |
| train_1/reward            | -2.0695921520047706   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.795761812005583   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 421.31. Rollout time: 229.36, Training time: 191.92
Evaluating epoch 72
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 6640698.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.913693276742814   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.999999979026814   |
| train_0/current_q         | -9.627497520032904    |
| train_0/fw_bonus          | -0.9985106348991394   |
| train_0/fw_loss           | 0.007334002887364477  |
| train_0/mu_grads          | -0.030902037862688303 |
| train_0/mu_grads_std      | 0.6059127256274224    |
| train_0/mu_loss           | 9.523536144021765     |
| train_0/next_q            | -9.516248832686705    |
| train_0/q_grads           | -0.014469742425717413 |
| train_0/q_grads_std       | 0.3891680702567101    |
| train_0/q_loss            | 0.18168258175582627   |
| train_0/reward            | -0.7376708435120236   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023388671875        |
| train_0/target_q          | -9.786319691479367    |
| train_1/avg_q             | -13.996256736698834   |
| train_1/current_q         | -12.813061366881504   |
| train_1/fw_bonus          | -0.9694195985794067   |
| train_1/fw_loss           | 0.1582376342266798    |
| train_1/mu_grads          | -0.06672370862215757  |
| train_1/mu_grads_std      | 0.3784794330596924    |
| train_1/mu_loss           | 5.532531748122203     |
| train_1/n_subgoals        | 2691.0                |
| train_1/next_q            | -14.020878880568798   |
| train_1/q_grads           | -0.10358638353645802  |
| train_1/q_grads_std       | 0.4762477084994316    |
| train_1/q_loss            | 0.34127325304607065   |
| train_1/reward            | -2.0756033529534763   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.816499025468087   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 402.73. Rollout time: 221.32, Training time: 181.38
Evaluating epoch 73
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 6731823.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.73579250182221    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999998042379    |
| train_0/current_q         | -9.65067138919493     |
| train_0/fw_bonus          | -0.998515197634697    |
| train_0/fw_loss           | 0.007312907569576055  |
| train_0/mu_grads          | -0.031161821447312832 |
| train_0/mu_grads_std      | 0.6082694306969643    |
| train_0/mu_loss           | 9.540884236576488     |
| train_0/next_q            | -9.532798646794204    |
| train_0/q_grads           | -0.01479692873544991  |
| train_0/q_grads_std       | 0.3911009684205055    |
| train_0/q_loss            | 0.19356246002882074   |
| train_0/reward            | -0.7397239054764213   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.016015625           |
| train_0/target_q          | -9.808216140042656    |
| train_1/avg_q             | -14.022434574785429   |
| train_1/current_q         | -12.866663163749546   |
| train_1/fw_bonus          | -0.9681547790765762   |
| train_1/fw_loss           | 0.1640548437833786    |
| train_1/mu_grads          | -0.06715047582983971  |
| train_1/mu_grads_std      | 0.3800554916262627    |
| train_1/mu_loss           | 5.467601762386389     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.01495840323756    |
| train_1/q_grads           | -0.10441665817052126  |
| train_1/q_grads_std       | 0.47963402718305587   |
| train_1/q_loss            | 0.30113198165269267   |
| train_1/reward            | -2.079157953671529    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.867879807321241   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 425.24. Rollout time: 233.21, Training time: 191.99
Evaluating epoch 74
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 74                   |
| policy/steps              | 6822948.0            |
| test/episodes             | 1875.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.047727163982277  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999998929   |
| train_0/current_q         | -9.67608980587174    |
| train_0/fw_bonus          | -0.9984497353434563  |
| train_0/fw_loss           | 0.007615543145220727 |
| train_0/mu_grads          | -0.03131437627598643 |
| train_0/mu_grads_std      | 0.6104789510369301   |
| train_0/mu_loss           | 9.56130515807842     |
| train_0/next_q            | -9.552855389418855   |
| train_0/q_grads           | -0.01577481981366873 |
| train_0/q_grads_std       | 0.3928460665047169   |
| train_0/q_loss            | 0.19650403044613357  |
| train_0/reward            | -0.7419738994554791  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.019091796875       |
| train_0/target_q          | -9.829710221830412   |
| train_1/avg_q             | -14.044091856023769  |
| train_1/current_q         | -12.844834607217166  |
| train_1/fw_bonus          | -0.9685370311141014  |
| train_1/fw_loss           | 0.1622967105358839   |
| train_1/mu_grads          | -0.0676408801227808  |
| train_1/mu_grads_std      | 0.3809546515345573   |
| train_1/mu_loss           | 5.55779683055672     |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.998154238338008  |
| train_1/q_grads           | -0.10529809705913067 |
| train_1/q_grads_std       | 0.4832764618098736   |
| train_1/q_loss            | 0.27355969829459686  |
| train_1/reward            | -2.0781405909874593  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015625            |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.847403494914044  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 428.18. Rollout time: 242.45, Training time: 185.70
Evaluating epoch 75
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 6914073.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.128612282889522   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999991      |
| train_0/current_q         | -9.725523411268611    |
| train_0/fw_bonus          | -0.9984663501381874   |
| train_0/fw_loss           | 0.007538797077722847  |
| train_0/mu_grads          | -0.031242795893922447 |
| train_0/mu_grads_std      | 0.612769202888012     |
| train_0/mu_loss           | 9.61567990535528      |
| train_0/next_q            | -9.606497969241424    |
| train_0/q_grads           | -0.016337138134986162 |
| train_0/q_grads_std       | 0.394025819003582     |
| train_0/q_loss            | 0.19385954419174128   |
| train_0/reward            | -0.7409568064816995   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0136962890625       |
| train_0/target_q          | -9.87825095026344     |
| train_1/avg_q             | -14.048041205978508   |
| train_1/current_q         | -12.843324306412367   |
| train_1/fw_bonus          | -0.9688138857483863   |
| train_1/fw_loss           | 0.16102339774370195   |
| train_1/mu_grads          | -0.06761693004518747  |
| train_1/mu_grads_std      | 0.3822066344320774    |
| train_1/mu_loss           | 5.543057474619419     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.996041370535576   |
| train_1/q_grads           | -0.10613912213593721  |
| train_1/q_grads_std       | 0.48585198596119883   |
| train_1/q_loss            | 0.44869078113563915   |
| train_1/reward            | -2.122175501781021    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.855333614451101   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 402.67. Rollout time: 225.39, Training time: 177.25
Evaluating epoch 76
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 7005198.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.646956980571192   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999994827   |
| train_0/current_q         | -9.713961006860966    |
| train_0/fw_bonus          | -0.9985062137246132   |
| train_0/fw_loss           | 0.00735438778065145   |
| train_0/mu_grads          | -0.030981306498870254 |
| train_0/mu_grads_std      | 0.6151267364621162    |
| train_0/mu_loss           | 9.597384953622681     |
| train_0/next_q            | -9.588115195399109    |
| train_0/q_grads           | -0.016617796197533608 |
| train_0/q_grads_std       | 0.3960121303796768    |
| train_0/q_loss            | 0.18102810072532763   |
| train_0/reward            | -0.7435280144803983   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.015087890625        |
| train_0/target_q          | -9.865659746391222    |
| train_1/avg_q             | -14.076674717808489   |
| train_1/current_q         | -12.90290779173743    |
| train_1/fw_bonus          | -0.9685058996081353   |
| train_1/fw_loss           | 0.1624399244785309    |
| train_1/mu_grads          | -0.06784823387861252  |
| train_1/mu_grads_std      | 0.3838585868477821    |
| train_1/mu_loss           | 5.388423146992058     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.043302430994085   |
| train_1/q_grads           | -0.10727248694747686  |
| train_1/q_grads_std       | 0.4885962851345539    |
| train_1/q_loss            | 0.2585128168437928    |
| train_1/reward            | -2.099011251550837    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.906272049498497   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 447.99. Rollout time: 251.01, Training time: 196.95
Evaluating epoch 77
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 7096323.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.29285209865244    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99919095913015    |
| train_0/current_q         | -9.629126045461678    |
| train_0/fw_bonus          | -0.9984763026237488   |
| train_0/fw_loss           | 0.007492777123115957  |
| train_0/mu_grads          | -0.03188507668673992  |
| train_0/mu_grads_std      | 0.6173023104667663    |
| train_0/mu_loss           | 9.517179381704262     |
| train_0/next_q            | -9.508267160090487    |
| train_0/q_grads           | -0.017044773511588573 |
| train_0/q_grads_std       | 0.3986094407737255    |
| train_0/q_loss            | 0.18457813385186994   |
| train_0/reward            | -0.741047231345874    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01923828125         |
| train_0/target_q          | -9.78486239761711     |
| train_1/avg_q             | -14.082914366626415   |
| train_1/current_q         | -12.888425461518818   |
| train_1/fw_bonus          | -0.9688579782843589   |
| train_1/fw_loss           | 0.1608206659555435    |
| train_1/mu_grads          | -0.06811121664941311  |
| train_1/mu_grads_std      | 0.3851338565349579    |
| train_1/mu_loss           | 5.486867492175598     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.032021935302032   |
| train_1/q_grads           | -0.10774821359664202  |
| train_1/q_grads_std       | 0.49084223955869677   |
| train_1/q_loss            | 0.377566739929084     |
| train_1/reward            | -2.0765798666630872   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.888492746263731   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 436.14. Rollout time: 246.01, Training time: 190.10
Evaluating epoch 78
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 7187448.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.908668537322217   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.597752228857953    |
| train_0/fw_bonus          | -0.9985054552555084   |
| train_0/fw_loss           | 0.007357947458513081  |
| train_0/mu_grads          | -0.031075663585215806 |
| train_0/mu_grads_std      | 0.6195955574512482    |
| train_0/mu_loss           | 9.491952600224911     |
| train_0/next_q            | -9.482591633779668    |
| train_0/q_grads           | -0.017656059004366398 |
| train_0/q_grads_std       | 0.4014962397515774    |
| train_0/q_loss            | 0.17872066875412626   |
| train_0/reward            | -0.7360080984028172   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0145263671875       |
| train_0/target_q          | -9.749768360064289    |
| train_1/avg_q             | -14.117575143942721   |
| train_1/current_q         | -12.868094401231469   |
| train_1/fw_bonus          | -0.9690288379788399   |
| train_1/fw_loss           | 0.1600348275154829    |
| train_1/mu_grads          | -0.06837805286049843  |
| train_1/mu_grads_std      | 0.386725265532732     |
| train_1/mu_loss           | 5.446126285290573     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.028627616653006   |
| train_1/q_grads           | -0.10784014575183391  |
| train_1/q_grads_std       | 0.4930638179183006    |
| train_1/q_loss            | 0.31263804317129235   |
| train_1/reward            | -2.132817641500151    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.872427761737532   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 437.88. Rollout time: 244.89, Training time: 192.96
Evaluating epoch 79
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 7278455.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.518020629895984   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.999999999997616   |
| train_0/current_q         | -9.725334419109352    |
| train_0/fw_bonus          | -0.9985107138752938   |
| train_0/fw_loss           | 0.007333677879069     |
| train_0/mu_grads          | -0.03122406518086791  |
| train_0/mu_grads_std      | 0.6227687761187554    |
| train_0/mu_loss           | 9.619067247219567     |
| train_0/next_q            | -9.612496671555837    |
| train_0/q_grads           | -0.018544132076203822 |
| train_0/q_grads_std       | 0.40378443226218225   |
| train_0/q_loss            | 0.1801480242421092    |
| train_0/reward            | -0.7382446090487065   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01171875            |
| train_0/target_q          | -9.87878873291117     |
| train_1/avg_q             | -14.06195768086104    |
| train_1/current_q         | -12.847100662403609   |
| train_1/fw_bonus          | -0.9678757220506669   |
| train_1/fw_loss           | 0.16533826291561127   |
| train_1/mu_grads          | -0.06867629345506429  |
| train_1/mu_grads_std      | 0.38727221041917803   |
| train_1/mu_loss           | 5.199369307823906     |
| train_1/n_subgoals        | 2696.0                |
| train_1/next_q            | -14.026734932838782   |
| train_1/q_grads           | -0.1086843429133296   |
| train_1/q_grads_std       | 0.49648949354887006   |
| train_1/q_loss            | 0.2537563718072962    |
| train_1/reward            | -2.0983909863512964   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00185546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.848447572135479   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 474.32. Rollout time: 268.98, Training time: 205.30
Evaluating epoch 80
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 7369580.0             |
| test/episodes             | 2025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.26566748521778    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.668149479167846    |
| train_0/fw_bonus          | -0.9984448820352554   |
| train_0/fw_loss           | 0.0076380580081604425 |
| train_0/mu_grads          | -0.031483364198356865 |
| train_0/mu_grads_std      | 0.6252426922321319    |
| train_0/mu_loss           | 9.555677864021451     |
| train_0/next_q            | -9.54924896619849     |
| train_0/q_grads           | -0.019357338873669507 |
| train_0/q_grads_std       | 0.40629944354295733   |
| train_0/q_loss            | 0.18958640034710264   |
| train_0/reward            | -0.7395422658824827   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0145263671875       |
| train_0/target_q          | -9.819967003463452    |
| train_1/avg_q             | -14.04006321953843    |
| train_1/current_q         | -12.844914870517432   |
| train_1/fw_bonus          | -0.9666414096951484   |
| train_1/fw_loss           | 0.17101518847048283   |
| train_1/mu_grads          | -0.06873616967350245  |
| train_1/mu_grads_std      | 0.3876166708767414    |
| train_1/mu_loss           | 5.0381486949391165    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.022788549334475   |
| train_1/q_grads           | -0.1101316848769784   |
| train_1/q_grads_std       | 0.5006326198577881    |
| train_1/q_loss            | 0.4549644067731826    |
| train_1/reward            | -2.0716507779950915   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.861225527057332   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_80.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 469.61. Rollout time: 270.15, Training time: 199.43
Evaluating epoch 81
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 7460705.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.09359331709426    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999999653    |
| train_0/current_q         | -9.72211066562178     |
| train_0/fw_bonus          | -0.9985048934817314   |
| train_0/fw_loss           | 0.0073604794568382205 |
| train_0/mu_grads          | -0.03254335392266512  |
| train_0/mu_grads_std      | 0.6280721813440323    |
| train_0/mu_loss           | 9.617319461976432     |
| train_0/next_q            | -9.605825927391361    |
| train_0/q_grads           | -0.020110365701839328 |
| train_0/q_grads_std       | 0.40849038362503054   |
| train_0/q_loss            | 0.18508530697810077   |
| train_0/reward            | -0.7394502073839249   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01748046875         |
| train_0/target_q          | -9.87814506067096     |
| train_1/avg_q             | -14.072021570625415   |
| train_1/current_q         | -12.90944957357065    |
| train_1/fw_bonus          | -0.9659513399004936   |
| train_1/fw_loss           | 0.1741889152675867    |
| train_1/mu_grads          | -0.06920237075537443  |
| train_1/mu_grads_std      | 0.3874173365533352    |
| train_1/mu_loss           | 5.309273793972338     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.050781686321145   |
| train_1/q_grads           | -0.11199258584529162  |
| train_1/q_grads_std       | 0.503773084282875     |
| train_1/q_loss            | 0.41689799424586854   |
| train_1/reward            | -2.1055464743476477   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00185546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.916133982049777   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 473.63. Rollout time: 264.30, Training time: 209.29
Evaluating epoch 82
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 7551830.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.056383708943187   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999787191793   |
| train_0/current_q         | -9.666260579005918    |
| train_0/fw_bonus          | -0.9985170736908913   |
| train_0/fw_loss           | 0.007304167561233044  |
| train_0/mu_grads          | -0.03267106544226408  |
| train_0/mu_grads_std      | 0.6302837610244751    |
| train_0/mu_loss           | 9.566445133407317     |
| train_0/next_q            | -9.556991184255207    |
| train_0/q_grads           | -0.020463062357157467 |
| train_0/q_grads_std       | 0.41024058014154435   |
| train_0/q_loss            | 0.18294420051906263   |
| train_0/reward            | -0.737136959752388    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.024169921875        |
| train_0/target_q          | -9.824945257953695    |
| train_1/avg_q             | -14.095131584043854   |
| train_1/current_q         | -12.854676027550365   |
| train_1/fw_bonus          | -0.9662339791655541   |
| train_1/fw_loss           | 0.17288898192346097   |
| train_1/mu_grads          | -0.06934230625629426  |
| train_1/mu_grads_std      | 0.3880835182964802    |
| train_1/mu_loss           | 5.211488337679893     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.040341191713827   |
| train_1/q_grads           | -0.11255874820053577  |
| train_1/q_grads_std       | 0.5061587825417518    |
| train_1/q_loss            | 0.47959475211689373   |
| train_1/reward            | -2.109398730369139    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.868759120938114   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 479.56. Rollout time: 277.74, Training time: 201.77
Evaluating epoch 83
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 7642955.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.081907384949229   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999998200696   |
| train_0/current_q         | -9.693244369802347    |
| train_0/fw_bonus          | -0.9985588058829308   |
| train_0/fw_loss           | 0.007111228490248323  |
| train_0/mu_grads          | -0.033623789343982934 |
| train_0/mu_grads_std      | 0.6322464764118194    |
| train_0/mu_loss           | 9.585525875308681     |
| train_0/next_q            | -9.579548780907643    |
| train_0/q_grads           | -0.021254808036610486 |
| train_0/q_grads_std       | 0.41259743049740794   |
| train_0/q_loss            | 0.18410231623052825   |
| train_0/reward            | -0.7377559649852629   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0191162109375       |
| train_0/target_q          | -9.844178991092324    |
| train_1/avg_q             | -14.074723654809128   |
| train_1/current_q         | -12.778506072312638   |
| train_1/fw_bonus          | -0.9667180836200714   |
| train_1/fw_loss           | 0.17066245935857297   |
| train_1/mu_grads          | -0.06963226664811373  |
| train_1/mu_grads_std      | 0.38875005692243575   |
| train_1/mu_loss           | 5.171597903517276     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.038709294384892   |
| train_1/q_grads           | -0.11331913396716117  |
| train_1/q_grads_std       | 0.5089338824152947    |
| train_1/q_loss            | 0.23389828261326082   |
| train_1/reward            | -2.0325411757890834   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.782253803935381   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 470.90. Rollout time: 266.28, Training time: 204.59
Evaluating epoch 84
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 7734080.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.601326836899776   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999996   |
| train_0/current_q         | -9.667595213645672    |
| train_0/fw_bonus          | -0.9986317232251167   |
| train_0/fw_loss           | 0.006774074642453343  |
| train_0/mu_grads          | -0.03489436991512775  |
| train_0/mu_grads_std      | 0.6355355888605118    |
| train_0/mu_loss           | 9.561852256688754     |
| train_0/next_q            | -9.55601739895632     |
| train_0/q_grads           | -0.021191082894802094 |
| train_0/q_grads_std       | 0.41478405296802523   |
| train_0/q_loss            | 0.18570331620760933   |
| train_0/reward            | -0.7360834340674046   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0130615234375       |
| train_0/target_q          | -9.819846293818118    |
| train_1/avg_q             | -14.085830665043662   |
| train_1/current_q         | -12.75663556884303    |
| train_1/fw_bonus          | -0.9677677094936371   |
| train_1/fw_loss           | 0.16583505272865295   |
| train_1/mu_grads          | -0.06997234094887972  |
| train_1/mu_grads_std      | 0.38905540108680725   |
| train_1/mu_loss           | 5.389113268503321     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.031406836741104   |
| train_1/q_grads           | -0.1137805251404643   |
| train_1/q_grads_std       | 0.5114206343889236    |
| train_1/q_loss            | 0.5756248078542542    |
| train_1/reward            | -2.107089419734257    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.756892777413565   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 543.79. Rollout time: 291.39, Training time: 252.35
Evaluating epoch 85
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 7825205.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999996   |
| test_1/avg_q              | -12.53054441064499    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999992962   |
| train_0/current_q         | -9.580852172314561    |
| train_0/fw_bonus          | -0.9987176656723022   |
| train_0/fw_loss           | 0.006376506807282567  |
| train_0/mu_grads          | -0.0348064168356359   |
| train_0/mu_grads_std      | 0.6386072978377342    |
| train_0/mu_loss           | 9.480310485007447     |
| train_0/next_q            | -9.474526015617409    |
| train_0/q_grads           | -0.022156269010156392 |
| train_0/q_grads_std       | 0.4163256071507931    |
| train_0/q_loss            | 0.16891327620991062   |
| train_0/reward            | -0.7312924343670602   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0124755859375       |
| train_0/target_q          | -9.734597021077747    |
| train_1/avg_q             | -14.09323144533883    |
| train_1/current_q         | -12.73344003149551    |
| train_1/fw_bonus          | -0.9689411297440529   |
| train_1/fw_loss           | 0.16043824553489686   |
| train_1/mu_grads          | -0.07018914744257927  |
| train_1/mu_grads_std      | 0.39032642245292665   |
| train_1/mu_loss           | 4.9457307730901165    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.007746479073523   |
| train_1/q_grads           | -0.11384872272610665  |
| train_1/q_grads_std       | 0.5132919788360596    |
| train_1/q_loss            | 0.2919302253097824    |
| train_1/reward            | -2.1256082553933084   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.7431114652363     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 461.02. Rollout time: 249.26, Training time: 211.73
Evaluating epoch 86
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 7916330.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.839515320872305   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999987926865554   |
| train_0/current_q         | -9.68036981131425     |
| train_0/fw_bonus          | -0.9987259313464165   |
| train_0/fw_loss           | 0.006338364398106933  |
| train_0/mu_grads          | -0.034777849167585376 |
| train_0/mu_grads_std      | 0.6408491849899292    |
| train_0/mu_loss           | 9.580828826625183     |
| train_0/next_q            | -9.574982415692611    |
| train_0/q_grads           | -0.023001263150945306 |
| train_0/q_grads_std       | 0.4183562397956848    |
| train_0/q_loss            | 0.17816213759551452   |
| train_0/reward            | -0.7329567148975912   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01396484375         |
| train_0/target_q          | -9.83572422171745     |
| train_1/avg_q             | -14.057853867911122   |
| train_1/current_q         | -12.683041137258886   |
| train_1/fw_bonus          | -0.9678638309240342   |
| train_1/fw_loss           | 0.16539293006062508   |
| train_1/mu_grads          | -0.07062934786081314  |
| train_1/mu_grads_std      | 0.39135396257042887   |
| train_1/mu_loss           | 5.179356751285646     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.996948589991547   |
| train_1/q_grads           | -0.11429885420948267  |
| train_1/q_grads_std       | 0.5156362369656563    |
| train_1/q_loss            | 0.4039432433436028    |
| train_1/reward            | -2.122188753334194    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.68850935314487    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 487.47. Rollout time: 265.85, Training time: 221.59
Evaluating epoch 87
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 87                   |
| policy/steps              | 8007455.0            |
| test/episodes             | 2200.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -11.876225668948532  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999889333418   |
| train_0/current_q         | -9.613251259281075   |
| train_0/fw_bonus          | -0.9985921964049339  |
| train_0/fw_loss           | 0.006956776173319667 |
| train_0/mu_grads          | -0.03561239605769515 |
| train_0/mu_grads_std      | 0.6436437696218491   |
| train_0/mu_loss           | 9.508877189314394    |
| train_0/next_q            | -9.500794446575476   |
| train_0/q_grads           | -0.0226250056643039  |
| train_0/q_grads_std       | 0.42094972878694537  |
| train_0/q_loss            | 0.17451812864890423  |
| train_0/reward            | -0.735477742679359   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0129150390625      |
| train_0/target_q          | -9.76600310806441    |
| train_1/avg_q             | -14.008717917154915  |
| train_1/current_q         | -12.731073075541389  |
| train_1/fw_bonus          | -0.9640885338187217  |
| train_1/fw_loss           | 0.18275642953813076  |
| train_1/mu_grads          | -0.07120516207069158 |
| train_1/mu_grads_std      | 0.3924716256558895   |
| train_1/mu_loss           | 5.252938284380784    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.00583383063687   |
| train_1/q_grads           | -0.11522177699953318 |
| train_1/q_grads_std       | 0.5182632505893707   |
| train_1/q_loss            | 0.4522623791289818   |
| train_1/reward            | -2.104444166884787   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001123046875       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.739563132249582  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 465.23. Rollout time: 262.62, Training time: 202.58
Evaluating epoch 88
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 8098580.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.28887628925947    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999847700042   |
| train_0/current_q         | -9.58941714914576     |
| train_0/fw_bonus          | -0.9984442517161369   |
| train_0/fw_loss           | 0.007641018077265471  |
| train_0/mu_grads          | -0.036419852543622254 |
| train_0/mu_grads_std      | 0.6457172811031342    |
| train_0/mu_loss           | 9.479700068050906     |
| train_0/next_q            | -9.470846613742912    |
| train_0/q_grads           | -0.022999737970530988 |
| train_0/q_grads_std       | 0.4229246824979782    |
| train_0/q_loss            | 0.19500616802453652   |
| train_0/reward            | -0.7406161644874374   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0141845703125       |
| train_0/target_q          | -9.742217167342455    |
| train_1/avg_q             | -14.023908590579458   |
| train_1/current_q         | -12.843248349565183   |
| train_1/fw_bonus          | -0.9586893796920777   |
| train_1/fw_loss           | 0.2075883574783802    |
| train_1/mu_grads          | -0.07146248817443848  |
| train_1/mu_grads_std      | 0.392972619086504     |
| train_1/mu_loss           | 5.230604997001312     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.039026989721677   |
| train_1/q_grads           | -0.11598698738962412  |
| train_1/q_grads_std       | 0.5212642669677734    |
| train_1/q_loss            | 0.303607425674539     |
| train_1/reward            | -2.1164052340202035   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00185546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.844809223655904   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 452.92. Rollout time: 252.91, Training time: 199.98
Evaluating epoch 89
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 8189705.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999996   |
| test_1/avg_q              | -11.154680619216848   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999999970897     |
| train_0/current_q         | -9.747348508966661    |
| train_0/fw_bonus          | -0.9983430996537208   |
| train_0/fw_loss           | 0.008108711522072553  |
| train_0/mu_grads          | -0.035984931886196135 |
| train_0/mu_grads_std      | 0.6479580938816071    |
| train_0/mu_loss           | 9.627101185063022     |
| train_0/next_q            | -9.618105865005125    |
| train_0/q_grads           | -0.024315569223836063 |
| train_0/q_grads_std       | 0.42497450634837153   |
| train_0/q_loss            | 0.21240350182260292   |
| train_0/reward            | -0.7490250702147023   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0155517578125       |
| train_0/target_q          | -9.904714093799672    |
| train_1/avg_q             | -14.109996439840128   |
| train_1/current_q         | -12.837617838556287   |
| train_1/fw_bonus          | -0.9554889440536499   |
| train_1/fw_loss           | 0.22230785973370076   |
| train_1/mu_grads          | -0.07162534296512604  |
| train_1/mu_grads_std      | 0.3940811477601528    |
| train_1/mu_loss           | 5.200848757527401     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.019976378061298   |
| train_1/q_grads           | -0.11738748159259557  |
| train_1/q_grads_std       | 0.5247244238853455    |
| train_1/q_loss            | 0.3975304001625197    |
| train_1/reward            | -2.077427090657875    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.842009749039116   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 516.71. Rollout time: 295.26, Training time: 221.41
Evaluating epoch 90
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 90                   |
| policy/steps              | 8280830.0            |
| test/episodes             | 2275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999999999999726  |
| test_1/avg_q              | -11.450860571550376  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999999964665  |
| train_0/current_q         | -9.74738304109145    |
| train_0/fw_bonus          | -0.9981939420104027  |
| train_0/fw_loss           | 0.008798506704624742 |
| train_0/mu_grads          | -0.03631160454824567 |
| train_0/mu_grads_std      | 0.6501316383481026   |
| train_0/mu_loss           | 9.627428903531063    |
| train_0/next_q            | -9.613183868179968   |
| train_0/q_grads           | -0.02512616883032024 |
| train_0/q_grads_std       | 0.42810591086745264  |
| train_0/q_loss            | 0.22365505196681754  |
| train_0/reward            | -0.7546267585057649  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0138671875         |
| train_0/target_q          | -9.900220535454235   |
| train_1/avg_q             | -13.998730589939672  |
| train_1/current_q         | -12.953747551045694  |
| train_1/fw_bonus          | -0.9528470754623413  |
| train_1/fw_loss           | 0.2344584122300148   |
| train_1/mu_grads          | -0.07214116305112839 |
| train_1/mu_grads_std      | 0.3961172439157963   |
| train_1/mu_loss           | 5.1411540929096535   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.011024697862842  |
| train_1/q_grads           | -0.11809712667018175 |
| train_1/q_grads_std       | 0.5296452969312668   |
| train_1/q_loss            | 0.36018180361719676  |
| train_1/reward            | -2.0932692430993485  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001416015625       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.960324432482405  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_90.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 474.65. Rollout time: 259.29, Training time: 215.33
Evaluating epoch 91
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 8371955.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999997886   |
| test_1/avg_q              | -12.922494445792303   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999996664   |
| train_0/current_q         | -9.697751162734471    |
| train_0/fw_bonus          | -0.9982105478644371   |
| train_0/fw_loss           | 0.008721730369143189  |
| train_0/mu_grads          | -0.0368523420765996   |
| train_0/mu_grads_std      | 0.6527672544121742    |
| train_0/mu_loss           | 9.564761489547168     |
| train_0/next_q            | -9.554639744603065    |
| train_0/q_grads           | -0.025962651800364257 |
| train_0/q_grads_std       | 0.4303128756582737    |
| train_0/q_loss            | 0.24318276464137698   |
| train_0/reward            | -0.7563806652324274   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.013818359375        |
| train_0/target_q          | -9.849872716850717    |
| train_1/avg_q             | -14.037988087208177   |
| train_1/current_q         | -13.050337613134625   |
| train_1/fw_bonus          | -0.9515802904963493   |
| train_1/fw_loss           | 0.2402846995741129    |
| train_1/mu_grads          | -0.07246022466570139  |
| train_1/mu_grads_std      | 0.39763106778264046   |
| train_1/mu_loss           | 5.225204944494799     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.032578887539282   |
| train_1/q_grads           | -0.11910110712051392  |
| train_1/q_grads_std       | 0.5341156557202339    |
| train_1/q_loss            | 0.26180805732970025   |
| train_1/reward            | -2.103988384165132    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.055370495967361   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 430.55. Rollout time: 242.42, Training time: 188.10
Evaluating epoch 92
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 8462930.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999972225   |
| test_1/avg_q              | -12.996166397198147   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.999995711892534   |
| train_0/current_q         | -9.650992598696496    |
| train_0/fw_bonus          | -0.9982236072421073   |
| train_0/fw_loss           | 0.008661391562782228  |
| train_0/mu_grads          | -0.03798757204785943  |
| train_0/mu_grads_std      | 0.6545529276132583    |
| train_0/mu_loss           | 9.52039173912475      |
| train_0/next_q            | -9.509335714334963    |
| train_0/q_grads           | -0.025984469475224613 |
| train_0/q_grads_std       | 0.4322471864521503    |
| train_0/q_loss            | 0.22403495358171227   |
| train_0/reward            | -0.7552519355740515   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0142578125          |
| train_0/target_q          | -9.802949293359362    |
| train_1/avg_q             | -14.052743002381744   |
| train_1/current_q         | -12.98533421604549    |
| train_1/fw_bonus          | -0.95291977673769     |
| train_1/fw_loss           | 0.23412406556308268   |
| train_1/mu_grads          | -0.07255152370780707  |
| train_1/mu_grads_std      | 0.39852428063750267   |
| train_1/mu_loss           | 5.007819657013853     |
| train_1/n_subgoals        | 2695.0                |
| train_1/next_q            | -14.032806857656947   |
| train_1/q_grads           | -0.11973830498754978  |
| train_1/q_grads_std       | 0.5384940460324288    |
| train_1/q_loss            | 0.2791786103569421    |
| train_1/reward            | -2.0815502197605382   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001806640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.995802693815381   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 429.11. Rollout time: 244.24, Training time: 184.84
Evaluating epoch 93
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 93                    |
| policy/steps              | 8554055.0             |
| test/episodes             | 2350.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999991044   |
| test_1/avg_q              | -11.659588133776715   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999987098439604   |
| train_0/current_q         | -9.745912584183094    |
| train_0/fw_bonus          | -0.9982966184616089   |
| train_0/fw_loss           | 0.008323709829710424  |
| train_0/mu_grads          | -0.038728303741663694 |
| train_0/mu_grads_std      | 0.657256755232811     |
| train_0/mu_loss           | 9.61984913970401      |
| train_0/next_q            | -9.60668854264677     |
| train_0/q_grads           | -0.026510347612202168 |
| train_0/q_grads_std       | 0.43489272966980935   |
| train_0/q_loss            | 0.21610720222776275   |
| train_0/reward            | -0.7537259455406456   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0134033203125       |
| train_0/target_q          | -9.903104482406482    |
| train_1/avg_q             | -14.028601018540428   |
| train_1/current_q         | -12.979765331888848   |
| train_1/fw_bonus          | -0.9547154888510704   |
| train_1/fw_loss           | 0.22586516477167606   |
| train_1/mu_grads          | -0.07206787914037704  |
| train_1/mu_grads_std      | 0.39734211564064026   |
| train_1/mu_loss           | 5.16868243313001      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.04770012153308    |
| train_1/q_grads           | -0.12013586610555649  |
| train_1/q_grads_std       | 0.5411448076367378    |
| train_1/q_loss            | 0.4112799988560608    |
| train_1/reward            | -2.0854265924448554   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.98449022151488    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 431.58. Rollout time: 245.35, Training time: 186.20
Evaluating epoch 94
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 94                    |
| policy/steps              | 8645180.0             |
| test/episodes             | 2375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999963002   |
| test_1/avg_q              | -13.4374286423622     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999978638506   |
| train_0/current_q         | -9.69986323891446     |
| train_0/fw_bonus          | -0.9983838856220245   |
| train_0/fw_loss           | 0.007920108560938388  |
| train_0/mu_grads          | -0.038462563324719666 |
| train_0/mu_grads_std      | 0.6600820675492287    |
| train_0/mu_loss           | 9.577901442256143     |
| train_0/next_q            | -9.567648727636822    |
| train_0/q_grads           | -0.02621626970358193  |
| train_0/q_grads_std       | 0.43734932839870455   |
| train_0/q_loss            | 0.20475585784466768   |
| train_0/reward            | -0.7481421414217039   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0113525390625       |
| train_0/target_q          | -9.853928733357932    |
| train_1/avg_q             | -14.112243774363483   |
| train_1/current_q         | -12.88063915182778    |
| train_1/fw_bonus          | -0.9557950630784035   |
| train_1/fw_loss           | 0.22089994177222252   |
| train_1/mu_grads          | -0.07145926970988511  |
| train_1/mu_grads_std      | 0.39721349626779556   |
| train_1/mu_loss           | 4.780354586645471     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.011864646609258   |
| train_1/q_grads           | -0.12051886301487684  |
| train_1/q_grads_std       | 0.5433282271027565    |
| train_1/q_loss            | 0.4264072677261061    |
| train_1/reward            | -2.132902416859724    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.890193965909958   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 428.42. Rollout time: 244.63, Training time: 183.76
Evaluating epoch 95
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 95                    |
| policy/steps              | 8736305.0             |
| test/episodes             | 2400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999246015   |
| test_1/avg_q              | -13.307752417645574   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999970768541    |
| train_0/current_q         | -9.643846417227376    |
| train_0/fw_bonus          | -0.9985008597373962   |
| train_0/fw_loss           | 0.007379193976521492  |
| train_0/mu_grads          | -0.03825714588165283  |
| train_0/mu_grads_std      | 0.6621228292584419    |
| train_0/mu_loss           | 9.531731431361553     |
| train_0/next_q            | -9.52124925584288     |
| train_0/q_grads           | -0.026194847468286753 |
| train_0/q_grads_std       | 0.4390904203057289    |
| train_0/q_loss            | 0.19454490631574373   |
| train_0/reward            | -0.7414501369545178   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0101318359375       |
| train_0/target_q          | -9.796365031109527    |
| train_1/avg_q             | -14.089779923494692   |
| train_1/current_q         | -12.877023754201996   |
| train_1/fw_bonus          | -0.9585417822003365   |
| train_1/fw_loss           | 0.2082671858370304    |
| train_1/mu_grads          | -0.07135615348815919  |
| train_1/mu_grads_std      | 0.3977546565234661    |
| train_1/mu_loss           | 4.900867994462331     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.048186225770104   |
| train_1/q_grads           | -0.12139836438000202  |
| train_1/q_grads_std       | 0.545502807199955     |
| train_1/q_loss            | 0.3249253256989169    |
| train_1/reward            | -2.096482804844709    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.884609639124818   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 427.12. Rollout time: 245.01, Training time: 182.08
Evaluating epoch 96
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 96                    |
| policy/steps              | 8827430.0             |
| test/episodes             | 2425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.081302353998773   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999997674962   |
| train_0/current_q         | -9.623738460640807    |
| train_0/fw_bonus          | -0.9985525488853455   |
| train_0/fw_loss           | 0.007140155858360231  |
| train_0/mu_grads          | -0.0385921779088676   |
| train_0/mu_grads_std      | 0.6641256973147392    |
| train_0/mu_loss           | 9.507501342621529     |
| train_0/next_q            | -9.498908731014073    |
| train_0/q_grads           | -0.026700704405084253 |
| train_0/q_grads_std       | 0.4410152196884155    |
| train_0/q_loss            | 0.1989835134494701    |
| train_0/reward            | -0.7413783256764873   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0108642578125       |
| train_0/target_q          | -9.77252843766131     |
| train_1/avg_q             | -14.095127233347911   |
| train_1/current_q         | -12.94206619221884    |
| train_1/fw_bonus          | -0.9616398230195046   |
| train_1/fw_loss           | 0.19401860460639      |
| train_1/mu_grads          | -0.07150999289005995  |
| train_1/mu_grads_std      | 0.3974738046526909    |
| train_1/mu_loss           | 4.800559588979265     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.048627390798805   |
| train_1/q_grads           | -0.12202795948833227  |
| train_1/q_grads_std       | 0.5480594456195831    |
| train_1/q_loss            | 0.3149382882283705    |
| train_1/reward            | -2.08162557279793     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.94458443159661    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 425.11. Rollout time: 242.58, Training time: 182.50
Evaluating epoch 97
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 97                    |
| policy/steps              | 8918555.0             |
| test/episodes             | 2450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999995094884    |
| test_1/avg_q              | -12.678614104169117   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999966862868    |
| train_0/current_q         | -9.667251442617282    |
| train_0/fw_bonus          | -0.9985698387026787   |
| train_0/fw_loss           | 0.007060107763390988  |
| train_0/mu_grads          | -0.03858526637777686  |
| train_0/mu_grads_std      | 0.6665019527077675    |
| train_0/mu_loss           | 9.551166278986098     |
| train_0/next_q            | -9.540939617515011    |
| train_0/q_grads           | -0.026778993057087065 |
| train_0/q_grads_std       | 0.4437012031674385    |
| train_0/q_loss            | 0.20029706846239384   |
| train_0/reward            | -0.7440969414354186   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0105712890625       |
| train_0/target_q          | -9.819620332491294    |
| train_1/avg_q             | -14.10619249988142    |
| train_1/current_q         | -12.83217659251388    |
| train_1/fw_bonus          | -0.9623472452163696   |
| train_1/fw_loss           | 0.19076499454677104   |
| train_1/mu_grads          | -0.07189670838415622  |
| train_1/mu_grads_std      | 0.39709400236606596   |
| train_1/mu_loss           | 5.087974792333166     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.03553057243422    |
| train_1/q_grads           | -0.12227390594780445  |
| train_1/q_grads_std       | 0.5498019322752953    |
| train_1/q_loss            | 0.5904554501699966    |
| train_1/reward            | -2.094271765858866    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.84083234259108    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 430.10. Rollout time: 242.19, Training time: 187.88
Evaluating epoch 98
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 9009680.0             |
| test/episodes             | 2475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999999997    |
| test_1/avg_q              | -13.752793473218578   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99656560748239    |
| train_0/current_q         | -9.701979753428414    |
| train_0/fw_bonus          | -0.998518094420433    |
| train_0/fw_loss           | 0.007299491472076624  |
| train_0/mu_grads          | -0.038793387822806835 |
| train_0/mu_grads_std      | 0.6679721370339393    |
| train_0/mu_loss           | 9.5859317399134       |
| train_0/next_q            | -9.573689296388714    |
| train_0/q_grads           | -0.02727688066661358  |
| train_0/q_grads_std       | 0.4469469115138054    |
| train_0/q_loss            | 0.20218245073395824   |
| train_0/reward            | -0.7449133444431937   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010693359375        |
| train_0/target_q          | -9.852311762698934    |
| train_1/avg_q             | -14.013148290490374   |
| train_1/current_q         | -12.952967174349226   |
| train_1/fw_bonus          | -0.9597220823168755   |
| train_1/fw_loss           | 0.20283865965902806   |
| train_1/mu_grads          | -0.07212009113281966  |
| train_1/mu_grads_std      | 0.3970013275742531    |
| train_1/mu_loss           | 5.044587180209044     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.033418063204744   |
| train_1/q_grads           | -0.12247769068926573  |
| train_1/q_grads_std       | 0.5518401592969895    |
| train_1/q_loss            | 0.32180157995364134   |
| train_1/reward            | -2.0770046015379195   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.954572108561006   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 428.11. Rollout time: 245.46, Training time: 182.62
Evaluating epoch 99
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 9100805.0             |
| test/episodes             | 2500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999922568158   |
| test_1/avg_q              | -13.026923751088352   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9999988811614     |
| train_0/current_q         | -9.757334135109454    |
| train_0/fw_bonus          | -0.9984180361032486   |
| train_0/fw_loss           | 0.007762239838484675  |
| train_0/mu_grads          | -0.038146299216896294 |
| train_0/mu_grads_std      | 0.6690346151590347    |
| train_0/mu_loss           | 9.636674777643108     |
| train_0/next_q            | -9.62605366985893     |
| train_0/q_grads           | -0.027873033517971636 |
| train_0/q_grads_std       | 0.44966507479548457   |
| train_0/q_loss            | 0.21532946448489304   |
| train_0/reward            | -0.7499536438132054   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.011083984375        |
| train_0/target_q          | -9.913734701929297    |
| train_1/avg_q             | -13.9963549177696     |
| train_1/current_q         | -12.960270678513751   |
| train_1/fw_bonus          | -0.956605076789856    |
| train_1/fw_loss           | 0.21717455759644508   |
| train_1/mu_grads          | -0.07248530704528093  |
| train_1/mu_grads_std      | 0.3966801092028618    |
| train_1/mu_loss           | 4.8800952885032105    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.034083204970932   |
| train_1/q_grads           | -0.12324390728026628  |
| train_1/q_grads_std       | 0.5546541064977646    |
| train_1/q_loss            | 0.32808976151875663   |
| train_1/reward            | -2.0364690394191713   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.966375792588703   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
