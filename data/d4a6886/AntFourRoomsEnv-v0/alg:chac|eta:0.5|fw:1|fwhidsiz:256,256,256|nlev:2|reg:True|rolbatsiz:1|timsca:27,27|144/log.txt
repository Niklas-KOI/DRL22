Starting process id: 96859
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fded0f36ef0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 484.53. Rollout time: 250.08, Training time: 234.43
Evaluating epoch 0
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 91054.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -24.683832883792334   |
| test_1/avg_q              | -9.8954042357665      |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -12.729780144388714   |
| train_0/current_q         | -8.549303824749583    |
| train_0/fw_bonus          | -0.9937457725405693   |
| train_0/fw_loss           | 0.03280116468667984   |
| train_0/mu_grads          | 0.003173432528274134  |
| train_0/mu_grads_std      | 0.1527279183268547    |
| train_0/mu_loss           | 8.567201437155076     |
| train_0/next_q            | -8.54899717118421     |
| train_0/q_grads           | 0.007034952635876834  |
| train_0/q_grads_std       | 0.10356566440314055   |
| train_0/q_loss            | 0.36281931372093024   |
| train_0/reward            | -0.7186258182227903   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00048828125         |
| train_0/target_q          | -8.669960176253129    |
| train_1/avg_q             | -7.176832800417026    |
| train_1/current_q         | -8.088175622224192    |
| train_1/fw_bonus          | -0.9903147980570793   |
| train_1/fw_loss           | 0.0676804631948471    |
| train_1/mu_grads          | -0.019229442672804    |
| train_1/mu_grads_std      | 0.14455053955316544   |
| train_1/mu_loss           | 6.636384565788117     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.789474860085346    |
| train_1/q_grads           | 0.010249623539857566  |
| train_1/q_grads_std       | 0.1149663170799613    |
| train_1/q_loss            | 3.0729746301392042    |
| train_1/reward            | -2.098245777779084    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0036376953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0011111111111111111 |
| train_1/target_q          | -8.107622234481148    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 452.42. Rollout time: 251.21, Training time: 201.17
Evaluating epoch 1
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 181980.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.929022535314164    |
| test_1/avg_q              | -13.445362893579235    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -20.57734824131512     |
| train_0/current_q         | -8.984529016328974     |
| train_0/fw_bonus          | -0.996842785179615     |
| train_0/fw_loss           | 0.016857160883955658   |
| train_0/mu_grads          | -0.0029039523797109723 |
| train_0/mu_grads_std      | 0.17524981312453747    |
| train_0/mu_loss           | 8.947258338129737      |
| train_0/next_q            | -8.942082467630033     |
| train_0/q_grads           | -0.0016236772673437372 |
| train_0/q_grads_std       | 0.12775748893618583    |
| train_0/q_loss            | 0.3138589129010031     |
| train_0/reward            | -0.7130454173522593    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0087646484375        |
| train_0/target_q          | -9.13295792134808      |
| train_1/avg_q             | -12.363187363020698    |
| train_1/current_q         | -7.453375682430277     |
| train_1/fw_bonus          | -0.9885336384177208    |
| train_1/fw_loss           | 0.07714589443057776    |
| train_1/mu_grads          | -0.028424057317897676  |
| train_1/mu_grads_std      | 0.1788270477205515     |
| train_1/mu_loss           | 4.4516545966690995     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.1666929577258       |
| train_1/q_grads           | -0.010703874356113374  |
| train_1/q_grads_std       | 0.15774708539247512    |
| train_1/q_loss            | 4.088942846860646      |
| train_1/reward            | -2.0468913389013323    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002783203125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.002962962962962963   |
| train_1/target_q          | -7.600521343601261     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 450.70. Rollout time: 256.77, Training time: 193.90
Evaluating epoch 2
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 2                       |
| policy/steps              | 273105.0                |
| test/episodes             | 75.0                    |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -26.99999999996878      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 300.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.85021013061044      |
| train_0/current_q         | -8.63704222011347       |
| train_0/fw_bonus          | -0.9975808516144753     |
| train_0/fw_loss           | 0.013057528506033122    |
| train_0/mu_grads          | -0.005342255020514131   |
| train_0/mu_grads_std      | 0.20136064775288104     |
| train_0/mu_loss           | 8.547139418448745       |
| train_0/next_q            | -8.544158403970917      |
| train_0/q_grads           | -0.00029613254737341775 |
| train_0/q_grads_std       | 0.1389382265508175      |
| train_0/q_loss            | 0.20795523048491438     |
| train_0/reward            | -0.7141956931671303     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0236572265625         |
| train_0/target_q          | -8.766262092232589      |
| train_1/avg_q             | -21.93562446464839      |
| train_1/current_q         | -26.999997006128048     |
| train_1/fw_bonus          | -0.9878022387623787     |
| train_1/fw_loss           | 0.08103285152465105     |
| train_1/mu_grads          | -0.03474177597090602    |
| train_1/mu_grads_std      | 0.18355463445186615     |
| train_1/mu_loss           | 26.999999536325152      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -27.0                   |
| train_1/q_grads           | -0.011239034635946155   |
| train_1/q_grads_std       | 0.16959308236837387     |
| train_1/q_loss            | 120.22131075486436      |
| train_1/reward            | -2.101652581453527      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020263671875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -22.212802972078542     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 452.98. Rollout time: 248.33, Training time: 204.62
Evaluating epoch 3
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 364230.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -26.999999999972275    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -8.915690203920063     |
| train_0/fw_bonus          | -0.9979285955429077    |
| train_0/fw_loss           | 0.011267211684025825   |
| train_0/mu_grads          | -0.008551042596809565  |
| train_0/mu_grads_std      | 0.22307632602751254    |
| train_0/mu_loss           | 8.858972227604886      |
| train_0/next_q            | -8.859280575149313     |
| train_0/q_grads           | 4.3264196690984136e-05 |
| train_0/q_grads_std       | 0.1457060117274523     |
| train_0/q_loss            | 0.21705315537794814    |
| train_0/reward            | -0.7116351966033108    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0309814453125        |
| train_0/target_q          | -9.046558115375834     |
| train_1/avg_q             | -26.999999998242355    |
| train_1/current_q         | -26.999995719291782    |
| train_1/fw_bonus          | -0.9871832668781281    |
| train_1/fw_loss           | 0.08432218655943871    |
| train_1/mu_grads          | -0.03474216014146805   |
| train_1/mu_grads_std      | 0.1835544180124998     |
| train_1/mu_loss           | 26.99999929654515      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.011341022117994726  |
| train_1/q_grads_std       | 0.16954082250595093    |
| train_1/q_loss            | 120.55116048321256     |
| train_1/reward            | -2.0697146802842328    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001953125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -22.2163948560655      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 448.84. Rollout time: 251.29, Training time: 197.52
Evaluating epoch 4
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 4                       |
| policy/steps              | 455355.0                |
| test/episodes             | 125.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.840073149046118e-08  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 500.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.999911394231834     |
| train_0/current_q         | -9.130666797197264      |
| train_0/fw_bonus          | -0.9982073664665222     |
| train_0/fw_loss           | 0.009832066111266613    |
| train_0/mu_grads          | -0.008690923149697483   |
| train_0/mu_grads_std      | 0.24016281068325043     |
| train_0/mu_loss           | 9.087680305231576       |
| train_0/next_q            | -9.080579167038639      |
| train_0/q_grads           | -0.0019004963542101905  |
| train_0/q_grads_std       | 0.15229489281773567     |
| train_0/q_loss            | 0.21737273506428734     |
| train_0/reward            | -0.7132394235624815     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0515869140625         |
| train_0/target_q          | -9.280199991090722      |
| train_1/avg_q             | -21.91987578092159      |
| train_1/current_q         | -0.0005497413830589384  |
| train_1/fw_bonus          | -0.9866064682602882     |
| train_1/fw_loss           | 0.08738747611641884     |
| train_1/mu_grads          | -0.04222029447555542    |
| train_1/mu_grads_std      | 0.18634448945522308     |
| train_1/mu_loss           | 2.524579273370763e-07   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.3409297399641347e-12 |
| train_1/q_grads           | -0.025474328082054853   |
| train_1/q_grads_std       | 0.18136249408125876     |
| train_1/q_loss            | 18.57450203653496       |
| train_1/reward            | -2.1003466882022623     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00244140625           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.100346688204107      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 463.63. Rollout time: 252.03, Training time: 211.57
Evaluating epoch 5
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 5                       |
| policy/steps              | 546434.0                |
| test/episodes             | 150.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.1355700539895923e-08 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 600.0                   |
| train/success_rate        | 0.01                    |
| train_0/avg_q             | -26.999999999843922     |
| train_0/current_q         | -9.07331509738491       |
| train_0/fw_bonus          | -0.9984023496508598     |
| train_0/fw_loss           | 0.008828240353614092    |
| train_0/mu_grads          | -0.007594297779724002   |
| train_0/mu_grads_std      | 0.2518259987235069      |
| train_0/mu_loss           | 9.011545917803755       |
| train_0/next_q            | -9.016319632836224      |
| train_0/q_grads           | -0.003237093280768022   |
| train_0/q_grads_std       | 0.15438382029533387     |
| train_0/q_loss            | 0.1734328082241475      |
| train_0/reward            | -0.7066352565932903     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.055908203125          |
| train_0/target_q          | -9.223262848450512      |
| train_1/avg_q             | -6.225800606389495      |
| train_1/current_q         | -2.465790469781853e-07  |
| train_1/fw_bonus          | -0.985732863843441      |
| train_1/fw_loss           | 0.09202997907996177     |
| train_1/mu_grads          | -0.04534284397959709    |
| train_1/mu_grads_std      | 0.19080783426761627     |
| train_1/mu_loss           | 5.948773616204164e-08   |
| train_1/n_subgoals        | 2699.0                  |
| train_1/next_q            | -8.928236158739989e-26  |
| train_1/q_grads           | -0.02296370631083846    |
| train_1/q_grads_std       | 0.20148642361164093     |
| train_1/q_loss            | 18.09326789306681       |
| train_1/reward            | -2.062959206859523      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0022216796875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.062959206859523      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 481.84. Rollout time: 260.29, Training time: 221.51
Evaluating epoch 6
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 6                       |
| policy/steps              | 637559.0                |
| test/episodes             | 175.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.70267359181073e-09   |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 700.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.393853061291006      |
| train_0/fw_bonus          | -0.9985230460762977     |
| train_0/fw_loss           | 0.008206846157554537    |
| train_0/mu_grads          | -0.007587511942256242   |
| train_0/mu_grads_std      | 0.2568249344825745      |
| train_0/mu_loss           | 9.345813082745655       |
| train_0/next_q            | -9.344471961335753      |
| train_0/q_grads           | -0.0029035835526883603  |
| train_0/q_grads_std       | 0.158040102571249       |
| train_0/q_loss            | 0.14732867693806662     |
| train_0/reward            | -0.7050964861431567     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.046728515625          |
| train_0/target_q          | -9.5395597903678        |
| train_1/avg_q             | -2.425332176475755e-08  |
| train_1/current_q         | -1.515746426606759e-07  |
| train_1/fw_bonus          | -0.9865304604172707     |
| train_1/fw_loss           | 0.08779138624668122     |
| train_1/mu_grads          | -0.04534284397959709    |
| train_1/mu_grads_std      | 0.19080783426761627     |
| train_1/mu_loss           | 4.465243615243374e-08   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.4465736610279416e-28 |
| train_1/q_grads           | -0.022963897697627543   |
| train_1/q_grads_std       | 0.20148637890815735     |
| train_1/q_loss            | 18.946658421093705      |
| train_1/reward            | -2.1169834903339506     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00283203125           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1169834903339506     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 473.00. Rollout time: 257.94, Training time: 215.03
Evaluating epoch 7
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 7                       |
| policy/steps              | 728684.0                |
| test/episodes             | 200.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.737508536243171e-09  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 800.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.473491443610747      |
| train_0/fw_bonus          | -0.99866553992033       |
| train_0/fw_loss           | 0.007473289570771158    |
| train_0/mu_grads          | -0.009830513875931502   |
| train_0/mu_grads_std      | 0.26911490336060523     |
| train_0/mu_loss           | 9.425756472225775       |
| train_0/next_q            | -9.42152283857924       |
| train_0/q_grads           | -0.003346282464917749   |
| train_0/q_grads_std       | 0.16375523060560226     |
| train_0/q_loss            | 0.15306685143921722     |
| train_0/reward            | -0.7048869686295802     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0489990234375         |
| train_0/target_q          | -9.62433590569342       |
| train_1/avg_q             | -6.454969443744078e-08  |
| train_1/current_q         | -1.3235959455131451e-07 |
| train_1/fw_bonus          | -0.9864370107650757     |
| train_1/fw_loss           | 0.08828796483576298     |
| train_1/mu_grads          | -0.04534293711185455    |
| train_1/mu_grads_std      | 0.1908079285174608      |
| train_1/mu_loss           | 3.780107495966509e-08   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -6.622960974790169e-28  |
| train_1/q_grads           | -0.02296461621299386    |
| train_1/q_grads_std       | 0.20148613452911376     |
| train_1/q_loss            | 19.07835434152123       |
| train_1/reward            | -2.124151123732736      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00244140625           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.124151123732736      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 453.17. Rollout time: 243.47, Training time: 209.67
Evaluating epoch 8
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 8                       |
| policy/steps              | 819809.0                |
| test/episodes             | 225.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -5.267220980377341e-10  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 900.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.524070597863119      |
| train_0/fw_bonus          | -0.9988115891814232     |
| train_0/fw_loss           | 0.006721417629159987    |
| train_0/mu_grads          | -0.007786453329026699   |
| train_0/mu_grads_std      | 0.2791721738874912      |
| train_0/mu_loss           | 9.483549151807797       |
| train_0/next_q            | -9.479835854210124      |
| train_0/q_grads           | -0.003766871668631211   |
| train_0/q_grads_std       | 0.16933490633964537     |
| train_0/q_loss            | 0.15381284834765951     |
| train_0/reward            | -0.7008340148706338     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0364990234375         |
| train_0/target_q          | -9.679664909941405      |
| train_1/avg_q             | -8.187397493179499e-08  |
| train_1/current_q         | -7.224894908815515e-08  |
| train_1/fw_bonus          | -0.9872273951768875     |
| train_1/fw_loss           | 0.08408769350498915     |
| train_1/mu_grads          | -0.04534308239817619    |
| train_1/mu_grads_std      | 0.19080810248851776     |
| train_1/mu_loss           | 1.9509391712762755e-08  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.9240819228181086e-27 |
| train_1/q_grads           | -0.022965998342260718   |
| train_1/q_grads_std       | 0.20148520730435848     |
| train_1/q_loss            | 19.018931339776547      |
| train_1/reward            | -2.1185648688682703     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021728515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1185648688682703     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 525.78. Rollout time: 287.10, Training time: 238.64
Evaluating epoch 9
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 910934.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.049127132019457e-08 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.424489753248341     |
| train_0/fw_bonus          | -0.9988226786255836    |
| train_0/fw_loss           | 0.00666431630961597    |
| train_0/mu_grads          | -0.00891490604262799   |
| train_0/mu_grads_std      | 0.29429879114031793    |
| train_0/mu_loss           | 9.375774776053857      |
| train_0/next_q            | -9.372244917086705     |
| train_0/q_grads           | -0.004426513682119548  |
| train_0/q_grads_std       | 0.1732543557882309     |
| train_0/q_loss            | 0.12838722426809748    |
| train_0/reward            | -0.6987155372902635    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0485595703125        |
| train_0/target_q          | -9.577765529047506     |
| train_1/avg_q             | -6.950527649569271e-08 |
| train_1/current_q         | -6.839707120475507e-08 |
| train_1/fw_bonus          | -0.9876890420913697    |
| train_1/fw_loss           | 0.08163436222821474    |
| train_1/mu_grads          | -0.04534321250393987   |
| train_1/mu_grads_std      | 0.190808642283082      |
| train_1/mu_loss           | 1.2723975274039567e-08 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.136281452982859e-28 |
| train_1/q_grads           | -0.02296916232444346   |
| train_1/q_grads_std       | 0.2014830756932497     |
| train_1/q_loss            | 18.307882252485165     |
| train_1/reward            | -2.070077432178368     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018798828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.070077432178368     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 526.16. Rollout time: 281.60, Training time: 244.52
Evaluating epoch 10
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 10                      |
| policy/steps              | 1002059.0               |
| test/episodes             | 275.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.075907259964081e-08  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.440424933900065      |
| train_0/fw_bonus          | -0.9988802224397659     |
| train_0/fw_loss           | 0.006368067802395671    |
| train_0/mu_grads          | -0.01122002126649022    |
| train_0/mu_grads_std      | 0.30408563613891604     |
| train_0/mu_loss           | 9.39580215452818        |
| train_0/next_q            | -9.390864537959384      |
| train_0/q_grads           | -0.005134256801102311   |
| train_0/q_grads_std       | 0.1767353855073452      |
| train_0/q_loss            | 0.12674016369198693     |
| train_0/reward            | -0.6991715554438998     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0238037109375         |
| train_0/target_q          | -9.591710694611844      |
| train_1/avg_q             | -6.085525712220846e-08  |
| train_1/current_q         | -5.4418793858273845e-08 |
| train_1/fw_bonus          | -0.9879737511277199     |
| train_1/fw_loss           | 0.08012138903141022     |
| train_1/mu_grads          | -0.0453434182330966     |
| train_1/mu_grads_std      | 0.1908111937344074      |
| train_1/mu_loss           | 1.1000840556704398e-08  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.1843505914886823e-27 |
| train_1/q_grads           | -0.022978573199361564   |
| train_1/q_grads_std       | 0.2014773540198803      |
| train_1/q_loss            | 18.558641141226758      |
| train_1/reward            | -2.085673884488642      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002392578125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.085673884488642      |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 531.08. Rollout time: 295.26, Training time: 235.78
Evaluating epoch 11
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 11                      |
| policy/steps              | 1093184.0               |
| test/episodes             | 300.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.167531978036415e-08  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.352377257975496      |
| train_0/fw_bonus          | -0.9989398762583732     |
| train_0/fw_loss           | 0.006060952390544117    |
| train_0/mu_grads          | -0.012927372683770954   |
| train_0/mu_grads_std      | 0.3137997694313526      |
| train_0/mu_loss           | 9.30286253257521        |
| train_0/next_q            | -9.29984365936916       |
| train_0/q_grads           | -0.004949891718570143   |
| train_0/q_grads_std       | 0.18025812804698943     |
| train_0/q_loss            | 0.12013685684483524     |
| train_0/reward            | -0.6964548009855207     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0310791015625         |
| train_0/target_q          | -9.503563265665077      |
| train_1/avg_q             | -6.819533222112636e-08  |
| train_1/current_q         | -1.3425424759333742e-07 |
| train_1/fw_bonus          | -0.9885896667838097     |
| train_1/fw_loss           | 0.07684823218733072     |
| train_1/mu_grads          | -0.04534441642463207    |
| train_1/mu_grads_std      | 0.1908244274556637      |
| train_1/mu_loss           | 2.0363017657114334e-08  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -9.009098611489841e-27  |
| train_1/q_grads           | -0.023033986520022153   |
| train_1/q_grads_std       | 0.20143885351717472     |
| train_1/q_loss            | 18.2130691927377        |
| train_1/reward            | -2.0637040130692186     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021728515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0637040130692186     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 511.89. Rollout time: 276.33, Training time: 235.52
Evaluating epoch 12
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1184309.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999999999999268   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.494226424307547    |
| train_0/fw_bonus          | -0.9988505393266678   |
| train_0/fw_loss           | 0.006520904903300107  |
| train_0/mu_grads          | -0.013784432550892234 |
| train_0/mu_grads_std      | 0.3243499554693699    |
| train_0/mu_loss           | 9.447880541134065     |
| train_0/next_q            | -9.442032283320236    |
| train_0/q_grads           | -0.005711683433037251 |
| train_0/q_grads_std       | 0.1835501842200756    |
| train_0/q_loss            | 0.13431717774717583   |
| train_0/reward            | -0.7018422585089865   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0296142578125       |
| train_0/target_q          | -9.64831110662569     |
| train_1/avg_q             | -11.900722811692773   |
| train_1/current_q         | -26.9999972232413     |
| train_1/fw_bonus          | -0.9887336954474449   |
| train_1/fw_loss           | 0.0760827373713255    |
| train_1/mu_grads          | -0.04562567174434662  |
| train_1/mu_grads_std      | 0.19327805936336517   |
| train_1/mu_loss           | 26.999999999995794    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.02459326428361237  |
| train_1/q_grads_std       | 0.20505568124353885   |
| train_1/q_loss            | 136.4775820359758     |
| train_1/reward            | -2.068756504839257    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00205078125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.60044839937052    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 536.94. Rollout time: 302.48, Training time: 234.41
Evaluating epoch 13
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1275434.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999999999995875   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.575908334464822    |
| train_0/fw_bonus          | -0.9987891986966133   |
| train_0/fw_loss           | 0.006836641568224877  |
| train_0/mu_grads          | -0.015083509171381593 |
| train_0/mu_grads_std      | 0.33355947956442833   |
| train_0/mu_loss           | 9.521024669586026     |
| train_0/next_q            | -9.516168056155       |
| train_0/q_grads           | -0.006739507347811013 |
| train_0/q_grads_std       | 0.18860965743660926   |
| train_0/q_loss            | 0.16238594196620265   |
| train_0/reward            | -0.7067310274091142   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0345458984375       |
| train_0/target_q          | -9.728830709063091    |
| train_1/avg_q             | -26.999999704626777   |
| train_1/current_q         | -26.9999882667843     |
| train_1/fw_bonus          | -0.9894868925213813   |
| train_1/fw_loss           | 0.07208014912903309   |
| train_1/mu_grads          | -0.04562567174434662  |
| train_1/mu_grads_std      | 0.19327805936336517   |
| train_1/mu_loss           | 26.999999999993086    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.024732660967856646 |
| train_1/q_grads_std       | 0.20522593855857849   |
| train_1/q_loss            | 131.34345504747816    |
| train_1/reward            | -2.0791916886606487   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0024658203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.79434647381691    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 602.96. Rollout time: 326.33, Training time: 276.59
Evaluating epoch 14
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 14                      |
| policy/steps              | 1366559.0               |
| test/episodes             | 375.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.0838094030831983e-34 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.667992768002339      |
| train_0/fw_bonus          | -0.9987501621246337     |
| train_0/fw_loss           | 0.007037589675746858    |
| train_0/mu_grads          | -0.01531821524258703    |
| train_0/mu_grads_std      | 0.34535627737641333     |
| train_0/mu_loss           | 9.604098353346425       |
| train_0/next_q            | -9.599021888665359      |
| train_0/q_grads           | -0.007496079534757882   |
| train_0/q_grads_std       | 0.19274421222507954     |
| train_0/q_loss            | 0.15478332854859608     |
| train_0/reward            | -0.7113745971146272     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.041357421875          |
| train_0/target_q          | -9.825096637186999      |
| train_1/avg_q             | -14.824597045425328     |
| train_1/current_q         | -2.791995773941988e-11  |
| train_1/fw_bonus          | -0.9896994277834892     |
| train_1/fw_loss           | 0.07095061019062995     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 2.3033058945778903e-25  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.3226708897113695e-43 |
| train_1/q_grads           | -0.022404402494430542   |
| train_1/q_grads_std       | 0.21841195784509182     |
| train_1/q_loss            | 18.04149474108615       |
| train_1/reward            | -2.0580943490051142     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002685546875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0580943490051142     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 616.66. Rollout time: 327.62, Training time: 289.00
Evaluating epoch 15
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 1457684.0              |
| test/episodes             | 400.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -5.726473604369762e-49 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.407677280991706     |
| train_0/fw_bonus          | -0.9987199574708938    |
| train_0/fw_loss           | 0.007193123165052384   |
| train_0/mu_grads          | -0.014582463190890849  |
| train_0/mu_grads_std      | 0.35692035853862764    |
| train_0/mu_loss           | 9.336395449672889      |
| train_0/next_q            | -9.331614611375745     |
| train_0/q_grads           | -0.007441273494623602  |
| train_0/q_grads_std       | 0.19651107899844647    |
| train_0/q_loss            | 0.14163811451824732    |
| train_0/reward            | -0.7086983585082635    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0356201171875        |
| train_0/target_q          | -9.560124178688076     |
| train_1/avg_q             | -2.669543156794385e-13 |
| train_1/current_q         | -3.314638811480252e-11 |
| train_1/fw_bonus          | -0.9901016056537628    |
| train_1/fw_loss           | 0.06881336756050586    |
| train_1/mu_grads          | -0.045855484902858734  |
| train_1/mu_grads_std      | 0.1957458108663559     |
| train_1/mu_loss           | 7.678177567585295e-26  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.684641348536087e-47 |
| train_1/q_grads           | -0.022399236029013992  |
| train_1/q_grads_std       | 0.21841387823224068    |
| train_1/q_loss            | 18.409336642019518     |
| train_1/reward            | -2.0832954360041187    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023681640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0832954360041187    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 535.22. Rollout time: 274.72, Training time: 260.48
Evaluating epoch 16
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 16                      |
| policy/steps              | 1548809.0               |
| test/episodes             | 425.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.043292687851307e-31  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.999999999999996     |
| train_0/current_q         | -9.439007812574868      |
| train_0/fw_bonus          | -0.9987001299858094     |
| train_0/fw_loss           | 0.007295233313925564    |
| train_0/mu_grads          | -0.014235681900754572   |
| train_0/mu_grads_std      | 0.36890760213136675     |
| train_0/mu_loss           | 9.36181352847834        |
| train_0/next_q            | -9.356209890656547      |
| train_0/q_grads           | -0.007187802577391267   |
| train_0/q_grads_std       | 0.20016003511846064     |
| train_0/q_loss            | 0.15891709339561416     |
| train_0/reward            | -0.7136811173048045     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0315185546875         |
| train_0/target_q          | -9.59203988089897       |
| train_1/avg_q             | -1.1755782266210866e-13 |
| train_1/current_q         | -3.739803836215027e-11  |
| train_1/fw_bonus          | -0.9905387356877327     |
| train_1/fw_loss           | 0.06649038270115852     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 9.156942041948824e-30   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.3061434511436357e-43 |
| train_1/q_grads           | -0.022387610003352165   |
| train_1/q_grads_std       | 0.21841856501996518     |
| train_1/q_loss            | 18.308933453302664      |
| train_1/reward            | -2.0789607753918973     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0029052734375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0789607753918973     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 481.93. Rollout time: 257.18, Training time: 224.72
Evaluating epoch 17
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 17                      |
| policy/steps              | 1639934.0               |
| test/episodes             | 450.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -26.999999999999105     |
| test_1/avg_q              | -4.6028578159199553e-32 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.999999999995428     |
| train_0/current_q         | -9.450607941213281      |
| train_0/fw_bonus          | -0.9988189473748207     |
| train_0/fw_loss           | 0.006683511531446129    |
| train_0/mu_grads          | -0.013817857159301639   |
| train_0/mu_grads_std      | 0.37908374443650245     |
| train_0/mu_loss           | 9.36748662865466        |
| train_0/next_q            | -9.363237329702244      |
| train_0/q_grads           | -0.007705581234768033   |
| train_0/q_grads_std       | 0.20463272482156752     |
| train_0/q_loss            | 0.1565530867592988      |
| train_0/reward            | -0.7139724620479683     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0198486328125         |
| train_0/target_q          | -9.60409281068016       |
| train_1/avg_q             | -1.224527439094187e-13  |
| train_1/current_q         | -4.970459266125081e-11  |
| train_1/fw_bonus          | -0.9910964399576188     |
| train_1/fw_loss           | 0.06352663170546294     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 9.45476928827585e-30    |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -5.795662802845997e-47  |
| train_1/q_grads           | -0.022367112198844553   |
| train_1/q_grads_std       | 0.21842734925448895     |
| train_1/q_loss            | 18.31838650838775       |
| train_1/reward            | -2.0791907960767277     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002685546875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0791907960767277     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 472.99. Rollout time: 252.61, Training time: 220.34
Evaluating epoch 18
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1731059.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -4.308697820160972e-50 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999991181     |
| train_0/current_q         | -9.575253474162514     |
| train_0/fw_bonus          | -0.9988971561193466    |
| train_0/fw_loss           | 0.006280848558526486   |
| train_0/mu_grads          | -0.01366515012923628   |
| train_0/mu_grads_std      | 0.3876920573413372     |
| train_0/mu_loss           | 9.493790812615037      |
| train_0/next_q            | -9.488811748355294     |
| train_0/q_grads           | -0.007707444950938225  |
| train_0/q_grads_std       | 0.2094496540725231     |
| train_0/q_loss            | 0.15260341738206035    |
| train_0/reward            | -0.7153055146911356    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.027099609375         |
| train_0/target_q          | -9.731042978996204     |
| train_1/avg_q             | -9.079573410069747e-15 |
| train_1/current_q         | -7.16888823234329e-11  |
| train_1/fw_bonus          | -0.991266930103302     |
| train_1/fw_loss           | 0.06262058475986124    |
| train_1/mu_grads          | -0.045855484902858734  |
| train_1/mu_grads_std      | 0.1957458108663559     |
| train_1/mu_loss           | 3.830888739082881e-30  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -2.053883013833894e-44 |
| train_1/q_grads           | -0.02233573803678155   |
| train_1/q_grads_std       | 0.218441966176033      |
| train_1/q_loss            | 18.154373023216607     |
| train_1/reward            | -2.0698400077388213    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0024169921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0698400077388213    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 474.38. Rollout time: 255.15, Training time: 219.20
Evaluating epoch 19
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 19                      |
| policy/steps              | 1822184.0               |
| test/episodes             | 500.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.0976113794796686e-31 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.565848036193378      |
| train_0/fw_bonus          | -0.9990046963095665     |
| train_0/fw_loss           | 0.005727244075387716    |
| train_0/mu_grads          | -0.012354230508208275   |
| train_0/mu_grads_std      | 0.3933840669691563      |
| train_0/mu_loss           | 9.488703799127089       |
| train_0/next_q            | -9.483652861183055      |
| train_0/q_grads           | -0.009444652474485338   |
| train_0/q_grads_std       | 0.21391402669250964     |
| train_0/q_loss            | 0.1435508761284893      |
| train_0/reward            | -0.7141263714249362     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.012451171875          |
| train_0/target_q          | -9.72040096966981       |
| train_1/avg_q             | -8.348272184583468e-14  |
| train_1/current_q         | -5.0950605493898774e-11 |
| train_1/fw_bonus          | -0.9918467938899994     |
| train_1/fw_loss           | 0.05953907901421189     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 1.6761577449853582e-29  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.5974164934191326e-45 |
| train_1/q_grads           | -0.022297058580443264   |
| train_1/q_grads_std       | 0.21846284717321396     |
| train_1/q_loss            | 18.366875065030676      |
| train_1/reward            | -2.082520073095657      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020751953125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.082520073095657      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 479.01. Rollout time: 258.96, Training time: 220.01
Evaluating epoch 20
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 20                      |
| policy/steps              | 1913309.0               |
| test/episodes             | 525.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.244456933002581e-46  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.667536277283         |
| train_0/fw_bonus          | -0.9989544898271561     |
| train_0/fw_loss           | 0.005985679861623794    |
| train_0/mu_grads          | -0.010434525669552386   |
| train_0/mu_grads_std      | 0.39869311451911926     |
| train_0/mu_loss           | 9.587863685220045       |
| train_0/next_q            | -9.586113132339815      |
| train_0/q_grads           | -0.010333916964009404   |
| train_0/q_grads_std       | 0.21796236522495746     |
| train_0/q_loss            | 0.15943671421241876     |
| train_0/reward            | -0.7176413107670669     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0189697265625         |
| train_0/target_q          | -9.821107100028554      |
| train_1/avg_q             | -2.1856754241154626e-14 |
| train_1/current_q         | -9.036530485344089e-11  |
| train_1/fw_bonus          | -0.9919824331998826     |
| train_1/fw_loss           | 0.05881823152303696     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 5.783589876968784e-29   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.007829626782134e-44  |
| train_1/q_grads           | -0.02224387302994728    |
| train_1/q_grads_std       | 0.21849899515509605     |
| train_1/q_loss            | 18.726271859721827      |
| train_1/reward            | -2.11109131382691       |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0023193359375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.11109131382691       |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 482.17. Rollout time: 249.79, Training time: 232.35
Evaluating epoch 21
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 21                      |
| policy/steps              | 2004434.0               |
| test/episodes             | 550.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.1195473990592864e-29 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.519553299585928      |
| train_0/fw_bonus          | -0.9989132583141327     |
| train_0/fw_loss           | 0.006197997136041522    |
| train_0/mu_grads          | -0.00966828097589314    |
| train_0/mu_grads_std      | 0.40463649556040765     |
| train_0/mu_loss           | 9.429324067614093       |
| train_0/next_q            | -9.424141892656298      |
| train_0/q_grads           | -0.01137514179572463    |
| train_0/q_grads_std       | 0.222276172041893       |
| train_0/q_loss            | 0.14989340533626105     |
| train_0/reward            | -0.7178160028721322     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0246826171875         |
| train_0/target_q          | -9.671144747615775      |
| train_1/avg_q             | -7.010552648145084e-13  |
| train_1/current_q         | -1.306178953874164e-10  |
| train_1/fw_bonus          | -0.9912346690893173     |
| train_1/fw_loss           | 0.06279204664751888     |
| train_1/mu_grads          | -0.045855484902858734   |
| train_1/mu_grads_std      | 0.1957458108663559      |
| train_1/mu_loss           | 5.680444352992708e-28   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -9.059253651927717e-40  |
| train_1/q_grads           | -0.022142814192920923   |
| train_1/q_grads_std       | 0.21858221665024757     |
| train_1/q_loss            | 18.851966275785134      |
| train_1/reward            | -2.1213741681822285     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00205078125           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1213741681822285     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 469.76. Rollout time: 247.53, Training time: 222.19
Evaluating epoch 22
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 22                      |
| policy/steps              | 2095559.0               |
| test/episodes             | 575.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.5635962643847338e-09 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.493000308656649      |
| train_0/fw_bonus          | -0.998829385638237      |
| train_0/fw_loss           | 0.006629817525390535    |
| train_0/mu_grads          | -0.012401399970985948   |
| train_0/mu_grads_std      | 0.4113024860620499      |
| train_0/mu_loss           | 9.40617528504254        |
| train_0/next_q            | -9.400727012352437      |
| train_0/q_grads           | -0.012060788553208112   |
| train_0/q_grads_std       | 0.2273146327584982      |
| train_0/q_loss            | 0.15238165017938177     |
| train_0/reward            | -0.7176519933207601     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0254638671875         |
| train_0/target_q          | -9.647022480595849      |
| train_1/avg_q             | -9.449791704097779      |
| train_1/current_q         | -1.350079540178828e-06  |
| train_1/fw_bonus          | -0.990053091943264      |
| train_1/fw_loss           | 0.06907124556601048     |
| train_1/mu_grads          | -0.048252102266997096   |
| train_1/mu_grads_std      | 0.2010023444890976      |
| train_1/mu_loss           | 1.2448922297303718e-07  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -5.340528852682541e-25  |
| train_1/q_grads           | -0.0300122763030231     |
| train_1/q_grads_std       | 0.23181484490633011     |
| train_1/q_loss            | 18.460449349592874      |
| train_1/reward            | -2.0956002750484912     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0026123046875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0956002750484912     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 475.16. Rollout time: 247.42, Training time: 227.71
Evaluating epoch 23
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 23                      |
| policy/steps              | 2186684.0               |
| test/episodes             | 600.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.0555450561565227e-08 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -26.999999999999318     |
| train_0/current_q         | -9.52529697902259       |
| train_0/fw_bonus          | -0.9988041892647743     |
| train_0/fw_loss           | 0.006759497604798525    |
| train_0/mu_grads          | -0.014605289162136614   |
| train_0/mu_grads_std      | 0.4177329674363136      |
| train_0/mu_loss           | 9.437052395074428       |
| train_0/next_q            | -9.429730795587455      |
| train_0/q_grads           | -0.012647123425267637   |
| train_0/q_grads_std       | 0.23212236762046815     |
| train_0/q_loss            | 0.15289596040783163     |
| train_0/reward            | -0.7186769964471751     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.022216796875          |
| train_0/target_q          | -9.67840699150691       |
| train_1/avg_q             | -1.3765458703004707e-08 |
| train_1/current_q         | -1.2450596122049201e-06 |
| train_1/fw_bonus          | -0.9893574550747871     |
| train_1/fw_loss           | 0.07276792638003826     |
| train_1/mu_grads          | -0.04825234040617943    |
| train_1/mu_grads_std      | 0.20100250840187073     |
| train_1/mu_loss           | 1.1283517881650034e-07  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.5577648830864687e-24 |
| train_1/q_grads           | -0.03000035514123738    |
| train_1/q_grads_std       | 0.2319245383143425      |
| train_1/q_loss            | 18.42081025227435       |
| train_1/reward            | -2.092457056443527      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00224609375           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.092457056443527      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 468.70. Rollout time: 253.88, Training time: 214.80
Evaluating epoch 24
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2277809.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -27.0                 |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999986   |
| train_0/current_q         | -9.5075859229818      |
| train_0/fw_bonus          | -0.9987268283963203   |
| train_0/fw_loss           | 0.0071577436523512    |
| train_0/mu_grads          | -0.014938236004672945 |
| train_0/mu_grads_std      | 0.4245610676705837    |
| train_0/mu_loss           | 9.420058204221887     |
| train_0/next_q            | -9.412150985350204    |
| train_0/q_grads           | -0.013644715235568584 |
| train_0/q_grads_std       | 0.2372090697288513    |
| train_0/q_loss            | 0.15788251248698076   |
| train_0/reward            | -0.7201764039251429   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.035009765625        |
| train_0/target_q          | -9.66043805097024     |
| train_1/avg_q             | -6.480000013666931    |
| train_1/current_q         | -26.999998914336732   |
| train_1/fw_bonus          | -0.9886644184589386   |
| train_1/fw_loss           | 0.07645101696252823   |
| train_1/mu_grads          | -0.04905307665467262  |
| train_1/mu_grads_std      | 0.2026008665561676    |
| train_1/mu_loss           | 27.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.025425853999331595 |
| train_1/q_grads_std       | 0.23743853457272052   |
| train_1/q_loss            | 115.87219373740943    |
| train_1/reward            | -2.115743338055472    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00205078125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.374180838055487   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 448.86. Rollout time: 251.40, Training time: 197.43
Evaluating epoch 25
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2368934.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -27.0                 |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.494347624961282    |
| train_0/fw_bonus          | -0.9987532794475555   |
| train_0/fw_loss           | 0.007021612115204334  |
| train_0/mu_grads          | -0.0157804936170578   |
| train_0/mu_grads_std      | 0.4301558069884777    |
| train_0/mu_loss           | 9.41206963684344      |
| train_0/next_q            | -9.404806960579739    |
| train_0/q_grads           | -0.013903422094881535 |
| train_0/q_grads_std       | 0.2421512335538864    |
| train_0/q_loss            | 0.15864400708132403   |
| train_0/reward            | -0.7191642347730521   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0283447265625       |
| train_0/target_q          | -9.648543236789816    |
| train_1/avg_q             | -26.999999999997208   |
| train_1/current_q         | -26.99999499744729    |
| train_1/fw_bonus          | -0.988165108859539    |
| train_1/fw_loss           | 0.07910443358123302   |
| train_1/mu_grads          | -0.04905307665467262  |
| train_1/mu_grads_std      | 0.2026008665561676    |
| train_1/mu_loss           | 27.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.025517994537949562 |
| train_1/q_grads_std       | 0.23746060766279697   |
| train_1/q_loss            | 117.45961618214817    |
| train_1/reward            | -2.0935454452221167   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020263671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.32420511319088    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 451.34. Rollout time: 255.46, Training time: 195.85
Evaluating epoch 26
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2460059.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -25.462390117064086   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.558266988641368    |
| train_0/fw_bonus          | -0.9987469986081123   |
| train_0/fw_loss           | 0.007053951488342136  |
| train_0/mu_grads          | -0.014589123404584825 |
| train_0/mu_grads_std      | 0.43539226055145264   |
| train_0/mu_loss           | 9.470499714664651     |
| train_0/next_q            | -9.463557891731043    |
| train_0/q_grads           | -0.014162819669581949 |
| train_0/q_grads_std       | 0.24698860123753547   |
| train_0/q_loss            | 0.16041156657507902   |
| train_0/reward            | -0.7208578710058646   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0336181640625       |
| train_0/target_q          | -9.709159955873794    |
| train_1/avg_q             | -24.485855668328515   |
| train_1/current_q         | -22.99683766467199    |
| train_1/fw_bonus          | -0.9875437945127488   |
| train_1/fw_loss           | 0.08240623567253351   |
| train_1/mu_grads          | -0.04650484612211585  |
| train_1/mu_grads_std      | 0.21308454871177673   |
| train_1/mu_loss           | 26.499151989263122    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.02366908104158938  |
| train_1/q_grads_std       | 0.2664378948509693    |
| train_1/q_loss            | 24.881443101232538    |
| train_1/reward            | -2.1363866455511014   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00205078125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.278544848676113   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 451.11. Rollout time: 252.94, Training time: 198.13
Evaluating epoch 27
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2551184.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -4.819995105833894    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.505257538213604    |
| train_0/fw_bonus          | -0.9987988501787186   |
| train_0/fw_loss           | 0.006786937615834177  |
| train_0/mu_grads          | -0.014345312304794789 |
| train_0/mu_grads_std      | 0.4400475449860096    |
| train_0/mu_loss           | 9.41598524437894      |
| train_0/next_q            | -9.409704170519467    |
| train_0/q_grads           | -0.014944639638997614 |
| train_0/q_grads_std       | 0.2511605769395828    |
| train_0/q_loss            | 0.1522582624010696    |
| train_0/reward            | -0.7207495266040496   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01611328125         |
| train_0/target_q          | -9.659228175768604    |
| train_1/avg_q             | -23.164762180359027   |
| train_1/current_q         | -22.85332501100433    |
| train_1/fw_bonus          | -0.987840661406517    |
| train_1/fw_loss           | 0.08082862421870232   |
| train_1/mu_grads          | -0.05023064641281962  |
| train_1/mu_grads_std      | 0.21662022173404694   |
| train_1/mu_loss           | 1.802550841644215     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.02823009490966797  |
| train_1/q_grads_std       | 0.28388040214776994   |
| train_1/q_loss            | 17.869504637853925    |
| train_1/reward            | -2.1259027532592882   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.385632245446804   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 459.27. Rollout time: 253.31, Training time: 205.93
Evaluating epoch 28
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2642309.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -18.475278678343596   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.537776984653146    |
| train_0/fw_bonus          | -0.9987915724515914   |
| train_0/fw_loss           | 0.006824485200922936  |
| train_0/mu_grads          | -0.014350637444294989 |
| train_0/mu_grads_std      | 0.44442003071308134   |
| train_0/mu_loss           | 9.449590851861196     |
| train_0/next_q            | -9.443347397259988    |
| train_0/q_grads           | -0.015226607793010771 |
| train_0/q_grads_std       | 0.2562289983034134    |
| train_0/q_loss            | 0.1606023015112332    |
| train_0/reward            | -0.7215637510584202   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0260986328125       |
| train_0/target_q          | -9.688195776273117    |
| train_1/avg_q             | -18.682327223586327   |
| train_1/current_q         | -23.10645910217847    |
| train_1/fw_bonus          | -0.987708754837513    |
| train_1/fw_loss           | 0.0815296195447445    |
| train_1/mu_grads          | -0.05000067017972469  |
| train_1/mu_grads_std      | 0.2204607404768467    |
| train_1/mu_loss           | 8.458182997396632     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.03301021046936512  |
| train_1/q_grads_std       | 0.30108615234494207   |
| train_1/q_loss            | 20.525061788860338    |
| train_1/reward            | -2.103534553164354    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020751953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.35163611566437    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 445.25. Rollout time: 246.71, Training time: 198.51
Evaluating epoch 29
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2733434.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.2924178140139135   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.572392758681307    |
| train_0/fw_bonus          | -0.9987625271081925   |
| train_0/fw_loss           | 0.006974032276775688  |
| train_0/mu_grads          | -0.015132516948506236 |
| train_0/mu_grads_std      | 0.44855599105358124   |
| train_0/mu_loss           | 9.483390978574572     |
| train_0/next_q            | -9.47852407176443     |
| train_0/q_grads           | -0.015804970078170298 |
| train_0/q_grads_std       | 0.2595559872686863    |
| train_0/q_loss            | 0.15443847176075334   |
| train_0/reward            | -0.7220741289223952   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0195068359375       |
| train_0/target_q          | -9.72778315374797     |
| train_1/avg_q             | -24.16836359714523    |
| train_1/current_q         | -22.599594264011067   |
| train_1/fw_bonus          | -0.9870976343750953   |
| train_1/fw_loss           | 0.08477725237607955   |
| train_1/mu_grads          | -0.050471055787056684 |
| train_1/mu_grads_std      | 0.22459404170513153   |
| train_1/mu_loss           | 2.6939637688793217    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0376873011700809   |
| train_1/q_grads_std       | 0.31291658207774165   |
| train_1/q_loss            | 12.103920543058749    |
| train_1/reward            | -2.0758242090203565   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00263671875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.35622557620787    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 442.59. Rollout time: 249.75, Training time: 192.81
Evaluating epoch 30
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 30                      |
| policy/steps              | 2824559.0               |
| test/episodes             | 775.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -2.9669131735513525e-06 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.413014164298929      |
| train_0/fw_bonus          | -0.9988191455602646     |
| train_0/fw_loss           | 0.006682479835581035    |
| train_0/mu_grads          | -0.014345572260208429   |
| train_0/mu_grads_std      | 0.453209038823843       |
| train_0/mu_loss           | 9.323728018491034       |
| train_0/next_q            | -9.317714252607525      |
| train_0/q_grads           | -0.01667814967222512    |
| train_0/q_grads_std       | 0.26263604164123533     |
| train_0/q_loss            | 0.15109939102164044     |
| train_0/reward            | -0.7196854525580421     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0190185546875         |
| train_0/target_q          | -9.563053531765291      |
| train_1/avg_q             | -9.859693987928138      |
| train_1/current_q         | -0.0021837506823887878  |
| train_1/fw_bonus          | -0.9872326269745827     |
| train_1/fw_loss           | 0.08405985236167908     |
| train_1/mu_grads          | -0.04992409432306886    |
| train_1/mu_grads_std      | 0.22643311098217964     |
| train_1/mu_loss           | 5.066789445111129e-06   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.1878320858026956e-29 |
| train_1/q_grads           | -0.0438313202932477     |
| train_1/q_grads_std       | 0.3198083773255348      |
| train_1/q_loss            | 19.073073894698744      |
| train_1/reward            | -2.1342046949546782     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002392578125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1342046949546782     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 480.72. Rollout time: 249.01, Training time: 231.68
Evaluating epoch 31
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
--------------------------------------------------------
| epoch                     | 31                       |
| policy/steps              | 2915684.0                |
| test/episodes             | 800.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -27.0                    |
| test_1/avg_q              | -5.162114499122319e-30   |
| test_1/n_subgoals         | 675.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3200.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -27.0                    |
| train_0/current_q         | -9.540279419487566       |
| train_0/fw_bonus          | -0.9988543063402175      |
| train_0/fw_loss           | 0.006501480320002884     |
| train_0/mu_grads          | -0.014180314680561423    |
| train_0/mu_grads_std      | 0.4588719345629215       |
| train_0/mu_loss           | 9.452137461790892        |
| train_0/next_q            | -9.447525562979877       |
| train_0/q_grads           | -0.017250066716223957    |
| train_0/q_grads_std       | 0.26586795449256895      |
| train_0/q_loss            | 0.1414449009445758       |
| train_0/reward            | -0.7203377974605246      |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.0271240234375          |
| train_0/target_q          | -9.694903502640877       |
| train_1/avg_q             | -0.11523654756989914     |
| train_1/current_q         | -3.235861960844202e-06   |
| train_1/fw_bonus          | -0.9875796183943748      |
| train_1/fw_loss           | 0.08221590127795934      |
| train_1/mu_grads          | -0.049280133098363876    |
| train_1/mu_grads_std      | 0.22712643444538116      |
| train_1/mu_loss           | 1.2170589033383849e-12   |
| train_1/n_subgoals        | 2700.0                   |
| train_1/next_q            | -5.3234500362010314e-142 |
| train_1/q_grads           | -0.04374614115804434     |
| train_1/q_grads_std       | 0.32060760259628296      |
| train_1/q_loss            | 18.561454218861225       |
| train_1/reward            | -2.097598400594143       |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.002294921875           |
| train_1/reward_-27.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -2.097598400594143       |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 490.18. Rollout time: 252.53, Training time: 237.62
Evaluating epoch 32
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 32                      |
| policy/steps              | 3006809.0               |
| test/episodes             | 825.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.3110960671174719e-17 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.499913788039915      |
| train_0/fw_bonus          | -0.9988425865769386     |
| train_0/fw_loss           | 0.006561867368873209    |
| train_0/mu_grads          | -0.015852628368884326   |
| train_0/mu_grads_std      | 0.4648575909435749      |
| train_0/mu_loss           | 9.406876288796315       |
| train_0/next_q            | -9.404196456286531      |
| train_0/q_grads           | -0.017889806441962718   |
| train_0/q_grads_std       | 0.2697943910956383      |
| train_0/q_loss            | 0.14955499982218023     |
| train_0/reward            | -0.7210887685017952     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0114501953125         |
| train_0/target_q          | -9.654136342018779      |
| train_1/avg_q             | -4.5024498323100724e-11 |
| train_1/current_q         | -1.341641840669291e-06  |
| train_1/fw_bonus          | -0.9876371949911118     |
| train_1/fw_loss           | 0.0819100022315979      |
| train_1/mu_grads          | -0.049280133098363876   |
| train_1/mu_grads_std      | 0.22712643444538116     |
| train_1/mu_loss           | 4.570554879034096e-13   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.299194058238959e-149 |
| train_1/q_grads           | -0.04374703615903854    |
| train_1/q_grads_std       | 0.32060757279396057     |
| train_1/q_loss            | 19.124530053220116      |
| train_1/reward            | -2.1327712253631033     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020263671875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1327712253631033     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 491.30. Rollout time: 252.23, Training time: 239.04
Evaluating epoch 33
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
--------------------------------------------------------
| epoch                     | 33                       |
| policy/steps              | 3097934.0                |
| test/episodes             | 850.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -27.0                    |
| test_1/avg_q              | -5.278386465039503e-17   |
| test_1/n_subgoals         | 675.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3400.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -27.0                    |
| train_0/current_q         | -9.477665549884012       |
| train_0/fw_bonus          | -0.9988752171397209      |
| train_0/fw_loss           | 0.006393851921893656     |
| train_0/mu_grads          | -0.017974933283403514    |
| train_0/mu_grads_std      | 0.4688362814486027       |
| train_0/mu_loss           | 9.394172322960515        |
| train_0/next_q            | -9.38947108833733        |
| train_0/q_grads           | -0.01893062419258058     |
| train_0/q_grads_std       | 0.2732978783547878       |
| train_0/q_loss            | 0.1457720857173081       |
| train_0/reward            | -0.717919051458739       |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.033642578125           |
| train_0/target_q          | -9.631277768856688       |
| train_1/avg_q             | -9.45414618959805e-11    |
| train_1/current_q         | -2.0973271852061603e-06  |
| train_1/fw_bonus          | -0.9881017044186592      |
| train_1/fw_loss           | 0.07944145034998655      |
| train_1/mu_grads          | -0.049280133098363876    |
| train_1/mu_grads_std      | 0.22712643444538116      |
| train_1/mu_loss           | 5.700920965017519e-13    |
| train_1/n_subgoals        | 2700.0                   |
| train_1/next_q            | -1.4063538620009733e-148 |
| train_1/q_grads           | -0.04375153351575136     |
| train_1/q_grads_std       | 0.32060649022459986      |
| train_1/q_loss            | 18.76918462898694        |
| train_1/reward            | -2.108931217728241       |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.001904296875           |
| train_1/reward_-27.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -2.108931217728241       |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 493.19. Rollout time: 251.49, Training time: 241.67
Evaluating epoch 34
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
--------------------------------------------------------
| epoch                     | 34                       |
| policy/steps              | 3189059.0                |
| test/episodes             | 875.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -27.0                    |
| test_1/avg_q              | -3.3337428274194275e-11  |
| test_1/n_subgoals         | 675.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3500.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -27.0                    |
| train_0/current_q         | -9.569661073900093       |
| train_0/fw_bonus          | -0.9990185469388961      |
| train_0/fw_loss           | 0.005655963369645178     |
| train_0/mu_grads          | -0.01870139194652438     |
| train_0/mu_grads_std      | 0.4728759855031967       |
| train_0/mu_loss           | 9.491197723104124        |
| train_0/next_q            | -9.48451412403829        |
| train_0/q_grads           | -0.019984581880271433    |
| train_0/q_grads_std       | 0.2772467777132988       |
| train_0/q_loss            | 0.13986748448658315      |
| train_0/reward            | -0.7166113216022495      |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.011083984375           |
| train_0/target_q          | -9.724875757453656       |
| train_1/avg_q             | -1.5971247192162671e-09  |
| train_1/current_q         | -5.549456478722146e-06   |
| train_1/fw_bonus          | -0.988602590560913       |
| train_1/fw_loss           | 0.07677965220063925      |
| train_1/mu_grads          | -0.049280133098363876    |
| train_1/mu_grads_std      | 0.22712643444538116      |
| train_1/mu_loss           | 2.6375634911475562e-12   |
| train_1/n_subgoals        | 2700.0                   |
| train_1/next_q            | -1.1016530972420704e-155 |
| train_1/q_grads           | -0.04378507984802127     |
| train_1/q_grads_std       | 0.32060283049941063      |
| train_1/q_loss            | 18.778238616718426       |
| train_1/reward            | -2.1084736489683564      |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.0021240234375          |
| train_1/reward_-27.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -2.1084736489683564      |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 465.72. Rollout time: 249.04, Training time: 216.66
Evaluating epoch 35
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 3280184.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -17.58690942135864    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.512501273574077    |
| train_0/fw_bonus          | -0.9990557372570038   |
| train_0/fw_loss           | 0.005464526673313231  |
| train_0/mu_grads          | -0.01982413758523762  |
| train_0/mu_grads_std      | 0.4768465027213097    |
| train_0/mu_loss           | 9.432657755305119     |
| train_0/next_q            | -9.429020081878328    |
| train_0/q_grads           | -0.020203715097159146 |
| train_0/q_grads_std       | 0.2811007134616375    |
| train_0/q_loss            | 0.1345651494246909    |
| train_0/reward            | -0.7149453440899378   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007666015625        |
| train_0/target_q          | -9.666817776768067    |
| train_1/avg_q             | -6.504081036920344    |
| train_1/current_q         | -22.612797240658146   |
| train_1/fw_bonus          | -0.9887111470103264   |
| train_1/fw_loss           | 0.07620264291763305   |
| train_1/mu_grads          | -0.051815620716661216 |
| train_1/mu_grads_std      | 0.23871807120740413   |
| train_1/mu_loss           | 7.206851237024293     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04640438221395016  |
| train_1/q_grads_std       | 0.3288259744644165    |
| train_1/q_loss            | 19.36323989920739     |
| train_1/reward            | -2.121003524326807    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001806640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.94145567276432    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 444.90. Rollout time: 249.67, Training time: 195.20
Evaluating epoch 36
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 36                      |
| policy/steps              | 3371309.0               |
| test/episodes             | 925.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.388365048215128e-16  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.459898532343622      |
| train_0/fw_bonus          | -0.9990373849868774     |
| train_0/fw_loss           | 0.00555896784644574     |
| train_0/mu_grads          | -0.02059806473553181    |
| train_0/mu_grads_std      | 0.4801852934062481      |
| train_0/mu_loss           | 9.384707668853066       |
| train_0/next_q            | -9.3810485994234        |
| train_0/q_grads           | -0.02129565910436213    |
| train_0/q_grads_std       | 0.28571673929691316     |
| train_0/q_loss            | 0.13665639906211807     |
| train_0/reward            | -0.7125924217252759     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.01142578125           |
| train_0/target_q          | -9.611542299463075      |
| train_1/avg_q             | -9.453225612388238      |
| train_1/current_q         | -7.315443914465867e-06  |
| train_1/fw_bonus          | -0.9879664823412895     |
| train_1/fw_loss           | 0.08015993312001228     |
| train_1/mu_grads          | -0.05226440355181694    |
| train_1/mu_grads_std      | 0.24165308475494385     |
| train_1/mu_loss           | 2.359458210828129e-08   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -6.023350712336561e-103 |
| train_1/q_grads           | -0.054263578914105895   |
| train_1/q_grads_std       | 0.3342633232474327      |
| train_1/q_loss            | 17.549755887137128      |
| train_1/reward            | -2.0265516057297646     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021484375            |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0265516057297646     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 443.24. Rollout time: 244.22, Training time: 199.00
Evaluating epoch 37
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 3462434.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.575903543012153   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.46747210030757     |
| train_0/fw_bonus          | -0.9989940956234932   |
| train_0/fw_loss           | 0.005781745514832437  |
| train_0/mu_grads          | -0.02105268696323037  |
| train_0/mu_grads_std      | 0.4835257053375244    |
| train_0/mu_loss           | 9.392199009961637     |
| train_0/next_q            | -9.388839797779658    |
| train_0/q_grads           | -0.0222434688359499   |
| train_0/q_grads_std       | 0.2898099921643734    |
| train_0/q_loss            | 0.14191074526218386   |
| train_0/reward            | -0.7149145350434992   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0107177734375       |
| train_0/target_q          | -9.620068602254797    |
| train_1/avg_q             | -10.88295606086362    |
| train_1/current_q         | -22.73642408735038    |
| train_1/fw_bonus          | -0.9873453542590142   |
| train_1/fw_loss           | 0.08346086908131838   |
| train_1/mu_grads          | -0.05261965915560722  |
| train_1/mu_grads_std      | 0.24471839144825935   |
| train_1/mu_loss           | 10.774452508957847    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.053919894993305205 |
| train_1/q_grads_std       | 0.33854737132787704   |
| train_1/q_loss            | 19.131850442369338    |
| train_1/reward            | -2.0966511888349486   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002099609375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -21.937775212272463   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 447.63. Rollout time: 252.86, Training time: 194.74
Evaluating epoch 38
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3553559.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -23.596530247118817   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.521290976983162    |
| train_0/fw_bonus          | -0.9989952892065048   |
| train_0/fw_loss           | 0.005775707017164677  |
| train_0/mu_grads          | -0.021237309789285064 |
| train_0/mu_grads_std      | 0.4865781456232071    |
| train_0/mu_loss           | 9.444201491524257     |
| train_0/next_q            | -9.439308256997178    |
| train_0/q_grads           | -0.022952502174302936 |
| train_0/q_grads_std       | 0.2941837251186371    |
| train_0/q_loss            | 0.13262373368334934   |
| train_0/reward            | -0.7156597503744706   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008984375           |
| train_0/target_q          | -9.676719620580277    |
| train_1/avg_q             | -26.99114285796774    |
| train_1/current_q         | -22.85370345177667    |
| train_1/fw_bonus          | -0.987233915925026    |
| train_1/fw_loss           | 0.08405303079634904   |
| train_1/mu_grads          | -0.053090987354516984 |
| train_1/mu_grads_std      | 0.24673416130244732   |
| train_1/mu_loss           | 9.909415494072032     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05355301760137081  |
| train_1/q_grads_std       | 0.34487295597791673   |
| train_1/q_loss            | 18.88911569169327     |
| train_1/reward            | -2.095777602308226    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0025390625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.06803883277699    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 463.51. Rollout time: 256.00, Training time: 207.47
Evaluating epoch 39
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 39                      |
| policy/steps              | 3644684.0               |
| test/episodes             | 1000.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -6.432206314473525e-23  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.621082550412003      |
| train_0/fw_bonus          | -0.9989962384104729     |
| train_0/fw_loss           | 0.005770823266357183    |
| train_0/mu_grads          | -0.021245513996109366   |
| train_0/mu_grads_std      | 0.4889573812484741      |
| train_0/mu_loss           | 9.542047027357686       |
| train_0/next_q            | -9.5381591537055        |
| train_0/q_grads           | -0.023324742168188094   |
| train_0/q_grads_std       | 0.2975953623652458      |
| train_0/q_loss            | 0.1344234600587162      |
| train_0/reward            | -0.7171128613787005     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.01083984375           |
| train_0/target_q          | -9.777753134392938      |
| train_1/avg_q             | -22.79837106192705      |
| train_1/current_q         | -1.5106702982841956e-09 |
| train_1/fw_bonus          | -0.9863447278738022     |
| train_1/fw_loss           | 0.08877839352935553     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 7.105891292342884e-17   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05398182114586234    |
| train_1/q_grads_std       | 0.35038262605667114     |
| train_1/q_loss            | 18.754835944006253      |
| train_1/reward            | -2.1111533213275835     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020751953125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1111533213275835     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 498.37. Rollout time: 252.26, Training time: 246.08
Evaluating epoch 40
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 40                      |
| policy/steps              | 3735809.0               |
| test/episodes             | 1025.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.735890830040844e-24  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.464789647053319      |
| train_0/fw_bonus          | -0.9989870265126228     |
| train_0/fw_loss           | 0.005818227725103498    |
| train_0/mu_grads          | -0.02128291530534625    |
| train_0/mu_grads_std      | 0.492292957752943       |
| train_0/mu_loss           | 9.379757330148044       |
| train_0/next_q            | -9.373892492762568      |
| train_0/q_grads           | -0.023906862549483775   |
| train_0/q_grads_std       | 0.3009283497929573      |
| train_0/q_loss            | 0.1426149408229911      |
| train_0/reward            | -0.7172791560537007     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00966796875           |
| train_0/target_q          | -9.61768703813649       |
| train_1/avg_q             | -6.995653095240097e-11  |
| train_1/current_q         | -2.0000904573435176e-09 |
| train_1/fw_bonus          | -0.9864863112568856     |
| train_1/fw_loss           | 0.08802595473825932     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 6.238199724606311e-17   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05398209355771542    |
| train_1/q_grads_std       | 0.35038259625434875     |
| train_1/q_loss            | 18.960040398873524      |
| train_1/reward            | -2.1250790961057646     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00224609375           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1250790961057646     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 497.59. Rollout time: 254.92, Training time: 242.64
Evaluating epoch 41
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 41                      |
| policy/steps              | 3826934.0               |
| test/episodes             | 1050.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.464081961481589e-21  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.452647898097325      |
| train_0/fw_bonus          | -0.9990063175559044     |
| train_0/fw_loss           | 0.005718924209941178    |
| train_0/mu_grads          | -0.022123744897544383   |
| train_0/mu_grads_std      | 0.4970112696290016      |
| train_0/mu_loss           | 9.360336135675068       |
| train_0/next_q            | -9.356174626427777      |
| train_0/q_grads           | -0.025127289118245244   |
| train_0/q_grads_std       | 0.30467253029346464     |
| train_0/q_loss            | 0.1435191262689742      |
| train_0/reward            | -0.7170324529601203     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0086669921875         |
| train_0/target_q          | -9.60565762444919       |
| train_1/avg_q             | -5.1824646900343286e-11 |
| train_1/current_q         | -2.580118690947464e-09  |
| train_1/fw_bonus          | -0.9874003693461418     |
| train_1/fw_loss           | 0.08316839616745711     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 2.4484506394308517e-16  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05398242175579071    |
| train_1/q_grads_std       | 0.350382536649704       |
| train_1/q_loss            | 18.23700691104337       |
| train_1/reward            | -2.0768422808658213     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016845703125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0768422808658213     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 497.87. Rollout time: 253.60, Training time: 244.24
Evaluating epoch 42
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3918059.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -1.424420721335564e-23 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.616574195717899     |
| train_0/fw_bonus          | -0.9990304112434387    |
| train_0/fw_loss           | 0.00559484523255378    |
| train_0/mu_grads          | -0.02171845072880387   |
| train_0/mu_grads_std      | 0.5030293181538582     |
| train_0/mu_loss           | 9.52793817090104       |
| train_0/next_q            | -9.523119041751844     |
| train_0/q_grads           | -0.025908496836200355  |
| train_0/q_grads_std       | 0.3079297348856926     |
| train_0/q_loss            | 0.13548934561046483    |
| train_0/reward            | -0.7192051481179078    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00869140625          |
| train_0/target_q          | -9.772369648979382     |
| train_1/avg_q             | -3.443373800066507e-11 |
| train_1/current_q         | -2.236934434997339e-09 |
| train_1/fw_bonus          | -0.9872359231114387    |
| train_1/fw_loss           | 0.08404245655983686    |
| train_1/mu_grads          | -0.0534789115190506    |
| train_1/mu_grads_std      | 0.2504447102546692     |
| train_1/mu_loss           | 4.2434304455861295e-16 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05398288182914257   |
| train_1/q_grads_std       | 0.35038241744041443    |
| train_1/q_loss            | 19.04278204693606      |
| train_1/reward            | -2.134352815504826     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017333984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.134352815504826     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 495.28. Rollout time: 254.89, Training time: 240.36
Evaluating epoch 43
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 43                      |
| policy/steps              | 4009184.0               |
| test/episodes             | 1100.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.6568928798551786e-23 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.47112941231352       |
| train_0/fw_bonus          | -0.998973836004734      |
| train_0/fw_loss           | 0.005886097950860858    |
| train_0/mu_grads          | -0.021020781621336936   |
| train_0/mu_grads_std      | 0.5071202084422112      |
| train_0/mu_loss           | 9.38224883826886        |
| train_0/next_q            | -9.37828968663774       |
| train_0/q_grads           | -0.025368585670366883   |
| train_0/q_grads_std       | 0.3113207548856735      |
| train_0/q_loss            | 0.14194962553479945     |
| train_0/reward            | -0.7179927791745285     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.01279296875           |
| train_0/target_q          | -9.625609342253068      |
| train_1/avg_q             | -5.058970394357644e-10  |
| train_1/current_q         | -2.134586115848165e-09  |
| train_1/fw_bonus          | -0.9867666214704514     |
| train_1/fw_loss           | 0.08653632905334234     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 1.440978767827287e-14   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05398358358070254    |
| train_1/q_grads_std       | 0.35038191080093384     |
| train_1/q_loss            | 18.398139237668865      |
| train_1/reward            | -2.0906123150940403     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021240234375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0906123150940403     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 490.58. Rollout time: 253.91, Training time: 236.63
Evaluating epoch 44
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 44                      |
| policy/steps              | 4100309.0               |
| test/episodes             | 1125.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.7507148946901038e-19 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.554939768579468      |
| train_0/fw_bonus          | -0.9989686802029609     |
| train_0/fw_loss           | 0.00591263931710273     |
| train_0/mu_grads          | -0.021194052416831255   |
| train_0/mu_grads_std      | 0.5096556589007377      |
| train_0/mu_loss           | 9.46734461795286        |
| train_0/next_q            | -9.461571218114264      |
| train_0/q_grads           | -0.025527443224564194   |
| train_0/q_grads_std       | 0.3156404845416546      |
| train_0/q_loss            | 0.14145438204905472     |
| train_0/reward            | -0.7197968420638062     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.014111328125          |
| train_0/target_q          | -9.708450457695879      |
| train_1/avg_q             | -1.3270067792623035e-08 |
| train_1/current_q         | -2.5136700667038596e-09 |
| train_1/fw_bonus          | -0.9873462155461311     |
| train_1/fw_loss           | 0.08345628306269645     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 5.514253554678353e-15   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05398604860529303    |
| train_1/q_grads_std       | 0.350380914658308       |
| train_1/q_loss            | 19.154703186792872      |
| train_1/reward            | -2.143355721340049      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001904296875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.143355721340049      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 489.82. Rollout time: 253.56, Training time: 236.24
Evaluating epoch 45
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 45                      |
| policy/steps              | 4191434.0               |
| test/episodes             | 1150.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.2904741198218764e-24 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.530421304664204      |
| train_0/fw_bonus          | -0.9989853054285049     |
| train_0/fw_loss           | 0.005827115464489907    |
| train_0/mu_grads          | -0.022612678399309517   |
| train_0/mu_grads_std      | 0.5124226868152618      |
| train_0/mu_loss           | 9.435930547672875       |
| train_0/next_q            | -9.430274149674299      |
| train_0/q_grads           | -0.025875234883278607   |
| train_0/q_grads_std       | 0.32011103108525274     |
| train_0/q_loss            | 0.14231334000084112     |
| train_0/reward            | -0.7217216520293732     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0108154296875         |
| train_0/target_q          | -9.684359845860381      |
| train_1/avg_q             | -1.1253331178785753e-09 |
| train_1/current_q         | -2.493230310799622e-09  |
| train_1/fw_bonus          | -0.9876558959484101     |
| train_1/fw_loss           | 0.08181052058935165     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 2.544521760132736e-14   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.053996968735009435   |
| train_1/q_grads_std       | 0.35037638172507285     |
| train_1/q_loss            | 18.70898880926837       |
| train_1/reward            | -2.111552557775576      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021728515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.111552557775576      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 495.12. Rollout time: 254.83, Training time: 240.26
Evaluating epoch 46
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 46                      |
| policy/steps              | 4282559.0               |
| test/episodes             | 1175.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.484840603862538e-20  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.624218730841946      |
| train_0/fw_bonus          | -0.9989656537771225     |
| train_0/fw_loss           | 0.005928203230723739    |
| train_0/mu_grads          | -0.021657591918483377   |
| train_0/mu_grads_std      | 0.5146606594324112      |
| train_0/mu_loss           | 9.538756394644794       |
| train_0/next_q            | -9.533582306648645      |
| train_0/q_grads           | -0.026123317470774055   |
| train_0/q_grads_std       | 0.32369420155882833     |
| train_0/q_loss            | 0.14385914392336474     |
| train_0/reward            | -0.7231522639951435     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0114501953125         |
| train_0/target_q          | -9.782278533531478      |
| train_1/avg_q             | -3.3692883580101397e-10 |
| train_1/current_q         | -4.54872118591178e-09   |
| train_1/fw_bonus          | -0.9872314691543579     |
| train_1/fw_loss           | 0.08406605795025826     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 1.2273458938413096e-14  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.054020352009683845   |
| train_1/q_grads_std       | 0.35037314891815186     |
| train_1/q_loss            | 18.557342282166257      |
| train_1/reward            | -2.0995117283047877     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016357421875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0995117283047877     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 497.93. Rollout time: 252.04, Training time: 245.86
Evaluating epoch 47
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 47                      |
| policy/steps              | 4373684.0               |
| test/episodes             | 1200.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -2.2195110110787904e-17 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.532944238232384      |
| train_0/fw_bonus          | -0.9989938691258431     |
| train_0/fw_loss           | 0.005783012951724231    |
| train_0/mu_grads          | -0.022877629846334457   |
| train_0/mu_grads_std      | 0.515794312953949       |
| train_0/mu_loss           | 9.44325575983039        |
| train_0/next_q            | -9.438244000450718      |
| train_0/q_grads           | -0.026787096820771693   |
| train_0/q_grads_std       | 0.3275821179151535      |
| train_0/q_loss            | 0.14348507741121724     |
| train_0/reward            | -0.7217503495354322     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0132080078125         |
| train_0/target_q          | -9.687208066454678      |
| train_1/avg_q             | -1.5421886635053663e-09 |
| train_1/current_q         | -3.6207681506828805e-09 |
| train_1/fw_bonus          | -0.9870260030031204     |
| train_1/fw_loss           | 0.08515788335353136     |
| train_1/mu_grads          | -0.0534789115190506     |
| train_1/mu_grads_std      | 0.2504447102546692      |
| train_1/mu_loss           | 1.7295187569828306e-14  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.0540864241309464     |
| train_1/q_grads_std       | 0.35036959424614905     |
| train_1/q_loss            | 18.55304818427546       |
| train_1/reward            | -2.102314275516983      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002392578125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.102314275516983      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 432.13. Rollout time: 234.76, Training time: 197.34
Evaluating epoch 48
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4464809.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -12.96794550036958    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.556643939522731    |
| train_0/fw_bonus          | -0.9990647584199905   |
| train_0/fw_loss           | 0.0054180794162675735 |
| train_0/mu_grads          | -0.023398442985489966 |
| train_0/mu_grads_std      | 0.5166193902492523    |
| train_0/mu_loss           | 9.468290509369515     |
| train_0/next_q            | -9.463462384754635    |
| train_0/q_grads           | -0.027540862420573832 |
| train_0/q_grads_std       | 0.3314175337553024    |
| train_0/q_loss            | 0.14222017131712197   |
| train_0/reward            | -0.7208092299639247   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.009716796875        |
| train_0/target_q          | -9.71114779671095     |
| train_1/avg_q             | -11.492148811076838   |
| train_1/current_q         | -22.51055620718251    |
| train_1/fw_bonus          | -0.9873480871319771   |
| train_1/fw_loss           | 0.08344634342938662   |
| train_1/mu_grads          | -0.05213511167094111  |
| train_1/mu_grads_std      | 0.2561370424926281    |
| train_1/mu_loss           | 15.068225588921024    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05557945109903813  |
| train_1/q_grads_std       | 0.35417519733309744   |
| train_1/q_loss            | 10.977690941297222    |
| train_1/reward            | -2.0785495273499692   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021728515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.426780484381233   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 410.87. Rollout time: 226.94, Training time: 183.90
Evaluating epoch 49
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 4555934.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999999999730036   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999993825   |
| train_0/current_q         | -9.558348181727215    |
| train_0/fw_bonus          | -0.999036829173565    |
| train_0/fw_loss           | 0.005561795504763723  |
| train_0/mu_grads          | -0.02408785494044423  |
| train_0/mu_grads_std      | 0.5174752861261368    |
| train_0/mu_loss           | 9.471554135004327     |
| train_0/next_q            | -9.467504085373228    |
| train_0/q_grads           | -0.028234600182622673 |
| train_0/q_grads_std       | 0.3353762783110142    |
| train_0/q_loss            | 0.1471234968526522    |
| train_0/reward            | -0.7193548422146705   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0116455078125       |
| train_0/target_q          | -9.709413164280116    |
| train_1/avg_q             | -21.24679953468559    |
| train_1/current_q         | -23.15922963302314    |
| train_1/fw_bonus          | -0.986379736661911    |
| train_1/fw_loss           | 0.0885923808440566    |
| train_1/mu_grads          | -0.05368042290210724  |
| train_1/mu_grads_std      | 0.25825417041778564   |
| train_1/mu_loss           | 26.99999446311142     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.057649220991879704 |
| train_1/q_grads_std       | 0.357248268276453     |
| train_1/q_loss            | 19.093085868951327    |
| train_1/reward            | -2.1163954325515077   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.382584885676522   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 404.69. Rollout time: 225.03, Training time: 179.64
Evaluating epoch 50
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 4647059.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.999999999741352   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.543523523684737    |
| train_0/fw_bonus          | -0.9990297466516495   |
| train_0/fw_loss           | 0.005598314094822854  |
| train_0/mu_grads          | -0.024388743005692957 |
| train_0/mu_grads_std      | 0.5179009422659874    |
| train_0/mu_loss           | 9.460971203362025     |
| train_0/next_q            | -9.45499014537504     |
| train_0/q_grads           | -0.029287312738597394 |
| train_0/q_grads_std       | 0.33792463317513466   |
| train_0/q_loss            | 0.14310979246447414   |
| train_0/reward            | -0.7197541276276752   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0117431640625       |
| train_0/target_q          | -9.69712936398395     |
| train_1/avg_q             | -26.999999994427657   |
| train_1/current_q         | -23.012419598989307   |
| train_1/fw_bonus          | -0.9863966926932335   |
| train_1/fw_loss           | 0.08850225154310465   |
| train_1/mu_grads          | -0.053680649120360614 |
| train_1/mu_grads_std      | 0.2582568868994713    |
| train_1/mu_loss           | 26.99996802672066     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.05720993084833026  |
| train_1/q_grads_std       | 0.36097020357847215   |
| train_1/q_loss            | 18.136196161814894    |
| train_1/reward            | -2.104831646385719    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002392578125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.246989849510733   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 405.08. Rollout time: 224.54, Training time: 180.51
Evaluating epoch 51
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 4738184.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.99999999221356    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.604931541885804    |
| train_0/fw_bonus          | -0.9990368828177452   |
| train_0/fw_loss           | 0.005561527819372714  |
| train_0/mu_grads          | -0.024456429295241833 |
| train_0/mu_grads_std      | 0.5191882610321045    |
| train_0/mu_loss           | 9.522780866931498     |
| train_0/next_q            | -9.517406652165018    |
| train_0/q_grads           | -0.029869458777830003 |
| train_0/q_grads_std       | 0.3411919787526131    |
| train_0/q_loss            | 0.13929096033036975   |
| train_0/reward            | -0.7199896340360283   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0100830078125       |
| train_0/target_q          | -9.76164383168637     |
| train_1/avg_q             | -26.999999935214664   |
| train_1/current_q         | -23.083304772542558   |
| train_1/fw_bonus          | -0.9862192168831825   |
| train_1/fw_loss           | 0.08944544084370136   |
| train_1/mu_grads          | -0.05375506682321429  |
| train_1/mu_grads_std      | 0.2581959955394268    |
| train_1/mu_loss           | 26.999915228327676    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0556746774353087   |
| train_1/q_grads_std       | 0.36673952713608743   |
| train_1/q_loss            | 18.048106799255052    |
| train_1/reward            | -2.1234806979002316   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020263671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.297938705712745   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 425.93. Rollout time: 226.94, Training time: 198.96
Evaluating epoch 52
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 52                      |
| policy/steps              | 4829309.0               |
| test/episodes             | 1325.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.875201627083884e-38  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.579050250890857      |
| train_0/fw_bonus          | -0.9990081652998924     |
| train_0/fw_loss           | 0.005709388421382755    |
| train_0/mu_grads          | -0.02495638527907431    |
| train_0/mu_grads_std      | 0.5218746364116669      |
| train_0/mu_loss           | 9.500018028708405       |
| train_0/next_q            | -9.495828067197838      |
| train_0/q_grads           | -0.030013555893674493   |
| train_0/q_grads_std       | 0.34498432353138925     |
| train_0/q_loss            | 0.13891570315315885     |
| train_0/reward            | -0.7184371875686338     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.010205078125          |
| train_0/target_q          | -9.734125139765283      |
| train_1/avg_q             | -18.089986318058322     |
| train_1/current_q         | -2.9143394363747436e-06 |
| train_1/fw_bonus          | -0.9852472931146622     |
| train_1/fw_loss           | 0.09461041036993265     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 3.052902709163011e-20   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05558988079428673    |
| train_1/q_grads_std       | 0.3708674222230911      |
| train_1/q_loss            | 18.83315763856272       |
| train_1/reward            | -2.1128384937190274     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0022705078125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1128384937190274     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 436.20. Rollout time: 227.33, Training time: 208.84
Evaluating epoch 53
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 4920434.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -4.677216814193337e-29 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.447188434508083     |
| train_0/fw_bonus          | -0.9990179762244225    |
| train_0/fw_loss           | 0.005658870562911034   |
| train_0/mu_grads          | -0.02631012354977429   |
| train_0/mu_grads_std      | 0.5234353229403496     |
| train_0/mu_loss           | 9.369754382251674      |
| train_0/next_q            | -9.365305866679059     |
| train_0/q_grads           | -0.030534037714824082  |
| train_0/q_grads_std       | 0.3486370950937271     |
| train_0/q_loss            | 0.13564946866624636    |
| train_0/reward            | -0.7142184611417178    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0093505859375        |
| train_0/target_q          | -9.599291875258837     |
| train_1/avg_q             | -9.713801854039012e-14 |
| train_1/current_q         | -1.999715717476532e-06 |
| train_1/fw_bonus          | -0.9853295221924782    |
| train_1/fw_loss           | 0.09417348895221948    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 2.6699253701969583e-20 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.055575776100158694  |
| train_1/q_grads_std       | 0.37086703032255175    |
| train_1/q_loss            | 18.402457373628454     |
| train_1/reward            | -2.085389367977041     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00205078125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.085389367977041     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 435.43. Rollout time: 226.52, Training time: 208.87
Evaluating epoch 54
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 54                      |
| policy/steps              | 5011559.0               |
| test/episodes             | 1375.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.3566430119930964e-31 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.464513389481732      |
| train_0/fw_bonus          | -0.9990785047411919     |
| train_0/fw_loss           | 0.005347253347281367    |
| train_0/mu_grads          | -0.02711716340854764    |
| train_0/mu_grads_std      | 0.5255974486470223      |
| train_0/mu_loss           | 9.391346825581971       |
| train_0/next_q            | -9.387591800332146      |
| train_0/q_grads           | -0.031151425652205945   |
| train_0/q_grads_std       | 0.35221830755472183     |
| train_0/q_loss            | 0.13082889029068256     |
| train_0/reward            | -0.7118927686686221     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0103271484375         |
| train_0/target_q          | -9.617505866574408      |
| train_1/avg_q             | -3.2249320784512253e-14 |
| train_1/current_q         | -9.009385674611132e-06  |
| train_1/fw_bonus          | -0.9861863061785698     |
| train_1/fw_loss           | 0.08962023463100195     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 4.4305015479952e-20     |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05542878275737166    |
| train_1/q_grads_std       | 0.3709075331687927      |
| train_1/q_loss            | 18.159345706589324      |
| train_1/reward            | -2.067617084630183      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0018310546875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.067617084630183      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 436.93. Rollout time: 232.19, Training time: 204.71
Evaluating epoch 55
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 55                      |
| policy/steps              | 5102684.0               |
| test/episodes             | 1400.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -6.928143898161251e-37  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.51641334156192       |
| train_0/fw_bonus          | -0.9991332098841668     |
| train_0/fw_loss           | 0.005065593589097262    |
| train_0/mu_grads          | -0.02865128335542977    |
| train_0/mu_grads_std      | 0.5271555006504058      |
| train_0/mu_loss           | 9.436094923972552       |
| train_0/next_q            | -9.433270448707784      |
| train_0/q_grads           | -0.03200829531997442    |
| train_0/q_grads_std       | 0.35576664879918096     |
| train_0/q_loss            | 0.12684582754677        |
| train_0/reward            | -0.7135802803561091     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0080810546875         |
| train_0/target_q          | -9.668950177071459      |
| train_1/avg_q             | -3.194917478621057e-14  |
| train_1/current_q         | -0.00011733324574469241 |
| train_1/fw_bonus          | -0.9864281475543976     |
| train_1/fw_loss           | 0.08833514619618654     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 1.254077732176648e-19   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05521409884095192    |
| train_1/q_grads_std       | 0.37122169584035875     |
| train_1/q_loss            | 18.318363090808003      |
| train_1/reward            | -2.07955440040314       |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016845703125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.07955440040314       |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 443.13. Rollout time: 230.98, Training time: 212.12
Evaluating epoch 56
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 5193809.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -5.321969862631261e-31 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.465710245138796     |
| train_0/fw_bonus          | -0.9991663515567779    |
| train_0/fw_loss           | 0.004894991347100586   |
| train_0/mu_grads          | -0.028127062739804386  |
| train_0/mu_grads_std      | 0.5300434395670891     |
| train_0/mu_loss           | 9.380595727688934      |
| train_0/next_q            | -9.376919384704893     |
| train_0/q_grads           | -0.03211585292592645   |
| train_0/q_grads_std       | 0.35899472534656524    |
| train_0/q_loss            | 0.1274889682968016     |
| train_0/reward            | -0.7123883534433844    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007568359375         |
| train_0/target_q          | -9.618207927973938     |
| train_1/avg_q             | -8.942202026451818e-14 |
| train_1/current_q         | -5.588454718246866e-05 |
| train_1/fw_bonus          | -0.9867093279957772    |
| train_1/fw_loss           | 0.08684082012623548    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 2.269164285394349e-19  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.054837450943887235  |
| train_1/q_grads_std       | 0.37206710800528525    |
| train_1/q_loss            | 18.812938305947817     |
| train_1/reward            | -2.1144484141652358    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1144484141652358    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 425.55. Rollout time: 227.17, Training time: 198.36
Evaluating epoch 57
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 57                      |
| policy/steps              | 5284934.0               |
| test/episodes             | 1450.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.2619102299666108e-40 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.343742338499144      |
| train_0/fw_bonus          | -0.9992044165730476     |
| train_0/fw_loss           | 0.004699041158892215    |
| train_0/mu_grads          | -0.02842291775159538    |
| train_0/mu_grads_std      | 0.5321985840797424      |
| train_0/mu_loss           | 9.262709792109693       |
| train_0/next_q            | -9.260009596828748      |
| train_0/q_grads           | -0.03213679958134889    |
| train_0/q_grads_std       | 0.36287503466010096     |
| train_0/q_loss            | 0.12303629874345527     |
| train_0/reward            | -0.7078297476451553     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0068115234375         |
| train_0/target_q          | -9.495779594020721      |
| train_1/avg_q             | -1.6880092634453786e-12 |
| train_1/current_q         | -7.206041571541374e-09  |
| train_1/fw_bonus          | -0.9864661678671837     |
| train_1/fw_loss           | 0.0881330244243145      |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 9.34984817162621e-26    |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05464545339345932    |
| train_1/q_grads_std       | 0.37255124002695084     |
| train_1/q_loss            | 18.346041597574956      |
| train_1/reward            | -2.0827472446973845     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0013427734375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0827472446973845     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 421.43. Rollout time: 225.01, Training time: 196.39
Evaluating epoch 58
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 5376059.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -3.775200600755141e-50 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.387529250304343     |
| train_0/fw_bonus          | -0.9991828307509423    |
| train_0/fw_loss           | 0.0048101611668244     |
| train_0/mu_grads          | -0.028415177902206778  |
| train_0/mu_grads_std      | 0.5334629237651825     |
| train_0/mu_loss           | 9.303437807770402      |
| train_0/next_q            | -9.301817111455705     |
| train_0/q_grads           | -0.03316171783953905   |
| train_0/q_grads_std       | 0.3650040879845619     |
| train_0/q_loss            | 0.12003045895435227    |
| train_0/reward            | -0.7087466896991828    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00732421875          |
| train_0/target_q          | -9.540331202282886     |
| train_1/avg_q             | -8.8008516815265e-16   |
| train_1/current_q         | -4.434850282454773e-09 |
| train_1/fw_bonus          | -0.9861822202801704    |
| train_1/fw_loss           | 0.08964198119938374    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 2.920973347084326e-25  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05464694555848837   |
| train_1/q_grads_std       | 0.37255086526274683    |
| train_1/q_loss            | 18.32154450919249      |
| train_1/reward            | -2.0780154288499033    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009765625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0780154288499033    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 417.59. Rollout time: 227.42, Training time: 190.14
Evaluating epoch 59
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 5467184.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -2.946225413715052e-36 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.464860558220881     |
| train_0/fw_bonus          | -0.9991395562887192    |
| train_0/fw_loss           | 0.005032981024123728   |
| train_0/mu_grads          | -0.027555110026150943  |
| train_0/mu_grads_std      | 0.5360955953598022     |
| train_0/mu_loss           | 9.375125374610226      |
| train_0/next_q            | -9.371341425340441     |
| train_0/q_grads           | -0.03354522502049804   |
| train_0/q_grads_std       | 0.36804370284080506    |
| train_0/q_loss            | 0.12028620383606461    |
| train_0/reward            | -0.7136566899585887    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.006591796875         |
| train_0/target_q          | -9.61791541522442      |
| train_1/avg_q             | -3.6685521587189e-14   |
| train_1/current_q         | -5.199525654912347e-08 |
| train_1/fw_bonus          | -0.98581862449646      |
| train_1/fw_loss           | 0.0915742726996541     |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 2.893520097626147e-24  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.054656552616506815  |
| train_1/q_grads_std       | 0.3725332699716091     |
| train_1/q_loss            | 17.800112381591294     |
| train_1/reward            | -2.0483048172987766    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0014404296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0483048172987766    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 415.04. Rollout time: 224.08, Training time: 190.93
Evaluating epoch 60
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 5558309.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -3.79303363191911e-41  |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.595065296574472     |
| train_0/fw_bonus          | -0.9991033136844635    |
| train_0/fw_loss           | 0.005219507054425776   |
| train_0/mu_grads          | -0.028624093206599355  |
| train_0/mu_grads_std      | 0.5401328429579735     |
| train_0/mu_loss           | 9.501897879714209      |
| train_0/next_q            | -9.498502034862861     |
| train_0/q_grads           | -0.03384565841406584   |
| train_0/q_grads_std       | 0.37076822891831396    |
| train_0/q_loss            | 0.12806224503153812    |
| train_0/reward            | -0.7161776366447157    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0079345703125        |
| train_0/target_q          | -9.747171510612315     |
| train_1/avg_q             | -2.153744669106388e-18 |
| train_1/current_q         | -7.815922095912049e-10 |
| train_1/fw_bonus          | -0.9847610414028167    |
| train_1/fw_loss           | 0.09719450976699591    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 3.002174862013801e-27  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05479074101895094   |
| train_1/q_grads_std       | 0.37273168861865996    |
| train_1/q_loss            | 18.788289341675636     |
| train_1/reward            | -2.1128272966896473    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001318359375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1128272966896473    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_60.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 415.86. Rollout time: 226.12, Training time: 189.71
Evaluating epoch 61
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 61                      |
| policy/steps              | 5649434.0               |
| test/episodes             | 1550.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.7646355600339931e-41 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.607585683324725      |
| train_0/fw_bonus          | -0.9990753993391991     |
| train_0/fw_loss           | 0.005363194190431386    |
| train_0/mu_grads          | -0.029340200033038853   |
| train_0/mu_grads_std      | 0.5447085276246071      |
| train_0/mu_loss           | 9.515080746549495       |
| train_0/next_q            | -9.510344838631333      |
| train_0/q_grads           | -0.03475745432078838    |
| train_0/q_grads_std       | 0.37350860312581063     |
| train_0/q_loss            | 0.12874325740065473     |
| train_0/reward            | -0.7203995214389579     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00869140625           |
| train_0/target_q          | -9.761468731248154      |
| train_1/avg_q             | -3.1029834898464017e-19 |
| train_1/current_q         | -9.51328592110492e-09   |
| train_1/fw_bonus          | -0.9839235648512841     |
| train_1/fw_loss           | 0.10164504926651716     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 3.2390502768765726e-27  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.054810362868011      |
| train_1/q_grads_std       | 0.37274077013134954     |
| train_1/q_loss            | 18.917744263728984      |
| train_1/reward            | -2.119183462239016      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001611328125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.119183462239016      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 421.13. Rollout time: 226.24, Training time: 194.86
Evaluating epoch 62
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 62                      |
| policy/steps              | 5740446.0               |
| test/episodes             | 1575.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -5.061118793993869e-41  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6300.0                  |
| train/success_rate        | 0.01                    |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.470820571375874      |
| train_0/fw_bonus          | -0.9990436509251595     |
| train_0/fw_loss           | 0.005526691244449466    |
| train_0/mu_grads          | -0.030321370204910637   |
| train_0/mu_grads_std      | 0.5486521482467651      |
| train_0/mu_loss           | 9.375295830258555       |
| train_0/next_q            | -9.368866125343416      |
| train_0/q_grads           | -0.03596760146319866    |
| train_0/q_grads_std       | 0.3766546115279198      |
| train_0/q_loss            | 0.12881717348577965     |
| train_0/reward            | -0.7192239743308164     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0072265625            |
| train_0/target_q          | -9.621832818982123      |
| train_1/avg_q             | -2.0155041249570416e-15 |
| train_1/current_q         | -2.991289731994709e-09  |
| train_1/fw_bonus          | -0.9840539187192917     |
| train_1/fw_loss           | 0.10095237269997596     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 8.77076230587234e-27    |
| train_1/n_subgoals        | 2696.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05543420016765595    |
| train_1/q_grads_std       | 0.3726930692791939      |
| train_1/q_loss            | 18.42570541254827       |
| train_1/reward            | -2.0848492211211123     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0010498046875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0848492211211123     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 421.62. Rollout time: 223.85, Training time: 197.74
Evaluating epoch 63
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 63                      |
| policy/steps              | 5831571.0               |
| test/episodes             | 1600.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.0664625085448253e-40 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.555669022645974      |
| train_0/fw_bonus          | -0.9990652501583099     |
| train_0/fw_loss           | 0.0054154607118107375   |
| train_0/mu_grads          | -0.031477052718400955   |
| train_0/mu_grads_std      | 0.5514848873019218      |
| train_0/mu_loss           | 9.449785307817123       |
| train_0/next_q            | -9.444929103614475      |
| train_0/q_grads           | -0.03700925251469016    |
| train_0/q_grads_std       | 0.37952466160058973     |
| train_0/q_loss            | 0.1281999311082195      |
| train_0/reward            | -0.7230677850879147     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0077392578125         |
| train_0/target_q          | -9.709577465679555      |
| train_1/avg_q             | -4.9592224852016026e-15 |
| train_1/current_q         | -1.3094088739674202e-08 |
| train_1/fw_bonus          | -0.983735266327858      |
| train_1/fw_loss           | 0.10264570508152246     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 1.984053981643937e-25   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05551150692626834    |
| train_1/q_grads_std       | 0.3727248527109623      |
| train_1/q_loss            | 18.262921559681214      |
| train_1/reward            | -2.076206014543277      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0013427734375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.076206014543277      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 436.66. Rollout time: 233.47, Training time: 203.16
Evaluating epoch 64
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 64                      |
| policy/steps              | 5922696.0               |
| test/episodes             | 1625.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.720199349772792e-38  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.545825264918696      |
| train_0/fw_bonus          | -0.9990667581558228     |
| train_0/fw_loss           | 0.005407722224481404    |
| train_0/mu_grads          | -0.033065341785550116   |
| train_0/mu_grads_std      | 0.5547773897647857      |
| train_0/mu_loss           | 9.446465520314783       |
| train_0/next_q            | -9.443327953302184      |
| train_0/q_grads           | -0.03849504804238677    |
| train_0/q_grads_std       | 0.3827623039484024      |
| train_0/q_loss            | 0.13044049402989152     |
| train_0/reward            | -0.7213473454437918     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.007421875             |
| train_0/target_q          | -9.699884746432755      |
| train_1/avg_q             | -2.0377654709209943e-15 |
| train_1/current_q         | -1.1225185961578541e-10 |
| train_1/fw_bonus          | -0.9839537978172302     |
| train_1/fw_loss           | 0.10148443039506674     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 6.1481939662087e-20     |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05560373859480024    |
| train_1/q_grads_std       | 0.372577628493309       |
| train_1/q_loss            | 18.480618340847947      |
| train_1/reward            | -2.0900359786726765     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0012939453125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0900359786726765     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 431.17. Rollout time: 231.05, Training time: 200.09
Evaluating epoch 65
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 65                      |
| policy/steps              | 6013821.0               |
| test/episodes             | 1650.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.978958889400859e-21  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.38260754671092       |
| train_0/fw_bonus          | -0.9989999607205391     |
| train_0/fw_loss           | 0.005751573946326971    |
| train_0/mu_grads          | -0.03261185511946678    |
| train_0/mu_grads_std      | 0.5576602861285209      |
| train_0/mu_loss           | 9.289089536246763       |
| train_0/next_q            | -9.28577302104431       |
| train_0/q_grads           | -0.0394752811640501     |
| train_0/q_grads_std       | 0.38650252521038053     |
| train_0/q_loss            | 0.13872074725841363     |
| train_0/reward            | -0.7176274264718814     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.010986328125          |
| train_0/target_q          | -9.534008576419746      |
| train_1/avg_q             | -1.9222671989388568e-19 |
| train_1/current_q         | -6.036172604271058e-11  |
| train_1/fw_bonus          | -0.9838602244853973     |
| train_1/fw_loss           | 0.10198168624192476     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 7.888235502779556e-20   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05561683494597673    |
| train_1/q_grads_std       | 0.3725837737321854      |
| train_1/q_loss            | 18.664779866265498      |
| train_1/reward            | -2.102257259681937      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002099609375          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.102257259681937      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 429.65. Rollout time: 229.16, Training time: 200.46
Evaluating epoch 66
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 6104946.0              |
| test/episodes             | 1675.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -1.298454107218232e-22 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.453738985423303     |
| train_0/fw_bonus          | -0.9989996090531349    |
| train_0/fw_loss           | 0.005753464961890132   |
| train_0/mu_grads          | -0.03318495387211442   |
| train_0/mu_grads_std      | 0.5612181469798088     |
| train_0/mu_loss           | 9.359942097987783      |
| train_0/next_q            | -9.355817644377728     |
| train_0/q_grads           | -0.03956657443195581   |
| train_0/q_grads_std       | 0.38974451199173926    |
| train_0/q_loss            | 0.13745268525801427    |
| train_0/reward            | -0.7185427701937442    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.010546875            |
| train_0/target_q          | -9.607790482526832     |
| train_1/avg_q             | -7.16060024026682e-20  |
| train_1/current_q         | -1.965834456790517e-10 |
| train_1/fw_bonus          | -0.9836842238903045    |
| train_1/fw_loss           | 0.10291691776365042    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 8.563660273368145e-20  |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05564136821776629   |
| train_1/q_grads_std       | 0.37257831543684006    |
| train_1/q_loss            | 18.997758774914388     |
| train_1/reward            | -2.1247156522716977    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00205078125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1247156522716977    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 430.68. Rollout time: 231.46, Training time: 199.20
Evaluating epoch 67
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 6196071.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -1.957183729255823e-47 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.448810232172052     |
| train_0/fw_bonus          | -0.9989884421229362    |
| train_0/fw_loss           | 0.005810883734375239   |
| train_0/mu_grads          | -0.03362591611221433   |
| train_0/mu_grads_std      | 0.564649011194706      |
| train_0/mu_loss           | 9.35425520292606       |
| train_0/next_q            | -9.348903389728296     |
| train_0/q_grads           | -0.0398439534008503    |
| train_0/q_grads_std       | 0.39238244444131853    |
| train_0/q_loss            | 0.1472853154110402     |
| train_0/reward            | -0.7194649277764256    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0089111328125        |
| train_0/target_q          | -9.600210613070411     |
| train_1/avg_q             | -6.273476681930737e-17 |
| train_1/current_q         | -5.336031392520392e-13 |
| train_1/fw_bonus          | -0.982689592242241     |
| train_1/fw_loss           | 0.10820271391421557    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 3.80465533466307e-27   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05658205971121788   |
| train_1/q_grads_std       | 0.37257876992225647    |
| train_1/q_loss            | 18.966859024414653     |
| train_1/reward            | -2.1219600293923575    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017578125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1219600293923575    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 421.71. Rollout time: 227.93, Training time: 193.76
Evaluating epoch 68
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 68                      |
| policy/steps              | 6287196.0               |
| test/episodes             | 1725.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -2.8760403572324917e-37 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.577838983904808      |
| train_0/fw_bonus          | -0.9989938840270043     |
| train_0/fw_loss           | 0.005782897945027799    |
| train_0/mu_grads          | -0.03395622493699193    |
| train_0/mu_grads_std      | 0.5670048326253891      |
| train_0/mu_loss           | 9.482355762900713       |
| train_0/next_q            | -9.477402297453247      |
| train_0/q_grads           | -0.039987508207559586   |
| train_0/q_grads_std       | 0.3952678248286247      |
| train_0/q_loss            | 0.1418944248892029      |
| train_0/reward            | -0.7197117864721804     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0107421875            |
| train_0/target_q          | -9.732158140693244      |
| train_1/avg_q             | -3.4303531710717367e-20 |
| train_1/current_q         | -3.5344790413817046e-13 |
| train_1/fw_bonus          | -0.9819009840488434     |
| train_1/fw_loss           | 0.11239358019083738     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 1.6880397481042877e-26  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.056582119315862656   |
| train_1/q_grads_std       | 0.3725787401199341      |
| train_1/q_loss            | 18.59852203512736       |
| train_1/reward            | -2.099727345831343      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001904296875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.099727345831343      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 422.32. Rollout time: 228.99, Training time: 193.30
Evaluating epoch 69
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 69                      |
| policy/steps              | 6378321.0               |
| test/episodes             | 1750.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.0707846061568281e-34 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.506798807235423      |
| train_0/fw_bonus          | -0.9989769235253334     |
| train_0/fw_loss           | 0.005870242812670767    |
| train_0/mu_grads          | -0.034077599085867404   |
| train_0/mu_grads_std      | 0.5689593598246574      |
| train_0/mu_loss           | 9.41359637121179        |
| train_0/next_q            | -9.407398874276717      |
| train_0/q_grads           | -0.0405623878352344     |
| train_0/q_grads_std       | 0.3983496464788914      |
| train_0/q_loss            | 0.1447629797377783      |
| train_0/reward            | -0.7214367018161283     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0101318359375         |
| train_0/target_q          | -9.657957162236325      |
| train_1/avg_q             | -9.579721768514265e-21  |
| train_1/current_q         | -2.2153278312178392e-13 |
| train_1/fw_bonus          | -0.9826051846146584     |
| train_1/fw_loss           | 0.10865124277770519     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 3.5471548152153134e-27  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05658221356570721    |
| train_1/q_grads_std       | 0.3725787103176117      |
| train_1/q_loss            | 18.876583506064605      |
| train_1/reward            | -2.11675425480571       |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020751953125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.11675425480571       |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 418.24. Rollout time: 229.70, Training time: 188.50
Evaluating epoch 70
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 70                      |
| policy/steps              | 6469446.0               |
| test/episodes             | 1775.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -3.2051917171530415e-42 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.543760719784414      |
| train_0/fw_bonus          | -0.9990535527467728     |
| train_0/fw_loss           | 0.005475692870095372    |
| train_0/mu_grads          | -0.0341823267750442     |
| train_0/mu_grads_std      | 0.571898652613163       |
| train_0/mu_loss           | 9.445455937126928       |
| train_0/next_q            | -9.4388790676094        |
| train_0/q_grads           | -0.040182387735694644   |
| train_0/q_grads_std       | 0.40177463069558145     |
| train_0/q_loss            | 0.1383493659003598      |
| train_0/reward            | -0.7221342006319901     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.008349609375          |
| train_0/target_q          | -9.698103800118218      |
| train_1/avg_q             | -5.016254213975018e-24  |
| train_1/current_q         | -1.0800426500936077e-12 |
| train_1/fw_bonus          | -0.982545118033886      |
| train_1/fw_loss           | 0.10897038411349058     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 2.940580466132763e-27   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05658237263560295    |
| train_1/q_grads_std       | 0.3725786507129669      |
| train_1/q_loss            | 18.28572732547129       |
| train_1/reward            | -2.0793096762768983     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016845703125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0793096762768983     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_70.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 415.76. Rollout time: 229.16, Training time: 186.57
Evaluating epoch 71
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 6560571.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -3.516735391184963e-42 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.52137970016874      |
| train_0/fw_bonus          | -0.9990777492523193    |
| train_0/fw_loss           | 0.005351128871552646   |
| train_0/mu_grads          | -0.03440840123221278   |
| train_0/mu_grads_std      | 0.5756963536143302     |
| train_0/mu_loss           | 9.41770897405605       |
| train_0/next_q            | -9.411451884863467     |
| train_0/q_grads           | -0.04048010800033808   |
| train_0/q_grads_std       | 0.4048975229263306     |
| train_0/q_loss            | 0.13828950399401507    |
| train_0/reward            | -0.7223538185236975    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007470703125         |
| train_0/target_q          | -9.673983230623012     |
| train_1/avg_q             | -9.6180565663538e-17   |
| train_1/current_q         | -2.313255295317333e-13 |
| train_1/fw_bonus          | -0.9833030506968499    |
| train_1/fw_loss           | 0.10494260247796774    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 2.9198132324005496e-27 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05658254697918892   |
| train_1/q_grads_std       | 0.37257859110832214    |
| train_1/q_loss            | 18.76707091782108      |
| train_1/reward            | -2.1110607075890586    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0014892578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1110607075890586    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 409.21. Rollout time: 226.85, Training time: 182.33
Evaluating epoch 72
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 72                     |
| policy/steps              | 6651696.0              |
| test/episodes             | 1825.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -4.998561257887325e-35 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.516773454916052     |
| train_0/fw_bonus          | -0.9991057619452477    |
| train_0/fw_loss           | 0.005206914606969803   |
| train_0/mu_grads          | -0.03521090317517519   |
| train_0/mu_grads_std      | 0.5787120670080185     |
| train_0/mu_loss           | 9.415093363181436      |
| train_0/next_q            | -9.408715027796594     |
| train_0/q_grads           | -0.04044286897405982   |
| train_0/q_grads_std       | 0.4074482500553131     |
| train_0/q_loss            | 0.13544644610297896    |
| train_0/reward            | -0.7221236838580808    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0068359375           |
| train_0/target_q          | -9.670002842700672     |
| train_1/avg_q             | -1.476863368539554e-18 |
| train_1/current_q         | -1.145149707489855e-13 |
| train_1/fw_bonus          | -0.9827439457178115    |
| train_1/fw_loss           | 0.10791386626660823    |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 1.5874139810763858e-27 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05658266320824623   |
| train_1/q_grads_std       | 0.372578501701355      |
| train_1/q_loss            | 18.852889907453637     |
| train_1/reward            | -2.1130638659415126    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001220703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.1130638659415126    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 407.76. Rollout time: 226.36, Training time: 181.36
Evaluating epoch 73
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 73                     |
| policy/steps              | 6742821.0              |
| test/episodes             | 1850.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -2.897065735680311e-44 |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.555719144668206     |
| train_0/fw_bonus          | -0.9991252735257149    |
| train_0/fw_loss           | 0.005106530676130205   |
| train_0/mu_grads          | -0.03677909011021256   |
| train_0/mu_grads_std      | 0.5820537313818932     |
| train_0/mu_loss           | 9.440981108763765      |
| train_0/next_q            | -9.433521932624592     |
| train_0/q_grads           | -0.0401955122128129    |
| train_0/q_grads_std       | 0.41076876446604726    |
| train_0/q_loss            | 0.13388028220596068    |
| train_0/reward            | -0.7225240584768471    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00693359375          |
| train_0/target_q          | -9.70951434953927      |
| train_1/avg_q             | -8.756122046544802e-22 |
| train_1/current_q         | -9.022891487372036e-14 |
| train_1/fw_bonus          | -0.9834686860442161    |
| train_1/fw_loss           | 0.1040624376386404     |
| train_1/mu_grads          | -0.0536678321659565    |
| train_1/mu_grads_std      | 0.25884443521499634    |
| train_1/mu_loss           | 1.2040437674518752e-27 |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | 0.0                    |
| train_1/q_grads           | -0.05658272551372647   |
| train_1/q_grads_std       | 0.3725784718990326     |
| train_1/q_loss            | 18.230724475802024     |
| train_1/reward            | -2.071507289568399     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013427734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.071507289568399     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 414.29. Rollout time: 230.46, Training time: 183.80
Evaluating epoch 74
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 74                      |
| policy/steps              | 6833946.0               |
| test/episodes             | 1875.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.1030425212725007e-31 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.52855703831968       |
| train_0/fw_bonus          | -0.999105603992939      |
| train_0/fw_loss           | 0.005207756569143384    |
| train_0/mu_grads          | -0.03645039694383741    |
| train_0/mu_grads_std      | 0.5856757536530495      |
| train_0/mu_loss           | 9.417447642776912       |
| train_0/next_q            | -9.413057896994133      |
| train_0/q_grads           | -0.040099082980304956   |
| train_0/q_grads_std       | 0.41247599497437476     |
| train_0/q_loss            | 0.13625138772916437     |
| train_0/reward            | -0.7210860044149741     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0080322265625         |
| train_0/target_q          | -9.682982383057896      |
| train_1/avg_q             | -1.8345587376097576e-22 |
| train_1/current_q         | -9.50907168855508e-13   |
| train_1/fw_bonus          | -0.9827469661831856     |
| train_1/fw_loss           | 0.10789784751832485     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 5.983977852526989e-28   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05658450499176979    |
| train_1/q_grads_std       | 0.3725779950618744      |
| train_1/q_loss            | 18.702221689489214      |
| train_1/reward            | -2.1033119548468675     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001171875             |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1033119548468675     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 411.19. Rollout time: 225.75, Training time: 185.41
Evaluating epoch 75
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 75                      |
| policy/steps              | 6925071.0               |
| test/episodes             | 1900.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.4295282929584596e-38 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.584577243720798      |
| train_0/fw_bonus          | -0.9990596935153008     |
| train_0/fw_loss           | 0.005444059055298567    |
| train_0/mu_grads          | -0.03764990670606494    |
| train_0/mu_grads_std      | 0.5884975388646125      |
| train_0/mu_loss           | 9.492838072517362       |
| train_0/next_q            | -9.488751833810213      |
| train_0/q_grads           | -0.040874931309372184   |
| train_0/q_grads_std       | 0.41524681746959685     |
| train_0/q_loss            | 0.13839011345704377     |
| train_0/reward            | -0.7190977221755019     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00830078125           |
| train_0/target_q          | -9.73993993237097       |
| train_1/avg_q             | -2.1329194240609843e-20 |
| train_1/current_q         | -8.060414252275631e-13  |
| train_1/fw_bonus          | -0.9815535455942154     |
| train_1/fw_loss           | 0.11423992775380612     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 2.2957768852781534e-27  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.056586893554776904   |
| train_1/q_grads_std       | 0.37257692217826843     |
| train_1/q_loss            | 18.57398920756334       |
| train_1/reward            | -2.0900321446868473     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0017333984375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0900321446868473     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 411.70. Rollout time: 228.41, Training time: 183.26
Evaluating epoch 76
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 76                      |
| policy/steps              | 7016196.0               |
| test/episodes             | 1925.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.816382687378552e-39  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.56511559666239       |
| train_0/fw_bonus          | -0.9990196451544762     |
| train_0/fw_loss           | 0.005650309135671705    |
| train_0/mu_grads          | -0.03760890746489167    |
| train_0/mu_grads_std      | 0.5918822735548019      |
| train_0/mu_loss           | 9.474077682422458       |
| train_0/next_q            | -9.469136044884937      |
| train_0/q_grads           | -0.04223833428695798    |
| train_0/q_grads_std       | 0.4183880686759949      |
| train_0/q_loss            | 0.13705517408210177     |
| train_0/reward            | -0.7196514214629133     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0097900390625         |
| train_0/target_q          | -9.719895005467412      |
| train_1/avg_q             | -2.992146475654e-23     |
| train_1/current_q         | -1.0309082657186578e-12 |
| train_1/fw_bonus          | -0.980539046227932      |
| train_1/fw_loss           | 0.11963120214641094     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 1.318264520728519e-26   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05658998461440205    |
| train_1/q_grads_std       | 0.37257458865642545     |
| train_1/q_loss            | 17.89371122450883       |
| train_1/reward            | -2.0454697229986776     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0023193359375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0454697229986776     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 410.43. Rollout time: 226.30, Training time: 184.10
Evaluating epoch 77
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 77                      |
| policy/steps              | 7107321.0               |
| test/episodes             | 1950.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -6.649993138209763e-42  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.695125223034353      |
| train_0/fw_bonus          | -0.9989940851926804     |
| train_0/fw_loss           | 0.00578181796008721     |
| train_0/mu_grads          | -0.03846678109839559    |
| train_0/mu_grads_std      | 0.5950202897191048      |
| train_0/mu_loss           | 9.612126201953107       |
| train_0/next_q            | -9.606320876541691      |
| train_0/q_grads           | -0.042586861085146664   |
| train_0/q_grads_std       | 0.4212402395904064      |
| train_0/q_loss            | 0.1410412549778352      |
| train_0/reward            | -0.7218725358536175     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00966796875           |
| train_0/target_q          | -9.851376715698123      |
| train_1/avg_q             | -6.211885907584598e-20  |
| train_1/current_q         | -1.8108478599104926e-12 |
| train_1/fw_bonus          | -0.9791429549455642     |
| train_1/fw_loss           | 0.12705043870955707     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 1.354408014731807e-26   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05659678718075156    |
| train_1/q_grads_std       | 0.3725685402750969      |
| train_1/q_loss            | 18.31971487961369       |
| train_1/reward            | -2.076326846158918      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0021240234375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.076326846158918      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 412.47. Rollout time: 225.24, Training time: 187.20
Evaluating epoch 78
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 78                      |
| policy/steps              | 7198446.0               |
| test/episodes             | 1975.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -4.014345575829568e-44  |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.607034099156955      |
| train_0/fw_bonus          | -0.9990001082420349     |
| train_0/fw_loss           | 0.005750843684654683    |
| train_0/mu_grads          | -0.03922102963551879    |
| train_0/mu_grads_std      | 0.5964417889714241      |
| train_0/mu_loss           | 9.525905806100008       |
| train_0/next_q            | -9.521315564944956      |
| train_0/q_grads           | -0.04316366231068969    |
| train_0/q_grads_std       | 0.4233100175857544      |
| train_0/q_loss            | 0.13710171120802755     |
| train_0/reward            | -0.7192266184378241     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0090576171875         |
| train_0/target_q          | -9.763599161933604      |
| train_1/avg_q             | -3.2443962298647514e-24 |
| train_1/current_q         | -4.54508607267694e-12   |
| train_1/fw_bonus          | -0.9782466620206833     |
| train_1/fw_loss           | 0.13181354589760302     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 3.554921840720094e-25   |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05661596963182092    |
| train_1/q_grads_std       | 0.3725520968437195      |
| train_1/q_loss            | 18.41889516771415       |
| train_1/reward            | -2.083239540748764      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0022705078125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.083239540748764      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 435.13. Rollout time: 235.24, Training time: 199.86
Evaluating epoch 79
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 79                      |
| policy/steps              | 7289571.0               |
| test/episodes             | 2000.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.7457432183993e-33    |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 8000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.515436974550108      |
| train_0/fw_bonus          | -0.9990301370620728     |
| train_0/fw_loss           | 0.0055962669779546555   |
| train_0/mu_grads          | -0.04037804733961821    |
| train_0/mu_grads_std      | 0.5985505074262619      |
| train_0/mu_loss           | 9.430088024483535       |
| train_0/next_q            | -9.425160291333357      |
| train_0/q_grads           | -0.04343266077339649    |
| train_0/q_grads_std       | 0.4258702002465725      |
| train_0/q_loss            | 0.13951338403491848     |
| train_0/reward            | -0.7167880177039478     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00732421875           |
| train_0/target_q          | -9.668771273238747      |
| train_1/avg_q             | -1.5130184108691789e-21 |
| train_1/current_q         | -3.952207528115455e-12  |
| train_1/fw_bonus          | -0.9782348290085793     |
| train_1/fw_loss           | 0.13187642227858304     |
| train_1/mu_grads          | -0.0536678321659565     |
| train_1/mu_grads_std      | 0.25884443521499634     |
| train_1/mu_loss           | 2.8276950873002025e-24  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.05663772793486714    |
| train_1/q_grads_std       | 0.3725328579545021      |
| train_1/q_loss            | 18.238933960806236      |
| train_1/reward            | -2.0719299145479453     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0019775390625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0719299145479453     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 443.72. Rollout time: 246.17, Training time: 197.52
Evaluating epoch 80
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 7380696.0              |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -1.667379138839669     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.500753347482512     |
| train_0/fw_bonus          | -0.9990979388356209    |
| train_0/fw_loss           | 0.005247221258468926   |
| train_0/mu_grads          | -0.041711616609245536  |
| train_0/mu_grads_std      | 0.6000191047787666     |
| train_0/mu_loss           | 9.41459890744691       |
| train_0/next_q            | -9.41210781981346      |
| train_0/q_grads           | -0.044223228748887775  |
| train_0/q_grads_std       | 0.42836722210049627    |
| train_0/q_loss            | 0.13548240626875496    |
| train_0/reward            | -0.7156012146173453    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007861328125         |
| train_0/target_q          | -9.65172919366923      |
| train_1/avg_q             | -4.441489860077444     |
| train_1/current_q         | -2.070898551935202     |
| train_1/fw_bonus          | -0.9787028431892395    |
| train_1/fw_loss           | 0.12938932627439498    |
| train_1/mu_grads          | -0.05677691930904984   |
| train_1/mu_grads_std      | 0.25827771574258807    |
| train_1/mu_loss           | 0.8817166253536979     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.698738619149215e-06 |
| train_1/q_grads           | -0.06001879945397377   |
| train_1/q_grads_std       | 0.3657797545194626     |
| train_1/q_loss            | 0.22539542986855202    |
| train_1/reward            | -2.0758382337822696    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021728515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0758457537647756    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_80.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 443.63. Rollout time: 257.88, Training time: 185.71
Evaluating epoch 81
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 7471821.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -0.9960876485096899   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.411183231614766    |
| train_0/fw_bonus          | -0.9990921601653099   |
| train_0/fw_loss           | 0.005276940483599901  |
| train_0/mu_grads          | -0.04146835003048181  |
| train_0/mu_grads_std      | 0.6006835788488388    |
| train_0/mu_loss           | 9.322016464943164     |
| train_0/next_q            | -9.319407373356615    |
| train_0/q_grads           | -0.04546273732557893  |
| train_0/q_grads_std       | 0.4308255225419998    |
| train_0/q_loss            | 0.135781350117759     |
| train_0/reward            | -0.7178078007680597   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0074951171875       |
| train_0/target_q          | -9.563432217819914    |
| train_1/avg_q             | -8.76980884473147     |
| train_1/current_q         | -2.053784881645982    |
| train_1/fw_bonus          | -0.9792948260903358   |
| train_1/fw_loss           | 0.12624333892017603   |
| train_1/mu_grads          | -0.05881890468299389  |
| train_1/mu_grads_std      | 0.2566413529217243    |
| train_1/mu_loss           | 0.8790562821030032    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.70526695945463e-09 |
| train_1/q_grads           | -0.06158124031499028  |
| train_1/q_grads_std       | 0.3675240077078342    |
| train_1/q_loss            | 0.47010459707557717   |
| train_1/reward            | -2.0560658707669064   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -2.05606587595772     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 419.68. Rollout time: 233.37, Training time: 186.28
Evaluating epoch 82
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 82                     |
| policy/steps              | 7562946.0              |
| test/episodes             | 2075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -0.9892854583210202    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.585515322036226     |
| train_0/fw_bonus          | -0.9990871712565422    |
| train_0/fw_loss           | 0.005302631377708167   |
| train_0/mu_grads          | -0.04200203809887171   |
| train_0/mu_grads_std      | 0.6014928221702576     |
| train_0/mu_loss           | 9.495027585915365      |
| train_0/next_q            | -9.491283614719743     |
| train_0/q_grads           | -0.04563777549192309   |
| train_0/q_grads_std       | 0.4330058999359608     |
| train_0/q_loss            | 0.13959060186702715    |
| train_0/reward            | -0.7203321610875719    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0084228515625        |
| train_0/target_q          | -9.740458765593639     |
| train_1/avg_q             | -10.603957863939302    |
| train_1/current_q         | -2.0489438623996334    |
| train_1/fw_bonus          | -0.9782865136861801    |
| train_1/fw_loss           | 0.13160171024501324    |
| train_1/mu_grads          | -0.057296198327094316  |
| train_1/mu_grads_std      | 0.25607254803180696    |
| train_1/mu_loss           | 0.8374458946137203     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.114083134125199e-08 |
| train_1/q_grads           | -0.062405246682465075  |
| train_1/q_grads_std       | 0.3710488438606262     |
| train_1/q_loss            | 0.4274405669097103     |
| train_1/reward            | -2.0569044910778755    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020751953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0569045429704893    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 449.86. Rollout time: 251.91, Training time: 197.92
Evaluating epoch 83
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 83                      |
| policy/steps              | 7654071.0               |
| test/episodes             | 2100.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.0030003917645434     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 8400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.525581619802413      |
| train_0/fw_bonus          | -0.9990679919719696     |
| train_0/fw_loss           | 0.005401409743353724    |
| train_0/mu_grads          | -0.04239734411239624    |
| train_0/mu_grads_std      | 0.6031569421291352      |
| train_0/mu_loss           | 9.432826984380997       |
| train_0/next_q            | -9.427897836999422      |
| train_0/q_grads           | -0.045822712033987044   |
| train_0/q_grads_std       | 0.4350598596036434      |
| train_0/q_loss            | 0.13679844317249593     |
| train_0/reward            | -0.7178811615791346     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0092041015625         |
| train_0/target_q          | -9.67918673136349       |
| train_1/avg_q             | -11.221134984004344     |
| train_1/current_q         | -2.06071956885101       |
| train_1/fw_bonus          | -0.978207316994667      |
| train_1/fw_loss           | 0.1320226386189461      |
| train_1/mu_grads          | -0.05746160866692662    |
| train_1/mu_grads_std      | 0.2564317651093006      |
| train_1/mu_loss           | 0.8484657396661011      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.3355243103478673e-12 |
| train_1/q_grads           | -0.06319242119789123    |
| train_1/q_grads_std       | 0.3754986204206944      |
| train_1/q_loss            | 0.36961696223165735     |
| train_1/reward            | -2.0654586388242024     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00166015625           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0654586388248726     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 418.95. Rollout time: 233.60, Training time: 185.33
Evaluating epoch 84
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 84                      |
| policy/steps              | 7745196.0               |
| test/episodes             | 2125.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -0.9922554267598069     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 8500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.50100474216229       |
| train_0/fw_bonus          | -0.999025346338749      |
| train_0/fw_loss           | 0.005620906979311257    |
| train_0/mu_grads          | -0.04267474273219705    |
| train_0/mu_grads_std      | 0.6047030538320541      |
| train_0/mu_loss           | 9.407389598068933       |
| train_0/next_q            | -9.403055669468452      |
| train_0/q_grads           | -0.046229229960590604   |
| train_0/q_grads_std       | 0.4372653692960739      |
| train_0/q_loss            | 0.1342960490105476      |
| train_0/reward            | -0.7197275193677342     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0081298828125         |
| train_0/target_q          | -9.652776948608636      |
| train_1/avg_q             | -11.885070255812005     |
| train_1/current_q         | -2.079108565714942      |
| train_1/fw_bonus          | -0.9779926016926765     |
| train_1/fw_loss           | 0.13316373117268085     |
| train_1/mu_grads          | -0.057508589886128905   |
| train_1/mu_grads_std      | 0.25693098157644273     |
| train_1/mu_loss           | 0.8439270086646653      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.7971568778440072e-10 |
| train_1/q_grads           | -0.06424570325762033    |
| train_1/q_grads_std       | 0.3811423175036907      |
| train_1/q_loss            | 0.28316265870784074     |
| train_1/reward            | -2.0811960034494406     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0019775390625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.081196003620434      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 471.76. Rollout time: 259.76, Training time: 211.97
Evaluating epoch 85
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 85                      |
| policy/steps              | 7836321.0               |
| test/episodes             | 2150.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -0.9606154097389208     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 8600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.483412545616778      |
| train_0/fw_bonus          | -0.9989978909492493     |
| train_0/fw_loss           | 0.005762321944348514    |
| train_0/mu_grads          | -0.04281881907954812    |
| train_0/mu_grads_std      | 0.6069933190941811      |
| train_0/mu_loss           | 9.394813001617138       |
| train_0/next_q            | -9.389660932526661      |
| train_0/q_grads           | -0.046692033670842646   |
| train_0/q_grads_std       | 0.44018530398607253     |
| train_0/q_loss            | 0.13674326208041668     |
| train_0/reward            | -0.7191278472753766     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00810546875           |
| train_0/target_q          | -9.634652533659587      |
| train_1/avg_q             | -11.993880798126431     |
| train_1/current_q         | -2.052234536246887      |
| train_1/fw_bonus          | -0.9771385088562965     |
| train_1/fw_loss           | 0.13770253546535968     |
| train_1/mu_grads          | -0.05811827024444938    |
| train_1/mu_grads_std      | 0.2590080663561821      |
| train_1/mu_loss           | 0.8139365857065766      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.6598380572603675e-07 |
| train_1/q_grads           | -0.06454333811998367    |
| train_1/q_grads_std       | 0.38677811697125436     |
| train_1/q_loss            | 0.5950360371154257      |
| train_1/reward            | -2.057014078937209      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016845703125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.057014224505885      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 424.22. Rollout time: 230.61, Training time: 193.59
Evaluating epoch 86
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 7927446.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -15.669222799436328   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.640195477812885    |
| train_0/fw_bonus          | -0.9989816188812256   |
| train_0/fw_loss           | 0.00584607592318207   |
| train_0/mu_grads          | -0.043213681969791654 |
| train_0/mu_grads_std      | 0.6087260708212853    |
| train_0/mu_loss           | 9.55201777469362      |
| train_0/next_q            | -9.546454618025667    |
| train_0/q_grads           | -0.04724137568846345  |
| train_0/q_grads_std       | 0.4435924842953682    |
| train_0/q_loss            | 0.13951805945567222   |
| train_0/reward            | -0.72053572871082     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00751953125         |
| train_0/target_q          | -9.795267922473007    |
| train_1/avg_q             | -19.651080145147727   |
| train_1/current_q         | -22.880391803354193   |
| train_1/fw_bonus          | -0.9758101418614388   |
| train_1/fw_loss           | 0.14476180374622344   |
| train_1/mu_grads          | -0.05592022556811571  |
| train_1/mu_grads_std      | 0.26287114843726156   |
| train_1/mu_loss           | 4.362249584721673     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06417221259325742  |
| train_1/q_grads_std       | 0.3894731648266315    |
| train_1/q_loss            | 19.03000080408119     |
| train_1/reward            | -2.0686545830394607   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.128771282258224   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 438.51. Rollout time: 242.75, Training time: 195.73
Evaluating epoch 87
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 8018571.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -15.025458394104579   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.587285005747617    |
| train_0/fw_bonus          | -0.9989971905946732   |
| train_0/fw_loss           | 0.005765868443995714  |
| train_0/mu_grads          | -0.043485844042152166 |
| train_0/mu_grads_std      | 0.6110822319984436    |
| train_0/mu_loss           | 9.499858791261554     |
| train_0/next_q            | -9.494853475231634    |
| train_0/q_grads           | -0.047362680081278086 |
| train_0/q_grads_std       | 0.4469219855964184    |
| train_0/q_loss            | 0.14151519160251508   |
| train_0/reward            | -0.7197988895895833   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0067138671875       |
| train_0/target_q          | -9.741006637190496    |
| train_1/avg_q             | -23.586811663841313   |
| train_1/current_q         | -22.57672010498133    |
| train_1/fw_bonus          | -0.9756534710526467   |
| train_1/fw_loss           | 0.1455943316221237    |
| train_1/mu_grads          | -0.05539122391492128  |
| train_1/mu_grads_std      | 0.2648521065711975    |
| train_1/mu_loss           | 5.433208178931613     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.0644472362473607   |
| train_1/q_grads_std       | 0.3932026408612728    |
| train_1/q_loss            | 14.283211768100767    |
| train_1/reward            | -2.083212483837997    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.18531892915051    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 462.44. Rollout time: 261.68, Training time: 200.73
Evaluating epoch 88
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 8109696.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -26.787504046250543   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.588678869835423    |
| train_0/fw_bonus          | -0.9990418449044227   |
| train_0/fw_loss           | 0.005536049127113074  |
| train_0/mu_grads          | -0.044287247210741044 |
| train_0/mu_grads_std      | 0.6126539781689644    |
| train_0/mu_loss           | 9.500963149376485     |
| train_0/next_q            | -9.493981277160298    |
| train_0/q_grads           | -0.04803127059713006  |
| train_0/q_grads_std       | 0.44993790686130525   |
| train_0/q_loss            | 0.1417485951897421    |
| train_0/reward            | -0.7220795107357845   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006494140625        |
| train_0/target_q          | -9.745103085825956    |
| train_1/avg_q             | -23.397765231914143   |
| train_1/current_q         | -22.768088249627617   |
| train_1/fw_bonus          | -0.9758618757128715   |
| train_1/fw_loss           | 0.14448685776442288   |
| train_1/mu_grads          | -0.054793279990553855 |
| train_1/mu_grads_std      | 0.2695883549749851    |
| train_1/mu_loss           | 9.829067447808344     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.06442090310156345  |
| train_1/q_grads_std       | 0.3975051738321781    |
| train_1/q_loss            | 18.467184898682728    |
| train_1/reward            | -2.1118567229052134   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013916015625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -22.189415316655225   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 445.33. Rollout time: 245.32, Training time: 199.98
Evaluating epoch 89
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 8200821.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.445228177773355    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.60904925861891     |
| train_0/fw_bonus          | -0.9990628585219383   |
| train_0/fw_loss           | 0.005427798582240939  |
| train_0/mu_grads          | -0.04520733868703246  |
| train_0/mu_grads_std      | 0.6139983355998992    |
| train_0/mu_loss           | 9.521410964607501     |
| train_0/next_q            | -9.516598935754393    |
| train_0/q_grads           | -0.049231745302677155 |
| train_0/q_grads_std       | 0.4521955743432045    |
| train_0/q_loss            | 0.14305141582156064   |
| train_0/reward            | -0.7213209813642607   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005908203125        |
| train_0/target_q          | -9.763397010988959    |
| train_1/avg_q             | -20.75729190192676    |
| train_1/current_q         | -18.154966684670462   |
| train_1/fw_bonus          | -0.9764936164021492   |
| train_1/fw_loss           | 0.1411296810954809    |
| train_1/mu_grads          | -0.05377244502305985  |
| train_1/mu_grads_std      | 0.2715404786169529    |
| train_1/mu_loss           | 2.851695685753646     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -20.88769580861927    |
| train_1/q_grads           | -0.06643249336630105  |
| train_1/q_grads_std       | 0.3963416576385498    |
| train_1/q_loss            | 11.167543239483125    |
| train_1/reward            | -2.1414084274161724   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -17.79587565540963    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 497.27. Rollout time: 268.98, Training time: 228.25
Evaluating epoch 90
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 90                      |
| policy/steps              | 8291946.0               |
| test/episodes             | 2275.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -9.39008524777685e-19   |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 9100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.553167226109434      |
| train_0/fw_bonus          | -0.9991093784570694     |
| train_0/fw_loss           | 0.005188359308522195    |
| train_0/mu_grads          | -0.0464432492852211     |
| train_0/mu_grads_std      | 0.6152794018387795      |
| train_0/mu_loss           | 9.459145910911861       |
| train_0/next_q            | -9.45840861185738       |
| train_0/q_grads           | -0.04897301597520709    |
| train_0/q_grads_std       | 0.4541314788162708      |
| train_0/q_loss            | 0.14161333234322132     |
| train_0/reward            | -0.721270993618964      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00556640625           |
| train_0/target_q          | -9.706285654596007      |
| train_1/avg_q             | -8.917114348353806      |
| train_1/current_q         | -0.003826023949813603   |
| train_1/fw_bonus          | -0.9764112114906311     |
| train_1/fw_loss           | 0.14156764037907124     |
| train_1/mu_grads          | -0.05448177084326744    |
| train_1/mu_grads_std      | 0.27218636870384216     |
| train_1/mu_loss           | 1.0295282147222435e-13  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.315618501374385e-220 |
| train_1/q_grads           | -0.06537683829665183    |
| train_1/q_grads_std       | 0.39788868054747584     |
| train_1/q_loss            | 18.525048560161707      |
| train_1/reward            | -2.0986304057223606     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0020263671875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0986304057223606     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_90.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 513.45. Rollout time: 285.22, Training time: 228.19
Evaluating epoch 91
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 8383071.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -20.782853843951216   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.432075425200821    |
| train_0/fw_bonus          | -0.999091811478138    |
| train_0/fw_loss           | 0.005278755107428879  |
| train_0/mu_grads          | -0.04683461328968406  |
| train_0/mu_grads_std      | 0.615937101840973     |
| train_0/mu_loss           | 9.33964608043766      |
| train_0/next_q            | -9.33578705508133     |
| train_0/q_grads           | -0.049258435051888226 |
| train_0/q_grads_std       | 0.455269642919302     |
| train_0/q_loss            | 0.1396439933554331    |
| train_0/reward            | -0.7193090895205387   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00615234375         |
| train_0/target_q          | -9.581794166989607    |
| train_1/avg_q             | -1.7186209621614037   |
| train_1/current_q         | -17.47227108110968    |
| train_1/fw_bonus          | -0.9761224746704101   |
| train_1/fw_loss           | 0.1431019317358732    |
| train_1/mu_grads          | -0.05391949713230133  |
| train_1/mu_grads_std      | 0.2709560289978981    |
| train_1/mu_loss           | 20.395034946973567    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -20.375893057509792   |
| train_1/q_grads           | -0.06664650831371546  |
| train_1/q_grads_std       | 0.39791224524378777   |
| train_1/q_loss            | 8.962043922311654     |
| train_1/reward            | -2.127526574784133    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016357421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -17.491270466600525   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 479.53. Rollout time: 274.31, Training time: 205.19
Evaluating epoch 92
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
----------------------------------------------------
| epoch                     | 92                   |
| policy/steps              | 8474196.0            |
| test/episodes             | 2325.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -20.399735068328983  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.49110023651913    |
| train_0/fw_bonus          | -0.9991285160183907  |
| train_0/fw_loss           | 0.005089819594286382 |
| train_0/mu_grads          | -0.04699615314602852 |
| train_0/mu_grads_std      | 0.6166666805744171   |
| train_0/mu_loss           | 9.400821540427064    |
| train_0/next_q            | -9.397410539392183   |
| train_0/q_grads           | -0.04881901135668158 |
| train_0/q_grads_std       | 0.45678548961877824  |
| train_0/q_loss            | 0.13166257541646073  |
| train_0/reward            | -0.7149695290092495  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.005517578125       |
| train_0/target_q          | -9.643206541183599   |
| train_1/avg_q             | -21.486801834052866  |
| train_1/current_q         | -23.036266195525023  |
| train_1/fw_bonus          | -0.9755573868751526  |
| train_1/fw_loss           | 0.14610501416027546  |
| train_1/mu_grads          | -0.05314104054123163 |
| train_1/mu_grads_std      | 0.2739189349114895   |
| train_1/mu_loss           | 12.032411129415346   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -26.999982175329762  |
| train_1/q_grads           | -0.06419383566826582 |
| train_1/q_grads_std       | 0.39746046587824824  |
| train_1/q_loss            | 18.608810160337004   |
| train_1/reward            | -2.1264017408611835  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015869140625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -22.35381425488791   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 510.18. Rollout time: 285.55, Training time: 224.59
Evaluating epoch 93
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 8565321.0              |
| test/episodes             | 2350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -2.17678436812612      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.519879545449845     |
| train_0/fw_bonus          | -0.999164529144764     |
| train_0/fw_loss           | 0.0049044034676626325  |
| train_0/mu_grads          | -0.04762178976088762   |
| train_0/mu_grads_std      | 0.6187365859746933     |
| train_0/mu_loss           | 9.430769397744152      |
| train_0/next_q            | -9.427313146764536     |
| train_0/q_grads           | -0.048969656322151424  |
| train_0/q_grads_std       | 0.45849620550870895    |
| train_0/q_loss            | 0.13109212592494077    |
| train_0/reward            | -0.7159640992736968    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.005419921875         |
| train_0/target_q          | -9.670467033296358     |
| train_1/avg_q             | -10.54639897219252     |
| train_1/current_q         | -0.46764983656431314   |
| train_1/fw_bonus          | -0.9763554707169533    |
| train_1/fw_loss           | 0.1418638151139021     |
| train_1/mu_grads          | -0.05241193380206823   |
| train_1/mu_grads_std      | 0.2751671954989433     |
| train_1/mu_loss           | 0.21043915022911416    |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.0033795434837231688 |
| train_1/q_grads           | -0.064715008251369     |
| train_1/q_grads_std       | 0.3964006580412388     |
| train_1/q_loss            | 12.317724127857698     |
| train_1/reward            | -2.102264648250275     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015380859375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.104904880625052     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 513.03. Rollout time: 273.17, Training time: 239.82
Evaluating epoch 94
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 94                      |
| policy/steps              | 8656446.0               |
| test/episodes             | 2375.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.8007362414591618e-19 |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 9500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.554724054039568      |
| train_0/fw_bonus          | -0.9991480216383934     |
| train_0/fw_loss           | 0.00498929686145857     |
| train_0/mu_grads          | -0.04706810628995299    |
| train_0/mu_grads_std      | 0.6206724852323532      |
| train_0/mu_loss           | 9.469973565724843       |
| train_0/next_q            | -9.465627027874945      |
| train_0/q_grads           | -0.049393748957663776   |
| train_0/q_grads_std       | 0.4615665525197983      |
| train_0/q_loss            | 0.13159669941330104     |
| train_0/reward            | -0.7171521436990588     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0058837890625         |
| train_0/target_q          | -9.70977006056524       |
| train_1/avg_q             | -2.363037834432848      |
| train_1/current_q         | -0.07639173945842063    |
| train_1/fw_bonus          | -0.9763911023736        |
| train_1/fw_loss           | 0.14167444296181203     |
| train_1/mu_grads          | -0.05232496187090874    |
| train_1/mu_grads_std      | 0.27589696645736694     |
| train_1/mu_loss           | 3.1770188758632394e-17  |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | 0.0                     |
| train_1/q_grads           | -0.06452912539243698    |
| train_1/q_grads_std       | 0.3987730711698532      |
| train_1/q_loss            | 17.950328393686174      |
| train_1/reward            | -2.0587643990074866     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00185546875           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.0587643990074866     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 572.20. Rollout time: 303.67, Training time: 268.49
Evaluating epoch 95
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 8747571.0              |
| test/episodes             | 2400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.715213756146117    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.986469111633713    |
| train_0/current_q         | -9.586769711664095     |
| train_0/fw_bonus          | -0.9991011336445809    |
| train_0/fw_loss           | 0.00523084953892976    |
| train_0/mu_grads          | -0.04636080265045166   |
| train_0/mu_grads_std      | 0.6217165231704712     |
| train_0/mu_loss           | 9.49977040576648       |
| train_0/next_q            | -9.497921027656664     |
| train_0/q_grads           | -0.04972261833027005   |
| train_0/q_grads_std       | 0.46537124887108805    |
| train_0/q_loss            | 0.13563850822373358    |
| train_0/reward            | -0.7180564180242073    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0060791015625        |
| train_0/target_q          | -9.742099694906832     |
| train_1/avg_q             | -4.771858856140487     |
| train_1/current_q         | -2.065173662518311     |
| train_1/fw_bonus          | -0.9770312830805779    |
| train_1/fw_loss           | 0.13827232960611582    |
| train_1/mu_grads          | -0.053714937902987     |
| train_1/mu_grads_std      | 0.2720325879752636     |
| train_1/mu_loss           | 6.007774471561229      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.930221415977959e-08 |
| train_1/q_grads           | -0.06492343805730343   |
| train_1/q_grads_std       | 0.3985326185822487     |
| train_1/q_loss            | 0.1606201488481493     |
| train_1/reward            | -2.0723291220201645    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001904296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.072329180133223     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 477.81. Rollout time: 266.91, Training time: 210.87
Evaluating epoch 96
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 8838696.0              |
| test/episodes             | 2425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.55746418068594     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.45543647717343      |
| train_0/fw_bonus          | -0.9991637319326401    |
| train_0/fw_loss           | 0.004908487130887806   |
| train_0/mu_grads          | -0.046302192565053704  |
| train_0/mu_grads_std      | 0.6242875382304192     |
| train_0/mu_loss           | 9.3729002633652        |
| train_0/next_q            | -9.368769945322194     |
| train_0/q_grads           | -0.050231170188635585  |
| train_0/q_grads_std       | 0.46746027544140817    |
| train_0/q_loss            | 0.13049632353415755    |
| train_0/reward            | -0.7142547182280395    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00556640625          |
| train_0/target_q          | -9.60840078034931      |
| train_1/avg_q             | -13.764886291177994    |
| train_1/current_q         | -2.085481417144459     |
| train_1/fw_bonus          | -0.9763361930847168    |
| train_1/fw_loss           | 0.141966250911355      |
| train_1/mu_grads          | -0.05390790430828929   |
| train_1/mu_grads_std      | 0.27330480217933656    |
| train_1/mu_loss           | 7.5136962665206966     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.0032977785979715008 |
| train_1/q_grads           | -0.06458446346223354   |
| train_1/q_grads_std       | 0.3982677958905697     |
| train_1/q_loss            | 0.08062479366391655    |
| train_1/reward            | -2.087777470949368     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001806640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.0877774709497166    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 508.00. Rollout time: 273.61, Training time: 234.36
Evaluating epoch 97
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 97                      |
| policy/steps              | 8929821.0               |
| test/episodes             | 2450.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -12.793882571090979     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 9800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.501016205800706      |
| train_0/fw_bonus          | -0.9991180241107941     |
| train_0/fw_loss           | 0.005143779492937028    |
| train_0/mu_grads          | -0.04603204671293497    |
| train_0/mu_grads_std      | 0.6254138067364693      |
| train_0/mu_loss           | 9.415984698506875       |
| train_0/next_q            | -9.41171322398694       |
| train_0/q_grads           | -0.0509111481718719     |
| train_0/q_grads_std       | 0.4697930462658405      |
| train_0/q_loss            | 0.13102795229344638     |
| train_0/reward            | -0.7154769837310596     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.006494140625          |
| train_0/target_q          | -9.6536117399667        |
| train_1/avg_q             | -13.891616069163128     |
| train_1/current_q         | -2.1209829839758543     |
| train_1/fw_bonus          | -0.9762122705578804     |
| train_1/fw_loss           | 0.14262481331825255     |
| train_1/mu_grads          | -0.05408787550404668    |
| train_1/mu_grads_std      | 0.2748659856617451      |
| train_1/mu_loss           | 5.4548702494472865      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.2582230142309516e-08 |
| train_1/q_grads           | -0.06506570503115654    |
| train_1/q_grads_std       | 0.40079534947872164     |
| train_1/q_loss            | 0.036954050210495124    |
| train_1/reward            | -2.1216510557816948     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0015869140625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.121651055781997      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 496.22. Rollout time: 276.58, Training time: 219.61
Evaluating epoch 98
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 9020946.0              |
| test/episodes             | 2475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -12.418986171637869    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.489658268889432     |
| train_0/fw_bonus          | -0.9991457790136338    |
| train_0/fw_loss           | 0.005000989662948996   |
| train_0/mu_grads          | -0.0468542049638927    |
| train_0/mu_grads_std      | 0.627716702222824      |
| train_0/mu_loss           | 9.411144040585762      |
| train_0/next_q            | -9.406619037711817     |
| train_0/q_grads           | -0.05086545469239354   |
| train_0/q_grads_std       | 0.47136808186769485    |
| train_0/q_loss            | 0.12721131868562566    |
| train_0/reward            | -0.713440070485376     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0059326171875        |
| train_0/target_q          | -9.642160684605694     |
| train_1/avg_q             | -13.855642635795775    |
| train_1/current_q         | -2.0731476862793117    |
| train_1/fw_bonus          | -0.9750624895095825    |
| train_1/fw_loss           | 0.14873500391840935    |
| train_1/mu_grads          | -0.05429561324417591   |
| train_1/mu_grads_std      | 0.27583117336034774    |
| train_1/mu_loss           | 6.163079237224409      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.838544397460049e-23 |
| train_1/q_grads           | -0.06514230035245419   |
| train_1/q_grads_std       | 0.40153239741921426    |
| train_1/q_loss            | 0.02272460433381058    |
| train_1/reward            | -2.07338329809063      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00146484375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -2.07338329809063      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 491.37. Rollout time: 274.84, Training time: 216.50
Evaluating epoch 99
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144
-------------------------------------------------------
| epoch                     | 99                      |
| policy/steps              | 9112071.0               |
| test/episodes             | 2500.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -1.0284128959837937     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 10000.0                 |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.451495429422744      |
| train_0/fw_bonus          | -0.9991667285561562     |
| train_0/fw_loss           | 0.0048931501689366995   |
| train_0/mu_grads          | -0.049327794928103685   |
| train_0/mu_grads_std      | 0.6295991569757462      |
| train_0/mu_loss           | 9.374436983510396       |
| train_0/next_q            | -9.370149843732976      |
| train_0/q_grads           | -0.0509998525492847     |
| train_0/q_grads_std       | 0.4732675440609455      |
| train_0/q_loss            | 0.1300745969635809      |
| train_0/reward            | -0.7120345285366056     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0056396484375         |
| train_0/target_q          | -9.604711063672791      |
| train_1/avg_q             | -12.427412778285813     |
| train_1/current_q         | -2.113331262972417      |
| train_1/fw_bonus          | -0.9762428849935532     |
| train_1/fw_loss           | 0.14246212989091872     |
| train_1/mu_grads          | -0.05338904280215502    |
| train_1/mu_grads_std      | 0.2745801702141762      |
| train_1/mu_loss           | 0.8267655093984706      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.7978580729045508e-27 |
| train_1/q_grads           | -0.06574984323233365    |
| train_1/q_grads_std       | 0.40156035497784615     |
| train_1/q_loss            | 0.1618701945114685      |
| train_1/reward            | -2.1129871633929724     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002001953125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -2.1129871633929724     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|144/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
