Starting process id: 68733
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f9b2962fc20>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 584.49. Rollout time: 284.25, Training time: 300.20
Evaluating epoch 0
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 91093.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -22.056841813464622   |
| test_1/avg_q              | -16.383731428245586   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -5.525177755755255    |
| train_0/current_q         | -5.932998392259668    |
| train_0/fw_bonus          | -0.9941377267241478   |
| train_0/fw_loss           | 0.02815746869891882   |
| train_0/mu_grads          | -0.016861795913428068 |
| train_0/mu_grads_std      | 0.1696532867848873    |
| train_0/mu_loss           | 5.90824454583886      |
| train_0/next_q            | -5.8119381323578665   |
| train_0/q_grads           | 0.004669378616381436  |
| train_0/q_grads_std       | 0.10712484139949083   |
| train_0/q_loss            | 0.5737365049024648    |
| train_0/reward            | -0.7160019594761252   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000341796875        |
| train_0/target_q          | -5.922502563097221    |
| train_1/avg_q             | -7.642833828040369    |
| train_1/current_q         | -8.016666344802035    |
| train_1/fw_bonus          | -0.9896941319108009   |
| train_1/fw_loss           | 0.05924187172204256   |
| train_1/mu_grads          | -0.015693963039666414 |
| train_1/mu_grads_std      | 0.1483385745435953    |
| train_1/mu_loss           | 6.172715384015102     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.732799505223232    |
| train_1/q_grads           | 0.012817362998612225  |
| train_1/q_grads_std       | 0.10929977986961603   |
| train_1/q_loss            | 1.9424584733374128    |
| train_1/reward            | -2.1353133719465403   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00263671875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0007407407407407407 |
| train_1/target_q          | -8.029738629997563    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 463.81. Rollout time: 255.84, Training time: 207.93
Evaluating epoch 1
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 182218.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -10.516356949775377   |
| test_1/avg_q              | -10.463900216769856   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -20.117892177684425   |
| train_0/current_q         | -7.977129704580113    |
| train_0/fw_bonus          | -0.9969336465001106   |
| train_0/fw_loss           | 0.015017704013735056  |
| train_0/mu_grads          | -0.018769179889932274 |
| train_0/mu_grads_std      | 0.2002023782581091    |
| train_0/mu_loss           | 7.8952600146620595    |
| train_0/next_q            | -7.893113601418714    |
| train_0/q_grads           | 0.004421663179527968  |
| train_0/q_grads_std       | 0.13285639211535455   |
| train_0/q_loss            | 0.4925774563105653    |
| train_0/reward            | -0.7146899709601712   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0063720703125       |
| train_0/target_q          | -8.0456502983982      |
| train_1/avg_q             | -14.484017084628846   |
| train_1/current_q         | -8.372242566345225    |
| train_1/fw_bonus          | -0.9866339489817619   |
| train_1/fw_loss           | 0.07331491038203239   |
| train_1/mu_grads          | -0.03347789561375976  |
| train_1/mu_grads_std      | 0.17990585714578627   |
| train_1/mu_loss           | 5.894463233890252     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.10747930940999     |
| train_1/q_grads           | 0.003338217391865328  |
| train_1/q_grads_std       | 0.12418392226099968   |
| train_1/q_loss            | 1.4773089929630565    |
| train_1/reward            | -2.159234942753392    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.34073393767817     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 474.11. Rollout time: 264.40, Training time: 209.67
Evaluating epoch 2
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 273343.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.727719043945307   |
| test_1/avg_q              | -14.014529724416196   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -18.205092948215007   |
| train_0/current_q         | -7.999729775929348    |
| train_0/fw_bonus          | -0.9974951043725013   |
| train_0/fw_loss           | 0.01237911896314472   |
| train_0/mu_grads          | -0.017499989224597813 |
| train_0/mu_grads_std      | 0.23476673401892184   |
| train_0/mu_loss           | 7.889996354040238     |
| train_0/next_q            | -7.908422973722895    |
| train_0/q_grads           | 0.002282497924170457  |
| train_0/q_grads_std       | 0.15103112049400808   |
| train_0/q_loss            | 0.4798412443647274    |
| train_0/reward            | -0.712382805908419    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0072998046875       |
| train_0/target_q          | -8.05117688793632     |
| train_1/avg_q             | -13.193181944522156   |
| train_1/current_q         | -7.967633554018311    |
| train_1/fw_bonus          | -0.9845024675130845   |
| train_1/fw_loss           | 0.08311703782528639   |
| train_1/mu_grads          | -0.037882722541689874 |
| train_1/mu_grads_std      | 0.1979762066155672    |
| train_1/mu_loss           | 5.817053575796172     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.843637377570495    |
| train_1/q_grads           | -0.005387376609724015 |
| train_1/q_grads_std       | 0.13927853479981422   |
| train_1/q_loss            | 2.611061220407975     |
| train_1/reward            | -2.122646745410748    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.216955594315374    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 459.97. Rollout time: 256.42, Training time: 203.51
Evaluating epoch 3
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 364454.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -23.360024151457058    |
| test_1/avg_q              | -14.188064608643035    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -23.710490690005805    |
| train_0/current_q         | -8.681126758796758     |
| train_0/fw_bonus          | -0.997816552221775     |
| train_0/fw_loss           | 0.010868443944491445   |
| train_0/mu_grads          | -0.014586793119087815  |
| train_0/mu_grads_std      | 0.2592454172670841     |
| train_0/mu_loss           | 8.577811779195285      |
| train_0/next_q            | -8.619489502265523     |
| train_0/q_grads           | 0.005093478260096163   |
| train_0/q_grads_std       | 0.16323696933686732    |
| train_0/q_loss            | 0.5099721173220835     |
| train_0/reward            | -0.7099678469086939    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.01865234375          |
| train_0/target_q          | -8.815319795675371     |
| train_1/avg_q             | -14.254612631131426    |
| train_1/current_q         | -9.243307694749655     |
| train_1/fw_bonus          | -0.9830439582467079    |
| train_1/fw_loss           | 0.0898244434967637     |
| train_1/mu_grads          | -0.04214390506967902   |
| train_1/mu_grads_std      | 0.21558163575828077    |
| train_1/mu_loss           | 6.452568791100873      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.986356278984687     |
| train_1/q_grads           | -0.017869357531890274  |
| train_1/q_grads_std       | 0.154841136187315      |
| train_1/q_loss            | 1.5354323941383436     |
| train_1/reward            | -2.1102963888268276    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007080078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -9.238231134159093     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 436.39. Rollout time: 239.57, Training time: 196.79
Evaluating epoch 4
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 455451.0              |
| test/episodes             | 125.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.992084288685483   |
| test_1/avg_q              | -12.73921327775528    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -24.46451979176885    |
| train_0/current_q         | -9.246236036142884    |
| train_0/fw_bonus          | -0.998005460202694    |
| train_0/fw_loss           | 0.009980654180981218  |
| train_0/mu_grads          | -0.015276420512236655 |
| train_0/mu_grads_std      | 0.27580238580703736   |
| train_0/mu_loss           | 9.218121697829373     |
| train_0/next_q            | -9.218297226727248    |
| train_0/q_grads           | 0.006495884526520968  |
| train_0/q_grads_std       | 0.17582216076552867   |
| train_0/q_loss            | 0.26271111897327826   |
| train_0/reward            | -0.7122839806506818   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.033447265625        |
| train_0/target_q          | -9.390426072594114    |
| train_1/avg_q             | -14.099218010037717   |
| train_1/current_q         | -8.386053918344086    |
| train_1/fw_bonus          | -0.9812385559082031   |
| train_1/fw_loss           | 0.09812704995274543   |
| train_1/mu_grads          | -0.042842866480350496 |
| train_1/mu_grads_std      | 0.22946208007633687   |
| train_1/mu_loss           | 5.816145168203459     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.900019279765547    |
| train_1/q_grads           | -0.02506476887501776  |
| train_1/q_grads_std       | 0.16811705194413662   |
| train_1/q_loss            | 0.7169497718941449    |
| train_1/reward            | -2.1236881212003937   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000732421875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0025925925925925925 |
| train_1/target_q          | -8.37997895646493     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 491.33. Rollout time: 282.08, Training time: 209.22
Evaluating epoch 5
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 546576.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999993932   |
| test_1/avg_q              | -12.216530145565258   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.924063212968722   |
| train_0/current_q         | -9.205078074654457    |
| train_0/fw_bonus          | -0.9981007725000381   |
| train_0/fw_loss           | 0.009532748558558523  |
| train_0/mu_grads          | -0.016417495254427195 |
| train_0/mu_grads_std      | 0.2853360839188099    |
| train_0/mu_loss           | 9.205190707814864     |
| train_0/next_q            | -9.19323614855394     |
| train_0/q_grads           | 0.008202831028029323  |
| train_0/q_grads_std       | 0.18161002025008202   |
| train_0/q_loss            | 0.33849503563411143   |
| train_0/reward            | -0.7124537048475759   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0291259765625       |
| train_0/target_q          | -9.333463741411341    |
| train_1/avg_q             | -13.776764713013367   |
| train_1/current_q         | -7.803281268349627    |
| train_1/fw_bonus          | -0.9810049965977669   |
| train_1/fw_loss           | 0.09920108281075954   |
| train_1/mu_grads          | -0.0445200783200562   |
| train_1/mu_grads_std      | 0.23887793458998202   |
| train_1/mu_loss           | 5.876381281372156     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.359304834363526    |
| train_1/q_grads           | -0.035896651446819305 |
| train_1/q_grads_std       | 0.1787487596273422    |
| train_1/q_loss            | 1.0552322824435219    |
| train_1/reward            | -2.101928281359869    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000732421875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.781178548899424    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 467.56. Rollout time: 266.61, Training time: 200.91
Evaluating epoch 6
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 637255.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -19.83227571363646    |
| test_1/avg_q              | -12.242564918159127   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.88596320373073    |
| train_0/current_q         | -8.836388941323078    |
| train_0/fw_bonus          | -0.9982453927397728   |
| train_0/fw_loss           | 0.008853113930672406  |
| train_0/mu_grads          | -0.018746140552684663 |
| train_0/mu_grads_std      | 0.29348651096224787   |
| train_0/mu_loss           | 8.82215091998361      |
| train_0/next_q            | -8.819857903677217    |
| train_0/q_grads           | 0.010444201878271997  |
| train_0/q_grads_std       | 0.18804627209901809   |
| train_0/q_loss            | 0.5197872926028367    |
| train_0/reward            | -0.7084244504090748   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0437255859375       |
| train_0/target_q          | -8.921515883176099    |
| train_1/avg_q             | -13.769610507994441   |
| train_1/current_q         | -8.920567817944809    |
| train_1/fw_bonus          | -0.9807932868599891   |
| train_1/fw_loss           | 0.10017468966543674   |
| train_1/mu_grads          | -0.04756300011649728  |
| train_1/mu_grads_std      | 0.24627028293907643   |
| train_1/mu_loss           | 7.090354930066918     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.761140959445484    |
| train_1/q_grads           | -0.03935288963839412  |
| train_1/q_grads_std       | 0.19265689812600612   |
| train_1/q_loss            | 2.38735051963429      |
| train_1/reward            | -2.0373326795182947   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.006666666666666667  |
| train_1/target_q          | -8.875508588115602    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 439.86. Rollout time: 247.28, Training time: 192.55
Evaluating epoch 7
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 727222.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -24.111114724290708   |
| test_1/avg_q              | -12.654354013645271   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -22.46011238753094    |
| train_0/current_q         | -8.882259497029159    |
| train_0/fw_bonus          | -0.9982329398393631   |
| train_0/fw_loss           | 0.008911613980308175  |
| train_0/mu_grads          | -0.015819332422688605 |
| train_0/mu_grads_std      | 0.29827279075980184   |
| train_0/mu_loss           | 8.875821306554311     |
| train_0/next_q            | -8.870397826704757    |
| train_0/q_grads           | 0.013291232287883759  |
| train_0/q_grads_std       | 0.19852650724351406   |
| train_0/q_loss            | 0.3603946075368961    |
| train_0/reward            | -0.7108596326645056   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0535888671875       |
| train_0/target_q          | -9.033228197059923    |
| train_1/avg_q             | -13.58312096927923    |
| train_1/current_q         | -8.579807514503193    |
| train_1/fw_bonus          | -0.9816798880696297   |
| train_1/fw_loss           | 0.09609752129763365   |
| train_1/mu_grads          | -0.04422484943643212  |
| train_1/mu_grads_std      | 0.2631078973412514    |
| train_1/mu_loss           | 5.519088476997454     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.19805110001265     |
| train_1/q_grads           | -0.039565148670226334 |
| train_1/q_grads_std       | 0.20201372355222702   |
| train_1/q_loss            | 1.3740856552510248    |
| train_1/reward            | -2.0889356374646013   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.017777777777777778  |
| train_1/target_q          | -8.544985560594828    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 422.34. Rollout time: 239.09, Training time: 183.22
Evaluating epoch 8
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 818322.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999981449433477    |
| test_1/avg_q              | -13.23386180461487     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -25.4808279653442      |
| train_0/current_q         | -9.513471475169167     |
| train_0/fw_bonus          | -0.9984070777893066    |
| train_0/fw_loss           | 0.008093248051591218   |
| train_0/mu_grads          | -0.01726980130188167   |
| train_0/mu_grads_std      | 0.30267841294407843    |
| train_0/mu_loss           | 9.510960730633782      |
| train_0/next_q            | -9.512989786048617     |
| train_0/q_grads           | 0.017024842742830514   |
| train_0/q_grads_std       | 0.2022306352853775     |
| train_0/q_loss            | 0.3412048411720129     |
| train_0/reward            | -0.70922550911273      |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.042626953125         |
| train_0/target_q          | -9.65981603941039      |
| train_1/avg_q             | -12.983349771195272    |
| train_1/current_q         | -8.49631771437407      |
| train_1/fw_bonus          | -0.9835672587156296    |
| train_1/fw_loss           | 0.08741790950298309    |
| train_1/mu_grads          | -0.04262156318873167   |
| train_1/mu_grads_std      | 0.28017881885170937    |
| train_1/mu_loss           | 6.133363128239603      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.125943655275691     |
| train_1/q_grads           | -0.04151855260133743   |
| train_1/q_grads_std       | 0.21278554759919643    |
| train_1/q_loss            | 0.7575353569846841     |
| train_1/reward            | -2.0937367506288864    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001513671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -8.478024107192118     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 419.52. Rollout time: 239.21, Training time: 180.28
Evaluating epoch 9
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 909301.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.51474040942983    |
| test_1/avg_q              | -14.058179930140625   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.12707019832518    |
| train_0/current_q         | -9.467141895410197    |
| train_0/fw_bonus          | -0.998455160856247    |
| train_0/fw_loss           | 0.007867214793805033  |
| train_0/mu_grads          | -0.016816779458895325 |
| train_0/mu_grads_std      | 0.3077725939452648    |
| train_0/mu_loss           | 9.463010361294883     |
| train_0/next_q            | -9.467645726534002    |
| train_0/q_grads           | 0.018973037507385014  |
| train_0/q_grads_std       | 0.20780015252530576   |
| train_0/q_loss            | 0.3656339360315107    |
| train_0/reward            | -0.7067837370435882   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0477294921875       |
| train_0/target_q          | -9.607333375931779    |
| train_1/avg_q             | -13.908719437736169   |
| train_1/current_q         | -8.27360518209754     |
| train_1/fw_bonus          | -0.9839092135429383   |
| train_1/fw_loss           | 0.0858453031629324    |
| train_1/mu_grads          | -0.04454085025936365  |
| train_1/mu_grads_std      | 0.28533449992537496   |
| train_1/mu_loss           | 6.253043147883703     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.834304286072732    |
| train_1/q_grads           | -0.0428959277458489   |
| train_1/q_grads_std       | 0.21859454810619355   |
| train_1/q_loss            | 0.5584000963042477    |
| train_1/reward            | -2.0564565601387583   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002001953125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.002962962962962963  |
| train_1/target_q          | -8.26153979118876     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 419.53. Rollout time: 237.43, Training time: 182.07
Evaluating epoch 10
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 999772.0              |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999998562433507   |
| test_1/avg_q              | -13.981865726568584   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.140242663877014   |
| train_0/current_q         | -9.33526854237309     |
| train_0/fw_bonus          | -0.9985567525029182   |
| train_0/fw_loss           | 0.007389768527355045  |
| train_0/mu_grads          | -0.01247011220548302  |
| train_0/mu_grads_std      | 0.31543743833899496   |
| train_0/mu_loss           | 9.318924702720995     |
| train_0/next_q            | -9.323740499400229    |
| train_0/q_grads           | 0.02125284718349576   |
| train_0/q_grads_std       | 0.21456494517624378   |
| train_0/q_loss            | 0.356265779547136     |
| train_0/reward            | -0.7069688112220319   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0285888671875       |
| train_0/target_q          | -9.482758438384232    |
| train_1/avg_q             | -13.999630273837091   |
| train_1/current_q         | -7.951601114184733    |
| train_1/fw_bonus          | -0.9848933607339859   |
| train_1/fw_loss           | 0.08131941836327314   |
| train_1/mu_grads          | -0.045119116082787514 |
| train_1/mu_grads_std      | 0.289792650192976     |
| train_1/mu_loss           | 6.011083247351946     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.463454660994961    |
| train_1/q_grads           | -0.04552495703101158  |
| train_1/q_grads_std       | 0.22642664127051831   |
| train_1/q_loss            | 0.598715252134444     |
| train_1/reward            | -2.0530057658012084   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002099609375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.013333333333333334  |
| train_1/target_q          | -7.954898080059439    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 420.02. Rollout time: 237.96, Training time: 182.03
Evaluating epoch 11
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1090604.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.230502648791827   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.34955635286916    |
| train_0/current_q         | -9.33293680185217     |
| train_0/fw_bonus          | -0.9986303374171257   |
| train_0/fw_loss           | 0.007044047152157873  |
| train_0/mu_grads          | -0.013983873929828406 |
| train_0/mu_grads_std      | 0.32089963257312776   |
| train_0/mu_loss           | 9.319620296004718     |
| train_0/next_q            | -9.328674779866045    |
| train_0/q_grads           | 0.02516769589856267   |
| train_0/q_grads_std       | 0.2222245492041111    |
| train_0/q_loss            | 0.44059169753021976   |
| train_0/reward            | -0.7072741482115816   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0419189453125       |
| train_0/target_q          | -9.495225888535549    |
| train_1/avg_q             | -13.941258283685144   |
| train_1/current_q         | -7.842380316244807    |
| train_1/fw_bonus          | -0.9848593875765801   |
| train_1/fw_loss           | 0.08147574439644814   |
| train_1/mu_grads          | -0.049643308855593204 |
| train_1/mu_grads_std      | 0.3035186342895031    |
| train_1/mu_loss           | 5.785371637873362     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.482167180548876    |
| train_1/q_grads           | -0.04936491856351495  |
| train_1/q_grads_std       | 0.23527959771454335   |
| train_1/q_loss            | 0.8979094885743848    |
| train_1/reward            | -2.1017436513073333   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.005925925925925926  |
| train_1/target_q          | -7.95278894022268     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 423.62. Rollout time: 241.03, Training time: 182.56
Evaluating epoch 12
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1181729.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.346442002073621   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.997286050589693   |
| train_0/current_q         | -9.611545778661853    |
| train_0/fw_bonus          | -0.9988075330853462   |
| train_0/fw_loss           | 0.006211301684379578  |
| train_0/mu_grads          | -0.014675398427061736 |
| train_0/mu_grads_std      | 0.32629276663064954   |
| train_0/mu_loss           | 9.611477376097547     |
| train_0/next_q            | -9.61256202737029     |
| train_0/q_grads           | 0.031190891144797207  |
| train_0/q_grads_std       | 0.228393217548728     |
| train_0/q_loss            | 0.4584947579127709    |
| train_0/reward            | -0.7059711443347624   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01494140625         |
| train_0/target_q          | -9.755809353215765    |
| train_1/avg_q             | -14.056673448702647   |
| train_1/current_q         | -9.401039541103929    |
| train_1/fw_bonus          | -0.9857366681098938   |
| train_1/fw_loss           | 0.07744123991578818   |
| train_1/mu_grads          | -0.043306476715952155 |
| train_1/mu_grads_std      | 0.31135008335113523   |
| train_1/mu_loss           | 6.0753440754455275    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.626766143132622    |
| train_1/q_grads           | -0.05415916442871094  |
| train_1/q_grads_std       | 0.24362900108098984   |
| train_1/q_loss            | 1.9770976802627545    |
| train_1/reward            | -2.0965304477162134   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021728515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.387984458606741    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 419.20. Rollout time: 237.64, Training time: 181.53
Evaluating epoch 13
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1272854.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.031924335235992   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999999141    |
| train_0/current_q         | -9.439710726911207    |
| train_0/fw_bonus          | -0.9988363683223724   |
| train_0/fw_loss           | 0.006075761804822832  |
| train_0/mu_grads          | -0.014138334337621928 |
| train_0/mu_grads_std      | 0.3305092602968216    |
| train_0/mu_loss           | 9.43237498413034      |
| train_0/next_q            | -9.425984078496743    |
| train_0/q_grads           | 0.028822037018835546  |
| train_0/q_grads_std       | 0.22969317063689232   |
| train_0/q_loss            | 0.24223996404485462   |
| train_0/reward            | -0.7041300960139779   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01015625            |
| train_0/target_q          | -9.572463322408652    |
| train_1/avg_q             | -14.185319953886301   |
| train_1/current_q         | -8.109065168404536    |
| train_1/fw_bonus          | -0.9862969785928726   |
| train_1/fw_loss           | 0.07486454844474792   |
| train_1/mu_grads          | -0.046523678675293924 |
| train_1/mu_grads_std      | 0.314178341627121     |
| train_1/mu_loss           | 5.889330192475053     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.585246054762268    |
| train_1/q_grads           | -0.05337208788841963  |
| train_1/q_grads_std       | 0.24550467282533645   |
| train_1/q_loss            | 0.7360832519185516    |
| train_1/reward            | -2.074154348010052    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0030029296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.095610735691265    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 421.37. Rollout time: 243.32, Training time: 178.02
Evaluating epoch 14
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 1363979.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.765099675094998   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999996654    |
| train_0/current_q         | -9.19361247282184     |
| train_0/fw_bonus          | -0.9988766208291053   |
| train_0/fw_loss           | 0.005886578117497265  |
| train_0/mu_grads          | -0.009695896063931286 |
| train_0/mu_grads_std      | 0.33544325828552246   |
| train_0/mu_loss           | 9.183915333601778     |
| train_0/next_q            | -9.181768817864842    |
| train_0/q_grads           | 0.03146917298436165   |
| train_0/q_grads_std       | 0.23295077830553054   |
| train_0/q_loss            | 0.30862159314864007   |
| train_0/reward            | -0.7034788370299794   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0135009765625       |
| train_0/target_q          | -9.349234711196932    |
| train_1/avg_q             | -14.174564025600159   |
| train_1/current_q         | -7.489992596190248    |
| train_1/fw_bonus          | -0.9868297770619392   |
| train_1/fw_loss           | 0.07241432629525661   |
| train_1/mu_grads          | -0.049235157947987315 |
| train_1/mu_grads_std      | 0.3172408379614353    |
| train_1/mu_loss           | 6.073172087350213     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.0638174484245795   |
| train_1/q_grads           | -0.052097327541559935 |
| train_1/q_grads_std       | 0.24529963061213494   |
| train_1/q_loss            | 0.4623801387394527    |
| train_1/reward            | -2.0929144006928255   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0025634765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.4644054236773485   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 408.50. Rollout time: 232.42, Training time: 176.05
Evaluating epoch 15
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 1455078.0              |
| test/episodes             | 400.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999282735329956    |
| test_1/avg_q              | -13.793452733819475    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.86046311034265     |
| train_0/current_q         | -9.307671913732856     |
| train_0/fw_bonus          | -0.9988602295517921    |
| train_0/fw_loss           | 0.005963606492150575   |
| train_0/mu_grads          | -0.008286728337407113  |
| train_0/mu_grads_std      | 0.3434426590800285     |
| train_0/mu_loss           | 9.29153567618701       |
| train_0/next_q            | -9.291534811437662     |
| train_0/q_grads           | 0.031510943081229925   |
| train_0/q_grads_std       | 0.2371405404061079     |
| train_0/q_loss            | 0.18229653412401764    |
| train_0/reward            | -0.7033973993631661    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.015185546875         |
| train_0/target_q          | -9.456856477850934     |
| train_1/avg_q             | -13.863131093194658    |
| train_1/current_q         | -8.178793243139754     |
| train_1/fw_bonus          | -0.9872986152768135    |
| train_1/fw_loss           | 0.07025824096053838    |
| train_1/mu_grads          | -0.0497773127630353    |
| train_1/mu_grads_std      | 0.3212607279419899     |
| train_1/mu_loss           | 5.772881445985817      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.7766880844442285    |
| train_1/q_grads           | -0.053106305189430714  |
| train_1/q_grads_std       | 0.24909172132611274    |
| train_1/q_loss            | 1.3003447609347145     |
| train_1/reward            | -2.1172943297468008    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021728515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -8.182836704249542     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 393.77. Rollout time: 219.94, Training time: 173.80
Evaluating epoch 16
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1546203.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999475507970807   |
| test_1/avg_q              | -13.830195460579615   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.74125470329869    |
| train_0/current_q         | -9.363481102304709    |
| train_0/fw_bonus          | -0.9988644927740097   |
| train_0/fw_loss           | 0.005943524336908012  |
| train_0/mu_grads          | -0.005689967016223818 |
| train_0/mu_grads_std      | 0.35211076512932776   |
| train_0/mu_loss           | 9.343014777928337     |
| train_0/next_q            | -9.343979295269403    |
| train_0/q_grads           | 0.02807975159958005   |
| train_0/q_grads_std       | 0.24270559065043926   |
| train_0/q_loss            | 0.1719436267194018    |
| train_0/reward            | -0.701360961971659    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01572265625         |
| train_0/target_q          | -9.520167272421222    |
| train_1/avg_q             | -13.91964295380313    |
| train_1/current_q         | -8.660967450358537    |
| train_1/fw_bonus          | -0.9878003388643265   |
| train_1/fw_loss           | 0.06795098707079887   |
| train_1/mu_grads          | -0.04955240758135915  |
| train_1/mu_grads_std      | 0.32451847195625305   |
| train_1/mu_loss           | 6.838267675784711     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.563723220172758    |
| train_1/q_grads           | -0.05299417525529861  |
| train_1/q_grads_std       | 0.2521372377872467    |
| train_1/q_loss            | 3.766447274135923     |
| train_1/reward            | -2.1327307321291302   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022705078125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.635646627148457    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 389.38. Rollout time: 218.64, Training time: 170.71
Evaluating epoch 17
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1637326.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.88181261636163     |
| test_1/avg_q              | -13.948121372020601    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -25.527208792694754    |
| train_0/current_q         | -9.369006947039463     |
| train_0/fw_bonus          | -0.9988501995801926    |
| train_0/fw_loss           | 0.006010756245814264   |
| train_0/mu_grads          | -0.0026959928683936594 |
| train_0/mu_grads_std      | 0.35918540358543394    |
| train_0/mu_loss           | 9.362921663523979      |
| train_0/next_q            | -9.36226463304852      |
| train_0/q_grads           | 0.02682984797284007    |
| train_0/q_grads_std       | 0.2467158917337656     |
| train_0/q_loss            | 0.21897644518624784    |
| train_0/reward            | -0.7000476567736769    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0170166015625        |
| train_0/target_q          | -9.515927874666499     |
| train_1/avg_q             | -13.986007592874866    |
| train_1/current_q         | -7.81261872131337      |
| train_1/fw_bonus          | -0.9873434454202652    |
| train_1/fw_loss           | 0.07005210127681494    |
| train_1/mu_grads          | -0.05080391289666295   |
| train_1/mu_grads_std      | 0.32367086708545684    |
| train_1/mu_loss           | 6.145999622457916      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.346289964750502     |
| train_1/q_grads           | -0.05414467519149184   |
| train_1/q_grads_std       | 0.25423949137330054    |
| train_1/q_loss            | 0.557485665477825      |
| train_1/reward            | -2.1092845156774276    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001904296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -7.805661824948396     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 388.39. Rollout time: 217.35, Training time: 171.02
Evaluating epoch 18
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1728451.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99499556585011     |
| test_1/avg_q              | -13.968975422271889    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.920668194168442    |
| train_0/current_q         | -9.453918519130564     |
| train_0/fw_bonus          | -0.9988647535443306    |
| train_0/fw_loss           | 0.005942279659211636   |
| train_0/mu_grads          | -0.0049690664513036605 |
| train_0/mu_grads_std      | 0.3654665522277355     |
| train_0/mu_loss           | 9.432820248268154      |
| train_0/next_q            | -9.431588584914866     |
| train_0/q_grads           | 0.028074756218120455   |
| train_0/q_grads_std       | 0.24908165596425533    |
| train_0/q_loss            | 0.17218637406630677    |
| train_0/reward            | -0.7027649028786982    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0207275390625        |
| train_0/target_q          | -9.604421154502301     |
| train_1/avg_q             | -13.849068085459598    |
| train_1/current_q         | -7.68676631674515      |
| train_1/fw_bonus          | -0.988432140648365     |
| train_1/fw_loss           | 0.0650454112328589     |
| train_1/mu_grads          | -0.05098454300314188   |
| train_1/mu_grads_std      | 0.32373339384794236    |
| train_1/mu_loss           | 6.245192073284133      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.163670735475797     |
| train_1/q_grads           | -0.05428436324000359   |
| train_1/q_grads_std       | 0.2546344891190529     |
| train_1/q_loss            | 0.3546730492294562     |
| train_1/reward            | -2.076039804276661     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.683576992234893     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 390.57. Rollout time: 217.99, Training time: 172.55
Evaluating epoch 19
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1819576.0             |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999990004696   |
| test_1/avg_q              | -13.881198328715545   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.991453950917933   |
| train_0/current_q         | -9.398375355115064    |
| train_0/fw_bonus          | -0.9988026350736618   |
| train_0/fw_loss           | 0.006234222569037229  |
| train_0/mu_grads          | -0.006845038151368499 |
| train_0/mu_grads_std      | 0.37087764516472815   |
| train_0/mu_loss           | 9.374165577273493     |
| train_0/next_q            | -9.373853687221347    |
| train_0/q_grads           | 0.029187824809923768  |
| train_0/q_grads_std       | 0.25338859409093856   |
| train_0/q_loss            | 0.1760395979867586    |
| train_0/reward            | -0.7047480026536505   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0220703125          |
| train_0/target_q          | -9.559933035014264    |
| train_1/avg_q             | -13.894212661791265   |
| train_1/current_q         | -8.082700641692497    |
| train_1/fw_bonus          | -0.9881054267287255   |
| train_1/fw_loss           | 0.06654796013608574   |
| train_1/mu_grads          | -0.05353210940957069  |
| train_1/mu_grads_std      | 0.3233879193663597    |
| train_1/mu_loss           | 6.200770061207633     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.571365191208976    |
| train_1/q_grads           | -0.05512894382700324  |
| train_1/q_grads_std       | 0.2569863900542259    |
| train_1/q_loss            | 0.49988025018655546   |
| train_1/reward            | -2.129306615972746    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0026123046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.071382339126497    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 394.36. Rollout time: 217.81, Training time: 176.52
Evaluating epoch 20
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1910701.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -17.508002104209698   |
| test_1/avg_q              | -14.329739294952272   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.648862683925625   |
| train_0/current_q         | -9.194652537999751    |
| train_0/fw_bonus          | -0.998863174021244    |
| train_0/fw_loss           | 0.005949735292233527  |
| train_0/mu_grads          | -0.004967886942904442 |
| train_0/mu_grads_std      | 0.3795683585107327    |
| train_0/mu_loss           | 9.166209783895887     |
| train_0/next_q            | -9.173190478223535    |
| train_0/q_grads           | 0.028551272582262754  |
| train_0/q_grads_std       | 0.25842284560203554   |
| train_0/q_loss            | 0.27446677936823705   |
| train_0/reward            | -0.7041435042789089   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.021435546875        |
| train_0/target_q          | -9.366733646766756    |
| train_1/avg_q             | -13.99415088794912    |
| train_1/current_q         | -9.82242889196176     |
| train_1/fw_bonus          | -0.9885088726878166   |
| train_1/fw_loss           | 0.06469261385500431   |
| train_1/mu_grads          | -0.05487638069316745  |
| train_1/mu_grads_std      | 0.3249192513525486    |
| train_1/mu_loss           | 6.807293917375747     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.561535647300845    |
| train_1/q_grads           | -0.05647349217906594  |
| train_1/q_grads_std       | 0.2623440630733967    |
| train_1/q_loss            | 2.341463527040638     |
| train_1/reward            | -2.1043618546253127   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0024658203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.883731643556928    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 428.39. Rollout time: 233.33, Training time: 195.03
Evaluating epoch 21
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 2001826.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999815580345   |
| test_1/avg_q              | -13.89533214245821    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -23.073423325086594   |
| train_0/current_q         | -9.462722182946777    |
| train_0/fw_bonus          | -0.9988573729991913   |
| train_0/fw_loss           | 0.005977059865836054  |
| train_0/mu_grads          | -0.006916759675368667 |
| train_0/mu_grads_std      | 0.3822373390197754    |
| train_0/mu_loss           | 9.459088766646435     |
| train_0/next_q            | -9.460109894384086    |
| train_0/q_grads           | 0.032559083122760055  |
| train_0/q_grads_std       | 0.263324985653162     |
| train_0/q_loss            | 0.26069892637545766   |
| train_0/reward            | -0.7066430383594706   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0118408203125       |
| train_0/target_q          | -9.630722293723291    |
| train_1/avg_q             | -14.121134572908028   |
| train_1/current_q         | -8.463796734007833    |
| train_1/fw_bonus          | -0.988884350657463    |
| train_1/fw_loss           | 0.06296583143994212   |
| train_1/mu_grads          | -0.05310796778649092  |
| train_1/mu_grads_std      | 0.3285141967236996    |
| train_1/mu_loss           | 6.376285869076801     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.022467771636022    |
| train_1/q_grads           | -0.0555261243134737   |
| train_1/q_grads_std       | 0.263219889998436     |
| train_1/q_loss            | 0.6785919169306996    |
| train_1/reward            | -2.0804895394096095   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0023193359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.443189546287838    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 475.02. Rollout time: 268.21, Training time: 206.75
Evaluating epoch 22
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 2092951.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.492856592554244   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99974577737748    |
| train_0/current_q         | -9.46382514693193     |
| train_0/fw_bonus          | -0.9988262176513671   |
| train_0/fw_loss           | 0.006123451248276979  |
| train_0/mu_grads          | -0.007945049996487796 |
| train_0/mu_grads_std      | 0.3873273603618145    |
| train_0/mu_loss           | 9.438290151264948     |
| train_0/next_q            | -9.439994121533054    |
| train_0/q_grads           | 0.03462099758908153   |
| train_0/q_grads_std       | 0.26693024188280107   |
| train_0/q_loss            | 0.1980869821648112    |
| train_0/reward            | -0.7086782448779558   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0258544921875       |
| train_0/target_q          | -9.614585763282102    |
| train_1/avg_q             | -14.08945554497054    |
| train_1/current_q         | -9.703999378169915    |
| train_1/fw_bonus          | -0.9884863331913948   |
| train_1/fw_loss           | 0.06479622917249798   |
| train_1/mu_grads          | -0.05378514900803566  |
| train_1/mu_grads_std      | 0.33225297182798386   |
| train_1/mu_loss           | 6.577889301168019     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.64107154421682     |
| train_1/q_grads           | -0.056375426799058916 |
| train_1/q_grads_std       | 0.2678056091070175    |
| train_1/q_loss            | 1.4238102733387208    |
| train_1/reward            | -2.1319995140933314   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020751953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.712497046473867    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 534.64. Rollout time: 303.38, Training time: 231.21
Evaluating epoch 23
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 2184076.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.00112076365169     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999825925511573    |
| train_0/current_q         | -9.444874016684683     |
| train_0/fw_bonus          | -0.9988915666937828    |
| train_0/fw_loss           | 0.005816333880648017   |
| train_0/mu_grads          | -0.0052328236517496405 |
| train_0/mu_grads_std      | 0.3931979775428772     |
| train_0/mu_loss           | 9.418551001987446      |
| train_0/next_q            | -9.417295752164344     |
| train_0/q_grads           | 0.03484340170398355    |
| train_0/q_grads_std       | 0.26860125064849855    |
| train_0/q_loss            | 0.1703702266612114     |
| train_0/reward            | -0.7075390447382233    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0103759765625        |
| train_0/target_q          | -9.59908232774606      |
| train_1/avg_q             | -14.106501316865728    |
| train_1/current_q         | -8.949156304279654     |
| train_1/fw_bonus          | -0.9884606450796127    |
| train_1/fw_loss           | 0.06491435505449772    |
| train_1/mu_grads          | -0.05457235472276807   |
| train_1/mu_grads_std      | 0.33434427082538604    |
| train_1/mu_loss           | 6.173731643685765      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.586927664095048     |
| train_1/q_grads           | -0.05652741314843297   |
| train_1/q_grads_std       | 0.2725576288998127     |
| train_1/q_loss            | 0.7721473608731065     |
| train_1/reward            | -2.102860693958064     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0030029296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -8.94229678491676      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 518.67. Rollout time: 288.17, Training time: 230.46
Evaluating epoch 24
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2275201.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999962247    |
| test_1/avg_q              | -14.171288562113677   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99995072829897    |
| train_0/current_q         | -9.34143112956398     |
| train_0/fw_bonus          | -0.9989024251699448   |
| train_0/fw_loss           | 0.005765274842269718  |
| train_0/mu_grads          | -0.005335272511001676 |
| train_0/mu_grads_std      | 0.39858398512005805   |
| train_0/mu_loss           | 9.313779779062589     |
| train_0/next_q            | -9.312803957285166    |
| train_0/q_grads           | 0.03310901531949639   |
| train_0/q_grads_std       | 0.2721285030245781    |
| train_0/q_loss            | 0.17077533844533727   |
| train_0/reward            | -0.7063115671808191   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01220703125         |
| train_0/target_q          | -9.485646650015573    |
| train_1/avg_q             | -14.00179898797569    |
| train_1/current_q         | -7.681069709732026    |
| train_1/fw_bonus          | -0.9872971698641777   |
| train_1/fw_loss           | 0.07026489451527596   |
| train_1/mu_grads          | -0.05403443528339267  |
| train_1/mu_grads_std      | 0.3356053106486797    |
| train_1/mu_loss           | 6.05512341954847      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.1698854181982385   |
| train_1/q_grads           | -0.05559065900743008  |
| train_1/q_grads_std       | 0.2762995459139347    |
| train_1/q_loss            | 0.2976354307339723    |
| train_1/reward            | -2.1273766130616423   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002734375           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.675288606699541    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 518.67. Rollout time: 278.99, Training time: 239.64
Evaluating epoch 25
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2366326.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999999475195    |
| test_1/avg_q              | -13.961272978116783   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999570051246167   |
| train_0/current_q         | -9.471106914559376    |
| train_0/fw_bonus          | -0.9989014327526092   |
| train_0/fw_loss           | 0.005769984680227935  |
| train_0/mu_grads          | -0.007763638976030052 |
| train_0/mu_grads_std      | 0.4024331301450729    |
| train_0/mu_loss           | 9.442699490638525     |
| train_0/next_q            | -9.44086488912081     |
| train_0/q_grads           | 0.03421587329357863   |
| train_0/q_grads_std       | 0.27358599230647085   |
| train_0/q_loss            | 0.18420202822055157   |
| train_0/reward            | -0.7095703434519237   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0087890625          |
| train_0/target_q          | -9.624152325701186    |
| train_1/avg_q             | -14.05591283245295    |
| train_1/current_q         | -8.072814458287855    |
| train_1/fw_bonus          | -0.9860823169350624   |
| train_1/fw_loss           | 0.07585170846432447   |
| train_1/mu_grads          | -0.05487085860222578  |
| train_1/mu_grads_std      | 0.33567751869559287   |
| train_1/mu_loss           | 6.068339045243081     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.667586196261084    |
| train_1/q_grads           | -0.05814050901681185  |
| train_1/q_grads_std       | 0.280131583660841     |
| train_1/q_loss            | 0.6140218358616987    |
| train_1/reward            | -2.0865470189884947   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.067563056467463    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 533.57. Rollout time: 306.74, Training time: 226.79
Evaluating epoch 26
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 2457451.0             |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999997738874427   |
| test_1/avg_q              | -14.143269606173048   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.997103650499678   |
| train_0/current_q         | -9.420906396177353    |
| train_0/fw_bonus          | -0.9989501565694809   |
| train_0/fw_loss           | 0.005540957709308713  |
| train_0/mu_grads          | -0.012135646818205715 |
| train_0/mu_grads_std      | 0.4037128910422325    |
| train_0/mu_loss           | 9.394538380662942     |
| train_0/next_q            | -9.392244314238525    |
| train_0/q_grads           | 0.03602320197969675   |
| train_0/q_grads_std       | 0.27881563603878023   |
| train_0/q_loss            | 0.1893442253155367    |
| train_0/reward            | -0.7094604326615809   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00927734375         |
| train_0/target_q          | -9.582722628873773    |
| train_1/avg_q             | -14.207560445957801   |
| train_1/current_q         | -8.126565356570485    |
| train_1/fw_bonus          | -0.9854082062840461   |
| train_1/fw_loss           | 0.07895181179046631   |
| train_1/mu_grads          | -0.05503297634422779  |
| train_1/mu_grads_std      | 0.336810053139925     |
| train_1/mu_loss           | 6.233423340197363     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.619852884261675    |
| train_1/q_grads           | -0.05770454192534089  |
| train_1/q_grads_std       | 0.285117793828249     |
| train_1/q_loss            | 1.1441394455310987    |
| train_1/reward            | -2.116776367046259    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021240234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.106306425537639    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 532.60. Rollout time: 308.34, Training time: 224.21
Evaluating epoch 27
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 2548576.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.044443085286861   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99678898312977    |
| train_0/current_q         | -9.599817920487672    |
| train_0/fw_bonus          | -0.9989376291632652   |
| train_0/fw_loss           | 0.005599927867297083  |
| train_0/mu_grads          | -0.015267028636299074 |
| train_0/mu_grads_std      | 0.40615138709545134   |
| train_0/mu_loss           | 9.58859471593561      |
| train_0/next_q            | -9.587390926882758    |
| train_0/q_grads           | 0.0363766354508698    |
| train_0/q_grads_std       | 0.2847511187195778    |
| train_0/q_loss            | 0.20275741370698325   |
| train_0/reward            | -0.7139219320881238   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0097412109375       |
| train_0/target_q          | -9.754168541511223    |
| train_1/avg_q             | -14.076200046395744   |
| train_1/current_q         | -7.787113747078837    |
| train_1/fw_bonus          | -0.9840334802865982   |
| train_1/fw_loss           | 0.08527380079030991   |
| train_1/mu_grads          | -0.05542186200618744  |
| train_1/mu_grads_std      | 0.33795063868165015   |
| train_1/mu_loss           | 5.903828656018047     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.241464566258887    |
| train_1/q_grads           | -0.05796854393556714  |
| train_1/q_grads_std       | 0.2881632000207901    |
| train_1/q_loss            | 0.5998297189350774    |
| train_1/reward            | -2.0899049267529337   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00244140625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.7906078245439785   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 496.36. Rollout time: 277.72, Training time: 218.60
Evaluating epoch 28
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2639701.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.954165034335238   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999995330222333   |
| train_0/current_q         | -9.460998902461906    |
| train_0/fw_bonus          | -0.9989138722419739   |
| train_0/fw_loss           | 0.005711547925602645  |
| train_0/mu_grads          | -0.01824600948020816  |
| train_0/mu_grads_std      | 0.4069490574300289    |
| train_0/mu_loss           | 9.438810232131576     |
| train_0/next_q            | -9.437802664655095    |
| train_0/q_grads           | 0.03653023913502693   |
| train_0/q_grads_std       | 0.28829932287335397   |
| train_0/q_loss            | 0.22124230063838918   |
| train_0/reward            | -0.7100892559756176   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.011865234375        |
| train_0/target_q          | -9.624980031277394    |
| train_1/avg_q             | -14.012111907652223   |
| train_1/current_q         | -7.887774225793677    |
| train_1/fw_bonus          | -0.9841268926858902   |
| train_1/fw_loss           | 0.08484424632042646   |
| train_1/mu_grads          | -0.056730262283235786 |
| train_1/mu_grads_std      | 0.3398936688899994    |
| train_1/mu_loss           | 6.0253338906774205    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.360850734216234    |
| train_1/q_grads           | -0.0587079799734056   |
| train_1/q_grads_std       | 0.29084900617599485   |
| train_1/q_loss            | 0.41729809228934955   |
| train_1/reward            | -2.104636689167819    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021240234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.876401304833616    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 485.72. Rollout time: 272.98, Training time: 212.70
Evaluating epoch 29
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2730586.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.058312690350498   |
| test_1/avg_q              | -13.944420730954104   |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.83898575625466    |
| train_0/current_q         | -9.495678664031656    |
| train_0/fw_bonus          | -0.9988853737711907   |
| train_0/fw_loss           | 0.005845399515237659  |
| train_0/mu_grads          | -0.023612334625795484 |
| train_0/mu_grads_std      | 0.40691944137215613   |
| train_0/mu_loss           | 9.480273669641276     |
| train_0/next_q            | -9.473323318778657    |
| train_0/q_grads           | 0.036746278032660486  |
| train_0/q_grads_std       | 0.29224768951535224   |
| train_0/q_loss            | 0.24100662514861698   |
| train_0/reward            | -0.7122112455203023   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.012353515625        |
| train_0/target_q          | -9.646348809035372    |
| train_1/avg_q             | -13.975024840613866   |
| train_1/current_q         | -8.638608051145791    |
| train_1/fw_bonus          | -0.983853654563427    |
| train_1/fw_loss           | 0.08610083293169737   |
| train_1/mu_grads          | -0.05672772377729416  |
| train_1/mu_grads_std      | 0.34037807434797285   |
| train_1/mu_loss           | 6.607071121524899     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.25072202980828     |
| train_1/q_grads           | -0.06056683491915464  |
| train_1/q_grads_std       | 0.2933450758457184    |
| train_1/q_loss            | 1.0853327842355172    |
| train_1/reward            | -2.1295244810389704   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.003703703703703704  |
| train_1/target_q          | -8.618122677048415    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 465.59. Rollout time: 266.20, Training time: 199.36
Evaluating epoch 30
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 30                   |
| policy/steps              | 2821313.0            |
| test/episodes             | 775.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -23.504424396779285  |
| test_1/avg_q              | -13.919887028863359  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -25.472323218091688  |
| train_0/current_q         | -9.611432785485075   |
| train_0/fw_bonus          | -0.9988218784332276  |
| train_0/fw_loss           | 0.006143865152262151 |
| train_0/mu_grads          | -0.02428070977330208 |
| train_0/mu_grads_std      | 0.4117100201547146   |
| train_0/mu_loss           | 9.61362722583066     |
| train_0/next_q            | -9.609733356564387   |
| train_0/q_grads           | 0.037164243403822184 |
| train_0/q_grads_std       | 0.3003935404121876   |
| train_0/q_loss            | 0.36719191276325625  |
| train_0/reward            | -0.718527146957058   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0102294921875      |
| train_0/target_q          | -9.752604359536267   |
| train_1/avg_q             | -14.141913254950284  |
| train_1/current_q         | -9.328623807568942   |
| train_1/fw_bonus          | -0.9821234673261643  |
| train_1/fw_loss           | 0.09405745752155781  |
| train_1/mu_grads          | -0.05591142699122429 |
| train_1/mu_grads_std      | 0.34349601045250894  |
| train_1/mu_loss           | 6.227474665232295    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -9.207691505718767   |
| train_1/q_grads           | -0.06128682978451252 |
| train_1/q_grads_std       | 0.2959403328597546   |
| train_1/q_loss            | 1.2765903510260757   |
| train_1/reward            | -2.0812961163661385  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015625            |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.006666666666666667 |
| train_1/target_q          | -9.412667235667408   |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 462.84. Rollout time: 265.79, Training time: 197.01
Evaluating epoch 31
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2912322.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999828234187735   |
| test_1/avg_q              | -13.899328682651777   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.82849795089222    |
| train_0/current_q         | -9.465333231650817    |
| train_0/fw_bonus          | -0.9987395286560059   |
| train_0/fw_loss           | 0.0065308160032145676 |
| train_0/mu_grads          | -0.0256861328613013   |
| train_0/mu_grads_std      | 0.4171079620718956    |
| train_0/mu_loss           | 9.409653037872559     |
| train_0/next_q            | -9.405251719312705    |
| train_0/q_grads           | 0.03834530189633369   |
| train_0/q_grads_std       | 0.3039308600127697    |
| train_0/q_loss            | 0.23907580548651958   |
| train_0/reward            | -0.7213058029388776   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0125244140625       |
| train_0/target_q          | -9.614923681564573    |
| train_1/avg_q             | -13.952235808625764   |
| train_1/current_q         | -7.574288223506954    |
| train_1/fw_bonus          | -0.9820155635476112   |
| train_1/fw_loss           | 0.09455375354737043   |
| train_1/mu_grads          | -0.0573480567894876   |
| train_1/mu_grads_std      | 0.34543041959404946   |
| train_1/mu_loss           | 6.12660856367444      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.094135099797446    |
| train_1/q_grads           | -0.06077146716415882  |
| train_1/q_grads_std       | 0.29705354049801824   |
| train_1/q_loss            | 0.6936521711529997    |
| train_1/reward            | -2.0959272144027636   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.002962962962962963  |
| train_1/target_q          | -7.58446126210296     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 510.74. Rollout time: 285.91, Training time: 224.79
Evaluating epoch 32
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 3003447.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.113879583186758   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.994860430018438   |
| train_0/current_q         | -9.44314887294924     |
| train_0/fw_bonus          | -0.9986861065030098   |
| train_0/fw_loss           | 0.0067819820018485185 |
| train_0/mu_grads          | -0.02671458930708468  |
| train_0/mu_grads_std      | 0.42034299597144126   |
| train_0/mu_loss           | 9.397433162689733     |
| train_0/next_q            | -9.39063256493947     |
| train_0/q_grads           | 0.03967092158272863   |
| train_0/q_grads_std       | 0.3078013211488724    |
| train_0/q_loss            | 0.259081772054094     |
| train_0/reward            | -0.7229026157423505   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01630859375         |
| train_0/target_q          | -9.579856653534218    |
| train_1/avg_q             | -14.13625327930069    |
| train_1/current_q         | -9.92651735194834     |
| train_1/fw_bonus          | -0.9809335559606552   |
| train_1/fw_loss           | 0.09952962268143892   |
| train_1/mu_grads          | -0.05793343000113964  |
| train_1/mu_grads_std      | 0.34739903062582017   |
| train_1/mu_loss           | 6.940683292765553     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -10.024847994749962   |
| train_1/q_grads           | -0.061393468361347917 |
| train_1/q_grads_std       | 0.2979808397591114    |
| train_1/q_loss            | 1.675263949708358     |
| train_1/reward            | -2.0928471509083466   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014404296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.907537087408471    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 531.07. Rollout time: 298.01, Training time: 233.02
Evaluating epoch 33
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 3094572.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999879133   |
| test_1/avg_q              | -13.893191724214255   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999997955395315   |
| train_0/current_q         | -9.504820198831334    |
| train_0/fw_bonus          | -0.9984573781490326   |
| train_0/fw_loss           | 0.007856831105891615  |
| train_0/mu_grads          | -0.029638608917593956 |
| train_0/mu_grads_std      | 0.42526681944727895   |
| train_0/mu_loss           | 9.449942177842397     |
| train_0/next_q            | -9.43982738373118     |
| train_0/q_grads           | 0.041044396348297596  |
| train_0/q_grads_std       | 0.31162973642349245   |
| train_0/q_loss            | 0.30436364891831025   |
| train_0/reward            | -0.7334327910633874   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0148193359375       |
| train_0/target_q          | -9.655620157766261    |
| train_1/avg_q             | -14.192911039741361   |
| train_1/current_q         | -9.893838033029093    |
| train_1/fw_bonus          | -0.9788565292954445   |
| train_1/fw_loss           | 0.10908139199018478   |
| train_1/mu_grads          | -0.057238537911325695 |
| train_1/mu_grads_std      | 0.3490371026098728    |
| train_1/mu_loss           | 6.612486712571555     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.90707928251822     |
| train_1/q_grads           | -0.06123377839103341  |
| train_1/q_grads_std       | 0.30097834542393687   |
| train_1/q_loss            | 1.178914159644578     |
| train_1/reward            | -2.1108516043612324   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.897519634339924    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 490.05. Rollout time: 285.35, Training time: 204.66
Evaluating epoch 34
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 34                   |
| policy/steps              | 3185557.0            |
| test/episodes             | 875.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.98955666314004   |
| test_1/avg_q              | -13.403814136735996  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3500.0               |
| train/success_rate        | 0.01                 |
| train_0/avg_q             | -26.98813589007667   |
| train_0/current_q         | -9.45723766036412    |
| train_0/fw_bonus          | -0.9982665285468102  |
| train_0/fw_loss           | 0.008753793477080763 |
| train_0/mu_grads          | -0.03205066993832588 |
| train_0/mu_grads_std      | 0.4311075933277607   |
| train_0/mu_loss           | 9.38567606260209     |
| train_0/next_q            | -9.371268434263541   |
| train_0/q_grads           | 0.0390389927662909   |
| train_0/q_grads_std       | 0.3135589867830276   |
| train_0/q_loss            | 0.38496606940042977  |
| train_0/reward            | -0.7442138258134946  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0182373046875      |
| train_0/target_q          | -9.59240321055039    |
| train_1/avg_q             | -13.992094421714583  |
| train_1/current_q         | -10.25206316378608   |
| train_1/fw_bonus          | -0.9763874650001526  |
| train_1/fw_loss           | 0.12043599635362626  |
| train_1/mu_grads          | -0.05865581212565303 |
| train_1/mu_grads_std      | 0.35102603286504747  |
| train_1/mu_loss           | 6.4970077409016      |
| train_1/n_subgoals        | 2695.0               |
| train_1/next_q            | -10.286655268305749  |
| train_1/q_grads           | -0.06220506047829986 |
| train_1/q_grads_std       | 0.3051424026489258   |
| train_1/q_loss            | 1.3825144395182234   |
| train_1/reward            | -2.130735239752539   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015625            |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.26069626915257   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 551.76. Rollout time: 321.13, Training time: 230.58
Evaluating epoch 35
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 35                   |
| policy/steps              | 3276682.0            |
| test/episodes             | 900.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999996639961505  |
| test_1/avg_q              | -14.301967662082639  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.6167894592756    |
| train_0/current_q         | -9.75610959994444    |
| train_0/fw_bonus          | -0.9980936720967293  |
| train_0/fw_loss           | 0.009566071978770196 |
| train_0/mu_grads          | -0.03281707977876067 |
| train_0/mu_grads_std      | 0.43505425229668615  |
| train_0/mu_loss           | 9.681269131639866    |
| train_0/next_q            | -9.668073124262103   |
| train_0/q_grads           | 0.03734152773395181  |
| train_0/q_grads_std       | 0.3198100969195366   |
| train_0/q_loss            | 0.3707408096268024   |
| train_0/reward            | -0.7513295540280523  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.014208984375       |
| train_0/target_q          | -9.906164535255778   |
| train_1/avg_q             | -13.930015172264921  |
| train_1/current_q         | -10.039640966054206  |
| train_1/fw_bonus          | -0.9723348304629326  |
| train_1/fw_loss           | 0.13907314669340848  |
| train_1/mu_grads          | -0.05952088162302971 |
| train_1/mu_grads_std      | 0.3533963993191719   |
| train_1/mu_loss           | 6.192695747506413    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -10.020705115146558  |
| train_1/q_grads           | -0.06333114951848984 |
| train_1/q_grads_std       | 0.3098913714289665   |
| train_1/q_loss            | 1.4527108302098726   |
| train_1/reward            | -2.078342705767864   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001611328125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.049291072428824  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 525.19. Rollout time: 302.31, Training time: 222.82
Evaluating epoch 36
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 3367807.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999476973478    |
| test_1/avg_q              | -14.156726349808377   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.744984876309314   |
| train_0/current_q         | -9.76084761620154     |
| train_0/fw_bonus          | -0.9980678901076316   |
| train_0/fw_loss           | 0.009687317279167473  |
| train_0/mu_grads          | -0.032194754015654324 |
| train_0/mu_grads_std      | 0.4392682433128357    |
| train_0/mu_loss           | 9.703568038383539     |
| train_0/next_q            | -9.68886219789184     |
| train_0/q_grads           | 0.037631109543144706  |
| train_0/q_grads_std       | 0.32424838542938234   |
| train_0/q_loss            | 0.42074536580419597   |
| train_0/reward            | -0.7553449744984391   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0137451171875       |
| train_0/target_q          | -9.910130443539785    |
| train_1/avg_q             | -14.090637062627014   |
| train_1/current_q         | -10.373838077254984   |
| train_1/fw_bonus          | -0.971481965482235    |
| train_1/fw_loss           | 0.14299524314701556   |
| train_1/mu_grads          | -0.060190612263977525 |
| train_1/mu_grads_std      | 0.35505944564938546   |
| train_1/mu_loss           | 6.2135257943685485    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -10.14965991609301    |
| train_1/q_grads           | -0.06535540129989385  |
| train_1/q_grads_std       | 0.3133114747703075    |
| train_1/q_loss            | 1.6552435799439658    |
| train_1/reward            | -2.0798327784556023   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.345258466809033   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 582.42. Rollout time: 342.55, Training time: 239.80
Evaluating epoch 37
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 37                   |
| policy/steps              | 3458932.0            |
| test/episodes             | 950.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999667055197982  |
| test_1/avg_q              | -13.653878772145248  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99943041522903   |
| train_0/current_q         | -10.017673633242698  |
| train_0/fw_bonus          | -0.9978840008378029  |
| train_0/fw_loss           | 0.010551453498192132 |
| train_0/mu_grads          | -0.03203552793711424 |
| train_0/mu_grads_std      | 0.4430682100355625   |
| train_0/mu_loss           | 9.956436507996028    |
| train_0/next_q            | -9.941225546003713   |
| train_0/q_grads           | 0.03936085607856512  |
| train_0/q_grads_std       | 0.32808473855257037  |
| train_0/q_loss            | 0.5868827900515325   |
| train_0/reward            | -0.7708536231722973  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0137939453125      |
| train_0/target_q          | -10.16645153272153   |
| train_1/avg_q             | -13.98646391727656   |
| train_1/current_q         | -9.700293999871638   |
| train_1/fw_bonus          | -0.9694212004542351  |
| train_1/fw_loss           | 0.15247219614684582  |
| train_1/mu_grads          | -0.06080874837934971 |
| train_1/mu_grads_std      | 0.35622203052043916  |
| train_1/mu_loss           | 6.196773191234044    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -9.237515142632935   |
| train_1/q_grads           | -0.0654799135401845  |
| train_1/q_grads_std       | 0.3136825703084469   |
| train_1/q_loss            | 0.8660542378059006   |
| train_1/reward            | -2.113201811876934   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.000830078125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -9.678099808374848   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 520.37. Rollout time: 296.66, Training time: 223.67
Evaluating epoch 38
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3549816.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -25.621729271760096   |
| test_1/avg_q              | -13.068486298491766   |
| test_1/n_subgoals         | 669.0                 |
| test_1/subgoal_succ_rate  | 0.0014947683109118087 |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.58437954159179    |
| train_0/current_q         | -9.978433358273406    |
| train_0/fw_bonus          | -0.9977401599287987   |
| train_0/fw_loss           | 0.011227432801388205  |
| train_0/mu_grads          | -0.031000494863837956 |
| train_0/mu_grads_std      | 0.4455688983201981    |
| train_0/mu_loss           | 9.861888514540187     |
| train_0/next_q            | -9.84168983834265     |
| train_0/q_grads           | 0.039663606137037274  |
| train_0/q_grads_std       | 0.3328299343585968    |
| train_0/q_loss            | 0.477186096764003     |
| train_0/reward            | -0.7873954734161088   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.017724609375        |
| train_0/target_q          | -10.125811501538609   |
| train_1/avg_q             | -13.939099492622077   |
| train_1/current_q         | -9.879182443615436    |
| train_1/fw_bonus          | -0.9659108757972718   |
| train_1/fw_loss           | 0.16861529126763344   |
| train_1/mu_grads          | -0.06135117150843143  |
| train_1/mu_grads_std      | 0.357161808013916     |
| train_1/mu_loss           | 5.972462498085035     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.473781994581785    |
| train_1/q_grads           | -0.06521110236644745  |
| train_1/q_grads_std       | 0.31637840047478677   |
| train_1/q_loss            | 1.8911730901851562    |
| train_1/reward            | -2.153817259283096    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007568359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0007407407407407407 |
| train_1/target_q          | -9.894538431776448    |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 39
Time for epoch 39: 548.22. Rollout time: 312.01, Training time: 236.16
Evaluating epoch 39
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 3640664.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.992381793387253   |
| test_1/avg_q              | -14.223920088221623   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.363676096123584   |
| train_0/current_q         | -10.200100536285529   |
| train_0/fw_bonus          | -0.9975591585040092   |
| train_0/fw_loss           | 0.012078060419298708  |
| train_0/mu_grads          | -0.02933604046702385  |
| train_0/mu_grads_std      | 0.4502349466085434    |
| train_0/mu_loss           | 10.078716594925309    |
| train_0/next_q            | -10.050693505604382   |
| train_0/q_grads           | 0.043682088144123554  |
| train_0/q_grads_std       | 0.34259624481201173   |
| train_0/q_loss            | 0.5597964975023064    |
| train_0/reward            | -0.801806926086283    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0109619140625       |
| train_0/target_q          | -10.352242652401676   |
| train_1/avg_q             | -13.954020996639285   |
| train_1/current_q         | -7.351648366211165    |
| train_1/fw_bonus          | -0.9607822507619858   |
| train_1/fw_loss           | 0.19220067225396634   |
| train_1/mu_grads          | -0.06083399150520563  |
| train_1/mu_grads_std      | 0.3602427840232849    |
| train_1/mu_loss           | 5.515746083934144     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.828288284903801    |
| train_1/q_grads           | -0.06637636721134185  |
| train_1/q_grads_std       | 0.3174552947282791    |
| train_1/q_loss            | 1.0601220096545103    |
| train_1/reward            | -2.1463335069827734   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000537109375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0044444444444444444 |
| train_1/target_q          | -7.531513673425539    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 40
Time for epoch 40: 596.18. Rollout time: 348.75, Training time: 247.35
Evaluating epoch 40
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 3731789.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.923233998887312   |
| test_1/avg_q              | -13.525293782123011   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.914767968620477   |
| train_0/current_q         | -10.033288886471357   |
| train_0/fw_bonus          | -0.9975826695561409   |
| train_0/fw_loss           | 0.011967600788921118  |
| train_0/mu_grads          | -0.03038241728208959  |
| train_0/mu_grads_std      | 0.45270720645785334   |
| train_0/mu_loss           | 9.882609980366263     |
| train_0/next_q            | -9.855460870022338    |
| train_0/q_grads           | 0.04346789894625545   |
| train_0/q_grads_std       | 0.34645785167813303   |
| train_0/q_loss            | 0.4722605435823576    |
| train_0/reward            | -0.8042600846318237   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0088623046875       |
| train_0/target_q          | -10.182632667459671   |
| train_1/avg_q             | -13.92338062503803    |
| train_1/current_q         | -8.841478063710804    |
| train_1/fw_bonus          | -0.9633960604667664   |
| train_1/fw_loss           | 0.18018036261200904   |
| train_1/mu_grads          | -0.061843893770128486 |
| train_1/mu_grads_std      | 0.3621268801391125    |
| train_1/mu_loss           | 6.274571774391679     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.299109969898392    |
| train_1/q_grads           | -0.06607354339212179  |
| train_1/q_grads_std       | 0.31975590661168096   |
| train_1/q_loss            | 0.5278126413740439    |
| train_1/reward            | -2.10682010206001     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007568359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.830224747815333    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 41
Time for epoch 41: 581.30. Rollout time: 335.23, Training time: 245.99
Evaluating epoch 41
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 3822863.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.281332164970507   |
| test_1/avg_q              | -12.589784274615193   |
| test_1/n_subgoals         | 678.0                 |
| test_1/subgoal_succ_rate  | 0.004424778761061947  |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.238743590498363   |
| train_0/current_q         | -10.07988649329179    |
| train_0/fw_bonus          | -0.9974838122725487   |
| train_0/fw_loss           | 0.012432167609222233  |
| train_0/mu_grads          | -0.03182932203635573  |
| train_0/mu_grads_std      | 0.4570182390511036    |
| train_0/mu_loss           | 9.931214842148874     |
| train_0/next_q            | -9.911900614919324    |
| train_0/q_grads           | 0.03968964600935578   |
| train_0/q_grads_std       | 0.35005337968468664   |
| train_0/q_loss            | 0.6173494354896532    |
| train_0/reward            | -0.8052116347222181   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0092041015625       |
| train_0/target_q          | -10.2090071269389     |
| train_1/avg_q             | -13.922930493381374   |
| train_1/current_q         | -9.82938334565792     |
| train_1/fw_bonus          | -0.9636941477656364   |
| train_1/fw_loss           | 0.17880950756371022   |
| train_1/mu_grads          | -0.06203279579058289  |
| train_1/mu_grads_std      | 0.36277599930763244   |
| train_1/mu_loss           | 6.04734019488718      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -9.386931871815275    |
| train_1/q_grads           | -0.06746950130909682  |
| train_1/q_grads_std       | 0.32384506314992906   |
| train_1/q_loss            | 1.2381351481356786    |
| train_1/reward            | -2.1296253988926765   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005615234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0007407407407407407 |
| train_1/target_q          | -9.862658194999273    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 42
Time for epoch 42: 592.75. Rollout time: 345.65, Training time: 247.04
Evaluating epoch 42
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 42                    |
| policy/steps              | 3913494.0             |
| test/episodes             | 1075.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -26.97715031978945    |
| test_1/avg_q              | -13.289668341209286   |
| test_1/n_subgoals         | 666.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.798227677630607   |
| train_0/current_q         | -10.120951002272175   |
| train_0/fw_bonus          | -0.9974309772253036   |
| train_0/fw_loss           | 0.012680504377931357  |
| train_0/mu_grads          | -0.028937972523272036 |
| train_0/mu_grads_std      | 0.46142068058252333   |
| train_0/mu_loss           | 9.973341016984245     |
| train_0/next_q            | -9.950902355750191    |
| train_0/q_grads           | 0.042603990994393826  |
| train_0/q_grads_std       | 0.354204823076725     |
| train_0/q_loss            | 0.48086922739217053   |
| train_0/reward            | -0.8046114829179715   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0110107421875       |
| train_0/target_q          | -10.266885806298262   |
| train_1/avg_q             | -13.676134064411318   |
| train_1/current_q         | -9.398499935361878    |
| train_1/fw_bonus          | -0.9624651163816452   |
| train_1/fw_loss           | 0.18446155600249767   |
| train_1/mu_grads          | -0.06346017681062222  |
| train_1/mu_grads_std      | 0.3638376951217651    |
| train_1/mu_loss           | 6.867716781910644     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -8.953772564079255    |
| train_1/q_grads           | -0.06745172273367643  |
| train_1/q_grads_std       | 0.3259801775217056    |
| train_1/q_loss            | 1.4124818876861238    |
| train_1/reward            | -2.0802682046909466   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005859375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.003703703703703704  |
| train_1/target_q          | -9.404793244348841    |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 43
Time for epoch 43: 583.20. Rollout time: 335.75, Training time: 247.39
Evaluating epoch 43
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 43                   |
| policy/steps              | 4004408.0            |
| test/episodes             | 1100.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999979652980766  |
| test_1/avg_q              | -13.62671023411045   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 4400.0               |
| train/success_rate        | 0.01                 |
| train_0/avg_q             | -26.952581911111192  |
| train_0/current_q         | -10.016046196748253  |
| train_0/fw_bonus          | -0.9974780291318893  |
| train_0/fw_loss           | 0.01245936646591872  |
| train_0/mu_grads          | -0.02936772131361067 |
| train_0/mu_grads_std      | 0.4657259576022625   |
| train_0/mu_loss           | 9.881288778275819    |
| train_0/next_q            | -9.863057127449641   |
| train_0/q_grads           | 0.04385949904099107  |
| train_0/q_grads_std       | 0.3599675498902798   |
| train_0/q_loss            | 0.40266432368001037  |
| train_0/reward            | -0.7900842290393484  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0130615234375      |
| train_0/target_q          | -10.17144015018681   |
| train_1/avg_q             | -13.853734765470811  |
| train_1/current_q         | -9.572831631925842   |
| train_1/fw_bonus          | -0.9642056360840797  |
| train_1/fw_loss           | 0.17645727284252644  |
| train_1/mu_grads          | -0.06305582895874977 |
| train_1/mu_grads_std      | 0.36359642297029493  |
| train_1/mu_loss           | 6.601603071547709    |
| train_1/n_subgoals        | 2693.0               |
| train_1/next_q            | -9.146934213978657   |
| train_1/q_grads           | -0.06805268209427595 |
| train_1/q_grads_std       | 0.3271123364567757   |
| train_1/q_loss            | 1.8181115344369594   |
| train_1/reward            | -2.0657454030530062  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0008056640625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -9.562294641788021   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 44
Time for epoch 44: 602.88. Rollout time: 356.33, Training time: 246.47
Evaluating epoch 44
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 4095533.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999996163171808   |
| test_1/avg_q              | -13.042618196235608   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.76550682305448    |
| train_0/current_q         | -9.833475771402508    |
| train_0/fw_bonus          | -0.9976488679647446   |
| train_0/fw_loss           | 0.011656453739851714  |
| train_0/mu_grads          | -0.029688127944245933 |
| train_0/mu_grads_std      | 0.46851263791322706   |
| train_0/mu_loss           | 9.712091178921577     |
| train_0/next_q            | -9.69604522325732     |
| train_0/q_grads           | 0.04574831081554294   |
| train_0/q_grads_std       | 0.3657403111457825    |
| train_0/q_loss            | 0.36666980526731896   |
| train_0/reward            | -0.7754235592226906   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0113525390625       |
| train_0/target_q          | -9.982096537599457    |
| train_1/avg_q             | -13.767963413698332   |
| train_1/current_q         | -8.314342262170761    |
| train_1/fw_bonus          | -0.9645608782768249   |
| train_1/fw_loss           | 0.17482369728386402   |
| train_1/mu_grads          | -0.06267089433968068  |
| train_1/mu_grads_std      | 0.3655377432703972    |
| train_1/mu_loss           | 5.990978737429849     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.7756515475245775   |
| train_1/q_grads           | -0.06741358563303948  |
| train_1/q_grads_std       | 0.3301292844116688    |
| train_1/q_loss            | 1.4761316539630416    |
| train_1/reward            | -2.0955738924421894   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.365260147054869    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 45
Time for epoch 45: 604.67. Rollout time: 360.49, Training time: 244.11
Evaluating epoch 45
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 4186658.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999998444261    |
| test_1/avg_q              | -13.686173957377807   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.98802743289205    |
| train_0/current_q         | -9.945758799079092    |
| train_0/fw_bonus          | -0.9977633908390999   |
| train_0/fw_loss           | 0.011118287942372263  |
| train_0/mu_grads          | -0.027347486419603228 |
| train_0/mu_grads_std      | 0.4718989171087742    |
| train_0/mu_loss           | 9.827099872773221     |
| train_0/next_q            | -9.811687928079015    |
| train_0/q_grads           | 0.046890970692038535  |
| train_0/q_grads_std       | 0.36946224197745325   |
| train_0/q_loss            | 0.3410349922863153    |
| train_0/reward            | -0.7722703668521718   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.013134765625        |
| train_0/target_q          | -10.099037657114607   |
| train_1/avg_q             | -13.917966209012366   |
| train_1/current_q         | -11.452862365062867   |
| train_1/fw_bonus          | -0.9634585723280906   |
| train_1/fw_loss           | 0.17989290952682496   |
| train_1/mu_grads          | -0.06347740981727838  |
| train_1/mu_grads_std      | 0.365740355104208     |
| train_1/mu_loss           | 6.806630554804039     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -11.259495423104493   |
| train_1/q_grads           | -0.06705615743994713  |
| train_1/q_grads_std       | 0.3316266521811485    |
| train_1/q_loss            | 2.274245813966119     |
| train_1/reward            | -2.1099153215916884   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000439453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.448590229937041   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 46
Time for epoch 46: 595.75. Rollout time: 360.76, Training time: 234.93
Evaluating epoch 46
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 4277783.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999340474   |
| test_1/avg_q              | -14.254495976616663   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.993040584665273   |
| train_0/current_q         | -9.837197370194541    |
| train_0/fw_bonus          | -0.9977031499147415   |
| train_0/fw_loss           | 0.011401373357512058  |
| train_0/mu_grads          | -0.027998729888349772 |
| train_0/mu_grads_std      | 0.47541837096214296   |
| train_0/mu_loss           | 9.705760884746566     |
| train_0/next_q            | -9.688814076222865    |
| train_0/q_grads           | 0.04723359057679773   |
| train_0/q_grads_std       | 0.3722947873175144    |
| train_0/q_loss            | 0.3259542223765687    |
| train_0/reward            | -0.773094740765373    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01103515625         |
| train_0/target_q          | -9.989353167590295    |
| train_1/avg_q             | -14.404479443088196   |
| train_1/current_q         | -12.696849036735586   |
| train_1/fw_bonus          | -0.9623316496610641   |
| train_1/fw_loss           | 0.18507533557713032   |
| train_1/mu_grads          | -0.06502398867160082  |
| train_1/mu_grads_std      | 0.3679002456367016    |
| train_1/mu_loss           | 6.87816690286863      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -12.826576879155056   |
| train_1/q_grads           | -0.06692025568336249  |
| train_1/q_grads_std       | 0.333502958714962     |
| train_1/q_loss            | 3.1476733249577133    |
| train_1/reward            | -2.1123547916744427   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0004638671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.714550953793427   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 608.58. Rollout time: 364.52, Training time: 243.99
Evaluating epoch 47
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 4368908.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.527927806864941   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.997277878601377   |
| train_0/current_q         | -9.906682833392114    |
| train_0/fw_bonus          | -0.9976434424519539   |
| train_0/fw_loss           | 0.011682029278017581  |
| train_0/mu_grads          | -0.031310612056404355 |
| train_0/mu_grads_std      | 0.47957364544272424   |
| train_0/mu_loss           | 9.781525946578569     |
| train_0/next_q            | -9.763008888753344    |
| train_0/q_grads           | 0.04759489465504885   |
| train_0/q_grads_std       | 0.3755673684179783    |
| train_0/q_loss            | 0.3220313526070513    |
| train_0/reward            | -0.7732479865735513   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.011767578125        |
| train_0/target_q          | -10.062085424631075   |
| train_1/avg_q             | -14.279314016035388   |
| train_1/current_q         | -6.610721767577982    |
| train_1/fw_bonus          | -0.9618233501911163   |
| train_1/fw_loss           | 0.1874128807336092    |
| train_1/mu_grads          | -0.06519732140004635  |
| train_1/mu_grads_std      | 0.37078356742858887   |
| train_1/mu_loss           | 4.969715743219951     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.3444853223844095   |
| train_1/q_grads           | -0.06823766976594925  |
| train_1/q_grads_std       | 0.3349670432507992    |
| train_1/q_loss            | 2.1421676261088147    |
| train_1/reward            | -2.094156304716307    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006103515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.070300528581049    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 586.74. Rollout time: 345.53, Training time: 241.16
Evaluating epoch 48
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4460033.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999136648   |
| test_1/avg_q              | -14.141398998969445   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99997190608488    |
| train_0/current_q         | -9.832883833297966    |
| train_0/fw_bonus          | -0.9978222891688346   |
| train_0/fw_loss           | 0.010841487813740969  |
| train_0/mu_grads          | -0.033617292810231444 |
| train_0/mu_grads_std      | 0.48344684541225436   |
| train_0/mu_loss           | 9.71169427150841      |
| train_0/next_q            | -9.697430516327032    |
| train_0/q_grads           | 0.04744951408356428   |
| train_0/q_grads_std       | 0.37892288342118263   |
| train_0/q_loss            | 0.317764602510711     |
| train_0/reward            | -0.765158702993358    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.013818359375        |
| train_0/target_q          | -9.988266039909382    |
| train_1/avg_q             | -13.886393913804254   |
| train_1/current_q         | -11.64432155698879    |
| train_1/fw_bonus          | -0.9630079001188279   |
| train_1/fw_loss           | 0.1819654442369938    |
| train_1/mu_grads          | -0.06607367936521769  |
| train_1/mu_grads_std      | 0.3718285284936428    |
| train_1/mu_loss           | 7.812409219748747     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -11.960022727050397   |
| train_1/q_grads           | -0.07036919705569744  |
| train_1/q_grads_std       | 0.33565801084041597   |
| train_1/q_loss            | 1.9059851205476008    |
| train_1/reward            | -2.15730961365407     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.69508982227246    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 798.55. Rollout time: 446.85, Training time: 351.55
Evaluating epoch 49
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 49                   |
| policy/steps              | 4551158.0            |
| test/episodes             | 1250.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.034111860169634  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99995294857639   |
| train_0/current_q         | -9.762007498097546   |
| train_0/fw_bonus          | -0.9979360416531563  |
| train_0/fw_loss           | 0.010306858364492655 |
| train_0/mu_grads          | -0.03553303638473153 |
| train_0/mu_grads_std      | 0.48794259801506995  |
| train_0/mu_loss           | 9.644771593940494    |
| train_0/next_q            | -9.630048633100085   |
| train_0/q_grads           | 0.04756300467997789  |
| train_0/q_grads_std       | 0.38246538788080214  |
| train_0/q_loss            | 0.3047364741272043   |
| train_0/reward            | -0.763201423350256   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0118896484375      |
| train_0/target_q          | -9.911850249116648   |
| train_1/avg_q             | -14.05599186314201   |
| train_1/current_q         | -10.473773885077794  |
| train_1/fw_bonus          | -0.9631297960877419  |
| train_1/fw_loss           | 0.18140488490462303  |
| train_1/mu_grads          | -0.06620801668614149 |
| train_1/mu_grads_std      | 0.37485925406217574  |
| train_1/mu_loss           | 6.952805097815992    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -10.506468611403193  |
| train_1/q_grads           | -0.06979942470788955 |
| train_1/q_grads_std       | 0.3390694119036198   |
| train_1/q_loss            | 1.0244261362904366   |
| train_1/reward            | -2.107932082886691   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.000439453125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.48108093029135   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 575.99. Rollout time: 341.65, Training time: 234.27
Evaluating epoch 50
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 50                   |
| policy/steps              | 4642283.0            |
| test/episodes             | 1275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.962863049814562  |
| test_1/avg_q              | -14.148962370928158  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -24.999210237426944  |
| train_0/current_q         | -9.570898192690466   |
| train_0/fw_bonus          | -0.9979632556438446  |
| train_0/fw_loss           | 0.010179015249013901 |
| train_0/mu_grads          | -0.03426134902983904 |
| train_0/mu_grads_std      | 0.4944394566118717   |
| train_0/mu_loss           | 9.54774275250752     |
| train_0/next_q            | -9.542472782185047   |
| train_0/q_grads           | 0.03489836435765028  |
| train_0/q_grads_std       | 0.38235127851366996  |
| train_0/q_loss            | 0.4541083593414662   |
| train_0/reward            | -0.7608224470342975  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.013525390625       |
| train_0/target_q          | -9.740139162933614   |
| train_1/avg_q             | -13.905456372260186  |
| train_1/current_q         | -10.901100709873937  |
| train_1/fw_bonus          | -0.9669330313801765  |
| train_1/fw_loss           | 0.1639147076755762   |
| train_1/mu_grads          | -0.06654226966202259 |
| train_1/mu_grads_std      | 0.3767537407577038   |
| train_1/mu_loss           | 6.949488402117611    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -11.085124257714037  |
| train_1/q_grads           | -0.06998652443289757 |
| train_1/q_grads_std       | 0.3432891696691513   |
| train_1/q_loss            | 2.5907339568641112   |
| train_1/reward            | -2.1487863391703286  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0005615234375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.040012280813713  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 634.09. Rollout time: 372.23, Training time: 261.81
Evaluating epoch 51
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 51                   |
| policy/steps              | 4733408.0            |
| test/episodes             | 1300.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.99999952537176   |
| test_1/avg_q              | -14.310755227766602  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5200.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.97916634430669   |
| train_0/current_q         | -9.598321879980213   |
| train_0/fw_bonus          | -0.9981712609529495  |
| train_0/fw_loss           | 0.009201465407386422 |
| train_0/mu_grads          | -0.03351330915465951 |
| train_0/mu_grads_std      | 0.49467468410730364  |
| train_0/mu_loss           | 9.543573410544155    |
| train_0/next_q            | -9.536202576048963   |
| train_0/q_grads           | 0.03583555882796645  |
| train_0/q_grads_std       | 0.3825052224099636   |
| train_0/q_loss            | 0.31901091013998983  |
| train_0/reward            | -0.7479259627099963  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.014453125          |
| train_0/target_q          | -9.752670693370556   |
| train_1/avg_q             | -14.121763696982622  |
| train_1/current_q         | -11.504074476737058  |
| train_1/fw_bonus          | -0.9681233540177345  |
| train_1/fw_loss           | 0.1584406614303589   |
| train_1/mu_grads          | -0.06716172713786364 |
| train_1/mu_grads_std      | 0.3780537135899067   |
| train_1/mu_loss           | 6.9586516145463495   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -11.729250158946021  |
| train_1/q_grads           | -0.07155238389968872 |
| train_1/q_grads_std       | 0.3475606955587864   |
| train_1/q_loss            | 3.4314806213329647   |
| train_1/reward            | -2.080301914822485   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.000927734375       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.51229207361757   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 796.19. Rollout time: 493.89, Training time: 302.21
Evaluating epoch 52
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 4824533.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.992348185392647   |
| test_1/avg_q              | -13.491956247516645   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99957726835019    |
| train_0/current_q         | -9.674257955932799    |
| train_0/fw_bonus          | -0.9983180180191994   |
| train_0/fw_loss           | 0.008511763857677579  |
| train_0/mu_grads          | -0.033656613621860745 |
| train_0/mu_grads_std      | 0.4959350794553757    |
| train_0/mu_loss           | 9.609442242287068     |
| train_0/next_q            | -9.601276908929492    |
| train_0/q_grads           | 0.03615403454750776   |
| train_0/q_grads_std       | 0.3832372136414051    |
| train_0/q_loss            | 0.28458370519211373   |
| train_0/reward            | -0.7417493418950472   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.012060546875        |
| train_0/target_q          | -9.823955138152376    |
| train_1/avg_q             | -14.104604181985703   |
| train_1/current_q         | -9.754048984816606    |
| train_1/fw_bonus          | -0.968555648624897    |
| train_1/fw_loss           | 0.15645268708467483   |
| train_1/mu_grads          | -0.06769741084426642  |
| train_1/mu_grads_std      | 0.3794572904706001    |
| train_1/mu_loss           | 6.0875862044898685    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -10.135242334639008   |
| train_1/q_grads           | -0.07089640945196152  |
| train_1/q_grads_std       | 0.3481406144797802    |
| train_1/q_loss            | 1.7347311040701119    |
| train_1/reward            | -2.1252690333225472   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.942693814376474    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 752.56. Rollout time: 475.17, Training time: 277.28
Evaluating epoch 53
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 53                   |
| policy/steps              | 4915643.0            |
| test/episodes             | 1350.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999746995018278  |
| test_1/avg_q              | -2.684534658192258   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5400.0               |
| train/success_rate        | 0.01                 |
| train_0/avg_q             | -26.998203095442708  |
| train_0/current_q         | -9.72329625680887    |
| train_0/fw_bonus          | -0.9982022687792778  |
| train_0/fw_loss           | 0.009055792307481169 |
| train_0/mu_grads          | -0.03322623651474714 |
| train_0/mu_grads_std      | 0.49951362833380697  |
| train_0/mu_loss           | 9.633795023692048    |
| train_0/next_q            | -9.625225617588047   |
| train_0/q_grads           | 0.03738976884633303  |
| train_0/q_grads_std       | 0.3844385229051113   |
| train_0/q_loss            | 0.28700415678886937  |
| train_0/reward            | -0.7446455628305557  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0116455078125      |
| train_0/target_q          | -9.875071865734766   |
| train_1/avg_q             | -13.325213267810195  |
| train_1/current_q         | -2.6879281094437157  |
| train_1/fw_bonus          | -0.9679534077644348  |
| train_1/fw_loss           | 0.15922217555344104  |
| train_1/mu_grads          | -0.06899064686149359 |
| train_1/mu_grads_std      | 0.378279972076416    |
| train_1/mu_loss           | 1.7795606741243746   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -1.6921390024682252  |
| train_1/q_grads           | -0.07005545012652874 |
| train_1/q_grads_std       | 0.3514945313334465   |
| train_1/q_loss            | 2.0125208936711623   |
| train_1/reward            | -2.1069259276504453  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.000927734375       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -3.3942369288434797  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 744.39. Rollout time: 491.95, Training time: 252.36
Evaluating epoch 54
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 5005770.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.97499603163151    |
| test_1/avg_q              | -15.237871828300065   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.11277659532331    |
| train_0/current_q         | -9.686507241346488    |
| train_0/fw_bonus          | -0.9982576549053193   |
| train_0/fw_loss           | 0.008795453794300556  |
| train_0/mu_grads          | -0.034488558676093815 |
| train_0/mu_grads_std      | 0.5028076618909836    |
| train_0/mu_loss           | 9.593429322294897     |
| train_0/next_q            | -9.585264444356179    |
| train_0/q_grads           | 0.040896630939096214  |
| train_0/q_grads_std       | 0.3880465097725391    |
| train_0/q_loss            | 0.29390105219239687   |
| train_0/reward            | -0.745662030265521    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0134521484375       |
| train_0/target_q          | -9.83564830230922     |
| train_1/avg_q             | -12.971181108745363   |
| train_1/current_q         | -7.8131168234738535   |
| train_1/fw_bonus          | -0.9708136916160583   |
| train_1/fw_loss           | 0.1460684545338154    |
| train_1/mu_grads          | -0.0699053704738617   |
| train_1/mu_grads_std      | 0.3791149914264679    |
| train_1/mu_loss           | 6.540393765953643     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.382419625815731    |
| train_1/q_grads           | -0.07046973202377557  |
| train_1/q_grads_std       | 0.35104009285569193   |
| train_1/q_loss            | 1.3834058610960298    |
| train_1/reward            | -2.1019839958469673   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.015185185185185185  |
| train_1/target_q          | -7.897559814224314    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 717.20. Rollout time: 463.24, Training time: 253.86
Evaluating epoch 55
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 5096895.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999933274068898   |
| test_1/avg_q              | -16.200047618864065   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.842480410359304   |
| train_0/current_q         | -9.653223035760934    |
| train_0/fw_bonus          | -0.9983543828129768   |
| train_0/fw_loss           | 0.008340868109371513  |
| train_0/mu_grads          | -0.036804816126823424 |
| train_0/mu_grads_std      | 0.5078333973884582    |
| train_0/mu_loss           | 9.559183212673709     |
| train_0/next_q            | -9.549496277763835    |
| train_0/q_grads           | 0.042417262122035025  |
| train_0/q_grads_std       | 0.38987568989396093   |
| train_0/q_loss            | 0.28705254570910765   |
| train_0/reward            | -0.748945257980813    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0107421875          |
| train_0/target_q          | -9.812121610378592    |
| train_1/avg_q             | -15.34995105208952    |
| train_1/current_q         | -14.559645386238618   |
| train_1/fw_bonus          | -0.9714565813541413   |
| train_1/fw_loss           | 0.14311198219656945   |
| train_1/mu_grads          | -0.06979356873780489  |
| train_1/mu_grads_std      | 0.3793318085372448    |
| train_1/mu_loss           | 16.13408716755787     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -16.159507445706407   |
| train_1/q_grads           | -0.07245187032967806  |
| train_1/q_grads_std       | 0.35444953888654707   |
| train_1/q_loss            | 2.6296738837321967    |
| train_1/reward            | -2.1023420595622158   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -14.542486082946889   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 713.43. Rollout time: 457.03, Training time: 256.30
Evaluating epoch 56
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 56                   |
| policy/steps              | 5188020.0            |
| test/episodes             | 1425.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999999999999805  |
| test_1/avg_q              | -13.953772610694648  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5700.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999977651128628  |
| train_0/current_q         | -9.690655325427503   |
| train_0/fw_bonus          | -0.9984245404601098  |
| train_0/fw_loss           | 0.008011114271357655 |
| train_0/mu_grads          | -0.03770257914438844 |
| train_0/mu_grads_std      | 0.5114764094352722   |
| train_0/mu_loss           | 9.591478581748012    |
| train_0/next_q            | -9.58178589418795    |
| train_0/q_grads           | 0.042448180448263886 |
| train_0/q_grads_std       | 0.3912084370851517   |
| train_0/q_loss            | 0.2799003976075477   |
| train_0/reward            | -0.7535213569273764  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0100830078125      |
| train_0/target_q          | -9.848391136724235   |
| train_1/avg_q             | -14.779234475988881  |
| train_1/current_q         | -12.806630371972403  |
| train_1/fw_bonus          | -0.9737676873803138  |
| train_1/fw_loss           | 0.13248369935899973  |
| train_1/mu_grads          | -0.06938112266361714 |
| train_1/mu_grads_std      | 0.3795791782438755   |
| train_1/mu_loss           | 13.78501305543669    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.913415686502066  |
| train_1/q_grads           | -0.0727303646504879  |
| train_1/q_grads_std       | 0.35827297419309617  |
| train_1/q_loss            | 1.099838058566823    |
| train_1/reward            | -2.104986875675968   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00126953125        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.834244687836456  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 710.52. Rollout time: 455.37, Training time: 255.03
Evaluating epoch 57
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 57                   |
| policy/steps              | 5279145.0            |
| test/episodes             | 1450.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.980870099535581  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999996360803  |
| train_0/current_q         | -9.718977947935498   |
| train_0/fw_bonus          | -0.9983956068754196  |
| train_0/fw_loss           | 0.008147175214253366 |
| train_0/mu_grads          | -0.03781278375536203 |
| train_0/mu_grads_std      | 0.5145368263125419   |
| train_0/mu_loss           | 9.62473328414973     |
| train_0/next_q            | -9.613072613780137   |
| train_0/q_grads           | 0.04271597377955914  |
| train_0/q_grads_std       | 0.39363662600517274  |
| train_0/q_loss            | 0.28344595376365717  |
| train_0/reward            | -0.7525425255458685  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.010498046875       |
| train_0/target_q          | -9.868186203235343   |
| train_1/avg_q             | -15.001921643821365  |
| train_1/current_q         | -12.786040538224345  |
| train_1/fw_bonus          | -0.974279873073101   |
| train_1/fw_loss           | 0.13012835048139096  |
| train_1/mu_grads          | -0.07072681710124015 |
| train_1/mu_grads_std      | 0.38012775778770447  |
| train_1/mu_loss           | 13.906510292419247   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.91355350265473   |
| train_1/q_grads           | -0.07359015718102455 |
| train_1/q_grads_std       | 0.36186864525079726  |
| train_1/q_loss            | 0.9994171830139177   |
| train_1/reward            | -2.121148724066006   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013427734375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.831413958785015  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 764.45. Rollout time: 491.84, Training time: 272.51
Evaluating epoch 58
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 58                   |
| policy/steps              | 5370270.0            |
| test/episodes             | 1475.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.846419334319904  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5900.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.66870237685373    |
| train_0/fw_bonus          | -0.9985461860895157  |
| train_0/fw_loss           | 0.007439498964231461 |
| train_0/mu_grads          | -0.03633623588830233 |
| train_0/mu_grads_std      | 0.5180701285600662   |
| train_0/mu_loss           | 9.576219873761692    |
| train_0/next_q            | -9.565168009551126   |
| train_0/q_grads           | 0.044831930007785556 |
| train_0/q_grads_std       | 0.39781835600733756  |
| train_0/q_loss            | 0.25762511639985386  |
| train_0/reward            | -0.7457452586022555  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0106689453125      |
| train_0/target_q          | -9.825107311757293   |
| train_1/avg_q             | -13.968352666852228  |
| train_1/current_q         | -12.764069831468847  |
| train_1/fw_bonus          | -0.9764491826295852  |
| train_1/fw_loss           | 0.12015216797590256  |
| train_1/mu_grads          | -0.07072360813617706 |
| train_1/mu_grads_std      | 0.38012394309043884  |
| train_1/mu_loss           | 13.95122450784304    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.954324928336376  |
| train_1/q_grads           | -0.07392088454216719 |
| train_1/q_grads_std       | 0.36532912850379945  |
| train_1/q_loss            | 0.9707300393872856   |
| train_1/reward            | -2.1041547705091945  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013916015625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.811040987477913  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 764.78. Rollout time: 492.83, Training time: 271.80
Evaluating epoch 59
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 59                   |
| policy/steps              | 5461395.0            |
| test/episodes             | 1500.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.184818143890181  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.729690692884942   |
| train_0/fw_bonus          | -0.9986663401126862  |
| train_0/fw_loss           | 0.006874786701519042 |
| train_0/mu_grads          | -0.03619136409834027 |
| train_0/mu_grads_std      | 0.5195786520838738   |
| train_0/mu_loss           | 9.633516782378285    |
| train_0/next_q            | -9.624012069484106   |
| train_0/q_grads           | 0.04435825124382973  |
| train_0/q_grads_std       | 0.3988983377814293   |
| train_0/q_loss            | 0.23183747875351784  |
| train_0/reward            | -0.741764812204201   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.012548828125       |
| train_0/target_q          | -9.887466528097647   |
| train_1/avg_q             | -13.955114860747504  |
| train_1/current_q         | -12.7469008351997    |
| train_1/fw_bonus          | -0.9774778753519058  |
| train_1/fw_loss           | 0.11542147435247899  |
| train_1/mu_grads          | -0.07065890096127987 |
| train_1/mu_grads_std      | 0.3803877666592598   |
| train_1/mu_loss           | 14.003592202830905   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.998099585916265  |
| train_1/q_grads           | -0.07507933396846056 |
| train_1/q_grads_std       | 0.3690018758177757   |
| train_1/q_loss            | 0.7860181458596479   |
| train_1/reward            | -2.1205870839723504  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0021240234375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.810368225386217  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 783.13. Rollout time: 503.21, Training time: 279.82
Evaluating epoch 60
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 60                   |
| policy/steps              | 5552520.0            |
| test/episodes             | 1525.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.01123562685808   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.60717372045507    |
| train_0/fw_bonus          | -0.9987122297286988  |
| train_0/fw_loss           | 0.006659170822240412 |
| train_0/mu_grads          | -0.0356895400211215  |
| train_0/mu_grads_std      | 0.5211985021829605   |
| train_0/mu_loss           | 9.51179578181445     |
| train_0/next_q            | -9.506179251037267   |
| train_0/q_grads           | 0.043960573803633454 |
| train_0/q_grads_std       | 0.3999457977712154   |
| train_0/q_loss            | 0.21117895138089054  |
| train_0/reward            | -0.7355865801677283  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0112060546875      |
| train_0/target_q          | -9.76009029393487    |
| train_1/avg_q             | -14.068891516143648  |
| train_1/current_q         | -12.694752981993622  |
| train_1/fw_bonus          | -0.9777578040957451  |
| train_1/fw_loss           | 0.1141341557726264   |
| train_1/mu_grads          | -0.07018683850765228 |
| train_1/mu_grads_std      | 0.3806990087032318   |
| train_1/mu_loss           | 13.9807674948175     |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.982697665984873  |
| train_1/q_grads           | -0.07588843014091254 |
| train_1/q_grads_std       | 0.3721541233360767   |
| train_1/q_loss            | 0.9422655528118018   |
| train_1/reward            | -2.1223627902232693  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0027099609375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.763075646805019  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 798.00. Rollout time: 525.33, Training time: 272.55
Evaluating epoch 61
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 5643645.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.096903238720929   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.674406079760569    |
| train_0/fw_bonus          | -0.9987349286675453   |
| train_0/fw_loss           | 0.006552451394964009  |
| train_0/mu_grads          | -0.036169597506523134 |
| train_0/mu_grads_std      | 0.5223961412906647    |
| train_0/mu_loss           | 9.581126853953146     |
| train_0/next_q            | -9.57349914416021     |
| train_0/q_grads           | 0.042876276560127734  |
| train_0/q_grads_std       | 0.4007508583366871    |
| train_0/q_loss            | 0.19786614587564588   |
| train_0/reward            | -0.7371726414799923   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0115478515625       |
| train_0/target_q          | -9.827955438172477    |
| train_1/avg_q             | -14.03418386715196    |
| train_1/current_q         | -12.608977340083129   |
| train_1/fw_bonus          | -0.9761353924870491   |
| train_1/fw_loss           | 0.1215952519327402    |
| train_1/mu_grads          | -0.07021131366491318  |
| train_1/mu_grads_std      | 0.3806823492050171    |
| train_1/mu_loss           | 13.96509932700729     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -13.964367845372323   |
| train_1/q_grads           | -0.07683139145374299  |
| train_1/q_grads_std       | 0.3754307508468628    |
| train_1/q_loss            | 0.9946298323498943    |
| train_1/reward            | -2.106707832541724    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.679778869461526   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 788.47. Rollout time: 511.39, Training time: 276.97
Evaluating epoch 62
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 5734770.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.961064129942955   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.730303151656637    |
| train_0/fw_bonus          | -0.998832818865776    |
| train_0/fw_loss           | 0.0060924265184439715 |
| train_0/mu_grads          | -0.03681382322683931  |
| train_0/mu_grads_std      | 0.5228942155838012    |
| train_0/mu_loss           | 9.641534541659468     |
| train_0/next_q            | -9.633964462231429    |
| train_0/q_grads           | 0.04234351385384798   |
| train_0/q_grads_std       | 0.4014605112373829    |
| train_0/q_loss            | 0.1919355181380314    |
| train_0/reward            | -0.7357933620965923   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01044921875         |
| train_0/target_q          | -9.88491856527492     |
| train_1/avg_q             | -14.019641711922644   |
| train_1/current_q         | -12.67506511572203    |
| train_1/fw_bonus          | -0.9777401342988015   |
| train_1/fw_loss           | 0.11421540845185518   |
| train_1/mu_grads          | -0.07021131366491318  |
| train_1/mu_grads_std      | 0.3806823492050171    |
| train_1/mu_loss           | 13.999758970697496    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.000384570204535   |
| train_1/q_grads           | -0.07815533448010684  |
| train_1/q_grads_std       | 0.37986068055033684   |
| train_1/q_loss            | 0.8927765410053409    |
| train_1/reward            | -2.0886869628979183   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002001953125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.733855500066005   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 867.35. Rollout time: 569.28, Training time: 297.93
Evaluating epoch 63
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 63                   |
| policy/steps              | 5825895.0            |
| test/episodes             | 1600.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.042373632660148  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.619252139958082   |
| train_0/fw_bonus          | -0.9988362848758697  |
| train_0/fw_loss           | 0.006076108885463327 |
| train_0/mu_grads          | -0.03789615174755454 |
| train_0/mu_grads_std      | 0.5224754571914673   |
| train_0/mu_loss           | 9.529149099623277    |
| train_0/next_q            | -9.522901589139908   |
| train_0/q_grads           | 0.041640504729002714 |
| train_0/q_grads_std       | 0.40243793874979017  |
| train_0/q_loss            | 0.19004864490488088  |
| train_0/reward            | -0.7326700982885086  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.010791015625       |
| train_0/target_q          | -9.772611543481862   |
| train_1/avg_q             | -13.991648546253165  |
| train_1/current_q         | -12.621713663317088  |
| train_1/fw_bonus          | -0.9780559837818146  |
| train_1/fw_loss           | 0.11276293192058802  |
| train_1/mu_grads          | -0.07021131366491318 |
| train_1/mu_grads_std      | 0.3806823492050171   |
| train_1/mu_loss           | 14.000601722384957   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.000672661556479  |
| train_1/q_grads           | -0.07936029881238937 |
| train_1/q_grads_std       | 0.3853213094174862   |
| train_1/q_loss            | 0.8079458920977147   |
| train_1/reward            | -2.1057150013788486  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002099609375       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.679994621755913  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 761.61. Rollout time: 504.31, Training time: 257.20
Evaluating epoch 64
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 64                   |
| policy/steps              | 5917020.0            |
| test/episodes             | 1625.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.000937562813792  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.566112596042458   |
| train_0/fw_bonus          | -0.9988577783107757  |
| train_0/fw_loss           | 0.005975146032869816 |
| train_0/mu_grads          | -0.03749919719994068 |
| train_0/mu_grads_std      | 0.5207196548581123   |
| train_0/mu_loss           | 9.47067432014837     |
| train_0/next_q            | -9.46371896244193    |
| train_0/q_grads           | 0.0411404138430953   |
| train_0/q_grads_std       | 0.40305581167340276  |
| train_0/q_loss            | 0.181812172439332    |
| train_0/reward            | -0.7313502732591587  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0087646484375      |
| train_0/target_q          | -9.718075057550427   |
| train_1/avg_q             | -14.088752628772248  |
| train_1/current_q         | -12.642428138347086  |
| train_1/fw_bonus          | -0.9783413335680962  |
| train_1/fw_loss           | 0.11145062744617462  |
| train_1/mu_grads          | -0.07021131366491318 |
| train_1/mu_grads_std      | 0.3806823492050171   |
| train_1/mu_loss           | 13.971734058475011   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.973157391061275  |
| train_1/q_grads           | -0.0806068131700158  |
| train_1/q_grads_std       | 0.3910421222448349   |
| train_1/q_loss            | 0.6396489864255575   |
| train_1/reward            | -2.1105818021896994  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002294921875       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.667017166559328  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 754.77. Rollout time: 491.08, Training time: 263.56
Evaluating epoch 65
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 6008145.0             |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.5750347639223     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.57316628992896     |
| train_0/fw_bonus          | -0.998821584880352    |
| train_0/fw_loss           | 0.006145254103466868  |
| train_0/mu_grads          | -0.038800699170678854 |
| train_0/mu_grads_std      | 0.5214155569672585    |
| train_0/mu_loss           | 9.472394134192383     |
| train_0/next_q            | -9.46387730561544     |
| train_0/q_grads           | 0.04037524908781052   |
| train_0/q_grads_std       | 0.40438142567873003   |
| train_0/q_loss            | 0.19551495611150496   |
| train_0/reward            | -0.7341519995745329   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00966796875         |
| train_0/target_q          | -9.722653222909527    |
| train_1/avg_q             | -14.05145444734957    |
| train_1/current_q         | -12.74508553588101    |
| train_1/fw_bonus          | -0.9775332763791085   |
| train_1/fw_loss           | 0.11516675688326358   |
| train_1/mu_grads          | -0.07019215822219849  |
| train_1/mu_grads_std      | 0.38069450855255127   |
| train_1/mu_loss           | 14.066390368927335    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.100852600737355   |
| train_1/q_grads           | -0.08090796787291765  |
| train_1/q_grads_std       | 0.39373346120119096   |
| train_1/q_loss            | 0.7320309416704956    |
| train_1/reward            | -2.0875215159292564   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020263671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.74299072069697    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 716.37. Rollout time: 462.57, Training time: 253.66
Evaluating epoch 66
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 6099270.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.075864719680926   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.53973481880519     |
| train_0/fw_bonus          | -0.99865602850914     |
| train_0/fw_loss           | 0.0069232900394126775 |
| train_0/mu_grads          | -0.040005773026496175 |
| train_0/mu_grads_std      | 0.52256388515234      |
| train_0/mu_loss           | 9.435749459792312     |
| train_0/next_q            | -9.425794052342784    |
| train_0/q_grads           | 0.03984686303883791   |
| train_0/q_grads_std       | 0.40530084893107415   |
| train_0/q_loss            | 0.21003682444542177   |
| train_0/reward            | -0.7398675621960138   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0100830078125       |
| train_0/target_q          | -9.686970095887947    |
| train_1/avg_q             | -14.182809515817032   |
| train_1/current_q         | -13.418105992243298   |
| train_1/fw_bonus          | -0.9759500026702881   |
| train_1/fw_loss           | 0.12244777660816908   |
| train_1/mu_grads          | -0.07018385082483292  |
| train_1/mu_grads_std      | 0.3807031810283661    |
| train_1/mu_loss           | 14.762522412357772    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.785932558880821   |
| train_1/q_grads           | -0.08191187214106321  |
| train_1/q_grads_std       | 0.3967409856617451    |
| train_1/q_loss            | 1.6393583211038423    |
| train_1/reward            | -2.0837757852787036   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.37868694271495    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 729.23. Rollout time: 470.57, Training time: 258.57
Evaluating epoch 67
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 6190395.0             |
| test/episodes             | 1700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.234331826044913   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.653940964685896    |
| train_0/fw_bonus          | -0.9985329374670983   |
| train_0/fw_loss           | 0.007501790428068489  |
| train_0/mu_grads          | -0.039398105815052986 |
| train_0/mu_grads_std      | 0.5244041472673416    |
| train_0/mu_loss           | 9.540699915889451     |
| train_0/next_q            | -9.53264857424799     |
| train_0/q_grads           | 0.039691660180687906  |
| train_0/q_grads_std       | 0.4064112715423107    |
| train_0/q_loss            | 0.2246124049569196    |
| train_0/reward            | -0.7466297442995711   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0098876953125       |
| train_0/target_q          | -9.806149563845945    |
| train_1/avg_q             | -13.674619671339622   |
| train_1/current_q         | -12.801399822564354   |
| train_1/fw_bonus          | -0.9716391742229462   |
| train_1/fw_loss           | 0.14227229356765747   |
| train_1/mu_grads          | -0.07017771154642105  |
| train_1/mu_grads_std      | 0.3807080388069153    |
| train_1/mu_loss           | 13.994375346061366    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.010992198844558   |
| train_1/q_grads           | -0.0838039018213749   |
| train_1/q_grads_std       | 0.3990617737174034    |
| train_1/q_loss            | 0.7381378740384451    |
| train_1/reward            | -2.097452885904204    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.794735322390348   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 725.52. Rollout time: 471.72, Training time: 253.72
Evaluating epoch 68
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 6281520.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.250504763452067   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.723971013325563    |
| train_0/fw_bonus          | -0.9984919711947441   |
| train_0/fw_loss           | 0.007694297446869313  |
| train_0/mu_grads          | -0.039984884206205606 |
| train_0/mu_grads_std      | 0.5263149380683899    |
| train_0/mu_loss           | 9.61231523727433      |
| train_0/next_q            | -9.602384797036358    |
| train_0/q_grads           | 0.03937065955251455   |
| train_0/q_grads_std       | 0.4073344022035599    |
| train_0/q_loss            | 0.23430434200579225   |
| train_0/reward            | -0.7533475442229246   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0092041015625       |
| train_0/target_q          | -9.88200173131482     |
| train_1/avg_q             | -14.018273511766257   |
| train_1/current_q         | -12.915514270162891   |
| train_1/fw_bonus          | -0.969945602118969    |
| train_1/fw_loss           | 0.15006062313914298   |
| train_1/mu_grads          | -0.06989063322544098  |
| train_1/mu_grads_std      | 0.3809160590171814    |
| train_1/mu_loss           | 13.971852233743414    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.117881989602102   |
| train_1/q_grads           | -0.08515343666076661  |
| train_1/q_grads_std       | 0.4004999965429306    |
| train_1/q_loss            | 0.6735526248394306    |
| train_1/reward            | -2.136022603278252    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.925355892951774   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 745.92. Rollout time: 479.33, Training time: 266.49
Evaluating epoch 69
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 69                   |
| policy/steps              | 6372645.0            |
| test/episodes             | 1750.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.750193685127867  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.69402204442965    |
| train_0/fw_bonus          | -0.9985191822052002  |
| train_0/fw_loss           | 0.00756641001207754  |
| train_0/mu_grads          | -0.03930626148357987 |
| train_0/mu_grads_std      | 0.5283511742949486   |
| train_0/mu_loss           | 9.57899714490008     |
| train_0/next_q            | -9.571248299191337   |
| train_0/q_grads           | 0.03909494671970606  |
| train_0/q_grads_std       | 0.40832222923636435  |
| train_0/q_loss            | 0.21885860448421432  |
| train_0/reward            | -0.7511272640316747  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0096435546875      |
| train_0/target_q          | -9.844993245538792   |
| train_1/avg_q             | -14.12169548044559   |
| train_1/current_q         | -12.924518352159144  |
| train_1/fw_bonus          | -0.9687555953860283  |
| train_1/fw_loss           | 0.1555331364274025   |
| train_1/mu_grads          | -0.0698043629527092  |
| train_1/mu_grads_std      | 0.3809811472892761   |
| train_1/mu_loss           | 13.99148706275609    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.174341252543849  |
| train_1/q_grads           | -0.08634645529091359 |
| train_1/q_grads_std       | 0.40371841117739676  |
| train_1/q_loss            | 0.5776971975285687   |
| train_1/reward            | -2.1154202811019784  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0021728515625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.92122969788264   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 788.38. Rollout time: 507.46, Training time: 280.82
Evaluating epoch 70
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 70                    |
| policy/steps              | 6463770.0             |
| test/episodes             | 1775.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.692141680421898   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.548442589393252    |
| train_0/fw_bonus          | -0.9985504299402237   |
| train_0/fw_loss           | 0.0074195844936184585 |
| train_0/mu_grads          | -0.03953285235911608  |
| train_0/mu_grads_std      | 0.5295573502779007    |
| train_0/mu_loss           | 9.434668237419887     |
| train_0/next_q            | -9.426594284487106    |
| train_0/q_grads           | 0.03886161064729095   |
| train_0/q_grads_std       | 0.4092296354472637    |
| train_0/q_loss            | 0.22051241703182273   |
| train_0/reward            | -0.7477981585507223   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0089599609375       |
| train_0/target_q          | -9.696839569735184    |
| train_1/avg_q             | -13.93280723177796    |
| train_1/current_q         | -12.874249798696436   |
| train_1/fw_bonus          | -0.9679609388113022   |
| train_1/fw_loss           | 0.15918766036629678   |
| train_1/mu_grads          | -0.06980433315038681  |
| train_1/mu_grads_std      | 0.3809811472892761    |
| train_1/mu_loss           | 13.919895191152511    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.100821429995653   |
| train_1/q_grads           | -0.08724500499665737  |
| train_1/q_grads_std       | 0.40687004551291467   |
| train_1/q_loss            | 0.5198581848951189    |
| train_1/reward            | -2.093074701025762    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002099609375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.883640501853415   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 729.47. Rollout time: 475.36, Training time: 254.02
Evaluating epoch 71
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 6554895.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.974653025204558   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.650420013889649    |
| train_0/fw_bonus          | -0.9985566481947898   |
| train_0/fw_loss           | 0.007390337542165071  |
| train_0/mu_grads          | -0.039416953641921285 |
| train_0/mu_grads_std      | 0.5304992154240609    |
| train_0/mu_loss           | 9.538788674063415     |
| train_0/next_q            | -9.52858917596539     |
| train_0/q_grads           | 0.03768286434933543   |
| train_0/q_grads_std       | 0.4099154002964497    |
| train_0/q_loss            | 0.21065629207141062   |
| train_0/reward            | -0.7480332035287575   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00859375            |
| train_0/target_q          | -9.805758285620206    |
| train_1/avg_q             | -13.910753160918073   |
| train_1/current_q         | -12.947534908369553   |
| train_1/fw_bonus          | -0.9685270667076111   |
| train_1/fw_loss           | 0.1565841492265463    |
| train_1/mu_grads          | -0.06980433315038681  |
| train_1/mu_grads_std      | 0.3809811472892761    |
| train_1/mu_loss           | 13.99735399438843     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.139474952005866   |
| train_1/q_grads           | -0.08734750412404538  |
| train_1/q_grads_std       | 0.40939109176397326   |
| train_1/q_loss            | 0.5828563483622042    |
| train_1/reward            | -2.143528665591293    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.946830583314247   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 728.08. Rollout time: 478.29, Training time: 249.70
Evaluating epoch 72
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 72                   |
| policy/steps              | 6646020.0            |
| test/episodes             | 1825.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.78603207424649   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.558729601077598   |
| train_0/fw_bonus          | -0.9985743001103401  |
| train_0/fw_loss           | 0.007307351473718882 |
| train_0/mu_grads          | -0.03757505863904953 |
| train_0/mu_grads_std      | 0.5325144991278649   |
| train_0/mu_loss           | 9.443503980209897    |
| train_0/next_q            | -9.436223184286012   |
| train_0/q_grads           | 0.03709384063258767  |
| train_0/q_grads_std       | 0.4110292121767998   |
| train_0/q_loss            | 0.21670191786085366  |
| train_0/reward            | -0.747211954757222   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0103515625         |
| train_0/target_q          | -9.70869290350372    |
| train_1/avg_q             | -14.019083601881759  |
| train_1/current_q         | -12.984246091055109  |
| train_1/fw_bonus          | -0.9682107031345367  |
| train_1/fw_loss           | 0.15803896002471446  |
| train_1/mu_grads          | -0.06980433315038681 |
| train_1/mu_grads_std      | 0.3809811472892761   |
| train_1/mu_loss           | 14.032983183834924   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.135220524301198  |
| train_1/q_grads           | -0.08690846543759108 |
| train_1/q_grads_std       | 0.411055625975132    |
| train_1/q_loss            | 0.697212669322833    |
| train_1/reward            | -2.0534046704990034  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0024658203125      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.98035406118467   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 733.05. Rollout time: 484.43, Training time: 248.52
Evaluating epoch 73
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 73                   |
| policy/steps              | 6737145.0            |
| test/episodes             | 1850.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.098946284980979  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.670365469082501   |
| train_0/fw_bonus          | -0.9985389515757561  |
| train_0/fw_loss           | 0.007473474985454231 |
| train_0/mu_grads          | -0.03768721958622336 |
| train_0/mu_grads_std      | 0.53518947660923     |
| train_0/mu_loss           | 9.557237890989109    |
| train_0/next_q            | -9.54692010884951    |
| train_0/q_grads           | 0.03650913015007973  |
| train_0/q_grads_std       | 0.4121645264327526   |
| train_0/q_loss            | 0.21666192067077192  |
| train_0/reward            | -0.7500263118250586  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.009521484375       |
| train_0/target_q          | -9.826610896282606   |
| train_1/avg_q             | -13.96802668731472   |
| train_1/current_q         | -12.958928797397155  |
| train_1/fw_bonus          | -0.9687167599797248  |
| train_1/fw_loss           | 0.15571178868412971  |
| train_1/mu_grads          | -0.06980396062135696 |
| train_1/mu_grads_std      | 0.3809813857078552   |
| train_1/mu_loss           | 13.984367462287299   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.048964006823109  |
| train_1/q_grads           | -0.08821625988930464 |
| train_1/q_grads_std       | 0.41414581909775733  |
| train_1/q_loss            | 0.6095625477015473   |
| train_1/reward            | -2.0734819124852946  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002001953125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.961383742871174  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 722.55. Rollout time: 465.06, Training time: 257.39
Evaluating epoch 74
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 74                   |
| policy/steps              | 6828270.0            |
| test/episodes             | 1875.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.842729946972726  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999999999986  |
| train_0/current_q         | -9.854166973381933   |
| train_0/fw_bonus          | -0.9982715144753456  |
| train_0/fw_loss           | 0.008730284357443451 |
| train_0/mu_grads          | -0.03739178199321032 |
| train_0/mu_grads_std      | 0.5376296952366829   |
| train_0/mu_loss           | 9.729322942295738    |
| train_0/next_q            | -9.72038707182529    |
| train_0/q_grads           | 0.035569214075803754 |
| train_0/q_grads_std       | 0.4136550985276699   |
| train_0/q_loss            | 0.2398757483665896   |
| train_0/reward            | -0.7597192566383455  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.009130859375       |
| train_0/target_q          | -10.007800005254575  |
| train_1/avg_q             | -14.03433019814268   |
| train_1/current_q         | -13.018762962906559  |
| train_1/fw_bonus          | -0.9639123052358627  |
| train_1/fw_loss           | 0.17780631892383097  |
| train_1/mu_grads          | -0.0697656199336052  |
| train_1/mu_grads_std      | 0.3810422420501709   |
| train_1/mu_loss           | 13.984272984922836   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.045497423920427  |
| train_1/q_grads           | -0.08935474567115306 |
| train_1/q_grads_std       | 0.41817198395729066  |
| train_1/q_loss            | 0.5310326615148908   |
| train_1/reward            | -2.0796001924849405  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0021728515625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.017756456721354  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 719.23. Rollout time: 467.25, Training time: 251.89
Evaluating epoch 75
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 75                   |
| policy/steps              | 6919395.0            |
| test/episodes             | 1900.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999999999999922  |
| test_1/avg_q              | -14.06243723464012   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999701156   |
| train_0/current_q         | -9.917889088609275   |
| train_0/fw_bonus          | -0.9981823861598969  |
| train_0/fw_loss           | 0.00914914885070175  |
| train_0/mu_grads          | -0.03818726595491171 |
| train_0/mu_grads_std      | 0.5397275373339653   |
| train_0/mu_loss           | 9.7867021845959      |
| train_0/next_q            | -9.775729677377964   |
| train_0/q_grads           | 0.0351899023167789   |
| train_0/q_grads_std       | 0.4162545226514339   |
| train_0/q_loss            | 0.26053966776902476  |
| train_0/reward            | -0.7670233256678329  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0081787109375      |
| train_0/target_q          | -10.071910606877612  |
| train_1/avg_q             | -13.90268845580121   |
| train_1/current_q         | -13.02793914102763   |
| train_1/fw_bonus          | -0.9611702755093574  |
| train_1/fw_loss           | 0.19041621014475824  |
| train_1/mu_grads          | -0.0697656199336052  |
| train_1/mu_grads_std      | 0.3810422420501709   |
| train_1/mu_loss           | 13.952090469547448   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.015958862896005  |
| train_1/q_grads           | -0.09053940828889609 |
| train_1/q_grads_std       | 0.4214965723454952   |
| train_1/q_loss            | 0.5098639271618668   |
| train_1/reward            | -2.101373714381771   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0019775390625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.027888736562517  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 745.07. Rollout time: 488.77, Training time: 256.20
Evaluating epoch 76
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 7010520.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.388575050317382   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999911978373    |
| train_0/current_q         | -9.870441676139793    |
| train_0/fw_bonus          | -0.9979268625378609   |
| train_0/fw_loss           | 0.010350049403496087  |
| train_0/mu_grads          | -0.037843940686434506 |
| train_0/mu_grads_std      | 0.5416897267103196    |
| train_0/mu_loss           | 9.735185282775655     |
| train_0/next_q            | -9.723223002926858    |
| train_0/q_grads           | 0.03552984166890383   |
| train_0/q_grads_std       | 0.4186425760388374    |
| train_0/q_loss            | 0.282883280423635     |
| train_0/reward            | -0.7694590352279193   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0094970703125       |
| train_0/target_q          | -10.024211817133033   |
| train_1/avg_q             | -13.966567629703768   |
| train_1/current_q         | -13.071800495648239   |
| train_1/fw_bonus          | -0.9586525812745095   |
| train_1/fw_loss           | 0.20199447497725487   |
| train_1/mu_grads          | -0.0697726458311081   |
| train_1/mu_grads_std      | 0.38103628158569336   |
| train_1/mu_loss           | 14.010564559072293    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.103662203490995   |
| train_1/q_grads           | -0.09139082096517086  |
| train_1/q_grads_std       | 0.4247930683195591    |
| train_1/q_loss            | 0.6179311083301791    |
| train_1/reward            | -2.0665577392894194   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.070102419254425   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 727.81. Rollout time: 467.89, Training time: 259.83
Evaluating epoch 77
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 77                   |
| policy/steps              | 7101645.0            |
| test/episodes             | 1950.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.96986310436421   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.833599833117367   |
| train_0/fw_bonus          | -0.9977344274520874  |
| train_0/fw_loss           | 0.011254404066130519 |
| train_0/mu_grads          | -0.03838448682799935 |
| train_0/mu_grads_std      | 0.5433594733476639   |
| train_0/mu_loss           | 9.694004906474085    |
| train_0/next_q            | -9.677775270427007   |
| train_0/q_grads           | 0.035614396911114454 |
| train_0/q_grads_std       | 0.4204790160059929   |
| train_0/q_loss            | 0.2675398002173889   |
| train_0/reward            | -0.7725854749623977  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0078125            |
| train_0/target_q          | -9.98671415748591    |
| train_1/avg_q             | -14.175020156830918  |
| train_1/current_q         | -13.083066084721187  |
| train_1/fw_bonus          | -0.9544724017381668  |
| train_1/fw_loss           | 0.22121820785105228  |
| train_1/mu_grads          | -0.06958930194377899 |
| train_1/mu_grads_std      | 0.381172776222229    |
| train_1/mu_loss           | 13.991835506942829   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.090641991651037  |
| train_1/q_grads           | -0.0920514116063714  |
| train_1/q_grads_std       | 0.42771405577659605  |
| train_1/q_loss            | 0.3872322068148672   |
| train_1/reward            | -2.0937767209819866  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015380859375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.080490979001166  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 610.15. Rollout time: 378.33, Training time: 231.74
Evaluating epoch 78
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 78                   |
| policy/steps              | 7192770.0            |
| test/episodes             | 1975.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.890474644719331  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7900.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.894002887139617   |
| train_0/fw_bonus          | -0.9975334241986274  |
| train_0/fw_loss           | 0.012199044111184776 |
| train_0/mu_grads          | -0.03983693448826671 |
| train_0/mu_grads_std      | 0.545964066684246    |
| train_0/mu_loss           | 9.742611984500135    |
| train_0/next_q            | -9.73145322311808    |
| train_0/q_grads           | 0.03491658577695489  |
| train_0/q_grads_std       | 0.4224920153617859   |
| train_0/q_loss            | 0.29699108868951896  |
| train_0/reward            | -0.7811885857045127  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0102294921875      |
| train_0/target_q          | -10.046401165929248  |
| train_1/avg_q             | -14.028130296814824  |
| train_1/current_q         | -13.046208137380892  |
| train_1/fw_bonus          | -0.9512519747018814  |
| train_1/fw_loss           | 0.2360281113535166   |
| train_1/mu_grads          | -0.06958930194377899 |
| train_1/mu_grads_std      | 0.381172776222229    |
| train_1/mu_loss           | 13.932866489167827   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.059796048183983  |
| train_1/q_grads           | -0.09297164510935545 |
| train_1/q_grads_std       | 0.4302490472793579   |
| train_1/q_loss            | 0.5983329932667827   |
| train_1/reward            | -2.0855991328637176  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015869140625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.040724577997509  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 605.05. Rollout time: 373.24, Training time: 231.75
Evaluating epoch 79
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 79                   |
| policy/steps              | 7283895.0            |
| test/episodes             | 2000.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.133497153542882  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999999089   |
| train_0/current_q         | -9.993327436561577   |
| train_0/fw_bonus          | -0.997582359611988   |
| train_0/fw_loss           | 0.011968999868258834 |
| train_0/mu_grads          | -0.04030104205012321 |
| train_0/mu_grads_std      | 0.5489734813570977   |
| train_0/mu_loss           | 9.855384077314152    |
| train_0/next_q            | -9.840982295291017   |
| train_0/q_grads           | 0.03431212930008769  |
| train_0/q_grads_std       | 0.42387695163488387  |
| train_0/q_loss            | 0.29509630496531974  |
| train_0/reward            | -0.7759152090809949  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0086669921875      |
| train_0/target_q          | -10.148682585525833  |
| train_1/avg_q             | -13.968934466473378  |
| train_1/current_q         | -13.075036505580636  |
| train_1/fw_bonus          | -0.9538646712899208  |
| train_1/fw_loss           | 0.22401295602321625  |
| train_1/mu_grads          | -0.06935884058475494 |
| train_1/mu_grads_std      | 0.38136613368988037  |
| train_1/mu_loss           | 13.971261209627485   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.095897913387159  |
| train_1/q_grads           | -0.0937143413349986  |
| train_1/q_grads_std       | 0.43300537914037707  |
| train_1/q_loss            | 0.4888799201477575   |
| train_1/reward            | -2.1053380961464425  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013916015625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.076666006266919  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 690.81. Rollout time: 433.10, Training time: 257.65
Evaluating epoch 80
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 80                   |
| policy/steps              | 7375020.0            |
| test/episodes             | 2025.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.949740942336701  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.762649352930222   |
| train_0/fw_bonus          | -0.997689999639988   |
| train_0/fw_loss           | 0.01146318402606994  |
| train_0/mu_grads          | -0.04007449448108673 |
| train_0/mu_grads_std      | 0.5521017372608185   |
| train_0/mu_loss           | 9.619758532494663    |
| train_0/next_q            | -9.605889754668794   |
| train_0/q_grads           | 0.03346542017534375  |
| train_0/q_grads_std       | 0.42495947927236555  |
| train_0/q_loss            | 0.26680092218440027  |
| train_0/reward            | -0.7711472467461136  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00771484375        |
| train_0/target_q          | -9.915400090101658   |
| train_1/avg_q             | -14.11685898027714   |
| train_1/current_q         | -13.159444228620156  |
| train_1/fw_bonus          | -0.95516267567873    |
| train_1/fw_loss           | 0.21804376132786274  |
| train_1/mu_grads          | -0.06935884058475494 |
| train_1/mu_grads_std      | 0.38136613368988037  |
| train_1/mu_loss           | 13.984724523310044   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.225820240925978  |
| train_1/q_grads           | -0.09405602179467679 |
| train_1/q_grads_std       | 0.435692723095417    |
| train_1/q_loss            | 0.38032540613570776  |
| train_1/reward            | -2.126128699634137   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00185546875        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.155235056824859  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 632.84. Rollout time: 410.34, Training time: 222.42
Evaluating epoch 81
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 7466086.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.731975498825742   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.876438917298804    |
| train_0/fw_bonus          | -0.997833751142025    |
| train_0/fw_loss           | 0.010787615203298628  |
| train_0/mu_grads          | -0.040094407927244904 |
| train_0/mu_grads_std      | 0.5546440824866294    |
| train_0/mu_loss           | 9.72658077144419      |
| train_0/next_q            | -9.71696099947668     |
| train_0/q_grads           | 0.03251831438392401   |
| train_0/q_grads_std       | 0.4263997867703438    |
| train_0/q_loss            | 0.2532889981444024    |
| train_0/reward            | -0.771182501079602    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0080322265625       |
| train_0/target_q          | -10.02665977284144    |
| train_1/avg_q             | -14.016983158037117   |
| train_1/current_q         | -13.15903519344786    |
| train_1/fw_bonus          | -0.9564537569880486   |
| train_1/fw_loss           | 0.2121063396334648    |
| train_1/mu_grads          | -0.06935884058475494  |
| train_1/mu_grads_std      | 0.38136613368988037   |
| train_1/mu_loss           | 13.957261505027066    |
| train_1/n_subgoals        | 2698.0                |
| train_1/next_q            | -14.104738977402935   |
| train_1/q_grads           | -0.09445445723831654  |
| train_1/q_grads_std       | 0.43776271492242813   |
| train_1/q_loss            | 0.6592723066080355    |
| train_1/reward            | -2.127250319189625    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.164185674084166   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 606.98. Rollout time: 380.92, Training time: 225.99
Evaluating epoch 82
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 82                   |
| policy/steps              | 7557211.0            |
| test/episodes             | 2075.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.857953560164757  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.69721077837187    |
| train_0/fw_bonus          | -0.9981023102998734  |
| train_0/fw_loss           | 0.009525526384823024 |
| train_0/mu_grads          | -0.04006251767277717 |
| train_0/mu_grads_std      | 0.5569400653243065   |
| train_0/mu_loss           | 9.557759362630957    |
| train_0/next_q            | -9.543573186654452   |
| train_0/q_grads           | 0.03165763225406408  |
| train_0/q_grads_std       | 0.4277931697666645   |
| train_0/q_loss            | 0.24521428775525117  |
| train_0/reward            | -0.7653475396189606  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007568359375       |
| train_0/target_q          | -9.848455804499336   |
| train_1/avg_q             | -13.973816204454499  |
| train_1/current_q         | -13.116292969922487  |
| train_1/fw_bonus          | -0.9590327709913253  |
| train_1/fw_loss           | 0.20024614818394185  |
| train_1/mu_grads          | -0.06935884058475494 |
| train_1/mu_grads_std      | 0.38136613368988037  |
| train_1/mu_loss           | 13.988320707423588   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.040513250055682  |
| train_1/q_grads           | -0.09487840551882983 |
| train_1/q_grads_std       | 0.4408155709505081   |
| train_1/q_loss            | 0.336587760453433    |
| train_1/reward            | -2.0995725329747073  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00146484375        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.115328877993102  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 604.98. Rollout time: 380.30, Training time: 224.61
Evaluating epoch 83
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 7648336.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.021433465821717   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.896688113955815    |
| train_0/fw_bonus          | -0.9982991650700569   |
| train_0/fw_loss           | 0.008600400516297669  |
| train_0/mu_grads          | -0.040047965571284296 |
| train_0/mu_grads_std      | 0.5592948108911514    |
| train_0/mu_loss           | 9.760667268885674     |
| train_0/next_q            | -9.749734557441077    |
| train_0/q_grads           | 0.03173576220870018   |
| train_0/q_grads_std       | 0.4282357953488827    |
| train_0/q_loss            | 0.24419673324823502   |
| train_0/reward            | -0.7620035833104339   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007568359375        |
| train_0/target_q          | -10.052829650799804   |
| train_1/avg_q             | -13.97876757103745    |
| train_1/current_q         | -13.09752819363971    |
| train_1/fw_bonus          | -0.961862999200821    |
| train_1/fw_loss           | 0.1872306026518345    |
| train_1/mu_grads          | -0.06935884058475494  |
| train_1/mu_grads_std      | 0.38136613368988037   |
| train_1/mu_loss           | 13.977308848127667    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.057980208487123   |
| train_1/q_grads           | -0.09535066988319159  |
| train_1/q_grads_std       | 0.44369944632053376   |
| train_1/q_loss            | 0.38073201000977985   |
| train_1/reward            | -2.0857044441516335   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.103554068850542   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 597.76. Rollout time: 375.94, Training time: 221.75
Evaluating epoch 84
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 84                   |
| policy/steps              | 7739461.0            |
| test/episodes             | 2125.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.406784118718438  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.724000508676713   |
| train_0/fw_bonus          | -0.9983886823058128  |
| train_0/fw_loss           | 0.008179725590161979 |
| train_0/mu_grads          | -0.03992745950818062 |
| train_0/mu_grads_std      | 0.5624289438128471   |
| train_0/mu_loss           | 9.592793686786132    |
| train_0/next_q            | -9.579962296081446   |
| train_0/q_grads           | 0.030525395972654225 |
| train_0/q_grads_std       | 0.4289836294949055   |
| train_0/q_loss            | 0.23807527056578923  |
| train_0/reward            | -0.7581420900336525  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00791015625        |
| train_0/target_q          | -9.877076976936468   |
| train_1/avg_q             | -14.026838778241252  |
| train_1/current_q         | -12.98682200533934   |
| train_1/fw_bonus          | -0.9611695453524589  |
| train_1/fw_loss           | 0.1904195725917816   |
| train_1/mu_grads          | -0.06928454339504242 |
| train_1/mu_grads_std      | 0.3815130293369293   |
| train_1/mu_loss           | 13.922648418076795   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.965715468242706  |
| train_1/q_grads           | -0.09605657234787941 |
| train_1/q_grads_std       | 0.4468287698924541   |
| train_1/q_loss            | 0.9543615112524737   |
| train_1/reward            | -2.114032038895675   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00205078125        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.002435241645827  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 589.30. Rollout time: 368.00, Training time: 221.23
Evaluating epoch 85
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 85                   |
| policy/steps              | 7830586.0            |
| test/episodes             | 2150.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.818730012431388  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.774055513005077   |
| train_0/fw_bonus          | -0.9983546003699303  |
| train_0/fw_loss           | 0.008339805842842907 |
| train_0/mu_grads          | -0.03985539088025689 |
| train_0/mu_grads_std      | 0.5654455691576004   |
| train_0/mu_loss           | 9.647222738203814    |
| train_0/next_q            | -9.633431318610196   |
| train_0/q_grads           | 0.030463526817038657 |
| train_0/q_grads_std       | 0.4300172969698906   |
| train_0/q_loss            | 0.23929352039334031  |
| train_0/reward            | -0.7588330665108515  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007568359375       |
| train_0/target_q          | -9.925437545320694   |
| train_1/avg_q             | -13.784264823087495  |
| train_1/current_q         | -12.98795796616464   |
| train_1/fw_bonus          | -0.9596356466412544  |
| train_1/fw_loss           | 0.19747362956404685  |
| train_1/mu_grads          | -0.0694231241941452  |
| train_1/mu_grads_std      | 0.38177475333213806  |
| train_1/mu_loss           | 13.98246564872223    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -13.992539045668389  |
| train_1/q_grads           | -0.09711643252521754 |
| train_1/q_grads_std       | 0.4501497268676758   |
| train_1/q_loss            | 0.6520568196387189   |
| train_1/reward            | -2.0896444830788825  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013916015625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.994241671731023  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 603.51. Rollout time: 375.09, Training time: 228.33
Evaluating epoch 86
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 86                   |
| policy/steps              | 7921451.0            |
| test/episodes             | 2175.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.174384038531452  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8700.0               |
| train/success_rate        | 0.01                 |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.71756986828612    |
| train_0/fw_bonus          | -0.9983610093593598  |
| train_0/fw_loss           | 0.008309748442843556 |
| train_0/mu_grads          | -0.04021617379039526 |
| train_0/mu_grads_std      | 0.5681688517332077   |
| train_0/mu_loss           | 9.587539809546822    |
| train_0/next_q            | -9.576061359904653   |
| train_0/q_grads           | 0.029799143644049765 |
| train_0/q_grads_std       | 0.43123736679553987  |
| train_0/q_loss            | 0.23360393062337065  |
| train_0/reward            | -0.7579573578295822  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.008447265625       |
| train_0/target_q          | -9.87062758894526    |
| train_1/avg_q             | -13.962748519181659  |
| train_1/current_q         | -13.015535751684894  |
| train_1/fw_bonus          | -0.9587163284420968  |
| train_1/fw_loss           | 0.20170130021870136  |
| train_1/mu_grads          | -0.0694231241941452  |
| train_1/mu_grads_std      | 0.38177475333213806  |
| train_1/mu_loss           | 13.995544142020725   |
| train_1/n_subgoals        | 2691.0               |
| train_1/next_q            | -14.02802179039892   |
| train_1/q_grads           | -0.0970191102474928  |
| train_1/q_grads_std       | 0.45423632860183716  |
| train_1/q_loss            | 0.41547083874020974  |
| train_1/reward            | -2.064465590546024   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015380859375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.016128790846688  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 598.12. Rollout time: 369.36, Training time: 228.69
Evaluating epoch 87
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 8012397.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.13054569659374    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.810312508658763    |
| train_0/fw_bonus          | -0.9980499133467674   |
| train_0/fw_loss           | 0.009771776269190013  |
| train_0/mu_grads          | -0.039691900555044415 |
| train_0/mu_grads_std      | 0.570770862698555     |
| train_0/mu_loss           | 9.672894399799205     |
| train_0/next_q            | -9.66012280392319     |
| train_0/q_grads           | 0.02923900745809078   |
| train_0/q_grads_std       | 0.4322694294154644    |
| train_0/q_loss            | 0.26148886693540074   |
| train_0/reward            | -0.7650161645949993   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007275390625        |
| train_0/target_q          | -9.96346563704471     |
| train_1/avg_q             | -14.087092070155478   |
| train_1/current_q         | -12.996817583717586   |
| train_1/fw_bonus          | -0.9547239229083061   |
| train_1/fw_loss           | 0.22006147280335425   |
| train_1/mu_grads          | -0.06942346692085266  |
| train_1/mu_grads_std      | 0.381774365901947     |
| train_1/mu_loss           | 13.979695939858066    |
| train_1/n_subgoals        | 2694.0                |
| train_1/next_q            | -14.075315879451011   |
| train_1/q_grads           | -0.09762650579214097  |
| train_1/q_grads_std       | 0.45692554861307144   |
| train_1/q_loss            | 0.5375063945196884    |
| train_1/reward            | -2.127447408734588    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.99843707932239    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 594.51. Rollout time: 368.48, Training time: 225.94
Evaluating epoch 88
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 88                   |
| policy/steps              | 8103522.0            |
| test/episodes             | 2225.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.9215685035043    |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8900.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.820654078516597   |
| train_0/fw_bonus          | -0.9980984807014466  |
| train_0/fw_loss           | 0.009543494204990566 |
| train_0/mu_grads          | -0.03902672231197357 |
| train_0/mu_grads_std      | 0.5725140824913979   |
| train_0/mu_loss           | 9.680084760588644    |
| train_0/next_q            | -9.67119381719468    |
| train_0/q_grads           | 0.028507743822410704 |
| train_0/q_grads_std       | 0.43343936577439307  |
| train_0/q_loss            | 0.24934391882209606  |
| train_0/reward            | -0.7660780499012617  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0076904296875      |
| train_0/target_q          | -9.974043131462384   |
| train_1/avg_q             | -14.08777794282726   |
| train_1/current_q         | -12.960339930418268  |
| train_1/fw_bonus          | -0.9554629638791085  |
| train_1/fw_loss           | 0.2166627675294876   |
| train_1/mu_grads          | -0.06942403316497803 |
| train_1/mu_grads_std      | 0.38177379965782166  |
| train_1/mu_loss           | 13.965113407300976   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.044158078559423  |
| train_1/q_grads           | -0.09774200823158026 |
| train_1/q_grads_std       | 0.460124858468771    |
| train_1/q_loss            | 0.4732015690966131   |
| train_1/reward            | -2.1012422262683685  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001904296875       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.960804077661106  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 598.04. Rollout time: 374.00, Training time: 223.95
Evaluating epoch 89
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 8194647.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.911777048690322   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.881677447790633    |
| train_0/fw_bonus          | -0.9980700388550758   |
| train_0/fw_loss           | 0.009677186445333063  |
| train_0/mu_grads          | -0.038660017494112256 |
| train_0/mu_grads_std      | 0.57463488727808      |
| train_0/mu_loss           | 9.733685150162824     |
| train_0/next_q            | -9.724641700752027    |
| train_0/q_grads           | 0.02732448894530535   |
| train_0/q_grads_std       | 0.4346025101840496    |
| train_0/q_loss            | 0.26367711113586884   |
| train_0/reward            | -0.7711785721185151   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0077880859375       |
| train_0/target_q          | -10.030846827876156   |
| train_1/avg_q             | -14.020943272025615   |
| train_1/current_q         | -13.148967176393512   |
| train_1/fw_bonus          | -0.9574119195342063   |
| train_1/fw_loss           | 0.20770002007484437   |
| train_1/mu_grads          | -0.06943203508853912  |
| train_1/mu_grads_std      | 0.3817675709724426    |
| train_1/mu_loss           | 14.02214786280596     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.211513804384335   |
| train_1/q_grads           | -0.09850252959877252  |
| train_1/q_grads_std       | 0.46544093564152716   |
| train_1/q_loss            | 0.6614624192008153    |
| train_1/reward            | -2.1256786150326663   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -13.157189519188126   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 604.87. Rollout time: 380.46, Training time: 224.31
Evaluating epoch 90
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 90                   |
| policy/steps              | 8285772.0            |
| test/episodes             | 2275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999999999999993  |
| test_1/avg_q              | -13.78444277056111   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.901647910856601   |
| train_0/fw_bonus          | -0.9981909841299057  |
| train_0/fw_loss           | 0.009108784329146146 |
| train_0/mu_grads          | -0.03927104854956269 |
| train_0/mu_grads_std      | 0.5758407667279244   |
| train_0/mu_loss           | 9.758698869040856    |
| train_0/next_q            | -9.749411519096084   |
| train_0/q_grads           | 0.027114485390484333 |
| train_0/q_grads_std       | 0.4353061057627201   |
| train_0/q_loss            | 0.24995977145500667  |
| train_0/reward            | -0.7655505690447171  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0066162109375      |
| train_0/target_q          | -10.054710329078256  |
| train_1/avg_q             | -14.04778104484269   |
| train_1/current_q         | -14.313318590937394  |
| train_1/fw_bonus          | -0.9603856071829796  |
| train_1/fw_loss           | 0.194024708122015    |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 14.056750517436504   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -15.801143121165595  |
| train_1/q_grads           | -0.09928497038781643 |
| train_1/q_grads_std       | 0.4753171421587467   |
| train_1/q_loss            | 1.5012286606445644   |
| train_1/reward            | -2.09552483755906    |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0016357421875      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -14.340615251350533  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 618.75. Rollout time: 389.42, Training time: 229.24
Evaluating epoch 91
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 91                   |
| policy/steps              | 8376897.0            |
| test/episodes             | 2300.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.884506638910382  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9200.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999999993   |
| train_0/current_q         | -9.848328082729193   |
| train_0/fw_bonus          | -0.9982142433524132  |
| train_0/fw_loss           | 0.008999503694940358 |
| train_0/mu_grads          | -0.03840315164998174 |
| train_0/mu_grads_std      | 0.5775029972195626   |
| train_0/mu_loss           | 9.69834213041545     |
| train_0/next_q            | -9.68863625306271    |
| train_0/q_grads           | 0.02597678145393729  |
| train_0/q_grads_std       | 0.4363092087209225   |
| train_0/q_loss            | 0.2205423827863683   |
| train_0/reward            | -0.765110535830172   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0065185546875      |
| train_0/target_q          | -10.00423884899468   |
| train_1/avg_q             | -14.028946397267587  |
| train_1/current_q         | -13.93259367768788   |
| train_1/fw_bonus          | -0.9610773086547851  |
| train_1/fw_loss           | 0.1908437941223383   |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 14.122404795047558   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -15.283244029812977  |
| train_1/q_grads           | -0.100497424043715   |
| train_1/q_grads_std       | 0.4837100826203823   |
| train_1/q_loss            | 1.4717291032565953   |
| train_1/reward            | -2.100167557172972   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00185546875        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.92033812950576   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 595.33. Rollout time: 371.44, Training time: 223.82
Evaluating epoch 92
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 92                   |
| policy/steps              | 8468022.0            |
| test/episodes             | 2325.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.879010363453858  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.9999999999992    |
| train_0/current_q         | -9.806555396275431   |
| train_0/fw_bonus          | -0.9983713731169701  |
| train_0/fw_loss           | 0.00826101521961391  |
| train_0/mu_grads          | -0.04004305610433221 |
| train_0/mu_grads_std      | 0.5797057583928108   |
| train_0/mu_loss           | 9.664961562538199    |
| train_0/next_q            | -9.653833482026219   |
| train_0/q_grads           | 0.02590542649850249  |
| train_0/q_grads_std       | 0.4370930127799511   |
| train_0/q_loss            | 0.2228947281598268   |
| train_0/reward            | -0.7613316831178963  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0060791015625      |
| train_0/target_q          | -9.95849141121663    |
| train_1/avg_q             | -14.009899228810747  |
| train_1/current_q         | -13.30377076418423   |
| train_1/fw_bonus          | -0.9630430743098259  |
| train_1/fw_loss           | 0.18180364109575747  |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 14.045555499626516   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.432727506820331  |
| train_1/q_grads           | -0.10089701134711504 |
| train_1/q_grads_std       | 0.48856273368000985  |
| train_1/q_loss            | 1.1044859754464005   |
| train_1/reward            | -2.081484919181821   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00224609375        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.314369240976564  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 594.70. Rollout time: 369.58, Training time: 225.05
Evaluating epoch 93
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 93                   |
| policy/steps              | 8559147.0            |
| test/episodes             | 2350.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.913989409118253  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999999996   |
| train_0/current_q         | -9.84136035575737    |
| train_0/fw_bonus          | -0.9983184099197387  |
| train_0/fw_loss           | 0.00850996260996908  |
| train_0/mu_grads          | -0.0398723628371954  |
| train_0/mu_grads_std      | 0.5818885579705239   |
| train_0/mu_loss           | 9.70651509937639     |
| train_0/next_q            | -9.698530677814329   |
| train_0/q_grads           | 0.0254676581826061   |
| train_0/q_grads_std       | 0.43748695179820063  |
| train_0/q_loss            | 0.22517714247034726  |
| train_0/reward            | -0.7566787325769837  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007421875          |
| train_0/target_q          | -9.994973428935182   |
| train_1/avg_q             | -14.055985002273971  |
| train_1/current_q         | -13.215687800008956  |
| train_1/fw_bonus          | -0.962263998389244   |
| train_1/fw_loss           | 0.18538639545440674  |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 13.996533617232974   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.325075047152652  |
| train_1/q_grads           | -0.10098973028361798 |
| train_1/q_grads_std       | 0.49255389869213106  |
| train_1/q_loss            | 0.744026970548822    |
| train_1/reward            | -2.093558762667817   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00205078125        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.227784209117061  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 591.01. Rollout time: 366.60, Training time: 224.34
Evaluating epoch 94
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 94                   |
| policy/steps              | 8650272.0            |
| test/episodes             | 2375.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.03063768522311   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.76962229545397    |
| train_0/fw_bonus          | -0.9981850996613503  |
| train_0/fw_loss           | 0.009136424167081714 |
| train_0/mu_grads          | -0.0408350694924593  |
| train_0/mu_grads_std      | 0.5845748394727707   |
| train_0/mu_loss           | 9.64005225888047     |
| train_0/next_q            | -9.632178826538254   |
| train_0/q_grads           | 0.02496921056881547  |
| train_0/q_grads_std       | 0.43826833963394163  |
| train_0/q_loss            | 0.24543103729240973  |
| train_0/reward            | -0.7555744839548424  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0063232421875      |
| train_0/target_q          | -9.923508835472855   |
| train_1/avg_q             | -13.988555824334625  |
| train_1/current_q         | -13.169308040958333  |
| train_1/fw_bonus          | -0.9611091002821922  |
| train_1/fw_loss           | 0.1906975656747818   |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 13.996517929797474   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.356647366112332  |
| train_1/q_grads           | -0.10170936696231365 |
| train_1/q_grads_std       | 0.49635592475533485  |
| train_1/q_loss            | 0.6867570994213091   |
| train_1/reward            | -2.0888309165769896  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001611328125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.169615978621147  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 593.96. Rollout time: 366.03, Training time: 227.85
Evaluating epoch 95
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 95                   |
| policy/steps              | 8741397.0            |
| test/episodes             | 2400.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.26078501036341   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.753859857740158   |
| train_0/fw_bonus          | -0.9979830533266068  |
| train_0/fw_loss           | 0.010085993190295994 |
| train_0/mu_grads          | -0.0401714650914073  |
| train_0/mu_grads_std      | 0.5873429208993912   |
| train_0/mu_loss           | 9.619772277259148    |
| train_0/next_q            | -9.60861512018984    |
| train_0/q_grads           | 0.024114236747846008 |
| train_0/q_grads_std       | 0.43951293975114825  |
| train_0/q_loss            | 0.2506535253937626   |
| train_0/reward            | -0.7601121287982096  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0072998046875      |
| train_0/target_q          | -9.906724290131622   |
| train_1/avg_q             | -14.011849528664072  |
| train_1/current_q         | -13.014199629946159  |
| train_1/fw_bonus          | -0.9553284183144569  |
| train_1/fw_loss           | 0.217281549051404    |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 14.013710484872956   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.188778151357573  |
| train_1/q_grads           | -0.10252771433442831 |
| train_1/q_grads_std       | 0.4990467756986618   |
| train_1/q_loss            | 0.730907858804628    |
| train_1/reward            | -2.0866974106545966  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0019287109375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.024365291340041  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 601.19. Rollout time: 370.62, Training time: 230.48
Evaluating epoch 96
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 96                   |
| policy/steps              | 8832522.0            |
| test/episodes             | 2425.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -13.847998646500367  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9700.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999999999   |
| train_0/current_q         | -9.86007199281651    |
| train_0/fw_bonus          | -0.9979202374815941  |
| train_0/fw_loss           | 0.010381132503971458 |
| train_0/mu_grads          | -0.04064551573246718 |
| train_0/mu_grads_std      | 0.5902176231145859   |
| train_0/mu_loss           | 9.726335129751098    |
| train_0/next_q            | -9.710980243970164   |
| train_0/q_grads           | 0.023503744322806597 |
| train_0/q_grads_std       | 0.44137553572654725  |
| train_0/q_loss            | 0.24421877590816168  |
| train_0/reward            | -0.7627784820462693  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0076904296875      |
| train_0/target_q          | -10.016316671894195  |
| train_1/avg_q             | -14.097949526065939  |
| train_1/current_q         | -12.876115582333593  |
| train_1/fw_bonus          | -0.9539126038551331  |
| train_1/fw_loss           | 0.22379252985119819  |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 13.994593720238584   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.072095312068978  |
| train_1/q_grads           | -0.10340792313218117 |
| train_1/q_grads_std       | 0.5022390529513359   |
| train_1/q_loss            | 0.6238531493449169   |
| train_1/reward            | -2.1170686059886066  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002001953125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.88357121420733   |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 606.82. Rollout time: 371.29, Training time: 235.45
Evaluating epoch 97
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 97                   |
| policy/steps              | 8923647.0            |
| test/episodes             | 2450.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.01565486996364   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.99999999999949   |
| train_0/current_q         | -9.738429849116887   |
| train_0/fw_bonus          | -0.9979833483695983  |
| train_0/fw_loss           | 0.010084586939774454 |
| train_0/mu_grads          | -0.0420368236489594  |
| train_0/mu_grads_std      | 0.5931243404746056   |
| train_0/mu_loss           | 9.60254325826053     |
| train_0/next_q            | -9.587606656302878   |
| train_0/q_grads           | 0.023323025926947592 |
| train_0/q_grads_std       | 0.44284839555621147  |
| train_0/q_loss            | 0.23901167347142965  |
| train_0/reward            | -0.7608813213868416  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00625              |
| train_0/target_q          | -9.89199438296345    |
| train_1/avg_q             | -13.951879649628488  |
| train_1/current_q         | -12.958097054277506  |
| train_1/fw_bonus          | -0.9533338487148285  |
| train_1/fw_loss           | 0.22645411901175977  |
| train_1/mu_grads          | -0.06943203508853912 |
| train_1/mu_grads_std      | 0.3817675709724426   |
| train_1/mu_loss           | 14.047586679988225   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.169004606260676  |
| train_1/q_grads           | -0.10453017950057983 |
| train_1/q_grads_std       | 0.5055528968572617   |
| train_1/q_loss            | 0.6383578359832366   |
| train_1/reward            | -2.142560474957281   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001953125          |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -12.958518997119535  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 606.21. Rollout time: 378.22, Training time: 227.91
Evaluating epoch 98
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 9014772.0             |
| test/episodes             | 2475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.966876576916151   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999999998395    |
| train_0/current_q         | -9.885815233273698    |
| train_0/fw_bonus          | -0.9980558156967163   |
| train_0/fw_loss           | 0.009744039876386524  |
| train_0/mu_grads          | -0.041965311765670775 |
| train_0/mu_grads_std      | 0.5960141986608505    |
| train_0/mu_loss           | 9.754272472834359     |
| train_0/next_q            | -9.742694721117683    |
| train_0/q_grads           | 0.02316329935565591   |
| train_0/q_grads_std       | 0.4448687508702278    |
| train_0/q_loss            | 0.24754067812579672   |
| train_0/reward            | -0.7607222407285008   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0072509765625       |
| train_0/target_q          | -10.039132920583794   |
| train_1/avg_q             | -14.026579173342098   |
| train_1/current_q         | -12.94008892549461    |
| train_1/fw_bonus          | -0.9547633215785026   |
| train_1/fw_loss           | 0.21988031454384327   |
| train_1/mu_grads          | -0.06943203508853912  |
| train_1/mu_grads_std      | 0.3817675709724426    |
| train_1/mu_loss           | 13.984559439740291    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -14.055849291146538   |
| train_1/q_grads           | -0.1049422511830926   |
| train_1/q_grads_std       | 0.5083206027746201    |
| train_1/q_loss            | 0.4969269320099225    |
| train_1/reward            | -2.1195691569191695   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001513671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -12.93919864897975    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 593.84. Rollout time: 372.86, Training time: 220.89
Evaluating epoch 99
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|109
----------------------------------------------------
| epoch                     | 99                   |
| policy/steps              | 9105897.0            |
| test/episodes             | 2500.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -14.00484279691629   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 10000.0              |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.999999999999993  |
| train_0/current_q         | -9.775245039726816   |
| train_0/fw_bonus          | -0.9981161937117576  |
| train_0/fw_loss           | 0.009460245328955352 |
| train_0/mu_grads          | -0.042390704061836   |
| train_0/mu_grads_std      | 0.5992773398756981   |
| train_0/mu_loss           | 9.646554751960918    |
| train_0/next_q            | -9.632859480368385   |
| train_0/q_grads           | 0.022813602024689315 |
| train_0/q_grads_std       | 0.44665693789720534  |
| train_0/q_loss            | 0.24386286104033789  |
| train_0/reward            | -0.7590190358176188  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.007861328125       |
| train_0/target_q          | -9.92991562805253    |
| train_1/avg_q             | -14.053286579055337  |
| train_1/current_q         | -13.009607576767465  |
| train_1/fw_bonus          | -0.95228660851717    |
| train_1/fw_loss           | 0.2312700480222702   |
| train_1/mu_grads          | -0.06944530457258224 |
| train_1/mu_grads_std      | 0.3817278742790222   |
| train_1/mu_loss           | 14.03193071540025    |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -14.076806764368694  |
| train_1/q_grads           | -0.10571208130568266 |
| train_1/q_grads_std       | 0.510570864379406    |
| train_1/q_loss            | 0.6700685448902836   |
| train_1/reward            | -2.1383991673872513  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0018310546875      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -13.009037035345449  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
