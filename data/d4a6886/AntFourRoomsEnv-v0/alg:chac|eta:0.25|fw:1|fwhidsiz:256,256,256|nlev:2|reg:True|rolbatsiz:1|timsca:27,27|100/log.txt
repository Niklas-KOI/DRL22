Starting process id: 73990
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f9cf11577a0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 517.77. Rollout time: 259.26, Training time: 258.48
Evaluating epoch 0
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 91103.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -24.236548718647093    |
| test_1/avg_q              | -5.296244643917149     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -11.462042534944628    |
| train_0/current_q         | -7.716040754180142     |
| train_0/fw_bonus          | -0.9937183067202568    |
| train_0/fw_loss           | 0.02920060884207487    |
| train_0/mu_grads          | -0.0068588001769967375 |
| train_0/mu_grads_std      | 0.15570086874067784    |
| train_0/mu_loss           | 7.5801578872336135     |
| train_0/next_q            | -7.573127711639179     |
| train_0/q_grads           | 0.015158360893838107   |
| train_0/q_grads_std       | 0.1041764035820961     |
| train_0/q_loss            | 0.22443339657465203    |
| train_0/reward            | -0.8568487939905026    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 2.44140625e-05         |
| train_0/target_q          | -7.8060061942553105    |
| train_1/avg_q             | -4.154072437178086     |
| train_1/current_q         | -5.257300016496363     |
| train_1/fw_bonus          | -0.9895504876971245    |
| train_1/fw_loss           | 0.06067241607233882    |
| train_1/mu_grads          | -0.01476435805670917   |
| train_1/mu_grads_std      | 0.16178482621908188    |
| train_1/mu_loss           | 3.326637398907809      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.816867789381325     |
| train_1/q_grads           | 0.01800180240534246    |
| train_1/q_grads_std       | 0.10810889322310686    |
| train_1/q_loss            | 0.7556989310527442     |
| train_1/reward            | -1.5473630735446933    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022216796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -5.233741510098223     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 433.78. Rollout time: 241.00, Training time: 192.75
Evaluating epoch 1
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 182228.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.94382599934534    |
| test_1/avg_q              | -4.984953547405573    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -21.022956939814225   |
| train_0/current_q         | -8.580395841332923    |
| train_0/fw_bonus          | -0.9967012524604797   |
| train_0/fw_loss           | 0.015558395511470735  |
| train_0/mu_grads          | -0.011043694149702788 |
| train_0/mu_grads_std      | 0.18126497231423855   |
| train_0/mu_loss           | 8.627930608513104     |
| train_0/next_q            | -8.583661860247933    |
| train_0/q_grads           | 0.007835215365048498  |
| train_0/q_grads_std       | 0.13433312848210335   |
| train_0/q_loss            | 0.5220661026959466    |
| train_0/reward            | -0.8553933628689265   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0004638671875       |
| train_0/target_q          | -8.744087352835276    |
| train_1/avg_q             | -6.805789657511642    |
| train_1/current_q         | -5.748010874395857    |
| train_1/fw_bonus          | -0.9860364466905593   |
| train_1/fw_loss           | 0.07669616360217332   |
| train_1/mu_grads          | -0.029255914594978095 |
| train_1/mu_grads_std      | 0.18503627069294454   |
| train_1/mu_loss           | 3.2984657943167717    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.496898256692239    |
| train_1/q_grads           | 0.0038735636102501304 |
| train_1/q_grads_std       | 0.12528702281415463   |
| train_1/q_loss            | 1.105545221056281     |
| train_1/reward            | -1.5139169827423757   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -5.734911042193746    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 427.72. Rollout time: 240.79, Training time: 186.91
Evaluating epoch 2
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 273353.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999801578305   |
| test_1/avg_q              | -6.014549658020662    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.92592861676367    |
| train_0/current_q         | -9.038585532044285    |
| train_0/fw_bonus          | -0.9976068332791328   |
| train_0/fw_loss           | 0.01141674113459885   |
| train_0/mu_grads          | -0.00928534718696028  |
| train_0/mu_grads_std      | 0.1894965495914221    |
| train_0/mu_loss           | 9.028609048384563     |
| train_0/next_q            | -9.026800486600179    |
| train_0/q_grads           | 0.007569472619798035  |
| train_0/q_grads_std       | 0.13653358183801173   |
| train_0/q_loss            | 0.23815806943505818   |
| train_0/reward            | -0.8555964815968764   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0112060546875       |
| train_0/target_q          | -9.182468244706715    |
| train_1/avg_q             | -6.668127835922317    |
| train_1/current_q         | -6.277668758927705    |
| train_1/fw_bonus          | -0.9857789680361748   |
| train_1/fw_loss           | 0.07787025552242995   |
| train_1/mu_grads          | -0.0297820336651057   |
| train_1/mu_grads_std      | 0.20503602437675      |
| train_1/mu_loss           | 3.1909432256697574    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.1746593038137245   |
| train_1/q_grads           | -0.010187956737354398 |
| train_1/q_grads_std       | 0.1459510713815689    |
| train_1/q_loss            | 0.963220752059532     |
| train_1/reward            | -1.5329438415923504   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.239319149843729    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 429.14. Rollout time: 238.48, Training time: 190.63
Evaluating epoch 3
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 364478.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.303558364192963   |
| test_1/avg_q              | -7.146521316303206    |
| test_1/n_subgoals         | 677.0                 |
| test_1/subgoal_succ_rate  | 0.0029542097488921715 |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.93393527885215    |
| train_0/current_q         | -9.520908112700301    |
| train_0/fw_bonus          | -0.9978724956512451   |
| train_0/fw_loss           | 0.010201760684140027  |
| train_0/mu_grads          | -0.007795708661433309 |
| train_0/mu_grads_std      | 0.20368332006037235   |
| train_0/mu_loss           | 9.517596475273447     |
| train_0/next_q            | -9.515667719722902    |
| train_0/q_grads           | 0.008511084783822297  |
| train_0/q_grads_std       | 0.13918466903269291   |
| train_0/q_loss            | 0.20933405986850756   |
| train_0/reward            | -0.8551426509584417   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01630859375         |
| train_0/target_q          | -9.667666872461838    |
| train_1/avg_q             | -7.069534976914195    |
| train_1/current_q         | -6.376920239543852    |
| train_1/fw_bonus          | -0.9848344132304192   |
| train_1/fw_loss           | 0.08217729702591896   |
| train_1/mu_grads          | -0.03075753739103675  |
| train_1/mu_grads_std      | 0.2222076579928398    |
| train_1/mu_loss           | 3.041096768125223     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.302703549658516    |
| train_1/q_grads           | -0.019887543562799693 |
| train_1/q_grads_std       | 0.1756832215934992    |
| train_1/q_loss            | 0.5939492252895564    |
| train_1/reward            | -1.533761308901012    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.3760301570787545   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 430.40. Rollout time: 242.91, Training time: 187.47
Evaluating epoch 4
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 455514.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.679876291899753    |
| test_1/avg_q              | -4.875560346671099     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.792616329432075    |
| train_0/current_q         | -9.591506829755124     |
| train_0/fw_bonus          | -0.997871159017086     |
| train_0/fw_loss           | 0.010207893373444677   |
| train_0/mu_grads          | -0.0017783926508855076 |
| train_0/mu_grads_std      | 0.22069469429552555    |
| train_0/mu_loss           | 9.578261382206808      |
| train_0/next_q            | -9.578839491999153     |
| train_0/q_grads           | 0.007684025296475739   |
| train_0/q_grads_std       | 0.14320868887007238    |
| train_0/q_loss            | 0.19800045130585658    |
| train_0/reward            | -0.8559106880711624    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.019482421875         |
| train_0/target_q          | -9.753110728676097     |
| train_1/avg_q             | -7.703208870322797     |
| train_1/current_q         | -7.730868925063405     |
| train_1/fw_bonus          | -0.9838104233145714    |
| train_1/fw_loss           | 0.08684662021696568    |
| train_1/mu_grads          | -0.032640075869858266  |
| train_1/mu_grads_std      | 0.23068994730710984    |
| train_1/mu_loss           | 3.4865023187937147     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.068715873974366     |
| train_1/q_grads           | -0.04183657467365265   |
| train_1/q_grads_std       | 0.20438676178455353    |
| train_1/q_loss            | 1.4794558896574124     |
| train_1/reward            | -1.5392127935716418    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010498046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0014814814814814814  |
| train_1/target_q          | -7.644582343846724     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 426.64. Rollout time: 238.42, Training time: 188.19
Evaluating epoch 5
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 546639.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99074226381694    |
| test_1/avg_q              | -6.641757725252734    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.817874099993716   |
| train_0/current_q         | -9.573627311023635    |
| train_0/fw_bonus          | -0.9980184346437454   |
| train_0/fw_loss           | 0.009534273063763976  |
| train_0/mu_grads          | -0.003739100164966658 |
| train_0/mu_grads_std      | 0.23250345848500728   |
| train_0/mu_loss           | 9.550048635373702     |
| train_0/next_q            | -9.549144197841477    |
| train_0/q_grads           | 0.006656022032257169  |
| train_0/q_grads_std       | 0.14459716118872165   |
| train_0/q_loss            | 0.20388581664034439   |
| train_0/reward            | -0.8557831183425151   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02880859375         |
| train_0/target_q          | -9.719548001345924    |
| train_1/avg_q             | -7.2604233726384555   |
| train_1/current_q         | -6.855670479147099    |
| train_1/fw_bonus          | -0.9834832608699798   |
| train_1/fw_loss           | 0.08833842016756535   |
| train_1/mu_grads          | -0.03187961988151074  |
| train_1/mu_grads_std      | 0.23510973602533342   |
| train_1/mu_loss           | 3.0834125000110566    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.987606199003156    |
| train_1/q_grads           | -0.04634061185643077  |
| train_1/q_grads_std       | 0.22678819186985494   |
| train_1/q_loss            | 0.6134194617817276    |
| train_1/reward            | -1.5557093698269455   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009765625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.87432943233223     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 427.16. Rollout time: 240.92, Training time: 186.21
Evaluating epoch 6
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 637764.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999545879653   |
| test_1/avg_q              | -7.370440035099728    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.991084491644145   |
| train_0/current_q         | -9.652164828710607    |
| train_0/fw_bonus          | -0.9981045827269555   |
| train_0/fw_loss           | 0.009140251902863383  |
| train_0/mu_grads          | -0.008056408283300698 |
| train_0/mu_grads_std      | 0.2451316736638546    |
| train_0/mu_loss           | 9.617371957908697     |
| train_0/next_q            | -9.618384264241167    |
| train_0/q_grads           | 0.007328908145427704  |
| train_0/q_grads_std       | 0.14960978776216508   |
| train_0/q_loss            | 0.18872771351595713   |
| train_0/reward            | -0.8569585741046467   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.03466796875         |
| train_0/target_q          | -9.803614400891236    |
| train_1/avg_q             | -7.63707522742271     |
| train_1/current_q         | -7.00113966679167     |
| train_1/fw_bonus          | -0.9842034742236138   |
| train_1/fw_loss           | 0.08505431711673736   |
| train_1/mu_grads          | -0.03199694901704788  |
| train_1/mu_grads_std      | 0.24066777266561984   |
| train_1/mu_loss           | 3.155989853722914     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.146198378302577    |
| train_1/q_grads           | -0.053265906684100625 |
| train_1/q_grads_std       | 0.25059966221451757   |
| train_1/q_loss            | 0.6938510452000353    |
| train_1/reward            | -1.5605341984410188   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.007183878204211    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 426.39. Rollout time: 240.23, Training time: 186.12
Evaluating epoch 7
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 728803.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.66099316297556    |
| test_1/avg_q              | -7.212035200880152    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.25529257835814    |
| train_0/current_q         | -9.720213864982224    |
| train_0/fw_bonus          | -0.9981167957186698   |
| train_0/fw_loss           | 0.009084475203417241  |
| train_0/mu_grads          | -0.00908978849183768  |
| train_0/mu_grads_std      | 0.2583035431802273    |
| train_0/mu_loss           | 9.688247182331006     |
| train_0/next_q            | -9.687476758942065    |
| train_0/q_grads           | 0.006474470510147512  |
| train_0/q_grads_std       | 0.15297629795968531   |
| train_0/q_loss            | 0.23835574776134463   |
| train_0/reward            | -0.8575963827548548   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0397705078125       |
| train_0/target_q          | -9.84456326636595     |
| train_1/avg_q             | -7.601080790964191    |
| train_1/current_q         | -6.981975510107185    |
| train_1/fw_bonus          | -0.9844353944063187   |
| train_1/fw_loss           | 0.08399679660797119   |
| train_1/mu_grads          | -0.035479473602026704 |
| train_1/mu_grads_std      | 0.24379100166261197   |
| train_1/mu_loss           | 3.1425998215567756    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.142869071714176    |
| train_1/q_grads           | -0.06542600803077221  |
| train_1/q_grads_std       | 0.2827878683805466    |
| train_1/q_loss            | 0.6140074235155693    |
| train_1/reward            | -1.544082160385733    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0022222222222222222 |
| train_1/target_q          | -6.973345284798159    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 425.57. Rollout time: 238.22, Training time: 187.32
Evaluating epoch 8
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 819835.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999998982293   |
| test_1/avg_q              | -7.466569508903391    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.832788961617457   |
| train_0/current_q         | -9.502259900668832    |
| train_0/fw_bonus          | -0.9980729043483734   |
| train_0/fw_loss           | 0.009285234892740846  |
| train_0/mu_grads          | -0.012408313993364572 |
| train_0/mu_grads_std      | 0.2716009236872196    |
| train_0/mu_loss           | 9.45878331041019      |
| train_0/next_q            | -9.45707962708688     |
| train_0/q_grads           | 0.006452991219703108  |
| train_0/q_grads_std       | 0.15746037773787974   |
| train_0/q_loss            | 0.20054430580453073   |
| train_0/reward            | -0.8556957845008583   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.028466796875        |
| train_0/target_q          | -9.646426181859962    |
| train_1/avg_q             | -7.45577640284025     |
| train_1/current_q         | -6.800243524079673    |
| train_1/fw_bonus          | -0.9850826352834702   |
| train_1/fw_loss           | 0.08104540780186653   |
| train_1/mu_grads          | -0.03754447679966688  |
| train_1/mu_grads_std      | 0.24798107370734215   |
| train_1/mu_loss           | 2.8528558647858397    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.939649174637831    |
| train_1/q_grads           | -0.0812297185882926   |
| train_1/q_grads_std       | 0.3128100298345089    |
| train_1/q_loss            | 0.6072999193437176    |
| train_1/reward            | -1.5370663761459582   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0022222222222222222 |
| train_1/target_q          | -6.80179675787317     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 399.63. Rollout time: 219.24, Training time: 180.36
Evaluating epoch 9
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 910960.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.97592818136433    |
| test_1/avg_q              | -6.965082735956348    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.975154971327143   |
| train_0/current_q         | -9.6107188174913      |
| train_0/fw_bonus          | -0.9981620818376541   |
| train_0/fw_loss           | 0.00887737920274958   |
| train_0/mu_grads          | -0.013034182996489108 |
| train_0/mu_grads_std      | 0.2844952143728733    |
| train_0/mu_loss           | 9.578032268279788     |
| train_0/next_q            | -9.576991171309038    |
| train_0/q_grads           | 0.0060600652126595374 |
| train_0/q_grads_std       | 0.1613627176731825    |
| train_0/q_loss            | 0.2178602149526144    |
| train_0/reward            | -0.856043430774298    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0399658203125       |
| train_0/target_q          | -9.770320710303977    |
| train_1/avg_q             | -7.501004494098018    |
| train_1/current_q         | -6.979613247731164    |
| train_1/fw_bonus          | -0.9856256976723671   |
| train_1/fw_loss           | 0.07856912780553102   |
| train_1/mu_grads          | -0.03893779339268803  |
| train_1/mu_grads_std      | 0.25131009295582774   |
| train_1/mu_loss           | 2.8725520505172333    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.164064806083853    |
| train_1/q_grads           | -0.09862482380121947  |
| train_1/q_grads_std       | 0.3375691257417202    |
| train_1/q_loss            | 0.7892862662671115    |
| train_1/reward            | -1.5585674174079032   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.981153710498106    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 397.51. Rollout time: 220.28, Training time: 177.20
Evaluating epoch 10
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 1001650.0             |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.997436922198183   |
| test_1/avg_q              | -7.235144309305722    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.230166617991586   |
| train_0/current_q         | -9.670834086622596    |
| train_0/fw_bonus          | -0.9982756555080414   |
| train_0/fw_loss           | 0.008357875735964627  |
| train_0/mu_grads          | -0.016881338460370897 |
| train_0/mu_grads_std      | 0.2992349058389664    |
| train_0/mu_loss           | 9.646694064895808     |
| train_0/next_q            | -9.64154163419888     |
| train_0/q_grads           | 0.00689703777898103   |
| train_0/q_grads_std       | 0.16740554794669152   |
| train_0/q_loss            | 0.270495495890798     |
| train_0/reward            | -0.8569587024714564   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0339599609375       |
| train_0/target_q          | -9.818037090163386    |
| train_1/avg_q             | -7.495366766129009    |
| train_1/current_q         | -6.74540114346618     |
| train_1/fw_bonus          | -0.9861037984490395   |
| train_1/fw_loss           | 0.07638911828398705   |
| train_1/mu_grads          | -0.04154780572280288  |
| train_1/mu_grads_std      | 0.2531114675104618    |
| train_1/mu_loss           | 3.0080635646741647    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.904410503435204    |
| train_1/q_grads           | -0.10769975818693638  |
| train_1/q_grads_std       | 0.3568356893956661    |
| train_1/q_loss            | 0.4601692186557568    |
| train_1/reward            | -1.5408168491427205   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0077777777777777776 |
| train_1/target_q          | -6.746358542895098    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 396.93. Rollout time: 221.90, Training time: 175.01
Evaluating epoch 11
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1092775.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.939174645002687   |
| test_1/avg_q              | -6.670180941510898    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.5356279547096     |
| train_0/current_q         | -9.655109731070958    |
| train_0/fw_bonus          | -0.9983161658048629   |
| train_0/fw_loss           | 0.008172605524305255  |
| train_0/mu_grads          | -0.020796202635392547 |
| train_0/mu_grads_std      | 0.31241195276379585   |
| train_0/mu_loss           | 9.614396543311457     |
| train_0/next_q            | -9.611194686785167    |
| train_0/q_grads           | 0.0075710963341407474 |
| train_0/q_grads_std       | 0.17480609603226185   |
| train_0/q_loss            | 0.21381820565048715   |
| train_0/reward            | -0.8571294662120635   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0403076171875       |
| train_0/target_q          | -9.812672098021114    |
| train_1/avg_q             | -7.490657710216865    |
| train_1/current_q         | -6.7219455358164      |
| train_1/fw_bonus          | -0.9867732554674149   |
| train_1/fw_loss           | 0.07333638593554496   |
| train_1/mu_grads          | -0.04381101699545979  |
| train_1/mu_grads_std      | 0.25681311935186385   |
| train_1/mu_loss           | 2.9293985876902093    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.84692647263963     |
| train_1/q_grads           | -0.11321021988987923  |
| train_1/q_grads_std       | 0.37187863439321517   |
| train_1/q_loss            | 0.4798153689152616    |
| train_1/reward            | -1.5421795501795714   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.724894412871592    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 398.45. Rollout time: 219.94, Training time: 178.48
Evaluating epoch 12
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 1183900.0             |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -23.34731764139455    |
| test_1/avg_q              | -6.180630442490645    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.863015474703488   |
| train_0/current_q         | -9.588901414535544    |
| train_0/fw_bonus          | -0.9983443409204483   |
| train_0/fw_loss           | 0.008043786894995719  |
| train_0/mu_grads          | -0.019837738759815694 |
| train_0/mu_grads_std      | 0.3281739719212055    |
| train_0/mu_loss           | 9.542299775430113     |
| train_0/next_q            | -9.545525589125361    |
| train_0/q_grads           | 0.008184136147610844  |
| train_0/q_grads_std       | 0.1809036262333393    |
| train_0/q_loss            | 0.2123933621668153    |
| train_0/reward            | -0.8591464408484171   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.033203125           |
| train_0/target_q          | -9.754645284799258    |
| train_1/avg_q             | -7.484543863512719    |
| train_1/current_q         | -6.827102539571875    |
| train_1/fw_bonus          | -0.9870667725801467   |
| train_1/fw_loss           | 0.07199798449873925   |
| train_1/mu_grads          | -0.044331449642777444 |
| train_1/mu_grads_std      | 0.2589594542980194    |
| train_1/mu_loss           | 2.855062971789818     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.931929417914714    |
| train_1/q_grads           | -0.12003445625305176  |
| train_1/q_grads_std       | 0.38167370706796644   |
| train_1/q_loss            | 0.6685846452402088    |
| train_1/reward            | -1.536424345881096    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.826477398331027    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 396.97. Rollout time: 218.11, Training time: 178.83
Evaluating epoch 13
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 1274976.0             |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.92361230814157    |
| test_1/avg_q              | -4.247181551512426    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.4255699992688     |
| train_0/current_q         | -9.706589913030603    |
| train_0/fw_bonus          | -0.9983927339315415   |
| train_0/fw_loss           | 0.007822495920117944  |
| train_0/mu_grads          | -0.022489863727241755 |
| train_0/mu_grads_std      | 0.33862683176994324   |
| train_0/mu_loss           | 9.664769304167303     |
| train_0/next_q            | -9.657198048411354    |
| train_0/q_grads           | 0.0075216277153231205 |
| train_0/q_grads_std       | 0.18487349562346936   |
| train_0/q_loss            | 0.20963121418918398   |
| train_0/reward            | -0.8594146640753024   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.03232421875         |
| train_0/target_q          | -9.860332208360884    |
| train_1/avg_q             | -7.517552945746755    |
| train_1/current_q         | -6.611313310095691    |
| train_1/fw_bonus          | -0.9875178962945939   |
| train_1/fw_loss           | 0.06994088720530271   |
| train_1/mu_grads          | -0.04442335087805986  |
| train_1/mu_grads_std      | 0.26083789169788363   |
| train_1/mu_loss           | 2.7010559382881625    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.6565565859378735   |
| train_1/q_grads           | -0.11933230608701706  |
| train_1/q_grads_std       | 0.38752067685127256   |
| train_1/q_loss            | 0.6700859145785374    |
| train_1/reward            | -1.5376904262360767   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001171875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0007407407407407407 |
| train_1/target_q          | -6.6085637193261935   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 420.44. Rollout time: 225.94, Training time: 194.47
Evaluating epoch 14
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 14                   |
| policy/steps              | 1365888.0            |
| test/episodes             | 375.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -23.44563261187965   |
| test_1/avg_q              | -6.702736688080868   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 1500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -25.32604074064064   |
| train_0/current_q         | -9.776770404125633   |
| train_0/fw_bonus          | -0.998429648578167   |
| train_0/fw_loss           | 0.007653655542526394 |
| train_0/mu_grads          | -0.01951862554997206 |
| train_0/mu_grads_std      | 0.3498350016772747   |
| train_0/mu_loss           | 9.750626261168808    |
| train_0/next_q            | -9.74262500619414    |
| train_0/q_grads           | 0.007779708120506257 |
| train_0/q_grads_std       | 0.18857247866690158  |
| train_0/q_loss            | 0.3554298545457553   |
| train_0/reward            | -0.8604738466412527  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.02919921875        |
| train_0/target_q          | -9.927938405568275   |
| train_1/avg_q             | -7.461927643855845   |
| train_1/current_q         | -5.326212570144976   |
| train_1/fw_bonus          | -0.9871483683586121  |
| train_1/fw_loss           | 0.07162595354020596  |
| train_1/mu_grads          | -0.04499894911423326 |
| train_1/mu_grads_std      | 0.26157116740942     |
| train_1/mu_loss           | 3.0426194673819906   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -4.9209295865965945  |
| train_1/q_grads           | -0.12125102151185274 |
| train_1/q_grads_std       | 0.3930786199867725   |
| train_1/q_loss            | 1.4344329683947457   |
| train_1/reward            | -1.5501574113601237  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0009033203125      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.004074074074074074 |
| train_1/target_q          | -5.342198315763693   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 469.05. Rollout time: 260.23, Training time: 208.78
Evaluating epoch 15
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1456966.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.71839799769651    |
| test_1/avg_q              | -6.647586399146242    |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.04425688167904    |
| train_0/current_q         | -9.57788302318852     |
| train_0/fw_bonus          | -0.9983082994818687   |
| train_0/fw_loss           | 0.008208686101716012  |
| train_0/mu_grads          | -0.0178740247618407   |
| train_0/mu_grads_std      | 0.3614187814295292    |
| train_0/mu_loss           | 9.537889198088937     |
| train_0/next_q            | -9.529767311357332    |
| train_0/q_grads           | 0.008057270990684628  |
| train_0/q_grads_std       | 0.19373344592750072   |
| train_0/q_loss            | 0.28754893830375783   |
| train_0/reward            | -0.8608161763026146   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0312744140625       |
| train_0/target_q          | -9.733434674964286    |
| train_1/avg_q             | -7.554073235476624    |
| train_1/current_q         | -6.643369428390924    |
| train_1/fw_bonus          | -0.9859905377030372   |
| train_1/fw_loss           | 0.0769055312499404    |
| train_1/mu_grads          | -0.04646949907764793  |
| train_1/mu_grads_std      | 0.2636556655168533    |
| train_1/mu_loss           | 2.6974783751614035    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.702461619883539    |
| train_1/q_grads           | -0.12476216107606888  |
| train_1/q_grads_std       | 0.3982117161154747    |
| train_1/q_loss            | 0.6011457958904629    |
| train_1/reward            | -1.5492157971850247   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0011111111111111111 |
| train_1/target_q          | -6.64318958505383     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 534.90. Rollout time: 297.65, Training time: 237.20
Evaluating epoch 16
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1547968.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -23.965416812579875   |
| test_1/avg_q              | -6.271937099343114    |
| test_1/n_subgoals         | 703.0                 |
| test_1/subgoal_succ_rate  | 0.03982930298719772   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.711308912885624   |
| train_0/current_q         | -9.72975647582974     |
| train_0/fw_bonus          | -0.998216587305069    |
| train_0/fw_loss           | 0.008628033939749003  |
| train_0/mu_grads          | -0.015152277960442006 |
| train_0/mu_grads_std      | 0.36949280127882955   |
| train_0/mu_loss           | 9.686730285748226     |
| train_0/next_q            | -9.681088851067587    |
| train_0/q_grads           | 0.010043812356889248  |
| train_0/q_grads_std       | 0.1985978402197361    |
| train_0/q_loss            | 0.33981890550212845   |
| train_0/reward            | -0.8627188424725318   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0271728515625       |
| train_0/target_q          | -9.8771241034406      |
| train_1/avg_q             | -7.50217919646049     |
| train_1/current_q         | -6.921665279341916    |
| train_1/fw_bonus          | -0.9856441155076027   |
| train_1/fw_loss           | 0.07848517261445523   |
| train_1/mu_grads          | -0.04766517383977771  |
| train_1/mu_grads_std      | 0.26549549028277397   |
| train_1/mu_loss           | 2.575893257510962     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.033387062566382    |
| train_1/q_grads           | -0.1315509404987097   |
| train_1/q_grads_std       | 0.40610369220376014   |
| train_1/q_loss            | 0.5766709192079579    |
| train_1/reward            | -1.5402828871097882   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001171875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0022222222222222222 |
| train_1/target_q          | -6.924921003433934    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 525.79. Rollout time: 297.31, Training time: 228.44
Evaluating epoch 17
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1638773.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -22.98712165086548    |
| test_1/avg_q              | -6.128736604964208    |
| test_1/n_subgoals         | 687.0                 |
| test_1/subgoal_succ_rate  | 0.017467248908296942  |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.40837793890164    |
| train_0/current_q         | -9.669599632300475    |
| train_0/fw_bonus          | -0.998290479183197    |
| train_0/fw_loss           | 0.008290124975610524  |
| train_0/mu_grads          | -0.014437593007460236 |
| train_0/mu_grads_std      | 0.3785883031785488    |
| train_0/mu_loss           | 9.630959312339089     |
| train_0/next_q            | -9.625235262604903    |
| train_0/q_grads           | 0.008851446071639657  |
| train_0/q_grads_std       | 0.20283862836658956   |
| train_0/q_loss            | 0.3402711004929243    |
| train_0/reward            | -0.8618037975160405   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023828125           |
| train_0/target_q          | -9.827246426327875    |
| train_1/avg_q             | -7.516257928395454    |
| train_1/current_q         | -7.002808264020828    |
| train_1/fw_bonus          | -0.9857225075364113   |
| train_1/fw_loss           | 0.07812767345458269   |
| train_1/mu_grads          | -0.04837503656744957  |
| train_1/mu_grads_std      | 0.26802079305052756   |
| train_1/mu_loss           | 2.63369265871059      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.128811880575275    |
| train_1/q_grads           | -0.13744909204542638  |
| train_1/q_grads_std       | 0.4184289678931236    |
| train_1/q_loss            | 0.4488697094527703    |
| train_1/reward            | -1.5568211794463422   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.004814814814814815  |
| train_1/target_q          | -7.000242148143973    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 519.81. Rollout time: 281.72, Training time: 238.03
Evaluating epoch 18
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 1728866.0             |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -25.156169461597795   |
| test_1/avg_q              | -5.6816048617363695   |
| test_1/n_subgoals         | 678.0                 |
| test_1/subgoal_succ_rate  | 0.004424778761061947  |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.052341932730705   |
| train_0/current_q         | -9.720283935796711    |
| train_0/fw_bonus          | -0.9983267188072205   |
| train_0/fw_loss           | 0.008124375052284449  |
| train_0/mu_grads          | -0.014136977749876678 |
| train_0/mu_grads_std      | 0.3868693307042122    |
| train_0/mu_loss           | 9.713297926849716     |
| train_0/next_q            | -9.699101085450035    |
| train_0/q_grads           | 0.011124143004417419  |
| train_0/q_grads_std       | 0.2072138462215662    |
| train_0/q_loss            | 0.3573360197507073    |
| train_0/reward            | -0.8616905978386058   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.01953125            |
| train_0/target_q          | -9.872597874593312    |
| train_1/avg_q             | -7.461305755537652    |
| train_1/current_q         | -6.686389311114651    |
| train_1/fw_bonus          | -0.9847176283597946   |
| train_1/fw_loss           | 0.08270984049886465   |
| train_1/mu_grads          | -0.05011084266006947  |
| train_1/mu_grads_std      | 0.27046124786138537   |
| train_1/mu_loss           | 2.483200810663166     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.761665274282595    |
| train_1/q_grads           | -0.14025613516569138  |
| train_1/q_grads_std       | 0.425489042699337     |
| train_1/q_loss            | 0.620813267568155     |
| train_1/reward            | -1.5362921260973963   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.017777777777777778  |
| train_1/target_q          | -6.684100089549142    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 537.66. Rollout time: 301.30, Training time: 236.32
Evaluating epoch 19
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1819464.0             |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.943306357038214   |
| test_1/avg_q              | -5.29084609415678     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.45316686990454    |
| train_0/current_q         | -9.649823861628173    |
| train_0/fw_bonus          | -0.9983485817909241   |
| train_0/fw_loss           | 0.008024358411785216  |
| train_0/mu_grads          | -0.013856509351171553 |
| train_0/mu_grads_std      | 0.3944074913859367    |
| train_0/mu_loss           | 9.621853008892257     |
| train_0/next_q            | -9.611030095548688    |
| train_0/q_grads           | 0.010701089608483016  |
| train_0/q_grads_std       | 0.21011220775544642   |
| train_0/q_loss            | 0.3041994004668426    |
| train_0/reward            | -0.8610539235669421   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02177734375         |
| train_0/target_q          | -9.794924297525515    |
| train_1/avg_q             | -7.487013197946432    |
| train_1/current_q         | -7.22737217058795     |
| train_1/fw_bonus          | -0.9845774546265602   |
| train_1/fw_loss           | 0.0833490252494812    |
| train_1/mu_grads          | -0.05215407414361835  |
| train_1/mu_grads_std      | 0.27318858355283737   |
| train_1/mu_loss           | 2.5721055422467494    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.493526354033298    |
| train_1/q_grads           | -0.1420790795236826   |
| train_1/q_grads_std       | 0.42469815611839296   |
| train_1/q_loss            | 0.5370422074961003    |
| train_1/reward            | -1.5566337718053547   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.009259259259259259  |
| train_1/target_q          | -7.22295589585884     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 547.86. Rollout time: 310.66, Training time: 237.16
Evaluating epoch 20
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1910589.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.996959572559977   |
| test_1/avg_q              | -5.0276072307934765   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.921522100999642   |
| train_0/current_q         | -9.638287469218245    |
| train_0/fw_bonus          | -0.9984502404928207   |
| train_0/fw_loss           | 0.0075594946392811835 |
| train_0/mu_grads          | -0.016219218634068965 |
| train_0/mu_grads_std      | 0.4007298283278942    |
| train_0/mu_loss           | 9.595343680694283     |
| train_0/next_q            | -9.586968824415866    |
| train_0/q_grads           | 0.010756282974034548  |
| train_0/q_grads_std       | 0.21263220012187958   |
| train_0/q_loss            | 0.27208386742088364   |
| train_0/reward            | -0.8592197564343224   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.023583984375        |
| train_0/target_q          | -9.775800708146749    |
| train_1/avg_q             | -7.53387351548903     |
| train_1/current_q         | -6.910637291509639    |
| train_1/fw_bonus          | -0.9852371603250504   |
| train_1/fw_loss           | 0.08034078162163497   |
| train_1/mu_grads          | -0.05259539242833853  |
| train_1/mu_grads_std      | 0.27518988475203515   |
| train_1/mu_loss           | 2.586843158000415     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.065114849115032    |
| train_1/q_grads           | -0.14768462181091307  |
| train_1/q_grads_std       | 0.42968648821115496   |
| train_1/q_loss            | 0.47265595571043717   |
| train_1/reward            | -1.5487423292805034   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00126953125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.910355635761206    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 506.57. Rollout time: 278.46, Training time: 228.08
Evaluating epoch 21
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 2001621.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99436234209272    |
| test_1/avg_q              | -5.540385053845065    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.89179388043921    |
| train_0/current_q         | -9.65012940635152     |
| train_0/fw_bonus          | -0.9985479131340981   |
| train_0/fw_loss           | 0.007112730457447469  |
| train_0/mu_grads          | -0.018264091527089476 |
| train_0/mu_grads_std      | 0.40620961487293245   |
| train_0/mu_loss           | 9.599648372629998     |
| train_0/next_q            | -9.590662246338585    |
| train_0/q_grads           | 0.009477286250330508  |
| train_0/q_grads_std       | 0.21484334468841554   |
| train_0/q_loss            | 0.2360159091604035    |
| train_0/reward            | -0.8589390179462498   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02236328125         |
| train_0/target_q          | -9.807963095251486    |
| train_1/avg_q             | -7.488340413859508    |
| train_1/current_q         | -6.7808841480334765   |
| train_1/fw_bonus          | -0.9855113878846169   |
| train_1/fw_loss           | 0.07909038998186588   |
| train_1/mu_grads          | -0.05310986330732703  |
| train_1/mu_grads_std      | 0.2789327345788479    |
| train_1/mu_loss           | 2.3574829214881       |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.947822057463267    |
| train_1/q_grads           | -0.15442951992154122  |
| train_1/q_grads_std       | 0.4341683015227318    |
| train_1/q_loss            | 0.34076733169538437   |
| train_1/reward            | -1.5447609787042893   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0014814814814814814 |
| train_1/target_q          | -6.77679086706881     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 500.49. Rollout time: 277.68, Training time: 222.77
Evaluating epoch 22
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 22                   |
| policy/steps              | 2092746.0            |
| test/episodes             | 575.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.999996384521893  |
| test_1/avg_q              | -6.628168456039568   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 2300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.75773409319471   |
| train_0/current_q         | -9.691179837742386   |
| train_0/fw_bonus          | -0.9986005455255509  |
| train_0/fw_loss           | 0.0068720699287951   |
| train_0/mu_grads          | -0.01953340913169086 |
| train_0/mu_grads_std      | 0.4120085671544075   |
| train_0/mu_loss           | 9.652261493276907    |
| train_0/next_q            | -9.650704782613776   |
| train_0/q_grads           | 0.010794300329871475 |
| train_0/q_grads_std       | 0.21837862394750118  |
| train_0/q_loss            | 0.2515525050835694   |
| train_0/reward            | -0.8571474291049526  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0181396484375      |
| train_0/target_q          | -9.84507292918311    |
| train_1/avg_q             | -7.517138368379333   |
| train_1/current_q         | -6.91049625531334    |
| train_1/fw_bonus          | -0.9850425943732262  |
| train_1/fw_loss           | 0.08122802544385195  |
| train_1/mu_grads          | -0.05403273487463593 |
| train_1/mu_grads_std      | 0.2809680990874767   |
| train_1/mu_loss           | 2.7335628683403663   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -7.070667275787085   |
| train_1/q_grads           | -0.15563928782939912 |
| train_1/q_grads_std       | 0.4392236642539501   |
| train_1/q_loss            | 0.4353456976104167   |
| train_1/reward            | -1.5293337027160305  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00107421875        |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -6.91235251204868    |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 478.59. Rollout time: 269.76, Training time: 208.80
Evaluating epoch 23
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 2183871.0             |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999988823939038   |
| test_1/avg_q              | -6.851673071957977    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.913931697872503   |
| train_0/current_q         | -9.643164168822498    |
| train_0/fw_bonus          | -0.9986212581396103   |
| train_0/fw_loss           | 0.006777300417888909  |
| train_0/mu_grads          | -0.018871651124209167 |
| train_0/mu_grads_std      | 0.41754135191440583   |
| train_0/mu_loss           | 9.625182179899637     |
| train_0/next_q            | -9.619960304965772    |
| train_0/q_grads           | 0.009219829551875591  |
| train_0/q_grads_std       | 0.22114968709647656   |
| train_0/q_loss            | 0.2880448055907209    |
| train_0/reward            | -0.8572362129547401   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0208984375          |
| train_0/target_q          | -9.792389958045652    |
| train_1/avg_q             | -7.534788048920462    |
| train_1/current_q         | -7.092057378122126    |
| train_1/fw_bonus          | -0.9852733388543129   |
| train_1/fw_loss           | 0.0801758648827672    |
| train_1/mu_grads          | -0.055400519352406266 |
| train_1/mu_grads_std      | 0.28213570490479467   |
| train_1/mu_loss           | 3.0997058534393647    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.281643698183632    |
| train_1/q_grads           | -0.16125438548624516  |
| train_1/q_grads_std       | 0.4480662576854229    |
| train_1/q_loss            | 0.5506211133727235    |
| train_1/reward            | -1.5424217986917939   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011962890625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.08849292988662     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 475.42. Rollout time: 267.11, Training time: 208.28
Evaluating epoch 24
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2274996.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999995140485   |
| test_1/avg_q              | -6.150598338727459    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.91083360666121    |
| train_0/current_q         | -9.694561719747691    |
| train_0/fw_bonus          | -0.9986133873462677   |
| train_0/fw_loss           | 0.006813363975379616  |
| train_0/mu_grads          | -0.018746195081621408 |
| train_0/mu_grads_std      | 0.42244422882795335   |
| train_0/mu_loss           | 9.656973822132262     |
| train_0/next_q            | -9.6490714836339      |
| train_0/q_grads           | 0.009283465519547462  |
| train_0/q_grads_std       | 0.22307182252407073   |
| train_0/q_loss            | 0.22434014477194236   |
| train_0/reward            | -0.8576453376197606   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0093994140625       |
| train_0/target_q          | -9.845433966502162    |
| train_1/avg_q             | -7.517155564139274    |
| train_1/current_q         | -7.014627655657807    |
| train_1/fw_bonus          | -0.9853895470499993   |
| train_1/fw_loss           | 0.07964595556259155   |
| train_1/mu_grads          | -0.05681811980903149  |
| train_1/mu_grads_std      | 0.28696100413799286   |
| train_1/mu_loss           | 2.665466448504459     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.12317395576176     |
| train_1/q_grads           | -0.16443093158304692  |
| train_1/q_grads_std       | 0.45416119024157525   |
| train_1/q_loss            | 0.5392461091383141    |
| train_1/reward            | -1.5432413785161772   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.015195986168635    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 527.81. Rollout time: 290.38, Training time: 237.40
Evaluating epoch 25
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 2366121.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99798487312547    |
| test_1/avg_q              | -6.878185869722264    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.878377888876187   |
| train_0/current_q         | -9.665201004389328    |
| train_0/fw_bonus          | -0.9985843971371651   |
| train_0/fw_loss           | 0.006945950200315565  |
| train_0/mu_grads          | -0.017952861404046415 |
| train_0/mu_grads_std      | 0.4286539666354656    |
| train_0/mu_loss           | 9.632354130173557     |
| train_0/next_q            | -9.63199217968258     |
| train_0/q_grads           | 0.009179268917068838  |
| train_0/q_grads_std       | 0.22585018277168273   |
| train_0/q_loss            | 0.23060870310386586   |
| train_0/reward            | -0.8591067491201102   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0140625             |
| train_0/target_q          | -9.830614494620008    |
| train_1/avg_q             | -7.571888563464438    |
| train_1/current_q         | -7.0579677044803075   |
| train_1/fw_bonus          | -0.9844407826662064   |
| train_1/fw_loss           | 0.08397221378982067   |
| train_1/mu_grads          | -0.05675155678763986  |
| train_1/mu_grads_std      | 0.29014483988285067   |
| train_1/mu_loss           | 3.0452486268840717    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.082404195777864    |
| train_1/q_grads           | -0.1697008416056633   |
| train_1/q_grads_std       | 0.46058789268136024   |
| train_1/q_loss            | 0.8149647431961249    |
| train_1/reward            | -1.5500127168590552   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009765625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.064657654521403    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 551.84. Rollout time: 303.77, Training time: 248.03
Evaluating epoch 26
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 26                   |
| policy/steps              | 2457246.0            |
| test/episodes             | 675.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -6.4131033845725955  |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 2700.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.92976153151298   |
| train_0/current_q         | -9.668594137226671   |
| train_0/fw_bonus          | -0.9985697984695434  |
| train_0/fw_loss           | 0.007012660964392126 |
| train_0/mu_grads          | -0.01892478410154581 |
| train_0/mu_grads_std      | 0.43507096022367475  |
| train_0/mu_loss           | 9.621820930971937    |
| train_0/next_q            | -9.611116642759413   |
| train_0/q_grads           | 0.009144963743165136 |
| train_0/q_grads_std       | 0.22867692410945892  |
| train_0/q_loss            | 0.2413114766859926   |
| train_0/reward            | -0.8588394612510456  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.016162109375       |
| train_0/target_q          | -9.811994908584282   |
| train_1/avg_q             | -7.466883084071273   |
| train_1/current_q         | -6.812372083645448   |
| train_1/fw_bonus          | -0.9842710509896279  |
| train_1/fw_loss           | 0.0847461499273777   |
| train_1/mu_grads          | -0.05752212926745415 |
| train_1/mu_grads_std      | 0.2955227427184582   |
| train_1/mu_loss           | 2.6715629921705872   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -6.748827706083484   |
| train_1/q_grads           | -0.17708065249025823 |
| train_1/q_grads_std       | 0.46428258046507836  |
| train_1/q_loss            | 0.8214068272188026   |
| train_1/reward            | -1.5545668176520848  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001220703125       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -6.809020378334459   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 505.03. Rollout time: 279.86, Training time: 225.13
Evaluating epoch 27
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 27                   |
| policy/steps              | 2548371.0            |
| test/episodes             | 700.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -7.26218369998886    |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 2800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.972611850403137  |
| train_0/current_q         | -9.667149069980635   |
| train_0/fw_bonus          | -0.998564624786377   |
| train_0/fw_loss           | 0.007036352960858494 |
| train_0/mu_grads          | -0.01888190726749599 |
| train_0/mu_grads_std      | 0.43939887806773187  |
| train_0/mu_loss           | 9.618401705836476    |
| train_0/next_q            | -9.609855580410727   |
| train_0/q_grads           | 0.008592592389322817 |
| train_0/q_grads_std       | 0.2312766369432211   |
| train_0/q_loss            | 0.23267433186347306  |
| train_0/reward            | -0.8595191700398572  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.012109375          |
| train_0/target_q          | -9.822132669142349   |
| train_1/avg_q             | -7.489305715681578   |
| train_1/current_q         | -6.893837279639117   |
| train_1/fw_bonus          | -0.984248910844326   |
| train_1/fw_loss           | 0.08484717719256878  |
| train_1/mu_grads          | -0.058199393004179   |
| train_1/mu_grads_std      | 0.30147218480706217  |
| train_1/mu_loss           | 3.0315375814855146   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -6.920962506627015   |
| train_1/q_grads           | -0.17810933142900467 |
| train_1/q_grads_std       | 0.46731691136956216  |
| train_1/q_loss            | 0.7652773560300101   |
| train_1/reward            | -1.5690033264196246  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013916015625      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -6.903116260251176   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 573.19. Rollout time: 339.28, Training time: 233.80
Evaluating epoch 28
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 2639496.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.191145115451331    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.970865004690218   |
| train_0/current_q         | -9.801389417129705    |
| train_0/fw_bonus          | -0.9986209005117417   |
| train_0/fw_loss           | 0.006778986298013478  |
| train_0/mu_grads          | -0.019325924571603537 |
| train_0/mu_grads_std      | 0.44305497631430624   |
| train_0/mu_loss           | 9.738857545155211     |
| train_0/next_q            | -9.731800696581647    |
| train_0/q_grads           | 0.008190983394160866  |
| train_0/q_grads_std       | 0.23327796384692193   |
| train_0/q_loss            | 0.22029223335434023   |
| train_0/reward            | -0.8624422351596877   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0083740234375       |
| train_0/target_q          | -9.956575559692634    |
| train_1/avg_q             | -7.538180824445256    |
| train_1/current_q         | -6.60049464226644     |
| train_1/fw_bonus          | -0.9844569578766823   |
| train_1/fw_loss           | 0.08389845155179501   |
| train_1/mu_grads          | -0.06022640708833933  |
| train_1/mu_grads_std      | 0.3037789538502693    |
| train_1/mu_loss           | 3.03563286013303      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.430944074204272    |
| train_1/q_grads           | -0.18127985186874868  |
| train_1/q_grads_std       | 0.4717144541442394    |
| train_1/q_loss            | 1.0146911142489157    |
| train_1/reward            | -1.5615788033101126   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.612406945528221    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 553.30. Rollout time: 317.30, Training time: 235.95
Evaluating epoch 29
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2730621.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.9999999995742     |
| test_1/avg_q              | -7.539184049441064    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.976895529297696   |
| train_0/current_q         | -9.83641915518507     |
| train_0/fw_bonus          | -0.9985789686441422   |
| train_0/fw_loss           | 0.006970757234375924  |
| train_0/mu_grads          | -0.022786097740754484 |
| train_0/mu_grads_std      | 0.44591736122965814   |
| train_0/mu_loss           | 9.772967600981215     |
| train_0/next_q            | -9.76503526850325     |
| train_0/q_grads           | 0.00810040917713195   |
| train_0/q_grads_std       | 0.2363013058900833    |
| train_0/q_loss            | 0.21366988589557373   |
| train_0/reward            | -0.8626366166965453   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0093505859375       |
| train_0/target_q          | -9.9890833354925      |
| train_1/avg_q             | -7.411444532968974    |
| train_1/current_q         | -7.1303905912298715   |
| train_1/fw_bonus          | -0.9830094203352928   |
| train_1/fw_loss           | 0.09049907177686692   |
| train_1/mu_grads          | -0.061442766711115836 |
| train_1/mu_grads_std      | 0.3064755782485008    |
| train_1/mu_loss           | 3.1960126552739423    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.922736780119817    |
| train_1/q_grads           | -0.1853359632194042   |
| train_1/q_grads_std       | 0.4736628718674183    |
| train_1/q_loss            | 0.9465401838803421    |
| train_1/reward            | -1.5746594106138219   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.126171175652074    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 591.95. Rollout time: 346.22, Training time: 245.67
Evaluating epoch 30
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2821721.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.421524448422435    |
| test_1/avg_q              | -7.243272409333363     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -25.648276566890626    |
| train_0/current_q         | -9.6257915853839       |
| train_0/fw_bonus          | -0.998510380089283     |
| train_0/fw_loss           | 0.007284489716403187   |
| train_0/mu_grads          | -0.0235143328551203    |
| train_0/mu_grads_std      | 0.44999672323465345    |
| train_0/mu_loss           | 9.560988488009897      |
| train_0/next_q            | -9.555269238838454     |
| train_0/q_grads           | 0.005545761715620756   |
| train_0/q_grads_std       | 0.24043147899210454    |
| train_0/q_loss            | 0.31532457360794225    |
| train_0/reward            | -0.8644772571191425    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0100830078125        |
| train_0/target_q          | -9.764431460070668     |
| train_1/avg_q             | -7.53524143572368      |
| train_1/current_q         | -6.943395694566855     |
| train_1/fw_bonus          | -0.9814593836665153    |
| train_1/fw_loss           | 0.097567074932158      |
| train_1/mu_grads          | -0.0615191045217216    |
| train_1/mu_grads_std      | 0.31011108979582785    |
| train_1/mu_loss           | 3.247263965740345      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.585959042225037     |
| train_1/q_grads           | -0.190251861512661     |
| train_1/q_grads_std       | 0.4766334518790245     |
| train_1/q_loss            | 1.4517550373228922     |
| train_1/reward            | -1.5485945398795593    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010498046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -6.946874817263054     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 504.79. Rollout time: 278.99, Training time: 225.76
Evaluating epoch 31
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2912846.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.880892718723857   |
| test_1/avg_q              | -7.078675222430589    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.559911410685817   |
| train_0/current_q         | -9.819638854223408    |
| train_0/fw_bonus          | -0.9982319101691246   |
| train_0/fw_loss           | 0.008557905640918762  |
| train_0/mu_grads          | -0.022850114107131957 |
| train_0/mu_grads_std      | 0.45604864582419397   |
| train_0/mu_loss           | 9.75275905228073      |
| train_0/next_q            | -9.741986585062405    |
| train_0/q_grads           | 0.00578861371614039   |
| train_0/q_grads_std       | 0.243504448980093     |
| train_0/q_loss            | 0.32666941315241693   |
| train_0/reward            | -0.8681563682985143   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0103759765625       |
| train_0/target_q          | -9.969156497546646    |
| train_1/avg_q             | -7.534793927513076    |
| train_1/current_q         | -6.883639367050809    |
| train_1/fw_bonus          | -0.9757182136178016   |
| train_1/fw_loss           | 0.12374621126800775   |
| train_1/mu_grads          | -0.061819550953805445 |
| train_1/mu_grads_std      | 0.31336269304156306   |
| train_1/mu_loss           | 3.3779782083179066    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.496389193677487    |
| train_1/q_grads           | -0.1899466011673212   |
| train_1/q_grads_std       | 0.4786484085023403    |
| train_1/q_loss            | 1.2800999064504297    |
| train_1/reward            | -1.563465910234663    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.888658514167487    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 561.85. Rollout time: 318.98, Training time: 242.83
Evaluating epoch 32
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 3003971.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999996310326   |
| test_1/avg_q              | -7.03867374689756     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.81311344967322    |
| train_0/current_q         | -9.982683345743354    |
| train_0/fw_bonus          | -0.9978552177548409   |
| train_0/fw_loss           | 0.010280804266221822  |
| train_0/mu_grads          | -0.023791295662522315 |
| train_0/mu_grads_std      | 0.4610435962677002    |
| train_0/mu_loss           | 9.896405365367267     |
| train_0/next_q            | -9.875758294267985    |
| train_0/q_grads           | 0.0067008527112193406 |
| train_0/q_grads_std       | 0.24820676185190677   |
| train_0/q_loss            | 0.37304888582803775   |
| train_0/reward            | -0.8745327645767247   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0177490234375       |
| train_0/target_q          | -10.122155692569757   |
| train_1/avg_q             | -7.53678837676552     |
| train_1/current_q         | -6.635229240105777    |
| train_1/fw_bonus          | -0.9692354932427406   |
| train_1/fw_loss           | 0.15330677889287472   |
| train_1/mu_grads          | -0.062161142751574514 |
| train_1/mu_grads_std      | 0.3142612636089325    |
| train_1/mu_loss           | 3.213880304664046     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.2212523703474245   |
| train_1/q_grads           | -0.18265798166394234  |
| train_1/q_grads_std       | 0.4738399267196655    |
| train_1/q_loss            | 1.0279964888659332    |
| train_1/reward            | -1.5435098699141236   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00078125            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.634815140462868    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 587.31. Rollout time: 342.78, Training time: 244.45
Evaluating epoch 33
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 3095096.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.0546926136351     |
| test_1/avg_q              | -5.833699403461722    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.72144027909749    |
| train_0/current_q         | -9.842499588391707    |
| train_0/fw_bonus          | -0.9978355139493942   |
| train_0/fw_loss           | 0.01037087372969836   |
| train_0/mu_grads          | -0.020177894877269863 |
| train_0/mu_grads_std      | 0.4664615891873837    |
| train_0/mu_loss           | 9.814490843880108     |
| train_0/next_q            | -9.805956236554737    |
| train_0/q_grads           | 0.0012324229901423678 |
| train_0/q_grads_std       | 0.25123015120625497   |
| train_0/q_loss            | 0.44455083863285977   |
| train_0/reward            | -0.8745790290791774   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0122314453125       |
| train_0/target_q          | -9.976218049316177    |
| train_1/avg_q             | -7.4451535016473915   |
| train_1/current_q         | -7.000464514741102    |
| train_1/fw_bonus          | -0.969101893901825    |
| train_1/fw_loss           | 0.15391597859561443   |
| train_1/mu_grads          | -0.06342142764478922  |
| train_1/mu_grads_std      | 0.3162649028003216    |
| train_1/mu_loss           | 3.3379541697468937    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.660575031910542    |
| train_1/q_grads           | -0.18205921314656734  |
| train_1/q_grads_std       | 0.47286774814128874   |
| train_1/q_loss            | 1.3175462703918714    |
| train_1/reward            | -1.5484939005342313   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00048828125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.008559129324259    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 592.35. Rollout time: 341.51, Training time: 250.78
Evaluating epoch 34
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 34                   |
| policy/steps              | 3185899.0            |
| test/episodes             | 875.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.872017026473685  |
| test_1/avg_q              | -6.438560262662561   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 3500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -26.407008243522895  |
| train_0/current_q         | -9.910219994890923   |
| train_0/fw_bonus          | -0.9976343259215354  |
| train_0/fw_loss           | 0.011290971119888128 |
| train_0/mu_grads          | -0.01965369116514921 |
| train_0/mu_grads_std      | 0.47430777102708815  |
| train_0/mu_loss           | 9.840673141310024    |
| train_0/next_q            | -9.827385863960624   |
| train_0/q_grads           | 0.001501049249782227 |
| train_0/q_grads_std       | 0.25533624812960626  |
| train_0/q_loss            | 0.4431650194272539   |
| train_0/reward            | -0.8805621748033445  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0139892578125      |
| train_0/target_q          | -10.04754189053284   |
| train_1/avg_q             | -7.396716753205671   |
| train_1/current_q         | -6.855405810725071   |
| train_1/fw_bonus          | -0.9625044122338295  |
| train_1/fw_loss           | 0.18399979658424853  |
| train_1/mu_grads          | -0.06356285214424133 |
| train_1/mu_grads_std      | 0.3170732922852039   |
| train_1/mu_loss           | 3.3261589655195265   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -6.376741716637704   |
| train_1/q_grads           | -0.18285055197775363 |
| train_1/q_grads_std       | 0.4749458633363247   |
| train_1/q_loss            | 1.1962716849831474   |
| train_1/reward            | -1.544357558979391   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0002685546875      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.005555555555555556 |
| train_1/target_q          | -6.85476371182064    |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 601.73. Rollout time: 357.51, Training time: 244.17
Evaluating epoch 35
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 3277024.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.768718768597335   |
| test_1/avg_q              | -7.467810372066249    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.714387205557372   |
| train_0/current_q         | -10.083958132522932   |
| train_0/fw_bonus          | -0.9972661837935448   |
| train_0/fw_loss           | 0.012974686012603343  |
| train_0/mu_grads          | -0.01787657323293388  |
| train_0/mu_grads_std      | 0.48119313046336176   |
| train_0/mu_loss           | 9.978980433004418     |
| train_0/next_q            | -9.963098708559283    |
| train_0/q_grads           | 0.0022654334316030145 |
| train_0/q_grads_std       | 0.2607115671038628    |
| train_0/q_loss            | 0.5603843242504849    |
| train_0/reward            | -0.889917408832116    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0096435546875       |
| train_0/target_q          | -10.234802599950584   |
| train_1/avg_q             | -7.4221130831086635   |
| train_1/current_q         | -6.274254471813163    |
| train_1/fw_bonus          | -0.9605152398347855   |
| train_1/fw_loss           | 0.1930701918900013    |
| train_1/mu_grads          | -0.06452338788658381  |
| train_1/mu_grads_std      | 0.3198170430958271    |
| train_1/mu_loss           | 3.1672578022087463    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.731357397336212    |
| train_1/q_grads           | -0.18322622999548913  |
| train_1/q_grads_std       | 0.47592129185795784   |
| train_1/q_loss            | 1.148101280562071     |
| train_1/reward            | -1.5378180766732839   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000244140625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.27790907136188     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 601.20. Rollout time: 350.95, Training time: 250.19
Evaluating epoch 36
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 36                    |
| policy/steps              | 3368071.0             |
| test/episodes             | 925.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.992719558338315   |
| test_1/avg_q              | -7.274553296516177    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3700.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.93524962387853    |
| train_0/current_q         | -10.303429461392748   |
| train_0/fw_bonus          | -0.997031708061695    |
| train_0/fw_loss           | 0.014047009032219648  |
| train_0/mu_grads          | -0.01816172725521028  |
| train_0/mu_grads_std      | 0.4883238814771175    |
| train_0/mu_loss           | 10.195824102084764    |
| train_0/next_q            | -10.170112283199597   |
| train_0/q_grads           | 0.0023698541335761547 |
| train_0/q_grads_std       | 0.26484298035502435   |
| train_0/q_loss            | 0.5865684570734788    |
| train_0/reward            | -0.8975601613536128   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.010107421875        |
| train_0/target_q          | -10.452129637832156   |
| train_1/avg_q             | -7.460768832443526    |
| train_1/current_q         | -6.892335747623133    |
| train_1/fw_bonus          | -0.9539040446281433   |
| train_1/fw_loss           | 0.22321658134460448   |
| train_1/mu_grads          | -0.06504816692322493  |
| train_1/mu_grads_std      | 0.3205519787967205    |
| train_1/mu_loss           | 3.369423618224721     |
| train_1/n_subgoals        | 2698.0                |
| train_1/next_q            | -6.370628593949156    |
| train_1/q_grads           | -0.18347671814262867  |
| train_1/q_grads_std       | 0.4768359251320362    |
| train_1/q_loss            | 0.9735934453697899    |
| train_1/reward            | -1.5369551350566326   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001708984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.894376301337616    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 613.88. Rollout time: 360.04, Training time: 253.77
Evaluating epoch 37
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 3459196.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.998852899872      |
| test_1/avg_q              | -6.540823947332297    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.9707135215753     |
| train_0/current_q         | -10.408450118815178   |
| train_0/fw_bonus          | -0.9967729181051255   |
| train_0/fw_loss           | 0.01523056677542627   |
| train_0/mu_grads          | -0.018997859116643666 |
| train_0/mu_grads_std      | 0.4928546518087387    |
| train_0/mu_loss           | 10.272151850717261    |
| train_0/next_q            | -10.252041227966279   |
| train_0/q_grads           | 0.0014596358116250486 |
| train_0/q_grads_std       | 0.26847378686070444   |
| train_0/q_loss            | 0.6182197764923207    |
| train_0/reward            | -0.9039273482616409   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008740234375        |
| train_0/target_q          | -10.554631589199394   |
| train_1/avg_q             | -7.4574574364661474   |
| train_1/current_q         | -6.473042033348963    |
| train_1/fw_bonus          | -0.9479397818446159   |
| train_1/fw_loss           | 0.25041297599673273   |
| train_1/mu_grads          | -0.06596935465931893  |
| train_1/mu_grads_std      | 0.32320100963115694   |
| train_1/mu_loss           | 3.1884127609361324    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.882596699197743    |
| train_1/q_grads           | -0.18087139762938023  |
| train_1/q_grads_std       | 0.4807883255183697    |
| train_1/q_loss            | 1.0669579571855619    |
| train_1/reward            | -1.5307058190053795   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001708984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.473551057487107    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 625.68. Rollout time: 372.40, Training time: 253.21
Evaluating epoch 38
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3550321.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.98877434930048    |
| test_1/avg_q              | -6.890824506680813    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.134147163534784   |
| train_0/current_q         | -10.378246124728054   |
| train_0/fw_bonus          | -0.9966224327683448   |
| train_0/fw_loss           | 0.01591877031605691   |
| train_0/mu_grads          | -0.021249248553067444 |
| train_0/mu_grads_std      | 0.49860174432396887   |
| train_0/mu_loss           | 10.286817298191195    |
| train_0/next_q            | -10.26119202424925    |
| train_0/q_grads           | 0.0005400679394369945 |
| train_0/q_grads_std       | 0.27318973243236544   |
| train_0/q_loss            | 0.8757961388797586    |
| train_0/reward            | -0.912103063367249    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008349609375        |
| train_0/target_q          | -10.503476805206166   |
| train_1/avg_q             | -7.358071735811395    |
| train_1/current_q         | -6.496721320779576    |
| train_1/fw_bonus          | -0.9460068613290786   |
| train_1/fw_loss           | 0.25922686830163      |
| train_1/mu_grads          | -0.06637937780469656  |
| train_1/mu_grads_std      | 0.3249249868094921    |
| train_1/mu_loss           | 3.1976872120720126    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.935349259685152    |
| train_1/q_grads           | -0.18044982179999353  |
| train_1/q_grads_std       | 0.4830846332013607    |
| train_1/q_loss            | 1.0686655328068673    |
| train_1/reward            | -1.522450712974387    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.510280050826415    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 588.16. Rollout time: 341.83, Training time: 246.26
Evaluating epoch 39
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 3641446.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999933009712088   |
| test_1/avg_q              | -7.184463717185914    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.676947366521517   |
| train_0/current_q         | -10.30875756864349    |
| train_0/fw_bonus          | -0.9969062939286232   |
| train_0/fw_loss           | 0.014620568044483662  |
| train_0/mu_grads          | -0.020733347907662392 |
| train_0/mu_grads_std      | 0.5041740626096726    |
| train_0/mu_loss           | 10.159707072812076    |
| train_0/next_q            | -10.1325141695682     |
| train_0/q_grads           | 0.0009258838326786645 |
| train_0/q_grads_std       | 0.27863832712173464   |
| train_0/q_loss            | 0.6018765602261054    |
| train_0/reward            | -0.9063284079427831   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049560546875       |
| train_0/target_q          | -10.443478917681578   |
| train_1/avg_q             | -7.481125656890424    |
| train_1/current_q         | -6.885980431626258    |
| train_1/fw_bonus          | -0.9499124526977539   |
| train_1/fw_loss           | 0.24141781963407993   |
| train_1/mu_grads          | -0.06651147566735745  |
| train_1/mu_grads_std      | 0.32625064849853513   |
| train_1/mu_loss           | 3.1584890994820682    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.464028132418823    |
| train_1/q_grads           | -0.17705931700766087  |
| train_1/q_grads_std       | 0.48454868867993356   |
| train_1/q_loss            | 1.0928511886132337    |
| train_1/reward            | -1.511537125948962    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000146484375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.893096995174465    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 614.25. Rollout time: 365.93, Training time: 248.24
Evaluating epoch 40
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 3732571.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.90293888212316    |
| test_1/avg_q              | -7.340585834640857    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.954417539929292   |
| train_0/current_q         | -10.311563271085387   |
| train_0/fw_bonus          | -0.997242434322834    |
| train_0/fw_loss           | 0.01308327168226242   |
| train_0/mu_grads          | -0.02369685531593859  |
| train_0/mu_grads_std      | 0.5075678169727326    |
| train_0/mu_loss           | 10.174809736450332    |
| train_0/next_q            | -10.152294651712952   |
| train_0/q_grads           | 0.0010778540861792862 |
| train_0/q_grads_std       | 0.282677336782217     |
| train_0/q_loss            | 0.4856126357665584    |
| train_0/reward            | -0.8987863208545604   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0068603515625       |
| train_0/target_q          | -10.466012627085139   |
| train_1/avg_q             | -7.487555345862234    |
| train_1/current_q         | -6.724662129357424    |
| train_1/fw_bonus          | -0.9509014993906021   |
| train_1/fw_loss           | 0.23690786585211754   |
| train_1/mu_grads          | -0.0673205602914095   |
| train_1/mu_grads_std      | 0.32698523327708245   |
| train_1/mu_loss           | 3.2597683066161793    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.249359410671153    |
| train_1/q_grads           | -0.17748430296778678  |
| train_1/q_grads_std       | 0.4861042231321335    |
| train_1/q_loss            | 0.6540785346604288    |
| train_1/reward            | -1.5034532278823463   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00029296875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.719203492680293    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 611.05. Rollout time: 361.02, Training time: 249.96
Evaluating epoch 41
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 3823696.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999975474697408   |
| test_1/avg_q              | -7.124109378988914    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.966184961514866   |
| train_0/current_q         | -10.109831148029757   |
| train_0/fw_bonus          | -0.9976681679487228   |
| train_0/fw_loss           | 0.011136277648620307  |
| train_0/mu_grads          | -0.025570296309888364 |
| train_0/mu_grads_std      | 0.5107927531003952    |
| train_0/mu_loss           | 9.974521214724145     |
| train_0/next_q            | -9.955248370921714    |
| train_0/q_grads           | 0.0008365514906472527 |
| train_0/q_grads_std       | 0.2856207177042961    |
| train_0/q_loss            | 0.3607947537839232    |
| train_0/reward            | -0.8906278261711122   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0060302734375       |
| train_0/target_q          | -10.258260608036101   |
| train_1/avg_q             | -7.453243785116279    |
| train_1/current_q         | -7.054493624608524    |
| train_1/fw_bonus          | -0.9536848828196526   |
| train_1/fw_loss           | 0.22421592138707638   |
| train_1/mu_grads          | -0.06867585759609937  |
| train_1/mu_grads_std      | 0.3266721874475479    |
| train_1/mu_loss           | 3.433433548228309     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.7070128900363795   |
| train_1/q_grads           | -0.17790570706129075  |
| train_1/q_grads_std       | 0.4865150511264801    |
| train_1/q_loss            | 0.7989851650560743    |
| train_1/reward            | -1.5337939393750275   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000634765625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.056924772287815    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 801.37. Rollout time: 481.55, Training time: 319.71
Evaluating epoch 42
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3914821.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99250102685002     |
| test_1/avg_q              | -6.584410113955955     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.68188334176555     |
| train_0/current_q         | -9.9054075373988       |
| train_0/fw_bonus          | -0.998036801815033     |
| train_0/fw_loss           | 0.009450268768705427   |
| train_0/mu_grads          | -0.02782643064856529   |
| train_0/mu_grads_std      | 0.5150360688567162     |
| train_0/mu_loss           | 9.837334770474673      |
| train_0/next_q            | -9.8292208346595       |
| train_0/q_grads           | -0.0008511007865308784 |
| train_0/q_grads_std       | 0.2878350704908371     |
| train_0/q_loss            | 0.36621672938046607    |
| train_0/reward            | -0.8815537302070879    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00625                |
| train_0/target_q          | -10.0385202705618      |
| train_1/avg_q             | -7.463614859151475     |
| train_1/current_q         | -6.283886515241275     |
| train_1/fw_bonus          | -0.9576040044426918    |
| train_1/fw_loss           | 0.20634515583515167    |
| train_1/mu_grads          | -0.070293446816504     |
| train_1/mu_grads_std      | 0.3241592265665531     |
| train_1/mu_loss           | 3.0644404117605903     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.735494426565593     |
| train_1/q_grads           | -0.1788606621325016    |
| train_1/q_grads_std       | 0.4876617453992367     |
| train_1/q_loss            | 0.8763274286964226     |
| train_1/reward            | -1.5340660405920061    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.2824255650840755    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 568.53. Rollout time: 330.41, Training time: 238.06
Evaluating epoch 43
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 4005745.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.959210038511284    |
| test_1/avg_q              | -7.494876452534605     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.98452475081168     |
| train_0/current_q         | -9.95556828459128      |
| train_0/fw_bonus          | -0.9981088221073151    |
| train_0/fw_loss           | 0.009120917762629688   |
| train_0/mu_grads          | -0.02602347731590271   |
| train_0/mu_grads_std      | 0.5190662577748298     |
| train_0/mu_loss           | 9.877326725389135      |
| train_0/next_q            | -9.864469292072046     |
| train_0/q_grads           | -0.0008307654090458528 |
| train_0/q_grads_std       | 0.28948086202144624    |
| train_0/q_loss            | 0.3464936757177673     |
| train_0/reward            | -0.8775305924398709    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.008642578125         |
| train_0/target_q          | -10.09203441415535     |
| train_1/avg_q             | -7.486089282243736     |
| train_1/current_q         | -6.428717581114197     |
| train_1/fw_bonus          | -0.9602820664644242    |
| train_1/fw_loss           | 0.19413344450294973    |
| train_1/mu_grads          | -0.07173331379890442   |
| train_1/mu_grads_std      | 0.32502126693725586    |
| train_1/mu_loss           | 3.40287391065          |
| train_1/n_subgoals        | 2693.0                 |
| train_1/next_q            | -5.907847244514798     |
| train_1/q_grads           | -0.17887156940996646   |
| train_1/q_grads_std       | 0.4864106498658657     |
| train_1/q_loss            | 0.8862613268312197     |
| train_1/reward            | -1.5407010542810895    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.4258188166272845    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 771.31. Rollout time: 441.28, Training time: 329.92
Evaluating epoch 44
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 4096449.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999762164139092    |
| test_1/avg_q              | -7.289274475051094     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -26.903720854765197    |
| train_0/current_q         | -10.141544671069706    |
| train_0/fw_bonus          | -0.9974972277879715    |
| train_0/fw_loss           | 0.011917993146926164   |
| train_0/mu_grads          | -0.021591936703771353  |
| train_0/mu_grads_std      | 0.5254935398697853     |
| train_0/mu_loss           | 10.03108629607884      |
| train_0/next_q            | -10.011912086294902    |
| train_0/q_grads           | -0.0007754687962005846 |
| train_0/q_grads_std       | 0.2925104759633541     |
| train_0/q_loss            | 0.3954923922068079     |
| train_0/reward            | -0.8848477766499855    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007568359375         |
| train_0/target_q          | -10.296593280808356    |
| train_1/avg_q             | -7.4778037785613325    |
| train_1/current_q         | -6.876386761171941     |
| train_1/fw_bonus          | -0.9561919391155242    |
| train_1/fw_loss           | 0.2127840608358383     |
| train_1/mu_grads          | -0.07294737119227648   |
| train_1/mu_grads_std      | 0.3262848660349846     |
| train_1/mu_loss           | 3.479041269432726      |
| train_1/n_subgoals        | 2686.0                 |
| train_1/next_q            | -6.391820779489848     |
| train_1/q_grads           | -0.1782998528331518    |
| train_1/q_grads_std       | 0.4889771223068237     |
| train_1/q_loss            | 1.195857690699865      |
| train_1/reward            | -1.5261771522826166    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.877282536278462     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 694.84. Rollout time: 428.33, Training time: 266.39
Evaluating epoch 45
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 45                     |
| policy/steps              | 4186664.0              |
| test/episodes             | 1150.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.928689899755142    |
| test_1/avg_q              | -7.119394607652597     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4600.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -26.989620693601506    |
| train_0/current_q         | -10.310382998756328    |
| train_0/fw_bonus          | -0.9967657640576363    |
| train_0/fw_loss           | 0.015263279480859638   |
| train_0/mu_grads          | -0.02132115778513253   |
| train_0/mu_grads_std      | 0.5290503934025764     |
| train_0/mu_loss           | 10.171140361950597     |
| train_0/next_q            | -10.148304459402315    |
| train_0/q_grads           | -0.0022421234578359874 |
| train_0/q_grads_std       | 0.29462880566716193    |
| train_0/q_loss            | 0.4471966222045197     |
| train_0/reward            | -0.8966282824010705    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007861328125         |
| train_0/target_q          | -10.457740679128705    |
| train_1/avg_q             | -7.4548729980359       |
| train_1/current_q         | -6.746183644582982     |
| train_1/fw_bonus          | -0.953717203438282     |
| train_1/fw_loss           | 0.22406858317553996    |
| train_1/mu_grads          | -0.07394372876733542   |
| train_1/mu_grads_std      | 0.3280121982097626     |
| train_1/mu_loss           | 3.417529910364192      |
| train_1/n_subgoals        | 2667.0                 |
| train_1/next_q            | -6.276175432706154     |
| train_1/q_grads           | -0.180231649056077     |
| train_1/q_grads_std       | 0.4912422113120556     |
| train_1/q_loss            | 0.8211293943066383     |
| train_1/reward            | -1.5361741307224293    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00029296875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.751438914964825     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 788.66. Rollout time: 514.76, Training time: 273.80
Evaluating epoch 46
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 4277253.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99999703692172    |
| test_1/avg_q              | -6.060484827789659    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.03                  |
| train_0/avg_q             | -26.939987982450514   |
| train_0/current_q         | -10.621249496800653   |
| train_0/fw_bonus          | -0.9962021738290787   |
| train_0/fw_loss           | 0.0178407933562994    |
| train_0/mu_grads          | -0.024935452872887252 |
| train_0/mu_grads_std      | 0.5316996663808823    |
| train_0/mu_loss           | 10.456998840876158    |
| train_0/next_q            | -10.427773391792446   |
| train_0/q_grads           | -0.001996815059101209 |
| train_0/q_grads_std       | 0.2964391089975834    |
| train_0/q_loss            | 0.5748762772477696    |
| train_0/reward            | -0.9113484164787223   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006591796875        |
| train_0/target_q          | -10.77273507314762    |
| train_1/avg_q             | -7.467797355228505    |
| train_1/current_q         | -6.771164021033246    |
| train_1/fw_bonus          | -0.9498093649744987   |
| train_1/fw_loss           | 0.24188786707818508   |
| train_1/mu_grads          | -0.07402503024786711  |
| train_1/mu_grads_std      | 0.3320587664842606    |
| train_1/mu_loss           | 3.4237640433895598    |
| train_1/n_subgoals        | 2681.0                |
| train_1/next_q            | -6.265120560939677    |
| train_1/q_grads           | -0.1802992310374975   |
| train_1/q_grads_std       | 0.4942827008664608    |
| train_1/q_loss            | 0.7449057100377798    |
| train_1/reward            | -1.5349827626610932   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001953125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.768483868123331    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 711.57. Rollout time: 466.76, Training time: 244.72
Evaluating epoch 47
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 4367677.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.9683201652572      |
| test_1/avg_q              | -6.745222493209033     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -26.90208698234706     |
| train_0/current_q         | -10.877820375108403    |
| train_0/fw_bonus          | -0.9958465978503227    |
| train_0/fw_loss           | 0.019467019429430365   |
| train_0/mu_grads          | -0.02720538666471839   |
| train_0/mu_grads_std      | 0.5347782388329506     |
| train_0/mu_loss           | 10.686738856064121     |
| train_0/next_q            | -10.655327270338477    |
| train_0/q_grads           | -0.0020296475733630357 |
| train_0/q_grads_std       | 0.29862657114863395    |
| train_0/q_loss            | 0.5972937268459368     |
| train_0/reward            | -0.9220131270718411    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0052001953125        |
| train_0/target_q          | -11.025661224278153    |
| train_1/avg_q             | -7.442444695790346     |
| train_1/current_q         | -7.262520466180874     |
| train_1/fw_bonus          | -0.9444084078073501    |
| train_1/fw_loss           | 0.26651573181152344    |
| train_1/mu_grads          | -0.07476693298667669   |
| train_1/mu_grads_std      | 0.3346616059541702     |
| train_1/mu_loss           | 3.0884516537220015     |
| train_1/n_subgoals        | 2675.0                 |
| train_1/next_q            | -6.92012272299011      |
| train_1/q_grads           | -0.18157214112579823   |
| train_1/q_grads_std       | 0.5002521634101867     |
| train_1/q_loss            | 0.5588873473782876     |
| train_1/reward            | -1.5171747118165513    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0001708984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.259292536058899     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 705.10. Rollout time: 454.13, Training time: 250.87
Evaluating epoch 48
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 4458759.0              |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99731925924209     |
| test_1/avg_q              | -6.1580797429060015    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.945016135993562    |
| train_0/current_q         | -10.896482836596292    |
| train_0/fw_bonus          | -0.9955182492733001    |
| train_0/fw_loss           | 0.020968752028420568   |
| train_0/mu_grads          | -0.029961556289345027  |
| train_0/mu_grads_std      | 0.5389522463083267     |
| train_0/mu_loss           | 10.677573417752484     |
| train_0/next_q            | -10.643493915406925    |
| train_0/q_grads           | -0.0029112270916812123 |
| train_0/q_grads_std       | 0.30078991651535036    |
| train_0/q_loss            | 0.617145983283307      |
| train_0/reward            | -0.9278886830739793    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0044189453125        |
| train_0/target_q          | -11.04736410307717     |
| train_1/avg_q             | -7.4136042455902995    |
| train_1/current_q         | -6.540586274121776     |
| train_1/fw_bonus          | -0.9403289750218391    |
| train_1/fw_loss           | 0.28511755242943765    |
| train_1/mu_grads          | -0.07553741447627545   |
| train_1/mu_grads_std      | 0.3377271965146065     |
| train_1/mu_loss           | 3.485646736370596      |
| train_1/n_subgoals        | 2699.0                 |
| train_1/next_q            | -6.016514612457129     |
| train_1/q_grads           | -0.18457858599722385   |
| train_1/q_grads_std       | 0.5038862302899361     |
| train_1/q_loss            | 0.5219727520845868     |
| train_1/reward            | -1.5235938925099617    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.536424263043129     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 703.87. Rollout time: 451.63, Training time: 252.12
Evaluating epoch 49
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 4549884.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999624887731592   |
| test_1/avg_q              | -7.265726266476994    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.94053650346075    |
| train_0/current_q         | -10.17964159817422    |
| train_0/fw_bonus          | -0.9959199592471123   |
| train_0/fw_loss           | 0.01913154497742653   |
| train_0/mu_grads          | -0.02938524531200528  |
| train_0/mu_grads_std      | 0.5433344572782517    |
| train_0/mu_loss           | 9.934871636432888     |
| train_0/next_q            | -9.896945201393375    |
| train_0/q_grads           | -0.001887017910485156 |
| train_0/q_grads_std       | 0.3049048878252506    |
| train_0/q_loss            | 0.6519426379948345    |
| train_0/reward            | -0.92466213577718     |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0036865234375       |
| train_0/target_q          | -10.27419387741598    |
| train_1/avg_q             | -7.3784905532273      |
| train_1/current_q         | -5.877971717886273    |
| train_1/fw_bonus          | -0.9440236300230026   |
| train_1/fw_loss           | 0.26827025786042213   |
| train_1/mu_grads          | -0.076434594579041    |
| train_1/mu_grads_std      | 0.3385397642850876    |
| train_1/mu_loss           | 3.4828666367866843    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.265681883154703    |
| train_1/q_grads           | -0.18673612289130687  |
| train_1/q_grads_std       | 0.5081254512071609    |
| train_1/q_loss            | 0.3928054499798733    |
| train_1/reward            | -1.5369300775571901   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001708984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -5.877906012876501    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 744.38. Rollout time: 486.05, Training time: 258.20
Evaluating epoch 50
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 50                     |
| policy/steps              | 4641009.0              |
| test/episodes             | 1275.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.996000858126138    |
| test_1/avg_q              | -6.854469460649407     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.963315462969607    |
| train_0/current_q         | -10.626778782467358    |
| train_0/fw_bonus          | -0.9966823056340217    |
| train_0/fw_loss           | 0.01564500853419304    |
| train_0/mu_grads          | -0.03055118736810982   |
| train_0/mu_grads_std      | 0.5468987748026848     |
| train_0/mu_loss           | 10.448385608778171     |
| train_0/next_q            | -10.419862478570803    |
| train_0/q_grads           | -0.0020415076753124593 |
| train_0/q_grads_std       | 0.30773631259799006    |
| train_0/q_loss            | 0.5094996312750097     |
| train_0/reward            | -0.9149128504926921    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0045166015625        |
| train_0/target_q          | -10.777895131647417    |
| train_1/avg_q             | -7.433396081809854     |
| train_1/current_q         | -6.388428403425032     |
| train_1/fw_bonus          | -0.9478511214256287    |
| train_1/fw_loss           | 0.2508172523230314     |
| train_1/mu_grads          | -0.0762985661625862    |
| train_1/mu_grads_std      | 0.3411812484264374     |
| train_1/mu_loss           | 3.3377078177546884     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.880902730392204     |
| train_1/q_grads           | -0.19002091959118844   |
| train_1/q_grads_std       | 0.5116876944899559     |
| train_1/q_loss            | 0.45532033598325083    |
| train_1/reward            | -1.5339962582540465    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000146484375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.386276460317485     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 813.11. Rollout time: 516.53, Training time: 296.48
Evaluating epoch 51
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 4731919.0              |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -26.999993900978122    |
| test_1/avg_q              | -6.1113208262601395    |
| test_1/n_subgoals         | 668.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.996147539629373    |
| train_0/current_q         | -10.316581465752302    |
| train_0/fw_bonus          | -0.9970983162522316    |
| train_0/fw_loss           | 0.013742396142333746   |
| train_0/mu_grads          | -0.029781897692009805  |
| train_0/mu_grads_std      | 0.5495665073394775     |
| train_0/mu_loss           | 10.1606069896857       |
| train_0/next_q            | -10.136536244357732    |
| train_0/q_grads           | -0.0012907785829156637 |
| train_0/q_grads_std       | 0.30967404767870904    |
| train_0/q_loss            | 0.4443458163059688     |
| train_0/reward            | -0.9018581618380267    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0055419921875        |
| train_0/target_q          | -10.465283890242258    |
| train_1/avg_q             | -7.466150271544875     |
| train_1/current_q         | -6.18115449774048      |
| train_1/fw_bonus          | -0.9521595984697342    |
| train_1/fw_loss           | 0.23117111325263978    |
| train_1/mu_grads          | -0.0762406598776579    |
| train_1/mu_grads_std      | 0.3427103295922279     |
| train_1/mu_loss           | 3.4222294531154915     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.6668089061892       |
| train_1/q_grads           | -0.19218644946813584   |
| train_1/q_grads_std       | 0.5147570386528969     |
| train_1/q_loss            | 0.4342610432483943     |
| train_1/reward            | -1.5099570962847793    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00029296875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.1837827331006725    |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 52
Time for epoch 52: 762.69. Rollout time: 484.78, Training time: 277.82
Evaluating epoch 52
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 4822822.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.972845880118655   |
| test_1/avg_q              | -7.240320907042438    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -26.931070956581564   |
| train_0/current_q         | -10.178822074104769   |
| train_0/fw_bonus          | -0.9976202860474587   |
| train_0/fw_loss           | 0.01135520467069      |
| train_0/mu_grads          | -0.03047201717272401  |
| train_0/mu_grads_std      | 0.5524142771959305    |
| train_0/mu_loss           | 10.049862439472989    |
| train_0/next_q            | -10.031553070633208   |
| train_0/q_grads           | -0.001256790419574827 |
| train_0/q_grads_std       | 0.3113425925374031    |
| train_0/q_loss            | 0.39344743858076586   |
| train_0/reward            | -0.8901646779893782   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006787109375        |
| train_0/target_q          | -10.328354176269135   |
| train_1/avg_q             | -7.424378999179865    |
| train_1/current_q         | -5.98343823730673     |
| train_1/fw_bonus          | -0.9563617810606957   |
| train_1/fw_loss           | 0.21200956553220748   |
| train_1/mu_grads          | -0.0761698542162776   |
| train_1/mu_grads_std      | 0.34253356531262397   |
| train_1/mu_loss           | 3.5131662092710365    |
| train_1/n_subgoals        | 2693.0                |
| train_1/next_q            | -5.519690985532963    |
| train_1/q_grads           | -0.19261721558868886  |
| train_1/q_grads_std       | 0.5203383758664131    |
| train_1/q_loss            | 0.6384466419509047    |
| train_1/reward            | -1.5454573705777874   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005126953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -5.9871805579356      |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 53
Time for epoch 53: 836.36. Rollout time: 538.85, Training time: 297.36
Evaluating epoch 53
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 4913449.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -26.996737561741135    |
| test_1/avg_q              | -7.153235616592544     |
| test_1/n_subgoals         | 658.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.897505247417133    |
| train_0/current_q         | -10.162716420878912    |
| train_0/fw_bonus          | -0.9978824838995933    |
| train_0/fw_loss           | 0.010156033630482852   |
| train_0/mu_grads          | -0.0314198799431324    |
| train_0/mu_grads_std      | 0.554651340842247      |
| train_0/mu_loss           | 10.043672852773453     |
| train_0/next_q            | -10.026476281521536    |
| train_0/q_grads           | -0.0010972589894663542 |
| train_0/q_grads_std       | 0.31390591859817507    |
| train_0/q_loss            | 0.33959695395840683    |
| train_0/reward            | -0.8852954131434672    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0060546875           |
| train_0/target_q          | -10.31329952163215     |
| train_1/avg_q             | -7.393360951158843     |
| train_1/current_q         | -5.456552770422149     |
| train_1/fw_bonus          | -0.9588633134961129    |
| train_1/fw_loss           | 0.20060279704630374    |
| train_1/mu_grads          | -0.07578220404684544   |
| train_1/mu_grads_std      | 0.3432222746312618     |
| train_1/mu_loss           | 3.4604938474198734     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.852193425071515     |
| train_1/q_grads           | -0.1958440277725458    |
| train_1/q_grads_std       | 0.5221857190132141     |
| train_1/q_loss            | 0.46301098231386695    |
| train_1/reward            | -1.542102814192185     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -5.4566024221049085    |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 54
Time for epoch 54: 801.86. Rollout time: 527.27, Training time: 274.49
Evaluating epoch 54
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 5003792.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -5.138902952731228     |
| test_1/n_subgoals         | 658.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -26.913392013363556    |
| train_0/current_q         | -10.196196454320056    |
| train_0/fw_bonus          | -0.9976202830672264    |
| train_0/fw_loss           | 0.011355247930623591   |
| train_0/mu_grads          | -0.03040054328739643   |
| train_0/mu_grads_std      | 0.5569602116942406     |
| train_0/mu_loss           | 10.066725435720002     |
| train_0/next_q            | -10.04043996055618     |
| train_0/q_grads           | -0.0003137521256576292 |
| train_0/q_grads_std       | 0.3160689502954483     |
| train_0/q_loss            | 0.3556294780697864     |
| train_0/reward            | -0.8913060289123678    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.008203125            |
| train_0/target_q          | -10.349867028008394    |
| train_1/avg_q             | -7.461479298369028     |
| train_1/current_q         | -5.874497712869744     |
| train_1/fw_bonus          | -0.9567797228693962    |
| train_1/fw_loss           | 0.2101037710905075     |
| train_1/mu_grads          | -0.07533026412129402   |
| train_1/mu_grads_std      | 0.3436231970787048     |
| train_1/mu_loss           | 3.9773575331206645     |
| train_1/n_subgoals        | 2690.0                 |
| train_1/next_q            | -5.425326659074018     |
| train_1/q_grads           | -0.19703322872519494   |
| train_1/q_grads_std       | 0.5228286936879158     |
| train_1/q_loss            | 2.9906130863325404     |
| train_1/reward            | -1.535571855174203     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -5.927991924291851     |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 55
Time for epoch 55: 837.95. Rollout time: 545.65, Training time: 292.18
Evaluating epoch 55
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 5094917.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999891557    |
| test_1/avg_q              | -7.1715632905915605    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.993934043997488    |
| train_0/current_q         | -10.215602191652518    |
| train_0/fw_bonus          | -0.9976321652531623    |
| train_0/fw_loss           | 0.011300886492244899   |
| train_0/mu_grads          | -0.030198570247739552  |
| train_0/mu_grads_std      | 0.5591535925865173     |
| train_0/mu_loss           | 10.077704393949716     |
| train_0/next_q            | -10.059074783559797    |
| train_0/q_grads           | -0.0029672070872038604 |
| train_0/q_grads_std       | 0.31766002625226974    |
| train_0/q_loss            | 0.37812779437028576    |
| train_0/reward            | -0.8915957049248391    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00654296875          |
| train_0/target_q          | -10.366753414170763    |
| train_1/avg_q             | -6.9625817807748565    |
| train_1/current_q         | -6.5492953014948085    |
| train_1/fw_bonus          | -0.9592978715896606    |
| train_1/fw_loss           | 0.1986212994903326     |
| train_1/mu_grads          | -0.07566338982433081   |
| train_1/mu_grads_std      | 0.34481874033808707    |
| train_1/mu_loss           | 3.643656824471165      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.074190978466155     |
| train_1/q_grads           | -0.19891067296266557   |
| train_1/q_grads_std       | 0.5247134804725647     |
| train_1/q_loss            | 0.96354744488563       |
| train_1/reward            | -1.5487702783160784    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00029296875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.547062260283951     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 56
Time for epoch 56: 848.30. Rollout time: 561.95, Training time: 286.25
Evaluating epoch 56
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 5186042.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.998809364956145   |
| test_1/avg_q              | -7.326471836456945    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.986676438497046   |
| train_0/current_q         | -10.335816547867614   |
| train_0/fw_bonus          | -0.9975459933280945   |
| train_0/fw_loss           | 0.01169504232238978   |
| train_0/mu_grads          | -0.02842389433644712  |
| train_0/mu_grads_std      | 0.5618136167526245    |
| train_0/mu_loss           | 10.196871334722227    |
| train_0/next_q            | -10.174269570538346   |
| train_0/q_grads           | -0.002713671687524766 |
| train_0/q_grads_std       | 0.31968304961919786   |
| train_0/q_loss            | 0.4290519498517157    |
| train_0/reward            | -0.8961270145198796   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0060302734375       |
| train_0/target_q          | -10.487276569122805   |
| train_1/avg_q             | -7.522769260429885    |
| train_1/current_q         | -7.0479811550831215   |
| train_1/fw_bonus          | -0.9579340875148773   |
| train_1/fw_loss           | 0.20484000705182553   |
| train_1/mu_grads          | -0.07595025822520256  |
| train_1/mu_grads_std      | 0.34536137580871584   |
| train_1/mu_loss           | 3.660404186496707     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.736835022303074    |
| train_1/q_grads           | -0.20113668777048588  |
| train_1/q_grads_std       | 0.5253051325678826    |
| train_1/q_loss            | 0.835618516953275     |
| train_1/reward            | -1.525170536601945    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0004150390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.055757966630949    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 57
Time for epoch 57: 767.66. Rollout time: 491.11, Training time: 276.45
Evaluating epoch 57
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 5276960.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.924930972618004   |
| test_1/avg_q              | -7.276089003014834    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.749838467329077   |
| train_0/current_q         | -10.376725774457858   |
| train_0/fw_bonus          | -0.9973169952630997   |
| train_0/fw_loss           | 0.012742288177832961  |
| train_0/mu_grads          | -0.02947003869339824  |
| train_0/mu_grads_std      | 0.5650357156991959    |
| train_0/mu_loss           | 10.224865884447363    |
| train_0/next_q            | -10.203088120497629   |
| train_0/q_grads           | -0.002454387809848413 |
| train_0/q_grads_std       | 0.3221805363893509    |
| train_0/q_loss            | 0.47239171433815585   |
| train_0/reward            | -0.9013751976948697   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0063720703125       |
| train_0/target_q          | -10.521630612440257   |
| train_1/avg_q             | -7.424815869103613    |
| train_1/current_q         | -7.130454319033899    |
| train_1/fw_bonus          | -0.9553004622459411   |
| train_1/fw_loss           | 0.21684909611940384   |
| train_1/mu_grads          | -0.07625898774713277  |
| train_1/mu_grads_std      | 0.34695180132985115   |
| train_1/mu_loss           | 3.826974831595102     |
| train_1/n_subgoals        | 2693.0                |
| train_1/next_q            | -6.722226514818026    |
| train_1/q_grads           | -0.2034519013017416   |
| train_1/q_grads_std       | 0.5283516854047775    |
| train_1/q_loss            | 0.6588134697929949    |
| train_1/reward            | -1.5249226080493827   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0003662109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0003713330857779428 |
| train_1/target_q          | -7.129519206013955    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 58
Time for epoch 58: 727.89. Rollout time: 466.39, Training time: 261.40
Evaluating epoch 58
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 5367647.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.866403180859166   |
| test_1/avg_q              | -7.9396859811352325   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -26.511395721525023   |
| train_0/current_q         | -10.414280682917164   |
| train_0/fw_bonus          | -0.9971755087375641   |
| train_0/fw_loss           | 0.013389386981725693  |
| train_0/mu_grads          | -0.02898279530927539  |
| train_0/mu_grads_std      | 0.5693105846643448    |
| train_0/mu_loss           | 10.255712968327806    |
| train_0/next_q            | -10.226129797485033   |
| train_0/q_grads           | -0.001153627212624997 |
| train_0/q_grads_std       | 0.32403270304203036   |
| train_0/q_loss            | 0.494366102651151     |
| train_0/reward            | -0.903863073787943    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00673828125         |
| train_0/target_q          | -10.562806638575367   |
| train_1/avg_q             | -7.662625091943821    |
| train_1/current_q         | -8.168585945428273    |
| train_1/fw_bonus          | -0.9552954450249672   |
| train_1/fw_loss           | 0.21687196455895902   |
| train_1/mu_grads          | -0.07669624369591474  |
| train_1/mu_grads_std      | 0.34844665974378586   |
| train_1/mu_loss           | 4.58272541039983      |
| train_1/n_subgoals        | 2685.0                |
| train_1/next_q            | -8.138811972553592    |
| train_1/q_grads           | -0.20291221477091312  |
| train_1/q_grads_std       | 0.5291153833270072    |
| train_1/q_loss            | 1.7381326218087019    |
| train_1/reward            | -1.5324322746848338   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000341796875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -8.161894822519809    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 744.45. Rollout time: 478.42, Training time: 265.90
Evaluating epoch 59
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 5458487.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999879517862     |
| test_1/avg_q              | -7.551463493637038     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.718672585328513    |
| train_0/current_q         | -10.33218745524693     |
| train_0/fw_bonus          | -0.9971831262111663    |
| train_0/fw_loss           | 0.013354499195702373   |
| train_0/mu_grads          | -0.02871991293504834   |
| train_0/mu_grads_std      | 0.5724316015839577     |
| train_0/mu_loss           | 10.1834969338923       |
| train_0/next_q            | -10.157686074268948    |
| train_0/q_grads           | -0.0003128266958810855 |
| train_0/q_grads_std       | 0.3259072326123714     |
| train_0/q_loss            | 0.48588657125960555    |
| train_0/reward            | -0.8998282677435782    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007177734375         |
| train_0/target_q          | -10.477239457819485    |
| train_1/avg_q             | -7.6875177849064285    |
| train_1/current_q         | -7.278036067167136     |
| train_1/fw_bonus          | -0.9562451526522636    |
| train_1/fw_loss           | 0.21254142001271248    |
| train_1/mu_grads          | -0.07693155836313963   |
| train_1/mu_grads_std      | 0.35010352581739423    |
| train_1/mu_loss           | 4.043154988630394      |
| train_1/n_subgoals        | 2691.0                 |
| train_1/next_q            | -7.139385955367314     |
| train_1/q_grads           | -0.20353395566344262   |
| train_1/q_grads_std       | 0.5314174339175224     |
| train_1/q_loss            | 0.3829358484765525     |
| train_1/reward            | -1.527785664419207     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0002197265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0007432181345224824  |
| train_1/target_q          | -7.276020991503671     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 750.79. Rollout time: 484.21, Training time: 266.44
Evaluating epoch 60
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 5549101.0             |
| test/episodes             | 1525.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.739568415288122   |
| test_1/avg_q              | -7.102703530958748    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.8450734843967     |
| train_0/current_q         | -10.608494587418864   |
| train_0/fw_bonus          | -0.9968617036938667   |
| train_0/fw_loss           | 0.014824460097588598  |
| train_0/mu_grads          | -0.02835685112513602  |
| train_0/mu_grads_std      | 0.5747762158513069    |
| train_0/mu_loss           | 10.43983678175957     |
| train_0/next_q            | -10.412952800179617   |
| train_0/q_grads           | 8.771105267157964e-06 |
| train_0/q_grads_std       | 0.32671840861439705   |
| train_0/q_loss            | 0.5299860808688598    |
| train_0/reward            | -0.905538135318784    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0073974609375       |
| train_0/target_q          | -10.757691945970038   |
| train_1/avg_q             | -7.493224832018396    |
| train_1/current_q         | -7.337255125464415    |
| train_1/fw_bonus          | -0.9517972752451896   |
| train_1/fw_loss           | 0.23282319791615008   |
| train_1/mu_grads          | -0.07733282279223204  |
| train_1/mu_grads_std      | 0.3516670122742653    |
| train_1/mu_loss           | 4.049882804475285     |
| train_1/n_subgoals        | 2684.0                |
| train_1/next_q            | -7.066570472368605    |
| train_1/q_grads           | -0.20442074909806252  |
| train_1/q_grads_std       | 0.5349756702780724    |
| train_1/q_loss            | 0.5879304047006141    |
| train_1/reward            | -1.5153677384550974   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000439453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0011177347242921013 |
| train_1/target_q          | -7.333484987995462    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 727.79. Rollout time: 471.97, Training time: 255.72
Evaluating epoch 61
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-------------------------------------------------------
| epoch                     | 61                      |
| policy/steps              | 5640011.0               |
| test/episodes             | 1550.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -26.999999541695292     |
| test_1/avg_q              | -7.245389790711216      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6200.0                  |
| train/success_rate        | 0.01                    |
| train_0/avg_q             | -26.96804114904377      |
| train_0/current_q         | -10.528060496491557     |
| train_0/fw_bonus          | -0.9965124920010566     |
| train_0/fw_loss           | 0.01642159014008939     |
| train_0/mu_grads          | -0.025910520693287253   |
| train_0/mu_grads_std      | 0.5780181050300598      |
| train_0/mu_loss           | 10.394890786995552      |
| train_0/next_q            | -10.365094496175342     |
| train_0/q_grads           | -0.00025725913656060584 |
| train_0/q_grads_std       | 0.32718013525009154     |
| train_0/q_loss            | 0.6571022237513647      |
| train_0/reward            | -0.9078824221767718     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.005224609375          |
| train_0/target_q          | -10.683913221289329     |
| train_1/avg_q             | -7.388710336156519      |
| train_1/current_q         | -7.197040614665755      |
| train_1/fw_bonus          | -0.9474899515509605     |
| train_1/fw_loss           | 0.25246418118476865     |
| train_1/mu_grads          | -0.07812975160777569    |
| train_1/mu_grads_std      | 0.3533748209476471      |
| train_1/mu_loss           | 4.103622525700876       |
| train_1/n_subgoals        | 2693.0                  |
| train_1/next_q            | -6.694989427874941      |
| train_1/q_grads           | -0.2076771792024374     |
| train_1/q_grads_std       | 0.5379884883761406      |
| train_1/q_loss            | 0.7994299932333501      |
| train_1/reward            | -1.5240818205020332     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 7.32421875e-05          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0003713330857779428   |
| train_1/target_q          | -7.201465572469678      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 792.48. Rollout time: 506.79, Training time: 285.57
Evaluating epoch 62
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 5730713.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.740063384753062    |
| test_1/n_subgoals         | 669.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.96617178192002    |
| train_0/current_q         | -10.619797753074641   |
| train_0/fw_bonus          | -0.9960708096623421   |
| train_0/fw_loss           | 0.018441653857007623  |
| train_0/mu_grads          | -0.02525070789270103  |
| train_0/mu_grads_std      | 0.5801050364971161    |
| train_0/mu_loss           | 10.456230215222877    |
| train_0/next_q            | -10.419036061333095   |
| train_0/q_grads           | 0.0007720556415733882 |
| train_0/q_grads_std       | 0.3286444194614887    |
| train_0/q_loss            | 0.570378270412005     |
| train_0/reward            | -0.9117991974606412   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00625               |
| train_0/target_q          | -10.771920347370818   |
| train_1/avg_q             | -7.437694921346412    |
| train_1/current_q         | -7.013291542038688    |
| train_1/fw_bonus          | -0.945409531891346    |
| train_1/fw_loss           | 0.2619507037103176    |
| train_1/mu_grads          | -0.078421101719141    |
| train_1/mu_grads_std      | 0.35390336737036704   |
| train_1/mu_loss           | 3.7816241014532608    |
| train_1/n_subgoals        | 2691.0                |
| train_1/next_q            | -6.50888835877961     |
| train_1/q_grads           | -0.20975929088890552  |
| train_1/q_grads_std       | 0.5432923674583435    |
| train_1/q_loss            | 0.7764210392317532    |
| train_1/reward            | -1.5284174983731647   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000244140625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.0199787775962035   |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 63
Time for epoch 63: 741.13. Rollout time: 480.05, Training time: 261.00
Evaluating epoch 63
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-------------------------------------------------------
| epoch                     | 63                      |
| policy/steps              | 5821805.0               |
| test/episodes             | 1600.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.234100297293178      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6400.0                  |
| train/success_rate        | 0.01                    |
| train_0/avg_q             | -26.991453152924855     |
| train_0/current_q         | -10.78942898659363      |
| train_0/fw_bonus          | -0.995831947028637      |
| train_0/fw_loss           | 0.019534019567072392    |
| train_0/mu_grads          | -0.023683837335556745   |
| train_0/mu_grads_std      | 0.5822627589106559      |
| train_0/mu_loss           | 10.607860967562743      |
| train_0/next_q            | -10.576014397869292     |
| train_0/q_grads           | -0.00022392421597032807 |
| train_0/q_grads_std       | 0.32997442185878756     |
| train_0/q_loss            | 0.6499372250785901      |
| train_0/reward            | -0.9188527258942486     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.004443359375          |
| train_0/target_q          | -10.94664632410298      |
| train_1/avg_q             | -7.368052517024309      |
| train_1/current_q         | -6.966492292600195      |
| train_1/fw_bonus          | -0.9406855091452598     |
| train_1/fw_loss           | 0.28349175825715067     |
| train_1/mu_grads          | -0.07907415460795164    |
| train_1/mu_grads_std      | 0.3558999076485634      |
| train_1/mu_loss           | 3.8735140782665676      |
| train_1/n_subgoals        | 2699.0                  |
| train_1/next_q            | -6.4271372533859665     |
| train_1/q_grads           | -0.21161041520535945    |
| train_1/q_grads_std       | 0.5486678048968315      |
| train_1/q_loss            | 0.7989410915095047      |
| train_1/reward            | -1.5274074402012048     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 9.765625e-05            |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -6.966429731285989      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 64
Time for epoch 64: 728.15. Rollout time: 466.99, Training time: 261.06
Evaluating epoch 64
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 5912164.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -26.999999999995424    |
| test_1/avg_q              | -6.815889467191106     |
| test_1/n_subgoals         | 662.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.994089834928634    |
| train_0/current_q         | -10.944442043064015    |
| train_0/fw_bonus          | -0.9956700205802917    |
| train_0/fw_loss           | 0.02027461170218885    |
| train_0/mu_grads          | -0.023911691410467027  |
| train_0/mu_grads_std      | 0.5847902104258538     |
| train_0/mu_loss           | 10.75144881045228      |
| train_0/next_q            | -10.714802343699356    |
| train_0/q_grads           | -0.0011982872005319224 |
| train_0/q_grads_std       | 0.33155478835105895    |
| train_0/q_loss            | 0.6728151901989367     |
| train_0/reward            | -0.9234248790817219    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00478515625          |
| train_0/target_q          | -11.09542566394215     |
| train_1/avg_q             | -7.514414130919376     |
| train_1/current_q         | -7.2557212803785065    |
| train_1/fw_bonus          | -0.9357889160513878    |
| train_1/fw_loss           | 0.30581971555948256    |
| train_1/mu_grads          | -0.07929357774555683   |
| train_1/mu_grads_std      | 0.35583987459540367    |
| train_1/mu_loss           | 3.7439885141549936     |
| train_1/n_subgoals        | 2686.0                 |
| train_1/next_q            | -6.868166013803313     |
| train_1/q_grads           | -0.2134825348854065    |
| train_1/q_grads_std       | 0.5536914750933647     |
| train_1/q_loss            | 0.5557292636861091     |
| train_1/reward            | -1.5247542833720218    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0001220703125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.260879891808384     |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 65
Time for epoch 65: 722.67. Rollout time: 464.94, Training time: 257.62
Evaluating epoch 65
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 65                     |
| policy/steps              | 6002861.0              |
| test/episodes             | 1650.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.904600088534192    |
| test_1/avg_q              | -5.412275514140248     |
| test_1/n_subgoals         | 678.0                  |
| test_1/subgoal_succ_rate  | 0.004424778761061947   |
| train/episodes            | 6600.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -26.993919386292056    |
| train_0/current_q         | -10.895558526997423    |
| train_0/fw_bonus          | -0.9958840101957321    |
| train_0/fw_loss           | 0.019295963644981384   |
| train_0/mu_grads          | -0.022785282181575894  |
| train_0/mu_grads_std      | 0.5878927662968636     |
| train_0/mu_loss           | 10.700820193421738     |
| train_0/next_q            | -10.6622875801689      |
| train_0/q_grads           | -0.0011774963204516098 |
| train_0/q_grads_std       | 0.3340971380472183     |
| train_0/q_loss            | 0.7018853831793003     |
| train_0/reward            | -0.9261427411198383    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0046630859375        |
| train_0/target_q          | -11.046912667034253    |
| train_1/avg_q             | -7.479207231257879     |
| train_1/current_q         | -7.147298322163964     |
| train_1/fw_bonus          | -0.9328789100050926    |
| train_1/fw_loss           | 0.3190890192985535     |
| train_1/mu_grads          | -0.07972291000187397   |
| train_1/mu_grads_std      | 0.35709292367100715    |
| train_1/mu_loss           | 3.4526033583431115     |
| train_1/n_subgoals        | 2686.0                 |
| train_1/next_q            | -6.650222810300138     |
| train_1/q_grads           | -0.2156865183264017    |
| train_1/q_grads_std       | 0.5583178877830506     |
| train_1/q_loss            | 0.7120331142135214     |
| train_1/reward            | -1.5161936081174645    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037230081906180194 |
| train_1/target_q          | -7.158123879520379     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 66
Time for epoch 66: 725.19. Rollout time: 466.81, Training time: 258.28
Evaluating epoch 66
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 6093876.0              |
| test/episodes             | 1675.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999997856     |
| test_1/avg_q              | -6.27069689640884      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.93910195268529     |
| train_0/current_q         | -10.829279466861042    |
| train_0/fw_bonus          | -0.9959468856453896    |
| train_0/fw_loss           | 0.01900841104798019    |
| train_0/mu_grads          | -0.02215829035267234   |
| train_0/mu_grads_std      | 0.5910040691494942     |
| train_0/mu_loss           | 10.61003069270915      |
| train_0/next_q            | -10.579803480540772    |
| train_0/q_grads           | -0.0012234488793183118 |
| train_0/q_grads_std       | 0.33664544075727465    |
| train_0/q_loss            | 0.6552498216884712     |
| train_0/reward            | -0.9256588912758161    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0049072265625        |
| train_0/target_q          | -10.97794486066616     |
| train_1/avg_q             | -7.410472735126794     |
| train_1/current_q         | -7.15505896948317      |
| train_1/fw_bonus          | -0.9321545094251633    |
| train_1/fw_loss           | 0.3223922446370125     |
| train_1/mu_grads          | -0.07993092015385628   |
| train_1/mu_grads_std      | 0.35790743604302405    |
| train_1/mu_loss           | 3.6628999748967788     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.644506768683516     |
| train_1/q_grads           | -0.21685012467205525   |
| train_1/q_grads_std       | 0.5620584964752198     |
| train_1/q_loss            | 0.7653112684547873     |
| train_1/reward            | -1.4948129012678693    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.001851851851851852   |
| train_1/target_q          | -7.150593864665112     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 67
Time for epoch 67: 705.89. Rollout time: 451.69, Training time: 254.07
Evaluating epoch 67
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 6184568.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.341093205048469     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.989746148592573    |
| train_0/current_q         | -10.695801455686583    |
| train_0/fw_bonus          | -0.9963504105806351    |
| train_0/fw_loss           | 0.017162911407649518   |
| train_0/mu_grads          | -0.019690639432519676  |
| train_0/mu_grads_std      | 0.594032983481884      |
| train_0/mu_loss           | 10.506903766385367     |
| train_0/next_q            | -10.470511735753552    |
| train_0/q_grads           | -0.0016549400781514124 |
| train_0/q_grads_std       | 0.3385348804295063     |
| train_0/q_loss            | 0.5861954560944639     |
| train_0/reward            | -0.9186373173157335    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0069580078125        |
| train_0/target_q          | -10.851004545099197    |
| train_1/avg_q             | -7.305447820629657     |
| train_1/current_q         | -7.200162866513514     |
| train_1/fw_bonus          | -0.9345529466867447    |
| train_1/fw_loss           | 0.31145559176802634    |
| train_1/mu_grads          | -0.07966692298650742   |
| train_1/mu_grads_std      | 0.36020257845520975    |
| train_1/mu_loss           | 3.56397461706741       |
| train_1/n_subgoals        | 2685.0                 |
| train_1/next_q            | -6.7516602834399775    |
| train_1/q_grads           | -0.21636699177324772   |
| train_1/q_grads_std       | 0.565811276435852      |
| train_1/q_loss            | 0.7736128628447552     |
| train_1/reward            | -1.521965736252605     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037243947858472997 |
| train_1/target_q          | -7.203254516202406     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 68
Time for epoch 68: 714.95. Rollout time: 462.68, Training time: 252.18
Evaluating epoch 68
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 6275693.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999987345   |
| test_1/avg_q              | -5.863213949236066    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.94122883044041    |
| train_0/current_q         | -10.58604002325538    |
| train_0/fw_bonus          | -0.9966744661331177   |
| train_0/fw_loss           | 0.015680822310969234  |
| train_0/mu_grads          | -0.020229575084522368 |
| train_0/mu_grads_std      | 0.5974165201187134    |
| train_0/mu_loss           | 10.422820566043825    |
| train_0/next_q            | -10.393522253508475   |
| train_0/q_grads           | -0.00232290449202992  |
| train_0/q_grads_std       | 0.3403602108359337    |
| train_0/q_loss            | 0.5581373930488432    |
| train_0/reward            | -0.9094565379869891   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0076171875          |
| train_0/target_q          | -10.737443461254877   |
| train_1/avg_q             | -7.267185293606469    |
| train_1/current_q         | -7.124796115166108    |
| train_1/fw_bonus          | -0.9381319582462311   |
| train_1/fw_loss           | 0.29513565376400946   |
| train_1/mu_grads          | -0.07998398672789335  |
| train_1/mu_grads_std      | 0.362165966629982     |
| train_1/mu_loss           | 3.2702584182966055    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.737891695532943    |
| train_1/q_grads           | -0.21849702820181846  |
| train_1/q_grads_std       | 0.5665228173136712    |
| train_1/q_loss            | 0.821067369906473     |
| train_1/reward            | -1.5200784655986355   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.128769550460397    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 723.37. Rollout time: 475.00, Training time: 248.26
Evaluating epoch 69
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 6366759.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.997429346566985    |
| test_1/avg_q              | -7.381474517920387     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.968169477293902    |
| train_0/current_q         | -10.467668802776167    |
| train_0/fw_bonus          | -0.9966130524873733    |
| train_0/fw_loss           | 0.015961659350432457   |
| train_0/mu_grads          | -0.020016884477809072  |
| train_0/mu_grads_std      | 0.6004761785268784     |
| train_0/mu_loss           | 10.301157033888702     |
| train_0/next_q            | -10.27620833122443     |
| train_0/q_grads           | -0.0026464719732757656 |
| train_0/q_grads_std       | 0.3416838951408863     |
| train_0/q_loss            | 0.5108948687597962     |
| train_0/reward            | -0.907432944093307     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00712890625          |
| train_0/target_q          | -10.621580558278419    |
| train_1/avg_q             | -7.361810126433172     |
| train_1/current_q         | -6.514626942521294     |
| train_1/fw_bonus          | -0.9404604151844979    |
| train_1/fw_loss           | 0.2845181480050087     |
| train_1/mu_grads          | -0.07985891569405794   |
| train_1/mu_grads_std      | 0.3644479617476463     |
| train_1/mu_loss           | 3.6155534423363695     |
| train_1/n_subgoals        | 2698.0                 |
| train_1/next_q            | -5.965865978036385     |
| train_1/q_grads           | -0.2221463516354561    |
| train_1/q_grads_std       | 0.5707275167107582     |
| train_1/q_loss            | 1.6102508777715865     |
| train_1/reward            | -1.5133226064237533    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.507234767585717     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 659.75. Rollout time: 424.68, Training time: 234.98
Evaluating epoch 70
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 6457666.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.706033254261985     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.99938890691195     |
| train_0/current_q         | -10.40309266023233     |
| train_0/fw_bonus          | -0.9969008177518844    |
| train_0/fw_loss           | 0.014645625650882722   |
| train_0/mu_grads          | -0.020682801166549324  |
| train_0/mu_grads_std      | 0.6032409906387329     |
| train_0/mu_loss           | 10.248237308568575     |
| train_0/next_q            | -10.225232932074196    |
| train_0/q_grads           | -0.0034031103656161576 |
| train_0/q_grads_std       | 0.34308357164263725    |
| train_0/q_loss            | 0.44995416298713575    |
| train_0/reward            | -0.9005259586323519    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0092529296875        |
| train_0/target_q          | -10.55301713816126     |
| train_1/avg_q             | -7.601260525512784     |
| train_1/current_q         | -7.784082448690532     |
| train_1/fw_bonus          | -0.9464045733213424    |
| train_1/fw_loss           | 0.25741343311965464    |
| train_1/mu_grads          | -0.08111306242644786   |
| train_1/mu_grads_std      | 0.3661029912531376     |
| train_1/mu_loss           | 3.208260322229357      |
| train_1/n_subgoals        | 2692.0                 |
| train_1/next_q            | -7.995698392464159     |
| train_1/q_grads           | -0.2198680244386196    |
| train_1/q_grads_std       | 0.5742048650979996     |
| train_1/q_loss            | 0.45530710392662915    |
| train_1/reward            | -1.5396862388435693    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.772903315783696     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 593.89. Rollout time: 366.22, Training time: 227.60
Evaluating epoch 71
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 6548791.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999995     |
| test_1/avg_q              | -4.451656388454502     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999996152    |
| train_0/current_q         | -10.102071612913155    |
| train_0/fw_bonus          | -0.9974222585558892    |
| train_0/fw_loss           | 0.012260880996473133   |
| train_0/mu_grads          | -0.021545172110199927  |
| train_0/mu_grads_std      | 0.6041472643613816     |
| train_0/mu_loss           | 9.971053533366751      |
| train_0/next_q            | -9.95389822828912      |
| train_0/q_grads           | -0.0037662376882508395 |
| train_0/q_grads_std       | 0.3441023908555508     |
| train_0/q_loss            | 0.3615116408645213     |
| train_0/reward            | -0.8884841734427027    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.007958984375         |
| train_0/target_q          | -10.250509247865836    |
| train_1/avg_q             | -7.696950157434005     |
| train_1/current_q         | -7.159052712023947     |
| train_1/fw_bonus          | -0.9541835531592369    |
| train_1/fw_loss           | 0.22194201685488224    |
| train_1/mu_grads          | -0.08107878770679236   |
| train_1/mu_grads_std      | 0.36686424612998964    |
| train_1/mu_loss           | 2.6019799806866417     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.288709689067349     |
| train_1/q_grads           | -0.2215370699763298    |
| train_1/q_grads_std       | 0.5802081853151322     |
| train_1/q_loss            | 0.35308408251641216    |
| train_1/reward            | -1.535974585351505     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 9.765625e-05           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.158364478385304     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 615.84. Rollout time: 384.76, Training time: 231.00
Evaluating epoch 72
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 6639916.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -5.103540166315102    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999463927   |
| train_0/current_q         | -9.958444451710589    |
| train_0/fw_bonus          | -0.9976236760616303   |
| train_0/fw_loss           | 0.011339703178964555  |
| train_0/mu_grads          | -0.023566912533715366 |
| train_0/mu_grads_std      | 0.6048962906002998    |
| train_0/mu_loss           | 9.843928636743078     |
| train_0/next_q            | -9.825996765217942    |
| train_0/q_grads           | -0.0039439816493541   |
| train_0/q_grads_std       | 0.34540645927190783   |
| train_0/q_loss            | 0.35761878779283224   |
| train_0/reward            | -0.8833312830174691   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0094482421875       |
| train_0/target_q          | -10.111378975023483   |
| train_1/avg_q             | -7.453692707207455    |
| train_1/current_q         | -7.152462695947439    |
| train_1/fw_bonus          | -0.9576711341738701   |
| train_1/fw_loss           | 0.2060390319675207    |
| train_1/mu_grads          | -0.08108071237802505  |
| train_1/mu_grads_std      | 0.36919507309794425   |
| train_1/mu_loss           | 2.636240244611122     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -7.335854584327706    |
| train_1/q_grads           | -0.22113459333777427  |
| train_1/q_grads_std       | 0.5854209735989571    |
| train_1/q_loss            | 0.35547714873854164   |
| train_1/reward            | -1.522336605523742    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0004638671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.151632849265056    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 735.52. Rollout time: 457.28, Training time: 278.16
Evaluating epoch 73
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 6730912.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.747132239211588    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.9990910189294     |
| train_0/current_q         | -10.06625064390715    |
| train_0/fw_bonus          | -0.997738017141819    |
| train_0/fw_loss           | 0.010816796403378248  |
| train_0/mu_grads          | -0.024426782736554742 |
| train_0/mu_grads_std      | 0.6066352516412735    |
| train_0/mu_loss           | 9.954926225399799     |
| train_0/next_q            | -9.938392161235159    |
| train_0/q_grads           | -0.005468521686270833 |
| train_0/q_grads_std       | 0.3470638059079647    |
| train_0/q_loss            | 0.34744600216807137   |
| train_0/reward            | -0.8818728453596123   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0089599609375       |
| train_0/target_q          | -10.219861633838105   |
| train_1/avg_q             | -7.460072730709305    |
| train_1/current_q         | -7.153254311473944    |
| train_1/fw_bonus          | -0.960683137178421    |
| train_1/fw_loss           | 0.19230461344122887   |
| train_1/mu_grads          | -0.08184896279126405  |
| train_1/mu_grads_std      | 0.37057691588997843   |
| train_1/mu_loss           | 2.6567050445733207    |
| train_1/n_subgoals        | 2696.0                |
| train_1/next_q            | -7.32153084226389     |
| train_1/q_grads           | -0.22234159745275975  |
| train_1/q_grads_std       | 0.590271283686161     |
| train_1/q_loss            | 0.4051550175210445    |
| train_1/reward            | -1.5423202173406025   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000439453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.153234926994948    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 607.78. Rollout time: 371.31, Training time: 236.39
Evaluating epoch 74
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 6822033.0             |
| test/episodes             | 1875.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.9993322853637     |
| test_1/avg_q              | -5.6207897168035625   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.996125483087155   |
| train_0/current_q         | -10.114778770286572   |
| train_0/fw_bonus          | -0.9978005975484848   |
| train_0/fw_loss           | 0.010530592151917517  |
| train_0/mu_grads          | -0.02617229735478759  |
| train_0/mu_grads_std      | 0.6085649192333221    |
| train_0/mu_loss           | 10.009162154494788    |
| train_0/next_q            | -9.989757319753243    |
| train_0/q_grads           | -0.005444812017958611 |
| train_0/q_grads_std       | 0.34885000213980677   |
| train_0/q_loss            | 0.3643198333316339    |
| train_0/reward            | -0.8811507371356129   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008837890625        |
| train_0/target_q          | -10.270234152048555   |
| train_1/avg_q             | -7.488852528764455    |
| train_1/current_q         | -7.131467411926738    |
| train_1/fw_bonus          | -0.9585986971855164   |
| train_1/fw_loss           | 0.2018094625324011    |
| train_1/mu_grads          | -0.08224088866263628  |
| train_1/mu_grads_std      | 0.37179297134280204   |
| train_1/mu_loss           | 2.990835613973529     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.985909598212229    |
| train_1/q_grads           | -0.22290473729372023  |
| train_1/q_grads_std       | 0.5914785593748093    |
| train_1/q_loss            | 0.8628125980596584    |
| train_1/reward            | -1.5357642082624807   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -7.141290700932676    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 616.00. Rollout time: 383.18, Training time: 232.76
Evaluating epoch 75
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 6913158.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99996646158509    |
| test_1/avg_q              | -6.444089969995447    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.983105078535544   |
| train_0/current_q         | -10.205238220297232   |
| train_0/fw_bonus          | -0.9976032510399818   |
| train_0/fw_loss           | 0.011433131201192737  |
| train_0/mu_grads          | -0.02833709097467363  |
| train_0/mu_grads_std      | 0.6106175795197487    |
| train_0/mu_loss           | 10.083548136460049    |
| train_0/next_q            | -10.066281587025646   |
| train_0/q_grads           | -0.005672457255423069 |
| train_0/q_grads_std       | 0.3504712678492069    |
| train_0/q_loss            | 0.40176656491290236   |
| train_0/reward            | -0.8873015573088197   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00927734375         |
| train_0/target_q          | -10.35487951935232    |
| train_1/avg_q             | -7.41500927150796     |
| train_1/current_q         | -6.8192496811348295   |
| train_1/fw_bonus          | -0.9549828097224236   |
| train_1/fw_loss           | 0.21829756759107113   |
| train_1/mu_grads          | -0.08243663534522057  |
| train_1/mu_grads_std      | 0.3728610806167126    |
| train_1/mu_loss           | 3.156177197716238     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.3864170784877405   |
| train_1/q_grads           | -0.225456665456295    |
| train_1/q_grads_std       | 0.5938120126724243    |
| train_1/q_loss            | 1.2050984352500198    |
| train_1/reward            | -1.521534954299932    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.835137711137463    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 613.20. Rollout time: 377.27, Training time: 235.86
Evaluating epoch 76
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 7004031.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999999999876   |
| test_1/avg_q              | -7.4995590107278565   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -26.999931045077556   |
| train_0/current_q         | -10.261331482371707   |
| train_0/fw_bonus          | -0.9973944947123528   |
| train_0/fw_loss           | 0.012387849926017224  |
| train_0/mu_grads          | -0.027883613621816038 |
| train_0/mu_grads_std      | 0.6132364109158516    |
| train_0/mu_loss           | 10.113484937979894    |
| train_0/next_q            | -10.09407453994346    |
| train_0/q_grads           | -0.005778368446044624 |
| train_0/q_grads_std       | 0.3522452741861343    |
| train_0/q_loss            | 0.4549255799214721    |
| train_0/reward            | -0.8990163301612484   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0071044921875       |
| train_0/target_q          | -10.417246592340224   |
| train_1/avg_q             | -7.4875372070765795   |
| train_1/current_q         | -6.2607278932062425   |
| train_1/fw_bonus          | -0.9519327506422997   |
| train_1/fw_loss           | 0.23220549188554288   |
| train_1/mu_grads          | -0.08254524264484644  |
| train_1/mu_grads_std      | 0.3749949559569359    |
| train_1/mu_loss           | 3.3403210607899156    |
| train_1/n_subgoals        | 2691.0                |
| train_1/next_q            | -5.769974638434484    |
| train_1/q_grads           | -0.22349984906613826  |
| train_1/q_grads_std       | 0.5928397387266159    |
| train_1/q_loss            | 0.7935668318227462    |
| train_1/reward            | -1.5350494166486897   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0004638671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.271983812308866    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 609.18. Rollout time: 370.66, Training time: 238.44
Evaluating epoch 77
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 7095156.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.125295302385655    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99992907492504    |
| train_0/current_q         | -10.382562480863456   |
| train_0/fw_bonus          | -0.9973956704139709   |
| train_0/fw_loss           | 0.012382463016547263  |
| train_0/mu_grads          | -0.029509180784225465 |
| train_0/mu_grads_std      | 0.6155811443924903    |
| train_0/mu_loss           | 10.217965886977453    |
| train_0/next_q            | -10.196158505570285   |
| train_0/q_grads           | -0.00604644026607275  |
| train_0/q_grads_std       | 0.3549919493496418    |
| train_0/q_loss            | 0.44614275026995215   |
| train_0/reward            | -0.9044981705548707   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0053466796875       |
| train_0/target_q          | -10.533258004610492   |
| train_1/avg_q             | -7.484867477995653    |
| train_1/current_q         | -6.620752865596205    |
| train_1/fw_bonus          | -0.950892049074173    |
| train_1/fw_loss           | 0.2369509596377611    |
| train_1/mu_grads          | -0.08331455737352371  |
| train_1/mu_grads_std      | 0.37805177122354505   |
| train_1/mu_loss           | 3.3217135016703487    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.188509751771414    |
| train_1/q_grads           | -0.22260743603110314  |
| train_1/q_grads_std       | 0.5971769273281098    |
| train_1/q_loss            | 0.8962683604385131    |
| train_1/reward            | -1.5189673799293815   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000390625           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.6237662097075      |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 616.16. Rollout time: 375.12, Training time: 240.97
Evaluating epoch 78
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 7186281.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.939345844516562    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.565284624737057   |
| train_0/current_q         | -10.465308526731224   |
| train_0/fw_bonus          | -0.9973705813288689   |
| train_0/fw_loss           | 0.012497238744981588  |
| train_0/mu_grads          | -0.029413111601024867 |
| train_0/mu_grads_std      | 0.6180744379758835    |
| train_0/mu_loss           | 10.292452649153768    |
| train_0/next_q            | -10.270140489160479   |
| train_0/q_grads           | -0.005700555781368166 |
| train_0/q_grads_std       | 0.35706896856427195   |
| train_0/q_loss            | 0.45309570397631094   |
| train_0/reward            | -0.9105096217506798   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0061767578125       |
| train_0/target_q          | -10.621295813715745   |
| train_1/avg_q             | -7.395307368732524    |
| train_1/current_q         | -6.969760317209358    |
| train_1/fw_bonus          | -0.9475359871983529   |
| train_1/fw_loss           | 0.2522542752325535    |
| train_1/mu_grads          | -0.08368777260184287  |
| train_1/mu_grads_std      | 0.3796142503619194    |
| train_1/mu_loss           | 3.20560349980362      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.571195882761449    |
| train_1/q_grads           | -0.22262566424906255  |
| train_1/q_grads_std       | 0.6012280777096748    |
| train_1/q_loss            | 0.86877848856504      |
| train_1/reward            | -1.5333570687540488   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000390625           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.972764277638779    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 610.86. Rollout time: 376.82, Training time: 233.96
Evaluating epoch 79
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 7277406.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.993278278399664   |
| test_1/avg_q              | -7.36233135352828     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.96739966047678    |
| train_0/current_q         | -10.142536177469358   |
| train_0/fw_bonus          | -0.9976630926132202   |
| train_0/fw_loss           | 0.011159409466199578  |
| train_0/mu_grads          | -0.029503567423671485 |
| train_0/mu_grads_std      | 0.6202369913458824    |
| train_0/mu_loss           | 9.970312863905297     |
| train_0/next_q            | -9.95000711006044     |
| train_0/q_grads           | -0.004231868439819664 |
| train_0/q_grads_std       | 0.35968268662691116   |
| train_0/q_loss            | 0.41850880378666383   |
| train_0/reward            | -0.9049123628021334   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0056396484375       |
| train_0/target_q          | -10.295511538259898   |
| train_1/avg_q             | -7.463505872362798    |
| train_1/current_q         | -6.691584873866077    |
| train_1/fw_bonus          | -0.9512907817959786   |
| train_1/fw_loss           | 0.23513277247548103   |
| train_1/mu_grads          | -0.08416149653494358  |
| train_1/mu_grads_std      | 0.3813496008515358    |
| train_1/mu_loss           | 3.3797218173913977    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.228837724857081    |
| train_1/q_grads           | -0.22373708561062813  |
| train_1/q_grads_std       | 0.6023580804467201    |
| train_1/q_loss            | 1.1806050551391192    |
| train_1/reward            | -1.5255591545523202   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0002197265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.700485797415143    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 606.98. Rollout time: 371.38, Training time: 235.54
Evaluating epoch 80
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
----------------------------------------------------
| epoch                     | 80                   |
| policy/steps              | 7368187.0            |
| test/episodes             | 2025.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -26.9904037933816    |
| test_1/avg_q              | -6.662437821358813   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8100.0               |
| train/success_rate        | 0.01                 |
| train_0/avg_q             | -26.980091081719554  |
| train_0/current_q         | -10.180934207250981  |
| train_0/fw_bonus          | -0.9977416291832923  |
| train_0/fw_loss           | 0.010800320678390563 |
| train_0/mu_grads          | -0.03076688414439559 |
| train_0/mu_grads_std      | 0.6209686174988747   |
| train_0/mu_loss           | 10.016394291780298   |
| train_0/next_q            | -10.000612400091091  |
| train_0/q_grads           | -0.00414583976380527 |
| train_0/q_grads_std       | 0.3618139706552029   |
| train_0/q_loss            | 0.37608036441602566  |
| train_0/reward            | -0.902206357877003   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00615234375        |
| train_0/target_q          | -10.335242589503805  |
| train_1/avg_q             | -7.451215197563047   |
| train_1/current_q         | -6.220218768222187   |
| train_1/fw_bonus          | -0.9516809463500977  |
| train_1/fw_loss           | 0.23335368633270265  |
| train_1/mu_grads          | -0.08498529959470033 |
| train_1/mu_grads_std      | 0.3827239252626896   |
| train_1/mu_loss           | 3.473974202797416    |
| train_1/n_subgoals        | 2688.0               |
| train_1/next_q            | -5.590654255600124   |
| train_1/q_grads           | -0.22362730354070665 |
| train_1/q_grads_std       | 0.6012996196746826   |
| train_1/q_loss            | 0.9745537587229318   |
| train_1/reward            | -1.5194674974984081  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0005615234375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -6.2161641156429255  |
----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 603.37. Rollout time: 365.31, Training time: 237.99
Evaluating epoch 81
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 7459050.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99976495531092    |
| test_1/avg_q              | -7.49185598636818     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -26.99874199163341    |
| train_0/current_q         | -10.215312398929104   |
| train_0/fw_bonus          | -0.9977379769086838   |
| train_0/fw_loss           | 0.01081692143343389   |
| train_0/mu_grads          | -0.03092779885046184  |
| train_0/mu_grads_std      | 0.6214904516935349    |
| train_0/mu_loss           | 10.061021146434607    |
| train_0/next_q            | -10.03724504121311    |
| train_0/q_grads           | -0.003982607601210475 |
| train_0/q_grads_std       | 0.3639570206403732    |
| train_0/q_loss            | 0.37328381292459445   |
| train_0/reward            | -0.9004336158526712   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0055908203125       |
| train_0/target_q          | -10.368726687030534   |
| train_1/avg_q             | -7.408722501018503    |
| train_1/current_q         | -6.330292223034876    |
| train_1/fw_bonus          | -0.9520233884453774   |
| train_1/fw_loss           | 0.2317921806126833    |
| train_1/mu_grads          | -0.08552887924015522  |
| train_1/mu_grads_std      | 0.38331756442785264   |
| train_1/mu_loss           | 3.592179468034402     |
| train_1/n_subgoals        | 2691.0                |
| train_1/next_q            | -5.722890248473346    |
| train_1/q_grads           | -0.22479945085942746  |
| train_1/q_grads_std       | 0.6011476084589958    |
| train_1/q_loss            | 0.925134502869436     |
| train_1/reward            | -1.5394814089813735   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.331450674934362    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 614.53. Rollout time: 379.38, Training time: 235.06
Evaluating epoch 82
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 7549540.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99886290543548    |
| test_1/avg_q              | -7.40230993957018     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -26.99175928869001    |
| train_0/current_q         | -10.210146020637618   |
| train_0/fw_bonus          | -0.9976843535900116   |
| train_0/fw_loss           | 0.011062227305956185  |
| train_0/mu_grads          | -0.030920165264979003 |
| train_0/mu_grads_std      | 0.6228187158703804    |
| train_0/mu_loss           | 10.04782180994608     |
| train_0/next_q            | -10.02678384698319    |
| train_0/q_grads           | -0.003500201238784939 |
| train_0/q_grads_std       | 0.36647127792239187   |
| train_0/q_loss            | 0.3747282008873767    |
| train_0/reward            | -0.9008389445123612   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006689453125        |
| train_0/target_q          | -10.360720945184944   |
| train_1/avg_q             | -7.48033119649528     |
| train_1/current_q         | -6.594423250891063    |
| train_1/fw_bonus          | -0.9503244236111641   |
| train_1/fw_loss           | 0.23953929990530015   |
| train_1/mu_grads          | -0.08647229764610528  |
| train_1/mu_grads_std      | 0.3843579426407814    |
| train_1/mu_loss           | 3.698849950784832     |
| train_1/n_subgoals        | 2677.0                |
| train_1/next_q            | -6.049734562209441    |
| train_1/q_grads           | -0.22604212425649167  |
| train_1/q_grads_std       | 0.6017922356724739    |
| train_1/q_loss            | 1.2562505279287746    |
| train_1/reward            | -1.5406913142978738   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005126953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.590954852458411    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 613.77. Rollout time: 372.17, Training time: 241.52
Evaluating epoch 83
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 7640665.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.9999999976413     |
| test_1/avg_q              | -7.265856566089345    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.97126928063702    |
| train_0/current_q         | -10.16092550568518    |
| train_0/fw_bonus          | -0.9977959722280503   |
| train_0/fw_loss           | 0.010551754478365183  |
| train_0/mu_grads          | -0.031782396417111156 |
| train_0/mu_grads_std      | 0.6245772704482079    |
| train_0/mu_loss           | 10.013186819510363    |
| train_0/next_q            | -9.994651039278187    |
| train_0/q_grads           | -0.003386680030962452 |
| train_0/q_grads_std       | 0.3681027203798294    |
| train_0/q_loss            | 0.4170439530753834    |
| train_0/reward            | -0.8963633311796002   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0064208984375       |
| train_0/target_q          | -10.311223718856994   |
| train_1/avg_q             | -7.465430274873844    |
| train_1/current_q         | -6.834552110356836    |
| train_1/fw_bonus          | -0.9540615573525428   |
| train_1/fw_loss           | 0.22249834463000298   |
| train_1/mu_grads          | -0.08708678744733334  |
| train_1/mu_grads_std      | 0.3849229998886585    |
| train_1/mu_loss           | 3.6056710721148937    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.316055647028682    |
| train_1/q_grads           | -0.22454407960176467  |
| train_1/q_grads_std       | 0.6047975614666938    |
| train_1/q_loss            | 0.9315176591057599    |
| train_1/reward            | -1.533899440083769    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0002197265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.839059161876969    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 599.96. Rollout time: 370.45, Training time: 229.46
Evaluating epoch 84
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 7731425.0              |
| test/episodes             | 2125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999958240007    |
| test_1/avg_q              | -7.051892877417324     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.99998166801612     |
| train_0/current_q         | -10.249317684328208    |
| train_0/fw_bonus          | -0.997645853459835     |
| train_0/fw_loss           | 0.011238281801342963   |
| train_0/mu_grads          | -0.03212517555803061   |
| train_0/mu_grads_std      | 0.6259700044989586     |
| train_0/mu_loss           | 10.089980745399396     |
| train_0/next_q            | -10.074834981744562    |
| train_0/q_grads           | -0.0029524609504733234 |
| train_0/q_grads_std       | 0.3706530638039112     |
| train_0/q_loss            | 0.4405826561461487     |
| train_0/reward            | -0.9004133447771892    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00634765625          |
| train_0/target_q          | -10.402159153210649    |
| train_1/avg_q             | -7.400876734031644     |
| train_1/current_q         | -6.462901082813147     |
| train_1/fw_bonus          | -0.951936973631382     |
| train_1/fw_loss           | 0.23218621872365475    |
| train_1/mu_grads          | -0.0876950554549694    |
| train_1/mu_grads_std      | 0.3856670692563057     |
| train_1/mu_loss           | 3.5136406087821412     |
| train_1/n_subgoals        | 2687.0                 |
| train_1/next_q            | -5.906656414324663     |
| train_1/q_grads           | -0.22423304356634616   |
| train_1/q_grads_std       | 0.6048865586519241     |
| train_1/q_loss            | 0.7297641334469356     |
| train_1/reward            | -1.5186158176045865    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.467662299801859     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 602.60. Rollout time: 370.52, Training time: 232.00
Evaluating epoch 85
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 85                     |
| policy/steps              | 7822550.0              |
| test/episodes             | 2150.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999999993    |
| test_1/avg_q              | -6.978991067236574     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.988659812186494    |
| train_0/current_q         | -10.227843783704438    |
| train_0/fw_bonus          | -0.9977600231766701    |
| train_0/fw_loss           | 0.010716131865046918   |
| train_0/mu_grads          | -0.03250652933493257   |
| train_0/mu_grads_std      | 0.6281028181314469     |
| train_0/mu_loss           | 10.075350754762121     |
| train_0/next_q            | -10.060264872940285    |
| train_0/q_grads           | -0.0024389778554905206 |
| train_0/q_grads_std       | 0.37457272633910177    |
| train_0/q_loss            | 0.370981968371045      |
| train_0/reward            | -0.8968246559481485    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0076416015625        |
| train_0/target_q          | -10.375996291061558    |
| train_1/avg_q             | -7.526680614584219     |
| train_1/current_q         | -7.083419682863015     |
| train_1/fw_bonus          | -0.9555082738399505    |
| train_1/fw_loss           | 0.21590145714581013    |
| train_1/mu_grads          | -0.08792310226708651   |
| train_1/mu_grads_std      | 0.38692297637462614    |
| train_1/mu_loss           | 3.065652229968033      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.788857085447381     |
| train_1/q_grads           | -0.22321433648467065   |
| train_1/q_grads_std       | 0.6061867669224739     |
| train_1/q_loss            | 0.7760944163327014     |
| train_1/reward            | -1.5315054750164563    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000537109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.081218104962576     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 602.60. Rollout time: 372.79, Training time: 229.73
Evaluating epoch 86
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 86                     |
| policy/steps              | 7913675.0              |
| test/episodes             | 2175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999986516748    |
| test_1/avg_q              | -6.9238666675887695    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999223741874    |
| train_0/current_q         | -10.047029842520221    |
| train_0/fw_bonus          | -0.99802365899086      |
| train_0/fw_loss           | 0.009510367270559072   |
| train_0/mu_grads          | -0.033149981312453745  |
| train_0/mu_grads_std      | 0.6300104141235352     |
| train_0/mu_loss           | 9.912435509556863      |
| train_0/next_q            | -9.900388303014399     |
| train_0/q_grads           | -0.0029973045689985155 |
| train_0/q_grads_std       | 0.3768629223108292     |
| train_0/q_loss            | 0.3056402118365599     |
| train_0/reward            | -0.8876412865298334    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0075439453125        |
| train_0/target_q          | -10.201189460135422    |
| train_1/avg_q             | -7.484063757184377     |
| train_1/current_q         | -6.565781287669894     |
| train_1/fw_bonus          | -0.960033868253231     |
| train_1/fw_loss           | 0.19526522420346737    |
| train_1/mu_grads          | -0.08885050639510154   |
| train_1/mu_grads_std      | 0.3876869216561317     |
| train_1/mu_loss           | 3.1523773072496653     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.390592979484849     |
| train_1/q_grads           | -0.22462280578911303   |
| train_1/q_grads_std       | 0.6093301564455033     |
| train_1/q_loss            | 0.899118698545579      |
| train_1/reward            | -1.5279172468894102    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.595705547057321     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 609.90. Rollout time: 373.13, Training time: 236.69
Evaluating epoch 87
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 8004800.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.739658910747266    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999118457654944   |
| train_0/current_q         | -9.958421593516968    |
| train_0/fw_bonus          | -0.9982734516263008   |
| train_0/fw_loss           | 0.008367991785053163  |
| train_0/mu_grads          | -0.033535891026258466 |
| train_0/mu_grads_std      | 0.631168146431446     |
| train_0/mu_loss           | 9.84690896812944      |
| train_0/next_q            | -9.83179420579948     |
| train_0/q_grads           | -0.003277682070620358 |
| train_0/q_grads_std       | 0.37899410650134085   |
| train_0/q_loss            | 0.29294988955701406   |
| train_0/reward            | -0.8806386842901702   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006591796875        |
| train_0/target_q          | -10.111216671389204   |
| train_1/avg_q             | -7.458077082095629    |
| train_1/current_q         | -6.099100822066407    |
| train_1/fw_bonus          | -0.9620813876390457   |
| train_1/fw_loss           | 0.18592878617346287   |
| train_1/mu_grads          | -0.08963484093546867  |
| train_1/mu_grads_std      | 0.387531802803278     |
| train_1/mu_loss           | 3.341142995210795     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.871129615048889    |
| train_1/q_grads           | -0.2245077807456255   |
| train_1/q_grads_std       | 0.611122639477253     |
| train_1/q_loss            | 0.4991189107100755    |
| train_1/reward            | -1.5433811028480704   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000634765625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.094766860621702    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 606.23. Rollout time: 376.06, Training time: 230.09
Evaluating epoch 88
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 88                     |
| policy/steps              | 8095925.0              |
| test/episodes             | 2225.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.382394805475194     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999255094367285    |
| train_0/current_q         | -9.982413485677043     |
| train_0/fw_bonus          | -0.998311024904251     |
| train_0/fw_loss           | 0.008196158742066473   |
| train_0/mu_grads          | -0.033441494964063165  |
| train_0/mu_grads_std      | 0.632391420006752      |
| train_0/mu_loss           | 9.8795753247684        |
| train_0/next_q            | -9.863451132078719     |
| train_0/q_grads           | -0.0028986933582928033 |
| train_0/q_grads_std       | 0.38191362023353576    |
| train_0/q_loss            | 0.2606204239478064     |
| train_0/reward            | -0.8778958672337467    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.006103515625         |
| train_0/target_q          | -10.141229876442925    |
| train_1/avg_q             | -7.502323205850609     |
| train_1/current_q         | -6.604726783188738     |
| train_1/fw_bonus          | -0.9619128674268722    |
| train_1/fw_loss           | 0.18669716753065585    |
| train_1/mu_grads          | -0.08962377477437258   |
| train_1/mu_grads_std      | 0.38832114413380625    |
| train_1/mu_loss           | 3.53603451468639       |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.595030909425534     |
| train_1/q_grads           | -0.22624655328691007   |
| train_1/q_grads_std       | 0.6142471507191658     |
| train_1/q_loss            | 0.35609448136187094    |
| train_1/reward            | -1.5243033059734443    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.612065236589379     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 610.50. Rollout time: 373.20, Training time: 237.23
Evaluating epoch 89
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 89                     |
| policy/steps              | 8187050.0              |
| test/episodes             | 2250.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999794912    |
| test_1/avg_q              | -7.098277259009108     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999991508727    |
| train_0/current_q         | -9.942662881122999     |
| train_0/fw_bonus          | -0.9984638750553131    |
| train_0/fw_loss           | 0.007497151766438037   |
| train_0/mu_grads          | -0.03398864986374974   |
| train_0/mu_grads_std      | 0.6334982231259346     |
| train_0/mu_loss           | 9.843506982257164      |
| train_0/next_q            | -9.834536789626393     |
| train_0/q_grads           | -0.0024958575319033115 |
| train_0/q_grads_std       | 0.38430195748806       |
| train_0/q_loss            | 0.2601030157410604     |
| train_0/reward            | -0.8739455565664684    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.009423828125         |
| train_0/target_q          | -10.092675432841276    |
| train_1/avg_q             | -7.46802228313324      |
| train_1/current_q         | -6.675682802513751     |
| train_1/fw_bonus          | -0.964247316122055     |
| train_1/fw_loss           | 0.17605238929390907    |
| train_1/mu_grads          | -0.08943942841142416   |
| train_1/mu_grads_std      | 0.38882495313882826    |
| train_1/mu_loss           | 3.50305254570116       |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.708407676643961     |
| train_1/q_grads           | -0.22743667773902415   |
| train_1/q_grads_std       | 0.619024096429348      |
| train_1/q_loss            | 0.3582890708975386     |
| train_1/reward            | -1.5283673635531159    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.680077734050771     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 595.76. Rollout time: 364.78, Training time: 230.91
Evaluating epoch 90
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 8278175.0             |
| test/episodes             | 2275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.435587107457223    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999996902385032   |
| train_0/current_q         | -9.802824893970095    |
| train_0/fw_bonus          | -0.9984755530953408   |
| train_0/fw_loss           | 0.007443720137234777  |
| train_0/mu_grads          | -0.03476926451548934  |
| train_0/mu_grads_std      | 0.6339171245694161    |
| train_0/mu_loss           | 9.70523977755207      |
| train_0/next_q            | -9.696569621453852    |
| train_0/q_grads           | -0.002607924258336425 |
| train_0/q_grads_std       | 0.3862232878804207    |
| train_0/q_loss            | 0.2362172826870995    |
| train_0/reward            | -0.8706889378823689   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0056640625          |
| train_0/target_q          | -9.95581072578419     |
| train_1/avg_q             | -7.355957749328861    |
| train_1/current_q         | -6.82331804204848     |
| train_1/fw_bonus          | -0.9660064920783042   |
| train_1/fw_loss           | 0.16803067103028296   |
| train_1/mu_grads          | -0.08897084426134824  |
| train_1/mu_grads_std      | 0.3898915134370327    |
| train_1/mu_loss           | 3.5720797936011843    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.809366754997251    |
| train_1/q_grads           | -0.22699893079698086  |
| train_1/q_grads_std       | 0.6216828167438507    |
| train_1/q_loss            | 0.48718974368511453   |
| train_1/reward            | -1.5319877803951385   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.817581271187999    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 598.79. Rollout time: 371.41, Training time: 227.31
Evaluating epoch 91
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 8369300.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.983525884183408   |
| test_1/avg_q              | -7.352706688928594    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.99999617628106    |
| train_0/current_q         | -9.971534774379165    |
| train_0/fw_bonus          | -0.9984518945217132   |
| train_0/fw_loss           | 0.007551853428594768  |
| train_0/mu_grads          | -0.034773253835737705 |
| train_0/mu_grads_std      | 0.6340659707784653    |
| train_0/mu_loss           | 9.86779871274779      |
| train_0/next_q            | -9.854659371586465    |
| train_0/q_grads           | -0.003166949941078201 |
| train_0/q_grads_std       | 0.38835676833987237   |
| train_0/q_loss            | 0.2404768923656852    |
| train_0/reward            | -0.8749619761918439   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0068115234375       |
| train_0/target_q          | -10.125540853196384   |
| train_1/avg_q             | -7.498543701572157    |
| train_1/current_q         | -6.403676019972695    |
| train_1/fw_bonus          | -0.9651852592825889   |
| train_1/fw_loss           | 0.1717753630131483    |
| train_1/mu_grads          | -0.08912520054727793  |
| train_1/mu_grads_std      | 0.39000169932842255   |
| train_1/mu_loss           | 3.3721017677166514    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.266883029185922    |
| train_1/q_grads           | -0.22744544148445128  |
| train_1/q_grads_std       | 0.6235649600625038    |
| train_1/q_loss            | 0.48934611644778697   |
| train_1/reward            | -1.5239377810688892   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006103515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.4040690859174445   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 550.10. Rollout time: 328.31, Training time: 221.74
Evaluating epoch 92
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 8460425.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.375456454685975    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.992426906470655   |
| train_0/current_q         | -9.810851316761381    |
| train_0/fw_bonus          | -0.9983732402324677   |
| train_0/fw_loss           | 0.007911616622004658  |
| train_0/mu_grads          | -0.035334364883601664 |
| train_0/mu_grads_std      | 0.6348134890198708    |
| train_0/mu_loss           | 9.694503691022494     |
| train_0/next_q            | -9.684756562536066    |
| train_0/q_grads           | -0.003326401533558965 |
| train_0/q_grads_std       | 0.3908980265259743    |
| train_0/q_loss            | 0.2462984245094742    |
| train_0/reward            | -0.8764715821176651   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0054931640625       |
| train_0/target_q          | -9.959825067465289    |
| train_1/avg_q             | -7.445404657410383    |
| train_1/current_q         | -6.247271377058681    |
| train_1/fw_bonus          | -0.9642077922821045   |
| train_1/fw_loss           | 0.17623254619538783   |
| train_1/mu_grads          | -0.0894915359094739   |
| train_1/mu_grads_std      | 0.3912009857594967    |
| train_1/mu_loss           | 3.4351148507436733    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.0785748432267654   |
| train_1/q_grads           | -0.22795246504247188  |
| train_1/q_grads_std       | 0.6266642734408379    |
| train_1/q_loss            | 0.4392425383210686    |
| train_1/reward            | -1.5537771847906696   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005859375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.251145452589615    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 525.77. Rollout time: 301.58, Training time: 224.14
Evaluating epoch 93
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 8551550.0              |
| test/episodes             | 2350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.996669765145466    |
| test_1/avg_q              | -7.611919909987445     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.933593712748955    |
| train_0/current_q         | -9.965398522167346     |
| train_0/fw_bonus          | -0.9984077081084252    |
| train_0/fw_loss           | 0.0077539975987747315  |
| train_0/mu_grads          | -0.035757084097713235  |
| train_0/mu_grads_std      | 0.6357992991805077     |
| train_0/mu_loss           | 9.844447780971631      |
| train_0/next_q            | -9.830690702831959     |
| train_0/q_grads           | -0.0029129421920515595 |
| train_0/q_grads_std       | 0.39265451207756996    |
| train_0/q_loss            | 0.2331360335192369     |
| train_0/reward            | -0.8789205256995046    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00654296875          |
| train_0/target_q          | -10.120318080745822    |
| train_1/avg_q             | -7.456684784995989     |
| train_1/current_q         | -6.332555913999411     |
| train_1/fw_bonus          | -0.9651261791586876    |
| train_1/fw_loss           | 0.17204485088586807    |
| train_1/mu_grads          | -0.090002466365695     |
| train_1/mu_grads_std      | 0.39202720373868943    |
| train_1/mu_loss           | 3.4146527562927056     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.219466282707289     |
| train_1/q_grads           | -0.22996498234570026   |
| train_1/q_grads_std       | 0.6300510480999947     |
| train_1/q_loss            | 0.6431173244598208     |
| train_1/reward            | -1.532120996019512     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009765625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.3313702513672085    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 513.05. Rollout time: 297.93, Training time: 215.06
Evaluating epoch 94
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 94                     |
| policy/steps              | 8642675.0              |
| test/episodes             | 2375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999920004    |
| test_1/avg_q              | -7.403977055934737     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.971308540884976    |
| train_0/current_q         | -9.917953663131263     |
| train_0/fw_bonus          | -0.9984043151140213    |
| train_0/fw_loss           | 0.007769529125653207   |
| train_0/mu_grads          | -0.03638732545077801   |
| train_0/mu_grads_std      | 0.6374447599053383     |
| train_0/mu_loss           | 9.798289072173839      |
| train_0/next_q            | -9.788585281289594     |
| train_0/q_grads           | -0.0017969745764276012 |
| train_0/q_grads_std       | 0.395814398676157      |
| train_0/q_loss            | 0.2311873412512865     |
| train_0/reward            | -0.8769953712064307    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.006201171875         |
| train_0/target_q          | -10.067413070815626    |
| train_1/avg_q             | -7.544125247013265     |
| train_1/current_q         | -6.284898555673279     |
| train_1/fw_bonus          | -0.9637654080986977    |
| train_1/fw_loss           | 0.17824979797005652    |
| train_1/mu_grads          | -0.09054789114743471   |
| train_1/mu_grads_std      | 0.39338346421718595    |
| train_1/mu_loss           | 3.3163908938516045     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.139556084416282     |
| train_1/q_grads           | -0.2311583261936903    |
| train_1/q_grads_std       | 0.6346751779317856     |
| train_1/q_loss            | 0.5339252270318845     |
| train_1/reward            | -1.5369964179320958    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.284460293438379     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 514.20. Rollout time: 301.34, Training time: 212.80
Evaluating epoch 95
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 8733800.0              |
| test/episodes             | 2400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.186952061561112     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.991532687267117    |
| train_0/current_q         | -9.899329378719925     |
| train_0/fw_bonus          | -0.9982966601848602    |
| train_0/fw_loss           | 0.008261825714726001   |
| train_0/mu_grads          | -0.03701293133199215   |
| train_0/mu_grads_std      | 0.6395168393850327     |
| train_0/mu_loss           | 9.780222920146654      |
| train_0/next_q            | -9.767085331634382     |
| train_0/q_grads           | -0.0016716009675292298 |
| train_0/q_grads_std       | 0.39830639213323593    |
| train_0/q_loss            | 0.24424547388522494    |
| train_0/reward            | -0.8782085846993141    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0053955078125        |
| train_0/target_q          | -10.053256938291621    |
| train_1/avg_q             | -7.432112442504785     |
| train_1/current_q         | -6.264193519744026     |
| train_1/fw_bonus          | -0.9605650931596756    |
| train_1/fw_loss           | 0.192842897772789      |
| train_1/mu_grads          | -0.09030900057405233   |
| train_1/mu_grads_std      | 0.39366059750318527    |
| train_1/mu_loss           | 3.358583478780351      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.955578525335672     |
| train_1/q_grads           | -0.2316070806235075    |
| train_1/q_grads_std       | 0.6365994527935982     |
| train_1/q_loss            | 0.9178936216080091     |
| train_1/reward            | -1.5245620030407736    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007080078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.266500834698003     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 524.60. Rollout time: 303.67, Training time: 220.87
Evaluating epoch 96
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 8824734.0              |
| test/episodes             | 2425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.111792197425785     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.98356754522348     |
| train_0/current_q         | -9.934093365195036     |
| train_0/fw_bonus          | -0.9981177657842636    |
| train_0/fw_loss           | 0.009080011397600174   |
| train_0/mu_grads          | -0.03593483734875917   |
| train_0/mu_grads_std      | 0.6416971325874329     |
| train_0/mu_loss           | 9.803111739495751      |
| train_0/next_q            | -9.788679077900188     |
| train_0/q_grads           | -0.0019386460131499915 |
| train_0/q_grads_std       | 0.3999161995947361     |
| train_0/q_loss            | 0.28552147254242577    |
| train_0/reward            | -0.8832746051528375    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0056884765625        |
| train_0/target_q          | -10.087681798032017    |
| train_1/avg_q             | -7.412358855509022     |
| train_1/current_q         | -6.368437512573541     |
| train_1/fw_bonus          | -0.9574690580368042    |
| train_1/fw_loss           | 0.20696049444377423    |
| train_1/mu_grads          | -0.0912397725507617    |
| train_1/mu_grads_std      | 0.3937828324735165     |
| train_1/mu_loss           | 3.4600874113469517     |
| train_1/n_subgoals        | 2693.0                 |
| train_1/next_q            | -6.1204122390382105    |
| train_1/q_grads           | -0.23290544748306274   |
| train_1/q_grads_std       | 0.6372510597109795     |
| train_1/q_loss            | 0.6377078289512189     |
| train_1/reward            | -1.5209399297193158    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005615234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -6.3727727258642854    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 530.59. Rollout time: 303.69, Training time: 226.84
Evaluating epoch 97
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 97                    |
| policy/steps              | 8915859.0             |
| test/episodes             | 2450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.86380084066811    |
| test_1/avg_q              | -7.432107543569495    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -25.994357576021255   |
| train_0/current_q         | -9.942573179848122    |
| train_0/fw_bonus          | -0.9980192184448242   |
| train_0/fw_loss           | 0.009530743700452149  |
| train_0/mu_grads          | -0.03493419829756021  |
| train_0/mu_grads_std      | 0.6435738861560821    |
| train_0/mu_loss           | 9.829916037203585     |
| train_0/next_q            | -9.818464924504847    |
| train_0/q_grads           | -0.004938308137934655 |
| train_0/q_grads_std       | 0.4011766143143177    |
| train_0/q_loss            | 0.48121082354421507   |
| train_0/reward            | -0.883109136717394    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.007373046875        |
| train_0/target_q          | -10.086164414809508   |
| train_1/avg_q             | -7.489902091206359    |
| train_1/current_q         | -6.311122477965044    |
| train_1/fw_bonus          | -0.956907357275486    |
| train_1/fw_loss           | 0.20952182076871395   |
| train_1/mu_grads          | -0.09129888787865639  |
| train_1/mu_grads_std      | 0.3931147962808609    |
| train_1/mu_loss           | 3.4434426100450204    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -6.0143729755192705   |
| train_1/q_grads           | -0.23456058129668236  |
| train_1/q_grads_std       | 0.6388905927538872    |
| train_1/q_loss            | 0.5061226132954473    |
| train_1/reward            | -1.5171434033589322   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00029296875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -6.314369161077925    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 535.60. Rollout time: 309.80, Training time: 225.76
Evaluating epoch 98
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 9006912.0              |
| test/episodes             | 2475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999882252333233    |
| test_1/avg_q              | -7.4444833403772845    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -26.42840760232364     |
| train_0/current_q         | -10.108252044072033    |
| train_0/fw_bonus          | -0.997875015437603     |
| train_0/fw_loss           | 0.010190228372812271   |
| train_0/mu_grads          | -0.03252037484198809   |
| train_0/mu_grads_std      | 0.6442741319537163     |
| train_0/mu_loss           | 9.98256121617447       |
| train_0/next_q            | -9.963851711990523     |
| train_0/q_grads           | -0.0018935073516331614 |
| train_0/q_grads_std       | 0.4054059311747551     |
| train_0/q_loss            | 0.3860595225730308     |
| train_0/reward            | -0.8859489852591651    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0051513671875        |
| train_0/target_q          | -10.254729025988018    |
| train_1/avg_q             | -7.4639507225660555    |
| train_1/current_q         | -6.55626568174697      |
| train_1/fw_bonus          | -0.9539403796195984    |
| train_1/fw_loss           | 0.22305089496076108    |
| train_1/mu_grads          | -0.09144482165575027   |
| train_1/mu_grads_std      | 0.39292885810136796    |
| train_1/mu_loss           | 3.5954463360562885     |
| train_1/n_subgoals        | 2698.0                 |
| train_1/next_q            | -6.2635327803551135    |
| train_1/q_grads           | -0.2344410326331854    |
| train_1/q_grads_std       | 0.6402307778596878     |
| train_1/q_loss            | 0.5263217620096874     |
| train_1/reward            | -1.5311352186850855    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00048828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037064492216456633 |
| train_1/target_q          | -6.560391491053108     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 524.86. Rollout time: 304.04, Training time: 220.77
Evaluating epoch 99
Data_dir: data/eef7a77/AntFourRoomsEnv-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 99                     |
| policy/steps              | 9098037.0              |
| test/episodes             | 2500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.954722765524124    |
| test_1/avg_q              | -7.411982970212996     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 10000.0                |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.95910495968671     |
| train_0/current_q         | -10.112914530543526    |
| train_0/fw_bonus          | -0.9977673351764679    |
| train_0/fw_loss           | 0.01068270425312221    |
| train_0/mu_grads          | -0.030868081003427507  |
| train_0/mu_grads_std      | 0.6449455708265305     |
| train_0/mu_loss           | 9.973895955533767      |
| train_0/next_q            | -9.955915196412075     |
| train_0/q_grads           | -0.0007854187380871736 |
| train_0/q_grads_std       | 0.4068607233464718     |
| train_0/q_loss            | 0.33929206704482806    |
| train_0/reward            | -0.8883828721838654    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.005517578125         |
| train_0/target_q          | -10.261437959712392    |
| train_1/avg_q             | -7.476290308288504     |
| train_1/current_q         | -7.138666265634501     |
| train_1/fw_bonus          | -0.9520325928926467    |
| train_1/fw_loss           | 0.2317501813173294     |
| train_1/mu_grads          | -0.09207386672496795   |
| train_1/mu_grads_std      | 0.39336771219968797    |
| train_1/mu_loss           | 3.7161552285483546     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.923882793873719     |
| train_1/q_grads           | -0.234473417699337     |
| train_1/q_grads_std       | 0.6415376633405685     |
| train_1/q_loss            | 0.4982979011738108     |
| train_1/reward            | -1.531871129686624     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0002685546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -7.139656652170449     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
