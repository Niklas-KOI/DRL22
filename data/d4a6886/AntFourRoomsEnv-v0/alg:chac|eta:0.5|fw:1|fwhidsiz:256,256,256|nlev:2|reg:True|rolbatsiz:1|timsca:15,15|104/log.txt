Starting process id: 69506
T: 700
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: AntFourRoomsEnv-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.9985714285714286
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fa7e0f3c170>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 15,15
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 8, subgoal = 5, end_goal = 3
subgoal_bounds: symmetric [8.  8.  0.5 3.  3. ], offset [0.  0.  0.5 0.  0. ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 15
Actor(
  (fc1): Linear(in_features=34, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=8, bias=True)
)
Critic(
  (fc1): Linear(in_features=42, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=37, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 15
Actor(
  (fc1): Linear(in_features=32, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=5, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=34, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=29, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 238.36. Rollout time: 68.14, Training time: 170.19
Evaluating epoch 0
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 28125.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -7.031712480633345     |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -8.568314376215758     |
| train_0/current_q         | -5.408012719134682     |
| train_0/fw_bonus          | -0.9937991514801979    |
| train_0/fw_loss           | 0.03051592642441392    |
| train_0/mu_grads          | -0.0018970088771311567 |
| train_0/mu_grads_std      | 0.15239244587719442    |
| train_0/mu_loss           | 5.343857561076755      |
| train_0/next_q            | -5.342129751732642     |
| train_0/q_grads           | 0.025544940773397685   |
| train_0/q_grads_std       | 0.11488812137395144    |
| train_0/q_loss            | 0.23800164923153377    |
| train_0/reward            | -0.7002687173597224    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0052490234375        |
| train_0/target_q          | -5.638072727458496     |
| train_1/avg_q             | -4.581352992722786     |
| train_1/current_q         | -4.604816787968003     |
| train_1/fw_bonus          | -0.9962661519646645    |
| train_1/fw_loss           | 0.03818657379597425    |
| train_1/mu_grads          | -0.01340906259138137   |
| train_1/mu_grads_std      | 0.15562377944588662    |
| train_1/mu_loss           | 3.6239321099372175     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -4.264618488183063     |
| train_1/q_grads           | 0.0171407253947109     |
| train_1/q_grads_std       | 0.11793584916740656    |
| train_1/q_loss            | 0.8649507596113427     |
| train_1/reward            | -1.5095588581265473    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0025390625           |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -4.572526514756003     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 222.49. Rollout time: 64.61, Training time: 157.85
Evaluating epoch 1
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 56250.0                |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -14.999999999320549    |
| test_1/avg_q              | -6.4275628136905505    |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -14.73122640289321     |
| train_0/current_q         | -5.362531758464391     |
| train_0/fw_bonus          | -0.996247510612011     |
| train_0/fw_loss           | 0.01895590340718627    |
| train_0/mu_grads          | -0.002616323600523174  |
| train_0/mu_grads_std      | 0.1967708732932806     |
| train_0/mu_loss           | 5.289864510246324      |
| train_0/next_q            | -5.288185884051583     |
| train_0/q_grads           | 0.02748041129671037    |
| train_0/q_grads_std       | 0.1267592217773199     |
| train_0/q_loss            | 0.23019336794296832    |
| train_0/reward            | -0.7003942591865779    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0144775390625        |
| train_0/target_q          | -5.588293458195544     |
| train_1/avg_q             | -7.233048049521163     |
| train_1/current_q         | -4.480188139648878     |
| train_1/fw_bonus          | -0.9944691553711891    |
| train_1/fw_loss           | 0.04731152346357703    |
| train_1/mu_grads          | -0.024298972543329002  |
| train_1/mu_grads_std      | 0.187991376593709      |
| train_1/mu_loss           | 3.247071487059729      |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -4.154532851072616     |
| train_1/q_grads           | -0.0005357949841709342 |
| train_1/q_grads_std       | 0.14069719463586808    |
| train_1/q_loss            | 0.6070165200062616     |
| train_1/reward            | -1.5138361392790103    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0034912109375        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -4.443143445911387     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 216.02. Rollout time: 63.62, Training time: 152.37
Evaluating epoch 2
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 84375.0               |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.99996087176484    |
| test_1/avg_q              | -5.730384441599083    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.997218787540827   |
| train_0/current_q         | -5.397389023486244    |
| train_0/fw_bonus          | -0.9975304931402207   |
| train_0/fw_loss           | 0.012898203334771097  |
| train_0/mu_grads          | -0.010599369346164168 |
| train_0/mu_grads_std      | 0.22307659797370433   |
| train_0/mu_loss           | 5.3289283264692475    |
| train_0/next_q            | -5.32688928638807     |
| train_0/q_grads           | 0.029577987268567085  |
| train_0/q_grads_std       | 0.13554839827120305   |
| train_0/q_loss            | 0.22344557180953903   |
| train_0/reward            | -0.7020489368696872   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0193359375          |
| train_0/target_q          | -5.6213165727653305   |
| train_1/avg_q             | -7.270060884490388    |
| train_1/current_q         | -4.042983305712406    |
| train_1/fw_bonus          | -0.9937606960535049   |
| train_1/fw_loss           | 0.050908961333334446  |
| train_1/mu_grads          | -0.03370015956461429  |
| train_1/mu_grads_std      | 0.1926391065120697    |
| train_1/mu_loss           | 3.298006005607853     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -3.577986779470396    |
| train_1/q_grads           | -0.00692135610152036  |
| train_1/q_grads_std       | 0.16989083476364614   |
| train_1/q_loss            | 0.7660607692245092    |
| train_1/reward            | -1.5205741986756038   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00390625            |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.020690757304758    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 220.53. Rollout time: 64.71, Training time: 155.80
Evaluating epoch 3
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 112451.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.107222805284385   |
| test_1/avg_q              | -6.232251177821374    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.619619408504278   |
| train_0/current_q         | -5.370712064620383    |
| train_0/fw_bonus          | -0.9980351611971855   |
| train_0/fw_loss           | 0.010515384608879685  |
| train_0/mu_grads          | -0.01763771679252386  |
| train_0/mu_grads_std      | 0.24901953414082528   |
| train_0/mu_loss           | 5.322193557871754     |
| train_0/next_q            | -5.320320002139606    |
| train_0/q_grads           | 0.03236617175862193   |
| train_0/q_grads_std       | 0.14552165195345879   |
| train_0/q_loss            | 0.2288827216698675    |
| train_0/reward            | -0.6991274425192386   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0144287109375       |
| train_0/target_q          | -5.599051210953742    |
| train_1/avg_q             | -6.624599011214772    |
| train_1/current_q         | -4.700966403481722    |
| train_1/fw_bonus          | -0.9926883891224861   |
| train_1/fw_loss           | 0.05635409764945507   |
| train_1/mu_grads          | -0.03417159114032984  |
| train_1/mu_grads_std      | 0.20963929183781146   |
| train_1/mu_loss           | 2.880495743011198     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.6761600748566226   |
| train_1/q_grads           | -0.008639604784548283 |
| train_1/q_grads_std       | 0.1839771971106529    |
| train_1/q_loss            | 0.6977638000294779    |
| train_1/reward            | -1.5102602042577928   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.003759765625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0033333333333333335 |
| train_1/target_q          | -4.7039579626356005   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 220.68. Rollout time: 64.38, Training time: 156.27
Evaluating epoch 4
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 140544.0              |
| test/episodes             | 125.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.99999999728519    |
| test_1/avg_q              | -5.668460075423772    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.66855077722041    |
| train_0/current_q         | -5.480206656355388    |
| train_0/fw_bonus          | -0.9983032315969467   |
| train_0/fw_loss           | 0.009249640139751136  |
| train_0/mu_grads          | -0.019315701071172954 |
| train_0/mu_grads_std      | 0.2719515211880207    |
| train_0/mu_loss           | 5.429398740459726     |
| train_0/next_q            | -5.426058180355767    |
| train_0/q_grads           | 0.030543155688792466  |
| train_0/q_grads_std       | 0.15492361560463905   |
| train_0/q_loss            | 0.22787581085284542   |
| train_0/reward            | -0.703363044224534    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.012158203125        |
| train_0/target_q          | -5.711793551053746    |
| train_1/avg_q             | -7.230935274672809    |
| train_1/current_q         | -4.892691490978104    |
| train_1/fw_bonus          | -0.9925193876028061   |
| train_1/fw_loss           | 0.057212143950164315  |
| train_1/mu_grads          | -0.03973218156024814  |
| train_1/mu_grads_std      | 0.22609438113868235   |
| train_1/mu_loss           | 2.7072435264990626    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.102207998357129    |
| train_1/q_grads           | -0.010381972114555538 |
| train_1/q_grads_std       | 0.1980190847069025    |
| train_1/q_loss            | 0.863690784280171     |
| train_1/reward            | -1.4890575522098515   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002587890625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.002                 |
| train_1/target_q          | -4.938830585753591    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 216.39. Rollout time: 64.57, Training time: 151.80
Evaluating epoch 5
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 168669.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.952066140177132   |
| test_1/avg_q              | -6.896074040681719    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.973648852342983   |
| train_0/current_q         | -5.465568522769656    |
| train_0/fw_bonus          | -0.9985117435455322   |
| train_0/fw_loss           | 0.008265202830079943  |
| train_0/mu_grads          | -0.021653500292450188 |
| train_0/mu_grads_std      | 0.28916287124156953   |
| train_0/mu_loss           | 5.409532265946557     |
| train_0/next_q            | -5.407007349546345    |
| train_0/q_grads           | 0.02808622969314456   |
| train_0/q_grads_std       | 0.16353979036211969   |
| train_0/q_loss            | 0.23037287665949227   |
| train_0/reward            | -0.7050297932371905   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0095458984375       |
| train_0/target_q          | -5.6905579560156      |
| train_1/avg_q             | -7.142355155940469    |
| train_1/current_q         | -4.596438845564078    |
| train_1/fw_bonus          | -0.9929898425936698   |
| train_1/fw_loss           | 0.054823311138898136  |
| train_1/mu_grads          | -0.04355494361370802  |
| train_1/mu_grads_std      | 0.24290951080620288   |
| train_1/mu_loss           | 2.5831025228847806    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.7089200652324505   |
| train_1/q_grads           | -0.012728704023174942 |
| train_1/q_grads_std       | 0.21024693921208382   |
| train_1/q_loss            | 0.5234600312460849    |
| train_1/reward            | -1.5155012673378223   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0023681640625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.664459661358888    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 213.84. Rollout time: 63.35, Training time: 150.46
Evaluating epoch 6
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 196794.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.747103402230828    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.975704773211886   |
| train_0/current_q         | -5.453549631854093    |
| train_0/fw_bonus          | -0.998658473789692    |
| train_0/fw_loss           | 0.007572366844397038  |
| train_0/mu_grads          | -0.021820969693362714 |
| train_0/mu_grads_std      | 0.30137887224555016   |
| train_0/mu_loss           | 5.392051229119976     |
| train_0/next_q            | -5.389286133449879    |
| train_0/q_grads           | 0.024294360354542733  |
| train_0/q_grads_std       | 0.1690812811255455    |
| train_0/q_loss            | 0.22554565490204367   |
| train_0/reward            | -0.7050055065366905   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0066162109375       |
| train_0/target_q          | -5.680994314232269    |
| train_1/avg_q             | -7.58251785965659     |
| train_1/current_q         | -4.811738283183251    |
| train_1/fw_bonus          | -0.9927023202180862   |
| train_1/fw_loss           | 0.05628334786742926   |
| train_1/mu_grads          | -0.046450074017047885 |
| train_1/mu_grads_std      | 0.2560677960515022    |
| train_1/mu_loss           | 2.6527156948512927    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.004564071638131    |
| train_1/q_grads           | -0.015389323863200844 |
| train_1/q_grads_std       | 0.2229720588773489    |
| train_1/q_loss            | 0.5032916384435687    |
| train_1/reward            | -1.507825764689187    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022705078125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.873270285139709    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 212.05. Rollout time: 63.23, Training time: 148.80
Evaluating epoch 7
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 224919.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.181359463771783    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.962198953043794   |
| train_0/current_q         | -5.404026482806932    |
| train_0/fw_bonus          | -0.9987457752227783   |
| train_0/fw_loss           | 0.0071601456846110524 |
| train_0/mu_grads          | -0.026807764312252402 |
| train_0/mu_grads_std      | 0.31374519094824793   |
| train_0/mu_loss           | 5.344858244574775     |
| train_0/next_q            | -5.341418263682231    |
| train_0/q_grads           | 0.020921023981645703  |
| train_0/q_grads_std       | 0.1767833337187767    |
| train_0/q_loss            | 0.22665955250716988   |
| train_0/reward            | -0.7056717182305874   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005810546875        |
| train_0/target_q          | -5.62811747059809     |
| train_1/avg_q             | -7.7173778810985      |
| train_1/current_q         | -4.681446507027426    |
| train_1/fw_bonus          | -0.993418550491333    |
| train_1/fw_loss           | 0.05264640711247921   |
| train_1/mu_grads          | -0.049682508874684575 |
| train_1/mu_grads_std      | 0.2696633279323578    |
| train_1/mu_loss           | 2.456418306651473     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.736075396213329    |
| train_1/q_grads           | -0.01788842990063131  |
| train_1/q_grads_std       | 0.23603422455489637   |
| train_1/q_loss            | 0.7543433341205166    |
| train_1/reward            | -1.5013967718834464   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002880859375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.7686365112153695   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 221.78. Rollout time: 63.61, Training time: 158.14
Evaluating epoch 8
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 253044.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.942523765563796    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.991379686445011   |
| train_0/current_q         | -5.453839784475269    |
| train_0/fw_bonus          | -0.998796109855175    |
| train_0/fw_loss           | 0.0069225464249029756 |
| train_0/mu_grads          | -0.025748420180752872 |
| train_0/mu_grads_std      | 0.3238950163125992    |
| train_0/mu_loss           | 5.392246277977638     |
| train_0/next_q            | -5.390401463349494    |
| train_0/q_grads           | 0.01831660605967045   |
| train_0/q_grads_std       | 0.18377010934054852   |
| train_0/q_loss            | 0.23063977177263678   |
| train_0/reward            | -0.7066734416228428   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0059326171875       |
| train_0/target_q          | -5.685139311234854    |
| train_1/avg_q             | -7.524625373918809    |
| train_1/current_q         | -4.61192645008014     |
| train_1/fw_bonus          | -0.9940812423825264   |
| train_1/fw_loss           | 0.04928132127970457   |
| train_1/mu_grads          | -0.05214144587516785  |
| train_1/mu_grads_std      | 0.2773177169263363    |
| train_1/mu_loss           | 2.68226941141517      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.69791837903516     |
| train_1/q_grads           | -0.020288582146167754 |
| train_1/q_grads_std       | 0.24417917467653752   |
| train_1/q_loss            | 0.4112146439901185    |
| train_1/reward            | -1.482965911426436    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0027099609375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.675458185593728    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 213.04. Rollout time: 63.16, Training time: 149.86
Evaluating epoch 9
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 281169.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.625959919046191    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999983288008   |
| train_0/current_q         | -5.449192534968528    |
| train_0/fw_bonus          | -0.9988223657011985   |
| train_0/fw_loss           | 0.006798546225763857  |
| train_0/mu_grads          | -0.029735655710101127 |
| train_0/mu_grads_std      | 0.3302418999373913    |
| train_0/mu_loss           | 5.3887721299842255    |
| train_0/next_q            | -5.386418485075728    |
| train_0/q_grads           | 0.014177760225720704  |
| train_0/q_grads_std       | 0.19109021201729776   |
| train_0/q_loss            | 0.22650284544061342   |
| train_0/reward            | -0.7059419440272905   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0060791015625       |
| train_0/target_q          | -5.67702979437067     |
| train_1/avg_q             | -7.3108366577736925   |
| train_1/current_q         | -4.813804411465644    |
| train_1/fw_bonus          | -0.9944705978035927   |
| train_1/fw_loss           | 0.04730415726080537   |
| train_1/mu_grads          | -0.05635764701291919  |
| train_1/mu_grads_std      | 0.2814283311367035    |
| train_1/mu_loss           | 2.6277361100363037    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.987039638613917    |
| train_1/q_grads           | -0.022139899944886566 |
| train_1/q_grads_std       | 0.2493178814649582    |
| train_1/q_loss            | 0.38981330227484007   |
| train_1/reward            | -1.4908510251625557   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00283203125         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.886330653729597    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 220.74. Rollout time: 63.44, Training time: 157.27
Evaluating epoch 10
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 309294.0              |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.834741437981259    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.428402334262332    |
| train_0/fw_bonus          | -0.9988872990012169   |
| train_0/fw_loss           | 0.006491911993362009  |
| train_0/mu_grads          | -0.027029431983828546 |
| train_0/mu_grads_std      | 0.3386378973722458    |
| train_0/mu_loss           | 5.368184184856763     |
| train_0/next_q            | -5.363978225186728    |
| train_0/q_grads           | 0.013936948729678988  |
| train_0/q_grads_std       | 0.19807155802845955   |
| train_0/q_loss            | 0.2176313258122486    |
| train_0/reward            | -0.705986623166973    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050537109375       |
| train_0/target_q          | -5.659826452480893    |
| train_1/avg_q             | -7.566582688690704    |
| train_1/current_q         | -4.942744271705688    |
| train_1/fw_bonus          | -0.9940908178687096   |
| train_1/fw_loss           | 0.049232712388038634  |
| train_1/mu_grads          | -0.058904627058655026 |
| train_1/mu_grads_std      | 0.2902370013296604    |
| train_1/mu_loss           | 2.649763629108162     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.420696959542829    |
| train_1/q_grads           | -0.02445370159111917  |
| train_1/q_grads_std       | 0.2587177507579327    |
| train_1/q_loss            | 0.39606626050290616   |
| train_1/reward            | -1.4646113231428899   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001953125           |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -5.0323054521908155   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 212.89. Rollout time: 62.50, Training time: 150.36
Evaluating epoch 11
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 337419.0              |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.49667777179665     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999999999454381   |
| train_0/current_q         | -5.415156613526895    |
| train_0/fw_bonus          | -0.9989258944988251   |
| train_0/fw_loss           | 0.006309696158859878  |
| train_0/mu_grads          | -0.026770866010338068 |
| train_0/mu_grads_std      | 0.3462449923157692    |
| train_0/mu_loss           | 5.3532270948251695    |
| train_0/next_q            | -5.350434291383058    |
| train_0/q_grads           | 0.011600178014487029  |
| train_0/q_grads_std       | 0.20408998541533946   |
| train_0/q_loss            | 0.21187669669318562   |
| train_0/reward            | -0.7032837510174431   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005908203125        |
| train_0/target_q          | -5.646395439289471    |
| train_1/avg_q             | -7.606053520985689    |
| train_1/current_q         | -4.6776574916090015   |
| train_1/fw_bonus          | -0.994318126142025    |
| train_1/fw_loss           | 0.04807842317968607   |
| train_1/mu_grads          | -0.06322697922587395  |
| train_1/mu_grads_std      | 0.2960650101304054    |
| train_1/mu_loss           | 2.5275879235994347    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.945584457459847    |
| train_1/q_grads           | -0.026152253337204456 |
| train_1/q_grads_std       | 0.26420575827360154   |
| train_1/q_loss            | 0.38442084608350835   |
| train_1/reward            | -1.4868807430393645   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0028564453125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.768040537903799    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 217.45. Rollout time: 63.62, Training time: 153.80
Evaluating epoch 12
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 365530.0              |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.321414175861287    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.99238787384417    |
| train_0/current_q         | -5.425402224152515    |
| train_0/fw_bonus          | -0.9989336475729942   |
| train_0/fw_loss           | 0.006273079884704202  |
| train_0/mu_grads          | -0.026322084292769433 |
| train_0/mu_grads_std      | 0.35367295518517494   |
| train_0/mu_loss           | 5.361217030366343     |
| train_0/next_q            | -5.35884313252406     |
| train_0/q_grads           | 0.010069589503109455  |
| train_0/q_grads_std       | 0.20962408930063248   |
| train_0/q_loss            | 0.21056900517255145   |
| train_0/reward            | -0.7038491521801916   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0051025390625       |
| train_0/target_q          | -5.658361681854992    |
| train_1/avg_q             | -7.618594750402155    |
| train_1/current_q         | -5.0867944974988015   |
| train_1/fw_bonus          | -0.9944950506091118   |
| train_1/fw_loss           | 0.04718002704903483   |
| train_1/mu_grads          | -0.06541603822261095  |
| train_1/mu_grads_std      | 0.3078767485916615    |
| train_1/mu_loss           | 2.776511401858066     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.605986194460752    |
| train_1/q_grads           | -0.027318987995386124 |
| train_1/q_grads_std       | 0.2701653949916363    |
| train_1/q_loss            | 0.38536062886487443   |
| train_1/reward            | -1.4854189114717884   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.003076171875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0006666666666666666 |
| train_1/target_q          | -5.1672108799044985   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 216.15. Rollout time: 62.75, Training time: 153.37
Evaluating epoch 13
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 393645.0              |
| test/episodes             | 350.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.754863470764723   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.93270754709398    |
| train_0/current_q         | -5.39784066748186     |
| train_0/fw_bonus          | -0.9990637078881264   |
| train_0/fw_loss           | 0.005659089668188244  |
| train_0/mu_grads          | -0.026816250337287784 |
| train_0/mu_grads_std      | 0.3578348822891712    |
| train_0/mu_loss           | 5.338081301812873     |
| train_0/next_q            | -5.335472485760509    |
| train_0/q_grads           | 0.007843030244112014  |
| train_0/q_grads_std       | 0.2148040659725666    |
| train_0/q_loss            | 0.20636514338979603   |
| train_0/reward            | -0.7015826290640689   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0059814453125       |
| train_0/target_q          | -5.628215791997286    |
| train_1/avg_q             | -7.543120714675216    |
| train_1/current_q         | -4.922057887916554    |
| train_1/fw_bonus          | -0.9952141866087914   |
| train_1/fw_loss           | 0.043528311979025604  |
| train_1/mu_grads          | -0.06825680658221245  |
| train_1/mu_grads_std      | 0.3126285284757614    |
| train_1/mu_loss           | 2.5772680914240755    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.452639459418888    |
| train_1/q_grads           | -0.034136390313506126 |
| train_1/q_grads_std       | 0.27893901616334915   |
| train_1/q_loss            | 5.905913174163992     |
| train_1/reward            | -1.4789669595178565   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002978515625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0006666666666666666 |
| train_1/target_q          | -5.11831576091965     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 212.15. Rollout time: 63.32, Training time: 148.80
Evaluating epoch 14
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 14                   |
| policy/steps              | 421668.0             |
| test/episodes             | 375.0                |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -14.998038686742458  |
| test_1/avg_q              | -7.430231695396059   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 1500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -14.605015398415414  |
| train_0/current_q         | -5.447628833357645   |
| train_0/fw_bonus          | -0.9990266770124435  |
| train_0/fw_loss           | 0.005833888577762991 |
| train_0/mu_grads          | -0.02531970860436559 |
| train_0/mu_grads_std      | 0.3629994884133339   |
| train_0/mu_loss           | 5.3927073996591135   |
| train_0/next_q            | -5.390152130686825   |
| train_0/q_grads           | 0.004875320929568261 |
| train_0/q_grads_std       | 0.22243164516985417  |
| train_0/q_loss            | 0.22006182797079782  |
| train_0/reward            | -0.7038346258348611  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0053955078125      |
| train_0/target_q          | -5.680228739599872   |
| train_1/avg_q             | -8.846638374262838   |
| train_1/current_q         | -4.543012747057165   |
| train_1/fw_bonus          | -0.9951045155525208  |
| train_1/fw_loss           | 0.044085264578461646 |
| train_1/mu_grads          | -0.06948604211211204 |
| train_1/mu_grads_std      | 0.31750314831733706  |
| train_1/mu_loss           | 2.873687671304984    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -4.205848044377665   |
| train_1/q_grads           | -0.03791035581380129 |
| train_1/q_grads_std       | 0.28194174394011495  |
| train_1/q_loss            | 0.4778649261542225   |
| train_1/reward            | -1.4876767671783455  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002587890625       |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.006                |
| train_1/target_q          | -4.598349612242261   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 219.46. Rollout time: 63.30, Training time: 156.13
Evaluating epoch 15
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 449793.0              |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999997853452   |
| test_1/avg_q              | -7.116954992818319    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.963169395785908   |
| train_0/current_q         | -5.476760989090236    |
| train_0/fw_bonus          | -0.9990591526031494   |
| train_0/fw_loss           | 0.005680579424370081  |
| train_0/mu_grads          | -0.023472012067213655 |
| train_0/mu_grads_std      | 0.36937878280878067   |
| train_0/mu_loss           | 5.420849159259567     |
| train_0/next_q            | -5.417241820440594    |
| train_0/q_grads           | 0.0036053532094229013 |
| train_0/q_grads_std       | 0.22930631823837758   |
| train_0/q_loss            | 0.22546419564980943   |
| train_0/reward            | -0.7060481268497825   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0056396484375       |
| train_0/target_q          | -5.714506361782121    |
| train_1/avg_q             | -7.494935333009352    |
| train_1/current_q         | -4.861756447149289    |
| train_1/fw_bonus          | -0.9952291578054429   |
| train_1/fw_loss           | 0.043452329467982054  |
| train_1/mu_grads          | -0.06814814992249012  |
| train_1/mu_grads_std      | 0.3250147864222527    |
| train_1/mu_loss           | 2.760845380974188     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.8217277065143715   |
| train_1/q_grads           | -0.038875749427825214 |
| train_1/q_grads_std       | 0.28660678416490554   |
| train_1/q_loss            | 0.4875523653819692    |
| train_1/reward            | -1.499079420921771    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.003173828125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.905825649272994    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 211.83. Rollout time: 63.29, Training time: 148.51
Evaluating epoch 16
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 477888.0              |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.73017008498549    |
| test_1/avg_q              | -7.25867748581085     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.741497413573665   |
| train_0/current_q         | -5.432106630628104    |
| train_0/fw_bonus          | -0.9990148931741715   |
| train_0/fw_loss           | 0.005889521434437483  |
| train_0/mu_grads          | -0.024245565850287677 |
| train_0/mu_grads_std      | 0.37669177129864695   |
| train_0/mu_loss           | 5.366502768264754     |
| train_0/next_q            | -5.363580362617145    |
| train_0/q_grads           | 0.002760342211695388  |
| train_0/q_grads_std       | 0.2367309257388115    |
| train_0/q_loss            | 0.23974050182791853   |
| train_0/reward            | -0.7082965081026487   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0050048828125       |
| train_0/target_q          | -5.656545277359652    |
| train_1/avg_q             | -7.612049731543846    |
| train_1/current_q         | -5.280901072895799    |
| train_1/fw_bonus          | -0.9945283070206642   |
| train_1/fw_loss           | 0.047011171001940966  |
| train_1/mu_grads          | -0.07000882420688867  |
| train_1/mu_grads_std      | 0.330894248187542     |
| train_1/mu_loss           | 2.9184761673221358    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -5.267946400257957    |
| train_1/q_grads           | -0.045878743100911376 |
| train_1/q_grads_std       | 0.29505904465913774   |
| train_1/q_loss            | 0.5101137290733696    |
| train_1/reward            | -1.5057846599003823   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002685546875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0026666666666666666 |
| train_1/target_q          | -5.315129942531245    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 224.07. Rollout time: 63.98, Training time: 160.06
Evaluating epoch 17
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 505998.0              |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999999999908466   |
| test_1/avg_q              | -6.265675864640138    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.721992632168291   |
| train_0/current_q         | -5.412016318344181    |
| train_0/fw_bonus          | -0.9988820850849152   |
| train_0/fw_loss           | 0.006516599131282419  |
| train_0/mu_grads          | -0.023497017798945308 |
| train_0/mu_grads_std      | 0.38349209204316137   |
| train_0/mu_loss           | 5.333787542990104     |
| train_0/next_q            | -5.332165434542594    |
| train_0/q_grads           | 0.0037261694553308187 |
| train_0/q_grads_std       | 0.24310647398233415   |
| train_0/q_loss            | 0.24971173587664902   |
| train_0/reward            | -0.7135157469783735   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005126953125        |
| train_0/target_q          | -5.634237151964101    |
| train_1/avg_q             | -7.635900323605096    |
| train_1/current_q         | -4.968445705137038    |
| train_1/fw_bonus          | -0.9937692508101463   |
| train_1/fw_loss           | 0.05086560109630227   |
| train_1/mu_grads          | -0.07280514985322953  |
| train_1/mu_grads_std      | 0.3396028205752373    |
| train_1/mu_loss           | 2.6693795405443703    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.888335327022017    |
| train_1/q_grads           | -0.05028426833450794  |
| train_1/q_grads_std       | 0.3029754921793938    |
| train_1/q_loss            | 0.48091287024244683   |
| train_1/reward            | -1.527560890071618    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002880859375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0013333333333333333 |
| train_1/target_q          | -4.999011343788865    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 214.09. Rollout time: 63.13, Training time: 150.94
Evaluating epoch 18
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 534123.0              |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.982969747812104   |
| test_1/avg_q              | -7.018287258058495    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999966734348051   |
| train_0/current_q         | -5.451922230628752    |
| train_0/fw_bonus          | -0.9988051727414131   |
| train_0/fw_loss           | 0.00687968471320346   |
| train_0/mu_grads          | -0.022155430214479566 |
| train_0/mu_grads_std      | 0.39098829627037046   |
| train_0/mu_loss           | 5.361840441578235     |
| train_0/next_q            | -5.354935241926562    |
| train_0/q_grads           | 0.0021097717224620284 |
| train_0/q_grads_std       | 0.24757833927869796   |
| train_0/q_loss            | 0.2572167815159947    |
| train_0/reward            | -0.7229621604725253   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0052490234375       |
| train_0/target_q          | -5.672702583096526    |
| train_1/avg_q             | -7.433201195257219    |
| train_1/current_q         | -4.818855113115697    |
| train_1/fw_bonus          | -0.9929409384727478   |
| train_1/fw_loss           | 0.05507163358852267   |
| train_1/mu_grads          | -0.07581591550260783  |
| train_1/mu_grads_std      | 0.34792772829532626   |
| train_1/mu_loss           | 2.659033208064738     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.264058197586914    |
| train_1/q_grads           | -0.05364256463944912  |
| train_1/q_grads_std       | 0.3059129409492016    |
| train_1/q_loss            | 0.4640504120629       |
| train_1/reward            | -1.5039167578761408   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.858291562079471    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 223.89. Rollout time: 63.52, Training time: 160.34
Evaluating epoch 19
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 562222.0              |
| test/episodes             | 500.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.3455813365451466   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.964150657501984   |
| train_0/current_q         | -5.549423726243969    |
| train_0/fw_bonus          | -0.9987207606434823   |
| train_0/fw_loss           | 0.0072782969917170705 |
| train_0/mu_grads          | -0.019218314765021206 |
| train_0/mu_grads_std      | 0.3975683569908142    |
| train_0/mu_loss           | 5.4632887530325736    |
| train_0/next_q            | -5.457734774484362    |
| train_0/q_grads           | 0.0036082610138691964 |
| train_0/q_grads_std       | 0.2528760202229023    |
| train_0/q_loss            | 0.2672987825294487    |
| train_0/reward            | -0.7301098899333738   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0051513671875       |
| train_0/target_q          | -5.784827760678086    |
| train_1/avg_q             | -7.6616109893840765   |
| train_1/current_q         | -4.986965302180165    |
| train_1/fw_bonus          | -0.9926508843898774   |
| train_1/fw_loss           | 0.05654444871470332   |
| train_1/mu_grads          | -0.07509715892374516  |
| train_1/mu_grads_std      | 0.3550454907119274    |
| train_1/mu_loss           | 2.8638887777080555    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.476322676534666    |
| train_1/q_grads           | -0.05437262263149023  |
| train_1/q_grads_std       | 0.3080857887864113    |
| train_1/q_loss            | 0.6469417631302247    |
| train_1/reward            | -1.527697515970067    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0013333333333333333 |
| train_1/target_q          | -5.0112340662856605   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 218.60. Rollout time: 62.90, Training time: 155.68
Evaluating epoch 20
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 590347.0              |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -14.999964473209431   |
| test_1/avg_q              | -7.525831514149737    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.99149468094063    |
| train_0/current_q         | -5.505227383856027    |
| train_0/fw_bonus          | -0.9987885296344757   |
| train_0/fw_loss           | 0.0069583148579113185 |
| train_0/mu_grads          | -0.020392504101619125 |
| train_0/mu_grads_std      | 0.4031005859375       |
| train_0/mu_loss           | 5.4088445911543035    |
| train_0/next_q            | -5.403370324162138    |
| train_0/q_grads           | 0.002878231805516407  |
| train_0/q_grads_std       | 0.2576845809817314    |
| train_0/q_loss            | 0.2673260159001477    |
| train_0/reward            | -0.7278732673636114   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049560546875       |
| train_0/target_q          | -5.724989948561792    |
| train_1/avg_q             | -7.737237604402525    |
| train_1/current_q         | -4.852591724702265    |
| train_1/fw_bonus          | -0.9930287912487984   |
| train_1/fw_loss           | 0.05462548192590475   |
| train_1/mu_grads          | -0.0751497508957982   |
| train_1/mu_grads_std      | 0.36219252422451975   |
| train_1/mu_loss           | 3.14418088869565      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -4.340826928815783    |
| train_1/q_grads           | -0.05530887898057699  |
| train_1/q_grads_std       | 0.31748045831918714   |
| train_1/q_loss            | 0.4158642691302106    |
| train_1/reward            | -1.5136408640959416   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0027587890625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -4.8637049958332765   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 223.91. Rollout time: 63.89, Training time: 160.00
Evaluating epoch 21
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 618472.0              |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -1.6973897618288147   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -14.999928120865324   |
| train_0/current_q         | -5.487708582119871    |
| train_0/fw_bonus          | -0.9988697826862335   |
| train_0/fw_loss           | 0.006574667256791145  |
| train_0/mu_grads          | -0.020613892609253524 |
| train_0/mu_grads_std      | 0.4072536289691925    |
| train_0/mu_loss           | 5.397086012292572     |
| train_0/next_q            | -5.392945619602261    |
| train_0/q_grads           | 0.0015822087763808668 |
| train_0/q_grads_std       | 0.26232481077313424   |
| train_0/q_loss            | 0.25093919555989375   |
| train_0/reward            | -0.7258753204820095   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046630859375       |
| train_0/target_q          | -5.715735456982007    |
| train_1/avg_q             | -7.29967949086154     |
| train_1/current_q         | -1.5258264006614175   |
| train_1/fw_bonus          | -0.993400190770626    |
| train_1/fw_loss           | 0.052739580161869526  |
| train_1/mu_grads          | -0.07847954705357552  |
| train_1/mu_grads_std      | 0.3659565895795822    |
| train_1/mu_loss           | 1.199484574788172     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -0.035963605028587094 |
| train_1/q_grads           | -0.058548349514603616 |
| train_1/q_grads_std       | 0.3240499645471573    |
| train_1/q_loss            | 0.11821625084289034   |
| train_1/reward            | -1.5052450187264186   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002490234375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.5316024403918687   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 255.24. Rollout time: 68.71, Training time: 186.50
Evaluating epoch 22
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 646597.0               |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -2.430332358974897     |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.532845357555911     |
| train_0/fw_bonus          | -0.9990070849657059    |
| train_0/fw_loss           | 0.005926333053503185   |
| train_0/mu_grads          | -0.02127050580456853   |
| train_0/mu_grads_std      | 0.41150598376989367    |
| train_0/mu_loss           | 5.452313272757401      |
| train_0/next_q            | -5.448433730453743     |
| train_0/q_grads           | -4.079821111417914e-05 |
| train_0/q_grads_std       | 0.26723153665661814    |
| train_0/q_loss            | 0.24772770868407407    |
| train_0/reward            | -0.7199625319546612    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.004541015625         |
| train_0/target_q          | -5.76548686119087      |
| train_1/avg_q             | -5.901644069203607     |
| train_1/current_q         | -3.051879039639373     |
| train_1/fw_bonus          | -0.9940960809588433    |
| train_1/fw_loss           | 0.049205920100212096   |
| train_1/mu_grads          | -0.0786210646852851    |
| train_1/mu_grads_std      | 0.36570840030908586    |
| train_1/mu_loss           | 1.2507890104219075     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -3.2617512729084446    |
| train_1/q_grads           | -0.06133560836315155   |
| train_1/q_grads_std       | 0.3407368876039982     |
| train_1/q_loss            | 4.809080207059854      |
| train_1/reward            | -1.502321480554383     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017333984375        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -3.7413475737491866    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 275.55. Rollout time: 78.09, Training time: 197.43
Evaluating epoch 23
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 674722.0              |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.94036980713688    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.43575206589882     |
| train_0/fw_bonus          | -0.9991326048970223   |
| train_0/fw_loss           | 0.0053337478428147735 |
| train_0/mu_grads          | -0.021157386898994445 |
| train_0/mu_grads_std      | 0.41540650874376295   |
| train_0/mu_loss           | 5.362555679120432     |
| train_0/next_q            | -5.360429237364937    |
| train_0/q_grads           | -0.00123444048804231  |
| train_0/q_grads_std       | 0.2718741796910763    |
| train_0/q_loss            | 0.22766599443759156   |
| train_0/reward            | -0.7106746992642001   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004248046875        |
| train_0/target_q          | -5.665288213000922    |
| train_1/avg_q             | -7.628613964567405    |
| train_1/current_q         | -11.242247610344513   |
| train_1/fw_bonus          | -0.9937881693243981   |
| train_1/fw_loss           | 0.05076953060925007   |
| train_1/mu_grads          | -0.0766881825402379   |
| train_1/mu_grads_std      | 0.3678780421614647    |
| train_1/mu_loss           | 6.046569923255968     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06026818612590432  |
| train_1/q_grads_std       | 0.3504725471138954    |
| train_1/q_loss            | 6.73006241371193      |
| train_1/reward            | -1.5070381232595538   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022705078125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.211693884978308   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 253.37. Rollout time: 69.70, Training time: 183.65
Evaluating epoch 24
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
------------------------------------------------------
| epoch                     | 24                     |
| policy/steps              | 702847.0               |
| test/episodes             | 625.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -7.769072792099004e-07 |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.4764533126329225    |
| train_0/fw_bonus          | -0.999288310110569     |
| train_0/fw_loss           | 0.00459849521284923    |
| train_0/mu_grads          | -0.019900842849165202  |
| train_0/mu_grads_std      | 0.4186591051518917     |
| train_0/mu_loss           | 5.410933018087101      |
| train_0/next_q            | -5.408072394167149     |
| train_0/q_grads           | -0.002452391473343596  |
| train_0/q_grads_std       | 0.2758837632834911     |
| train_0/q_loss            | 0.21038654860383602    |
| train_0/reward            | -0.7071270720844041    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.004150390625         |
| train_0/target_q          | -5.711372626717119     |
| train_1/avg_q             | -11.487043494173811    |
| train_1/current_q         | -0.0045876044182127235 |
| train_1/fw_bonus          | -0.9947862192988396    |
| train_1/fw_loss           | 0.04570146389305592    |
| train_1/mu_grads          | -0.07664827071130276   |
| train_1/mu_grads_std      | 0.3718398928642273     |
| train_1/mu_loss           | 0.001419493673437745   |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -1.214255273599171e-98 |
| train_1/q_grads           | -0.06119689075276256   |
| train_1/q_grads_std       | 0.3605313844978809     |
| train_1/q_loss            | 6.436124836577072      |
| train_1/reward            | -1.4941948712905286    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0026123046875        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4941948712905286    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 260.41. Rollout time: 71.70, Training time: 188.68
Evaluating epoch 25
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 730972.0              |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.9999116463686     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.439604310912815    |
| train_0/fw_bonus          | -0.9993553280830383   |
| train_0/fw_loss           | 0.004282132460502908  |
| train_0/mu_grads          | -0.021232274128124118 |
| train_0/mu_grads_std      | 0.422486899793148     |
| train_0/mu_loss           | 5.377859657453162     |
| train_0/next_q            | -5.375540447261664    |
| train_0/q_grads           | -0.003213342116214335 |
| train_0/q_grads_std       | 0.27939025685191154   |
| train_0/q_loss            | 0.2043608732210945    |
| train_0/reward            | -0.7044261992028623   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00419921875         |
| train_0/target_q          | -5.674407585256207    |
| train_1/avg_q             | -9.451066680463018    |
| train_1/current_q         | -10.989342648877255   |
| train_1/fw_bonus          | -0.9948793023824691   |
| train_1/fw_loss           | 0.04522886388003826   |
| train_1/mu_grads          | -0.07727846056222916  |
| train_1/mu_grads_std      | 0.3713907554745674    |
| train_1/mu_loss           | 5.954889571249699     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.05785452071577311  |
| train_1/q_grads_std       | 0.36869887784123423   |
| train_1/q_loss            | 5.53367999665277      |
| train_1/reward            | -1.520523145763582    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.900386427013586   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 261.42. Rollout time: 72.63, Training time: 188.76
Evaluating epoch 26
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 26                    |
| policy/steps              | 759097.0              |
| test/episodes             | 675.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.960717797085788   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.437358418081805    |
| train_0/fw_bonus          | -0.9994111225008965   |
| train_0/fw_loss           | 0.004018721717875451  |
| train_0/mu_grads          | -0.02313468619249761  |
| train_0/mu_grads_std      | 0.42586380019783976   |
| train_0/mu_loss           | 5.377973434552731     |
| train_0/next_q            | -5.376188089615264    |
| train_0/q_grads           | -0.004550483345519751 |
| train_0/q_grads_std       | 0.28232926353812215   |
| train_0/q_loss            | 0.19653273927618325   |
| train_0/reward            | -0.7015244059562974   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047607421875       |
| train_0/target_q          | -5.67117274289101     |
| train_1/avg_q             | -14.999987685122896   |
| train_1/current_q         | -10.991075617280664   |
| train_1/fw_bonus          | -0.9951129361987114   |
| train_1/fw_loss           | 0.04404243435710668   |
| train_1/mu_grads          | -0.07784373741596937  |
| train_1/mu_grads_std      | 0.37169135361909866   |
| train_1/mu_loss           | 5.839996126825376     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.059267799463123085 |
| train_1/q_grads_std       | 0.3772271007299423    |
| train_1/q_loss            | 5.8618746607998045    |
| train_1/reward            | -1.4968484640870883   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.925520339087091   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 248.96. Rollout time: 68.88, Training time: 180.06
Evaluating epoch 27
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 787222.0              |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -13.807468139155064   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.3855012834228635   |
| train_0/fw_bonus          | -0.9994533941149711   |
| train_0/fw_loss           | 0.003819128015311435  |
| train_0/mu_grads          | -0.02366830254904926  |
| train_0/mu_grads_std      | 0.4300012312829494    |
| train_0/mu_loss           | 5.318518207649296     |
| train_0/next_q            | -5.31673434320042     |
| train_0/q_grads           | -0.005515616596676409 |
| train_0/q_grads_std       | 0.286993969976902     |
| train_0/q_loss            | 0.1995068648555532    |
| train_0/reward            | -0.7027418314581155   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044189453125       |
| train_0/target_q          | -5.614672584471347    |
| train_1/avg_q             | -14.992523262183562   |
| train_1/current_q         | -11.081780550521803   |
| train_1/fw_bonus          | -0.9952569767832756   |
| train_1/fw_loss           | 0.04331103339791298   |
| train_1/mu_grads          | -0.07887968644499779  |
| train_1/mu_grads_std      | 0.3723327472805977    |
| train_1/mu_loss           | 5.499125955230881     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.059197808429598806 |
| train_1/q_grads_std       | 0.38423565253615377   |
| train_1/q_loss            | 5.503871648463437     |
| train_1/reward            | -1.5012539793875477   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022216796875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.025030834856302   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 247.90. Rollout time: 68.23, Training time: 179.65
Evaluating epoch 28
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 815347.0              |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -10.527198878831587   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.402280638072112    |
| train_0/fw_bonus          | -0.9995019763708115   |
| train_0/fw_loss           | 0.0035897446097806094 |
| train_0/mu_grads          | -0.025628140522167088 |
| train_0/mu_grads_std      | 0.433436119556427     |
| train_0/mu_loss           | 5.337620698806198     |
| train_0/next_q            | -5.335565677164595    |
| train_0/q_grads           | -0.007712277281098068 |
| train_0/q_grads_std       | 0.2921645298600197    |
| train_0/q_loss            | 0.19895532109319677   |
| train_0/reward            | -0.7031445405831619   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0045654296875       |
| train_0/target_q          | -5.634318084209347    |
| train_1/avg_q             | -14.79344946522036    |
| train_1/current_q         | -10.895335626288121   |
| train_1/fw_bonus          | -0.9960325717926025   |
| train_1/fw_loss           | 0.039372673723846674  |
| train_1/mu_grads          | -0.0796644052490592   |
| train_1/mu_grads_std      | 0.3729502886533737    |
| train_1/mu_loss           | 4.261548289465334     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.05989461550489068  |
| train_1/q_grads_std       | 0.38978479579091074   |
| train_1/q_loss            | 5.378816839712847     |
| train_1/reward            | -1.5018981219072884   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.925545582844792   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 294.06. Rollout time: 76.76, Training time: 217.27
Evaluating epoch 29
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 843472.0              |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.959277414643399   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.454452609411253    |
| train_0/fw_bonus          | -0.9995128139853477   |
| train_0/fw_loss           | 0.003538582567125559  |
| train_0/mu_grads          | -0.026434063073247673 |
| train_0/mu_grads_std      | 0.43820608630776403   |
| train_0/mu_loss           | 5.389539324648869     |
| train_0/next_q            | -5.386832718351265    |
| train_0/q_grads           | -0.009229696309193968 |
| train_0/q_grads_std       | 0.29713363721966746   |
| train_0/q_loss            | 0.19998207645118543   |
| train_0/reward            | -0.7052739817438123   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047607421875       |
| train_0/target_q          | -5.688742154512815    |
| train_1/avg_q             | -13.38362160265617    |
| train_1/current_q         | -11.04198777858063    |
| train_1/fw_bonus          | -0.9960887968540192   |
| train_1/fw_loss           | 0.03908716151490808   |
| train_1/mu_grads          | -0.08035978730767965  |
| train_1/mu_grads_std      | 0.37461758181452753   |
| train_1/mu_loss           | 5.601116797660305     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.0620549819432199   |
| train_1/q_grads_std       | 0.39373690634965897   |
| train_1/q_loss            | 5.589634939057595     |
| train_1/reward            | -1.5074682268998003   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015869140625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.981000941743554   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 300.06. Rollout time: 82.69, Training time: 217.34
Evaluating epoch 30
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 30                    |
| policy/steps              | 871597.0              |
| test/episodes             | 775.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -13.802808863137262   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.456954397840592    |
| train_0/fw_bonus          | -0.9994615331292153   |
| train_0/fw_loss           | 0.003780672186985612  |
| train_0/mu_grads          | -0.02735486999154091  |
| train_0/mu_grads_std      | 0.44194532334804537   |
| train_0/mu_loss           | 5.3877515481328775    |
| train_0/next_q            | -5.385576463561703    |
| train_0/q_grads           | -0.010934008285403252 |
| train_0/q_grads_std       | 0.30248050913214686   |
| train_0/q_loss            | 0.20004440898258186   |
| train_0/reward            | -0.7067864311720768   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.690399384956323    |
| train_1/avg_q             | -14.99999899076231    |
| train_1/current_q         | -11.221919441558509   |
| train_1/fw_bonus          | -0.9959890305995941   |
| train_1/fw_loss           | 0.03959382651373744   |
| train_1/mu_grads          | -0.08094722051173449  |
| train_1/mu_grads_std      | 0.37544491365551946   |
| train_1/mu_loss           | 5.325011860195277     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06209697686135769  |
| train_1/q_grads_std       | 0.4003288209438324    |
| train_1/q_loss            | 5.507786447711483     |
| train_1/reward            | -1.5284876738645834   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002294921875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.147728396520838   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 308.77. Rollout time: 84.14, Training time: 224.60
Evaluating epoch 31
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 899722.0              |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -10.233364613528591   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.423397015856126    |
| train_0/fw_bonus          | -0.9994740977883338   |
| train_0/fw_loss           | 0.003721356490859762  |
| train_0/mu_grads          | -0.02726709214039147  |
| train_0/mu_grads_std      | 0.44553755074739454   |
| train_0/mu_loss           | 5.353671997799021     |
| train_0/next_q            | -5.352442218159283    |
| train_0/q_grads           | -0.012125670164823531 |
| train_0/q_grads_std       | 0.3078318201005459    |
| train_0/q_loss            | 0.20110182197731036   |
| train_0/reward            | -0.7051813841906551   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005126953125        |
| train_0/target_q          | -5.655418307628247    |
| train_1/avg_q             | -14.823296067272853   |
| train_1/current_q         | -11.15777127721137    |
| train_1/fw_bonus          | -0.9958641842007637   |
| train_1/fw_loss           | 0.040227696858346464  |
| train_1/mu_grads          | -0.08195533826947213  |
| train_1/mu_grads_std      | 0.37662944942712784   |
| train_1/mu_loss           | 3.7573504679803476    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06328621786087751  |
| train_1/q_grads_std       | 0.40661735758185386   |
| train_1/q_loss            | 5.277612188396189     |
| train_1/reward            | -1.5017162742828076   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.127058071157814   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 285.42. Rollout time: 78.67, Training time: 206.71
Evaluating epoch 32
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
--------------------------------------------------------
| epoch                     | 32                       |
| policy/steps              | 927847.0                 |
| test/episodes             | 825.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -15.0                    |
| test_1/avg_q              | -9.832350699764011e-08   |
| test_1/n_subgoals         | 375.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3300.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -15.0                    |
| train_0/current_q         | -5.4404666696838335      |
| train_0/fw_bonus          | -0.9993555665016174      |
| train_0/fw_loss           | 0.004281040467321873     |
| train_0/mu_grads          | -0.027035980997607113    |
| train_0/mu_grads_std      | 0.4484054870903492       |
| train_0/mu_loss           | 5.3730753380933          |
| train_0/next_q            | -5.370265972111664       |
| train_0/q_grads           | -0.013233939744532108    |
| train_0/q_grads_std       | 0.3123114451766014       |
| train_0/q_loss            | 0.20115804015956287      |
| train_0/reward            | -0.706440474842384       |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.0050048828125          |
| train_0/target_q          | -5.674364220638658       |
| train_1/avg_q             | -8.036630187599002       |
| train_1/current_q         | -2.6719674638695283e-05  |
| train_1/fw_bonus          | -0.9946676716208458      |
| train_1/fw_loss           | 0.04630345245823264      |
| train_1/mu_grads          | -0.08316243626177311     |
| train_1/mu_grads_std      | 0.3777020961046219       |
| train_1/mu_loss           | 3.86303717242693e-08     |
| train_1/n_subgoals        | 1500.0                   |
| train_1/next_q            | -2.3517050369392224e-120 |
| train_1/q_grads           | -0.06662705447524786     |
| train_1/q_grads_std       | 0.4106363669037819       |
| train_1/q_loss            | 6.629172756272473        |
| train_1/reward            | -1.5206858886311239      |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.0022216796875          |
| train_1/reward_-15.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -1.5206858886311239      |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 287.08. Rollout time: 78.11, Training time: 208.94
Evaluating epoch 33
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 955972.0              |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.96831959165314    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.437013815114314    |
| train_0/fw_bonus          | -0.99931570738554     |
| train_0/fw_loss           | 0.004469149257056415  |
| train_0/mu_grads          | -0.02739271759055555  |
| train_0/mu_grads_std      | 0.451022157818079     |
| train_0/mu_loss           | 5.369677141381409     |
| train_0/next_q            | -5.367576236898904    |
| train_0/q_grads           | -0.014856917667202652 |
| train_0/q_grads_std       | 0.3180405214428902    |
| train_0/q_loss            | 0.20317492204081994   |
| train_0/reward            | -0.7055050273876986   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00478515625         |
| train_0/target_q          | -5.669513309357132    |
| train_1/avg_q             | -1.2124421250713486   |
| train_1/current_q         | -11.388082822898658   |
| train_1/fw_bonus          | -0.9931959435343742   |
| train_1/fw_loss           | 0.0537767481058836    |
| train_1/mu_grads          | -0.083089211396873    |
| train_1/mu_grads_std      | 0.3777965731918812    |
| train_1/mu_loss           | 5.379949692646352     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06831336114555597  |
| train_1/q_grads_std       | 0.4123793989419937    |
| train_1/q_loss            | 6.227041254368844     |
| train_1/reward            | -1.5041297092073365   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0025146484375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.309632638894842   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 276.63. Rollout time: 72.42, Training time: 204.18
Evaluating epoch 34
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
--------------------------------------------------------
| epoch                     | 34                       |
| policy/steps              | 984097.0                 |
| test/episodes             | 875.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -15.0                    |
| test_1/avg_q              | -0.9951237632261491      |
| test_1/n_subgoals         | 375.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3500.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -15.0                    |
| train_0/current_q         | -5.447725644343054       |
| train_0/fw_bonus          | -0.9992516070604325      |
| train_0/fw_loss           | 0.004771856917068362     |
| train_0/mu_grads          | -0.028841600893065332    |
| train_0/mu_grads_std      | 0.4544214092195034       |
| train_0/mu_loss           | 5.380507425779347        |
| train_0/next_q            | -5.377653830745255       |
| train_0/q_grads           | -0.015913780219852923    |
| train_0/q_grads_std       | 0.32339737340807917      |
| train_0/q_loss            | 0.20498245370573587      |
| train_0/reward            | -0.7061199441151984      |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.0044921875             |
| train_0/target_q          | -5.6815161457336645      |
| train_1/avg_q             | -13.545748955206196      |
| train_1/current_q         | -0.12454782646347033     |
| train_1/fw_bonus          | -0.9922117456793785      |
| train_1/fw_loss           | 0.058774369210004805     |
| train_1/mu_grads          | -0.0838308634236455      |
| train_1/mu_grads_std      | 0.38109807670116425      |
| train_1/mu_loss           | 0.08782847627826278      |
| train_1/n_subgoals        | 1500.0                   |
| train_1/next_q            | -4.9087761509521225e-115 |
| train_1/q_grads           | -0.06809149775654078     |
| train_1/q_grads_std       | 0.4187765777111053       |
| train_1/q_loss            | 6.092036440235813        |
| train_1/reward            | -1.4855101711000316      |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.0019775390625          |
| train_1/reward_-15.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -1.4855101711000316      |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 268.56. Rollout time: 71.71, Training time: 196.83
Evaluating epoch 35
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 1012222.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.09964919248298    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.456240231102514    |
| train_0/fw_bonus          | -0.9992118999361992   |
| train_0/fw_loss           | 0.004959282779600472  |
| train_0/mu_grads          | -0.028806697716936468 |
| train_0/mu_grads_std      | 0.4573623985052109    |
| train_0/mu_loss           | 5.393174458791593     |
| train_0/next_q            | -5.3912954226082475   |
| train_0/q_grads           | -0.01878448105417192  |
| train_0/q_grads_std       | 0.32895833998918533   |
| train_0/q_loss            | 0.20428190300586313   |
| train_0/reward            | -0.7055629867551033   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0043212890625       |
| train_0/target_q          | -5.691040519311252    |
| train_1/avg_q             | -6.817153318311014    |
| train_1/current_q         | -11.075751654918019   |
| train_1/fw_bonus          | -0.9922346845269203   |
| train_1/fw_loss           | 0.05865786578506231   |
| train_1/mu_grads          | -0.08254289329051971  |
| train_1/mu_grads_std      | 0.3841025583446026    |
| train_1/mu_loss           | 6.747209275929597     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -14.999999999997675   |
| train_1/q_grads           | -0.06821109615266323  |
| train_1/q_grads_std       | 0.42299851551651957   |
| train_1/q_loss            | 9.791538610523697     |
| train_1/reward            | -1.5105216421259684   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0026611328125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.216612950719625   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 268.41. Rollout time: 67.50, Training time: 200.89
Evaluating epoch 36
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-------------------------------------------------------
| epoch                     | 36                      |
| policy/steps              | 1040347.0               |
| test/episodes             | 925.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -7.562053520491156e-17  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.420248471755716      |
| train_0/fw_bonus          | -0.9992772594094277     |
| train_0/fw_loss           | 0.004650719894561917    |
| train_0/mu_grads          | -0.028875005105510353   |
| train_0/mu_grads_std      | 0.4609812296926975      |
| train_0/mu_loss           | 5.353868139450587       |
| train_0/next_q            | -5.352019184372377      |
| train_0/q_grads           | -0.01881113415583968    |
| train_0/q_grads_std       | 0.33420163840055467     |
| train_0/q_loss            | 0.2052098644340526      |
| train_0/reward            | -0.705876424445887      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0040283203125         |
| train_0/target_q          | -5.652469579188923      |
| train_1/avg_q             | -10.575032815253499     |
| train_1/current_q         | -3.0094677623487544e-05 |
| train_1/fw_bonus          | -0.9923431575298309     |
| train_1/fw_loss           | 0.05810706475749612     |
| train_1/mu_grads          | -0.08327221125364304    |
| train_1/mu_grads_std      | 0.38471493124961853     |
| train_1/mu_loss           | 6.383457681884719e-11   |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -4.696434685893379e-166 |
| train_1/q_grads           | -0.06946986559778452    |
| train_1/q_grads_std       | 0.426315101981163       |
| train_1/q_loss            | 6.505602505073493       |
| train_1/reward            | -1.5069137684316956     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00244140625           |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5069137684316956     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 303.95. Rollout time: 74.36, Training time: 229.57
Evaluating epoch 37
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
--------------------------------------------------------
| epoch                     | 37                       |
| policy/steps              | 1068472.0                |
| test/episodes             | 950.0                    |
| test/success_rate         | 0.0                      |
| test_0/avg_q              | -15.0                    |
| test_1/avg_q              | -7.518249924099513e-14   |
| test_1/n_subgoals         | 375.0                    |
| test_1/subgoal_succ_rate  | 0.0                      |
| train/episodes            | 3800.0                   |
| train/success_rate        | 0.0                      |
| train_0/avg_q             | -15.0                    |
| train_0/current_q         | -5.509279357323116       |
| train_0/fw_bonus          | -0.9992974191904068      |
| train_0/fw_loss           | 0.004555535351391882     |
| train_0/mu_grads          | -0.028775272751227023    |
| train_0/mu_grads_std      | 0.4629565715789795       |
| train_0/mu_loss           | 5.440820560363111        |
| train_0/next_q            | -5.438161710790861       |
| train_0/q_grads           | -0.01975632980465889     |
| train_0/q_grads_std       | 0.33942713513970374      |
| train_0/q_loss            | 0.20791351163835986      |
| train_0/reward            | -0.7101955862257455      |
| train_0/reward_-0.0_frac  | 0.0                      |
| train_0/reward_-1.0_frac  | 0.004248046875           |
| train_0/target_q          | -5.746411329712885       |
| train_1/avg_q             | -2.866509588461499e-10   |
| train_1/current_q         | -8.606200466310993e-06   |
| train_1/fw_bonus          | -0.9923847302794456      |
| train_1/fw_loss           | 0.05789591148495674      |
| train_1/mu_grads          | -0.08327221125364304     |
| train_1/mu_grads_std      | 0.38471493124961853      |
| train_1/mu_loss           | 3.8362621488671434e-11   |
| train_1/n_subgoals        | 1500.0                   |
| train_1/next_q            | -1.2091692374577548e-165 |
| train_1/q_grads           | -0.06944456156343222     |
| train_1/q_grads_std       | 0.426333399862051        |
| train_1/q_loss            | 6.337059915796077        |
| train_1/reward            | -1.4900644418303273      |
| train_1/reward_-0.0_frac  | 0.0                      |
| train_1/reward_-1.0_frac  | 0.002392578125           |
| train_1/reward_-15.0_frac | 0.0                      |
| train_1/subgoal_succ_rate | 0.0                      |
| train_1/target_q          | -1.4900644418303273      |
--------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 292.97. Rollout time: 71.88, Training time: 221.06
Evaluating epoch 38
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-------------------------------------------------------
| epoch                     | 38                      |
| policy/steps              | 1096597.0               |
| test/episodes             | 975.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -1.836752286511844e-13  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.463743512259215      |
| train_0/fw_bonus          | -0.9993361979722977     |
| train_0/fw_loss           | 0.004372457746649161    |
| train_0/mu_grads          | -0.028145534778013827   |
| train_0/mu_grads_std      | 0.465220020711422       |
| train_0/mu_loss           | 5.3946264007895         |
| train_0/next_q            | -5.391204956720949      |
| train_0/q_grads           | -0.020068378234282137   |
| train_0/q_grads_std       | 0.3442001387476921      |
| train_0/q_loss            | 0.20903344687543327     |
| train_0/reward            | -0.7095191729211365     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.004248046875          |
| train_0/target_q          | -5.695971699297578      |
| train_1/avg_q             | -5.9269991721344545e-09 |
| train_1/current_q         | -0.07375047355773315    |
| train_1/fw_bonus          | -0.9930186286568642     |
| train_1/fw_loss           | 0.054677131585776806    |
| train_1/mu_grads          | -0.08327219281345606    |
| train_1/mu_grads_std      | 0.38471493124961853     |
| train_1/mu_loss           | 1.5562380586308182e-08  |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -2.658223765366914e-90  |
| train_1/q_grads           | -0.06885962411761284    |
| train_1/q_grads_std       | 0.4255668357014656      |
| train_1/q_loss            | 6.278257155070756       |
| train_1/reward            | -1.4924077510622737     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00205078125           |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4924077510622737     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 274.11. Rollout time: 72.11, Training time: 201.97
Evaluating epoch 39
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 39                   |
| policy/steps              | 1124722.0            |
| test/episodes             | 1000.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -15.0                |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 4000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.454440130889582   |
| train_0/fw_bonus          | -0.9993788942694664  |
| train_0/fw_loss           | 0.004170884721679613 |
| train_0/mu_grads          | -0.02824667850509286 |
| train_0/mu_grads_std      | 0.4679191894829273   |
| train_0/mu_loss           | 5.381558071371864    |
| train_0/next_q            | -5.379967720015981   |
| train_0/q_grads           | -0.0207386395893991  |
| train_0/q_grads_std       | 0.3491474732756615   |
| train_0/q_loss            | 0.20943930026595092  |
| train_0/reward            | -0.7095893472112949  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0046630859375      |
| train_0/target_q          | -5.686507261208304   |
| train_1/avg_q             | -7.363683496301306   |
| train_1/current_q         | -11.363948511573948  |
| train_1/fw_bonus          | -0.993586978316307   |
| train_1/fw_loss           | 0.051791089680045845 |
| train_1/mu_grads          | -0.08378618489950895 |
| train_1/mu_grads_std      | 0.3855291798710823   |
| train_1/mu_loss           | 12.833037461520608   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.06813670471310615 |
| train_1/q_grads_std       | 0.4292720675468445   |
| train_1/q_loss            | 5.4075176530059865   |
| train_1/reward            | -1.5027627290532108  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00185546875        |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.332311068896967  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 282.12. Rollout time: 74.53, Training time: 207.56
Evaluating epoch 40
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 1152847.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.991904075193192   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.396052543725932    |
| train_0/fw_bonus          | -0.999377653002739    |
| train_0/fw_loss           | 0.0041766948066651825 |
| train_0/mu_grads          | -0.027417843323200942 |
| train_0/mu_grads_std      | 0.4708330772817135    |
| train_0/mu_loss           | 5.321201546649743     |
| train_0/next_q            | -5.3196677855850165   |
| train_0/q_grads           | -0.021092080837115647 |
| train_0/q_grads_std       | 0.3541699141263962    |
| train_0/q_loss            | 0.20775665297000181   |
| train_0/reward            | -0.7090638295863755   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0037109375          |
| train_0/target_q          | -5.627624899767439    |
| train_1/avg_q             | -14.995871025554967   |
| train_1/current_q         | -11.38197557331137    |
| train_1/fw_bonus          | -0.9936315685510635   |
| train_1/fw_loss           | 0.05156469596549869   |
| train_1/mu_grads          | -0.08420941308140754  |
| train_1/mu_grads_std      | 0.38581534326076505   |
| train_1/mu_loss           | 13.01171221108529     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06850678380578756  |
| train_1/q_grads_std       | 0.43513059690594674   |
| train_1/q_loss            | 5.295204453656959     |
| train_1/reward            | -1.4837176393593836   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.371764514359388   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 275.42. Rollout time: 75.03, Training time: 200.36
Evaluating epoch 41
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 1180972.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.212869022134885   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.460126430902902    |
| train_0/fw_bonus          | -0.9993762120604515   |
| train_0/fw_loss           | 0.004183527559507638  |
| train_0/mu_grads          | -0.027398703852668405 |
| train_0/mu_grads_std      | 0.4731383197009563    |
| train_0/mu_loss           | 5.389900058132649     |
| train_0/next_q            | -5.387110373225422    |
| train_0/q_grads           | -0.021715859370306134 |
| train_0/q_grads_std       | 0.3583017036318779    |
| train_0/q_loss            | 0.20773837121847832   |
| train_0/reward            | -0.7099542190837382   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004736328125        |
| train_0/target_q          | -5.695078219689549    |
| train_1/avg_q             | -14.999999999077566   |
| train_1/current_q         | -11.394845763502811   |
| train_1/fw_bonus          | -0.9935981258749962   |
| train_1/fw_loss           | 0.05173451937735081   |
| train_1/mu_grads          | -0.08440177794545889  |
| train_1/mu_grads_std      | 0.38682437762618066   |
| train_1/mu_loss           | 12.770052413970905    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06931353006511927  |
| train_1/q_grads_std       | 0.4426825106143951    |
| train_1/q_loss            | 5.294009311766108     |
| train_1/reward            | -1.5074924207045115   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002392578125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.357497303517018   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 222.40. Rollout time: 63.58, Training time: 158.79
Evaluating epoch 42
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 42                    |
| policy/steps              | 1209097.0             |
| test/episodes             | 1075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.481032121571983   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.398599175587371    |
| train_0/fw_bonus          | -0.9993074998259545   |
| train_0/fw_loss           | 0.004507971077691764  |
| train_0/mu_grads          | -0.028998090280219914 |
| train_0/mu_grads_std      | 0.4752732150256634    |
| train_0/mu_loss           | 5.321276097830625     |
| train_0/next_q            | -5.319082810586257    |
| train_0/q_grads           | -0.02325026779435575  |
| train_0/q_grads_std       | 0.3611236535012722    |
| train_0/q_loss            | 0.20666358046523525   |
| train_0/reward            | -0.7102616583630151   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0042236328125       |
| train_0/target_q          | -5.627269401414315    |
| train_1/avg_q             | -14.999923868250244   |
| train_1/current_q         | -11.449674487749238   |
| train_1/fw_bonus          | -0.9929932519793511   |
| train_1/fw_loss           | 0.054805984068661925  |
| train_1/mu_grads          | -0.08449523244053125  |
| train_1/mu_grads_std      | 0.3880440391600132    |
| train_1/mu_loss           | 12.857576638228498    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06834355797618627  |
| train_1/q_grads_std       | 0.4509825468063354    |
| train_1/q_loss            | 5.218112086737756     |
| train_1/reward            | -1.494043012025213    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00234375            |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.425874066712717   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 230.92. Rollout time: 64.02, Training time: 166.87
Evaluating epoch 43
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 43                    |
| policy/steps              | 1237222.0             |
| test/episodes             | 1100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.99999675857558    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.430415866322386    |
| train_0/fw_bonus          | -0.9993098452687263   |
| train_0/fw_loss           | 0.004496822226792574  |
| train_0/mu_grads          | -0.029764290060848    |
| train_0/mu_grads_std      | 0.4782536670565605    |
| train_0/mu_loss           | 5.353708147204427     |
| train_0/next_q            | -5.35150237087804     |
| train_0/q_grads           | -0.025047126645222306 |
| train_0/q_grads_std       | 0.36579857394099236   |
| train_0/q_loss            | 0.20966962345783052   |
| train_0/reward            | -0.7105680147491512   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004541015625        |
| train_0/target_q          | -5.661196889414644    |
| train_1/avg_q             | -14.98273355586611    |
| train_1/current_q         | -11.477999762372942   |
| train_1/fw_bonus          | -0.9924902275204659   |
| train_1/fw_loss           | 0.05736026838421822   |
| train_1/mu_grads          | -0.08551877271384001  |
| train_1/mu_grads_std      | 0.3889076568186283    |
| train_1/mu_loss           | 10.420655822219537    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.06977698132395745  |
| train_1/q_grads_std       | 0.45739075616002084   |
| train_1/q_loss            | 5.160403410046348     |
| train_1/reward            | -1.499638669880369    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0029052734375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.441877439411623   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 220.42. Rollout time: 63.10, Training time: 157.29
Evaluating epoch 44
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 1265347.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.99999970323041    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.390357372126407    |
| train_0/fw_bonus          | -0.9992905259132385   |
| train_0/fw_loss           | 0.004588059848174453  |
| train_0/mu_grads          | -0.030603252770379185 |
| train_0/mu_grads_std      | 0.48066750913858414   |
| train_0/mu_loss           | 5.3169637694188525    |
| train_0/next_q            | -5.31547493208096     |
| train_0/q_grads           | -0.026522549660876395 |
| train_0/q_grads_std       | 0.37047033160924914   |
| train_0/q_loss            | 0.21227361589311938   |
| train_0/reward            | -0.7085808140160225   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00517578125         |
| train_0/target_q          | -5.619548758936697    |
| train_1/avg_q             | -14.989847432917784   |
| train_1/current_q         | -11.426502170883264   |
| train_1/fw_bonus          | -0.992466127872467    |
| train_1/fw_loss           | 0.057482715137302874  |
| train_1/mu_grads          | -0.0859531369060278   |
| train_1/mu_grads_std      | 0.38979090079665185   |
| train_1/mu_loss           | 7.767750639256491     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.07114787623286248  |
| train_1/q_grads_std       | 0.4651258043944836    |
| train_1/q_loss            | 5.6922929394399135    |
| train_1/reward            | -1.5188771007386095   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00263671875         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.370317530426114   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 225.12. Rollout time: 63.82, Training time: 161.27
Evaluating epoch 45
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 1293472.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.999999998543679   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.355912095452377    |
| train_0/fw_bonus          | -0.999316257238388    |
| train_0/fw_loss           | 0.004466608841903507  |
| train_0/mu_grads          | -0.030273802252486347 |
| train_0/mu_grads_std      | 0.4838765226304531    |
| train_0/mu_loss           | 5.280938819113528     |
| train_0/next_q            | -5.2802548722550995   |
| train_0/q_grads           | -0.027133088419213892 |
| train_0/q_grads_std       | 0.37533314526081085   |
| train_0/q_loss            | 0.21142587125347223   |
| train_0/reward            | -0.7072264876362169   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00419921875         |
| train_0/target_q          | -5.583355141033209    |
| train_1/avg_q             | -14.999999975234779   |
| train_1/current_q         | -11.311921182154922   |
| train_1/fw_bonus          | -0.9919456750154495   |
| train_1/fw_loss           | 0.06012541651725769   |
| train_1/mu_grads          | -0.08647584412246942  |
| train_1/mu_grads_std      | 0.39064098447561263   |
| train_1/mu_loss           | 7.986555985189563     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.07236056681722403  |
| train_1/q_grads_std       | 0.4731825217604637    |
| train_1/q_loss            | 5.304366995207829     |
| train_1/reward            | -1.495423524659418    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002294921875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.284058778565674   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 226.25. Rollout time: 63.48, Training time: 162.74
Evaluating epoch 46
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 1321597.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.936801583647345   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.436987802531695    |
| train_0/fw_bonus          | -0.9993130221962929   |
| train_0/fw_loss           | 0.004481891635805368  |
| train_0/mu_grads          | -0.030310606537386774 |
| train_0/mu_grads_std      | 0.48548350036144255   |
| train_0/mu_loss           | 5.367487403387438     |
| train_0/next_q            | -5.364990824490502    |
| train_0/q_grads           | -0.027832572301849722 |
| train_0/q_grads_std       | 0.37893242165446284   |
| train_0/q_loss            | 0.20844151855261267   |
| train_0/reward            | -0.7082746738713468   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004296875           |
| train_0/target_q          | -5.669763061631242    |
| train_1/avg_q             | -14.999999575290609   |
| train_1/current_q         | -11.21553907417828    |
| train_1/fw_bonus          | -0.992529259622097    |
| train_1/fw_loss           | 0.05716212298721075   |
| train_1/mu_grads          | -0.08707911130040884  |
| train_1/mu_grads_std      | 0.390924210101366     |
| train_1/mu_loss           | 7.946253694883457     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.07360447775572539  |
| train_1/q_grads_std       | 0.4800455875694752    |
| train_1/q_loss            | 5.367311637460722     |
| train_1/reward            | -1.5117431413309532   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0024169921875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.168666969455959   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 226.89. Rollout time: 63.53, Training time: 163.33
Evaluating epoch 47
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 1349722.0             |
| test/episodes             | 1200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.317341577320917   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.478846502397189    |
| train_0/fw_bonus          | -0.9993651911616326   |
| train_0/fw_loss           | 0.004235538432840258  |
| train_0/mu_grads          | -0.032143644895404576 |
| train_0/mu_grads_std      | 0.487219013273716     |
| train_0/mu_loss           | 5.412593053644265     |
| train_0/next_q            | -5.411344580697362    |
| train_0/q_grads           | -0.028928708797320724 |
| train_0/q_grads_std       | 0.3817025326192379    |
| train_0/q_loss            | 0.2121642524397256    |
| train_0/reward            | -0.707775859911635    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0043701171875       |
| train_0/target_q          | -5.714435754405668    |
| train_1/avg_q             | -14.999999991114674   |
| train_1/current_q         | -11.139354157764286   |
| train_1/fw_bonus          | -0.9929789021611214   |
| train_1/fw_loss           | 0.054878887720406055  |
| train_1/mu_grads          | -0.08748011961579323  |
| train_1/mu_grads_std      | 0.3920458346605301    |
| train_1/mu_loss           | 7.856371674396842     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.07426561955362558  |
| train_1/q_grads_std       | 0.48713714331388475   |
| train_1/q_loss            | 5.522151066509335     |
| train_1/reward            | -1.5096364200006065   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021240234375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.092629584063111   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 234.66. Rollout time: 64.15, Training time: 170.48
Evaluating epoch 48
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 1377847.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.761652147922195   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.439528494650444    |
| train_0/fw_bonus          | -0.9993828698992729   |
| train_0/fw_loss           | 0.0041521104809362445 |
| train_0/mu_grads          | -0.03241993263363838  |
| train_0/mu_grads_std      | 0.4893408440053463    |
| train_0/mu_loss           | 5.3713975634807305    |
| train_0/next_q            | -5.369293173883532    |
| train_0/q_grads           | -0.029644650965929033 |
| train_0/q_grads_std       | 0.38440479189157484   |
| train_0/q_loss            | 0.20568345899449586   |
| train_0/reward            | -0.7060146750991407   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0043212890625       |
| train_0/target_q          | -5.671532994622338    |
| train_1/avg_q             | -14.919610071208657   |
| train_1/current_q         | -11.085568253745484   |
| train_1/fw_bonus          | -0.993075481057167    |
| train_1/fw_loss           | 0.054388425685465334  |
| train_1/mu_grads          | -0.08782491330057382  |
| train_1/mu_grads_std      | 0.3931771442294121    |
| train_1/mu_loss           | 6.875995699490387     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.07535708304494619  |
| train_1/q_grads_std       | 0.49315042346715926   |
| train_1/q_loss            | 5.5301803533540275    |
| train_1/reward            | -1.4941451626014897   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022705078125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.050939596195246   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 228.66. Rollout time: 63.63, Training time: 165.00
Evaluating epoch 49
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 49                   |
| policy/steps              | 1405972.0            |
| test/episodes             | 1250.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -13.12063061921663   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.455825609813621   |
| train_0/fw_bonus          | -0.9993520930409432  |
| train_0/fw_loss           | 0.004297417489578947 |
| train_0/mu_grads          | -0.0330632078461349  |
| train_0/mu_grads_std      | 0.49235622957348824  |
| train_0/mu_loss           | 5.390494084801459    |
| train_0/next_q            | -5.386976017889967   |
| train_0/q_grads           | -0.03035307489335537 |
| train_0/q_grads_std       | 0.38806159496307374  |
| train_0/q_loss            | 0.20450498492765984  |
| train_0/reward            | -0.7062190139011364  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.003662109375       |
| train_0/target_q          | -5.690523516422876   |
| train_1/avg_q             | -14.818206813649448  |
| train_1/current_q         | -11.103420465338438  |
| train_1/fw_bonus          | -0.9930202826857567  |
| train_1/fw_loss           | 0.054668722581118344 |
| train_1/mu_grads          | -0.08829892724752426 |
| train_1/mu_grads_std      | 0.3949581332504749   |
| train_1/mu_loss           | 6.756271293732733    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.07709598615765571 |
| train_1/q_grads_std       | 0.4987532258033752   |
| train_1/q_loss            | 5.654562652492659    |
| train_1/reward            | -1.5009779150750546  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0023193359375      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.07105115726256   |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 236.43. Rollout time: 64.32, Training time: 172.09
Evaluating epoch 50
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 50                   |
| policy/steps              | 1434097.0            |
| test/episodes             | 1275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -9.984688540751053   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.4608266226142685  |
| train_0/fw_bonus          | -0.9993855506181717  |
| train_0/fw_loss           | 0.004139440925791859 |
| train_0/mu_grads          | -0.0338021737523377  |
| train_0/mu_grads_std      | 0.49642736837267876  |
| train_0/mu_loss           | 5.389939606373919    |
| train_0/next_q            | -5.386290111688282   |
| train_0/q_grads           | -0.03181664180010557 |
| train_0/q_grads_std       | 0.3917467422783375   |
| train_0/q_loss            | 0.20198190604120062  |
| train_0/reward            | -0.7082132823452412  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.003857421875       |
| train_0/target_q          | -5.696515257441672   |
| train_1/avg_q             | -14.701721234033371  |
| train_1/current_q         | -11.19746545033603   |
| train_1/fw_bonus          | -0.9927227780222893  |
| train_1/fw_loss           | 0.05617942782118916  |
| train_1/mu_grads          | -0.08900652769953013 |
| train_1/mu_grads_std      | 0.39901914075016975  |
| train_1/mu_loss           | 3.9624285066804226   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.078013632632792   |
| train_1/q_grads_std       | 0.504800021648407    |
| train_1/q_loss            | 5.7301418727380975   |
| train_1/reward            | -1.5224844350210334  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0027587890625      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.137059630333537  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_50.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 228.23. Rollout time: 63.36, Training time: 164.84
Evaluating epoch 51
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 51                   |
| policy/steps              | 1462222.0            |
| test/episodes             | 1300.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -4.529897465544291   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5200.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.451155955760859   |
| train_0/fw_bonus          | -0.9993464350700378  |
| train_0/fw_loss           | 0.004324099939549342 |
| train_0/mu_grads          | -0.03359336704015732 |
| train_0/mu_grads_std      | 0.5001109629869461   |
| train_0/mu_loss           | 5.378639892482779    |
| train_0/next_q            | -5.377357398269291   |
| train_0/q_grads           | -0.03384762471541762 |
| train_0/q_grads_std       | 0.39519905894994733  |
| train_0/q_loss            | 0.20642602689282247  |
| train_0/reward            | -0.7085843525499513  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00400390625        |
| train_0/target_q          | -5.686115214658107   |
| train_1/avg_q             | -13.074131212403435  |
| train_1/current_q         | -10.744514227154713  |
| train_1/fw_bonus          | -0.9924932196736336  |
| train_1/fw_loss           | 0.057345078140497205 |
| train_1/mu_grads          | -0.09023694545030594 |
| train_1/mu_grads_std      | 0.40200807377696035  |
| train_1/mu_loss           | 1.538498868078575    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -14.999999999995202  |
| train_1/q_grads           | -0.08361853696405888 |
| train_1/q_grads_std       | 0.507815831899643    |
| train_1/q_loss            | 2.1289427407218056   |
| train_1/reward            | -1.5052676071769384  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00185546875        |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.214588896238634  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 247.56. Rollout time: 63.23, Training time: 184.30
Evaluating epoch 52
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-------------------------------------------------------
| epoch                     | 52                      |
| policy/steps              | 1490347.0               |
| test/episodes             | 1325.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -2.1254270626979633e-06 |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.50967216433286       |
| train_0/fw_bonus          | -0.9993578791618347     |
| train_0/fw_loss           | 0.004270070529310032    |
| train_0/mu_grads          | -0.03365012668073177    |
| train_0/mu_grads_std      | 0.5029052034020424      |
| train_0/mu_loss           | 5.441378351528757       |
| train_0/next_q            | -5.4385823239323505     |
| train_0/q_grads           | -0.03485410949215293    |
| train_0/q_grads_std       | 0.39845043122768403     |
| train_0/q_loss            | 0.20717493076720372     |
| train_0/reward            | -0.7097009140306909     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0036376953125         |
| train_0/target_q          | -5.746911100937604      |
| train_1/avg_q             | -3.4508324934358936     |
| train_1/current_q         | -0.007228366465332162   |
| train_1/fw_bonus          | -0.9917295575141907     |
| train_1/fw_loss           | 0.061222811415791514    |
| train_1/mu_grads          | -0.09062500521540642    |
| train_1/mu_grads_std      | 0.4027917221188545      |
| train_1/mu_loss           | 5.684210258025431e-07   |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -8.710345798861872e-39  |
| train_1/q_grads           | -0.08844267036765814    |
| train_1/q_grads_std       | 0.5070455610752106      |
| train_1/q_loss            | 6.561611962200223       |
| train_1/reward            | -1.5131865618961455     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0017578125            |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5131865618961455     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 237.10. Rollout time: 63.57, Training time: 173.51
Evaluating epoch 53
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-------------------------------------------------------
| epoch                     | 53                      |
| policy/steps              | 1518472.0               |
| test/episodes             | 1350.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -7.334801484719357e-05  |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.477813818511237      |
| train_0/fw_bonus          | -0.9994156643748283     |
| train_0/fw_loss           | 0.003997251723194495    |
| train_0/mu_grads          | -0.036483917478471996   |
| train_0/mu_grads_std      | 0.5062307447195054      |
| train_0/mu_loss           | 5.407660645433937       |
| train_0/next_q            | -5.4058232132380155     |
| train_0/q_grads           | -0.03587118526920676    |
| train_0/q_grads_std       | 0.40205481126904485     |
| train_0/q_loss            | 0.20888771094329694     |
| train_0/reward            | -0.7093391793910996     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0031982421875         |
| train_0/target_q          | -5.712426568539857      |
| train_1/avg_q             | -4.168055011553548      |
| train_1/current_q         | -0.5712324587767589     |
| train_1/fw_bonus          | -0.9923776552081108     |
| train_1/fw_loss           | 0.05793190542608499     |
| train_1/mu_grads          | -0.08927388694137335    |
| train_1/mu_grads_std      | 0.4080295510590076      |
| train_1/mu_loss           | 0.009185214571940183    |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -1.3465415843344128e-29 |
| train_1/q_grads           | -0.09722731653600931    |
| train_1/q_grads_std       | 0.5048549100756645      |
| train_1/q_loss            | 2.2002514337122414      |
| train_1/reward            | -1.5349095313402359     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0019287109375         |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5349095313402359     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 227.94. Rollout time: 63.65, Training time: 164.26
Evaluating epoch 54
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 1546597.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -3.9426349462098464   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.462208333223979    |
| train_0/fw_bonus          | -0.9994570016860962   |
| train_0/fw_loss           | 0.003802049270598218  |
| train_0/mu_grads          | -0.036704471241682766 |
| train_0/mu_grads_std      | 0.5089353412389755    |
| train_0/mu_loss           | 5.386123068327941     |
| train_0/next_q            | -5.383351134440085    |
| train_0/q_grads           | -0.03648152612149715  |
| train_0/q_grads_std       | 0.4049201689660549    |
| train_0/q_loss            | 0.2059628844197685    |
| train_0/reward            | -0.7103608277000604   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049072265625       |
| train_0/target_q          | -5.697280446727484    |
| train_1/avg_q             | -3.9037672244333494   |
| train_1/current_q         | -1.4021574727185393   |
| train_1/fw_bonus          | -0.9928114518523217   |
| train_1/fw_loss           | 0.0557291392236948    |
| train_1/mu_grads          | -0.08809200134128332  |
| train_1/mu_grads_std      | 0.4076653398573399    |
| train_1/mu_loss           | 1.8189331672835114    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -0.006914516546491048 |
| train_1/q_grads           | -0.0996977586299181   |
| train_1/q_grads_std       | 0.5046204969286918    |
| train_1/q_loss            | 0.20403439525580733   |
| train_1/reward            | -1.5100287725843373   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021240234375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.515165256715937    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 233.61. Rollout time: 63.95, Training time: 169.63
Evaluating epoch 55
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 1574722.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -15.0                  |
| test_1/avg_q              | -2.8430581468402405    |
| test_1/n_subgoals         | 375.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -15.0                  |
| train_0/current_q         | -5.464893038561846     |
| train_0/fw_bonus          | -0.9994465276598931    |
| train_0/fw_loss           | 0.003851526090875268   |
| train_0/mu_grads          | -0.036220569908618924  |
| train_0/mu_grads_std      | 0.5124218955636024     |
| train_0/mu_loss           | 5.392488544876853      |
| train_0/next_q            | -5.389806347993926     |
| train_0/q_grads           | -0.03723749509081244   |
| train_0/q_grads_std       | 0.40895129814743997    |
| train_0/q_loss            | 0.2031954262676472     |
| train_0/reward            | -0.7075723848858615    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0043701171875        |
| train_0/target_q          | -5.697855359451614     |
| train_1/avg_q             | -5.971209407066776     |
| train_1/current_q         | -1.5149097284442394    |
| train_1/fw_bonus          | -0.9926563650369644    |
| train_1/fw_loss           | 0.056516718585044146   |
| train_1/mu_grads          | -0.08731999807059765   |
| train_1/mu_grads_std      | 0.4069666787981987     |
| train_1/mu_loss           | 1.7541575114805326     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -0.0014462415932957997 |
| train_1/q_grads           | -0.10060834530740977   |
| train_1/q_grads_std       | 0.5049466177821159     |
| train_1/q_loss            | 0.15594122799359175    |
| train_1/reward            | -1.5178857930972298    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0019287109375        |
| train_1/reward_-15.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.519097462072902     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 227.92. Rollout time: 63.83, Training time: 164.07
Evaluating epoch 56
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 1602847.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.999999979590031   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.389316166114494    |
| train_0/fw_bonus          | -0.9995145484805107   |
| train_0/fw_loss           | 0.0035303847515024247 |
| train_0/mu_grads          | -0.03710444681346416  |
| train_0/mu_grads_std      | 0.5145096763968467    |
| train_0/mu_loss           | 5.315884847070761     |
| train_0/next_q            | -5.31250138111607     |
| train_0/q_grads           | -0.03868705239146948  |
| train_0/q_grads_std       | 0.41287618726491926   |
| train_0/q_loss            | 0.201972990505726     |
| train_0/reward            | -0.706019479016686    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004150390625        |
| train_0/target_q          | -5.617621485288645    |
| train_1/avg_q             | -11.959832761479916   |
| train_1/current_q         | -11.042460536091273   |
| train_1/fw_bonus          | -0.9926849186420441   |
| train_1/fw_loss           | 0.05637162942439318   |
| train_1/mu_grads          | -0.08789525274187326  |
| train_1/mu_grads_std      | 0.406817752122879     |
| train_1/mu_loss           | 5.880819028984165     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.1014392277225852   |
| train_1/q_grads_std       | 0.5089619114995003    |
| train_1/q_loss            | 5.7587089718699405    |
| train_1/reward            | -1.5000411928638642   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001416015625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.004438165520117   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 236.19. Rollout time: 63.89, Training time: 172.27
Evaluating epoch 57
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 57                   |
| policy/steps              | 1630972.0            |
| test/episodes             | 1450.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -14.999999991842948  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 5800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.4708991496317525  |
| train_0/fw_bonus          | -0.9995051071047782  |
| train_0/fw_loss           | 0.003574892407050356 |
| train_0/mu_grads          | -0.0371786835603416  |
| train_0/mu_grads_std      | 0.5168431341648102   |
| train_0/mu_loss           | 5.396650393104357    |
| train_0/next_q            | -5.394505428222052   |
| train_0/q_grads           | -0.03863951247185469 |
| train_0/q_grads_std       | 0.4159455381333828   |
| train_0/q_loss            | 0.2060018418618938   |
| train_0/reward            | -0.710055292967445   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0044677734375      |
| train_0/target_q          | -5.705326941071691   |
| train_1/avg_q             | -14.999999972411     |
| train_1/current_q         | -11.259368319670052  |
| train_1/fw_bonus          | -0.9928959339857102  |
| train_1/fw_loss           | 0.055300102289766076 |
| train_1/mu_grads          | -0.08815843146294355 |
| train_1/mu_grads_std      | 0.40676741153001783  |
| train_1/mu_loss           | 5.940004934990836    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.1009261131286621  |
| train_1/q_grads_std       | 0.5131375044584274   |
| train_1/q_loss            | 5.668385235530224    |
| train_1/reward            | -1.5097658431295713  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001513671875       |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.216216038442075  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 233.44. Rollout time: 63.54, Training time: 169.87
Evaluating epoch 58
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 1659097.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.967939497831603   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.476084094031184    |
| train_0/fw_bonus          | -0.9995045751333237   |
| train_0/fw_loss           | 0.0035774258722085506 |
| train_0/mu_grads          | -0.03711140463128686  |
| train_0/mu_grads_std      | 0.519692787528038     |
| train_0/mu_loss           | 5.401242425566824     |
| train_0/next_q            | -5.39755915626734     |
| train_0/q_grads           | -0.03852657955139875  |
| train_0/q_grads_std       | 0.41941472217440606   |
| train_0/q_loss            | 0.20374122318055532   |
| train_0/reward            | -0.7106897902202036   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0047607421875       |
| train_0/target_q          | -5.7097049146558      |
| train_1/avg_q             | -14.999996319581099   |
| train_1/current_q         | -11.31472361300933    |
| train_1/fw_bonus          | -0.9930410400032997   |
| train_1/fw_loss           | 0.0545633751899004    |
| train_1/mu_grads          | -0.08842475898563862  |
| train_1/mu_grads_std      | 0.40685188472270967   |
| train_1/mu_loss           | 5.882554189843837     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.10102292019873857  |
| train_1/q_grads_std       | 0.5169735431671143    |
| train_1/q_loss            | 5.513360864734118     |
| train_1/reward            | -1.51464795525535     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.276366705255354   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 236.45. Rollout time: 63.42, Training time: 173.00
Evaluating epoch 59
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 1687222.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -13.814721119112438   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.461008997217104    |
| train_0/fw_bonus          | -0.999478106200695    |
| train_0/fw_loss           | 0.0037023546814452858 |
| train_0/mu_grads          | -0.03823388470336795  |
| train_0/mu_grads_std      | 0.5217760071158409    |
| train_0/mu_loss           | 5.3876491713889205    |
| train_0/next_q            | -5.385675590616588    |
| train_0/q_grads           | -0.03986566672101617  |
| train_0/q_grads_std       | 0.42313437908887863   |
| train_0/q_loss            | 0.20290403928738004   |
| train_0/reward            | -0.7090896468675055   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005517578125        |
| train_0/target_q          | -5.694877249129827    |
| train_1/avg_q             | -14.990004438178852   |
| train_1/current_q         | -11.396816945175818   |
| train_1/fw_bonus          | -0.9919446811079979   |
| train_1/fw_loss           | 0.06013043951243162   |
| train_1/mu_grads          | -0.08855724930763245  |
| train_1/mu_grads_std      | 0.4075146086513996    |
| train_1/mu_loss           | 5.570357125357688     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09992949720472097  |
| train_1/q_grads_std       | 0.5216397851705551    |
| train_1/q_loss            | 5.198973058696585     |
| train_1/reward            | -1.4925665845199547   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.36410467045746    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 234.00. Rollout time: 62.68, Training time: 171.29
Evaluating epoch 60
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 60                   |
| policy/steps              | 1715347.0            |
| test/episodes             | 1525.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -14.999999999820245  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.486593822895685   |
| train_0/fw_bonus          | -0.999450045824051   |
| train_0/fw_loss           | 0.003834983758861199 |
| train_0/mu_grads          | -0.03897255957126618 |
| train_0/mu_grads_std      | 0.5242615267634392   |
| train_0/mu_loss           | 5.411649360480096    |
| train_0/next_q            | -5.411059765140047   |
| train_0/q_grads           | -0.04128090851008892 |
| train_0/q_grads_std       | 0.42709997817873957  |
| train_0/q_loss            | 0.2058165216974376   |
| train_0/reward            | -0.7097836093285878  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.00576171875        |
| train_0/target_q          | -5.720524563467871   |
| train_1/avg_q             | -14.97989454703284   |
| train_1/current_q         | -11.65820057726726   |
| train_1/fw_bonus          | -0.9912807092070579  |
| train_1/fw_loss           | 0.06350206434726716  |
| train_1/mu_grads          | -0.08873410299420356 |
| train_1/mu_grads_std      | 0.40778194069862367  |
| train_1/mu_loss           | 5.69174543820434     |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09748312141746282 |
| train_1/q_grads_std       | 0.5276401355862618   |
| train_1/q_loss            | 5.188754955872437    |
| train_1/reward            | -1.495774632764369   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001123046875       |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.638272191358126  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_60.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 232.73. Rollout time: 63.16, Training time: 169.55
Evaluating epoch 61
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 1743472.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -13.201005019737101   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.440433010393689    |
| train_0/fw_bonus          | -0.9994031608104705   |
| train_0/fw_loss           | 0.0040563303686212745 |
| train_0/mu_grads          | -0.039315042551606894 |
| train_0/mu_grads_std      | 0.5265375956892967    |
| train_0/mu_loss           | 5.366722450159605     |
| train_0/next_q            | -5.363104618453596    |
| train_0/q_grads           | -0.04198787864297628  |
| train_0/q_grads_std       | 0.43068430870771407   |
| train_0/q_loss            | 0.21184721642441162   |
| train_0/reward            | -0.7095648568654724   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0057861328125       |
| train_0/target_q          | -5.671982557214072    |
| train_1/avg_q             | -14.999999690704806   |
| train_1/current_q         | -11.707993170017911   |
| train_1/fw_bonus          | -0.9902719959616662   |
| train_1/fw_loss           | 0.06862420598044991   |
| train_1/mu_grads          | -0.08863100521266461  |
| train_1/mu_grads_std      | 0.40828791111707685   |
| train_1/mu_loss           | 5.195502909977332     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09709430150687695  |
| train_1/q_grads_std       | 0.5319912135601044    |
| train_1/q_loss            | 5.410093666148204     |
| train_1/reward            | -1.5169255481116124   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.660858653580368   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 240.43. Rollout time: 63.96, Training time: 176.44
Evaluating epoch 62
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 1771597.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.24684004121596    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.46505648475503     |
| train_0/fw_bonus          | -0.9994326233863831   |
| train_0/fw_loss           | 0.0039171897864434865 |
| train_0/mu_grads          | -0.04034417467191816  |
| train_0/mu_grads_std      | 0.5294721275568008    |
| train_0/mu_loss           | 5.385202646484018     |
| train_0/next_q            | -5.381338194154138    |
| train_0/q_grads           | -0.04226282620802522  |
| train_0/q_grads_std       | 0.4347701512277126    |
| train_0/q_loss            | 0.20088215470889761   |
| train_0/reward            | -0.708798341579677    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.006103515625        |
| train_0/target_q          | -5.698198009574542    |
| train_1/avg_q             | -14.970018307341768   |
| train_1/current_q         | -11.516200155158657   |
| train_1/fw_bonus          | -0.9904045358300209   |
| train_1/fw_loss           | 0.0679511371999979    |
| train_1/mu_grads          | -0.08875674419105054  |
| train_1/mu_grads_std      | 0.4087831385433674    |
| train_1/mu_loss           | 4.9265842723027315    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09369325600564479  |
| train_1/q_grads_std       | 0.5375250160694123    |
| train_1/q_loss            | 5.1719076070938454    |
| train_1/reward            | -1.509081666018028    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.479672486330532   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 231.03. Rollout time: 62.65, Training time: 168.35
Evaluating epoch 63
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 63                   |
| policy/steps              | 1799722.0            |
| test/episodes             | 1600.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -4.339288008019083   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.399947422956571   |
| train_0/fw_bonus          | -0.9994283735752105  |
| train_0/fw_loss           | 0.003937212302116677 |
| train_0/mu_grads          | -0.03974732477217913 |
| train_0/mu_grads_std      | 0.5336409360170364   |
| train_0/mu_loss           | 5.314929674388687    |
| train_0/next_q            | -5.311055372008189   |
| train_0/q_grads           | -0.04317478071898222 |
| train_0/q_grads_std       | 0.4384792856872082   |
| train_0/q_loss            | 0.20199491810927533  |
| train_0/reward            | -0.7066966116588447  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.005712890625       |
| train_0/target_q          | -5.631157439052296   |
| train_1/avg_q             | -14.587315016784462  |
| train_1/current_q         | -10.914486623237796  |
| train_1/fw_bonus          | -0.9900592669844628  |
| train_1/fw_loss           | 0.06970445355400443  |
| train_1/mu_grads          | -0.08633451592177152 |
| train_1/mu_grads_std      | 0.4113920494914055   |
| train_1/mu_loss           | 1.8531540365394104   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09277734216302633 |
| train_1/q_grads_std       | 0.5418590575456619   |
| train_1/q_loss            | 2.0292442419779784   |
| train_1/reward            | -1.5061502344018662  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0011962890625      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.363332851589373  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 235.67. Rollout time: 64.25, Training time: 171.39
Evaluating epoch 64
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 64                   |
| policy/steps              | 1827847.0            |
| test/episodes             | 1625.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -7.710879692442495   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6500.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.4702406096551615  |
| train_0/fw_bonus          | -0.9994186237454414  |
| train_0/fw_loss           | 0.003983294067438692 |
| train_0/mu_grads          | -0.03976982990279794 |
| train_0/mu_grads_std      | 0.5360947921872139   |
| train_0/mu_loss           | 5.39003859311658     |
| train_0/next_q            | -5.38829298757027    |
| train_0/q_grads           | -0.04422921920195222 |
| train_0/q_grads_std       | 0.4426030680537224   |
| train_0/q_loss            | 0.2028478491196312   |
| train_0/reward            | -0.707363118709327   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0048583984375      |
| train_0/target_q          | -5.70299730304924    |
| train_1/avg_q             | -8.833708430273091   |
| train_1/current_q         | -10.697805477973711  |
| train_1/fw_bonus          | -0.9900980770587922  |
| train_1/fw_loss           | 0.06950733214616775  |
| train_1/mu_grads          | -0.08671928718686103 |
| train_1/mu_grads_std      | 0.4130298487842083   |
| train_1/mu_loss           | 2.9001971693712667   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09049842003732919 |
| train_1/q_grads_std       | 0.5459167197346687   |
| train_1/q_loss            | 1.2601400706274795   |
| train_1/reward            | -1.5205495275782597  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0013427734375      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.256787320547016  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 233.60. Rollout time: 63.18, Training time: 170.39
Evaluating epoch 65
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 65                   |
| policy/steps              | 1855972.0            |
| test/episodes             | 1650.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -7.2962090635534445  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 6600.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.411263183272775   |
| train_0/fw_bonus          | -0.999421913921833   |
| train_0/fw_loss           | 0.003967739321524277 |
| train_0/mu_grads          | -0.041172862239182   |
| train_0/mu_grads_std      | 0.5398068428039551   |
| train_0/mu_loss           | 5.339985065373682    |
| train_0/next_q            | -5.336304383571359   |
| train_0/q_grads           | -0.04563066391274333 |
| train_0/q_grads_std       | 0.4472001701593399   |
| train_0/q_loss            | 0.202206165682985    |
| train_0/reward            | -0.7051186722739657  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0043212890625      |
| train_0/target_q          | -5.645286680998723   |
| train_1/avg_q             | -8.507899910694482   |
| train_1/current_q         | -10.86788009695621   |
| train_1/fw_bonus          | -0.9890767753124237  |
| train_1/fw_loss           | 0.07469337545335293  |
| train_1/mu_grads          | -0.08670168835669756 |
| train_1/mu_grads_std      | 0.41386386305093764  |
| train_1/mu_loss           | 2.911738185069829    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.0901447495445609  |
| train_1/q_grads_std       | 0.5496216103434562   |
| train_1/q_loss            | 0.8627777987319905   |
| train_1/reward            | -1.512848935022339   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0017578125         |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.430683407678595  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 247.32. Rollout time: 65.90, Training time: 181.40
Evaluating epoch 66
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 1884097.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -5.805096854972615    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.436889585153935    |
| train_0/fw_bonus          | -0.9994322955608368   |
| train_0/fw_loss           | 0.003918683860683813  |
| train_0/mu_grads          | -0.042492084484547374 |
| train_0/mu_grads_std      | 0.5423266381025315    |
| train_0/mu_loss           | 5.371232843901502     |
| train_0/next_q            | -5.368725078801763    |
| train_0/q_grads           | -0.04621932851150632  |
| train_0/q_grads_std       | 0.45219976231455805   |
| train_0/q_loss            | 0.20148007225737857   |
| train_0/reward            | -0.7042937890859321   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046630859375       |
| train_0/target_q          | -5.671185565478118    |
| train_1/avg_q             | -8.251577566979979    |
| train_1/current_q         | -10.882390446059182   |
| train_1/fw_bonus          | -0.9886304035782814   |
| train_1/fw_loss           | 0.07695997413247824   |
| train_1/mu_grads          | -0.08805150892585516  |
| train_1/mu_grads_std      | 0.4143685676157475    |
| train_1/mu_loss           | 2.0759444342996085    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09049728885293007  |
| train_1/q_grads_std       | 0.5533510029315949    |
| train_1/q_loss            | 1.2283271488348753    |
| train_1/reward            | -1.4933874710935924   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017822265625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.4431628617186     |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 297.23. Rollout time: 75.86, Training time: 221.34
Evaluating epoch 67
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 1912222.0             |
| test/episodes             | 1700.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.910118011184178    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.459834707188298    |
| train_0/fw_bonus          | -0.9994694128632545   |
| train_0/fw_loss           | 0.0037434476776979863 |
| train_0/mu_grads          | -0.0420497752726078   |
| train_0/mu_grads_std      | 0.545070829987526     |
| train_0/mu_loss           | 5.39395854676633      |
| train_0/next_q            | -5.390117334254297    |
| train_0/q_grads           | -0.0467770560644567   |
| train_0/q_grads_std       | 0.45665289759635924   |
| train_0/q_loss            | 0.2013477297843797    |
| train_0/reward            | -0.704934904207039    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0054931640625       |
| train_0/target_q          | -5.692252805337314    |
| train_1/avg_q             | -8.004898724227331    |
| train_1/current_q         | -10.986681742343132   |
| train_1/fw_bonus          | -0.9888717412948609   |
| train_1/fw_loss           | 0.0757345836609602    |
| train_1/mu_grads          | -0.08844800237566233  |
| train_1/mu_grads_std      | 0.41433217003941536   |
| train_1/mu_loss           | 2.6641918189377307    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09151777904480696  |
| train_1/q_grads_std       | 0.5574081808328628    |
| train_1/q_loss            | 0.7277858135927859    |
| train_1/reward            | -1.5148582283356518   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.564763013491909   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 292.85. Rollout time: 76.01, Training time: 216.81
Evaluating epoch 68
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 1940347.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.146466997097108    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.434134455278988    |
| train_0/fw_bonus          | -0.999482375383377    |
| train_0/fw_loss           | 0.0036822414374910297 |
| train_0/mu_grads          | -0.04043692220002413  |
| train_0/mu_grads_std      | 0.5471338540315628    |
| train_0/mu_loss           | 5.367641678786143     |
| train_0/next_q            | -5.365366660097488    |
| train_0/q_grads           | -0.04817811530083418  |
| train_0/q_grads_std       | 0.4610391415655613    |
| train_0/q_loss            | 0.19680622515728374   |
| train_0/reward            | -0.7042211710795527   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00517578125         |
| train_0/target_q          | -5.667025259902556    |
| train_1/avg_q             | -8.3672718222108      |
| train_1/current_q         | -10.980153197196845   |
| train_1/fw_bonus          | -0.9885808870196342   |
| train_1/fw_loss           | 0.07721141427755356   |
| train_1/mu_grads          | -0.08837163206189871  |
| train_1/mu_grads_std      | 0.41457296088337897   |
| train_1/mu_loss           | 2.7721349221042013    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09199632331728935  |
| train_1/q_grads_std       | 0.5627647176384926    |
| train_1/q_loss            | 0.7334554958728127    |
| train_1/reward            | -1.5086092948389704   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.551336345620225   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 292.98. Rollout time: 77.94, Training time: 215.01
Evaluating epoch 69
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 1968472.0             |
| test/episodes             | 1750.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.581116504858532    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.455043118706414    |
| train_0/fw_bonus          | -0.9994667202234269   |
| train_0/fw_loss           | 0.0037561599106993525 |
| train_0/mu_grads          | -0.040275948401540515 |
| train_0/mu_grads_std      | 0.549604645371437     |
| train_0/mu_loss           | 5.391498088153713     |
| train_0/next_q            | -5.387843406439164    |
| train_0/q_grads           | -0.049425555393099785 |
| train_0/q_grads_std       | 0.4655876778066158    |
| train_0/q_loss            | 0.19792103813353043   |
| train_0/reward            | -0.7039692027021374   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0048828125          |
| train_0/target_q          | -5.688332521477852    |
| train_1/avg_q             | -8.100956379637442    |
| train_1/current_q         | -10.723766167676086   |
| train_1/fw_bonus          | -0.98734560161829     |
| train_1/fw_loss           | 0.08348404187709094   |
| train_1/mu_grads          | -0.0885435774922371   |
| train_1/mu_grads_std      | 0.41529105305671693   |
| train_1/mu_loss           | 2.8525076908122515    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09257474057376384  |
| train_1/q_grads_std       | 0.5651571586728096    |
| train_1/q_loss            | 0.9492468785113385    |
| train_1/reward            | -1.5124838395036933   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.288916944972447   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 294.71. Rollout time: 73.44, Training time: 221.25
Evaluating epoch 70
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 70                   |
| policy/steps              | 1996597.0            |
| test/episodes             | 1775.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -7.4807916787468285  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.4511337944469265  |
| train_0/fw_bonus          | -0.9994930163025856  |
| train_0/fw_loss           | 0.00363198853447102  |
| train_0/mu_grads          | -0.04233729653060436 |
| train_0/mu_grads_std      | 0.5518584206700325   |
| train_0/mu_loss           | 5.390932261239708    |
| train_0/next_q            | -5.388899177471093   |
| train_0/q_grads           | -0.0512492093257606  |
| train_0/q_grads_std       | 0.4691906481981277   |
| train_0/q_loss            | 0.19410439332953056  |
| train_0/reward            | -0.7010160436446313  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0044677734375      |
| train_0/target_q          | -5.68531237104651    |
| train_1/avg_q             | -8.155945799391098   |
| train_1/current_q         | -10.349045111259116  |
| train_1/fw_bonus          | -0.9869656577706337  |
| train_1/fw_loss           | 0.08541339803487062  |
| train_1/mu_grads          | -0.08865033891052007 |
| train_1/mu_grads_std      | 0.4161366060376167   |
| train_1/mu_loss           | 2.9347699636063806   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09430574178695679 |
| train_1/q_grads_std       | 0.5694087594747543   |
| train_1/q_loss            | 0.9294805955776992   |
| train_1/reward            | -1.4891615394291875  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0015869140625      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.919268961304192  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_70.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 279.91. Rollout time: 75.84, Training time: 204.04
Evaluating epoch 71
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 2024722.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.855356522031955    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.480818877057392    |
| train_0/fw_bonus          | -0.9995216518640518   |
| train_0/fw_loss           | 0.003496847621863708  |
| train_0/mu_grads          | -0.042591024003922937 |
| train_0/mu_grads_std      | 0.5540204092860221    |
| train_0/mu_loss           | 5.422097796979538     |
| train_0/next_q            | -5.4192665269680464   |
| train_0/q_grads           | -0.05264900559559464  |
| train_0/q_grads_std       | 0.4727055631577969    |
| train_0/q_loss            | 0.1969298689922403    |
| train_0/reward            | -0.7014453937852523   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046875             |
| train_0/target_q          | -5.7151530476843515   |
| train_1/avg_q             | -8.152231609165447    |
| train_1/current_q         | -10.165617208188937   |
| train_1/fw_bonus          | -0.9874208450317383   |
| train_1/fw_loss           | 0.08310203924775124   |
| train_1/mu_grads          | -0.08876338191330432  |
| train_1/mu_grads_std      | 0.41709490939974786   |
| train_1/mu_loss           | 2.9769500899397374    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09413593262434006  |
| train_1/q_grads_std       | 0.5728988155722619    |
| train_1/q_loss            | 0.883030254750006     |
| train_1/reward            | -1.4993744811254146   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00166015625         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.722404266281668   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 285.56. Rollout time: 75.05, Training time: 210.48
Evaluating epoch 72
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 2052847.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.728362066210168    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.403383131482129    |
| train_0/fw_bonus          | -0.999531602859497    |
| train_0/fw_loss           | 0.0034498085908126084 |
| train_0/mu_grads          | -0.044260470848530534 |
| train_0/mu_grads_std      | 0.5564992293715477    |
| train_0/mu_loss           | 5.3436587240971       |
| train_0/next_q            | -5.3426625780019545   |
| train_0/q_grads           | -0.05409430153667927  |
| train_0/q_grads_std       | 0.47548975273966787   |
| train_0/q_loss            | 0.19509999911815784   |
| train_0/reward            | -0.6982399258333316   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004541015625        |
| train_0/target_q          | -5.636991852706993    |
| train_1/avg_q             | -8.191883934092917    |
| train_1/current_q         | -9.944619074361816    |
| train_1/fw_bonus          | -0.9871842637658119   |
| train_1/fw_loss           | 0.08430331945419312   |
| train_1/mu_grads          | -0.08884788975119591  |
| train_1/mu_grads_std      | 0.41766152903437614   |
| train_1/mu_loss           | 3.0134463488564753    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09496607966721057  |
| train_1/q_grads_std       | 0.5758892089128494    |
| train_1/q_loss            | 0.6916600808712752    |
| train_1/reward            | -1.4662117622712685   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.503697113833772   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 278.22. Rollout time: 74.94, Training time: 203.25
Evaluating epoch 73
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-------------------------------------------------------
| epoch                     | 73                      |
| policy/steps              | 2080972.0               |
| test/episodes             | 1850.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -15.0                   |
| test_1/avg_q              | -1.128810723178615      |
| test_1/n_subgoals         | 375.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -15.0                   |
| train_0/current_q         | -5.429236689757926      |
| train_0/fw_bonus          | -0.9995626226067543     |
| train_0/fw_loss           | 0.0033033673302270473   |
| train_0/mu_grads          | -0.04690676685422659    |
| train_0/mu_grads_std      | 0.5582833334803581      |
| train_0/mu_loss           | 5.3674354849438375      |
| train_0/next_q            | -5.36545896516182       |
| train_0/q_grads           | -0.0553270298987627     |
| train_0/q_grads_std       | 0.4779171831905842      |
| train_0/q_loss            | 0.19569290441672949     |
| train_0/reward            | -0.7005015271883167     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.004052734375          |
| train_0/target_q          | -5.662308945725218      |
| train_1/avg_q             | -7.745679391204667      |
| train_1/current_q         | -0.9174457933298829     |
| train_1/fw_bonus          | -0.9874840244650841     |
| train_1/fw_loss           | 0.08278123084455728     |
| train_1/mu_grads          | -0.0885254692286253     |
| train_1/mu_grads_std      | 0.41807069405913355     |
| train_1/mu_loss           | 0.5183040404607212      |
| train_1/n_subgoals        | 1500.0                  |
| train_1/next_q            | -0.00044923581244543914 |
| train_1/q_grads           | -0.09866444431245328    |
| train_1/q_grads_std       | 0.5787362203001976      |
| train_1/q_loss            | 0.8623929087332709      |
| train_1/reward            | -1.4709392733173445     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0018310546875         |
| train_1/reward_-15.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4713042545216433     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 268.46. Rollout time: 73.52, Training time: 194.91
Evaluating epoch 74
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 2109097.0             |
| test/episodes             | 1875.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -14.999999999969583   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.486913979580921    |
| train_0/fw_bonus          | -0.9994999200105668   |
| train_0/fw_loss           | 0.003599467460298911  |
| train_0/mu_grads          | -0.04701313618570566  |
| train_0/mu_grads_std      | 0.5594535142183303    |
| train_0/mu_loss           | 5.41739978585868      |
| train_0/next_q            | -5.415776855191915    |
| train_0/q_grads           | -0.056188215781003234 |
| train_0/q_grads_std       | 0.4807832419872284    |
| train_0/q_loss            | 0.20028899570083053   |
| train_0/reward            | -0.7056215382697701   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0040283203125       |
| train_0/target_q          | -5.723903676800392    |
| train_1/avg_q             | -8.650933584150781    |
| train_1/current_q         | -10.787479678778732   |
| train_1/fw_bonus          | -0.9874372586607933   |
| train_1/fw_loss           | 0.08301864601671696   |
| train_1/mu_grads          | -0.0904081292450428   |
| train_1/mu_grads_std      | 0.41540694534778594   |
| train_1/mu_loss           | 5.988638034918864     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.10126600004732608  |
| train_1/q_grads_std       | 0.57962726354599      |
| train_1/q_loss            | 5.325838876919882     |
| train_1/reward            | -1.4892874779230625   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001953125           |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.716982790423065   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 295.83. Rollout time: 76.54, Training time: 219.26
Evaluating epoch 75
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 2137222.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -9.601404347581514    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.384635126752373    |
| train_0/fw_bonus          | -0.9994965627789497   |
| train_0/fw_loss           | 0.0036152595246676357 |
| train_0/mu_grads          | -0.04838634124025702  |
| train_0/mu_grads_std      | 0.561221070587635     |
| train_0/mu_loss           | 5.3079723696352605    |
| train_0/next_q            | -5.3050468098109      |
| train_0/q_grads           | -0.056121840793639424 |
| train_0/q_grads_std       | 0.4831440173089504    |
| train_0/q_loss            | 0.1972568802599289    |
| train_0/reward            | -0.7038864675363584   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00439453125         |
| train_0/target_q          | -5.615695301425975    |
| train_1/avg_q             | -14.99048811494968    |
| train_1/current_q         | -10.968340573068414   |
| train_1/fw_bonus          | -0.9873787105083466   |
| train_1/fw_loss           | 0.08331597372889518   |
| train_1/mu_grads          | -0.09128770101815462  |
| train_1/mu_grads_std      | 0.41561898216605186   |
| train_1/mu_loss           | 4.058097008275811     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.1001407977193594   |
| train_1/q_grads_std       | 0.5828871712088585    |
| train_1/q_loss            | 5.2535090256914625    |
| train_1/reward            | -1.5159793926417477   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.877898337954253   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 287.72. Rollout time: 74.92, Training time: 212.77
Evaluating epoch 76
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 2165347.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.64508277152198    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.443236842982474    |
| train_0/fw_bonus          | -0.99948820322752     |
| train_0/fw_loss           | 0.0036548015719745307 |
| train_0/mu_grads          | -0.047870516590774057 |
| train_0/mu_grads_std      | 0.5644112423062324    |
| train_0/mu_loss           | 5.3649152371433475    |
| train_0/next_q            | -5.361617477614791    |
| train_0/q_grads           | -0.05697646709159017  |
| train_0/q_grads_std       | 0.4854295179247856    |
| train_0/q_loss            | 0.19750993660139982   |
| train_0/reward            | -0.7042484911180509   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0040771484375       |
| train_0/target_q          | -5.678514681549457    |
| train_1/avg_q             | -14.999928057024267   |
| train_1/current_q         | -11.109578210410586   |
| train_1/fw_bonus          | -0.9858848989009857   |
| train_1/fw_loss           | 0.09090139418840408   |
| train_1/mu_grads          | -0.0916150663048029   |
| train_1/mu_grads_std      | 0.4158952884376049    |
| train_1/mu_loss           | 4.045100775240806     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09905353281646967  |
| train_1/q_grads_std       | 0.5861055895686149    |
| train_1/q_loss            | 5.706425800614224     |
| train_1/reward            | -1.5246441046721884   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018310546875       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.012532288265941   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 246.10. Rollout time: 65.31, Training time: 180.77
Evaluating epoch 77
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 77                   |
| policy/steps              | 2193472.0            |
| test/episodes             | 1950.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -9.010361348065981   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 7800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.406363263787268   |
| train_0/fw_bonus          | -0.9994904577732087  |
| train_0/fw_loss           | 0.00364419401739724  |
| train_0/mu_grads          | -0.04930745912715793 |
| train_0/mu_grads_std      | 0.5663118094205857   |
| train_0/mu_loss           | 5.3351862794069005   |
| train_0/next_q            | -5.331946713047641   |
| train_0/q_grads           | -0.05809519225731492 |
| train_0/q_grads_std       | 0.48883374854922296  |
| train_0/q_loss            | 0.19664937913788563  |
| train_0/reward            | -0.7020035206493048  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.004345703125       |
| train_0/target_q          | -5.638026312339581   |
| train_1/avg_q             | -14.931347341744573  |
| train_1/current_q         | -11.28593524892189   |
| train_1/fw_bonus          | -0.9853153139352798  |
| train_1/fw_loss           | 0.09379367660731078  |
| train_1/mu_grads          | -0.09160879757255316 |
| train_1/mu_grads_std      | 0.4164311997592449   |
| train_1/mu_loss           | 3.0828962192414813   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.0992665410041809  |
| train_1/q_grads_std       | 0.5883340418338776   |
| train_1/q_loss            | 5.254780299548672    |
| train_1/reward            | -1.493731871987984   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0018798828125      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -11.238582946206739  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 238.58. Rollout time: 63.59, Training time: 174.97
Evaluating epoch 78
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 2221597.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -8.827063224301819    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.462470667751662    |
| train_0/fw_bonus          | -0.9994645953178406   |
| train_0/fw_loss           | 0.003766199795063585  |
| train_0/mu_grads          | -0.050862431339919564 |
| train_0/mu_grads_std      | 0.5681445017457009    |
| train_0/mu_loss           | 5.395540878210864     |
| train_0/next_q            | -5.394489977780248    |
| train_0/q_grads           | -0.058370246831327674 |
| train_0/q_grads_std       | 0.4918810300529003    |
| train_0/q_loss            | 0.2002034388699653    |
| train_0/reward            | -0.7030770261830185   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.003955078125        |
| train_0/target_q          | -5.698053717059223    |
| train_1/avg_q             | -14.894015213109538   |
| train_1/current_q         | -11.318273941707492   |
| train_1/fw_bonus          | -0.9847049832344055   |
| train_1/fw_loss           | 0.0968928024172783    |
| train_1/mu_grads          | -0.09202006105333567  |
| train_1/mu_grads_std      | 0.4173377677798271    |
| train_1/mu_loss           | 2.732741385829113     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09845988918095827  |
| train_1/q_grads_std       | 0.5911378249526024    |
| train_1/q_loss            | 5.401963880798855     |
| train_1/reward            | -1.5212099160380603   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015380859375       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.248475541038065   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 4417.35. Rollout time: 67.52, Training time: 4349.81
Evaluating epoch 79
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 2249722.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -11.096740205214623   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.457040156044342    |
| train_0/fw_bonus          | -0.9995101749897003   |
| train_0/fw_loss           | 0.0035509955196175724 |
| train_0/mu_grads          | -0.05167011525481939  |
| train_0/mu_grads_std      | 0.570241080224514     |
| train_0/mu_loss           | 5.397420572236044     |
| train_0/next_q            | -5.3958098396647705   |
| train_0/q_grads           | -0.059872505627572535 |
| train_0/q_grads_std       | 0.49538235664367675   |
| train_0/q_loss            | 0.197491945950317     |
| train_0/reward            | -0.700365440823225    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0038330078125       |
| train_0/target_q          | -5.691042364217005    |
| train_1/avg_q             | -14.894792439696554   |
| train_1/current_q         | -11.275814704264425   |
| train_1/fw_bonus          | -0.9847431257367134   |
| train_1/fw_loss           | 0.09669919461011886   |
| train_1/mu_grads          | -0.09233161341398954  |
| train_1/mu_grads_std      | 0.41817767098546027   |
| train_1/mu_loss           | 4.106525443377343     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09805172756314277  |
| train_1/q_grads_std       | 0.5943045616149902    |
| train_1/q_loss            | 5.395103398565911     |
| train_1/reward            | -1.539771459835174    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.176956518428929   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 289.71. Rollout time: 75.88, Training time: 213.81
Evaluating epoch 80
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 2277847.0             |
| test/episodes             | 2025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -11.135412085430028   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.441129734361252    |
| train_0/fw_bonus          | -0.9995102465152741   |
| train_0/fw_loss           | 0.003550598490983248  |
| train_0/mu_grads          | -0.052753388043493034 |
| train_0/mu_grads_std      | 0.5726724088191986    |
| train_0/mu_loss           | 5.387853836305988     |
| train_0/next_q            | -5.385016938318455    |
| train_0/q_grads           | -0.060988496709614995 |
| train_0/q_grads_std       | 0.4997514016926289    |
| train_0/q_loss            | 0.19397087345347241   |
| train_0/reward            | -0.6977653853056835   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0044189453125       |
| train_0/target_q          | -5.675820597860851    |
| train_1/avg_q             | -14.88443644700516    |
| train_1/current_q         | -11.18181448074881    |
| train_1/fw_bonus          | -0.9845264717936516   |
| train_1/fw_loss           | 0.09779927730560303   |
| train_1/mu_grads          | -0.09251602534204721  |
| train_1/mu_grads_std      | 0.41886075511574744   |
| train_1/mu_loss           | 3.9828136273301142    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09736272282898426  |
| train_1/q_grads_std       | 0.596048279106617     |
| train_1/q_loss            | 5.480245884476811     |
| train_1/reward            | -1.5004541547496046   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.126154838343359   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_80.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 296.48. Rollout time: 78.15, Training time: 218.29
Evaluating epoch 81
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 2305972.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -12.1906654428498     |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.4491618223895815   |
| train_0/fw_bonus          | -0.9995300889015197   |
| train_0/fw_loss           | 0.0034569606301374733 |
| train_0/mu_grads          | -0.052021028101444246 |
| train_0/mu_grads_std      | 0.575157280266285     |
| train_0/mu_loss           | 5.3973258647526645    |
| train_0/next_q            | -5.396063971152557    |
| train_0/q_grads           | -0.0621189477853477   |
| train_0/q_grads_std       | 0.5027891531586647    |
| train_0/q_loss            | 0.19255426061550263   |
| train_0/reward            | -0.696566805258044    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0052734375          |
| train_0/target_q          | -5.682957368374316    |
| train_1/avg_q             | -14.900464813269265   |
| train_1/current_q         | -11.201674389131131   |
| train_1/fw_bonus          | -0.984892125427723    |
| train_1/fw_loss           | 0.0959425749257207    |
| train_1/mu_grads          | -0.09391418416053057  |
| train_1/mu_grads_std      | 0.41893028020858764   |
| train_1/mu_loss           | 4.5441540263572415    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09704659543931485  |
| train_1/q_grads_std       | 0.5971907779574395    |
| train_1/q_loss            | 5.308329374122621     |
| train_1/reward            | -1.4948508443121682   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020751953125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.149621352124672   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 257.49. Rollout time: 67.02, Training time: 190.44
Evaluating epoch 82
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 2334097.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -13.745284471733235   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.470872709115494    |
| train_0/fw_bonus          | -0.9994975686073303   |
| train_0/fw_loss           | 0.0036105038307141513 |
| train_0/mu_grads          | -0.05407464941963554  |
| train_0/mu_grads_std      | 0.5783041834831237    |
| train_0/mu_loss           | 5.4163992130568       |
| train_0/next_q            | -5.41463827622961     |
| train_0/q_grads           | -0.06352629847824573  |
| train_0/q_grads_std       | 0.506704357266426     |
| train_0/q_loss            | 0.1936711446113714    |
| train_0/reward            | -0.6968801352741139   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0052978515625       |
| train_0/target_q          | -5.707442844580785    |
| train_1/avg_q             | -14.956320256493767   |
| train_1/current_q         | -11.085934947997307   |
| train_1/fw_bonus          | -0.983974152803421    |
| train_1/fw_loss           | 0.10060393437743187   |
| train_1/mu_grads          | -0.09411752931773662  |
| train_1/mu_grads_std      | 0.4198663242161274    |
| train_1/mu_loss           | 4.608532768356388     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09665070697665215  |
| train_1/q_grads_std       | 0.5991742879152298    |
| train_1/q_loss            | 5.14428386418423      |
| train_1/reward            | -1.4774729124743318   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.043957287474337   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 272.53. Rollout time: 70.49, Training time: 202.02
Evaluating epoch 83
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 2362222.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -10.801286060921628   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.374863791932263    |
| train_0/fw_bonus          | -0.9995421454310417   |
| train_0/fw_loss           | 0.00340003619203344   |
| train_0/mu_grads          | -0.053849545679986476 |
| train_0/mu_grads_std      | 0.5823200196027756    |
| train_0/mu_loss           | 5.31943224027299      |
| train_0/next_q            | -5.317810311413335    |
| train_0/q_grads           | -0.06529210545122624  |
| train_0/q_grads_std       | 0.5101083919405938    |
| train_0/q_loss            | 0.18702919858765826   |
| train_0/reward            | -0.6903838683225331   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0043212890625       |
| train_0/target_q          | -5.607542647174481    |
| train_1/avg_q             | -14.954970374099974   |
| train_1/current_q         | -10.863900148171824   |
| train_1/fw_bonus          | -0.9836048051714897   |
| train_1/fw_loss           | 0.10247939061373472   |
| train_1/mu_grads          | -0.09435008373111486  |
| train_1/mu_grads_std      | 0.42039638608694074   |
| train_1/mu_loss           | 4.62200400440617      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09609864819794893  |
| train_1/q_grads_std       | 0.6015025824308395    |
| train_1/q_loss            | 5.414156558768989     |
| train_1/reward            | -1.4908746692068235   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011962890625       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.794653966081828   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 259.43. Rollout time: 68.43, Training time: 190.96
Evaluating epoch 84
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 2390347.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -9.4346955260315      |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.417392591651689    |
| train_0/fw_bonus          | -0.9995697930455207   |
| train_0/fw_loss           | 0.0032695152680389584 |
| train_0/mu_grads          | -0.05446568392217159  |
| train_0/mu_grads_std      | 0.586141188442707     |
| train_0/mu_loss           | 5.3715497173416455    |
| train_0/next_q            | -5.369614909229975    |
| train_0/q_grads           | -0.06568123530596495  |
| train_0/q_grads_std       | 0.5142456114292144    |
| train_0/q_loss            | 0.18569437627889976   |
| train_0/reward            | -0.6894211277583964   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0049560546875       |
| train_0/target_q          | -5.651489856407702    |
| train_1/avg_q             | -14.93255844580346    |
| train_1/current_q         | -10.52377008517323    |
| train_1/fw_bonus          | -0.9830057457089424   |
| train_1/fw_loss           | 0.10552132036536932   |
| train_1/mu_grads          | -0.09446309916675091  |
| train_1/mu_grads_std      | 0.42184129282832145   |
| train_1/mu_loss           | 3.263358787982031     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.0951436035335064   |
| train_1/q_grads_std       | 0.6033443331718444    |
| train_1/q_loss            | 5.169807481885122     |
| train_1/reward            | -1.4642567821007106   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0015625             |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.484156684444462   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 244.24. Rollout time: 66.41, Training time: 177.80
Evaluating epoch 85
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 2418472.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -8.385400190411104    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.33888508964688     |
| train_0/fw_bonus          | -0.9996080189943314   |
| train_0/fw_loss           | 0.0030890548892784863 |
| train_0/mu_grads          | -0.054443931020796296 |
| train_0/mu_grads_std      | 0.5878011971712113    |
| train_0/mu_loss           | 5.2976002567963425    |
| train_0/next_q            | -5.296057374995593    |
| train_0/q_grads           | -0.06690089274197816  |
| train_0/q_grads_std       | 0.5181742623448372    |
| train_0/q_loss            | 0.18244203885617774   |
| train_0/reward            | -0.6861199256578402   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0045654296875       |
| train_0/target_q          | -5.5700000088644845   |
| train_1/avg_q             | -14.8692659018522     |
| train_1/current_q         | -10.378793904692603   |
| train_1/fw_bonus          | -0.9824265629053116   |
| train_1/fw_loss           | 0.10846237689256669   |
| train_1/mu_grads          | -0.09499566368758679  |
| train_1/mu_grads_std      | 0.42304267957806585   |
| train_1/mu_loss           | 4.7088540055252945    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09319779444485903  |
| train_1/q_grads_std       | 0.6067319273948669    |
| train_1/q_loss            | 5.488269642422084     |
| train_1/reward            | -1.4635155271796976   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.31402089827345    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 282.08. Rollout time: 74.65, Training time: 207.40
Evaluating epoch 86
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 86                   |
| policy/steps              | 2446597.0            |
| test/episodes             | 2175.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -9.656404183247938   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8700.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.359673282002502   |
| train_0/fw_bonus          | -0.9996146768331527  |
| train_0/fw_loss           | 0.003057629376417026 |
| train_0/mu_grads          | -0.05680406065657735 |
| train_0/mu_grads_std      | 0.5901076450943947   |
| train_0/mu_loss           | 5.314140406048403    |
| train_0/next_q            | -5.313176359899993   |
| train_0/q_grads           | -0.06794603113085032 |
| train_0/q_grads_std       | 0.5219646573066712   |
| train_0/q_loss            | 0.18146238048865734  |
| train_0/reward            | -0.6862819449146628  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0046875            |
| train_0/target_q          | -5.5903252147058335  |
| train_1/avg_q             | -14.93677684253786   |
| train_1/current_q         | -10.214499553771105  |
| train_1/fw_bonus          | -0.9824606478214264  |
| train_1/fw_loss           | 0.10828927736729384  |
| train_1/mu_grads          | -0.09536987412720918 |
| train_1/mu_grads_std      | 0.424940974265337    |
| train_1/mu_loss           | 4.2687695785563315   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.092467918433249   |
| train_1/q_grads_std       | 0.6090788021683693   |
| train_1/q_loss            | 5.503997836108551    |
| train_1/reward            | -1.4607615766835806  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00107421875        |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.149050150902331  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 278.10. Rollout time: 72.62, Training time: 205.46
Evaluating epoch 87
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 2474722.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -8.400362394992788    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.366161002485406    |
| train_0/fw_bonus          | -0.9996480703353882   |
| train_0/fw_loss           | 0.0028999403933994473 |
| train_0/mu_grads          | -0.057201719097793105 |
| train_0/mu_grads_std      | 0.5919005781412124    |
| train_0/mu_loss           | 5.327787082383857     |
| train_0/next_q            | -5.32608942446746     |
| train_0/q_grads           | -0.06888546366244555  |
| train_0/q_grads_std       | 0.5245664685964584    |
| train_0/q_loss            | 0.180791815208062     |
| train_0/reward            | -0.6847727646752901   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00576171875         |
| train_0/target_q          | -5.59843892203227     |
| train_1/avg_q             | -14.945022802337766   |
| train_1/current_q         | -10.112015842530655   |
| train_1/fw_bonus          | -0.98441192060709     |
| train_1/fw_loss           | 0.09838091190904379   |
| train_1/mu_grads          | -0.09562027659267187  |
| train_1/mu_grads_std      | 0.4263184182345867    |
| train_1/mu_loss           | 3.765723231401792     |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09173298794776201  |
| train_1/q_grads_std       | 0.6116092875599861    |
| train_1/q_loss            | 5.185752581883596     |
| train_1/reward            | -1.4533509842185595   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.056583406093562   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 271.01. Rollout time: 72.02, Training time: 198.97
Evaluating epoch 88
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 2502847.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -11.000980926673138   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.368427557022676    |
| train_0/fw_bonus          | -0.9996290639042854   |
| train_0/fw_loss           | 0.0029896621650550514 |
| train_0/mu_grads          | -0.05761738521978259  |
| train_0/mu_grads_std      | 0.5943154737353324    |
| train_0/mu_loss           | 5.327952288927659     |
| train_0/next_q            | -5.32514261903995     |
| train_0/q_grads           | -0.06990029104053974  |
| train_0/q_grads_std       | 0.5272813394665719    |
| train_0/q_loss            | 0.18465756181000073   |
| train_0/reward            | -0.6876197086952743   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.004833984375        |
| train_0/target_q          | -5.599358693341328    |
| train_1/avg_q             | -14.941463530027137   |
| train_1/current_q         | -10.355843814829218   |
| train_1/fw_bonus          | -0.9841929644346237   |
| train_1/fw_loss           | 0.09949280098080635   |
| train_1/mu_grads          | -0.0952535467222333   |
| train_1/mu_grads_std      | 0.42835692688822746   |
| train_1/mu_loss           | 4.3074917974020765    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09146432355046272  |
| train_1/q_grads_std       | 0.6145965218544006    |
| train_1/q_loss            | 5.652098969827668     |
| train_1/reward            | -1.48731132570756     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.268551560082562   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 342.77. Rollout time: 95.47, Training time: 247.27
Evaluating epoch 89
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 89                   |
| policy/steps              | 2530972.0            |
| test/episodes             | 2250.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -6.638472826126361   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9000.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.4439206281872945  |
| train_0/fw_bonus          | -0.9996248751878738  |
| train_0/fw_loss           | 0.003009430825477466 |
| train_0/mu_grads          | -0.05826443871483207 |
| train_0/mu_grads_std      | 0.5966128841042518   |
| train_0/mu_loss           | 5.397040421906989    |
| train_0/next_q            | -5.395205957511516   |
| train_0/q_grads           | -0.07077162358909846 |
| train_0/q_grads_std       | 0.5294453337788582   |
| train_0/q_loss            | 0.18809128616883425  |
| train_0/reward            | -0.6925736697805405  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.004736328125       |
| train_0/target_q          | -5.6779358867063525  |
| train_1/avg_q             | -14.862107177724829  |
| train_1/current_q         | -10.466397412093825  |
| train_1/fw_bonus          | -0.9843501359224319  |
| train_1/fw_loss           | 0.09869468566030264  |
| train_1/mu_grads          | -0.09397272821515798 |
| train_1/mu_grads_std      | 0.42916019558906554  |
| train_1/mu_loss           | 3.1330062729491734   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09129327759146691 |
| train_1/q_grads_std       | 0.617965167760849    |
| train_1/q_loss            | 5.319582098824073    |
| train_1/reward            | -1.4848874712268298  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001708984375       |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.402504658726832  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 276.51. Rollout time: 75.21, Training time: 201.28
Evaluating epoch 90
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 90                   |
| policy/steps              | 2559097.0            |
| test/episodes             | 2275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -10.800832182360624  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9100.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.408810619473741   |
| train_0/fw_bonus          | -0.9995810434222221  |
| train_0/fw_loss           | 0.003216384892584756 |
| train_0/mu_grads          | -0.05972149586305022 |
| train_0/mu_grads_std      | 0.5987105339765548   |
| train_0/mu_loss           | 5.354056965091424    |
| train_0/next_q            | -5.353172624199954   |
| train_0/q_grads           | -0.07167111672461032 |
| train_0/q_grads_std       | 0.5317649006843567   |
| train_0/q_loss            | 0.19220081101478023  |
| train_0/reward            | -0.6948100548914227  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0058349609375      |
| train_0/target_q          | -5.6433164262505215  |
| train_1/avg_q             | -14.906844420769279  |
| train_1/current_q         | -10.768475207968919  |
| train_1/fw_bonus          | -0.9841995567083359  |
| train_1/fw_loss           | 0.09945929758250713  |
| train_1/mu_grads          | -0.09392792042344808 |
| train_1/mu_grads_std      | 0.4302082397043705   |
| train_1/mu_loss           | 3.7001935623256386   |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.0917543338611722  |
| train_1/q_grads_std       | 0.6203978136181831   |
| train_1/q_loss            | 5.663200437174967    |
| train_1/reward            | -1.5078956792138343  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.00185546875        |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.689653491713837  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_90.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 269.29. Rollout time: 71.83, Training time: 197.43
Evaluating epoch 91
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 2587222.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -10.983411332534049   |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.392729628775578    |
| train_0/fw_bonus          | -0.9996020451188088   |
| train_0/fw_loss           | 0.0031173139926977456 |
| train_0/mu_grads          | -0.06140397060662508  |
| train_0/mu_grads_std      | 0.6012394204735756    |
| train_0/mu_loss           | 5.333488797202191     |
| train_0/next_q            | -5.33109716060381     |
| train_0/q_grads           | -0.07251809611916542  |
| train_0/q_grads_std       | 0.5343916609883308    |
| train_0/q_loss            | 0.19003365802309252   |
| train_0/reward            | -0.6951867567026057   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005224609375        |
| train_0/target_q          | -5.624011008653487    |
| train_1/avg_q             | -14.885362316003414   |
| train_1/current_q         | -10.662929621534797   |
| train_1/fw_bonus          | -0.9835944771766663   |
| train_1/fw_loss           | 0.10253186784684658   |
| train_1/mu_grads          | -0.09456855151802301  |
| train_1/mu_grads_std      | 0.4317134402692318    |
| train_1/mu_loss           | 3.6074862915533985    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09244843889027834  |
| train_1/q_grads_std       | 0.6223248422145844    |
| train_1/q_loss            | 5.369228242515564     |
| train_1/reward            | -1.4785281932207      |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017578125          |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.602505244001954   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 277.37. Rollout time: 72.71, Training time: 204.63
Evaluating epoch 92
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 92                   |
| policy/steps              | 2615347.0            |
| test/episodes             | 2325.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -7.308950420105234   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9300.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.453120748844183   |
| train_0/fw_bonus          | -0.9996214479207992  |
| train_0/fw_loss           | 0.003025664703454822 |
| train_0/mu_grads          | -0.06150548625737429 |
| train_0/mu_grads_std      | 0.6026790037751197   |
| train_0/mu_loss           | 5.3864879292499355   |
| train_0/next_q            | -5.384327722583803   |
| train_0/q_grads           | -0.07337812278419734 |
| train_0/q_grads_std       | 0.537631393969059    |
| train_0/q_loss            | 0.19203355148410767  |
| train_0/reward            | -0.6962218533357373  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0056640625         |
| train_0/target_q          | -5.688278969659699   |
| train_1/avg_q             | -14.942804699835285  |
| train_1/current_q         | -10.598173293379572  |
| train_1/fw_bonus          | -0.9843683332204819  |
| train_1/fw_loss           | 0.0986023098230362   |
| train_1/mu_grads          | -0.09461275823414325 |
| train_1/mu_grads_std      | 0.4345700554549694   |
| train_1/mu_loss           | 3.254590869962338    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09249216206371784 |
| train_1/q_grads_std       | 0.62503382563591     |
| train_1/q_loss            | 5.1248395627265415   |
| train_1/reward            | -1.4763882666935388  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0014404296875      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.536842368256043  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 294.18. Rollout time: 78.48, Training time: 215.68
Evaluating epoch 93
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 93                   |
| policy/steps              | 2643472.0            |
| test/episodes             | 2350.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -7.215213249876911   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9400.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.402421228500806   |
| train_0/fw_bonus          | -0.9996145218610764  |
| train_0/fw_loss           | 0.003058367926860228 |
| train_0/mu_grads          | -0.06216830676421523 |
| train_0/mu_grads_std      | 0.6043868094682694   |
| train_0/mu_loss           | 5.318484051035259    |
| train_0/next_q            | -5.316774735097427   |
| train_0/q_grads           | -0.07473476771265268 |
| train_0/q_grads_std       | 0.540969517827034    |
| train_0/q_loss            | 0.18921780342158434  |
| train_0/reward            | -0.693862433036702   |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.005029296875       |
| train_0/target_q          | -5.63592920676746    |
| train_1/avg_q             | -14.804522429667331  |
| train_1/current_q         | -10.508296244004802  |
| train_1/fw_bonus          | -0.9847201526165008  |
| train_1/fw_loss           | 0.09681581258773804  |
| train_1/mu_grads          | -0.0954041799530387  |
| train_1/mu_grads_std      | 0.43735329285264013  |
| train_1/mu_loss           | 2.628516391758572    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09278567861765623 |
| train_1/q_grads_std       | 0.6278601884841919   |
| train_1/q_loss            | 5.370210837966645    |
| train_1/reward            | -1.4793717934720916  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0010009765625      |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.444720914565846  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 264.16. Rollout time: 72.21, Training time: 191.93
Evaluating epoch 94
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 94                    |
| policy/steps              | 2671597.0             |
| test/episodes             | 2375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -5.216255581969684    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.3791804839178      |
| train_0/fw_bonus          | -0.9996492385864257   |
| train_0/fw_loss           | 0.0028944147692527623 |
| train_0/mu_grads          | -0.06280889250338077  |
| train_0/mu_grads_std      | 0.6065575242042541    |
| train_0/mu_loss           | 5.31522493853128      |
| train_0/next_q            | -5.314433964594925    |
| train_0/q_grads           | -0.07533294297754764  |
| train_0/q_grads_std       | 0.544389782845974     |
| train_0/q_loss            | 0.1856043269936402    |
| train_0/reward            | -0.6906693460216047   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0051513671875       |
| train_0/target_q          | -5.610547819871252    |
| train_1/avg_q             | -12.36723917086809    |
| train_1/current_q         | -9.615381953626525    |
| train_1/fw_bonus          | -0.9843571826815605   |
| train_1/fw_loss           | 0.09865896422415972   |
| train_1/mu_grads          | -0.09579278901219368  |
| train_1/mu_grads_std      | 0.4385336384177208    |
| train_1/mu_loss           | 2.41289177126653      |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09546138178557158  |
| train_1/q_grads_std       | 0.6284256115555763    |
| train_1/q_loss            | 1.3890005220361312    |
| train_1/reward            | -1.4878695039980812   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00146484375         |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.132373898529334   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 261.05. Rollout time: 68.85, Training time: 192.17
Evaluating epoch 95
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 95                    |
| policy/steps              | 2699722.0             |
| test/episodes             | 2400.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -5.761071064791323    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.37635148244657     |
| train_0/fw_bonus          | -0.9996610254049301   |
| train_0/fw_loss           | 0.0028387641883455216 |
| train_0/mu_grads          | -0.06256331913173199  |
| train_0/mu_grads_std      | 0.608781835436821     |
| train_0/mu_loss           | 5.322859659134198     |
| train_0/next_q            | -5.3225659164853285   |
| train_0/q_grads           | -0.07573542725294828  |
| train_0/q_grads_std       | 0.5480059534311295    |
| train_0/q_loss            | 0.1835758234467495    |
| train_0/reward            | -0.6878310009022244   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00576171875         |
| train_0/target_q          | -5.6093599806064285   |
| train_1/avg_q             | -8.523085021774106    |
| train_1/current_q         | -9.336144141382476    |
| train_1/fw_bonus          | -0.9848674789071084   |
| train_1/fw_loss           | 0.09606773145496846   |
| train_1/mu_grads          | -0.09578773453831672  |
| train_1/mu_grads_std      | 0.44058484882116317   |
| train_1/mu_loss           | 2.4900547107382422    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.09606728870421648  |
| train_1/q_grads_std       | 0.630010011792183     |
| train_1/q_loss            | 1.1974390245494813    |
| train_1/reward            | -1.4602193795370113   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001611328125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -9.865705219380763    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 305.53. Rollout time: 79.46, Training time: 226.04
Evaluating epoch 96
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 96                    |
| policy/steps              | 2727847.0             |
| test/episodes             | 2425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -6.739736892708861    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.412962549502876    |
| train_0/fw_bonus          | -0.9996184140443802   |
| train_0/fw_loss           | 0.0030399734037928282 |
| train_0/mu_grads          | -0.06197041850537062  |
| train_0/mu_grads_std      | 0.6118246212601661    |
| train_0/mu_loss           | 5.3592271836555705    |
| train_0/next_q            | -5.356756323896748    |
| train_0/q_grads           | -0.07818940486758948  |
| train_0/q_grads_std       | 0.5512171670794487    |
| train_0/q_loss            | 0.18522327191132262   |
| train_0/reward            | -0.6895675057974586   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.005810546875        |
| train_0/target_q          | -5.648049343264116    |
| train_1/avg_q             | -8.638693360025412    |
| train_1/current_q         | -9.547023244084144    |
| train_1/fw_bonus          | -0.9831490710377693   |
| train_1/fw_loss           | 0.10479361601173878   |
| train_1/mu_grads          | -0.09585447590798139  |
| train_1/mu_grads_std      | 0.44155012220144274   |
| train_1/mu_loss           | 2.5444290867450374    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -14.99999999998937    |
| train_1/q_grads           | -0.09783621858805418  |
| train_1/q_grads_std       | 0.6319526895880699    |
| train_1/q_loss            | 1.0786947118391939    |
| train_1/reward            | -1.4645359568276035   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.092172675567188   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 270.67. Rollout time: 74.17, Training time: 196.47
Evaluating epoch 97
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 97                   |
| policy/steps              | 2755972.0            |
| test/episodes             | 2450.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -6.289220493417688   |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 9800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.430466662954755   |
| train_0/fw_bonus          | -0.9995893195271492  |
| train_0/fw_loss           | 0.003177346772281453 |
| train_0/mu_grads          | -0.06270258668810129 |
| train_0/mu_grads_std      | 0.6138198405504227   |
| train_0/mu_loss           | 5.369150431093313    |
| train_0/next_q            | -5.367269982945032   |
| train_0/q_grads           | -0.07882262375205755 |
| train_0/q_grads_std       | 0.5535163402557373   |
| train_0/q_loss            | 0.18840663166076324  |
| train_0/reward            | -0.6920309855820961  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0054443359375      |
| train_0/target_q          | -5.665719187454816   |
| train_1/avg_q             | -8.453896366838286   |
| train_1/current_q         | -9.69568161297993    |
| train_1/fw_bonus          | -0.9830655515193939  |
| train_1/fw_loss           | 0.1052176732569933   |
| train_1/mu_grads          | -0.09600414652377368 |
| train_1/mu_grads_std      | 0.44246612340211866  |
| train_1/mu_loss           | 2.61722819424746     |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.09898142870515585 |
| train_1/q_grads_std       | 0.633829639852047    |
| train_1/q_loss            | 1.1652173934473045   |
| train_1/reward            | -1.4788374626739824  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.001171875          |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.253617736111485  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 317.74. Rollout time: 84.61, Training time: 233.09
Evaluating epoch 98
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 2784097.0             |
| test/episodes             | 2475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -15.0                 |
| test_1/avg_q              | -7.719452505758032    |
| test_1/n_subgoals         | 375.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.0                 |
| train_0/current_q         | -5.318421744266146    |
| train_0/fw_bonus          | -0.9995678305625916   |
| train_0/fw_loss           | 0.0032787554140668363 |
| train_0/mu_grads          | -0.06375341191887855  |
| train_0/mu_grads_std      | 0.616396601498127     |
| train_0/mu_loss           | 5.265263770510936     |
| train_0/next_q            | -5.263096274015636    |
| train_0/q_grads           | -0.0802878288552165   |
| train_0/q_grads_std       | 0.5554665580391884    |
| train_0/q_loss            | 0.1847451661967263    |
| train_0/reward            | -0.6891515944560525   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0051513671875       |
| train_0/target_q          | -5.548221255907248    |
| train_1/avg_q             | -8.186500752140647    |
| train_1/current_q         | -9.754521449880595    |
| train_1/fw_bonus          | -0.9819053739309311   |
| train_1/fw_loss           | 0.11110889613628387   |
| train_1/mu_grads          | -0.09569610059261321  |
| train_1/mu_grads_std      | 0.44336180612444875   |
| train_1/mu_loss           | 2.5090771807698125    |
| train_1/n_subgoals        | 1500.0                |
| train_1/next_q            | -15.0                 |
| train_1/q_grads           | -0.10071829333901405  |
| train_1/q_grads_std       | 0.636229333281517     |
| train_1/q_loss            | 1.3199033228670038    |
| train_1/reward            | -1.4764019074813404   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-15.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -10.309680716075093   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 288.76. Rollout time: 79.85, Training time: 208.88
Evaluating epoch 99
Data_dir: data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104
----------------------------------------------------
| epoch                     | 99                   |
| policy/steps              | 2812222.0            |
| test/episodes             | 2500.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -15.0                |
| test_1/avg_q              | -12.620904333555208  |
| test_1/n_subgoals         | 375.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 10000.0              |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -15.0                |
| train_0/current_q         | -5.398441976205996   |
| train_0/fw_bonus          | -0.999511931836605   |
| train_0/fw_loss           | 0.003542749094776809 |
| train_0/mu_grads          | -0.0638306349515915  |
| train_0/mu_grads_std      | 0.6197742819786072   |
| train_0/mu_loss           | 5.342980816753614    |
| train_0/next_q            | -5.339644601649182   |
| train_0/q_grads           | -0.08064847942441702 |
| train_0/q_grads_std       | 0.5581811279058456   |
| train_0/q_loss            | 0.192063813719706    |
| train_0/reward            | -0.6962647516586002  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.0049560546875      |
| train_0/target_q          | -5.630188174235252   |
| train_1/avg_q             | -9.542148478060192   |
| train_1/current_q         | -10.493067360320705  |
| train_1/fw_bonus          | -0.9806313738226891  |
| train_1/fw_loss           | 0.11757808364927769  |
| train_1/mu_grads          | -0.09567822776734829 |
| train_1/mu_grads_std      | 0.44342594742774966  |
| train_1/mu_loss           | 4.887540182914934    |
| train_1/n_subgoals        | 1500.0               |
| train_1/next_q            | -15.0                |
| train_1/q_grads           | -0.10361234303563834 |
| train_1/q_grads_std       | 0.6382213994860649   |
| train_1/q_loss            | 6.09177794131205     |
| train_1/reward            | -1.480183855301584   |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.002734375          |
| train_1/reward_-15.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -10.443379656082836  |
----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/AntFourRoomsEnv-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:15,15|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
