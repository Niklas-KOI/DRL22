Starting process id: 25979
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fb9515fcc20>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 15
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 717.64. Rollout time: 430.50, Training time: 287.10
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 80215.0                |
| test/episodes             | 15.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5613615855312416    |
| test_1/avg_q              | -19.655352952552658    |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.348491194801294     |
| train_0/current_q         | -1.9902379669795682    |
| train_0/fw_bonus          | -0.9990493938326835    |
| train_0/fw_loss           | 0.00023605341957591008 |
| train_0/mu_grads          | -0.006651334883645177  |
| train_0/mu_grads_std      | 0.14262251406908036    |
| train_0/mu_loss           | 1.8985944821243586     |
| train_0/next_q            | -1.910240047422699     |
| train_0/q_grads           | 0.03262011557817459    |
| train_0/q_grads_std       | 0.15488393008708953    |
| train_0/q_loss            | 0.45177155889653486    |
| train_0/reward            | -0.6211917924494628    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0048095703125        |
| train_0/target_q          | -2.359196396456672     |
| train_1/avg_q             | -15.265787694853698    |
| train_1/current_q         | -17.810037541948827    |
| train_1/fw_bonus          | -0.9987858384847641    |
| train_1/fw_loss           | 0.0015629212401108816  |
| train_1/mu_grads          | 0.022039140481501816   |
| train_1/mu_grads_std      | 0.08608988597989083    |
| train_1/mu_loss           | 21.0968870373711       |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -20.99345997978878     |
| train_1/q_grads           | 0.028705580299720167   |
| train_1/q_grads_std       | 0.24257974624633788    |
| train_1/q_loss            | 35.62632096272327      |
| train_1/reward            | -2.5441178463290273    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00380859375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.06481481481481481    |
| train_1/target_q          | -17.544272240109013    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 683.44. Rollout time: 463.45, Training time: 219.95
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 160774.0              |
| test/episodes             | 30.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -16.07491508590626    |
| test_1/avg_q              | -22.890993244999965   |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.04                  |
| train_0/avg_q             | -4.657247057551306    |
| train_0/current_q         | -5.1403431790230325   |
| train_0/fw_bonus          | -0.9987088039517402   |
| train_0/fw_loss           | 0.0003183829729096033 |
| train_0/mu_grads          | -0.011953719588927925 |
| train_0/mu_grads_std      | 0.1757603246718645    |
| train_0/mu_loss           | 5.148325982503829     |
| train_0/next_q            | -5.022468875828993    |
| train_0/q_grads           | 0.035318680480122565  |
| train_0/q_grads_std       | 0.1813174717128277    |
| train_0/q_loss            | 1.4554227176861818    |
| train_0/reward            | -0.6535346242359082   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00087890625         |
| train_0/target_q          | -4.875833462409546    |
| train_1/avg_q             | -22.644481992909814   |
| train_1/current_q         | -20.168723129762537   |
| train_1/fw_bonus          | -0.9986417323350907   |
| train_1/fw_loss           | 0.0016054770501796156 |
| train_1/mu_grads          | 0.022055068984627724  |
| train_1/mu_grads_std      | 0.08611967414617538   |
| train_1/mu_loss           | 23.464865885703933    |
| train_1/n_subgoals        | 2662.0                |
| train_1/next_q            | -23.409131137306115   |
| train_1/q_grads           | 0.023675062227994204  |
| train_1/q_grads_std       | 0.3258153319358826    |
| train_1/q_loss            | 19.062798366759985    |
| train_1/reward            | -2.5348533058062457   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0036865234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.04770848985725019   |
| train_1/target_q          | -20.03106310988995    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 643.11. Rollout time: 422.97, Training time: 220.08
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 230555.0              |
| test/episodes             | 45.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.646618327148703    |
| test_1/avg_q              | -24.22055894365784    |
| test_1/n_subgoals         | 6721.0                |
| test_1/subgoal_succ_rate  | 0.9869067103109657    |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.19                  |
| train_0/avg_q             | -10.402049686933028   |
| train_0/current_q         | -5.169369985576586    |
| train_0/fw_bonus          | -0.9985138639807701   |
| train_0/fw_loss           | 0.0003655060732853599 |
| train_0/mu_grads          | -0.013025771803222596 |
| train_0/mu_grads_std      | 0.20719044990837573   |
| train_0/mu_loss           | 4.94927768705597      |
| train_0/next_q            | -4.880723440352702    |
| train_0/q_grads           | 0.034431779943406585  |
| train_0/q_grads_std       | 0.18665999174118042   |
| train_0/q_loss            | 0.46967208203592303   |
| train_0/reward            | -0.6693977539263869   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000830078125        |
| train_0/target_q          | -5.058839652612429    |
| train_1/avg_q             | -23.2381987501161     |
| train_1/current_q         | -18.451701154928227   |
| train_1/fw_bonus          | -0.9979463696479798   |
| train_1/fw_loss           | 0.0018108262011082843 |
| train_1/mu_grads          | 0.022052393993362784  |
| train_1/mu_grads_std      | 0.08611663058400154   |
| train_1/mu_loss           | 20.796394122477395    |
| train_1/n_subgoals        | 2467.0                |
| train_1/next_q            | -20.738329375974672   |
| train_1/q_grads           | 0.018809070251882075  |
| train_1/q_grads_std       | 0.36490887999534605   |
| train_1/q_loss            | 14.457048122565457    |
| train_1/reward            | -2.5244804903912152   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0050048828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1580867450344548    |
| train_1/target_q          | -18.29362195411111    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 768.59. Rollout time: 501.38, Training time: 267.12
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 296825.0               |
| test/episodes             | 60.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.615822854061822     |
| test_1/avg_q              | -24.51894635830724     |
| test_1/n_subgoals         | 9443.0                 |
| test_1/subgoal_succ_rate  | 0.9952345652864556     |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.06                   |
| train_0/avg_q             | -8.505543767740303     |
| train_0/current_q         | -5.4639152921173055    |
| train_0/fw_bonus          | -0.9984919160604477    |
| train_0/fw_loss           | 0.00037081052432768046 |
| train_0/mu_grads          | -0.021769881946966052  |
| train_0/mu_grads_std      | 0.23121956661343573    |
| train_0/mu_loss           | 5.426417248108584      |
| train_0/next_q            | -5.253443265879744     |
| train_0/q_grads           | 0.03419551234692335    |
| train_0/q_grads_std       | 0.19194345325231552    |
| train_0/q_loss            | 0.7435070349534334     |
| train_0/reward            | -0.6797560374328896    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.002734375            |
| train_0/target_q          | -5.3844604359446295    |
| train_1/avg_q             | -23.198491628668283    |
| train_1/current_q         | -19.162606084946823    |
| train_1/fw_bonus          | -0.9977963969111443    |
| train_1/fw_loss           | 0.0018551190820289775  |
| train_1/mu_grads          | 0.02191290557384491    |
| train_1/mu_grads_std      | 0.08592421170324087    |
| train_1/mu_loss           | 21.562335773767742     |
| train_1/n_subgoals        | 2632.0                 |
| train_1/next_q            | -21.485238925072895    |
| train_1/q_grads           | 0.014810088509693741   |
| train_1/q_grads_std       | 0.386358293145895      |
| train_1/q_loss            | 11.906092002635052     |
| train_1/reward            | -2.429392942800405     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0052734375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.30775075987841943    |
| train_1/target_q          | -19.0210426787825      |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 519.60. Rollout time: 317.72, Training time: 201.84
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 354917.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5749295075588113    |
| test_1/avg_q              | -2.20013434287713      |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.25                   |
| train_0/avg_q             | -11.03350330471388     |
| train_0/current_q         | -3.2123840198052407    |
| train_0/fw_bonus          | -0.9984159991145134    |
| train_0/fw_loss           | 0.00038916406119824385 |
| train_0/mu_grads          | -0.035018949303776026  |
| train_0/mu_grads_std      | 0.26606459468603133    |
| train_0/mu_loss           | 3.1239968274703678     |
| train_0/next_q            | -3.039731940903183     |
| train_0/q_grads           | 0.03297347705811262    |
| train_0/q_grads_std       | 0.19982334412634373    |
| train_0/q_loss            | 0.6600757997653168     |
| train_0/reward            | -0.688141596837886     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0013916015625        |
| train_0/target_q          | -3.3800693139300435    |
| train_1/avg_q             | -16.989288737256423    |
| train_1/current_q         | -11.086311781971306    |
| train_1/fw_bonus          | -0.9977106004953384    |
| train_1/fw_loss           | 0.0018804516148520634  |
| train_1/mu_grads          | 0.0012004195566987618  |
| train_1/mu_grads_std      | 0.15388631597161292    |
| train_1/mu_loss           | 11.180025005403493     |
| train_1/n_subgoals        | 2325.0                 |
| train_1/next_q            | -11.240839086817811    |
| train_1/q_grads           | 0.01186639848165214    |
| train_1/q_grads_std       | 0.39284192845225335    |
| train_1/q_loss            | 18.922903952157053     |
| train_1/reward            | -2.356825111438593     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0051025390625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3367741935483871     |
| train_1/target_q          | -11.15938043037005     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 6323.03. Rollout time: 1984.21, Training time: 4338.78
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 412253.0               |
| test/episodes             | 90.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4044372526465874    |
| test_1/avg_q              | -4.2131699772044895    |
| test_1/n_subgoals         | 1173.0                 |
| test_1/subgoal_succ_rate  | 0.7050298380221653     |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -8.074890640314372     |
| train_0/current_q         | -5.114118434922022     |
| train_0/fw_bonus          | -0.9984147340059281    |
| train_0/fw_loss           | 0.00038946880085859447 |
| train_0/mu_grads          | -0.03949936917051673   |
| train_0/mu_grads_std      | 0.2932723768055439     |
| train_0/mu_loss           | 5.048532241696124      |
| train_0/next_q            | -4.93049631075924      |
| train_0/q_grads           | 0.031910148449242115   |
| train_0/q_grads_std       | 0.2090559933334589     |
| train_0/q_loss            | 0.7831015656572762     |
| train_0/reward            | -0.6938541723775415    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0011474609375        |
| train_0/target_q          | -5.069934606583459     |
| train_1/avg_q             | -8.697631160134657     |
| train_1/current_q         | -12.961562515888644    |
| train_1/fw_bonus          | -0.9980315759778022    |
| train_1/fw_loss           | 0.001785668946104124   |
| train_1/mu_grads          | 0.002156861464027315   |
| train_1/mu_grads_std      | 0.17787936329841614    |
| train_1/mu_loss           | 13.472479169007704     |
| train_1/n_subgoals        | 1923.0                 |
| train_1/next_q            | -13.585344764701158    |
| train_1/q_grads           | 0.00973489263560623    |
| train_1/q_grads_std       | 0.4064751848578453     |
| train_1/q_loss            | 13.959826064804588     |
| train_1/reward            | -2.3338706827373246    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0054443359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14508580343213728    |
| train_1/target_q          | -12.966061939049998    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 569.65. Rollout time: 351.23, Training time: 218.38
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 474391.0              |
| test/episodes             | 105.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.0325681013637298   |
| test_1/avg_q              | -9.59073925806753     |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -9.031484875630017    |
| train_0/current_q         | -5.140430111957196    |
| train_0/fw_bonus          | -0.9983466818928719   |
| train_0/fw_loss           | 0.0004059194267028943 |
| train_0/mu_grads          | -0.04664458222687244  |
| train_0/mu_grads_std      | 0.3194900445640087    |
| train_0/mu_loss           | 4.923290891697651     |
| train_0/next_q            | -4.814186563401788    |
| train_0/q_grads           | 0.024688069801777603  |
| train_0/q_grads_std       | 0.21986103877425195   |
| train_0/q_loss            | 0.5899888018736474    |
| train_0/reward            | -0.7114885260452866   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.001318359375        |
| train_0/target_q          | -5.03344894022093     |
| train_1/avg_q             | -10.658570910220698   |
| train_1/current_q         | -12.967568121855493   |
| train_1/fw_bonus          | -0.9970135897397995   |
| train_1/fw_loss           | 0.0020862909354036675 |
| train_1/mu_grads          | 0.0031716063269414006 |
| train_1/mu_grads_std      | 0.20756248719990253   |
| train_1/mu_loss           | 13.119641099717976    |
| train_1/n_subgoals        | 2117.0                |
| train_1/next_q            | -13.162430395549373   |
| train_1/q_grads           | 0.005375181802082807  |
| train_1/q_grads_std       | 0.41971272602677345   |
| train_1/q_loss            | 12.516376737199872    |
| train_1/reward            | -2.3357219016692397   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00498046875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14454416627302788   |
| train_1/target_q          | -13.015649877057246   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 3379.20. Rollout time: 3174.67, Training time: 204.49
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 554459.0              |
| test/episodes             | 120.0                 |
| test/success_rate         | 0.13333333333333333   |
| test_0/avg_q              | -1.721651549747174    |
| test_1/avg_q              | -6.9755118112872765   |
| test_1/n_subgoals         | 395.0                 |
| test_1/subgoal_succ_rate  | 0.002531645569620253  |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.06                  |
| train_0/avg_q             | -5.875983622479616    |
| train_0/current_q         | -5.636458440174546    |
| train_0/fw_bonus          | -0.9984629184007645   |
| train_0/fw_loss           | 0.0003778219535888638 |
| train_0/mu_grads          | -0.052343246154487134 |
| train_0/mu_grads_std      | 0.33324733227491377   |
| train_0/mu_loss           | 5.459497202064772     |
| train_0/next_q            | -5.301076486415671    |
| train_0/q_grads           | 0.023557812627404928  |
| train_0/q_grads_std       | 0.22653050534427166   |
| train_0/q_loss            | 0.6335748564741251    |
| train_0/reward            | -0.7292055732632434   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.002734375           |
| train_0/target_q          | -5.54709705171023     |
| train_1/avg_q             | -12.311481707582168   |
| train_1/current_q         | -13.282943403795457   |
| train_1/fw_bonus          | -0.996122607588768    |
| train_1/fw_loss           | 0.0023494015447795393 |
| train_1/mu_grads          | 0.0025892964680679143 |
| train_1/mu_grads_std      | 0.22936543114483357   |
| train_1/mu_loss           | 13.285069715915835    |
| train_1/n_subgoals        | 2610.0                |
| train_1/next_q            | -13.399443494802549   |
| train_1/q_grads           | -0.002133188670268282 |
| train_1/q_grads_std       | 0.4319709241390228    |
| train_1/q_loss            | 13.038477353031453    |
| train_1/reward            | -2.3141307541744025   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0056640625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.023371647509578545  |
| train_1/target_q          | -13.332071689346611   |
-----------------------------------------------------
New best value for test/success_rate: 0.13333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 8
Time for epoch 8: 27504.00. Rollout time: 26355.06, Training time: 1148.87
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 615565.0               |
| test/episodes             | 135.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0132233159960302    |
| test_1/avg_q              | -10.860249250954956    |
| test_1/n_subgoals         | 1350.0                 |
| test_1/subgoal_succ_rate  | 0.7288888888888889     |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -9.215159789801886     |
| train_0/current_q         | -4.838940531903061     |
| train_0/fw_bonus          | -0.9984795898199081    |
| train_0/fw_loss           | 0.00037379158311523497 |
| train_0/mu_grads          | -0.0560053669847548    |
| train_0/mu_grads_std      | 0.3498483061790466     |
| train_0/mu_loss           | 4.623224392803534      |
| train_0/next_q            | -4.483603368661648     |
| train_0/q_grads           | 0.025295689469203353   |
| train_0/q_grads_std       | 0.23573194853961468    |
| train_0/q_loss            | 0.5208321431732834     |
| train_0/reward            | -0.731992944538797     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0050048828125        |
| train_0/target_q          | -4.866001250010358     |
| train_1/avg_q             | -13.189080352732741    |
| train_1/current_q         | -7.621857241658342     |
| train_1/fw_bonus          | -0.9967195659875869    |
| train_1/fw_loss           | 0.0021731214335886763  |
| train_1/mu_grads          | 0.007424007961526513   |
| train_1/mu_grads_std      | 0.25139090269804       |
| train_1/mu_loss           | 6.953115477482103      |
| train_1/n_subgoals        | 2033.0                 |
| train_1/next_q            | -6.935543281716309     |
| train_1/q_grads           | -0.010375620564445853  |
| train_1/q_grads_std       | 0.44508726224303247    |
| train_1/q_loss            | 8.704189079733698      |
| train_1/reward            | -2.3837135811347254    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0053466796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1205115592720118     |
| train_1/target_q          | -7.822335668636724     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 9
Time for epoch 9: 638.54. Rollout time: 408.30, Training time: 230.20
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 682517.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.7821555798390744   |
| test_1/avg_q              | -9.026418459625548    |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.34                  |
| train_0/avg_q             | -7.708308242445853    |
| train_0/current_q         | -4.962773286925602    |
| train_0/fw_bonus          | -0.9986050516366959   |
| train_0/fw_loss           | 0.0003434653386648279 |
| train_0/mu_grads          | -0.06220429418608546  |
| train_0/mu_grads_std      | 0.36374539211392404   |
| train_0/mu_loss           | 4.751652860664763     |
| train_0/next_q            | -4.616235776909878    |
| train_0/q_grads           | 0.025743654230609536  |
| train_0/q_grads_std       | 0.24268451221287252   |
| train_0/q_loss            | 0.584357065678818     |
| train_0/reward            | -0.7350638592979521   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0127197265625       |
| train_0/target_q          | -4.9263313158332425   |
| train_1/avg_q             | -13.837290827560519   |
| train_1/current_q         | -13.34603810819559    |
| train_1/fw_bonus          | -0.9969374507665634   |
| train_1/fw_loss           | 0.002108772029168904  |
| train_1/mu_grads          | 0.005583819502498954  |
| train_1/mu_grads_std      | 0.2788725525140762    |
| train_1/mu_loss           | 13.543805943687005    |
| train_1/n_subgoals        | 2307.0                |
| train_1/next_q            | -13.489821423663168   |
| train_1/q_grads           | -0.014700197987258435 |
| train_1/q_grads_std       | 0.45470637157559396   |
| train_1/q_loss            | 15.072062111900445    |
| train_1/reward            | -2.3610629781403984   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0061767578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14651061985262245   |
| train_1/target_q          | -13.522078865141015   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 10
Time for epoch 10: 549.53. Rollout time: 338.81, Training time: 210.68
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 746444.0              |
| test/episodes             | 165.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.6414943316214412   |
| test_1/avg_q              | -6.5153852097146245   |
| test_1/n_subgoals         | 1684.0                |
| test_1/subgoal_succ_rate  | 0.7915676959619953    |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.32                  |
| train_0/avg_q             | -7.409876007343211    |
| train_0/current_q         | -4.353288825381576    |
| train_0/fw_bonus          | -0.9986472383141518   |
| train_0/fw_loss           | 0.0003332624284666963 |
| train_0/mu_grads          | -0.06494391523301601  |
| train_0/mu_grads_std      | 0.37980861887335776   |
| train_0/mu_loss           | 4.127346433867237     |
| train_0/next_q            | -4.002253152667284    |
| train_0/q_grads           | 0.026413257420063018  |
| train_0/q_grads_std       | 0.2520150125026703    |
| train_0/q_loss            | 0.5170542664252725    |
| train_0/reward            | -0.741043649630592    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0131103515625       |
| train_0/target_q          | -4.340967060477904    |
| train_1/avg_q             | -15.356641700626788   |
| train_1/current_q         | -12.536537160864158   |
| train_1/fw_bonus          | -0.9970248565077782   |
| train_1/fw_loss           | 0.002082961623091251  |
| train_1/mu_grads          | 0.004666213551536203  |
| train_1/mu_grads_std      | 0.29435724914073946   |
| train_1/mu_loss           | 12.21618902092953     |
| train_1/n_subgoals        | 2293.0                |
| train_1/next_q            | -12.197961976212111   |
| train_1/q_grads           | -0.018104242254048587 |
| train_1/q_grads_std       | 0.4659392349421978    |
| train_1/q_loss            | 18.394991176257367    |
| train_1/reward            | -2.4271859014257644   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0068603515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21631051024858264   |
| train_1/target_q          | -12.646592444280973   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 11
Time for epoch 11: 575.20. Rollout time: 361.91, Training time: 213.25
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 812687.0              |
| test/episodes             | 180.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.198363807087904    |
| test_1/avg_q              | -12.53906912630418    |
| test_1/n_subgoals         | 2919.0                |
| test_1/subgoal_succ_rate  | 0.8955121616992121    |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.35                  |
| train_0/avg_q             | -7.478001748049157    |
| train_0/current_q         | -4.210676673896076    |
| train_0/fw_bonus          | -0.9986292123794556   |
| train_0/fw_loss           | 0.0003376235676114447 |
| train_0/mu_grads          | -0.06256072269752622  |
| train_0/mu_grads_std      | 0.3961888812482357    |
| train_0/mu_loss           | 4.011620341177067     |
| train_0/next_q            | -3.9055634442400446   |
| train_0/q_grads           | 0.02740140906535089   |
| train_0/q_grads_std       | 0.25902939811348913   |
| train_0/q_loss            | 0.8094445969301741    |
| train_0/reward            | -0.7377981723890116   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.021142578125        |
| train_0/target_q          | -4.114712236783726    |
| train_1/avg_q             | -13.1386131802937     |
| train_1/current_q         | -13.343074192376292   |
| train_1/fw_bonus          | -0.997280566394329    |
| train_1/fw_loss           | 0.0020074460218893362 |
| train_1/mu_grads          | 0.006265527743380517  |
| train_1/mu_grads_std      | 0.3167696751654148    |
| train_1/mu_loss           | 13.386059262497156    |
| train_1/n_subgoals        | 2280.0                |
| train_1/next_q            | -13.298503348682777   |
| train_1/q_grads           | -0.020034776581451298 |
| train_1/q_grads_std       | 0.48006136417388917   |
| train_1/q_loss            | 12.390339997760544    |
| train_1/reward            | -2.360764233919326    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.005908203125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14605263157894738   |
| train_1/target_q          | -13.42839899745421    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 493.25. Rollout time: 282.81, Training time: 210.41
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 865126.0               |
| test/episodes             | 195.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.8428132696641284    |
| test_1/avg_q              | -7.116725134680946     |
| test_1/n_subgoals         | 1801.0                 |
| test_1/subgoal_succ_rate  | 0.8051082731815657     |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.6                    |
| train_0/avg_q             | -6.846912344807878     |
| train_0/current_q         | -4.818433770615348     |
| train_0/fw_bonus          | -0.9986828446388245    |
| train_0/fw_loss           | 0.00032465826952829955 |
| train_0/mu_grads          | -0.06364803183823824   |
| train_0/mu_grads_std      | 0.4120787687599659     |
| train_0/mu_loss           | 4.571123092227975      |
| train_0/next_q            | -4.486090367562199     |
| train_0/q_grads           | 0.02785702901892364    |
| train_0/q_grads_std       | 0.26368448957800866    |
| train_0/q_loss            | 0.737527712170212      |
| train_0/reward            | -0.7398623627810593    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.01708984375          |
| train_0/target_q          | -4.725606740729094     |
| train_1/avg_q             | -13.142932862614641    |
| train_1/current_q         | -13.007953506993356    |
| train_1/fw_bonus          | -0.9976776495575905    |
| train_1/fw_loss           | 0.0018901816598372533  |
| train_1/mu_grads          | 0.004698430781718344   |
| train_1/mu_grads_std      | 0.3407349564135075     |
| train_1/mu_loss           | 12.692622804857592     |
| train_1/n_subgoals        | 1852.0                 |
| train_1/next_q            | -12.714845058561824    |
| train_1/q_grads           | -0.02358903721906245   |
| train_1/q_grads_std       | 0.49385140240192416    |
| train_1/q_loss            | 11.242968317255228     |
| train_1/reward            | -2.4156120428942813    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005908203125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23704103671706264    |
| train_1/target_q          | -12.983303260293876    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 470.93. Rollout time: 275.58, Training time: 195.32
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 13                    |
| policy/steps              | 918270.0              |
| test/episodes             | 210.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5587374445796267   |
| test_1/avg_q              | -1.3224990678474664   |
| test_1/n_subgoals         | 1102.0                |
| test_1/subgoal_succ_rate  | 0.6569872958257713    |
| train/episodes            | 1400.0                |
| train/success_rate        | 0.65                  |
| train_0/avg_q             | -7.380296015405506    |
| train_0/current_q         | -4.966422165982986    |
| train_0/fw_bonus          | -0.9987913563847541   |
| train_0/fw_loss           | 0.0002984291459142696 |
| train_0/mu_grads          | -0.06887843068689108  |
| train_0/mu_grads_std      | 0.4189054764807224    |
| train_0/mu_loss           | 4.744074003013645     |
| train_0/next_q            | -4.592190010937221    |
| train_0/q_grads           | 0.027857131138443948  |
| train_0/q_grads_std       | 0.2696631126105785    |
| train_0/q_loss            | 0.5943405859044641    |
| train_0/reward            | -0.7360076532422681   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02578125            |
| train_0/target_q          | -4.8774167830975      |
| train_1/avg_q             | -12.946627965247597   |
| train_1/current_q         | -13.028616044904577   |
| train_1/fw_bonus          | -0.9977842062711716   |
| train_1/fw_loss           | 0.001858714476111345  |
| train_1/mu_grads          | 0.004414805700071156  |
| train_1/mu_grads_std      | 0.3624305695295334    |
| train_1/mu_loss           | 12.72441398221998     |
| train_1/n_subgoals        | 1834.0                |
| train_1/next_q            | -12.812473671809107   |
| train_1/q_grads           | -0.027093420596793295 |
| train_1/q_grads_std       | 0.5079872116446496    |
| train_1/q_loss            | 12.448813458010026    |
| train_1/reward            | -2.3349074789515725   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0052734375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2197382769901854    |
| train_1/target_q          | -12.978003653438602   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 457.89. Rollout time: 258.35, Training time: 199.50
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 969240.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.8096085784697165   |
| test_1/avg_q              | -4.659672030858011    |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.71                  |
| train_0/avg_q             | -9.066885430619607    |
| train_0/current_q         | -5.145233126177777    |
| train_0/fw_bonus          | -0.9988353759050369   |
| train_0/fw_loss           | 0.0002877858554711565 |
| train_0/mu_grads          | -0.07175533398985863  |
| train_0/mu_grads_std      | 0.4302035927772522    |
| train_0/mu_loss           | 4.966372686228811     |
| train_0/next_q            | -4.794614889730307    |
| train_0/q_grads           | 0.028057136898860337  |
| train_0/q_grads_std       | 0.2781755685806274    |
| train_0/q_loss            | 0.5890992285917485    |
| train_0/reward            | -0.732338240975514    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0299072265625       |
| train_0/target_q          | -5.0675866827197025   |
| train_1/avg_q             | -10.37531071547121    |
| train_1/current_q         | -12.41236939040543    |
| train_1/fw_bonus          | -0.998255880177021    |
| train_1/fw_loss           | 0.0017194233485497534 |
| train_1/mu_grads          | 0.0019192310544895008 |
| train_1/mu_grads_std      | 0.36997768804430964   |
| train_1/mu_loss           | 12.064086186657784    |
| train_1/n_subgoals        | 1783.0                |
| train_1/next_q            | -12.081494050207974   |
| train_1/q_grads           | -0.03339590951800346  |
| train_1/q_grads_std       | 0.5154801279306411    |
| train_1/q_loss            | 12.422956997532498    |
| train_1/reward            | -2.3297336474344776   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0052490234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.25294447560291644   |
| train_1/target_q          | -12.32521464117782    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 466.27. Rollout time: 261.39, Training time: 204.84
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 1020604.0              |
| test/episodes             | 240.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.596834271532559     |
| test_1/avg_q              | -9.44845500147386      |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -9.076810323061261     |
| train_0/current_q         | -5.5309930307154875    |
| train_0/fw_bonus          | -0.9987580373883247    |
| train_0/fw_loss           | 0.00030648389110865537 |
| train_0/mu_grads          | -0.07589851189404725   |
| train_0/mu_grads_std      | 0.43988236859440805    |
| train_0/mu_loss           | 5.351260519820783      |
| train_0/next_q            | -5.200830186619244     |
| train_0/q_grads           | 0.02856289460323751    |
| train_0/q_grads_std       | 0.28676658421754836    |
| train_0/q_loss            | 0.6909221263409493     |
| train_0/reward            | -0.734131647331742     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0265869140625        |
| train_0/target_q          | -5.454506298167392     |
| train_1/avg_q             | -12.344642181795656    |
| train_1/current_q         | -11.527307558852826    |
| train_1/fw_bonus          | -0.9986502259969712    |
| train_1/fw_loss           | 0.0016029691469157115  |
| train_1/mu_grads          | 0.001354538049781695   |
| train_1/mu_grads_std      | 0.3831082426011562     |
| train_1/mu_loss           | 11.258202087258812     |
| train_1/n_subgoals        | 1769.0                 |
| train_1/next_q            | -11.155041977130299    |
| train_1/q_grads           | -0.033660557214170696  |
| train_1/q_grads_std       | 0.5256120324134826     |
| train_1/q_loss            | 9.819628794944034      |
| train_1/reward            | -2.2986859950146026    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005224609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23968343697003958    |
| train_1/target_q          | -11.50516476344156     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 488.94. Rollout time: 286.19, Training time: 202.70
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1075751.0              |
| test/episodes             | 255.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.415424620441942     |
| test_1/avg_q              | -6.2951661387239195    |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -9.760224925334652     |
| train_0/current_q         | -5.350989904576371     |
| train_0/fw_bonus          | -0.9988091006875038    |
| train_0/fw_loss           | 0.00029413982556434346 |
| train_0/mu_grads          | -0.08377397861331701   |
| train_0/mu_grads_std      | 0.45072354227304456    |
| train_0/mu_loss           | 5.226127692748506      |
| train_0/next_q            | -5.06104838977051      |
| train_0/q_grads           | 0.02864570147357881    |
| train_0/q_grads_std       | 0.29473005831241605    |
| train_0/q_loss            | 0.6914406116100726     |
| train_0/reward            | -0.7318922163678507    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.02607421875          |
| train_0/target_q          | -5.32531653306219      |
| train_1/avg_q             | -14.577690609311912    |
| train_1/current_q         | -10.902464617399241    |
| train_1/fw_bonus          | -0.9985634326934815    |
| train_1/fw_loss           | 0.0016285995923681184  |
| train_1/mu_grads          | 0.00048658434679964556 |
| train_1/mu_grads_std      | 0.39728361293673514    |
| train_1/mu_loss           | 10.864868156106885     |
| train_1/n_subgoals        | 1981.0                 |
| train_1/next_q            | -10.786854400306689    |
| train_1/q_grads           | -0.034199808817356826  |
| train_1/q_grads_std       | 0.5376287057995797     |
| train_1/q_loss            | 12.895763539520539     |
| train_1/reward            | -2.2382394926018607    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005224609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25896012115093386    |
| train_1/target_q          | -11.041393094340057    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 549.36. Rollout time: 313.06, Training time: 236.26
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1131074.0             |
| test/episodes             | 270.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.2530018542500825   |
| test_1/avg_q              | -12.486627690145548   |
| test_1/n_subgoals         | 3181.0                |
| test_1/subgoal_succ_rate  | 0.9298962590380383    |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.38                  |
| train_0/avg_q             | -8.694094469804854    |
| train_0/current_q         | -5.542280183676019    |
| train_0/fw_bonus          | -0.9988682255148887   |
| train_0/fw_loss           | 0.0002798487817926798 |
| train_0/mu_grads          | -0.08376531768590212  |
| train_0/mu_grads_std      | 0.46263581737875936   |
| train_0/mu_loss           | 5.352315761600506     |
| train_0/next_q            | -5.21455085103072     |
| train_0/q_grads           | 0.029465628368780018  |
| train_0/q_grads_std       | 0.3004899531602859    |
| train_0/q_loss            | 0.6991010230474316    |
| train_0/reward            | -0.7371621233720361   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0277587890625       |
| train_0/target_q          | -5.438627290809597    |
| train_1/avg_q             | -12.136683659894523   |
| train_1/current_q         | -12.67370266457085    |
| train_1/fw_bonus          | -0.9981268957257271   |
| train_1/fw_loss           | 0.001757514404016547  |
| train_1/mu_grads          | 0.0005251037800917402 |
| train_1/mu_grads_std      | 0.40415604412555695   |
| train_1/mu_loss           | 13.112447966248434    |
| train_1/n_subgoals        | 2173.0                |
| train_1/next_q            | -12.959165372413537   |
| train_1/q_grads           | -0.035073413699865344 |
| train_1/q_grads_std       | 0.5503691658377647    |
| train_1/q_loss            | 7.271776657000588     |
| train_1/reward            | -2.206654527658247    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006005859375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3373216751035435    |
| train_1/target_q          | -12.759160611908365   |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 18
Time for epoch 18: 465.93. Rollout time: 246.08, Training time: 219.81
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 1171656.0             |
| test/episodes             | 285.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -2.0909922069512943   |
| test_1/avg_q              | -14.527891079973289   |
| test_1/n_subgoals         | 987.0                 |
| test_1/subgoal_succ_rate  | 0.7315096251266464    |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -9.115169223566456    |
| train_0/current_q         | -5.889500265756838    |
| train_0/fw_bonus          | -0.9988563194870949   |
| train_0/fw_loss           | 0.0002827275766321691 |
| train_0/mu_grads          | -0.09232903644442558  |
| train_0/mu_grads_std      | 0.46827245205640794   |
| train_0/mu_loss           | 5.701527940537053     |
| train_0/next_q            | -5.551094952427009    |
| train_0/q_grads           | 0.03094774140045047   |
| train_0/q_grads_std       | 0.30978885740041734   |
| train_0/q_loss            | 0.6482914030637128    |
| train_0/reward            | -0.7395212066650856   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0476318359375       |
| train_0/target_q          | -5.800165679271215    |
| train_1/avg_q             | -14.108641105044839   |
| train_1/current_q         | -12.088966043350291   |
| train_1/fw_bonus          | -0.9985497400164605   |
| train_1/fw_loss           | 0.0016326442157151178 |
| train_1/mu_grads          | -0.001103081277688034 |
| train_1/mu_grads_std      | 0.4152548976242542    |
| train_1/mu_loss           | 12.464386876836448    |
| train_1/n_subgoals        | 1817.0                |
| train_1/next_q            | -12.304969016823446   |
| train_1/q_grads           | -0.03745330264791846  |
| train_1/q_grads_std       | 0.5621716812252998    |
| train_1/q_loss            | 7.026845459442299     |
| train_1/reward            | -2.135605452650998    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0060546875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.5101816180517337    |
| train_1/target_q          | -12.198596310172164   |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 19
Time for epoch 19: 427.57. Rollout time: 203.46, Training time: 224.07
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1211390.0              |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.2024428801784666    |
| test_1/avg_q              | -15.500217428449096    |
| test_1/n_subgoals         | 9441.0                 |
| test_1/subgoal_succ_rate  | 0.9971401334604385     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.74                   |
| train_0/avg_q             | -10.919581323899562    |
| train_0/current_q         | -5.876362265127969     |
| train_0/fw_bonus          | -0.9987792402505875    |
| train_0/fw_loss           | 0.00030135898523440117 |
| train_0/mu_grads          | -0.09679889846593141   |
| train_0/mu_grads_std      | 0.4803704500198364     |
| train_0/mu_loss           | 5.6651559999522        |
| train_0/next_q            | -5.519482921258513     |
| train_0/q_grads           | 0.031878305971622466   |
| train_0/q_grads_std       | 0.3176340401172638     |
| train_0/q_loss            | 0.5576718720969926     |
| train_0/reward            | -0.7393188322592323    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05576171875          |
| train_0/target_q          | -5.8090599797828935    |
| train_1/avg_q             | -13.404806806880652    |
| train_1/current_q         | -11.092876193220945    |
| train_1/fw_bonus          | -0.9985336363315582    |
| train_1/fw_loss           | 0.0016373992228182032  |
| train_1/mu_grads          | -0.002044878527522087  |
| train_1/mu_grads_std      | 0.4237289637327194     |
| train_1/mu_loss           | 11.189657121924787     |
| train_1/n_subgoals        | 1541.0                 |
| train_1/next_q            | -11.02248548102238     |
| train_1/q_grads           | -0.04159619649872184   |
| train_1/q_grads_std       | 0.5701197817921638     |
| train_1/q_loss            | 7.012383823826248      |
| train_1/reward            | -2.069189073568123     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0059326171875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.41920830629461386    |
| train_1/target_q          | -11.176092237554936    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 20
Time for epoch 20: 535.50. Rollout time: 291.54, Training time: 243.92
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1259349.0             |
| test/episodes             | 315.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.909211750527346    |
| test_1/avg_q              | -0.17176612749848688  |
| test_1/n_subgoals         | 386.0                 |
| test_1/subgoal_succ_rate  | 0.0051813471502590676 |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -9.706644577753224    |
| train_0/current_q         | -5.582180446221857    |
| train_0/fw_bonus          | -0.9988249123096467   |
| train_0/fw_loss           | 0.0002903186938056024 |
| train_0/mu_grads          | -0.09993477184325457  |
| train_0/mu_grads_std      | 0.48655603900551797   |
| train_0/mu_loss           | 5.391362330852916     |
| train_0/next_q            | -5.215716025387037    |
| train_0/q_grads           | 0.03205328769981861   |
| train_0/q_grads_std       | 0.3243348255753517    |
| train_0/q_loss            | 0.6895576791587207    |
| train_0/reward            | -0.7434501233194168   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04033203125         |
| train_0/target_q          | -5.452952527963267    |
| train_1/avg_q             | -15.198953754948567   |
| train_1/current_q         | -6.3654267775523685   |
| train_1/fw_bonus          | -0.9988743022084237   |
| train_1/fw_loss           | 0.0015367972489912062 |
| train_1/mu_grads          | -0.00251461974112317  |
| train_1/mu_grads_std      | 0.4277710810303688    |
| train_1/mu_loss           | 5.804214365863303     |
| train_1/n_subgoals        | 2110.0                |
| train_1/next_q            | -5.801514800030207    |
| train_1/q_grads           | -0.040649257879704234 |
| train_1/q_grads_std       | 0.578245097398758     |
| train_1/q_loss            | 16.61592691389824     |
| train_1/reward            | -1.9857415245409356   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.005224609375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.46350710900473935   |
| train_1/target_q          | -6.963814982649211    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_20.pkl ...
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.16666666666666669
Training epoch 21
Time for epoch 21: 483.14. Rollout time: 246.52, Training time: 236.56
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 1305468.0             |
| test/episodes             | 330.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.9167149227271674   |
| test_1/avg_q              | -13.397900602551939   |
| test_1/n_subgoals         | 3914.0                |
| test_1/subgoal_succ_rate  | 0.9317833418497701    |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -8.06574119188226     |
| train_0/current_q         | -3.588895061314507    |
| train_0/fw_bonus          | -0.9988387793302536   |
| train_0/fw_loss           | 0.0002869663640012732 |
| train_0/mu_grads          | -0.10059977620840073  |
| train_0/mu_grads_std      | 0.49532950595021247   |
| train_0/mu_loss           | 3.4688066663949657    |
| train_0/next_q            | -3.2620981192655094   |
| train_0/q_grads           | 0.03160802312195301   |
| train_0/q_grads_std       | 0.3246641978621483    |
| train_0/q_loss            | 0.593287597803168     |
| train_0/reward            | -0.7425563736029289   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0390869140625       |
| train_0/target_q          | -3.64532440973786     |
| train_1/avg_q             | -8.831690494569749    |
| train_1/current_q         | -10.230835069758054   |
| train_1/fw_bonus          | -0.9986761286854744   |
| train_1/fw_loss           | 0.0015953224821714685 |
| train_1/mu_grads          | -0.004194230330176652 |
| train_1/mu_grads_std      | 0.4325281158089638    |
| train_1/mu_loss           | 10.109582152095907    |
| train_1/n_subgoals        | 1582.0                |
| train_1/next_q            | -9.853175056858452    |
| train_1/q_grads           | -0.04171384172514081  |
| train_1/q_grads_std       | 0.5862643748521805    |
| train_1/q_loss            | 7.514422224324809     |
| train_1/reward            | -1.9744126827132278   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0058837890625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2579013906447535    |
| train_1/target_q          | -10.302318015814643   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 22
Time for epoch 22: 488.31. Rollout time: 275.45, Training time: 212.81
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 1358600.0              |
| test/episodes             | 345.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.392713474902955     |
| test_1/avg_q              | -10.412540051809861    |
| test_1/n_subgoals         | 814.0                  |
| test_1/subgoal_succ_rate  | 0.5221130221130221     |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -7.657084492071516     |
| train_0/current_q         | -5.11406151853005      |
| train_0/fw_bonus          | -0.9989703565835952    |
| train_0/fw_loss           | 0.0002551588491769508  |
| train_0/mu_grads          | -0.10489048529416323   |
| train_0/mu_grads_std      | 0.5002997815608978     |
| train_0/mu_loss           | 4.929964579970715      |
| train_0/next_q            | -4.745361845684985     |
| train_0/q_grads           | 0.031429572775959966   |
| train_0/q_grads_std       | 0.32763679772615434    |
| train_0/q_loss            | 0.7091326526051333     |
| train_0/reward            | -0.7542530879734841    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0747314453125        |
| train_0/target_q          | -5.004617326873379     |
| train_1/avg_q             | -12.640230389522664    |
| train_1/current_q         | -10.28345354894636     |
| train_1/fw_bonus          | -0.9985707610845566    |
| train_1/fw_loss           | 0.0016264345118543132  |
| train_1/mu_grads          | -0.0046395922196097675 |
| train_1/mu_grads_std      | 0.4395910367369652     |
| train_1/mu_loss           | 10.103934076154093     |
| train_1/n_subgoals        | 1897.0                 |
| train_1/next_q            | -9.924671249826936     |
| train_1/q_grads           | -0.042041008733212946  |
| train_1/q_grads_std       | 0.595836840569973      |
| train_1/q_loss            | 7.278351004717223      |
| train_1/reward            | -1.971969351111693     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006787109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27148128624143386    |
| train_1/target_q          | -10.405512637097043    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 23
Time for epoch 23: 497.50. Rollout time: 284.99, Training time: 212.47
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 1417083.0             |
| test/episodes             | 360.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.9265846555766686   |
| test_1/avg_q              | -5.811359890579259    |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.39                  |
| train_0/avg_q             | -7.312549715208367    |
| train_0/current_q         | -2.8276160385385585   |
| train_0/fw_bonus          | -0.9989584505558013   |
| train_0/fw_loss           | 0.0002580383625172544 |
| train_0/mu_grads          | -0.10616011023521424  |
| train_0/mu_grads_std      | 0.5050748765468598    |
| train_0/mu_loss           | 2.6223011567883536    |
| train_0/next_q            | -2.6114596493076876   |
| train_0/q_grads           | 0.031474196910858156  |
| train_0/q_grads_std       | 0.3307769998908043    |
| train_0/q_loss            | 0.971892504285284     |
| train_0/reward            | -0.7584615356983704   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.06494140625         |
| train_0/target_q          | -3.098683653441202    |
| train_1/avg_q             | -13.830694819253463   |
| train_1/current_q         | -10.748216116811362   |
| train_1/fw_bonus          | -0.9982377126812935   |
| train_1/fw_loss           | 0.001724791675223969  |
| train_1/mu_grads          | -0.006039036193396896 |
| train_1/mu_grads_std      | 0.45168304070830345   |
| train_1/mu_loss           | 10.53229368203723     |
| train_1/n_subgoals        | 2103.0                |
| train_1/next_q            | -10.349067975101388   |
| train_1/q_grads           | -0.04485536385327578  |
| train_1/q_grads_std       | 0.6059566766023636    |
| train_1/q_loss            | 7.567770020033106     |
| train_1/reward            | -1.994316506552059    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00576171875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.25202092249167857   |
| train_1/target_q          | -10.848919216291268   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 24
Time for epoch 24: 558.05. Rollout time: 315.21, Training time: 242.80
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 1473372.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -2.7047440474162765   |
| test_1/avg_q              | -9.020717707793384    |
| test_1/n_subgoals         | 1534.0                |
| test_1/subgoal_succ_rate  | 0.8239895697522817    |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.45                  |
| train_0/avg_q             | -6.676278620517226    |
| train_0/current_q         | -5.667424554040882    |
| train_0/fw_bonus          | -0.9989540681242943   |
| train_0/fw_loss           | 0.0002590983214759035 |
| train_0/mu_grads          | -0.10511027574539185  |
| train_0/mu_grads_std      | 0.5106586188077926    |
| train_0/mu_loss           | 5.493912856472084     |
| train_0/next_q            | -5.291129155561911    |
| train_0/q_grads           | 0.031641266867518426  |
| train_0/q_grads_std       | 0.3345998957753181    |
| train_0/q_loss            | 0.610042378750649     |
| train_0/reward            | -0.7648691308018897   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.043798828125        |
| train_0/target_q          | -5.597266980474143    |
| train_1/avg_q             | -13.565066960730574   |
| train_1/current_q         | -10.592873049805785   |
| train_1/fw_bonus          | -0.998767314851284    |
| train_1/fw_loss           | 0.0015683938487200066 |
| train_1/mu_grads          | -0.007599730859510601 |
| train_1/mu_grads_std      | 0.4611886151134968    |
| train_1/mu_loss           | 10.385844729726733    |
| train_1/n_subgoals        | 2042.0                |
| train_1/next_q            | -10.194469012546197   |
| train_1/q_grads           | -0.046898191701620816 |
| train_1/q_grads_std       | 0.6157291471958161    |
| train_1/q_loss            | 5.262947856442411     |
| train_1/reward            | -1.9609039853872674   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006201171875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21890303623898139   |
| train_1/target_q          | -10.701157891205979   |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 25
Time for epoch 25: 433.77. Rollout time: 230.85, Training time: 202.88
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 25                     |
| policy/steps              | 1522651.0              |
| test/episodes             | 390.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5205556978653303    |
| test_1/avg_q              | -18.699600863571767    |
| test_1/n_subgoals         | 1799.0                 |
| test_1/subgoal_succ_rate  | 0.8048916064480267     |
| train/episodes            | 2600.0                 |
| train/success_rate        | 0.64                   |
| train_0/avg_q             | -9.488566315925521     |
| train_0/current_q         | -5.492675474436252     |
| train_0/fw_bonus          | -0.9990921422839165    |
| train_0/fw_loss           | 0.00022572094021597878 |
| train_0/mu_grads          | -0.10650007873773575   |
| train_0/mu_grads_std      | 0.5166103839874268     |
| train_0/mu_loss           | 5.328559751121265      |
| train_0/next_q            | -5.176000726950752     |
| train_0/q_grads           | 0.031444246787577866   |
| train_0/q_grads_std       | 0.3371467560529709     |
| train_0/q_loss            | 0.8279273963704075     |
| train_0/reward            | -0.7723926640032005    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.09296875             |
| train_0/target_q          | -5.504998746150181     |
| train_1/avg_q             | -13.815304041564978    |
| train_1/current_q         | -10.309497653738742    |
| train_1/fw_bonus          | -0.9988194450736045    |
| train_1/fw_loss           | 0.0015529998869169503  |
| train_1/mu_grads          | -0.00830836973618716   |
| train_1/mu_grads_std      | 0.4713213749229908     |
| train_1/mu_loss           | 10.187156208228348     |
| train_1/n_subgoals        | 1830.0                 |
| train_1/next_q            | -9.897360580404388     |
| train_1/q_grads           | -0.04739004531875253   |
| train_1/q_grads_std       | 0.6244000405073166     |
| train_1/q_loss            | 14.141703083957598     |
| train_1/reward            | -2.0110512941661       |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0056884765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.333879781420765      |
| train_1/target_q          | -10.428343899455449    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 26
Time for epoch 26: 468.72. Rollout time: 249.55, Training time: 219.13
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1571622.0              |
| test/episodes             | 405.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -2.356317275848128     |
| test_1/avg_q              | -16.108710319971106    |
| test_1/n_subgoals         | 2153.0                 |
| test_1/subgoal_succ_rate  | 0.8718067812354854     |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -10.525605153234505    |
| train_0/current_q         | -5.837960493725998     |
| train_0/fw_bonus          | -0.9991124361753464    |
| train_0/fw_loss           | 0.00022081417591834906 |
| train_0/mu_grads          | -0.1071332035586238    |
| train_0/mu_grads_std      | 0.5226440548896789     |
| train_0/mu_loss           | 5.72441218553611       |
| train_0/next_q            | -5.5051204877584725    |
| train_0/q_grads           | 0.03165475269779563    |
| train_0/q_grads_std       | 0.3399043396115303     |
| train_0/q_loss            | 0.808853719547395      |
| train_0/reward            | -0.7784951507524965    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0914794921875        |
| train_0/target_q          | -5.792070256803612     |
| train_1/avg_q             | -15.761092227662619    |
| train_1/current_q         | -11.783608373543307    |
| train_1/fw_bonus          | -0.9993229642510414    |
| train_1/fw_loss           | 0.0014042987662833185  |
| train_1/mu_grads          | -0.009840632858686148  |
| train_1/mu_grads_std      | 0.4751840755343437     |
| train_1/mu_loss           | 11.598136862388237     |
| train_1/n_subgoals        | 1894.0                 |
| train_1/next_q            | -11.3882457551859      |
| train_1/q_grads           | -0.045269074570387605  |
| train_1/q_grads_std       | 0.6320774853229523     |
| train_1/q_loss            | 5.030158494466141      |
| train_1/reward            | -2.0317399233455946    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005517578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.32312565997888065    |
| train_1/target_q          | -11.842306162711647    |
------------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 27
Time for epoch 27: 423.03. Rollout time: 202.50, Training time: 220.49
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 1612895.0             |
| test/episodes             | 420.0                 |
| test/success_rate         | 0.3333333333333333    |
| test_0/avg_q              | -2.091234970091585    |
| test_1/avg_q              | -13.43782757018896    |
| test_1/n_subgoals         | 503.0                 |
| test_1/subgoal_succ_rate  | 0.34592445328031807   |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -10.418963850842609   |
| train_0/current_q         | -6.067761317924848    |
| train_0/fw_bonus          | -0.9991342455148697   |
| train_0/fw_loss           | 0.0002155437643523328 |
| train_0/mu_grads          | -0.11042265389114618  |
| train_0/mu_grads_std      | 0.5264454111456871    |
| train_0/mu_loss           | 5.865888511426037     |
| train_0/next_q            | -5.705493642560599    |
| train_0/q_grads           | 0.03163948161527515   |
| train_0/q_grads_std       | 0.3431851029396057    |
| train_0/q_loss            | 0.6305516496468899    |
| train_0/reward            | -0.7790132968097169   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.110302734375        |
| train_0/target_q          | -6.011682185469207    |
| train_1/avg_q             | -14.643878816068026   |
| train_1/current_q         | -11.74852616129516    |
| train_1/fw_bonus          | -0.9994971334934235   |
| train_1/fw_loss           | 0.001352866881643422  |
| train_1/mu_grads          | -0.011446214001625776 |
| train_1/mu_grads_std      | 0.48046482503414156   |
| train_1/mu_loss           | 11.58367944820682     |
| train_1/n_subgoals        | 1628.0                |
| train_1/next_q            | -11.376377687269706   |
| train_1/q_grads           | -0.04592975554987788  |
| train_1/q_grads_std       | 0.6386204063892365    |
| train_1/q_loss            | 4.615939327777559     |
| train_1/reward            | -2.027681900466996    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0054443359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.40724815724815727   |
| train_1/target_q          | -11.846476492081816   |
-----------------------------------------------------
New best value for test/success_rate: 0.3333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.18333333333333335
Training epoch 28
Time for epoch 28: 428.75. Rollout time: 209.32, Training time: 219.39
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 1655545.0              |
| test/episodes             | 435.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.5813740649296348    |
| test_1/avg_q              | -13.854982977891796    |
| test_1/n_subgoals         | 1958.0                 |
| test_1/subgoal_succ_rate  | 0.8529111338100103     |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.74                   |
| train_0/avg_q             | -10.703362665840611    |
| train_0/current_q         | -5.779038445380925     |
| train_0/fw_bonus          | -0.9991518571972847    |
| train_0/fw_loss           | 0.00021128522566868924 |
| train_0/mu_grads          | -0.11638159658759832   |
| train_0/mu_grads_std      | 0.5318517833948135     |
| train_0/mu_loss           | 5.618226698824537      |
| train_0/next_q            | -5.427443546231178     |
| train_0/q_grads           | 0.03165834499523044    |
| train_0/q_grads_std       | 0.3478446163237095     |
| train_0/q_loss            | 0.7430812608439419     |
| train_0/reward            | -0.7858841562730958    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.092822265625         |
| train_0/target_q          | -5.721618391723659     |
| train_1/avg_q             | -13.42240898392888     |
| train_1/current_q         | -11.824844631465208    |
| train_1/fw_bonus          | -0.9995685815811157    |
| train_1/fw_loss           | 0.001331767495139502   |
| train_1/mu_grads          | -0.01259677044581622   |
| train_1/mu_grads_std      | 0.4865571342408657     |
| train_1/mu_loss           | 11.653399582055885     |
| train_1/n_subgoals        | 1631.0                 |
| train_1/next_q            | -11.4153956850193      |
| train_1/q_grads           | -0.046314791589975354  |
| train_1/q_grads_std       | 0.6468494564294816     |
| train_1/q_loss            | 4.589199414659302      |
| train_1/reward            | -2.062361628603321     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005029296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.37584304107909255    |
| train_1/target_q          | -11.889150433489458    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18333333333333335
Training epoch 29
Time for epoch 29: 420.93. Rollout time: 203.99, Training time: 216.90
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 1696317.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.4286307847311008    |
| test_1/avg_q              | -13.212183940712746    |
| test_1/n_subgoals         | 6450.0                 |
| test_1/subgoal_succ_rate  | 0.986046511627907      |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -10.952092743023895    |
| train_0/current_q         | -5.96158671613023      |
| train_0/fw_bonus          | -0.999266354739666     |
| train_0/fw_loss           | 0.00018360818139626645 |
| train_0/mu_grads          | -0.11838475205004215   |
| train_0/mu_grads_std      | 0.5363290399312973     |
| train_0/mu_loss           | 5.764147494724649      |
| train_0/next_q            | -5.587105361088723     |
| train_0/q_grads           | 0.031759167462587355   |
| train_0/q_grads_std       | 0.35240564718842504    |
| train_0/q_loss            | 0.6479607939919602     |
| train_0/reward            | -0.7864987178571028    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1168212890625        |
| train_0/target_q          | -5.9059147219334545    |
| train_1/avg_q             | -14.959960497008328    |
| train_1/current_q         | -11.605718948499563    |
| train_1/fw_bonus          | -0.9995066165924072    |
| train_1/fw_loss           | 0.0013500679808203131  |
| train_1/mu_grads          | -0.014561712485738098  |
| train_1/mu_grads_std      | 0.4917253449559212     |
| train_1/mu_loss           | 11.329016323237127     |
| train_1/n_subgoals        | 1611.0                 |
| train_1/next_q            | -11.129667177271994    |
| train_1/q_grads           | -0.04762634048238397   |
| train_1/q_grads_std       | 0.6525384187698364     |
| train_1/q_loss            | 5.099899156703377      |
| train_1/reward            | -2.038084660952154     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0050537109375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3898199875853507     |
| train_1/target_q          | -11.69161174353234     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.21666666666666667
Training epoch 30
Time for epoch 30: 465.87. Rollout time: 244.53, Training time: 221.29
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 1739521.0              |
| test/episodes             | 465.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.4209420603165637    |
| test_1/avg_q              | -14.041745680308477    |
| test_1/n_subgoals         | 6006.0                 |
| test_1/subgoal_succ_rate  | 0.9906759906759907     |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -13.48192778138493     |
| train_0/current_q         | -5.727062365375359     |
| train_0/fw_bonus          | -0.9992236271500587    |
| train_0/fw_loss           | 0.00019393580514588394 |
| train_0/mu_grads          | -0.12052464615553618   |
| train_0/mu_grads_std      | 0.5430063888430595     |
| train_0/mu_loss           | 5.525547329699191      |
| train_0/next_q            | -5.348992751715253     |
| train_0/q_grads           | 0.03204747950658202    |
| train_0/q_grads_std       | 0.3593979150056839     |
| train_0/q_loss            | 0.7159064984089669     |
| train_0/reward            | -0.7885754390183137    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0752197265625        |
| train_0/target_q          | -5.659670743447592     |
| train_1/avg_q             | -14.816582271202613    |
| train_1/current_q         | -11.19931480138209     |
| train_1/fw_bonus          | -0.9998726680874824    |
| train_1/fw_loss           | 0.001241964750806801   |
| train_1/mu_grads          | -0.013780156220309436  |
| train_1/mu_grads_std      | 0.496869508177042      |
| train_1/mu_loss           | 11.103757552203565     |
| train_1/n_subgoals        | 1851.0                 |
| train_1/next_q            | -10.870356147854087    |
| train_1/q_grads           | -0.04804620966315269   |
| train_1/q_grads_std       | 0.6585305675864219     |
| train_1/q_loss            | 4.564915497287186      |
| train_1/reward            | -1.9976732466122484    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0048828125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4246353322528363     |
| train_1/target_q          | -11.327513549175537    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.21666666666666667
Training epoch 31
Time for epoch 31: 397.80. Rollout time: 193.67, Training time: 204.09
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 1780542.0              |
| test/episodes             | 480.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.312370800561221     |
| test_1/avg_q              | -3.8689911454568713    |
| test_1/n_subgoals         | 2626.0                 |
| test_1/subgoal_succ_rate  | 0.8808073115003808     |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.73                   |
| train_0/avg_q             | -10.853185530931313    |
| train_0/current_q         | -6.135767362214479     |
| train_0/fw_bonus          | -0.9992822468280792    |
| train_0/fw_loss           | 0.00017976505478145555 |
| train_0/mu_grads          | -0.12090689800679684   |
| train_0/mu_grads_std      | 0.5487093403935432     |
| train_0/mu_loss           | 5.875533323321173      |
| train_0/next_q            | -5.673428595330714     |
| train_0/q_grads           | 0.03189025968313217    |
| train_0/q_grads_std       | 0.36511230692267416    |
| train_0/q_loss            | 0.4180304422551682     |
| train_0/reward            | -0.7893042061470623    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.14013671875          |
| train_0/target_q          | -6.075759245479882     |
| train_1/avg_q             | -14.311278813625531    |
| train_1/current_q         | -10.601078949956406    |
| train_1/fw_bonus          | -0.9997987151145935    |
| train_1/fw_loss           | 0.0012638051994144917  |
| train_1/mu_grads          | -0.014828544924966991  |
| train_1/mu_grads_std      | 0.49913316369056704    |
| train_1/mu_loss           | 10.340575060444943     |
| train_1/n_subgoals        | 1669.0                 |
| train_1/next_q            | -10.187147521959453    |
| train_1/q_grads           | -0.04671595571562648   |
| train_1/q_grads_std       | 0.6662401586771012     |
| train_1/q_loss            | 5.949322147764155      |
| train_1/reward            | -1.9424667698764098    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005078125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.44937088076692633    |
| train_1/target_q          | -10.676373287369023    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 32
Time for epoch 32: 494.33. Rollout time: 287.95, Training time: 206.35
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 1835284.0             |
| test/episodes             | 495.0                 |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.6168951705033494   |
| test_1/avg_q              | -19.305934045776567   |
| test_1/n_subgoals         | 586.0                 |
| test_1/subgoal_succ_rate  | 0.36689419795221845   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.49                  |
| train_0/avg_q             | -11.004006636402554   |
| train_0/current_q         | -6.0523860748851295   |
| train_0/fw_bonus          | -0.9992149010300636   |
| train_0/fw_loss           | 0.0001960474419320235 |
| train_0/mu_grads          | -0.12153666187077761  |
| train_0/mu_grads_std      | 0.5562606602907181    |
| train_0/mu_loss           | 5.870810954676349     |
| train_0/next_q            | -5.694546738695374    |
| train_0/q_grads           | 0.03181794099509716   |
| train_0/q_grads_std       | 0.37040920928120613   |
| train_0/q_loss            | 0.7131391590178074    |
| train_0/reward            | -0.7834829232200718   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1263427734375       |
| train_0/target_q          | -6.0119177207566015   |
| train_1/avg_q             | -14.359766925864443   |
| train_1/current_q         | -11.912737379540195   |
| train_1/fw_bonus          | -0.9996874526143074   |
| train_1/fw_loss           | 0.0012966642651008442 |
| train_1/mu_grads          | -0.015492916922084987 |
| train_1/mu_grads_std      | 0.504128035902977     |
| train_1/mu_loss           | 12.121747414228144    |
| train_1/n_subgoals        | 2067.0                |
| train_1/next_q            | -11.817146627339127   |
| train_1/q_grads           | -0.047339695412665604 |
| train_1/q_grads_std       | 0.674486494064331     |
| train_1/q_loss            | 6.153947904456928     |
| train_1/reward            | -1.925574939204671    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0052001953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2888243831640058    |
| train_1/target_q          | -12.001494963782845   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 33
Time for epoch 33: 442.12. Rollout time: 235.95, Training time: 206.13
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 1884137.0              |
| test/episodes             | 510.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -2.1478045363851637    |
| test_1/avg_q              | -11.84771881214151     |
| test_1/n_subgoals         | 396.0                  |
| test_1/subgoal_succ_rate  | 0.0025252525252525255  |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -10.511338936684439    |
| train_0/current_q         | -5.769950375363504     |
| train_0/fw_bonus          | -0.9991905972361564    |
| train_0/fw_loss           | 0.00020192054180370178 |
| train_0/mu_grads          | -0.12144615147262812   |
| train_0/mu_grads_std      | 0.5614204853773117     |
| train_0/mu_loss           | 5.570926351685221      |
| train_0/next_q            | -5.375883086952945     |
| train_0/q_grads           | 0.033620568085461856   |
| train_0/q_grads_std       | 0.3795660696923733     |
| train_0/q_loss            | 0.6267851538550996     |
| train_0/reward            | -0.7792288023745642    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.139453125            |
| train_0/target_q          | -5.73060602381288      |
| train_1/avg_q             | -15.805794036604631    |
| train_1/current_q         | -11.50465212467952     |
| train_1/fw_bonus          | -1.0001028999686241    |
| train_1/fw_loss           | 0.0011739760782802477  |
| train_1/mu_grads          | -0.015087047033011914  |
| train_1/mu_grads_std      | 0.5080896571278573     |
| train_1/mu_loss           | 11.734788702535607     |
| train_1/n_subgoals        | 1787.0                 |
| train_1/next_q            | -11.46345197469055     |
| train_1/q_grads           | -0.0491604195907712    |
| train_1/q_grads_std       | 0.6819844990968704     |
| train_1/q_loss            | 6.858501123324845      |
| train_1/reward            | -1.872926115552764     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004931640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3072188024622272     |
| train_1/target_q          | -11.62124529111002     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09999999999999999
Training epoch 34
Time for epoch 34: 430.17. Rollout time: 224.49, Training time: 205.64
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 1928343.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.26666666666666666    |
| test_0/avg_q              | -2.000157735325713     |
| test_1/avg_q              | -13.108593401428577    |
| test_1/n_subgoals         | 3143.0                 |
| test_1/subgoal_succ_rate  | 0.9557747375119313     |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -10.955130048431718    |
| train_0/current_q         | -6.319449025613556     |
| train_0/fw_bonus          | -0.9991501972079277    |
| train_0/fw_loss           | 0.00021168363236938602 |
| train_0/mu_grads          | -0.12171923350542783   |
| train_0/mu_grads_std      | 0.5669367507100105     |
| train_0/mu_loss           | 6.103162361854624      |
| train_0/next_q            | -5.9300208167713695    |
| train_0/q_grads           | 0.03428285643458366    |
| train_0/q_grads_std       | 0.38568548783659934    |
| train_0/q_loss            | 0.5046439547131059     |
| train_0/reward            | -0.7747509317887307    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1072021484375        |
| train_0/target_q          | -6.277088231530337     |
| train_1/avg_q             | -15.112914486333057    |
| train_1/current_q         | -11.599552436217577    |
| train_1/fw_bonus          | -1.000039851665497     |
| train_1/fw_loss           | 0.0011925928381970152  |
| train_1/mu_grads          | -0.015550338849425315  |
| train_1/mu_grads_std      | 0.515070018172264      |
| train_1/mu_loss           | 11.748206993671598     |
| train_1/n_subgoals        | 1666.0                 |
| train_1/next_q            | -11.479350231360232    |
| train_1/q_grads           | -0.05080368397757411   |
| train_1/q_grads_std       | 0.6895067602396011     |
| train_1/q_loss            | 5.261986227353429      |
| train_1/reward            | -1.9692787637035507    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0043212890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.29411764705882354    |
| train_1/target_q          | -11.6977557169403      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 35
Time for epoch 35: 430.26. Rollout time: 213.51, Training time: 216.71
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 35                    |
| policy/steps              | 1969931.0             |
| test/episodes             | 540.0                 |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.1125483251125972   |
| test_1/avg_q              | -17.06919139152693    |
| test_1/n_subgoals         | 2378.0                |
| test_1/subgoal_succ_rate  | 0.8898233809924306    |
| train/episodes            | 3600.0                |
| train/success_rate        | 0.73                  |
| train_0/avg_q             | -11.851495960586924   |
| train_0/current_q         | -6.09322579573425     |
| train_0/fw_bonus          | -0.9991278767585754   |
| train_0/fw_loss           | 0.0002170846153603634 |
| train_0/mu_grads          | -0.12413083799183369  |
| train_0/mu_grads_std      | 0.573471975326538     |
| train_0/mu_loss           | 5.909873067135622     |
| train_0/next_q            | -5.739179031123056    |
| train_0/q_grads           | 0.03465744014829397   |
| train_0/q_grads_std       | 0.390867967158556     |
| train_0/q_loss            | 0.7728140254750903    |
| train_0/reward            | -0.7724015958738164   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1090087890625       |
| train_0/target_q          | -6.071654969858753    |
| train_1/avg_q             | -15.280835422022792   |
| train_1/current_q         | -11.876389805464903   |
| train_1/fw_bonus          | -1.0001189067959786   |
| train_1/fw_loss           | 0.0011692508065607398 |
| train_1/mu_grads          | -0.015270556998439133 |
| train_1/mu_grads_std      | 0.5247963666915894    |
| train_1/mu_loss           | 12.150422045423799    |
| train_1/n_subgoals        | 1614.0                |
| train_1/next_q            | -11.905332234660383   |
| train_1/q_grads           | -0.05101884212344885  |
| train_1/q_grads_std       | 0.6964657261967659    |
| train_1/q_loss            | 4.927728317814039     |
| train_1/reward            | -1.9388297733024955   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.004736328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.38909541511771994   |
| train_1/target_q          | -11.951442695376937   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 36
Time for epoch 36: 389.07. Rollout time: 188.33, Training time: 200.70
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 2008079.0              |
| test/episodes             | 555.0                  |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -2.2437416934344694    |
| test_1/avg_q              | -12.427916366474266    |
| test_1/n_subgoals         | 1389.0                 |
| test_1/subgoal_succ_rate  | 0.8819294456443485     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.73                   |
| train_0/avg_q             | -11.262231339849585    |
| train_0/current_q         | -5.844968118784255     |
| train_0/fw_bonus          | -0.9990463361144066    |
| train_0/fw_loss           | 0.00023679428886680398 |
| train_0/mu_grads          | -0.12424843702465296   |
| train_0/mu_grads_std      | 0.5804245322942734     |
| train_0/mu_loss           | 5.768323709824891      |
| train_0/next_q            | -5.521589955220565     |
| train_0/q_grads           | 0.03444280615076423    |
| train_0/q_grads_std       | 0.39540966004133227    |
| train_0/q_loss            | 0.771384150576724      |
| train_0/reward            | -0.7710811629764066    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1115966796875        |
| train_0/target_q          | -5.793042076018942     |
| train_1/avg_q             | -14.807832571096814    |
| train_1/current_q         | -11.931737758526342    |
| train_1/fw_bonus          | -0.9999829441308975    |
| train_1/fw_loss           | 0.0012094013101886958  |
| train_1/mu_grads          | -0.01618722570128739   |
| train_1/mu_grads_std      | 0.5338893488049508     |
| train_1/mu_loss           | 12.277619298284286     |
| train_1/n_subgoals        | 1569.0                 |
| train_1/next_q            | -12.056029010623059    |
| train_1/q_grads           | -0.05119545990601182   |
| train_1/q_grads_std       | 0.7039865866303444     |
| train_1/q_loss            | 5.035336288536571      |
| train_1/reward            | -1.945753792756659     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0045654296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.372848948374761      |
| train_1/target_q          | -12.042537824820728    |
------------------------------------------------------
New best value for test/success_rate: 0.4. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 37
Time for epoch 37: 401.96. Rollout time: 191.18, Training time: 210.74
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 2047269.0             |
| test/episodes             | 570.0                 |
| test/success_rate         | 0.3333333333333333    |
| test_0/avg_q              | -1.5271206413818603   |
| test_1/avg_q              | -14.334305816952694   |
| test_1/n_subgoals         | 3403.0                |
| test_1/subgoal_succ_rate  | 0.9556273875991772    |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -11.644396481084094   |
| train_0/current_q         | -6.087710696489432    |
| train_0/fw_bonus          | -0.9990214407444      |
| train_0/fw_loss           | 0.000242811526186415  |
| train_0/mu_grads          | -0.12435631416738033  |
| train_0/mu_grads_std      | 0.5831245690584183    |
| train_0/mu_loss           | 5.90680914642185      |
| train_0/next_q            | -5.722775273762603    |
| train_0/q_grads           | 0.034365661535412075  |
| train_0/q_grads_std       | 0.3999438762664795    |
| train_0/q_loss            | 0.6277142470479614    |
| train_0/reward            | -0.772979236680112    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0837158203125       |
| train_0/target_q          | -6.017775702779778    |
| train_1/avg_q             | -14.223563680049923   |
| train_1/current_q         | -11.81015705975806    |
| train_1/fw_bonus          | -0.9997015282511711   |
| train_1/fw_loss           | 0.0012925087474286556 |
| train_1/mu_grads          | -0.015189380222000181 |
| train_1/mu_grads_std      | 0.5417436122894287    |
| train_1/mu_loss           | 12.197023089365981    |
| train_1/n_subgoals        | 1584.0                |
| train_1/next_q            | -11.920288818600731   |
| train_1/q_grads           | -0.05274538276717067  |
| train_1/q_grads_std       | 0.7108825221657753    |
| train_1/q_loss            | 5.085131092387838     |
| train_1/reward            | -1.97432113234172     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0052734375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4097222222222222    |
| train_1/target_q          | -11.930240717995122   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.26666666666666666
Training epoch 38
Time for epoch 38: 411.21. Rollout time: 191.26, Training time: 219.91
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 2082753.0              |
| test/episodes             | 585.0                  |
| test/success_rate         | 0.26666666666666666    |
| test_0/avg_q              | -1.8784727912044892    |
| test_1/avg_q              | -17.53492229936038     |
| test_1/n_subgoals         | 371.0                  |
| test_1/subgoal_succ_rate  | 0.2560646900269542     |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -11.798836892472947    |
| train_0/current_q         | -6.082041257643075     |
| train_0/fw_bonus          | -0.9989988207817078    |
| train_0/fw_loss           | 0.00024827878223732114 |
| train_0/mu_grads          | -0.1268521945923567    |
| train_0/mu_grads_std      | 0.5883171364665032     |
| train_0/mu_loss           | 5.917130988569122      |
| train_0/next_q            | -5.775109813744782     |
| train_0/q_grads           | 0.0363272120244801     |
| train_0/q_grads_std       | 0.40522842928767205    |
| train_0/q_loss            | 0.7371700291764162     |
| train_0/reward            | -0.7677001446885697    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0867431640625        |
| train_0/target_q          | -6.071161028637285     |
| train_1/avg_q             | -15.884459841775053    |
| train_1/current_q         | -11.494382737173293    |
| train_1/fw_bonus          | -1.0001089692115783    |
| train_1/fw_loss           | 0.0011721834423951804  |
| train_1/mu_grads          | -0.015144848171621561  |
| train_1/mu_grads_std      | 0.5504359185695649     |
| train_1/mu_loss           | 11.726533534263808     |
| train_1/n_subgoals        | 1401.0                 |
| train_1/next_q            | -11.561382175414753    |
| train_1/q_grads           | -0.052712144516408446  |
| train_1/q_grads_std       | 0.716702476143837      |
| train_1/q_loss            | 5.057562628047881      |
| train_1/reward            | -2.0328336393922655    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0040283203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3868665239114918     |
| train_1/target_q          | -11.625265483513683    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.26666666666666666
Training epoch 39
Time for epoch 39: 455.63. Rollout time: 209.05, Training time: 246.52
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 2116945.0             |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.5333333333333333    |
| test_0/avg_q              | -2.823524242721543    |
| test_1/avg_q              | -15.718958589576113   |
| test_1/n_subgoals         | 2336.0                |
| test_1/subgoal_succ_rate  | 0.9644691780821918    |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.85                  |
| train_0/avg_q             | -12.440169338903877   |
| train_0/current_q         | -6.426594813747843    |
| train_0/fw_bonus          | -0.9990024194121361   |
| train_0/fw_loss           | 0.000247408638097113  |
| train_0/mu_grads          | -0.12889506258070468  |
| train_0/mu_grads_std      | 0.5937539473176002    |
| train_0/mu_loss           | 6.2376286190069745    |
| train_0/next_q            | -6.071272187807487    |
| train_0/q_grads           | 0.036870591808110476  |
| train_0/q_grads_std       | 0.4093206122517586    |
| train_0/q_loss            | 0.6667887124970552    |
| train_0/reward            | -0.7658516795752803   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0863037109375       |
| train_0/target_q          | -6.355443822933724    |
| train_1/avg_q             | -14.973662809272943   |
| train_1/current_q         | -11.67442883526289    |
| train_1/fw_bonus          | -1.0003047570586205   |
| train_1/fw_loss           | 0.0011143672920297832 |
| train_1/mu_grads          | -0.01565527506172657  |
| train_1/mu_grads_std      | 0.5582396268844605    |
| train_1/mu_loss           | 11.951599317187156    |
| train_1/n_subgoals        | 1398.0                |
| train_1/next_q            | -11.67315792126742    |
| train_1/q_grads           | -0.05405304087325931  |
| train_1/q_grads_std       | 0.7228802561759948    |
| train_1/q_loss            | 5.449053971932431     |
| train_1/reward            | -1.9891386890263676   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0045654296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3876967095851216    |
| train_1/target_q          | -11.781702194390226   |
-----------------------------------------------------
New best value for test/success_rate: 0.5333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.3833333333333333
Training epoch 40
Time for epoch 40: 452.18. Rollout time: 218.20, Training time: 233.89
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 2154607.0              |
| test/episodes             | 615.0                  |
| test/success_rate         | 0.26666666666666666    |
| test_0/avg_q              | -2.666531499601721     |
| test_1/avg_q              | -14.233846168385657    |
| test_1/n_subgoals         | 504.0                  |
| test_1/subgoal_succ_rate  | 0.4146825396825397     |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -11.81391318416063     |
| train_0/current_q         | -5.745474906671289     |
| train_0/fw_bonus          | -0.9990454688668251    |
| train_0/fw_loss           | 0.00023700506208115257 |
| train_0/mu_grads          | -0.13140794150531293   |
| train_0/mu_grads_std      | 0.6006804898381233     |
| train_0/mu_loss           | 5.630679129428718      |
| train_0/next_q            | -5.4289101409400455    |
| train_0/q_grads           | 0.03671106761321426    |
| train_0/q_grads_std       | 0.4124838516116142     |
| train_0/q_loss            | 0.7981828183762346     |
| train_0/reward            | -0.7657525758073461    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.096875               |
| train_0/target_q          | -5.699575773759275     |
| train_1/avg_q             | -14.329023919670853    |
| train_1/current_q         | -11.02694575371964     |
| train_1/fw_bonus          | -1.0000129356980323    |
| train_1/fw_loss           | 0.0012005447613773867  |
| train_1/mu_grads          | -0.016501497849822043  |
| train_1/mu_grads_std      | 0.5640079841017723     |
| train_1/mu_loss           | 11.029159775115449     |
| train_1/n_subgoals        | 1494.0                 |
| train_1/next_q            | -10.806853329336652    |
| train_1/q_grads           | -0.05511885201558471   |
| train_1/q_grads_std       | 0.729782672226429      |
| train_1/q_loss            | 5.461318455158063      |
| train_1/reward            | -1.996737852136721     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0050048828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.41967871485943775    |
| train_1/target_q          | -11.125245712757149    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.35
Training epoch 41
Time for epoch 41: 471.05. Rollout time: 229.59, Training time: 241.36
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2192724.0              |
| test/episodes             | 630.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -2.807320366707651     |
| test_1/avg_q              | -15.770465897936983    |
| test_1/n_subgoals         | 397.0                  |
| test_1/subgoal_succ_rate  | 0.12846347607052896    |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.85                   |
| train_0/avg_q             | -11.234939407814268    |
| train_0/current_q         | -5.882993304410906     |
| train_0/fw_bonus          | -0.999028018116951     |
| train_0/fw_loss           | 0.00024122156828525475 |
| train_0/mu_grads          | -0.13247220329940318   |
| train_0/mu_grads_std      | 0.6086956068873406     |
| train_0/mu_loss           | 5.690391517831706      |
| train_0/next_q            | -5.520128212664772     |
| train_0/q_grads           | 0.03716333080083132    |
| train_0/q_grads_std       | 0.41801107451319697    |
| train_0/q_loss            | 0.6797659900021291     |
| train_0/reward            | -0.7639354708862811    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1041259765625        |
| train_0/target_q          | -5.816370365078606     |
| train_1/avg_q             | -13.985340751200694    |
| train_1/current_q         | -10.594937584231136    |
| train_1/fw_bonus          | -1.0000432416796685    |
| train_1/fw_loss           | 0.0011915968905668705  |
| train_1/mu_grads          | -0.016699954215437175  |
| train_1/mu_grads_std      | 0.5693912580609322     |
| train_1/mu_loss           | 10.665135133557095     |
| train_1/n_subgoals        | 1433.0                 |
| train_1/next_q            | -10.383320704540909    |
| train_1/q_grads           | -0.05688939094543457   |
| train_1/q_grads_std       | 0.7372043803334236     |
| train_1/q_loss            | 5.2391089231270245     |
| train_1/reward            | -1.9445969898402837    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0048583984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3866015352407537     |
| train_1/target_q          | -10.673492306032085    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.31666666666666665
Training epoch 42
Time for epoch 42: 585.45. Rollout time: 326.92, Training time: 258.41
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 42                    |
| policy/steps              | 2233682.0             |
| test/episodes             | 645.0                 |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -2.1089570323330715   |
| test_1/avg_q              | -16.378729389236625   |
| test_1/n_subgoals         | 1440.0                |
| test_1/subgoal_succ_rate  | 0.84375               |
| train/episodes            | 4300.0                |
| train/success_rate        | 0.7                   |
| train_0/avg_q             | -12.971358976470881   |
| train_0/current_q         | -6.177437953852142    |
| train_0/fw_bonus          | -0.9989403620362282   |
| train_0/fw_loss           | 0.0002624098953674547 |
| train_0/mu_grads          | -0.13287407718598843  |
| train_0/mu_grads_std      | 0.610955061018467     |
| train_0/mu_loss           | 6.011626660771633     |
| train_0/next_q            | -5.845673272891381    |
| train_0/q_grads           | 0.037635553441941735  |
| train_0/q_grads_std       | 0.4235451139509678    |
| train_0/q_loss            | 0.6151200259125694    |
| train_0/reward            | -0.7655981279422122   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.06943359375         |
| train_0/target_q          | -6.141192830246359    |
| train_1/avg_q             | -15.149757988498331   |
| train_1/current_q         | -11.632299920111482   |
| train_1/fw_bonus          | -0.9998890072107315   |
| train_1/fw_loss           | 0.001237142094760202  |
| train_1/mu_grads          | -0.016753713926300408 |
| train_1/mu_grads_std      | 0.5753008872270584    |
| train_1/mu_loss           | 11.970373905678276    |
| train_1/n_subgoals        | 1596.0                |
| train_1/next_q            | -11.632651401254241   |
| train_1/q_grads           | -0.05770976915955543  |
| train_1/q_grads_std       | 0.7444231316447258    |
| train_1/q_loss            | 5.594062814057992     |
| train_1/reward            | -1.9641690284399373   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0048583984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.32644110275689225   |
| train_1/target_q          | -11.693274069695299   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.35
Training epoch 43
Time for epoch 43: 529.87. Rollout time: 281.41, Training time: 248.36
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 2272461.0              |
| test/episodes             | 660.0                  |
| test/success_rate         | 0.3333333333333333     |
| test_0/avg_q              | -2.167134461837141     |
| test_1/avg_q              | -14.578339937087458    |
| test_1/n_subgoals         | 3344.0                 |
| test_1/subgoal_succ_rate  | 0.9668062200956937     |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -15.02405609316339     |
| train_0/current_q         | -6.32796102959017      |
| train_0/fw_bonus          | -0.998930175602436     |
| train_0/fw_loss           | 0.00026487204777367877 |
| train_0/mu_grads          | -0.1347810413688421    |
| train_0/mu_grads_std      | 0.6147820889949799     |
| train_0/mu_loss           | 6.143790110908563      |
| train_0/next_q            | -5.983158439726467     |
| train_0/q_grads           | 0.03795527769252658    |
| train_0/q_grads_std       | 0.4282965637743473     |
| train_0/q_loss            | 0.6087176164985639     |
| train_0/reward            | -0.7660533451115044    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.043212890625         |
| train_0/target_q          | -6.2801433648359675    |
| train_1/avg_q             | -15.983597028796515    |
| train_1/current_q         | -11.017109282917676    |
| train_1/fw_bonus          | -1.0000488117337227    |
| train_1/fw_loss           | 0.0011899495118996128  |
| train_1/mu_grads          | -0.017875218112021685  |
| train_1/mu_grads_std      | 0.5773482903838157     |
| train_1/mu_loss           | 11.303479319857491     |
| train_1/n_subgoals        | 1541.0                 |
| train_1/next_q            | -11.04015977639051     |
| train_1/q_grads           | -0.05933205410838127   |
| train_1/q_grads_std       | 0.7527206808328628     |
| train_1/q_loss            | 5.2031494602102315     |
| train_1/reward            | -1.9768249472163006    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00458984375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3685918234912395     |
| train_1/target_q          | -11.113845701818558    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.3
Training epoch 44
Time for epoch 44: 1717.17. Rollout time: 194.62, Training time: 1522.45
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 2306316.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.5333333333333333     |
| test_0/avg_q              | -1.642083776696956     |
| test_1/avg_q              | -13.639741511354913    |
| test_1/n_subgoals         | 1292.0                 |
| test_1/subgoal_succ_rate  | 0.8691950464396285     |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -12.41950726865542     |
| train_0/current_q         | -6.148247364420668     |
| train_0/fw_bonus          | -0.9989628523588181    |
| train_0/fw_loss           | 0.00025697370729176327 |
| train_0/mu_grads          | -0.13726664707064629   |
| train_0/mu_grads_std      | 0.6230042964220047     |
| train_0/mu_loss           | 6.0871385522103        |
| train_0/next_q            | -5.900530496019709     |
| train_0/q_grads           | 0.0383532203733921     |
| train_0/q_grads_std       | 0.43288087025284766    |
| train_0/q_loss            | 0.8956914839973493     |
| train_0/reward            | -0.7655488183940179    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0676025390625        |
| train_0/target_q          | -6.152553293862903     |
| train_1/avg_q             | -14.085976002672266    |
| train_1/current_q         | -10.592469238256665    |
| train_1/fw_bonus          | -1.0000176474452018    |
| train_1/fw_loss           | 0.0011991507490165532  |
| train_1/mu_grads          | -0.018218510318547487  |
| train_1/mu_grads_std      | 0.5774250403046608     |
| train_1/mu_loss           | 10.839228137513023     |
| train_1/n_subgoals        | 1453.0                 |
| train_1/next_q            | -10.58376252828318     |
| train_1/q_grads           | -0.06189501089975238   |
| train_1/q_grads_std       | 0.7613644629716874     |
| train_1/q_loss            | 5.4287589142458526     |
| train_1/reward            | -1.9009931826669344    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00478515625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.45836200963523743    |
| train_1/target_q          | -10.690782373803959    |
------------------------------------------------------
New best value for test/success_rate: 0.5333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.3666666666666667
Training epoch 45
Time for epoch 45: 558.78. Rollout time: 282.45, Training time: 276.24
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 2341172.0             |
| test/episodes             | 690.0                 |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -1.7353150195457583   |
| test_1/avg_q              | -15.16367267904541    |
| test_1/n_subgoals         | 2638.0                |
| test_1/subgoal_succ_rate  | 0.9643669446550417    |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -11.316080219475612   |
| train_0/current_q         | -6.212409438406548    |
| train_0/fw_bonus          | -0.999009758234024    |
| train_0/fw_loss           | 0.0002456356040056562 |
| train_0/mu_grads          | -0.13893495351076127  |
| train_0/mu_grads_std      | 0.6300584435462951    |
| train_0/mu_loss           | 5.999134109654623     |
| train_0/next_q            | -5.850420644176205    |
| train_0/q_grads           | 0.03867383487522602   |
| train_0/q_grads_std       | 0.43698742613196373   |
| train_0/q_loss            | 0.6084222289675283    |
| train_0/reward            | -0.7681240209520184   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0927001953125       |
| train_0/target_q          | -6.160661212881279    |
| train_1/avg_q             | -13.348073259905641   |
| train_1/current_q         | -10.858134282660592   |
| train_1/fw_bonus          | -1.0000341460108757   |
| train_1/fw_loss           | 0.0011942759068915621 |
| train_1/mu_grads          | -0.01883543934673071  |
| train_1/mu_grads_std      | 0.5769195944070816    |
| train_1/mu_loss           | 11.065193564488608    |
| train_1/n_subgoals        | 1488.0                |
| train_1/next_q            | -10.827279576717894   |
| train_1/q_grads           | -0.06369816679507494  |
| train_1/q_grads_std       | 0.7686349064111709    |
| train_1/q_loss            | 4.793166257080394     |
| train_1/reward            | -1.9231896929468348   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.004638671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.42405913978494625   |
| train_1/target_q          | -10.940713290228246   |
-----------------------------------------------------
New best value for test/success_rate: 0.6666666666666666. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.4833333333333333
Training epoch 46
Time for epoch 46: 451.53. Rollout time: 209.28, Training time: 242.15
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 2378056.0              |
| test/episodes             | 705.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8942579162439448    |
| test_1/avg_q              | -13.259588682894398    |
| test_1/n_subgoals         | 419.0                  |
| test_1/subgoal_succ_rate  | 0.04295942720763723    |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.85                   |
| train_0/avg_q             | -10.871491348903547    |
| train_0/current_q         | -4.069481576853001     |
| train_0/fw_bonus          | -0.9989350780844688    |
| train_0/fw_loss           | 0.00026368816761532796 |
| train_0/mu_grads          | -0.1396002434194088    |
| train_0/mu_grads_std      | 0.6368610545992851     |
| train_0/mu_loss           | 3.955967099884495      |
| train_0/next_q            | -3.829905344603567     |
| train_0/q_grads           | 0.03856416251510382    |
| train_0/q_grads_std       | 0.440887488424778      |
| train_0/q_loss            | 0.9650178428124665     |
| train_0/reward            | -0.7722618448104186    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.09326171875          |
| train_0/target_q          | -4.1898761604763255    |
| train_1/avg_q             | -13.470585261692314    |
| train_1/current_q         | -10.957235440618428    |
| train_1/fw_bonus          | -0.9999247387051582    |
| train_1/fw_loss           | 0.0012265966652194038  |
| train_1/mu_grads          | -0.018755380576476455  |
| train_1/mu_grads_std      | 0.5768608763813973     |
| train_1/mu_loss           | 11.30870615576141      |
| train_1/n_subgoals        | 1360.0                 |
| train_1/next_q            | -11.090082964106424    |
| train_1/q_grads           | -0.06547998394817114   |
| train_1/q_grads_std       | 0.7744622632861138     |
| train_1/q_loss            | 4.857608192666817      |
| train_1/reward            | -1.9278132116924098    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0048583984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4102941176470588     |
| train_1/target_q          | -11.06430332773506     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.3833333333333333
Training epoch 47
Time for epoch 47: 580.31. Rollout time: 313.00, Training time: 267.21
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 2418645.0              |
| test/episodes             | 720.0                  |
| test/success_rate         | 0.3333333333333333     |
| test_0/avg_q              | -2.681803078523188     |
| test_1/avg_q              | -18.25826309720597     |
| test_1/n_subgoals         | 2500.0                 |
| test_1/subgoal_succ_rate  | 0.9348                 |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.78                   |
| train_0/avg_q             | -9.356729634969364     |
| train_0/current_q         | -5.672018879314875     |
| train_0/fw_bonus          | -0.9989963755011558    |
| train_0/fw_loss           | 0.00024886894316296094 |
| train_0/mu_grads          | -0.1405697673559189    |
| train_0/mu_grads_std      | 0.6436036497354507     |
| train_0/mu_loss           | 5.625214193375766      |
| train_0/next_q            | -5.39651284102974      |
| train_0/q_grads           | 0.03907754132524133    |
| train_0/q_grads_std       | 0.44766651913523675    |
| train_0/q_loss            | 0.9249879510038104     |
| train_0/reward            | -0.7712334700689099    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11083984375          |
| train_0/target_q          | -5.69754153313274      |
| train_1/avg_q             | -13.706454377492216    |
| train_1/current_q         | -10.918730784236828    |
| train_1/fw_bonus          | -1.000008001923561     |
| train_1/fw_loss           | 0.0012020037887850777  |
| train_1/mu_grads          | -0.01889023925177753   |
| train_1/mu_grads_std      | 0.5797395497560501     |
| train_1/mu_loss           | 11.186458733173126     |
| train_1/n_subgoals        | 1483.0                 |
| train_1/next_q            | -10.904485123368229    |
| train_1/q_grads           | -0.06778031270951032   |
| train_1/q_grads_std       | 0.7824440389871598     |
| train_1/q_loss            | 5.1225576899213205     |
| train_1/reward            | -1.9145405718532857    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004931640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2737693863789616     |
| train_1/target_q          | -11.008656897244634    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.3833333333333333
Training epoch 48
Time for epoch 48: 484.39. Rollout time: 229.14, Training time: 255.15
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 2453592.0             |
| test/episodes             | 735.0                 |
| test/success_rate         | 0.3333333333333333    |
| test_0/avg_q              | -2.121595793533276    |
| test_1/avg_q              | -12.035418254742769   |
| test_1/n_subgoals         | 5041.0                |
| test_1/subgoal_succ_rate  | 0.9904780797460822    |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -12.585328516054716   |
| train_0/current_q         | -6.403092530235904    |
| train_0/fw_bonus          | -0.9990369021892548   |
| train_0/fw_loss           | 0.000239072683325503  |
| train_0/mu_grads          | -0.14128878191113473  |
| train_0/mu_grads_std      | 0.6492051482200623    |
| train_0/mu_loss           | 6.204232075695016     |
| train_0/next_q            | -6.031679102728158    |
| train_0/q_grads           | 0.03955674963071942   |
| train_0/q_grads_std       | 0.4582448609173298    |
| train_0/q_loss            | 0.5481294298341395    |
| train_0/reward            | -0.7698886210604542   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1018310546875       |
| train_0/target_q          | -6.367371227419329    |
| train_1/avg_q             | -13.790403709525906   |
| train_1/current_q         | -10.498448394827438   |
| train_1/fw_bonus          | -0.9995887517929077   |
| train_1/fw_loss           | 0.0013258091930765659 |
| train_1/mu_grads          | -0.01954909786581993  |
| train_1/mu_grads_std      | 0.5832563236355781    |
| train_1/mu_loss           | 10.690927132673995    |
| train_1/n_subgoals        | 1451.0                |
| train_1/next_q            | -10.424734408229673   |
| train_1/q_grads           | -0.06888362690806389  |
| train_1/q_grads_std       | 0.7905615925788879    |
| train_1/q_loss            | 5.325954634501481     |
| train_1/reward            | -1.9068551983171347   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0049072265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4720882150241213    |
| train_1/target_q          | -10.582062804440262   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.3333333333333333
Training epoch 49
Time for epoch 49: 475.42. Rollout time: 233.97, Training time: 241.35
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 2494043.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -0.5760821582954199    |
| test_1/avg_q              | -11.677440558135116    |
| test_1/n_subgoals         | 559.0                  |
| test_1/subgoal_succ_rate  | 0.29874776386404295    |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -13.484544625678566    |
| train_0/current_q         | -4.782460747047521     |
| train_0/fw_bonus          | -0.9990327745676041    |
| train_0/fw_loss           | 0.00024007216052268632 |
| train_0/mu_grads          | -0.13990506827831267   |
| train_0/mu_grads_std      | 0.6575909689068794     |
| train_0/mu_loss           | 4.5409023989685195     |
| train_0/next_q            | -4.454490393462672     |
| train_0/q_grads           | 0.040151546616107224   |
| train_0/q_grads_std       | 0.47119939625263213    |
| train_0/q_loss            | 0.5982905935327265     |
| train_0/reward            | -0.7725975482560898    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0830810546875        |
| train_0/target_q          | -4.974778913234806     |
| train_1/avg_q             | -13.412306880492645    |
| train_1/current_q         | -11.979123532085257    |
| train_1/fw_bonus          | -0.9997126221656799    |
| train_1/fw_loss           | 0.0012892284838017076  |
| train_1/mu_grads          | -0.01919873678125441   |
| train_1/mu_grads_std      | 0.5869214087724686     |
| train_1/mu_loss           | 12.722185609941532     |
| train_1/n_subgoals        | 1628.0                 |
| train_1/next_q            | -12.423069073083848    |
| train_1/q_grads           | -0.07004435565322638   |
| train_1/q_grads_std       | 0.7968262180685997     |
| train_1/q_loss            | 6.905736271994324      |
| train_1/reward            | -1.9160048179859586    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.005517578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.45515970515970516    |
| train_1/target_q          | -12.239679631721284    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18333333333333332
Training epoch 50
Time for epoch 50: 612.08. Rollout time: 352.19, Training time: 259.80
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 50                     |
| policy/steps              | 2546608.0              |
| test/episodes             | 765.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.424691558583647     |
| test_1/avg_q              | -18.22606121149603     |
| test_1/n_subgoals         | 1342.0                 |
| test_1/subgoal_succ_rate  | 0.732488822652757      |
| train/episodes            | 5100.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -8.645741195735217     |
| train_0/current_q         | -6.143475153411727     |
| train_0/fw_bonus          | -0.9990145146846772    |
| train_0/fw_loss           | 0.00024448445328744127 |
| train_0/mu_grads          | -0.1441350683569908    |
| train_0/mu_grads_std      | 0.6638085246086121     |
| train_0/mu_loss           | 5.93433047670216       |
| train_0/next_q            | -5.764124459106618     |
| train_0/q_grads           | 0.04129541711881757    |
| train_0/q_grads_std       | 0.476480720937252      |
| train_0/q_loss            | 0.5795170330792628     |
| train_0/reward            | -0.7699562662324752    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.077490234375         |
| train_0/target_q          | -6.085554052204259     |
| train_1/avg_q             | -13.509463214230948    |
| train_1/current_q         | -11.475295143249081    |
| train_1/fw_bonus          | -0.9998300686478615    |
| train_1/fw_loss           | 0.0012545498670078815  |
| train_1/mu_grads          | -0.020205339649692178  |
| train_1/mu_grads_std      | 0.5899348080158233     |
| train_1/mu_loss           | 11.808927134773942     |
| train_1/n_subgoals        | 1870.0                 |
| train_1/next_q            | -11.52983090869989     |
| train_1/q_grads           | -0.07102237530052662   |
| train_1/q_grads_std       | 0.8010768800973892     |
| train_1/q_loss            | 7.562005722310931      |
| train_1/reward            | -1.9515566360150842    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0052978515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24438502673796791    |
| train_1/target_q          | -11.555160052387823    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.23333333333333334
Training epoch 51
Time for epoch 51: 533.62. Rollout time: 267.46, Training time: 266.04
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 2586984.0              |
| test/episodes             | 780.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.6267119343875776    |
| test_1/avg_q              | -14.193337308106404    |
| test_1/n_subgoals         | 3044.0                 |
| test_1/subgoal_succ_rate  | 0.9329829172141918     |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -11.066133208260437    |
| train_0/current_q         | -6.468574291464096     |
| train_0/fw_bonus          | -0.9987673670053482    |
| train_0/fw_loss           | 0.00030423007483477705 |
| train_0/mu_grads          | -0.14333815947175027   |
| train_0/mu_grads_std      | 0.6721509367227554     |
| train_0/mu_loss           | 6.2658405206355505     |
| train_0/next_q            | -6.118054505919945     |
| train_0/q_grads           | 0.04081093594431877    |
| train_0/q_grads_std       | 0.48053073063492774    |
| train_0/q_loss            | 0.6481704537885584     |
| train_0/reward            | -0.7711395934711618    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1043212890625        |
| train_0/target_q          | -6.41737459129895      |
| train_1/avg_q             | -14.482885447520118    |
| train_1/current_q         | -10.529767743070002    |
| train_1/fw_bonus          | -0.9862991437315941    |
| train_1/fw_loss           | 0.005250392912421376   |
| train_1/mu_grads          | -0.019456373201683162  |
| train_1/mu_grads_std      | 0.5949229627847672     |
| train_1/mu_loss           | 10.520628391850016     |
| train_1/n_subgoals        | 1621.0                 |
| train_1/next_q            | -10.378382283649207    |
| train_1/q_grads           | -0.07086683083325625   |
| train_1/q_grads_std       | 0.8063060447573662     |
| train_1/q_loss            | 5.49568888020282       |
| train_1/reward            | -1.897398764069294     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004443359375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3929673041332511     |
| train_1/target_q          | -10.636631626710592    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 52
Time for epoch 52: 549.62. Rollout time: 275.53, Training time: 273.97
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 2623714.0             |
| test/episodes             | 795.0                 |
| test/success_rate         | 0.4666666666666667    |
| test_0/avg_q              | -2.54938328008846     |
| test_1/avg_q              | -16.135210653039834   |
| test_1/n_subgoals         | 824.0                 |
| test_1/subgoal_succ_rate  | 0.7633495145631068    |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.74                  |
| train_0/avg_q             | -11.094042155126317   |
| train_0/current_q         | -5.058874561238542    |
| train_0/fw_bonus          | -0.9988243773579597   |
| train_0/fw_loss           | 0.0002904491819208488 |
| train_0/mu_grads          | -0.14395574741065503  |
| train_0/mu_grads_std      | 0.6797520816326141    |
| train_0/mu_loss           | 5.029758142239871     |
| train_0/next_q            | -4.819700486596551    |
| train_0/q_grads           | 0.04118100386112929   |
| train_0/q_grads_std       | 0.4839226804673672    |
| train_0/q_loss            | 0.92655512459514      |
| train_0/reward            | -0.7669424200586945   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.09501953125         |
| train_0/target_q          | -5.110819129177839    |
| train_1/avg_q             | -13.52787726123025    |
| train_1/current_q         | -10.744701938833462   |
| train_1/fw_bonus          | -0.9914172708988189   |
| train_1/fw_loss           | 0.0037389507342595607 |
| train_1/mu_grads          | -0.020170493889600037 |
| train_1/mu_grads_std      | 0.5998284921050072    |
| train_1/mu_loss           | 10.770128799271212    |
| train_1/n_subgoals        | 1555.0                |
| train_1/next_q            | -10.588882118184745   |
| train_1/q_grads           | -0.07143883537501097  |
| train_1/q_grads_std       | 0.814097934961319     |
| train_1/q_loss            | 5.6372768731190614    |
| train_1/reward            | -1.8997769242650975   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0058837890625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.38713826366559484   |
| train_1/target_q          | -10.864593193157372   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.23333333333333334
Training epoch 53
Time for epoch 53: 450.99. Rollout time: 204.36, Training time: 246.52
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 53                    |
| policy/steps              | 2659585.0             |
| test/episodes             | 810.0                 |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.9507373733868951   |
| test_1/avg_q              | -16.12739717586942    |
| test_1/n_subgoals         | 462.0                 |
| test_1/subgoal_succ_rate  | 0.15584415584415584   |
| train/episodes            | 5400.0                |
| train/success_rate        | 0.88                  |
| train_0/avg_q             | -10.361653392788504   |
| train_0/current_q         | -5.445166467823976    |
| train_0/fw_bonus          | -0.9989563003182411   |
| train_0/fw_loss           | 0.0002585565995104844 |
| train_0/mu_grads          | -0.14481537267565728  |
| train_0/mu_grads_std      | 0.685571326315403     |
| train_0/mu_loss           | 5.287892052867332     |
| train_0/next_q            | -5.135829487126925    |
| train_0/q_grads           | 0.04148616883903742   |
| train_0/q_grads_std       | 0.48634817600250246   |
| train_0/q_loss            | 0.9747199940546792    |
| train_0/reward            | -0.7671401988565776   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1055908203125       |
| train_0/target_q          | -5.43977418041881     |
| train_1/avg_q             | -13.69139227253479    |
| train_1/current_q         | -10.307880403842212   |
| train_1/fw_bonus          | -0.9944202750921249   |
| train_1/fw_loss           | 0.0028521270491182805 |
| train_1/mu_grads          | -0.020736457128077746 |
| train_1/mu_grads_std      | 0.6047973051667214    |
| train_1/mu_loss           | 10.101843765778284    |
| train_1/n_subgoals        | 1189.0                |
| train_1/next_q            | -9.941156217362671    |
| train_1/q_grads           | -0.07132556196302176  |
| train_1/q_grads_std       | 0.8194403558969497    |
| train_1/q_loss            | 6.144539196386029     |
| train_1/reward            | -1.9576382724197174   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006103515625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.29857022708158115   |
| train_1/target_q          | -10.407934509360924   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.23333333333333334
Training epoch 54
Time for epoch 54: 601.93. Rollout time: 317.48, Training time: 284.34
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 2696156.0              |
| test/episodes             | 825.0                  |
| test/success_rate         | 0.6666666666666666     |
| test_0/avg_q              | -1.8893287859054007    |
| test_1/avg_q              | -15.730065537358403    |
| test_1/n_subgoals         | 246.0                  |
| test_1/subgoal_succ_rate  | 0.33739837398373984    |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.82                   |
| train_0/avg_q             | -10.571796558678747    |
| train_0/current_q         | -5.322103670746237     |
| train_0/fw_bonus          | -0.9987070232629776    |
| train_0/fw_loss           | 0.00031881490249361375 |
| train_0/mu_grads          | -0.14686281830072404   |
| train_0/mu_grads_std      | 0.6915621072053909     |
| train_0/mu_loss           | 5.175844334341487      |
| train_0/next_q            | -5.035392207788654     |
| train_0/q_grads           | 0.04123662989586592    |
| train_0/q_grads_std       | 0.48924278244376185    |
| train_0/q_loss            | 0.9248211470521168     |
| train_0/reward            | -0.769952634263609     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0990234375           |
| train_0/target_q          | -5.354126456363021     |
| train_1/avg_q             | -13.347221011789651    |
| train_1/current_q         | -10.66657962565503     |
| train_1/fw_bonus          | -0.9949958816170692    |
| train_1/fw_loss           | 0.0026821420702617615  |
| train_1/mu_grads          | -0.021916422760114074  |
| train_1/mu_grads_std      | 0.609476637840271      |
| train_1/mu_loss           | 10.505235231509062     |
| train_1/n_subgoals        | 1501.0                 |
| train_1/next_q            | -10.358426289238784    |
| train_1/q_grads           | -0.06990038473159074   |
| train_1/q_grads_std       | 0.8238916471600533     |
| train_1/q_loss            | 6.443049075306922      |
| train_1/reward            | -1.930078316291474     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0068603515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.31845436375749503    |
| train_1/target_q          | -10.718455672920687    |
------------------------------------------------------
New best value for test/success_rate: 0.6666666666666666. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.35
Training epoch 55
Time for epoch 55: 535.75. Rollout time: 239.58, Training time: 296.06
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 2723114.0             |
| test/episodes             | 840.0                 |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -2.6642223505759204   |
| test_1/avg_q              | -13.484090460343545   |
| test_1/n_subgoals         | 1623.0                |
| test_1/subgoal_succ_rate  | 0.9987677141096735    |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -10.102848934781614   |
| train_0/current_q         | -5.378825305229338    |
| train_0/fw_bonus          | -0.9987131461501122   |
| train_0/fw_loss           | 0.0003173334469465772 |
| train_0/mu_grads          | -0.14662875458598137  |
| train_0/mu_grads_std      | 0.6986120745539666    |
| train_0/mu_loss           | 5.158219410165548     |
| train_0/next_q            | -4.969671956128234    |
| train_0/q_grads           | 0.0410990048199892    |
| train_0/q_grads_std       | 0.4906935505568981    |
| train_0/q_loss            | 0.5989900637232307    |
| train_0/reward            | -0.7782122231466928   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1094970703125       |
| train_0/target_q          | -5.3228761410816885   |
| train_1/avg_q             | -13.873836532718895   |
| train_1/current_q         | -10.310763686242277   |
| train_1/fw_bonus          | -0.9957395881414414   |
| train_1/fw_loss           | 0.002462516981177032  |
| train_1/mu_grads          | -0.022433400619775057 |
| train_1/mu_grads_std      | 0.6134094342589378    |
| train_1/mu_loss           | 10.096681509419902    |
| train_1/n_subgoals        | 1214.0                |
| train_1/next_q            | -9.96934034615518     |
| train_1/q_grads           | -0.07025326620787382  |
| train_1/q_grads_std       | 0.8324266210198402    |
| train_1/q_loss            | 5.714534113425392     |
| train_1/reward            | -1.9405364595870196   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0056396484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.35337726523887975   |
| train_1/target_q          | -10.377149933065551   |
-----------------------------------------------------
New best value for test/success_rate: 0.8. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 56
Time for epoch 56: 568.52. Rollout time: 281.57, Training time: 286.84
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 2757143.0              |
| test/episodes             | 855.0                  |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -0.0010792833020587269 |
| test_1/avg_q              | -7.920351429584253     |
| test_1/n_subgoals         | 246.0                  |
| test_1/subgoal_succ_rate  | 0.2886178861788618     |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.77                   |
| train_0/avg_q             | -9.586439126499931     |
| train_0/current_q         | -0.006555951377483942  |
| train_0/fw_bonus          | -0.9986878708004951    |
| train_0/fw_loss           | 0.0003234445997804869  |
| train_0/mu_grads          | -0.14917225167155265   |
| train_0/mu_grads_std      | 0.7039589166641236     |
| train_0/mu_loss           | 0.00513167222605126    |
| train_0/next_q            | -0.0047608715093065135 |
| train_0/q_grads           | 0.04095860049128532    |
| train_0/q_grads_std       | 0.49189442172646525    |
| train_0/q_loss            | 0.7212291647196803     |
| train_0/reward            | -0.7769974066839496    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.10380859375          |
| train_0/target_q          | -0.7814815061386583    |
| train_1/avg_q             | -13.84123037138807     |
| train_1/current_q         | -10.540340858456783    |
| train_1/fw_bonus          | -0.996145136654377     |
| train_1/fw_loss           | 0.002342755376594141   |
| train_1/mu_grads          | -0.022766183223575355  |
| train_1/mu_grads_std      | 0.6169060081243515     |
| train_1/mu_loss           | 10.267238443905237     |
| train_1/n_subgoals        | 1450.0                 |
| train_1/next_q            | -10.212302723618297    |
| train_1/q_grads           | -0.0703519394621253    |
| train_1/q_grads_std       | 0.8403579831123352     |
| train_1/q_loss            | 5.949874624986002      |
| train_1/reward            | -1.99185244407563      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0067626953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36482758620689654    |
| train_1/target_q          | -10.617498071120712    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5666666666666667
Training epoch 57
Time for epoch 57: 726.17. Rollout time: 387.85, Training time: 338.19
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 2794209.0             |
| test/episodes             | 870.0                 |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -2.967000159991152    |
| test_1/avg_q              | -12.321195529460907   |
| test_1/n_subgoals         | 200.0                 |
| test_1/subgoal_succ_rate  | 0.685                 |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.79                  |
| train_0/avg_q             | -4.876164729964329    |
| train_0/current_q         | -5.506718583341749    |
| train_0/fw_bonus          | -0.998805770277977    |
| train_0/fw_loss           | 0.0002949448829895118 |
| train_0/mu_grads          | -0.14768123552203177  |
| train_0/mu_grads_std      | 0.708184789121151     |
| train_0/mu_loss           | 5.279392468307447     |
| train_0/next_q            | -5.122287989891744    |
| train_0/q_grads           | 0.04129583640024066   |
| train_0/q_grads_std       | 0.4941940873861313    |
| train_0/q_loss            | 0.6192023310132052    |
| train_0/reward            | -0.7753606219699577   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.100537109375        |
| train_0/target_q          | -5.456791897611483    |
| train_1/avg_q             | -13.23424138316157    |
| train_1/current_q         | -10.602856567155671   |
| train_1/fw_bonus          | -0.996129709482193    |
| train_1/fw_loss           | 0.0023473111621569844 |
| train_1/mu_grads          | -0.023034445894882082 |
| train_1/mu_grads_std      | 0.6190922111272812    |
| train_1/mu_loss           | 10.395676698560948    |
| train_1/n_subgoals        | 1483.0                |
| train_1/next_q            | -10.28629897436214    |
| train_1/q_grads           | -0.070897520147264    |
| train_1/q_grads_std       | 0.84863401055336      |
| train_1/q_loss            | 5.858062747325035     |
| train_1/reward            | -1.9975065468966933   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007177734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21847606203641268   |
| train_1/target_q          | -10.669679919312603   |
-----------------------------------------------------
New best value for test/success_rate: 0.8. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.75
Training epoch 58
Time for epoch 58: 630.99. Rollout time: 334.19, Training time: 296.63
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 2834748.0              |
| test/episodes             | 885.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.3949878570824388    |
| test_1/avg_q              | -22.44187456327323     |
| test_1/n_subgoals         | 5580.0                 |
| test_1/subgoal_succ_rate  | 0.9663082437275986     |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -11.681675127976966    |
| train_0/current_q         | -5.783283719465259     |
| train_0/fw_bonus          | -0.9985634163022041    |
| train_0/fw_loss           | 0.00035353142047824806 |
| train_0/mu_grads          | -0.14886271879076957   |
| train_0/mu_grads_std      | 0.7108516380190849     |
| train_0/mu_loss           | 5.556723546773204      |
| train_0/next_q            | -5.379914081753261     |
| train_0/q_grads           | 0.041467773541808126   |
| train_0/q_grads_std       | 0.496859323233366      |
| train_0/q_loss            | 0.5633502578820597     |
| train_0/reward            | -0.7756662415689789    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0799072265625        |
| train_0/target_q          | -5.727224115077651     |
| train_1/avg_q             | -14.756240329956901    |
| train_1/current_q         | -9.964720373360539     |
| train_1/fw_bonus          | -0.9963448971509934    |
| train_1/fw_loss           | 0.0022837620694190265  |
| train_1/mu_grads          | -0.02218027519993484   |
| train_1/mu_grads_std      | 0.6243862539529801     |
| train_1/mu_loss           | 9.665355499397425      |
| train_1/n_subgoals        | 1411.0                 |
| train_1/next_q            | -9.576787273968222     |
| train_1/q_grads           | -0.07313387654721737   |
| train_1/q_grads_std       | 0.8581241816282272     |
| train_1/q_loss            | 10.111716707665812     |
| train_1/reward            | -2.089369426994017     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070556640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3330970942593905     |
| train_1/target_q          | -10.121134156029482    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6166666666666666
Training epoch 59
Time for epoch 59: 544.93. Rollout time: 254.34, Training time: 290.47
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 2870021.0             |
| test/episodes             | 900.0                 |
| test/success_rate         | 0.4666666666666667    |
| test_0/avg_q              | -1.6635948245344545   |
| test_1/avg_q              | -8.827903228822787    |
| test_1/n_subgoals         | 376.0                 |
| test_1/subgoal_succ_rate  | 0.4148936170212766    |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.85                  |
| train_0/avg_q             | -9.670875397678309    |
| train_0/current_q         | -5.725447692375105    |
| train_0/fw_bonus          | -0.9988312855362892   |
| train_0/fw_loss           | 0.0002887767088395776 |
| train_0/mu_grads          | -0.15156158357858657  |
| train_0/mu_grads_std      | 0.7157440826296806    |
| train_0/mu_loss           | 5.515874516967277     |
| train_0/next_q            | -5.346570577524988    |
| train_0/q_grads           | 0.041471301857382056  |
| train_0/q_grads_std       | 0.49810746908187864   |
| train_0/q_loss            | 0.705429796979934     |
| train_0/reward            | -0.778498104776736    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1223876953125       |
| train_0/target_q          | -5.692995894092226    |
| train_1/avg_q             | -15.512761195562028   |
| train_1/current_q         | -10.498114990807215   |
| train_1/fw_bonus          | -0.996172608435154    |
| train_1/fw_loss           | 0.0023346432979451494 |
| train_1/mu_grads          | -0.022012968175113203 |
| train_1/mu_grads_std      | 0.6287413835525513    |
| train_1/mu_loss           | 10.200786693547201    |
| train_1/n_subgoals        | 1479.0                |
| train_1/next_q            | -10.13281247896999    |
| train_1/q_grads           | -0.074395602196455    |
| train_1/q_grads_std       | 0.867315636575222     |
| train_1/q_loss            | 6.468836118969352     |
| train_1/reward            | -2.0063612650192226   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.005859375           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.42461122379986477   |
| train_1/target_q          | -10.547214354838262   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5333333333333333
Training epoch 60
Time for epoch 60: 557.82. Rollout time: 286.38, Training time: 271.33
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 2905333.0             |
| test/episodes             | 915.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.4413206332598125   |
| test_1/avg_q              | -17.41944906602038    |
| test_1/n_subgoals         | 1723.0                |
| test_1/subgoal_succ_rate  | 0.93905977945444      |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -8.789432305841663    |
| train_0/current_q         | -5.393101189168119    |
| train_0/fw_bonus          | -0.9988591820001602   |
| train_0/fw_loss           | 0.0002820348436216591 |
| train_0/mu_grads          | -0.1519896760582924   |
| train_0/mu_grads_std      | 0.7189935490489006    |
| train_0/mu_loss           | 5.160508870378857     |
| train_0/next_q            | -4.986117158640494    |
| train_0/q_grads           | 0.041332703456282614  |
| train_0/q_grads_std       | 0.49967521131038667   |
| train_0/q_loss            | 0.624254391838212     |
| train_0/reward            | -0.7800065421874024   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.113671875           |
| train_0/target_q          | -5.327761131071843    |
| train_1/avg_q             | -12.246940416564755   |
| train_1/current_q         | -10.119876201592772   |
| train_1/fw_bonus          | -0.9956742182374001   |
| train_1/fw_loss           | 0.002481821773108095  |
| train_1/mu_grads          | -0.021396310813724995 |
| train_1/mu_grads_std      | 0.6325090125203132    |
| train_1/mu_loss           | 9.89502446287778      |
| train_1/n_subgoals        | 1435.0                |
| train_1/next_q            | -9.781988453485171    |
| train_1/q_grads           | -0.07489182204008102  |
| train_1/q_grads_std       | 0.8763979390263558    |
| train_1/q_loss            | 6.474385695231166     |
| train_1/reward            | -1.9824146478211333   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064208984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3407665505226481    |
| train_1/target_q          | -10.224023281653974   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 61
Time for epoch 61: 489.31. Rollout time: 209.32, Training time: 279.88
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 2931772.0             |
| test/episodes             | 930.0                 |
| test/success_rate         | 0.9333333333333333    |
| test_0/avg_q              | -2.5257091406499943   |
| test_1/avg_q              | -7.182347425609111    |
| test_1/n_subgoals         | 758.0                 |
| test_1/subgoal_succ_rate  | 0.9577836411609498    |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.85                  |
| train_0/avg_q             | -10.225997854198088   |
| train_0/current_q         | -5.503412848910258    |
| train_0/fw_bonus          | -0.9988950490951538   |
| train_0/fw_loss           | 0.000273362086591078  |
| train_0/mu_grads          | -0.15534268990159034  |
| train_0/mu_grads_std      | 0.7240901634097099    |
| train_0/mu_loss           | 5.279244900776424     |
| train_0/next_q            | -5.101162624777385    |
| train_0/q_grads           | 0.04150308696553111   |
| train_0/q_grads_std       | 0.5025519460439682    |
| train_0/q_loss            | 0.6775915715266695    |
| train_0/reward            | -0.7785506679698301   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0908935546875       |
| train_0/target_q          | -5.41822742717345     |
| train_1/avg_q             | -14.220480330484301   |
| train_1/current_q         | -10.3404911469301     |
| train_1/fw_bonus          | -0.995985135436058    |
| train_1/fw_loss           | 0.002390004083281383  |
| train_1/mu_grads          | -0.021416244842112065 |
| train_1/mu_grads_std      | 0.6355878829956054    |
| train_1/mu_loss           | 10.151371991136395    |
| train_1/n_subgoals        | 1263.0                |
| train_1/next_q            | -10.008019591170866   |
| train_1/q_grads           | -0.0738246701657772   |
| train_1/q_grads_std       | 0.8853777304291726    |
| train_1/q_loss            | 6.688202320055801     |
| train_1/reward            | -2.0073764107764873   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00654296875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.42042755344418054   |
| train_1/target_q          | -10.419636852743842   |
-----------------------------------------------------
New best value for test/success_rate: 0.9333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5333333333333333
Training epoch 62
Time for epoch 62: 417.93. Rollout time: 169.09, Training time: 248.75
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 2958705.0             |
| test/episodes             | 945.0                 |
| test/success_rate         | 0.8                   |
| test_0/avg_q              | -3.0363655164867516   |
| test_1/avg_q              | -15.162569487125696   |
| test_1/n_subgoals         | 1359.0                |
| test_1/subgoal_succ_rate  | 0.9690949227373068    |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.9                   |
| train_0/avg_q             | -9.586132260627565    |
| train_0/current_q         | -5.633854890872692    |
| train_0/fw_bonus          | -0.9987856179475785   |
| train_0/fw_loss           | 0.0002998174422828015 |
| train_0/mu_grads          | -0.15505843050777912  |
| train_0/mu_grads_std      | 0.7293082252144814    |
| train_0/mu_loss           | 5.40167250890932      |
| train_0/next_q            | -5.206032270295596    |
| train_0/q_grads           | 0.0416755267418921    |
| train_0/q_grads_std       | 0.5067470759153366    |
| train_0/q_loss            | 0.5620187476766861    |
| train_0/reward            | -0.7849503093788371   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0937744140625       |
| train_0/target_q          | -5.579036032894431    |
| train_1/avg_q             | -13.244370327707129   |
| train_1/current_q         | -10.097799679453312   |
| train_1/fw_bonus          | -0.9961547091603279   |
| train_1/fw_loss           | 0.002339929871959612  |
| train_1/mu_grads          | -0.02142638126388192  |
| train_1/mu_grads_std      | 0.6386370316147805    |
| train_1/mu_loss           | 10.012426944638984    |
| train_1/n_subgoals        | 1159.0                |
| train_1/next_q            | -9.826294147677249    |
| train_1/q_grads           | -0.07368262335658074  |
| train_1/q_grads_std       | 0.8910916030406952    |
| train_1/q_loss            | 6.325445106998698     |
| train_1/reward            | -1.9660552772889788   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064208984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.40638481449525454   |
| train_1/target_q          | -10.200496858835084   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7
Training epoch 63
Time for epoch 63: 527.34. Rollout time: 231.52, Training time: 295.67
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 2991572.0             |
| test/episodes             | 960.0                 |
| test/success_rate         | 0.26666666666666666   |
| test_0/avg_q              | -0.6900507021137516   |
| test_1/avg_q              | -12.442006424871405   |
| test_1/n_subgoals         | 346.0                 |
| test_1/subgoal_succ_rate  | 0.06358381502890173   |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -10.298500863653596   |
| train_0/current_q         | -2.4924312947410137   |
| train_0/fw_bonus          | -0.998821522295475    |
| train_0/fw_loss           | 0.0002911387593485415 |
| train_0/mu_grads          | -0.15760305300354957  |
| train_0/mu_grads_std      | 0.732491397857666     |
| train_0/mu_loss           | 2.299973883218408     |
| train_0/next_q            | -2.2059353043166334   |
| train_0/q_grads           | 0.041938351653516295  |
| train_0/q_grads_std       | 0.5083899915218353    |
| train_0/q_loss            | 0.5234098204618108    |
| train_0/reward            | -0.7837874099634063   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.10859375            |
| train_0/target_q          | -2.8425880275426336   |
| train_1/avg_q             | -13.979883839271865   |
| train_1/current_q         | -9.683168513963853    |
| train_1/fw_bonus          | -0.996336854994297    |
| train_1/fw_loss           | 0.002286139302304946  |
| train_1/mu_grads          | -0.020863907039165498 |
| train_1/mu_grads_std      | 0.6420915961265564    |
| train_1/mu_loss           | 9.504354623663088     |
| train_1/n_subgoals        | 1218.0                |
| train_1/next_q            | -9.334857688340692    |
| train_1/q_grads           | -0.07475297171622515  |
| train_1/q_grads_std       | 0.8981198370456696    |
| train_1/q_loss            | 7.002459008565111     |
| train_1/reward            | -1.9353024731815822   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007421875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3924466338259442    |
| train_1/target_q          | -9.813856413230479    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6499999999999999
Training epoch 64
Time for epoch 64: 611.29. Rollout time: 306.86, Training time: 304.33
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 3027763.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.6483277634406792   |
| test_1/avg_q              | -10.212325388495323   |
| test_1/n_subgoals         | 307.0                 |
| test_1/subgoal_succ_rate  | 0.16938110749185667   |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -6.848637787275825    |
| train_0/current_q         | -5.3328246297267246   |
| train_0/fw_bonus          | -0.9989342793822289   |
| train_0/fw_loss           | 0.0002638823640154442 |
| train_0/mu_grads          | -0.16084079444408417  |
| train_0/mu_grads_std      | 0.7348604261875152    |
| train_0/mu_loss           | 5.092148154112008     |
| train_0/next_q            | -4.945348266952802    |
| train_0/q_grads           | 0.04185009840875864   |
| train_0/q_grads_std       | 0.51076238155365      |
| train_0/q_loss            | 0.627884824872776     |
| train_0/reward            | -0.7859762436855817   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1142333984375       |
| train_0/target_q          | -5.3272685404486255   |
| train_1/avg_q             | -13.699017037054965   |
| train_1/current_q         | -9.648236796572625    |
| train_1/fw_bonus          | -0.9962092757225036   |
| train_1/fw_loss           | 0.0023238099296577276 |
| train_1/mu_grads          | -0.02073685168288648  |
| train_1/mu_grads_std      | 0.6454887792468071    |
| train_1/mu_loss           | 9.36619900295669      |
| train_1/n_subgoals        | 1312.0                |
| train_1/next_q            | -9.213145432862575    |
| train_1/q_grads           | -0.07633473426103592  |
| train_1/q_grads_std       | 0.9065204605460166    |
| train_1/q_loss            | 7.3774967363079185    |
| train_1/reward            | -2.0220625747359007   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064697265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2614329268292683    |
| train_1/target_q          | -9.74128387531545     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6
Training epoch 65
Time for epoch 65: 527.66. Rollout time: 237.43, Training time: 290.06
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 3062317.0             |
| test/episodes             | 990.0                 |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.8341298905516967   |
| test_1/avg_q              | -14.469307349823104   |
| test_1/n_subgoals         | 1392.0                |
| test_1/subgoal_succ_rate  | 0.8692528735632183    |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -8.411957143132616    |
| train_0/current_q         | -5.465301125280252    |
| train_0/fw_bonus          | -0.9988940462470055   |
| train_0/fw_loss           | 0.0002736065191129455 |
| train_0/mu_grads          | -0.16175698414444922  |
| train_0/mu_grads_std      | 0.7384439632296562    |
| train_0/mu_loss           | 5.23586443972804      |
| train_0/next_q            | -5.047536576069922    |
| train_0/q_grads           | 0.042111946176737546  |
| train_0/q_grads_std       | 0.5135220199823379    |
| train_0/q_loss            | 0.5882767710296426    |
| train_0/reward            | -0.7904339600496314   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.121923828125        |
| train_0/target_q          | -5.431332229778684    |
| train_1/avg_q             | -13.26657390187093    |
| train_1/current_q         | -9.816412081356225    |
| train_1/fw_bonus          | -0.9958923950791359   |
| train_1/fw_loss           | 0.0024173903337214144 |
| train_1/mu_grads          | -0.020170259941369294 |
| train_1/mu_grads_std      | 0.6502748250961303    |
| train_1/mu_loss           | 9.483896314906207     |
| train_1/n_subgoals        | 1397.0                |
| train_1/next_q            | -9.329926475576615    |
| train_1/q_grads           | -0.0774678548797965   |
| train_1/q_grads_std       | 0.9147541895508766    |
| train_1/q_loss            | 6.845222363477944     |
| train_1/reward            | -2.004844681708346    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006689453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.36435218324982105   |
| train_1/target_q          | -9.901353583441173    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.4666666666666667
Training epoch 66
Time for epoch 66: 512.93. Rollout time: 221.11, Training time: 291.71
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 3090510.0              |
| test/episodes             | 1005.0                 |
| test/success_rate         | 0.6666666666666666     |
| test_0/avg_q              | -1.6935157364836033    |
| test_1/avg_q              | -14.945060988824908    |
| test_1/n_subgoals         | 2460.0                 |
| test_1/subgoal_succ_rate  | 0.9784552845528456     |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.87                   |
| train_0/avg_q             | -9.400197190755689     |
| train_0/current_q         | -5.434735114920379     |
| train_0/fw_bonus          | -0.9989479973912239    |
| train_0/fw_loss           | 0.00026056384267576506 |
| train_0/mu_grads          | -0.16439754739403725   |
| train_0/mu_grads_std      | 0.7418138042092324     |
| train_0/mu_loss           | 5.222031008144532      |
| train_0/next_q            | -5.028539133627156     |
| train_0/q_grads           | 0.04238850250840187    |
| train_0/q_grads_std       | 0.5158480405807495     |
| train_0/q_loss            | 0.5937524997859558     |
| train_0/reward            | -0.7916925662484573    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1094482421875        |
| train_0/target_q          | -5.40480329844754      |
| train_1/avg_q             | -13.455563569819054    |
| train_1/current_q         | -9.855644833818932     |
| train_1/fw_bonus          | -0.9966912269592285    |
| train_1/fw_loss           | 0.0021814890031237157  |
| train_1/mu_grads          | -0.018838540045544507  |
| train_1/mu_grads_std      | 0.6541072085499764     |
| train_1/mu_loss           | 9.538942064635865      |
| train_1/n_subgoals        | 1148.0                 |
| train_1/next_q            | -9.409554724258507     |
| train_1/q_grads           | -0.07853490021079779   |
| train_1/q_grads_std       | 0.9203033000230789     |
| train_1/q_loss            | 6.665568851502764      |
| train_1/reward            | -1.9851408228609215    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0064453125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.33885017421602787    |
| train_1/target_q          | -9.914971174563519     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.43333333333333335
Training epoch 67
Time for epoch 67: 513.58. Rollout time: 223.70, Training time: 289.76
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 3118726.0              |
| test/episodes             | 1020.0                 |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -1.9127155528496298    |
| test_1/avg_q              | -14.540952042347486    |
| test_1/n_subgoals         | 399.0                  |
| test_1/subgoal_succ_rate  | 0.6892230576441103     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.83                   |
| train_0/avg_q             | -9.351742119064337     |
| train_0/current_q         | -5.537511027594168     |
| train_0/fw_bonus          | -0.998993743956089     |
| train_0/fw_loss           | 0.00024950499209808186 |
| train_0/mu_grads          | -0.16545626074075698   |
| train_0/mu_grads_std      | 0.7449732646346092     |
| train_0/mu_loss           | 5.284202362319661      |
| train_0/next_q            | -5.140756145986782     |
| train_0/q_grads           | 0.0420430094935        |
| train_0/q_grads_std       | 0.5162839189171791     |
| train_0/q_loss            | 0.6693748351745148     |
| train_0/reward            | -0.7930772945055651    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.13671875             |
| train_0/target_q          | -5.48872900489647      |
| train_1/avg_q             | -12.0820907450887      |
| train_1/current_q         | -9.624632235429749     |
| train_1/fw_bonus          | -0.9961148992180824    |
| train_1/fw_loss           | 0.002351683931192383   |
| train_1/mu_grads          | -0.018875580839812757  |
| train_1/mu_grads_std      | 0.6561610519886016     |
| train_1/mu_loss           | 9.301782044233105      |
| train_1/n_subgoals        | 1186.0                 |
| train_1/next_q            | -9.20222298069508      |
| train_1/q_grads           | -0.07998278327286243   |
| train_1/q_grads_std       | 0.9261254608631134     |
| train_1/q_loss            | 6.765602185267822      |
| train_1/reward            | -1.9869376597765949    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071533203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.37436762225969644    |
| train_1/target_q          | -9.69872479785007      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.55
Training epoch 68
Time for epoch 68: 527.21. Rollout time: 238.74, Training time: 288.38
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 3150823.0             |
| test/episodes             | 1035.0                |
| test/success_rate         | 0.4666666666666667    |
| test_0/avg_q              | -3.00253828671063     |
| test_1/avg_q              | -8.351360491671363    |
| test_1/n_subgoals         | 1789.0                |
| test_1/subgoal_succ_rate  | 0.9653437674678591    |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -8.380172676641124    |
| train_0/current_q         | -5.3590315592607585   |
| train_0/fw_bonus          | -0.9989281088113785   |
| train_0/fw_loss           | 0.0002653713872859953 |
| train_0/mu_grads          | -0.16611482836306096  |
| train_0/mu_grads_std      | 0.748395812511444     |
| train_0/mu_loss           | 5.137713477504349     |
| train_0/next_q            | -4.947645025511608    |
| train_0/q_grads           | 0.04198732916265726   |
| train_0/q_grads_std       | 0.5171534821391106    |
| train_0/q_loss            | 0.600361795382185     |
| train_0/reward            | -0.7943975552512711   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1040283203125       |
| train_0/target_q          | -5.323797005526473    |
| train_1/avg_q             | -13.59409111752761    |
| train_1/current_q         | -9.792297176866986    |
| train_1/fw_bonus          | -0.9962862253189086   |
| train_1/fw_loss           | 0.002301088083186187  |
| train_1/mu_grads          | -0.02009982205927372  |
| train_1/mu_grads_std      | 0.6574891924858093    |
| train_1/mu_loss           | 9.440710384104317     |
| train_1/n_subgoals        | 1228.0                |
| train_1/next_q            | -9.379925278669603    |
| train_1/q_grads           | -0.08084774278104305  |
| train_1/q_grads_std       | 0.9320348918437957    |
| train_1/q_loss            | 6.934085197016216     |
| train_1/reward            | -1.9200920636994852   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0069091796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.32003257328990226   |
| train_1/target_q          | -9.872995893099114    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5666666666666667
Training epoch 69
Time for epoch 69: 498.06. Rollout time: 229.17, Training time: 268.76
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 69                    |
| policy/steps              | 3182917.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -2.7120368066011364   |
| test_1/avg_q              | -12.693510642949946   |
| test_1/n_subgoals         | 1161.0                |
| test_1/subgoal_succ_rate  | 0.9233419465977606    |
| train/episodes            | 7000.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -8.694566721505756    |
| train_0/current_q         | -5.080460825479607    |
| train_0/fw_bonus          | -0.9989183634519577   |
| train_0/fw_loss           | 0.0002677267555554863 |
| train_0/mu_grads          | -0.16537593267858028  |
| train_0/mu_grads_std      | 0.7515390619635582    |
| train_0/mu_loss           | 4.842844632682014     |
| train_0/next_q            | -4.652924234144507    |
| train_0/q_grads           | 0.04186066761612892   |
| train_0/q_grads_std       | 0.517751170694828     |
| train_0/q_loss            | 0.6000013493743885    |
| train_0/reward            | -0.7980755392010905   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1177978515625       |
| train_0/target_q          | -5.039521249957292    |
| train_1/avg_q             | -13.411802635450027   |
| train_1/current_q         | -9.645274482575568    |
| train_1/fw_bonus          | -0.9957571387290954   |
| train_1/fw_loss           | 0.00245733130723238   |
| train_1/mu_grads          | -0.01944947652518749  |
| train_1/mu_grads_std      | 0.659318819642067     |
| train_1/mu_loss           | 9.38485116906991      |
| train_1/n_subgoals        | 1328.0                |
| train_1/next_q            | -9.24768137700386     |
| train_1/q_grads           | -0.08144588004797697  |
| train_1/q_grads_std       | 0.9398848116397858    |
| train_1/q_loss            | 7.105414304333832     |
| train_1/reward            | -1.926679765148947    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007080078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.35240963855421686   |
| train_1/target_q          | -9.72795589776582     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6333333333333333
Training epoch 70
Time for epoch 70: 443.76. Rollout time: 202.24, Training time: 241.40
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 3213116.0              |
| test/episodes             | 1065.0                 |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -2.931792121003971     |
| test_1/avg_q              | -13.650955671481228    |
| test_1/n_subgoals         | 511.0                  |
| test_1/subgoal_succ_rate  | 0.8454011741682974     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -8.321606910803608     |
| train_0/current_q         | -5.078636270828204     |
| train_0/fw_bonus          | -0.9986217573285103    |
| train_0/fw_loss           | 0.00033942629452212716 |
| train_0/mu_grads          | -0.16689232997596265   |
| train_0/mu_grads_std      | 0.7557047352194786     |
| train_0/mu_loss           | 4.885164515988355      |
| train_0/next_q            | -4.685210445241573     |
| train_0/q_grads           | 0.041846856102347375   |
| train_0/q_grads_std       | 0.5182245299220085     |
| train_0/q_loss            | 0.6792397038397351     |
| train_0/reward            | -0.7998507513115328    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1318603515625        |
| train_0/target_q          | -5.065035984988993     |
| train_1/avg_q             | -13.033970400830599    |
| train_1/current_q         | -9.946970652151919     |
| train_1/fw_bonus          | -0.995377105474472     |
| train_1/fw_loss           | 0.0025695650023408235  |
| train_1/mu_grads          | -0.019274430768564343  |
| train_1/mu_grads_std      | 0.6615182995796204     |
| train_1/mu_loss           | 9.61447812201757       |
| train_1/n_subgoals        | 1279.0                 |
| train_1/next_q            | -9.561114112983198     |
| train_1/q_grads           | -0.08192838225513696   |
| train_1/q_grads_std       | 0.9471303671598434     |
| train_1/q_loss            | 6.396085402448378      |
| train_1/reward            | -1.964597449313078     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0062744140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.364347146207975      |
| train_1/target_q          | -10.013907407881513    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.65
Training epoch 71
Time for epoch 71: 456.01. Rollout time: 206.13, Training time: 249.79
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 3244648.0             |
| test/episodes             | 1080.0                |
| test/success_rate         | 0.8666666666666667    |
| test_0/avg_q              | -2.557827783392727    |
| test_1/avg_q              | -13.571767503979602   |
| test_1/n_subgoals         | 2266.0                |
| test_1/subgoal_succ_rate  | 0.9872021182700794    |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.8                   |
| train_0/avg_q             | -10.308736962907773   |
| train_0/current_q         | -5.685007993896131    |
| train_0/fw_bonus          | -0.9985499769449234   |
| train_0/fw_loss           | 0.0003567771116649965 |
| train_0/mu_grads          | -0.16818924844264985  |
| train_0/mu_grads_std      | 0.7601502105593682    |
| train_0/mu_loss           | 5.467997785439978     |
| train_0/next_q            | -5.267100031978141    |
| train_0/q_grads           | 0.041566638927906754  |
| train_0/q_grads_std       | 0.5181036785244941    |
| train_0/q_loss            | 0.6495044463498358    |
| train_0/reward            | -0.8013708926897379   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0860107421875       |
| train_0/target_q          | -5.6297837329118625   |
| train_1/avg_q             | -13.48616794105848    |
| train_1/current_q         | -9.517892940805945    |
| train_1/fw_bonus          | -0.9955502718687057   |
| train_1/fw_loss           | 0.002518426306778565  |
| train_1/mu_grads          | -0.019394650077447294 |
| train_1/mu_grads_std      | 0.6651190504431724    |
| train_1/mu_loss           | 9.077915640181175     |
| train_1/n_subgoals        | 1365.0                |
| train_1/next_q            | -8.983331825809367    |
| train_1/q_grads           | -0.08288797698915004  |
| train_1/q_grads_std       | 0.9525483384728431    |
| train_1/q_loss            | 6.617102894247203     |
| train_1/reward            | -1.9835006039444125   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00634765625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.35824175824175825   |
| train_1/target_q          | -9.58486094653885     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6833333333333333
Training epoch 72
Time for epoch 72: 3412.59. Rollout time: 237.31, Training time: 3175.17
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 3270831.0             |
| test/episodes             | 1095.0                |
| test/success_rate         | 0.8666666666666667    |
| test_0/avg_q              | -2.798472084116674    |
| test_1/avg_q              | -12.19173434984668    |
| test_1/n_subgoals         | 1623.0                |
| test_1/subgoal_succ_rate  | 0.9858287122612446    |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.92                  |
| train_0/avg_q             | -9.27653238965648     |
| train_0/current_q         | -4.847103601780054    |
| train_0/fw_bonus          | -0.9985168159008027   |
| train_0/fw_loss           | 0.0003647934070613701 |
| train_0/mu_grads          | -0.16857010796666144  |
| train_0/mu_grads_std      | 0.7639351829886436    |
| train_0/mu_loss           | 4.5653253728291565    |
| train_0/next_q            | -4.396354638304765    |
| train_0/q_grads           | 0.041409154608845714  |
| train_0/q_grads_std       | 0.5183920934796333    |
| train_0/q_loss            | 0.6050438079131469    |
| train_0/reward            | -0.8032852095580892   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.118408203125        |
| train_0/target_q          | -4.796046520096544    |
| train_1/avg_q             | -12.989424216023133   |
| train_1/current_q         | -9.374703631681566    |
| train_1/fw_bonus          | -0.9961113288998604   |
| train_1/fw_loss           | 0.0023527391662355513 |
| train_1/mu_grads          | -0.019602103810757398 |
| train_1/mu_grads_std      | 0.66956367790699      |
| train_1/mu_loss           | 8.941639632710373     |
| train_1/n_subgoals        | 1182.0                |
| train_1/next_q            | -8.86926643383325     |
| train_1/q_grads           | -0.08349427152425051  |
| train_1/q_grads_std       | 0.9595978111028671    |
| train_1/q_loss            | 6.048877766153079     |
| train_1/reward            | -1.9220624990870419   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006640625           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.41624365482233505   |
| train_1/target_q          | -9.452503659724268    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7833333333333333
Training epoch 73
Time for epoch 73: 387.43. Rollout time: 140.59, Training time: 246.74
Evaluating epoch 73
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 3292158.0             |
| test/episodes             | 1110.0                |
| test/success_rate         | 0.8666666666666667    |
| test_0/avg_q              | -2.7886253477195955   |
| test_1/avg_q              | -17.94061419564752    |
| test_1/n_subgoals         | 529.0                 |
| test_1/subgoal_succ_rate  | 0.9848771266540642    |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.88                  |
| train_0/avg_q             | -7.808484309179473    |
| train_0/current_q         | -4.811059900816952    |
| train_0/fw_bonus          | -0.9983278378844261   |
| train_0/fw_loss           | 0.0004104756779270247 |
| train_0/mu_grads          | -0.1686368476599455   |
| train_0/mu_grads_std      | 0.76548852622509      |
| train_0/mu_loss           | 4.504286210773237     |
| train_0/next_q            | -4.356256910462508    |
| train_0/q_grads           | 0.04161445712670684   |
| train_0/q_grads_std       | 0.5187052264809608    |
| train_0/q_loss            | 0.5791280560086596    |
| train_0/reward            | -0.8043915284244576   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0718505859375       |
| train_0/target_q          | -4.766469205779579    |
| train_1/avg_q             | -12.137997697823133   |
| train_1/current_q         | -9.407525304897018    |
| train_1/fw_bonus          | -0.9958337977528572   |
| train_1/fw_loss           | 0.0024346965132281185 |
| train_1/mu_grads          | -0.018840588722378017 |
| train_1/mu_grads_std      | 0.6746781781315804    |
| train_1/mu_loss           | 8.969887182302001     |
| train_1/n_subgoals        | 1095.0                |
| train_1/next_q            | -8.871944914078936    |
| train_1/q_grads           | -0.0840296832844615   |
| train_1/q_grads_std       | 0.9677911475300789    |
| train_1/q_loss            | 6.191064423637378     |
| train_1/reward            | -1.9135519553194171   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0063720703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4940639269406393    |
| train_1/target_q          | -9.48150265588531     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8333333333333334
Training epoch 74
Time for epoch 74: 2053.60. Rollout time: 160.48, Training time: 1893.03
Evaluating epoch 74
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 3315389.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.7333333333333333    |
| test_0/avg_q              | -3.039752232550499    |
| test_1/avg_q              | -12.072585319275724   |
| test_1/n_subgoals         | 2217.0                |
| test_1/subgoal_succ_rate  | 0.9945872801082544    |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -8.120462905509488    |
| train_0/current_q         | -5.571404791018957    |
| train_0/fw_bonus          | -0.998333178460598    |
| train_0/fw_loss           | 0.0004091851064004004 |
| train_0/mu_grads          | -0.16975537315011024  |
| train_0/mu_grads_std      | 0.7675531283020973    |
| train_0/mu_loss           | 5.3809857925051245    |
| train_0/next_q            | -5.152503090575071    |
| train_0/q_grads           | 0.04110852815210819   |
| train_0/q_grads_std       | 0.5198086842894554    |
| train_0/q_loss            | 0.7466392299222865    |
| train_0/reward            | -0.8047773847796634   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0882568359375       |
| train_0/target_q          | -5.5061933460185255   |
| train_1/avg_q             | -12.30154530167431    |
| train_1/current_q         | -9.475725372805707    |
| train_1/fw_bonus          | -0.9958938911557198   |
| train_1/fw_loss           | 0.002416951220948249  |
| train_1/mu_grads          | -0.01916300258599222  |
| train_1/mu_grads_std      | 0.6798987478017807    |
| train_1/mu_loss           | 9.048040726694632     |
| train_1/n_subgoals        | 1222.0                |
| train_1/next_q            | -8.926602475588558    |
| train_1/q_grads           | -0.08469096776098013  |
| train_1/q_grads_std       | 0.9779208436608314    |
| train_1/q_loss            | 6.310124805899731     |
| train_1/reward            | -1.9086963715450112   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006689453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.5417348608837971    |
| train_1/target_q          | -9.53283983643791     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8333333333333334
Training epoch 75
Time for epoch 75: 414.07. Rollout time: 139.71, Training time: 274.24
Evaluating epoch 75
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 75                     |
| policy/steps              | 3333565.0              |
| test/episodes             | 1140.0                 |
| test/success_rate         | 0.8                    |
| test_0/avg_q              | -2.1437473336411       |
| test_1/avg_q              | -13.81924893526208     |
| test_1/n_subgoals         | 1741.0                 |
| test_1/subgoal_succ_rate  | 0.9977024698449167     |
| train/episodes            | 7600.0                 |
| train/success_rate        | 0.98                   |
| train_0/avg_q             | -10.269798842404875    |
| train_0/current_q         | -5.407199142911638     |
| train_0/fw_bonus          | -0.9984060198068618    |
| train_0/fw_loss           | 0.00039157626633823384 |
| train_0/mu_grads          | -0.17152556106448175   |
| train_0/mu_grads_std      | 0.7711487874388695     |
| train_0/mu_loss           | 5.156079957034481      |
| train_0/next_q            | -4.956214517735285     |
| train_0/q_grads           | 0.040368118323385715   |
| train_0/q_grads_std       | 0.5197604462504387     |
| train_0/q_loss            | 0.626188321524907      |
| train_0/reward            | -0.801444765927954     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.061669921875         |
| train_0/target_q          | -5.326959166225414     |
| train_1/avg_q             | -11.530293314190635    |
| train_1/current_q         | -9.009294481595973     |
| train_1/fw_bonus          | -0.9956365808844566    |
| train_1/fw_loss           | 0.002492937655188143   |
| train_1/mu_grads          | -0.020602780999615787  |
| train_1/mu_grads_std      | 0.684221975505352      |
| train_1/mu_loss           | 8.539294474084093      |
| train_1/n_subgoals        | 884.0                  |
| train_1/next_q            | -8.425008864396798     |
| train_1/q_grads           | -0.0845404777675867    |
| train_1/q_grads_std       | 0.9883803442120552     |
| train_1/q_loss            | 5.945426437856932      |
| train_1/reward            | -1.8674150040609674    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070068359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4751131221719457     |
| train_1/target_q          | -9.075860964954654     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8166666666666667
Training epoch 76
Time for epoch 76: 465.92. Rollout time: 183.41, Training time: 282.39
Evaluating epoch 76
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 3358146.0             |
| test/episodes             | 1155.0                |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -3.303190415797455    |
| test_1/avg_q              | -12.81060329656745    |
| test_1/n_subgoals         | 3055.0                |
| test_1/subgoal_succ_rate  | 0.9905073649754501    |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.88                  |
| train_0/avg_q             | -9.234117392003135    |
| train_0/current_q         | -5.4418284199082025   |
| train_0/fw_bonus          | -0.9986695200204849   |
| train_0/fw_loss           | 0.0003278771782788681 |
| train_0/mu_grads          | -0.17299638800323008  |
| train_0/mu_grads_std      | 0.7741927027702331    |
| train_0/mu_loss           | 5.2713686977053005    |
| train_0/next_q            | -5.021299992023074    |
| train_0/q_grads           | 0.04020831175148487   |
| train_0/q_grads_std       | 0.5199186965823174    |
| train_0/q_loss            | 0.7384750579710906    |
| train_0/reward            | -0.8017486820215709   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1104736328125       |
| train_0/target_q          | -5.38942407941378     |
| train_1/avg_q             | -11.698392436571071   |
| train_1/current_q         | -8.601396748375072    |
| train_1/fw_bonus          | -0.9962372958660126   |
| train_1/fw_loss           | 0.002315539336996153  |
| train_1/mu_grads          | -0.020506622083485127 |
| train_1/mu_grads_std      | 0.6898497879505158    |
| train_1/mu_loss           | 8.204652278828442     |
| train_1/n_subgoals        | 1181.0                |
| train_1/next_q            | -8.115726791622967    |
| train_1/q_grads           | -0.08486647997051477  |
| train_1/q_grads_std       | 0.9977733716368675    |
| train_1/q_loss            | 5.601658853445062     |
| train_1/reward            | -1.8239311487570375   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064453125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.519051651143099     |
| train_1/target_q          | -8.699747858353266    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7666666666666667
Training epoch 77
Time for epoch 77: 381.86. Rollout time: 138.55, Training time: 243.21
Evaluating epoch 77
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 77                     |
| policy/steps              | 3383131.0              |
| test/episodes             | 1170.0                 |
| test/success_rate         | 0.5333333333333333     |
| test_0/avg_q              | -3.3253163087943634    |
| test_1/avg_q              | -13.914157503232103    |
| test_1/n_subgoals         | 3354.0                 |
| test_1/subgoal_succ_rate  | 0.9883720930232558     |
| train/episodes            | 7800.0                 |
| train/success_rate        | 0.87                   |
| train_0/avg_q             | -10.299702439052869    |
| train_0/current_q         | -5.591614351765218     |
| train_0/fw_bonus          | -0.998621940612793     |
| train_0/fw_loss           | 0.00033938156157091725 |
| train_0/mu_grads          | -0.17384360991418363   |
| train_0/mu_grads_std      | 0.7764267668128013     |
| train_0/mu_loss           | 5.383990744339561      |
| train_0/next_q            | -5.156244548711766     |
| train_0/q_grads           | 0.04002275504171848    |
| train_0/q_grads_std       | 0.5217140898108482     |
| train_0/q_loss            | 0.5966252705990263     |
| train_0/reward            | -0.7982577800536091    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1162841796875        |
| train_0/target_q          | -5.542080178586998     |
| train_1/avg_q             | -12.238798699122784    |
| train_1/current_q         | -8.828555550380148     |
| train_1/fw_bonus          | -0.9962733045220376    |
| train_1/fw_loss           | 0.0023049052542774007  |
| train_1/mu_grads          | -0.02077183243818581   |
| train_1/mu_grads_std      | 0.694793501496315      |
| train_1/mu_loss           | 8.363770613443336      |
| train_1/n_subgoals        | 1082.0                 |
| train_1/next_q            | -8.270822606860097     |
| train_1/q_grads           | -0.08659053146839142   |
| train_1/q_grads_std       | 1.0091891705989837     |
| train_1/q_loss            | 6.072222730091886      |
| train_1/reward            | -1.8235556293402624    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007568359375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.49815157116451014    |
| train_1/target_q          | -8.864564160226497     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6833333333333332
Training epoch 78
Time for epoch 78: 422.78. Rollout time: 143.83, Training time: 278.81
Evaluating epoch 78
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 3402901.0             |
| test/episodes             | 1185.0                |
| test/success_rate         | 0.7333333333333333    |
| test_0/avg_q              | -1.7796553679101972   |
| test_1/avg_q              | -13.46214650813465    |
| test_1/n_subgoals         | 2967.0                |
| test_1/subgoal_succ_rate  | 0.9986518368722616    |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.96                  |
| train_0/avg_q             | -9.952943558425915    |
| train_0/current_q         | -5.417755558842719    |
| train_0/fw_bonus          | -0.9984558716416359   |
| train_0/fw_loss           | 0.0003795286833337741 |
| train_0/mu_grads          | -0.17531645372509957  |
| train_0/mu_grads_std      | 0.7799478903412819    |
| train_0/mu_loss           | 5.1550800402367996    |
| train_0/next_q            | -4.960288348837383    |
| train_0/q_grads           | 0.03994648540392518   |
| train_0/q_grads_std       | 0.5232443511486053    |
| train_0/q_loss            | 0.5687700642764576    |
| train_0/reward            | -0.7995895502070198   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.09873046875         |
| train_0/target_q          | -5.363019720656974    |
| train_1/avg_q             | -11.327643424966453   |
| train_1/current_q         | -8.589880085928048    |
| train_1/fw_bonus          | -0.9964723512530327   |
| train_1/fw_loss           | 0.0022461178625235332 |
| train_1/mu_grads          | -0.01948160198517144  |
| train_1/mu_grads_std      | 0.7008135125041008    |
| train_1/mu_loss           | 8.139536584700176     |
| train_1/n_subgoals        | 863.0                 |
| train_1/next_q            | -8.034811671796996    |
| train_1/q_grads           | -0.08792658429592848  |
| train_1/q_grads_std       | 1.01988143324852      |
| train_1/q_loss            | 6.628199450503549     |
| train_1/reward            | -1.816812183039292    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006201171875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4855156431054461    |
| train_1/target_q          | -8.649149876436862    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6833333333333333
Training epoch 79
Time for epoch 79: 431.94. Rollout time: 155.18, Training time: 276.63
Evaluating epoch 79
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 3425087.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -2.379927839083444     |
| test_1/avg_q              | -10.70486649641968     |
| test_1/n_subgoals         | 2560.0                 |
| test_1/subgoal_succ_rate  | 0.980859375            |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.9                    |
| train_0/avg_q             | -10.025173523814328    |
| train_0/current_q         | -5.2163719645801505    |
| train_0/fw_bonus          | -0.9986053794622421    |
| train_0/fw_loss           | 0.00034338359473622403 |
| train_0/mu_grads          | -0.1752740353345871    |
| train_0/mu_grads_std      | 0.782162094116211      |
| train_0/mu_loss           | 4.978438260466942      |
| train_0/next_q            | -4.7801964192618485    |
| train_0/q_grads           | 0.0399567567743361     |
| train_0/q_grads_std       | 0.5240506872534751     |
| train_0/q_loss            | 0.5493485434080113     |
| train_0/reward            | -0.8001030062430801    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.129541015625         |
| train_0/target_q          | -5.202211534952771     |
| train_1/avg_q             | -11.63054976223002     |
| train_1/current_q         | -8.31502378638207      |
| train_1/fw_bonus          | -0.9963393107056617    |
| train_1/fw_loss           | 0.002285412183846347   |
| train_1/mu_grads          | -0.019370165746659042  |
| train_1/mu_grads_std      | 0.7049051627516747     |
| train_1/mu_loss           | 7.8161099797876235     |
| train_1/n_subgoals        | 1078.0                 |
| train_1/next_q            | -7.730646117719037     |
| train_1/q_grads           | -0.08795680478215218   |
| train_1/q_grads_std       | 1.0278704732656478     |
| train_1/q_loss            | 6.003136127436056      |
| train_1/reward            | -1.8206241333788058    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.5204081632653061     |
| train_1/target_q          | -8.38702141270699      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6666666666666666
Training epoch 80
Time for epoch 80: 443.41. Rollout time: 160.12, Training time: 283.21
Evaluating epoch 80
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 3444630.0              |
| test/episodes             | 1215.0                 |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -1.2092025537726194    |
| test_1/avg_q              | -14.8827886363415      |
| test_1/n_subgoals         | 1179.0                 |
| test_1/subgoal_succ_rate  | 0.9626802374893978     |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.91                   |
| train_0/avg_q             | -9.740511439743909     |
| train_0/current_q         | -5.5104266576031184    |
| train_0/fw_bonus          | -0.9986703857779503    |
| train_0/fw_loss           | 0.00032767162301752253 |
| train_0/mu_grads          | -0.17704259641468525   |
| train_0/mu_grads_std      | 0.7845832154154777     |
| train_0/mu_loss           | 5.2240616878182        |
| train_0/next_q            | -5.021829404315582     |
| train_0/q_grads           | 0.0397393018938601     |
| train_0/q_grads_std       | 0.5228640168905259     |
| train_0/q_loss            | 0.47654576372563506    |
| train_0/reward            | -0.8005587087634922    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1177734375           |
| train_0/target_q          | -5.456505603148651     |
| train_1/avg_q             | -10.546859129020262    |
| train_1/current_q         | -8.375945691330628     |
| train_1/fw_bonus          | -0.9958553805947303    |
| train_1/fw_loss           | 0.00242832395597361    |
| train_1/mu_grads          | -0.019377269921824335  |
| train_1/mu_grads_std      | 0.7084365025162697     |
| train_1/mu_loss           | 7.8676343438733        |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -7.767443956441113     |
| train_1/q_grads           | -0.0889923058450222    |
| train_1/q_grads_std       | 1.0353396385908127     |
| train_1/q_loss            | 6.386385811832905      |
| train_1/reward            | -1.8036574465517332    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00703125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.533                  |
| train_1/target_q          | -8.456681881408688     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6833333333333333
Training epoch 81
Time for epoch 81: 433.93. Rollout time: 158.52, Training time: 275.32
Evaluating epoch 81
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 3464873.0             |
| test/episodes             | 1230.0                |
| test/success_rate         | 0.8666666666666667    |
| test_0/avg_q              | -1.7606287528946258   |
| test_1/avg_q              | -10.099084532201664   |
| test_1/n_subgoals         | 1323.0                |
| test_1/subgoal_succ_rate  | 0.9750566893424036    |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.94                  |
| train_0/avg_q             | -10.446209245871636   |
| train_0/current_q         | -5.722994464821461    |
| train_0/fw_bonus          | -0.9986106485128403   |
| train_0/fw_loss           | 0.0003421142198931193 |
| train_0/mu_grads          | -0.178553307056427    |
| train_0/mu_grads_std      | 0.7871042206883431    |
| train_0/mu_loss           | 5.4353503884994865    |
| train_0/next_q            | -5.237252141818084    |
| train_0/q_grads           | 0.03977211462333798   |
| train_0/q_grads_std       | 0.5232714757323265    |
| train_0/q_loss            | 0.4238692617754737    |
| train_0/reward            | -0.8003423561454838   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.125732421875        |
| train_0/target_q          | -5.6849956321883415   |
| train_1/avg_q             | -11.437504741289862   |
| train_1/current_q         | -8.541698383545357    |
| train_1/fw_bonus          | -0.9963488712906837   |
| train_1/fw_loss           | 0.0022825902327895165 |
| train_1/mu_grads          | -0.02055425550788641  |
| train_1/mu_grads_std      | 0.711875070631504     |
| train_1/mu_loss           | 8.124882980456714     |
| train_1/n_subgoals        | 998.0                 |
| train_1/next_q            | -7.999121818171451    |
| train_1/q_grads           | -0.08991114310920238  |
| train_1/q_grads_std       | 1.042788740992546     |
| train_1/q_loss            | 6.186994510782621     |
| train_1/reward            | -1.7602566499339445   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0062255859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.45691382765531063   |
| train_1/target_q          | -8.60884777703366     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7666666666666666
Training epoch 82
Time for epoch 82: 438.36. Rollout time: 150.47, Training time: 287.77
Evaluating epoch 82
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 3484545.0             |
| test/episodes             | 1245.0                |
| test/success_rate         | 0.7333333333333333    |
| test_0/avg_q              | -1.4106175591949088   |
| test_1/avg_q              | -13.015973207734357   |
| test_1/n_subgoals         | 1394.0                |
| test_1/subgoal_succ_rate  | 0.9626972740315638    |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.91                  |
| train_0/avg_q             | -10.913754569242299   |
| train_0/current_q         | -5.987715274748218    |
| train_0/fw_bonus          | -0.9983558923006057   |
| train_0/fw_loss           | 0.0004036954494949896 |
| train_0/mu_grads          | -0.1806602541357279   |
| train_0/mu_grads_std      | 0.7898534268140793    |
| train_0/mu_loss           | 5.737204845312295     |
| train_0/next_q            | -5.536442613333188    |
| train_0/q_grads           | 0.03996099960058928   |
| train_0/q_grads_std       | 0.5267195835709572    |
| train_0/q_loss            | 0.47699257996424727   |
| train_0/reward            | -0.7985940973965626   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1080810546875       |
| train_0/target_q          | -5.964720143200784    |
| train_1/avg_q             | -10.695010180530643   |
| train_1/current_q         | -8.013453034128464    |
| train_1/fw_bonus          | -0.9958200693130493   |
| train_1/fw_loss           | 0.0024387485987972467 |
| train_1/mu_grads          | -0.02185098910704255  |
| train_1/mu_grads_std      | 0.7147137999534607    |
| train_1/mu_loss           | 7.534033396703376     |
| train_1/n_subgoals        | 951.0                 |
| train_1/next_q            | -7.443746175110869    |
| train_1/q_grads           | -0.09165735952556134  |
| train_1/q_grads_std       | 1.049007034301758     |
| train_1/q_loss            | 6.155367683920087     |
| train_1/reward            | -1.7348192766014108   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00673828125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4952681388012618    |
| train_1/target_q          | -8.064670048795188    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7666666666666666
Training epoch 83
Time for epoch 83: 410.54. Rollout time: 139.92, Training time: 270.52
Evaluating epoch 83
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 83                     |
| policy/steps              | 3502661.0              |
| test/episodes             | 1260.0                 |
| test/success_rate         | 0.8666666666666667     |
| test_0/avg_q              | -1.52408497970818      |
| test_1/avg_q              | -11.621425286202662    |
| test_1/n_subgoals         | 143.0                  |
| test_1/subgoal_succ_rate  | 0.5594405594405595     |
| train/episodes            | 8400.0                 |
| train/success_rate        | 0.95                   |
| train_0/avg_q             | -12.056145435295658    |
| train_0/current_q         | -6.211545827771132     |
| train_0/fw_bonus          | -0.9984440922737121    |
| train_0/fw_loss           | 0.00038237619010033085 |
| train_0/mu_grads          | -0.18056718483567238   |
| train_0/mu_grads_std      | 0.7908272981643677     |
| train_0/mu_loss           | 5.955730442306189      |
| train_0/next_q            | -5.750907151532563     |
| train_0/q_grads           | 0.04036850668489933    |
| train_0/q_grads_std       | 0.5307768106460571     |
| train_0/q_loss            | 0.40675764307849854    |
| train_0/reward            | -0.7976090660893533    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11787109375          |
| train_0/target_q          | -6.2057850345966505    |
| train_1/avg_q             | -10.442742404059507    |
| train_1/current_q         | -7.601649155068145     |
| train_1/fw_bonus          | -0.995903666317463     |
| train_1/fw_loss           | 0.0024140631780028344  |
| train_1/mu_grads          | -0.022419673390686512  |
| train_1/mu_grads_std      | 0.7189217254519462     |
| train_1/mu_loss           | 7.117725464595681      |
| train_1/n_subgoals        | 940.0                  |
| train_1/next_q            | -7.0225520891369015    |
| train_1/q_grads           | -0.09243008624762297   |
| train_1/q_grads_std       | 1.0557447224855423     |
| train_1/q_loss            | 6.10543913218794       |
| train_1/reward            | -1.7198255268838694    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071533203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.49042553191489363    |
| train_1/target_q          | -7.67937932134352      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.8
Training epoch 84
Time for epoch 84: 434.57. Rollout time: 157.51, Training time: 276.93
Evaluating epoch 84
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 3527968.0              |
| test/episodes             | 1275.0                 |
| test/success_rate         | 0.4666666666666667     |
| test_0/avg_q              | -1.165754912135196     |
| test_1/avg_q              | -10.529475834106082    |
| test_1/n_subgoals         | 500.0                  |
| test_1/subgoal_succ_rate  | 0.558                  |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.91                   |
| train_0/avg_q             | -12.219358929341043    |
| train_0/current_q         | -6.1251884070991895    |
| train_0/fw_bonus          | -0.9985743746161461    |
| train_0/fw_loss           | 0.00035088129916402975 |
| train_0/mu_grads          | -0.18275701031088828   |
| train_0/mu_grads_std      | 0.7946837678551674     |
| train_0/mu_loss           | 5.941767886943811      |
| train_0/next_q            | -5.744115444821851     |
| train_0/q_grads           | 0.03972470751032233    |
| train_0/q_grads_std       | 0.5317819505929947     |
| train_0/q_loss            | 0.6137148416693574     |
| train_0/reward            | -0.7997839726129314    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1009765625           |
| train_0/target_q          | -6.129733201907432     |
| train_1/avg_q             | -11.180680869018458    |
| train_1/current_q         | -6.9962580912057835    |
| train_1/fw_bonus          | -0.9958852425217628    |
| train_1/fw_loss           | 0.002419501804979518   |
| train_1/mu_grads          | -0.02190289497375488   |
| train_1/mu_grads_std      | 0.7211993232369422     |
| train_1/mu_loss           | 6.480389828273755      |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -6.3470705278276025    |
| train_1/q_grads           | -0.09308120962232351   |
| train_1/q_grads_std       | 1.0629392504692077     |
| train_1/q_loss            | 5.708236076111028      |
| train_1/reward            | -1.6978299548292852    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071533203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4104627766599598     |
| train_1/target_q          | -7.055143683070725     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7333333333333334
Training epoch 85
Time for epoch 85: 468.79. Rollout time: 183.33, Training time: 285.35
Evaluating epoch 85
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 85                     |
| policy/steps              | 3552674.0              |
| test/episodes             | 1290.0                 |
| test/success_rate         | 0.7333333333333333     |
| test_0/avg_q              | -1.8034502203569922    |
| test_1/avg_q              | -10.142584851246252    |
| test_1/n_subgoals         | 1430.0                 |
| test_1/subgoal_succ_rate  | 0.9384615384615385     |
| train/episodes            | 8600.0                 |
| train/success_rate        | 0.89                   |
| train_0/avg_q             | -11.942404362530704    |
| train_0/current_q         | -6.409323991899873     |
| train_0/fw_bonus          | -0.9984275981783867    |
| train_0/fw_loss           | 0.00038636098688584755 |
| train_0/mu_grads          | -0.18624103516340257   |
| train_0/mu_grads_std      | 0.7964397370815277     |
| train_0/mu_loss           | 6.183669848221973      |
| train_0/next_q            | -5.984299125577353     |
| train_0/q_grads           | 0.040243557188659906   |
| train_0/q_grads_std       | 0.5321351066231728     |
| train_0/q_loss            | 0.4721923579179945     |
| train_0/reward            | -0.7987951303250156    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1140380859375        |
| train_0/target_q          | -6.412077363032869     |
| train_1/avg_q             | -11.092432667631364    |
| train_1/current_q         | -6.84835299395651      |
| train_1/fw_bonus          | -0.9959965407848358    |
| train_1/fw_loss           | 0.002386633935384452   |
| train_1/mu_grads          | -0.02178430394269526   |
| train_1/mu_grads_std      | 0.7222728580236435     |
| train_1/mu_loss           | 6.336417891000235      |
| train_1/n_subgoals        | 1041.0                 |
| train_1/next_q            | -6.15413683369195      |
| train_1/q_grads           | -0.09656840227544308   |
| train_1/q_grads_std       | 1.0713229954242707     |
| train_1/q_loss            | 6.283622167996083      |
| train_1/reward            | -1.6870728672045516    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0068603515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3631123919308357     |
| train_1/target_q          | -6.892160656582561     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7000000000000001
Training epoch 86
Time for epoch 86: 438.97. Rollout time: 195.62, Training time: 243.25
Evaluating epoch 86
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 86                     |
| policy/steps              | 3584889.0              |
| test/episodes             | 1305.0                 |
| test/success_rate         | 0.4666666666666667     |
| test_0/avg_q              | -1.9438219662375156    |
| test_1/avg_q              | -12.400560799809341    |
| test_1/n_subgoals         | 673.0                  |
| test_1/subgoal_succ_rate  | 0.687964338781575      |
| train/episodes            | 8700.0                 |
| train/success_rate        | 0.83                   |
| train_0/avg_q             | -10.094661200611597    |
| train_0/current_q         | -6.226146829618396     |
| train_0/fw_bonus          | -0.9984536916017532    |
| train_0/fw_loss           | 0.00038005322603567037 |
| train_0/mu_grads          | -0.18725451305508614   |
| train_0/mu_grads_std      | 0.7993147388100624     |
| train_0/mu_loss           | 6.012289188425443      |
| train_0/next_q            | -5.814641086724912     |
| train_0/q_grads           | 0.04015188906341791    |
| train_0/q_grads_std       | 0.5331571370363235     |
| train_0/q_loss            | 0.6729070022018315     |
| train_0/reward            | -0.8010172302234423    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.118798828125         |
| train_0/target_q          | -6.183594882083048     |
| train_1/avg_q             | -11.474703341477838    |
| train_1/current_q         | -6.935463684745642     |
| train_1/fw_bonus          | -0.9956422656774521    |
| train_1/fw_loss           | 0.002491259574890137   |
| train_1/mu_grads          | -0.02193395756185055   |
| train_1/mu_grads_std      | 0.7241913080215454     |
| train_1/mu_loss           | 6.346064413349952      |
| train_1/n_subgoals        | 1300.0                 |
| train_1/next_q            | -6.185300145992361     |
| train_1/q_grads           | -0.09792583137750625   |
| train_1/q_grads_std       | 1.0803025126457215     |
| train_1/q_loss            | 6.447781322294283      |
| train_1/reward            | -1.7488190128253336    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006103515625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.40076923076923077    |
| train_1/target_q          | -6.958145812197936     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6333333333333334
Training epoch 87
Time for epoch 87: 542.41. Rollout time: 250.30, Training time: 291.99
Evaluating epoch 87
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 87                     |
| policy/steps              | 3617339.0              |
| test/episodes             | 1320.0                 |
| test/success_rate         | 0.5333333333333333     |
| test_0/avg_q              | -1.9847569683388773    |
| test_1/avg_q              | -11.699033754461034    |
| test_1/n_subgoals         | 2282.0                 |
| test_1/subgoal_succ_rate  | 0.9535495179666958     |
| train/episodes            | 8800.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -9.673219248732556     |
| train_0/current_q         | -6.12104142256648      |
| train_0/fw_bonus          | -0.9985348999500274    |
| train_0/fw_loss           | 0.00036042004758201073 |
| train_0/mu_grads          | -0.18740070536732673   |
| train_0/mu_grads_std      | 0.8004193797707557     |
| train_0/mu_loss           | 5.903988901932051      |
| train_0/next_q            | -5.699348250275897     |
| train_0/q_grads           | 0.040509123262017964   |
| train_0/q_grads_std       | 0.5371635496616364     |
| train_0/q_loss            | 0.5976822658863814     |
| train_0/reward            | -0.8003417344512854    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0914794921875        |
| train_0/target_q          | -6.0758636702023665    |
| train_1/avg_q             | -11.352932694774951    |
| train_1/current_q         | -7.48539015256385      |
| train_1/fw_bonus          | -0.995669101178646     |
| train_1/fw_loss           | 0.0024833343049976975  |
| train_1/mu_grads          | -0.022659373097121717  |
| train_1/mu_grads_std      | 0.7257091477513313     |
| train_1/mu_loss           | 7.0946008122032        |
| train_1/n_subgoals        | 1289.0                 |
| train_1/next_q            | -6.9182883285531265    |
| train_1/q_grads           | -0.09915778562426567   |
| train_1/q_grads_std       | 1.0878252238035202     |
| train_1/q_loss            | 6.48910800360643       |
| train_1/reward            | -1.7700659558817278    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0064697265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3661753297129558     |
| train_1/target_q          | -7.5912437036183125    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5499999999999999
Training epoch 88
Time for epoch 88: 522.05. Rollout time: 227.09, Training time: 294.83
Evaluating epoch 88
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 3647796.0             |
| test/episodes             | 1335.0                |
| test/success_rate         | 0.5333333333333333    |
| test_0/avg_q              | -2.5997087222600395   |
| test_1/avg_q              | -7.524739969884976    |
| test_1/n_subgoals         | 3105.0                |
| test_1/subgoal_succ_rate  | 0.991304347826087     |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -11.670231941850421   |
| train_0/current_q         | -6.391017622649128    |
| train_0/fw_bonus          | -0.9985965773463249   |
| train_0/fw_loss           | 0.0003455125777691137 |
| train_0/mu_grads          | -0.18930093497037886  |
| train_0/mu_grads_std      | 0.8024371281266213    |
| train_0/mu_loss           | 6.1811984594709415    |
| train_0/next_q            | -5.9767820650681935   |
| train_0/q_grads           | 0.040746455918997525  |
| train_0/q_grads_std       | 0.5411442190408706    |
| train_0/q_loss            | 0.5385579620743226    |
| train_0/reward            | -0.8018036852987279   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1117431640625       |
| train_0/target_q          | -6.364818859866397    |
| train_1/avg_q             | -12.22606463963318    |
| train_1/current_q         | -7.710249143320508    |
| train_1/fw_bonus          | -0.9956783175468444   |
| train_1/fw_loss           | 0.0024806153436657042 |
| train_1/mu_grads          | -0.022813007654622196 |
| train_1/mu_grads_std      | 0.72667136490345      |
| train_1/mu_loss           | 7.2834977103272935    |
| train_1/n_subgoals        | 1273.0                |
| train_1/next_q            | -7.212342995754705    |
| train_1/q_grads           | -0.09932378195226192  |
| train_1/q_grads_std       | 1.0943724364042282    |
| train_1/q_loss            | 6.243518872759702     |
| train_1/reward            | -1.7749205529340544   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0068359375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4383346425765907    |
| train_1/target_q          | -7.800254360071395    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5666666666666667
Training epoch 89
Time for epoch 89: 429.92. Rollout time: 158.92, Training time: 270.91
Evaluating epoch 89
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 3673691.0             |
| test/episodes             | 1350.0                |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.706292254343788    |
| test_1/avg_q              | -12.70705455508316    |
| test_1/n_subgoals         | 476.0                 |
| test_1/subgoal_succ_rate  | 0.523109243697479     |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -12.315695081372231   |
| train_0/current_q         | -6.0798788818266605   |
| train_0/fw_bonus          | -0.9985653400421143   |
| train_0/fw_loss           | 0.0003530642225086922 |
| train_0/mu_grads          | -0.1894501894712448   |
| train_0/mu_grads_std      | 0.8071986645460129    |
| train_0/mu_loss           | 5.910733209337951     |
| train_0/next_q            | -5.660641602870196    |
| train_0/q_grads           | 0.040787698794156314  |
| train_0/q_grads_std       | 0.5441136553883552    |
| train_0/q_loss            | 0.5250189417054191    |
| train_0/reward            | -0.8077284925191635   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1149658203125       |
| train_0/target_q          | -6.124288564483887    |
| train_1/avg_q             | -11.280697552093573   |
| train_1/current_q         | -7.694232323100303    |
| train_1/fw_bonus          | -0.9957904860377311   |
| train_1/fw_loss           | 0.0024474871170241386 |
| train_1/mu_grads          | -0.022737226355820893 |
| train_1/mu_grads_std      | 0.7288587346673012    |
| train_1/mu_loss           | 7.1861308036250335    |
| train_1/n_subgoals        | 1046.0                |
| train_1/next_q            | -7.147196821182186    |
| train_1/q_grads           | -0.09948613904416562  |
| train_1/q_grads_std       | 1.1009519010782243    |
| train_1/q_loss            | 6.020910131517849     |
| train_1/reward            | -1.7614720360968932   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0061767578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.46175908221797324   |
| train_1/target_q          | -7.774265292036222    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.4833333333333333
Training epoch 90
Time for epoch 90: 480.66. Rollout time: 210.73, Training time: 269.84
Evaluating epoch 90
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 3701927.0             |
| test/episodes             | 1365.0                |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -1.489771446668713    |
| test_1/avg_q              | -12.93025937620356    |
| test_1/n_subgoals         | 1328.0                |
| test_1/subgoal_succ_rate  | 0.9450301204819277    |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -10.896665079152177   |
| train_0/current_q         | -6.135016915557585    |
| train_0/fw_bonus          | -0.9987919256091118   |
| train_0/fw_loss           | 0.0002982904843520373 |
| train_0/mu_grads          | -0.19106550551950932  |
| train_0/mu_grads_std      | 0.8074006363749504    |
| train_0/mu_loss           | 5.90709645360576      |
| train_0/next_q            | -5.741732620332196    |
| train_0/q_grads           | 0.04209628468379378   |
| train_0/q_grads_std       | 0.5492499753832817    |
| train_0/q_loss            | 0.581518456706833     |
| train_0/reward            | -0.8041047206304939   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.149365234375        |
| train_0/target_q          | -6.1432286294232785   |
| train_1/avg_q             | -11.40571915042079    |
| train_1/current_q         | -7.935517701063171    |
| train_1/fw_bonus          | -0.9955830916762352   |
| train_1/fw_loss           | 0.002508733532158658  |
| train_1/mu_grads          | -0.022438061237335206 |
| train_1/mu_grads_std      | 0.729861019551754     |
| train_1/mu_loss           | 7.462675942496654     |
| train_1/n_subgoals        | 1271.0                |
| train_1/next_q            | -7.374809747421262    |
| train_1/q_grads           | -0.10075713731348515  |
| train_1/q_grads_std       | 1.1077483683824538    |
| train_1/q_loss            | 6.248770446990122     |
| train_1/reward            | -1.7870915728373802   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0073974609375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4374508261211644    |
| train_1/target_q          | -8.010942545021729    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5333333333333333
Training epoch 91
Time for epoch 91: 434.37. Rollout time: 151.30, Training time: 282.96
Evaluating epoch 91
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 3723778.0             |
| test/episodes             | 1380.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -2.4193830369801006   |
| test_1/avg_q              | -13.19010123841661    |
| test_1/n_subgoals         | 2806.0                |
| test_1/subgoal_succ_rate  | 0.9932287954383464    |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.98                  |
| train_0/avg_q             | -10.994925095164463   |
| train_0/current_q         | -5.349496818057872    |
| train_0/fw_bonus          | -0.9987990543246269   |
| train_0/fw_loss           | 0.0002965712028526468 |
| train_0/mu_grads          | -0.1913906455039978   |
| train_0/mu_grads_std      | 0.8085218712687492    |
| train_0/mu_loss           | 5.069206201775554     |
| train_0/next_q            | -4.883047542432733    |
| train_0/q_grads           | 0.042315016593784095  |
| train_0/q_grads_std       | 0.550990255177021     |
| train_0/q_loss            | 0.5592277688522012    |
| train_0/reward            | -0.8042712936021417   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.148876953125        |
| train_0/target_q          | -5.2768168896770735   |
| train_1/avg_q             | -10.697531579547036   |
| train_1/current_q         | -7.863681060121148    |
| train_1/fw_bonus          | -0.996036197245121    |
| train_1/fw_loss           | 0.002374925569165498  |
| train_1/mu_grads          | -0.02334125298075378  |
| train_1/mu_grads_std      | 0.730764465034008     |
| train_1/mu_loss           | 7.467620187421296     |
| train_1/n_subgoals        | 921.0                 |
| train_1/next_q            | -7.379217036625278    |
| train_1/q_grads           | -0.10149799883365632  |
| train_1/q_grads_std       | 1.1157934278249741    |
| train_1/q_loss            | 6.577725490959557     |
| train_1/reward            | -1.7729409326675523   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0076904296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4755700325732899    |
| train_1/target_q          | -7.9563242945812025   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.55
Training epoch 92
Time for epoch 92: 523.44. Rollout time: 235.08, Training time: 288.24
Evaluating epoch 92
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 3754432.0             |
| test/episodes             | 1395.0                |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.816033039952537    |
| test_1/avg_q              | -9.20512795317648     |
| test_1/n_subgoals         | 3380.0                |
| test_1/subgoal_succ_rate  | 0.9733727810650887    |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.83                  |
| train_0/avg_q             | -9.28463713720964     |
| train_0/current_q         | -5.763308833514082    |
| train_0/fw_bonus          | -0.998738880455494    |
| train_0/fw_loss           | 0.0003111126061412506 |
| train_0/mu_grads          | -0.1884729377925396   |
| train_0/mu_grads_std      | 0.8089932516217232    |
| train_0/mu_loss           | 5.5424728423887135    |
| train_0/next_q            | -5.373056659387186    |
| train_0/q_grads           | 0.042343545611947773  |
| train_0/q_grads_std       | 0.5517319768667222    |
| train_0/q_loss            | 0.6619756492366141    |
| train_0/reward            | -0.8068929735218262   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1160400390625       |
| train_0/target_q          | -5.740950541663738    |
| train_1/avg_q             | -12.627207015275026   |
| train_1/current_q         | -8.265194256536486    |
| train_1/fw_bonus          | -0.9956493332982064   |
| train_1/fw_loss           | 0.0024891725333873183 |
| train_1/mu_grads          | -0.024324309080839157 |
| train_1/mu_grads_std      | 0.7318960130214691    |
| train_1/mu_loss           | 7.775607822341823     |
| train_1/n_subgoals        | 1245.0                |
| train_1/next_q            | -7.732762548099524    |
| train_1/q_grads           | -0.10215211194008589  |
| train_1/q_grads_std       | 1.1236366778612137    |
| train_1/q_loss            | 6.191259172673083     |
| train_1/reward            | -1.8109118430442321   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0067138671875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.43453815261044176   |
| train_1/target_q          | -8.326484821937015    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5166666666666666
Training epoch 93
Time for epoch 93: 597.76. Rollout time: 308.02, Training time: 289.60
Evaluating epoch 93
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 3796865.0              |
| test/episodes             | 1410.0                 |
| test/success_rate         | 0.5333333333333333     |
| test_0/avg_q              | -1.603731156789354     |
| test_1/avg_q              | -10.374220419874058    |
| test_1/n_subgoals         | 4334.0                 |
| test_1/subgoal_succ_rate  | 0.9771573604060914     |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.59                   |
| train_0/avg_q             | -8.584443771515016     |
| train_0/current_q         | -5.975135016561035     |
| train_0/fw_bonus          | -0.9989201322197914    |
| train_0/fw_loss           | 0.00026729864184744657 |
| train_0/mu_grads          | -0.1900067612528801    |
| train_0/mu_grads_std      | 0.8097191646695137     |
| train_0/mu_loss           | 5.754527009178717      |
| train_0/next_q            | -5.561815019417255     |
| train_0/q_grads           | 0.04231002796441317    |
| train_0/q_grads_std       | 0.5537266343832016     |
| train_0/q_loss            | 0.619626030027856      |
| train_0/reward            | -0.8066636283529078    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.149365234375         |
| train_0/target_q          | -5.938319118069472     |
| train_1/avg_q             | -12.260375468023991    |
| train_1/current_q         | -8.44321455455422      |
| train_1/fw_bonus          | -0.9954283356666564    |
| train_1/fw_loss           | 0.0025544324598740786  |
| train_1/mu_grads          | -0.024567871214821936  |
| train_1/mu_grads_std      | 0.7344709023833275     |
| train_1/mu_loss           | 7.953027750301443      |
| train_1/n_subgoals        | 1677.0                 |
| train_1/next_q            | -7.87662689081251      |
| train_1/q_grads           | -0.10346228871494531   |
| train_1/q_grads_std       | 1.1311660021543504     |
| train_1/q_loss            | 6.605379692721593      |
| train_1/reward            | -1.8575301813420082    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00703125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3488372093023256     |
| train_1/target_q          | -8.508992587913983     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5499999999999999
Training epoch 94
Time for epoch 94: 504.03. Rollout time: 206.89, Training time: 297.02
Evaluating epoch 94
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 94                    |
| policy/steps              | 3822524.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -2.090959332738591    |
| test_1/avg_q              | -4.721719130303823    |
| test_1/n_subgoals         | 1059.0                |
| test_1/subgoal_succ_rate  | 0.9178470254957507    |
| train/episodes            | 9500.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -12.061647543715496   |
| train_0/current_q         | -6.299312759202914    |
| train_0/fw_bonus          | -0.9987348407506943   |
| train_0/fw_loss           | 0.000312089381259284  |
| train_0/mu_grads          | -0.1896543476730585   |
| train_0/mu_grads_std      | 0.8100240483880043    |
| train_0/mu_loss           | 6.083574787979272     |
| train_0/next_q            | -5.890966900927827    |
| train_0/q_grads           | 0.04246372813358903   |
| train_0/q_grads_std       | 0.5567616760730744    |
| train_0/q_loss            | 0.661449907871093     |
| train_0/reward            | -0.8092906446760025   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1124267578125       |
| train_0/target_q          | -6.2428507737259435   |
| train_1/avg_q             | -11.382945854788144   |
| train_1/current_q         | -8.87806032485777     |
| train_1/fw_bonus          | -0.9961081847548485   |
| train_1/fw_loss           | 0.0023536673630587756 |
| train_1/mu_grads          | -0.023889201087877156 |
| train_1/mu_grads_std      | 0.7375819861888886    |
| train_1/mu_loss           | 8.408307468905692     |
| train_1/n_subgoals        | 1261.0                |
| train_1/next_q            | -8.349274525264274    |
| train_1/q_grads           | -0.10428359974175691  |
| train_1/q_grads_std       | 1.1396773248910903    |
| train_1/q_loss            | 6.219093028612302     |
| train_1/reward            | -1.8459997014782856   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006787109375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.5154639175257731    |
| train_1/target_q          | -8.95944294051015     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5499999999999999
Training epoch 95
Time for epoch 95: 542.43. Rollout time: 235.50, Training time: 306.83
Evaluating epoch 95
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 95                    |
| policy/steps              | 3850325.0             |
| test/episodes             | 1440.0                |
| test/success_rate         | 0.8666666666666667    |
| test_0/avg_q              | -2.575105123163919    |
| test_1/avg_q              | -8.129886317100118    |
| test_1/n_subgoals         | 1504.0                |
| test_1/subgoal_succ_rate  | 0.9986702127659575    |
| train/episodes            | 9600.0                |
| train/success_rate        | 0.88                  |
| train_0/avg_q             | -10.55197339706655    |
| train_0/current_q         | -6.339762905167043    |
| train_0/fw_bonus          | -0.9988594606518746   |
| train_0/fw_loss           | 0.0002819663739501266 |
| train_0/mu_grads          | -0.19030915312469004  |
| train_0/mu_grads_std      | 0.8115706264972686    |
| train_0/mu_loss           | 6.126964924042897     |
| train_0/next_q            | -5.91159969532079     |
| train_0/q_grads           | 0.041809506993740794  |
| train_0/q_grads_std       | 0.5589060589671135    |
| train_0/q_loss            | 0.6434136021011599    |
| train_0/reward            | -0.8138994352782902   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1710693359375       |
| train_0/target_q          | -6.276239165575075    |
| train_1/avg_q             | -11.58268050464892    |
| train_1/current_q         | -9.081583376955852    |
| train_1/fw_bonus          | -0.9958912655711174   |
| train_1/fw_loss           | 0.002417725225677714  |
| train_1/mu_grads          | -0.02329765143804252  |
| train_1/mu_grads_std      | 0.7409891977906227    |
| train_1/mu_loss           | 8.683054095563403     |
| train_1/n_subgoals        | 1305.0                |
| train_1/next_q            | -8.58841162285018     |
| train_1/q_grads           | -0.10547227896749974  |
| train_1/q_grads_std       | 1.1470724642276764    |
| train_1/q_loss            | 5.897224008550651     |
| train_1/reward            | -1.8243024058923765   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0066650390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.43908045977011495   |
| train_1/target_q          | -9.211834482726362    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6166666666666667
Training epoch 96
Time for epoch 96: 488.00. Rollout time: 187.99, Training time: 299.93
Evaluating epoch 96
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 3873556.0              |
| test/episodes             | 1455.0                 |
| test/success_rate         | 0.8666666666666667     |
| test_0/avg_q              | -2.9009340348412325    |
| test_1/avg_q              | -8.035496077813685     |
| test_1/n_subgoals         | 828.0                  |
| test_1/subgoal_succ_rate  | 0.967391304347826      |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.93                   |
| train_0/avg_q             | -11.575937395379542    |
| train_0/current_q         | -5.957378266714842     |
| train_0/fw_bonus          | -0.998961764574051     |
| train_0/fw_loss           | 0.00025723372054926586 |
| train_0/mu_grads          | -0.19121756553649902   |
| train_0/mu_grads_std      | 0.8108185648918151     |
| train_0/mu_loss           | 5.745564317588794      |
| train_0/next_q            | -5.543428448758496     |
| train_0/q_grads           | 0.04198131719604135    |
| train_0/q_grads_std       | 0.5613751992583275     |
| train_0/q_loss            | 0.5806454038871388     |
| train_0/reward            | -0.8133024556522287    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.126318359375         |
| train_0/target_q          | -5.940032746152386     |
| train_1/avg_q             | -10.98025797795524     |
| train_1/current_q         | -8.994325122275505     |
| train_1/fw_bonus          | -0.9965304523706436    |
| train_1/fw_loss           | 0.0022289650747552513  |
| train_1/mu_grads          | -0.02349961157888174   |
| train_1/mu_grads_std      | 0.7417020946741104     |
| train_1/mu_loss           | 8.52440161268782       |
| train_1/n_subgoals        | 1170.0                 |
| train_1/next_q            | -8.414245026899742     |
| train_1/q_grads           | -0.10662712175399065   |
| train_1/q_grads_std       | 1.1541589111089707     |
| train_1/q_loss            | 6.514002526478981      |
| train_1/reward            | -1.8579705035263032    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0068603515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.49230769230769234    |
| train_1/target_q          | -9.07471801101508      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7333333333333333
Training epoch 97
Time for epoch 97: 531.01. Rollout time: 208.11, Training time: 322.71
Evaluating epoch 97
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 97                     |
| policy/steps              | 3896735.0              |
| test/episodes             | 1470.0                 |
| test/success_rate         | 0.5333333333333333     |
| test_0/avg_q              | -2.8660988331454584    |
| test_1/avg_q              | -9.254630845500442     |
| test_1/n_subgoals         | 2555.0                 |
| test_1/subgoal_succ_rate  | 0.9851272015655578     |
| train/episodes            | 9800.0                 |
| train/success_rate        | 0.94                   |
| train_0/avg_q             | -10.18793553522049     |
| train_0/current_q         | -5.909682956363399     |
| train_0/fw_bonus          | -0.9988303348422051    |
| train_0/fw_loss           | 0.00028900428042106797 |
| train_0/mu_grads          | -0.19153226725757122   |
| train_0/mu_grads_std      | 0.8101096242666245     |
| train_0/mu_loss           | 5.67054015137605       |
| train_0/next_q            | -5.501153156449895     |
| train_0/q_grads           | 0.041780295129865405   |
| train_0/q_grads_std       | 0.5664319887757301     |
| train_0/q_loss            | 0.636552046353954      |
| train_0/reward            | -0.8107793636660062    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1475341796875        |
| train_0/target_q          | -5.867919111747466     |
| train_1/avg_q             | -10.356630959915183    |
| train_1/current_q         | -8.844277352368685     |
| train_1/fw_bonus          | -0.9967267736792564    |
| train_1/fw_loss           | 0.0021709891472710295  |
| train_1/mu_grads          | -0.023339101020246743  |
| train_1/mu_grads_std      | 0.7438221141695976     |
| train_1/mu_loss           | 8.49944795134057       |
| train_1/n_subgoals        | 999.0                  |
| train_1/next_q            | -8.356182511326315     |
| train_1/q_grads           | -0.10670171603560448   |
| train_1/q_grads_std       | 1.1612308830022813     |
| train_1/q_loss            | 6.096155540697961      |
| train_1/reward            | -1.77640947673317      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0065673828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.5205205205205206     |
| train_1/target_q          | -8.97176572404295      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7333333333333333
Training epoch 98
Time for epoch 98: 644.60. Rollout time: 286.67, Training time: 357.70
Evaluating epoch 98
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 98                    |
| policy/steps              | 3918184.0             |
| test/episodes             | 1485.0                |
| test/success_rate         | 0.6666666666666666    |
| test_0/avg_q              | -2.1786813337038566   |
| test_1/avg_q              | -12.911394609603647   |
| test_1/n_subgoals         | 2804.0                |
| test_1/subgoal_succ_rate  | 0.9953637660485022    |
| train/episodes            | 9900.0                |
| train/success_rate        | 0.88                  |
| train_0/avg_q             | -10.509919481582545   |
| train_0/current_q         | -6.0589383172095905   |
| train_0/fw_bonus          | -0.9988488212227822   |
| train_0/fw_loss           | 0.0002845389928552322 |
| train_0/mu_grads          | -0.1919407110661268   |
| train_0/mu_grads_std      | 0.8108549758791923    |
| train_0/mu_loss           | 5.859038772125875     |
| train_0/next_q            | -5.650416704668323    |
| train_0/q_grads           | 0.04148280508816242   |
| train_0/q_grads_std       | 0.5699472203850746    |
| train_0/q_loss            | 0.6960605067269103    |
| train_0/reward            | -0.8139883274146996   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1410400390625       |
| train_0/target_q          | -5.989404239089135    |
| train_1/avg_q             | -11.263520296204812   |
| train_1/current_q         | -8.459011613915674    |
| train_1/fw_bonus          | -0.9969012618064881   |
| train_1/fw_loss           | 0.0021194598346482964 |
| train_1/mu_grads          | -0.023643197119235994 |
| train_1/mu_grads_std      | 0.7472069188952446    |
| train_1/mu_loss           | 8.070582256327594     |
| train_1/n_subgoals        | 1034.0                |
| train_1/next_q            | -7.92854181023244     |
| train_1/q_grads           | -0.10714121703058481  |
| train_1/q_grads_std       | 1.1683501034975052    |
| train_1/q_loss            | 6.079040877812579     |
| train_1/reward            | -1.7760136467830308   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0072265625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.5338491295938105    |
| train_1/target_q          | -8.562765001305351    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7333333333333333
Training epoch 99
Time for epoch 99: 2584.95. Rollout time: 2133.78, Training time: 450.94
Evaluating epoch 99
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 3941192.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.5333333333333333    |
| test_0/avg_q              | -1.931823513197037    |
| test_1/avg_q              | -11.166558595975262   |
| test_1/n_subgoals         | 3414.0                |
| test_1/subgoal_succ_rate  | 0.99502050380785      |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.93                  |
| train_0/avg_q             | -10.853572243089191   |
| train_0/current_q         | -5.981309428432622    |
| train_0/fw_bonus          | -0.9990174993872643   |
| train_0/fw_loss           | 0.0002437620594719192 |
| train_0/mu_grads          | -0.19259139560163022  |
| train_0/mu_grads_std      | 0.8135495111346245    |
| train_0/mu_loss           | 5.7401458942800385    |
| train_0/next_q            | -5.570039332108005    |
| train_0/q_grads           | 0.04126668982207775   |
| train_0/q_grads_std       | 0.5733862817287445    |
| train_0/q_loss            | 0.6753424235904955    |
| train_0/reward            | -0.8121445133238012   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.172021484375        |
| train_0/target_q          | -5.922670523085804    |
| train_1/avg_q             | -10.557047694377637   |
| train_1/current_q         | -8.429939760982384    |
| train_1/fw_bonus          | -0.9969192773103714   |
| train_1/fw_loss           | 0.0021141380682820456 |
| train_1/mu_grads          | -0.023523496789857747 |
| train_1/mu_grads_std      | 0.7500682815909385    |
| train_1/mu_loss           | 8.110673719581447     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -7.953278433155505    |
| train_1/q_grads           | -0.10860016252845525  |
| train_1/q_grads_std       | 1.1756121158599853    |
| train_1/q_loss            | 5.181094965054404     |
| train_1/reward            | -1.7493579957379553   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006787109375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.482                 |
| train_1/target_q          | -8.54827509899879     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6499999999999999
Training epoch 100
Time for epoch 100: 32277.58. Rollout time: 16114.47, Training time: 16162.80
Evaluating epoch 100
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 100                    |
| policy/steps              | 3962125.0              |
| test/episodes             | 1515.0                 |
| test/success_rate         | 0.9333333333333333     |
| test_0/avg_q              | -2.285341463535398     |
| test_1/avg_q              | -6.038570159045085     |
| test_1/n_subgoals         | 1093.0                 |
| test_1/subgoal_succ_rate  | 0.970722781335773      |
| train/episodes            | 10100.0                |
| train/success_rate        | 0.85                   |
| train_0/avg_q             | -9.443380184136968     |
| train_0/current_q         | -6.107830048047727     |
| train_0/fw_bonus          | -0.9990239888429642    |
| train_0/fw_loss           | 0.00024219441729655955 |
| train_0/mu_grads          | -0.1919931948184967    |
| train_0/mu_grads_std      | 0.8149696111679077     |
| train_0/mu_loss           | 5.865062787646947      |
| train_0/next_q            | -5.667313927245621     |
| train_0/q_grads           | 0.041052155941724774   |
| train_0/q_grads_std       | 0.5762725055217743     |
| train_0/q_loss            | 0.5636371272153546     |
| train_0/reward            | -0.8112306072260254    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.146923828125         |
| train_0/target_q          | -6.061670188741802     |
| train_1/avg_q             | -11.150350374112382    |
| train_1/current_q         | -8.624528740090685     |
| train_1/fw_bonus          | -0.9969886794686318    |
| train_1/fw_loss           | 0.002093647274887189   |
| train_1/mu_grads          | -0.02363509386777878   |
| train_1/mu_grads_std      | 0.7510610714554786     |
| train_1/mu_loss           | 8.407353426320658      |
| train_1/n_subgoals        | 1082.0                 |
| train_1/next_q            | -8.175149378704376     |
| train_1/q_grads           | -0.10998735502362252   |
| train_1/q_grads_std       | 1.1821865737438202     |
| train_1/q_loss            | 7.294755348702722      |
| train_1/reward            | -1.740934179456599     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006787109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.5166358595194085     |
| train_1/target_q          | -8.720456791837073     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_100.pkl ...
New best value for test/success_rate: 0.9333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6666666666666667
Training epoch 101
Time for epoch 101: 1559.34. Rollout time: 705.66, Training time: 853.33
Evaluating epoch 101
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 101                    |
| policy/steps              | 3989757.0              |
| test/episodes             | 1530.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.673210325150596     |
| test_1/avg_q              | -9.17560809762602      |
| test_1/n_subgoals         | 4289.0                 |
| test_1/subgoal_succ_rate  | 0.9517370016320821     |
| train/episodes            | 10200.0                |
| train/success_rate        | 0.92                   |
| train_0/avg_q             | -10.72107588349963     |
| train_0/current_q         | -5.968547215063533     |
| train_0/fw_bonus          | -0.9990985870361329    |
| train_0/fw_loss           | 0.00022416118590626866 |
| train_0/mu_grads          | -0.19186775237321854   |
| train_0/mu_grads_std      | 0.8160436794161796     |
| train_0/mu_loss           | 5.707893446290717      |
| train_0/next_q            | -5.5303297077815845    |
| train_0/q_grads           | 0.041015700157731774   |
| train_0/q_grads_std       | 0.5790113940834999     |
| train_0/q_loss            | 0.5538227964873077     |
| train_0/reward            | -0.8115605368988327    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.18583984375          |
| train_0/target_q          | -5.918878875499942     |
| train_1/avg_q             | -10.812289787197543    |
| train_1/current_q         | -8.669051614439086     |
| train_1/fw_bonus          | -0.9970637783408165    |
| train_1/fw_loss           | 0.0020714669808512554  |
| train_1/mu_grads          | -0.02306967177428305   |
| train_1/mu_grads_std      | 0.7540012270212173     |
| train_1/mu_loss           | 8.423096157034546      |
| train_1/n_subgoals        | 976.0                  |
| train_1/next_q            | -8.261960644807075     |
| train_1/q_grads           | -0.1105444584041834    |
| train_1/q_grads_std       | 1.1881132304668427     |
| train_1/q_loss            | 7.25117597655719       |
| train_1/reward            | -1.748826492025546     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.48770491803278687    |
| train_1/target_q          | -8.748603747160919     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.55
Training epoch 102
Time for epoch 102: 2908.11. Rollout time: 1156.42, Training time: 1751.35
Evaluating epoch 102
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103
------------------------------------------------------
| epoch                     | 102                    |
| policy/steps              | 4015332.0              |
| test/episodes             | 1545.0                 |
| test/success_rate         | 0.9333333333333333     |
| test_0/avg_q              | -1.853467045528846     |
| test_1/avg_q              | -14.075974815250412    |
| test_1/n_subgoals         | 751.0                  |
| test_1/subgoal_succ_rate  | 0.9760319573901465     |
| train/episodes            | 10300.0                |
| train/success_rate        | 0.82                   |
| train_0/avg_q             | -10.248367172873136    |
| train_0/current_q         | -5.9018067257703395    |
| train_0/fw_bonus          | -0.9990488767623902    |
| train_0/fw_loss           | 0.00023617955957888626 |
| train_0/mu_grads          | -0.1935746565461159    |
| train_0/mu_grads_std      | 0.8203987210988999     |
| train_0/mu_loss           | 5.625970819338488      |
| train_0/next_q            | -5.459203978834731     |
| train_0/q_grads           | 0.04119506822898984    |
| train_0/q_grads_std       | 0.5823326602578163     |
| train_0/q_loss            | 0.5445685616443262     |
| train_0/reward            | -0.8137819940828195    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.163525390625         |
| train_0/target_q          | -5.862969236145686     |
| train_1/avg_q             | -11.806321457002555    |
| train_1/current_q         | -8.087109586958997     |
| train_1/fw_bonus          | -0.9968691021203995    |
| train_1/fw_loss           | 0.002128959714900702   |
| train_1/mu_grads          | -0.023851049970835446  |
| train_1/mu_grads_std      | 0.756910289824009      |
| train_1/mu_loss           | 7.767382985134776      |
| train_1/n_subgoals        | 1282.0                 |
| train_1/next_q            | -7.623967208636332     |
| train_1/q_grads           | -0.11081684827804565   |
| train_1/q_grads_std       | 1.1939964056015016     |
| train_1/q_loss            | 5.401521640627363      |
| train_1/reward            | -1.7488144414022826    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0074462890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43681747269890797    |
| train_1/target_q          | -8.197558187155618     |
------------------------------------------------------
New best value for test/success_rate: 0.9333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|103/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6166666666666667
Training epoch 103
