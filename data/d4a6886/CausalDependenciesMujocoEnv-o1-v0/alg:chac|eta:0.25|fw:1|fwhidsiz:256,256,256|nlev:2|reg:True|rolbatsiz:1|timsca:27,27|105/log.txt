Starting process id: 4726
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f7a58e53f80>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 530.40. Rollout time: 293.54, Training time: 236.83
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 73432.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.3100955016938913    |
| test_1/avg_q              | -0.7326965940182317    |
| test_1/n_subgoals         | 669.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -21.860238185526637    |
| train_0/current_q         | -8.75623672633451      |
| train_0/fw_bonus          | -0.9995103478431702    |
| train_0/fw_loss           | 0.00012641125667869346 |
| train_0/mu_grads          | -0.0054858334362506865 |
| train_0/mu_grads_std      | 0.15617899000644683    |
| train_0/mu_loss           | 8.69810620022216       |
| train_0/next_q            | -8.686439731047026     |
| train_0/q_grads           | 0.03814558498561382    |
| train_0/q_grads_std       | 0.14896652437746524    |
| train_0/q_loss            | 0.2180136818273845     |
| train_0/reward            | -0.8619008282228606    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 2.44140625e-05         |
| train_0/target_q          | -8.884582649184253     |
| train_1/avg_q             | -4.450267119297715     |
| train_1/current_q         | -2.7799738906308074    |
| train_1/fw_bonus          | -0.9962282255291939    |
| train_1/fw_loss           | 0.0016639559442410245  |
| train_1/mu_grads          | 0.015025984914973377   |
| train_1/mu_grads_std      | 0.09010760225355625    |
| train_1/mu_loss           | 2.975316915254352      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -2.6951376774233102    |
| train_1/q_grads           | 0.005898398690624163   |
| train_1/q_grads_std       | 0.18442476205527783    |
| train_1/q_loss            | 5.656634245360628      |
| train_1/reward            | -1.341696317581227     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015625              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2548148148148148     |
| train_1/target_q          | -3.0214531692866813    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_0.pkl ...
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 647.26. Rollout time: 429.94, Training time: 217.29
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 163798.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.6987492357859082   |
| test_1/avg_q              | -8.220891988637817    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -5.093105583923287    |
| train_0/current_q         | -5.189240377398475    |
| train_0/fw_bonus          | -0.9995188936591148   |
| train_0/fw_loss           | 0.0001242721655216883 |
| train_0/mu_grads          | -0.007648890453856439 |
| train_0/mu_grads_std      | 0.19048820957541465   |
| train_0/mu_loss           | 5.103688528964116     |
| train_0/next_q            | -5.095282112602076    |
| train_0/q_grads           | 0.046664362959563735  |
| train_0/q_grads_std       | 0.18147292658686637   |
| train_0/q_loss            | 0.35256840117710175   |
| train_0/reward            | -0.8662956595813739   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 2.44140625e-05        |
| train_0/target_q          | -5.277973536735507    |
| train_1/avg_q             | -5.310751696891841    |
| train_1/current_q         | -3.6661065366558248   |
| train_1/fw_bonus          | -0.9962737172842026   |
| train_1/fw_loss           | 0.001653245705529116  |
| train_1/mu_grads          | 0.015031299996189773  |
| train_1/mu_grads_std      | 0.09011732079088688   |
| train_1/mu_loss           | 4.611572173762589     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -3.2613504026500926   |
| train_1/q_grads           | 0.00837445657234639   |
| train_1/q_grads_std       | 0.2286076955497265    |
| train_1/q_loss            | 0.6276633083575585    |
| train_1/reward            | -1.439881068392424    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.014814814814814815  |
| train_1/target_q          | -3.6412655956316335   |
-----------------------------------------------------
Training epoch 2
Time for epoch 2: 616.54. Rollout time: 416.42, Training time: 200.08
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 253836.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.8829258515199      |
| test_1/avg_q              | -5.969452529185723     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -16.837987884490833    |
| train_0/current_q         | -6.201668403940088     |
| train_0/fw_bonus          | -0.9994277849793434    |
| train_0/fw_loss           | 0.00014709752540511544 |
| train_0/mu_grads          | -0.012224696739576758  |
| train_0/mu_grads_std      | 0.21178428456187248    |
| train_0/mu_loss           | 6.001076615544879      |
| train_0/next_q            | -5.992374186192866     |
| train_0/q_grads           | 0.05565587487071753    |
| train_0/q_grads_std       | 0.20666300915181637    |
| train_0/q_loss            | 0.3212865779748514     |
| train_0/reward            | -0.874552522932936     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 7.32421875e-05         |
| train_0/target_q          | -6.281361381527866     |
| train_1/avg_q             | -6.742118539605352     |
| train_1/current_q         | -0.5881068598106923    |
| train_1/fw_bonus          | -0.9965511545538902    |
| train_1/fw_loss           | 0.0015879231417784468  |
| train_1/mu_grads          | 0.015029766620136798   |
| train_1/mu_grads_std      | 0.09011418856680393    |
| train_1/mu_loss           | 0.7253501581500561     |
| train_1/n_subgoals        | 2662.0                 |
| train_1/next_q            | -0.7020369532689325    |
| train_1/q_grads           | -0.007889654359314591  |
| train_1/q_grads_std       | 0.2589123897254467     |
| train_1/q_loss            | 4.99411635046138       |
| train_1/reward            | -1.468720737316471     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0014404296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.002253944402704733   |
| train_1/target_q          | -1.9149461949624489    |
------------------------------------------------------
Training epoch 3
Time for epoch 3: 618.10. Rollout time: 406.00, Training time: 212.05
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 344961.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.485457853125642     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.95694919721137     |
| train_0/current_q         | -7.734095966923259     |
| train_0/fw_bonus          | -0.9995046481490135    |
| train_0/fw_loss           | 0.00012783985966962063 |
| train_0/mu_grads          | -0.012970147817395628  |
| train_0/mu_grads_std      | 0.22887527234852315    |
| train_0/mu_loss           | 7.59784157517394       |
| train_0/next_q            | -7.577848551179665     |
| train_0/q_grads           | 0.057042029406875375   |
| train_0/q_grads_std       | 0.2111545938998461     |
| train_0/q_loss            | 0.2197314479947746     |
| train_0/reward            | -0.8709846861718689    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001953125           |
| train_0/target_q          | -7.799009487206457     |
| train_1/avg_q             | -6.519802942325149     |
| train_1/current_q         | -1.6072825971569376    |
| train_1/fw_bonus          | -0.9977020025253296    |
| train_1/fw_loss           | 0.0013169524318072945  |
| train_1/mu_grads          | 0.015029603871516884   |
| train_1/mu_grads_std      | 0.09011433850973845    |
| train_1/mu_loss           | 4.561550115406363      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.2038680729859143    |
| train_1/q_grads           | -0.006311812461353839  |
| train_1/q_grads_std       | 0.2819436676800251     |
| train_1/q_loss            | 0.3301374316351067     |
| train_1/reward            | -1.485129536394379     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013427734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.608074740037472     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 4
Time for epoch 4: 675.19. Rollout time: 442.32, Training time: 232.83
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 436086.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.534848994171984     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -8.140443735847857     |
| train_0/fw_bonus          | -0.9995975136756897    |
| train_0/fw_loss           | 0.00010457580447109649 |
| train_0/mu_grads          | -0.017562098149210215  |
| train_0/mu_grads_std      | 0.24248899333178997    |
| train_0/mu_loss           | 8.037822056943423      |
| train_0/next_q            | -8.030492659687727     |
| train_0/q_grads           | 0.058502713404595855   |
| train_0/q_grads_std       | 0.21994761228561402    |
| train_0/q_loss            | 0.23503992863287046    |
| train_0/reward            | -0.8672152203434962    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000439453125         |
| train_0/target_q          | -8.238881461548853     |
| train_1/avg_q             | -7.495141740604099     |
| train_1/current_q         | -1.5143523990829406    |
| train_1/fw_bonus          | -0.9982153475284576    |
| train_1/fw_loss           | 0.0011960888281464578  |
| train_1/mu_grads          | 0.015025004325434566   |
| train_1/mu_grads_std      | 0.09010572917759418    |
| train_1/mu_loss           | 5.081472742263034      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.04391308145274031   |
| train_1/q_grads           | -0.008598642796278     |
| train_1/q_grads_std       | 0.32053704783320425    |
| train_1/q_loss            | 0.21179424612557823    |
| train_1/reward            | -1.4852948067738907    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015869140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5110616390294145    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 654.26. Rollout time: 434.85, Training time: 219.37
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 527211.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.60291470493631     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -8.4486761380281      |
| train_0/fw_bonus          | -0.9996191695332527   |
| train_0/fw_loss           | 9.914683796523605e-05 |
| train_0/mu_grads          | -0.021787717659026384 |
| train_0/mu_grads_std      | 0.26082432344555856   |
| train_0/mu_loss           | 8.349035107167847     |
| train_0/next_q            | -8.325516395030531    |
| train_0/q_grads           | 0.059156677965074775  |
| train_0/q_grads_std       | 0.22791275344789028   |
| train_0/q_loss            | 0.17737275128001836   |
| train_0/reward            | -0.8661511506157694   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -8.536871223142423    |
| train_1/avg_q             | -7.456287492850914    |
| train_1/current_q         | -1.6044962283033573   |
| train_1/fw_bonus          | -0.9984046071767807   |
| train_1/fw_loss           | 0.0011515257210703567 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 5.974468648550599     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.16639776236042944  |
| train_1/q_grads           | -0.012362653971649706 |
| train_1/q_grads_std       | 0.34235958084464074   |
| train_1/q_loss            | 0.11293978609065855   |
| train_1/reward            | -1.511163075065997    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010009765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.606133887480644    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 582.16. Rollout time: 388.19, Training time: 193.94
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 618336.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.497804586201452    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.26581256426941     |
| train_0/fw_bonus          | -0.999666377902031    |
| train_0/fw_loss           | 8.732158166822047e-05 |
| train_0/mu_grads          | -0.023522080201655627 |
| train_0/mu_grads_std      | 0.2753638617694378    |
| train_0/mu_loss           | 9.172885903786897     |
| train_0/next_q            | -9.157720482516046    |
| train_0/q_grads           | 0.05934738852083683   |
| train_0/q_grads_std       | 0.23055528923869134   |
| train_0/q_loss            | 0.13839483888973497   |
| train_0/reward            | -0.8622558878443669   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0007568359375       |
| train_0/target_q          | -9.39656547703738     |
| train_1/avg_q             | -7.506399777873036    |
| train_1/current_q         | -1.5332499672503648   |
| train_1/fw_bonus          | -0.9985796451568604   |
| train_1/fw_loss           | 0.0011103106720838697 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 6.960660432178026     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.047440239808999064 |
| train_1/q_grads           | -0.016377657372504472 |
| train_1/q_grads_std       | 0.3590487249195576    |
| train_1/q_loss            | 0.06614325572336578   |
| train_1/reward            | -1.5086698491097195   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009765625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.5331827632683894   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 533.68. Rollout time: 352.95, Training time: 180.70
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 709165.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.562099474551837     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.650451557326843     |
| train_0/fw_bonus          | -0.9998189821839333    |
| train_0/fw_loss           | 4.9089439198724e-05    |
| train_0/mu_grads          | -0.022478274768218398  |
| train_0/mu_grads_std      | 0.2808549597859383     |
| train_0/mu_loss           | 9.570309886743683      |
| train_0/next_q            | -9.563287786091356     |
| train_0/q_grads           | 0.05977569874376058    |
| train_0/q_grads_std       | 0.23311521857976913    |
| train_0/q_loss            | 0.10847093039139248    |
| train_0/reward            | -0.8559799620721605    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0119140625           |
| train_0/target_q          | -9.794587897513281     |
| train_1/avg_q             | -7.3095455994764       |
| train_1/current_q         | -1.4859879315154925    |
| train_1/fw_bonus          | -0.9986225068569183    |
| train_1/fw_loss           | 0.0011002214072505013  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 6.914391300516198      |
| train_1/n_subgoals        | 2690.0                 |
| train_1/next_q            | -0.0021727849752690197 |
| train_1/q_grads           | -0.01890168325044215   |
| train_1/q_grads_std       | 0.371063894033432      |
| train_1/q_loss            | 0.022335706710050342   |
| train_1/reward            | -1.4831099461225676    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010009765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4841332607552185    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 531.47. Rollout time: 352.69, Training time: 178.75
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 8                       |
| policy/steps              | 800290.0                |
| test/episodes             | 225.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.492816508009227      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 900.0                   |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.662702017636267      |
| train_0/fw_bonus          | -0.9998116165399551     |
| train_0/fw_loss           | 5.093526824566652e-05   |
| train_0/mu_grads          | -0.025541635835543273   |
| train_0/mu_grads_std      | 0.28438395634293556     |
| train_0/mu_loss           | 9.604689264118425       |
| train_0/next_q            | -9.597244707708962      |
| train_0/q_grads           | 0.059976320061832664    |
| train_0/q_grads_std       | 0.2352351225912571      |
| train_0/q_loss            | 0.11065808207952084     |
| train_0/reward            | -0.8544180398355821     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.011376953125          |
| train_0/target_q          | -9.821206348113733      |
| train_1/avg_q             | -7.443064924211481      |
| train_1/current_q         | -1.5024742549739467     |
| train_1/fw_bonus          | -0.9992773219943046     |
| train_1/fw_loss           | 0.0009460456421948038   |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 7.406657392206019       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.5214558742454755e-05 |
| train_1/q_grads           | -0.02114911386743188    |
| train_1/q_grads_std       | 0.37886135205626487     |
| train_1/q_loss            | 0.0361175611209328      |
| train_1/reward            | -1.5056530563670094     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00078125              |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5056608476194175     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 530.69. Rollout time: 350.77, Training time: 179.88
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 9                       |
| policy/steps              | 891415.0                |
| test/episodes             | 250.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.337767473084076      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.700260724082302      |
| train_0/fw_bonus          | -0.9998357519507408     |
| train_0/fw_loss           | 4.488736976782093e-05   |
| train_0/mu_grads          | -0.027124142879620193   |
| train_0/mu_grads_std      | 0.29021024852991106     |
| train_0/mu_loss           | 9.619411234007469       |
| train_0/next_q            | -9.615019204931361      |
| train_0/q_grads           | 0.05907552558928728     |
| train_0/q_grads_std       | 0.23585574068129062     |
| train_0/q_loss            | 0.0942282099351618      |
| train_0/reward            | -0.854198108323908      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.007080078125          |
| train_0/target_q          | -9.848854524273628      |
| train_1/avg_q             | -7.4808426292381744     |
| train_1/current_q         | -1.4706912596225814     |
| train_1/fw_bonus          | -0.9995192438364029     |
| train_1/fw_loss           | 0.0008890840123058297   |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 6.971241669461588       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -0.00021463088568922554 |
| train_1/q_grads           | -0.022601715894415973   |
| train_1/q_grads_std       | 0.3860616162419319      |
| train_1/q_loss            | 0.022903626407698913    |
| train_1/reward            | -1.4704280068370281     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001025390625          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4705392272307796     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 529.25. Rollout time: 349.05, Training time: 180.17
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 982540.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.540281984416114     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.605174619755942     |
| train_0/fw_bonus          | -0.9998923897743225    |
| train_0/fw_loss           | 3.0699498711328485e-05 |
| train_0/mu_grads          | -0.027161330729722977  |
| train_0/mu_grads_std      | 0.29419188424944875    |
| train_0/mu_loss           | 9.522732433021261      |
| train_0/next_q            | -9.516817890492883     |
| train_0/q_grads           | 0.05834430055692792    |
| train_0/q_grads_std       | 0.23620000742375852    |
| train_0/q_loss            | 0.09321721926211221    |
| train_0/reward            | -0.8538377503544325    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0511962890625        |
| train_0/target_q          | -9.754775859067456     |
| train_1/avg_q             | -7.443331724409267     |
| train_1/current_q         | -1.5176782648650984    |
| train_1/fw_bonus          | -0.9997829988598823    |
| train_1/fw_loss           | 0.000826982781291008   |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 7.057183129647638      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.0432355128961754    |
| train_1/q_grads           | -0.02371275322511792   |
| train_1/q_grads_std       | 0.39393417686223986    |
| train_1/q_loss            | 0.017151967345236746   |
| train_1/reward            | -1.4954976498658652    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00087890625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.517591187980958     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 529.69. Rollout time: 348.50, Training time: 181.15
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 1073665.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -8.344841371119761    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.579068427053446    |
| train_0/fw_bonus          | -0.9998816236853599   |
| train_0/fw_loss           | 3.339369850436924e-05 |
| train_0/mu_grads          | -0.027898315573111176 |
| train_0/mu_grads_std      | 0.2981280140578747    |
| train_0/mu_loss           | 9.501163283645374     |
| train_0/next_q            | -9.495561215250126    |
| train_0/q_grads           | 0.05791953457519412   |
| train_0/q_grads_std       | 0.23692088574171066   |
| train_0/q_loss            | 0.08987140489351987   |
| train_0/reward            | -0.8533047824908863   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0370361328125       |
| train_0/target_q          | -9.727694116946846    |
| train_1/avg_q             | -7.427760503990578    |
| train_1/current_q         | -14.635841104137654   |
| train_1/fw_bonus          | -0.9997875198721886   |
| train_1/fw_loss           | 0.0008259206166258082 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 18.597131801282995    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.023331933887675405 |
| train_1/q_grads_std       | 0.4280616298317909    |
| train_1/q_loss            | 20.46586560411675     |
| train_1/reward            | -1.4990105542645324   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -14.96544512457704    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 528.48. Rollout time: 349.15, Training time: 179.30
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 1164790.0              |
| test/episodes             | 325.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.7557425705932905    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.662773761720869     |
| train_0/fw_bonus          | -0.999902968108654     |
| train_0/fw_loss           | 2.8046453439856123e-05 |
| train_0/mu_grads          | -0.027242311136797072  |
| train_0/mu_grads_std      | 0.3022426299750805     |
| train_0/mu_loss           | 9.584006221298765      |
| train_0/next_q            | -9.579016085692087     |
| train_0/q_grads           | 0.057483420334756376   |
| train_0/q_grads_std       | 0.23764184340834618    |
| train_0/q_loss            | 0.08756041699193373    |
| train_0/reward            | -0.854480458132457     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05224609375          |
| train_0/target_q          | -9.814573592893035     |
| train_1/avg_q             | -7.542423524017685     |
| train_1/current_q         | -14.787204572437966    |
| train_1/fw_bonus          | -1.000098705291748     |
| train_1/fw_loss           | 0.000752648917841725   |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.414873423389558     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -26.999999999999478    |
| train_1/q_grads           | -0.021934800455346702  |
| train_1/q_grads_std       | 0.43866379335522654    |
| train_1/q_loss            | 17.20313337024316      |
| train_1/reward            | -1.4844734451078694    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.079461238076458    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 536.24. Rollout time: 351.47, Training time: 184.74
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 1255915.0              |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.736637767878728     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.663492814848897     |
| train_0/fw_bonus          | -0.999889375269413     |
| train_0/fw_loss           | 3.145599102936103e-05  |
| train_0/mu_grads          | -0.026707526622340085  |
| train_0/mu_grads_std      | 0.3063719853758812     |
| train_0/mu_loss           | 9.58517341475005       |
| train_0/next_q            | -9.578974115078        |
| train_0/q_grads           | 0.056889512296766045   |
| train_0/q_grads_std       | 0.23842977732419968    |
| train_0/q_loss            | 0.08953823355814297    |
| train_0/reward            | -0.8546594602041295    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0429443359375        |
| train_0/target_q          | -9.812121468521818     |
| train_1/avg_q             | -5.203505269447448     |
| train_1/current_q         | -1.481042583647853     |
| train_1/fw_bonus          | -1.0004102930426597    |
| train_1/fw_loss           | 0.0006792793879867532  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 6.9332347655408295     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.128540316244703e-06 |
| train_1/q_grads           | -0.0233425744343549    |
| train_1/q_grads_std       | 0.4403266593813896     |
| train_1/q_loss            | 0.07453137862583897    |
| train_1/reward            | -1.4965845962244202    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4965879703692642    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 539.32. Rollout time: 359.03, Training time: 180.26
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 1347040.0              |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.52468123057468      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.636608399299996     |
| train_0/fw_bonus          | -0.9999260991811753    |
| train_0/fw_loss           | 2.225992800504173e-05  |
| train_0/mu_grads          | -0.028745616087689996  |
| train_0/mu_grads_std      | 0.31071227565407755    |
| train_0/mu_loss           | 9.585787898642852      |
| train_0/next_q            | -9.575665661142137     |
| train_0/q_grads           | 0.05651717130094767    |
| train_0/q_grads_std       | 0.23968154489994048    |
| train_0/q_loss            | 0.10487852053568907    |
| train_0/reward            | -0.8540095003860187    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0739501953125        |
| train_0/target_q          | -9.786642066073693     |
| train_1/avg_q             | -7.23475453752835      |
| train_1/current_q         | -1.4865035400568978    |
| train_1/fw_bonus          | -1.0003682121634483    |
| train_1/fw_loss           | 0.0006891938028275035  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 6.2970366418957076     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.870311528430708e-07 |
| train_1/q_grads           | -0.023242697492241858  |
| train_1/q_grads_std       | 0.4412861794233322     |
| train_1/q_loss            | 0.045771092237709914   |
| train_1/reward            | -1.492323279225093     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000634765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4923234888265848    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 539.81. Rollout time: 358.39, Training time: 181.38
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1438165.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.534476365721466    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.675207587083804    |
| train_0/fw_bonus          | -0.9999207943677902   |
| train_0/fw_loss           | 2.358584579269518e-05 |
| train_0/mu_grads          | -0.028450005734339357 |
| train_0/mu_grads_std      | 0.3147083580493927    |
| train_0/mu_loss           | 9.595361556677894     |
| train_0/next_q            | -9.58952588788974     |
| train_0/q_grads           | 0.0559082044288516    |
| train_0/q_grads_std       | 0.24103011824190618   |
| train_0/q_loss            | 0.09210522672028766   |
| train_0/reward            | -0.8550980601517949   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1256103515625       |
| train_0/target_q          | -9.828016652427042    |
| train_1/avg_q             | -7.4015363711059      |
| train_1/current_q         | -1.4914599012664207   |
| train_1/fw_bonus          | -1.0005456686019898   |
| train_1/fw_loss           | 0.0006474117792095058 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 5.422494775993459     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -5.21175652788672e-10 |
| train_1/q_grads           | -0.022861642763018608 |
| train_1/q_grads_std       | 0.4427866473793983    |
| train_1/q_loss            | 0.03397057867496501   |
| train_1/reward            | -1.4956179916320251   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.4956179918338077   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 545.33. Rollout time: 363.42, Training time: 181.88
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1529290.0              |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.536850949825756     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.704379195566897     |
| train_0/fw_bonus          | -0.9999289855360984    |
| train_0/fw_loss           | 2.1530946469283663e-05 |
| train_0/mu_grads          | -0.029007397685199977  |
| train_0/mu_grads_std      | 0.3175562180578709     |
| train_0/mu_loss           | 9.624343820194042      |
| train_0/next_q            | -9.617241564643981     |
| train_0/q_grads           | 0.05564796291291714    |
| train_0/q_grads_std       | 0.2433146946132183     |
| train_0/q_loss            | 0.09115419060381198    |
| train_0/reward            | -0.8558671511767898    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1370849609375        |
| train_0/target_q          | -9.856724707092544     |
| train_1/avg_q             | -7.482392972349201     |
| train_1/current_q         | -1.486368484325757     |
| train_1/fw_bonus          | -1.0006734818220138    |
| train_1/fw_loss           | 0.0006173146102810279  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 4.710265730178508      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.953240926124509e-11 |
| train_1/q_grads           | -0.023374934680759907  |
| train_1/q_grads_std       | 0.44398885071277616    |
| train_1/q_loss            | 0.034379558714955946   |
| train_1/reward            | -1.4857468216272536    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001220703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4857468216552854    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 541.36. Rollout time: 357.88, Training time: 183.45
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1620415.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.717849548567026     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.73469097484146      |
| train_0/fw_bonus          | -0.9999281570315361    |
| train_0/fw_loss           | 2.1739867315773152e-05 |
| train_0/mu_grads          | -0.029551036981865765  |
| train_0/mu_grads_std      | 0.3199728988111019     |
| train_0/mu_loss           | 9.655888359762184      |
| train_0/next_q            | -9.648702388189516     |
| train_0/q_grads           | 0.05515407221391797    |
| train_0/q_grads_std       | 0.24555041268467903    |
| train_0/q_loss            | 0.0899067269921239     |
| train_0/reward            | -0.8560252173119807    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.121875               |
| train_0/target_q          | -9.887377073540934     |
| train_1/avg_q             | -7.375765492130848     |
| train_1/current_q         | -1.4823520681496813    |
| train_1/fw_bonus          | -1.0005158990621568    |
| train_1/fw_loss           | 0.0006544207120896317  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 3.9810351123872527     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.258779574763881e-11 |
| train_1/q_grads           | -0.024082560418173672  |
| train_1/q_grads_std       | 0.4451803885400295     |
| train_1/q_loss            | 0.029764853438807092   |
| train_1/reward            | -1.4818932723341276    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000634765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4818932723711031    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 539.99. Rollout time: 358.72, Training time: 181.24
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 18                      |
| policy/steps              | 1711540.0               |
| test/episodes             | 475.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.470181462260936      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.665148123194335      |
| train_0/fw_bonus          | -0.9998873546719551     |
| train_0/fw_loss           | 3.1962565162757525e-05  |
| train_0/mu_grads          | -0.03087013023905456    |
| train_0/mu_grads_std      | 0.3198888495564461      |
| train_0/mu_loss           | 9.589179594576674       |
| train_0/next_q            | -9.58193788154525       |
| train_0/q_grads           | 0.05477035827934742     |
| train_0/q_grads_std       | 0.24768304377794265     |
| train_0/q_loss            | 0.08627113022248444     |
| train_0/reward            | -0.8546640474363812     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1065185546875         |
| train_0/target_q          | -9.817327882763816      |
| train_1/avg_q             | -7.487491220742699      |
| train_1/current_q         | -1.4922294429676266     |
| train_1/fw_bonus          | -1.0007422983646392     |
| train_1/fw_loss           | 0.0006011143370415084   |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 3.5747656493905877      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.0445880353620277e-10 |
| train_1/q_grads           | -0.02482768930494785    |
| train_1/q_grads_std       | 0.44752685353159904     |
| train_1/q_loss            | 0.02552109768598123     |
| train_1/reward            | -1.491132898190699      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00078125              |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.491132898261548      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 539.51. Rollout time: 355.91, Training time: 183.57
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1802665.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.675089857103397     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.657323145733923     |
| train_0/fw_bonus          | -0.9999437376856803    |
| train_0/fw_loss           | 1.7836653773883883e-05 |
| train_0/mu_grads          | -0.03214607872068882   |
| train_0/mu_grads_std      | 0.32008658796548844    |
| train_0/mu_loss           | 9.58182410304048       |
| train_0/next_q            | -9.574122533194593     |
| train_0/q_grads           | 0.054542391654103996   |
| train_0/q_grads_std       | 0.2506636865437031     |
| train_0/q_loss            | 0.08711175659959919    |
| train_0/reward            | -0.8545171269885031    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2138916015625        |
| train_0/target_q          | -9.80846877130304      |
| train_1/avg_q             | -7.493376846660562     |
| train_1/current_q         | -1.4863419365597355    |
| train_1/fw_bonus          | -1.0007386445999145    |
| train_1/fw_loss           | 0.0006019735883455724  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 3.638999860421946      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.311183501339163e-11 |
| train_1/q_grads           | -0.025736879045143723  |
| train_1/q_grads_std       | 0.45124285817146303    |
| train_1/q_loss            | 0.016882945968321617   |
| train_1/reward            | -1.4861680032176081    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000634765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.486168003227236     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 540.00. Rollout time: 353.93, Training time: 186.04
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 20                      |
| policy/steps              | 1893790.0               |
| test/episodes             | 525.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.2522593511203715     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.593617375706778      |
| train_0/fw_bonus          | -0.9999350100755692     |
| train_0/fw_loss           | 2.002287610594067e-05   |
| train_0/mu_grads          | -0.032057886756956575   |
| train_0/mu_grads_std      | 0.3233460396528244      |
| train_0/mu_loss           | 9.521571751631916       |
| train_0/next_q            | -9.515052334635376      |
| train_0/q_grads           | 0.05437469659373164     |
| train_0/q_grads_std       | 0.25373240411281583     |
| train_0/q_loss            | 0.08898746228941734     |
| train_0/reward            | -0.8534851912845625     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.15341796875           |
| train_0/target_q          | -9.744590497002083      |
| train_1/avg_q             | -7.367733632401551      |
| train_1/current_q         | -1.4850932574752531     |
| train_1/fw_bonus          | -1.0010192900896073     |
| train_1/fw_loss           | 0.0005358940259611699   |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 3.94744347685291        |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -5.0887493424331356e-14 |
| train_1/q_grads           | -0.026492744265124202   |
| train_1/q_grads_std       | 0.45440470725297927     |
| train_1/q_loss            | 0.01541801232320052     |
| train_1/reward            | -1.4845840575537295     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006103515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4845840575537494     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 535.46. Rollout time: 349.65, Training time: 185.78
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 21                      |
| policy/steps              | 1984915.0               |
| test/episodes             | 550.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.482710228441754      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.638006908749288      |
| train_0/fw_bonus          | -0.9999406933784485     |
| train_0/fw_loss           | 1.8598250130708037e-05  |
| train_0/mu_grads          | -0.03211812507361174    |
| train_0/mu_grads_std      | 0.32813014537096025     |
| train_0/mu_loss           | 9.56130115709108        |
| train_0/next_q            | -9.554332123965969      |
| train_0/q_grads           | 0.05442303093150258     |
| train_0/q_grads_std       | 0.255805578827858       |
| train_0/q_loss            | 0.08816703117353959     |
| train_0/reward            | -0.8544965363500523     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1313232421875         |
| train_0/target_q          | -9.791868288124613      |
| train_1/avg_q             | -7.4176166281117615     |
| train_1/current_q         | -1.4839204870535307     |
| train_1/fw_bonus          | -1.000928094983101      |
| train_1/fw_loss           | 0.0005573704060225282   |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 4.037655711049824       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.6764840320637616e-08 |
| train_1/q_grads           | -0.028007389837875964   |
| train_1/q_grads_std       | 0.4578017324209213      |
| train_1/q_loss            | 0.012949664202952502    |
| train_1/reward            | -1.4834780495832092     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0008544921875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4834780653099044     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 540.56. Rollout time: 355.44, Training time: 185.09
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 2076040.0              |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.658165061954457     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.678184115946468     |
| train_0/fw_bonus          | -0.9999493390321732    |
| train_0/fw_loss           | 1.642893364532938e-05  |
| train_0/mu_grads          | -0.033213431295007464  |
| train_0/mu_grads_std      | 0.33144875317811967    |
| train_0/mu_loss           | 9.602509674670127      |
| train_0/next_q            | -9.59541650672563      |
| train_0/q_grads           | 0.054491824470460415   |
| train_0/q_grads_std       | 0.2572475917637348     |
| train_0/q_loss            | 0.08988787666274937    |
| train_0/reward            | -0.8551927279026131    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1601806640625        |
| train_0/target_q          | -9.832083656286983     |
| train_1/avg_q             | -7.4745881996376475    |
| train_1/current_q         | -1.4755444574271157    |
| train_1/fw_bonus          | -1.0010842949151992    |
| train_1/fw_loss           | 0.0005205939465668053  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 4.104367661046931      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.114069332571368e-08 |
| train_1/q_grads           | -0.028670872282236814  |
| train_1/q_grads_std       | 0.46099372804164884    |
| train_1/q_loss            | 0.013078583037625758   |
| train_1/reward            | -1.4759963199161574    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4759963481070488    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 546.40. Rollout time: 359.42, Training time: 186.95
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 2167165.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.560064288875212     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.70071822573601      |
| train_0/fw_bonus          | -0.9999543383717537    |
| train_0/fw_loss           | 1.5180394507297024e-05 |
| train_0/mu_grads          | -0.0338589352555573    |
| train_0/mu_grads_std      | 0.33474179953336713    |
| train_0/mu_loss           | 9.625996730039253      |
| train_0/next_q            | -9.619575945507126     |
| train_0/q_grads           | 0.05412706444039941    |
| train_0/q_grads_std       | 0.258895568549633      |
| train_0/q_loss            | 0.09246944196961333    |
| train_0/reward            | -0.8556359187845374    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.260107421875         |
| train_0/target_q          | -9.857826146112028     |
| train_1/avg_q             | -7.49320426412377      |
| train_1/current_q         | -1.4690864106893493    |
| train_1/fw_bonus          | -1.0011094510555267    |
| train_1/fw_loss           | 0.0005146691575646401  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 3.883232940492026      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.16981673768196e-08  |
| train_1/q_grads           | -0.02957107578404248   |
| train_1/q_grads_std       | 0.4646762490272522     |
| train_1/q_loss            | 0.014213786811347443   |
| train_1/reward            | -1.469093806076853     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4690938230813608    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 546.34. Rollout time: 358.48, Training time: 187.83
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 24                     |
| policy/steps              | 2258290.0              |
| test/episodes             | 625.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.491476074508117     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.69149963949808      |
| train_0/fw_bonus          | -0.9999486193060875    |
| train_0/fw_loss           | 1.6613317939118133e-05 |
| train_0/mu_grads          | -0.034568702522665265  |
| train_0/mu_grads_std      | 0.33954156637191774    |
| train_0/mu_loss           | 9.611883914217227      |
| train_0/next_q            | -9.604992543947366     |
| train_0/q_grads           | 0.05380954006686807    |
| train_0/q_grads_std       | 0.26136442720890046    |
| train_0/q_loss            | 0.0862112044934689     |
| train_0/reward            | -0.8556194222008344    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.241357421875         |
| train_0/target_q          | -9.845537126381787     |
| train_1/avg_q             | -7.461781028934406     |
| train_1/current_q         | -1.4934302575875922    |
| train_1/fw_bonus          | -1.001333263516426     |
| train_1/fw_loss           | 0.00046197168121580033 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 4.059838746210178      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.279661005769739e-09 |
| train_1/q_grads           | -0.030101837310940027  |
| train_1/q_grads_std       | 0.4685413852334023     |
| train_1/q_loss            | 0.009274025168505668   |
| train_1/reward            | -1.4942372536999755    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4942372570947702    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 544.68. Rollout time: 355.82, Training time: 188.83
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-------------------------------------------------------
| epoch                     | 25                      |
| policy/steps              | 2349415.0               |
| test/episodes             | 650.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.576789344676934      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.64690995855212       |
| train_0/fw_bonus          | -0.9999324142932892     |
| train_0/fw_loss           | 2.067415509827697e-05   |
| train_0/mu_grads          | -0.035068183299154045   |
| train_0/mu_grads_std      | 0.3422611549496651      |
| train_0/mu_loss           | 9.568137004245042       |
| train_0/next_q            | -9.561074360485147      |
| train_0/q_grads           | 0.053692145831882955    |
| train_0/q_grads_std       | 0.2643906034529209      |
| train_0/q_loss            | 0.08725285313855508     |
| train_0/reward            | -0.8552166401408613     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1136474609375         |
| train_0/target_q          | -9.799664864304077      |
| train_1/avg_q             | -7.4689287419569395     |
| train_1/current_q         | -1.481658119636141      |
| train_1/fw_bonus          | -1.0014138609170913     |
| train_1/fw_loss           | 0.00044299644214333965  |
| train_1/mu_grads          | 0.015022383071482182    |
| train_1/mu_grads_std      | 0.09010138362646103     |
| train_1/mu_loss           | 3.9435849948160757      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -5.7958573561308026e-12 |
| train_1/q_grads           | -0.030942961107939482   |
| train_1/q_grads_std       | 0.4724058978259563      |
| train_1/q_loss            | 0.019459926910529245    |
| train_1/reward            | -1.4812727946729864     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0007568359375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4812727946748747     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 542.64. Rollout time: 357.39, Training time: 185.22
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 2440540.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.6905015015270815    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.695070663925422     |
| train_0/fw_bonus          | -0.9999436110258102    |
| train_0/fw_loss           | 1.786748882750544e-05  |
| train_0/mu_grads          | -0.035019183345139024  |
| train_0/mu_grads_std      | 0.34345217421650887    |
| train_0/mu_loss           | 9.618581698697108      |
| train_0/next_q            | -9.612697663179208     |
| train_0/q_grads           | 0.053695324901491405   |
| train_0/q_grads_std       | 0.26723050475120547    |
| train_0/q_loss            | 0.08549076886741461    |
| train_0/reward            | -0.8549015561511624    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.23359375             |
| train_0/target_q          | -9.847871464955391     |
| train_1/avg_q             | -7.439396824095685     |
| train_1/current_q         | -14.843978130366333    |
| train_1/fw_bonus          | -1.001537936925888     |
| train_1/fw_loss           | 0.00041378139139851554 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.088553918959498     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.026505524385720493  |
| train_1/q_grads_std       | 0.485698739439249      |
| train_1/q_loss            | 22.924582282425398     |
| train_1/reward            | -1.4927672226796858    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000537109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.066437144554692    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 543.31. Rollout time: 356.65, Training time: 186.63
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 2531665.0              |
| test/episodes             | 700.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -8.48685424755264      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.662733248462361     |
| train_0/fw_bonus          | -0.9999312296509743    |
| train_0/fw_loss           | 2.0970604964531958e-05 |
| train_0/mu_grads          | -0.03582108477130532   |
| train_0/mu_grads_std      | 0.34480083361268044    |
| train_0/mu_loss           | 9.583800402317317      |
| train_0/next_q            | -9.577124201964637     |
| train_0/q_grads           | 0.05357894385233521    |
| train_0/q_grads_std       | 0.26867796331644056    |
| train_0/q_loss            | 0.08460806400258251    |
| train_0/reward            | -0.8548007136007072    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.223193359375         |
| train_0/target_q          | -9.812902400473993     |
| train_1/avg_q             | -8.139499914863293     |
| train_1/current_q         | -14.807829521012584    |
| train_1/fw_bonus          | -1.001468649506569     |
| train_1/fw_loss           | 0.00043009520595660433 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.08103731504587      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.02603406421840191   |
| train_1/q_grads_std       | 0.49525605514645576    |
| train_1/q_loss            | 21.1048453404498       |
| train_1/reward            | -1.5001615466404474    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007080078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.111945238046701    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 543.96. Rollout time: 358.85, Training time: 185.08
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 2622790.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.28678426722424      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.711178996276317     |
| train_0/fw_bonus          | -0.9999288126826287    |
| train_0/fw_loss           | 2.1574440143012908e-05 |
| train_0/mu_grads          | -0.03655118923634291   |
| train_0/mu_grads_std      | 0.3469366833567619     |
| train_0/mu_loss           | 9.632535577684216      |
| train_0/next_q            | -9.626325922053047     |
| train_0/q_grads           | 0.05340171763673425    |
| train_0/q_grads_std       | 0.27065315991640093    |
| train_0/q_loss            | 0.08605834457932335    |
| train_0/reward            | -0.8554519820696441    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1484375              |
| train_0/target_q          | -9.864561145875886     |
| train_1/avg_q             | -7.8050368507690076    |
| train_1/current_q         | -14.99752986885992     |
| train_1/fw_bonus          | -1.0016063809394837    |
| train_1/fw_loss           | 0.00039766729169059544 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.170393140220373     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.02737440993078053   |
| train_1/q_grads_std       | 0.5039681240916252     |
| train_1/q_loss            | 17.659965853582285     |
| train_1/reward            | -1.4804528298016522    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007080078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.193011911832908    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 545.06. Rollout time: 357.58, Training time: 187.45
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 2713915.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.95680301598554      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.59395795136206      |
| train_0/fw_bonus          | -0.9999331817030906    |
| train_0/fw_loss           | 2.0480326043070818e-05 |
| train_0/mu_grads          | -0.03708188394084573   |
| train_0/mu_grads_std      | 0.3485811442136765     |
| train_0/mu_loss           | 9.515777391777709      |
| train_0/next_q            | -9.509096202792355     |
| train_0/q_grads           | 0.05342191103845835    |
| train_0/q_grads_std       | 0.27159769386053084    |
| train_0/q_loss            | 0.08437614039759248    |
| train_0/reward            | -0.8541674157138914    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1788330078125        |
| train_0/target_q          | -9.745626670492985     |
| train_1/avg_q             | -7.424811690870017     |
| train_1/current_q         | -15.11139919030264     |
| train_1/fw_bonus          | -1.0017486840486527    |
| train_1/fw_loss           | 0.0003641626906755846  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.28067658840544      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.028449991112574936  |
| train_1/q_grads_std       | 0.51312765032053       |
| train_1/q_loss            | 15.19196538936642      |
| train_1/reward            | -1.4943901205842849    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.345192366678043    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 540.83. Rollout time: 352.64, Training time: 188.16
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2805040.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.760371216831939     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.526733235284894     |
| train_0/fw_bonus          | -0.9999352261424065    |
| train_0/fw_loss           | 1.9970119319623335e-05 |
| train_0/mu_grads          | -0.037720353342592716  |
| train_0/mu_grads_std      | 0.3497842937707901     |
| train_0/mu_loss           | 9.446899777390744      |
| train_0/next_q            | -9.440986857900835     |
| train_0/q_grads           | 0.05342979347333312    |
| train_0/q_grads_std       | 0.272236480563879      |
| train_0/q_loss            | 0.08480847128362834    |
| train_0/reward            | -0.8540041485350229    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1912353515625        |
| train_0/target_q          | -9.677078650204345     |
| train_1/avg_q             | -7.540022491244015     |
| train_1/current_q         | -14.982246524994997    |
| train_1/fw_bonus          | -1.0014823377132416    |
| train_1/fw_loss           | 0.00042687292079790495 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.23334817047963      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.028413003869354726  |
| train_1/q_grads_std       | 0.5234994485974311     |
| train_1/q_loss            | 13.240646570236652     |
| train_1/reward            | -1.5241342122943025    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000634765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.23023333338806     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 545.32. Rollout time: 357.62, Training time: 187.67
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 2896165.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.336528253079653    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.597252969987725    |
| train_0/fw_bonus          | -0.9999564677476883   |
| train_0/fw_loss           | 1.464557237795816e-05 |
| train_0/mu_grads          | -0.03821182958781719  |
| train_0/mu_grads_std      | 0.35106845423579214   |
| train_0/mu_loss           | 9.518024148135828     |
| train_0/next_q            | -9.512673596403436    |
| train_0/q_grads           | 0.05310264648869634   |
| train_0/q_grads_std       | 0.273262083530426     |
| train_0/q_loss            | 0.08389780355467599   |
| train_0/reward            | -0.8541970900652813   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2107421875          |
| train_0/target_q          | -9.748591113276948    |
| train_1/avg_q             | -7.451674370449346    |
| train_1/current_q         | -14.874459071155803   |
| train_1/fw_bonus          | -1.001791536808014    |
| train_1/fw_loss           | 0.0003540766345395241 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.23141170372687     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.028098537912592293 |
| train_1/q_grads_std       | 0.5311607092618942    |
| train_1/q_loss            | 10.539262264123566    |
| train_1/reward            | -1.5088082357731765   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00068359375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.138033821710684   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 545.56. Rollout time: 356.15, Training time: 189.38
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 32                     |
| policy/steps              | 2987030.0              |
| test/episodes             | 825.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.651485421265237     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3300.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.662584737015775     |
| train_0/fw_bonus          | -0.999943844974041     |
| train_0/fw_loss           | 1.7807932817959226e-05 |
| train_0/mu_grads          | -0.039143056422472     |
| train_0/mu_grads_std      | 0.35236070603132247    |
| train_0/mu_loss           | 9.584801990043106      |
| train_0/next_q            | -9.578449372186112     |
| train_0/q_grads           | 0.05300750620663166    |
| train_0/q_grads_std       | 0.27386531233787537    |
| train_0/q_loss            | 0.0834013620447992     |
| train_0/reward            | -0.8549139414884849    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.254833984375         |
| train_0/target_q          | -9.814561508607806     |
| train_1/avg_q             | -7.583543348658975     |
| train_1/current_q         | -15.009690755020094    |
| train_1/fw_bonus          | -1.001868885755539     |
| train_1/fw_loss           | 0.00033585925193619915 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.301728665538626     |
| train_1/n_subgoals        | 2691.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.02788725756108761   |
| train_1/q_grads_std       | 0.5363797694444656     |
| train_1/q_loss            | 10.043955435174784     |
| train_1/reward            | -1.5090005419231602    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0003662109375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.309415092704416    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 502.80. Rollout time: 328.35, Training time: 174.43
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 3078155.0              |
| test/episodes             | 850.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.937915626125022     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.546997918870359     |
| train_0/fw_bonus          | -0.9999345988035202    |
| train_0/fw_loss           | 2.0122032083236263e-05 |
| train_0/mu_grads          | -0.0393840323202312    |
| train_0/mu_grads_std      | 0.35333478078246117    |
| train_0/mu_loss           | 9.468660466643742      |
| train_0/next_q            | -9.461749625955857     |
| train_0/q_grads           | 0.0527212523855269     |
| train_0/q_grads_std       | 0.2744551129639149     |
| train_0/q_loss            | 0.0854973593511362     |
| train_0/reward            | -0.854217316499853     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1903564453125        |
| train_0/target_q          | -9.696023542082042     |
| train_1/avg_q             | -7.452929035374248     |
| train_1/current_q         | -14.932877182026498    |
| train_1/fw_bonus          | -1.001457729935646     |
| train_1/fw_loss           | 0.00043266191350994633 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.22118049415996      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.029039588011801242  |
| train_1/q_grads_std       | 0.5412996172904968     |
| train_1/q_loss            | 11.042360785285277     |
| train_1/reward            | -1.5158943370202906    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004150390625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.241373340926547    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 497.54. Rollout time: 324.17, Training time: 173.34
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 3169280.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -9.061712977239466    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.69164183247157     |
| train_0/fw_bonus          | -0.9999234646558761   |
| train_0/fw_loss           | 2.291350106133905e-05 |
| train_0/mu_grads          | -0.039489774871617554 |
| train_0/mu_grads_std      | 0.3573067307472229    |
| train_0/mu_loss           | 9.612944016351246     |
| train_0/next_q            | -9.606760248363631    |
| train_0/q_grads           | 0.052448980137705804  |
| train_0/q_grads_std       | 0.27632479965686796   |
| train_0/q_loss            | 0.08765478992612244   |
| train_0/reward            | -0.8553869381954428   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1644287109375       |
| train_0/target_q          | -9.843853987134882    |
| train_1/avg_q             | -7.482021474962414    |
| train_1/current_q         | -15.247981012670447   |
| train_1/fw_bonus          | -1.0004484161734581   |
| train_1/fw_loss           | 0.000670307528343983  |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.301456702369272    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.02855984037742019  |
| train_1/q_grads_std       | 0.5473251506686211    |
| train_1/q_loss            | 12.528690997213795    |
| train_1/reward            | -1.5064215245220112   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.565234512803267   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 507.03. Rollout time: 333.03, Training time: 173.97
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 3260405.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.3343802640318065    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.629901559259569     |
| train_0/fw_bonus          | -0.9999301165342331    |
| train_0/fw_loss           | 2.1248801817819186e-05 |
| train_0/mu_grads          | -0.040145845524966715  |
| train_0/mu_grads_std      | 0.36157371252775194    |
| train_0/mu_loss           | 9.547840156006952      |
| train_0/next_q            | -9.540845530551241     |
| train_0/q_grads           | 0.05236370358616114    |
| train_0/q_grads_std       | 0.27696680650115013    |
| train_0/q_loss            | 0.09080520028203043    |
| train_0/reward            | -0.855642165914469     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1921142578125        |
| train_0/target_q          | -9.783931314107239     |
| train_1/avg_q             | -7.922990374437852     |
| train_1/current_q         | -15.42463938362917     |
| train_1/fw_bonus          | -1.0009347915649414    |
| train_1/fw_loss           | 0.0005557909862545785  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.22379380228939      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.028525961004197596  |
| train_1/q_grads_std       | 0.5538435235619545     |
| train_1/q_loss            | 13.599151898747811     |
| train_1/reward            | -1.492497973369609     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.765781664775867    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 502.05. Rollout time: 326.45, Training time: 175.57
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 3351530.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.605431857777873     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.72205635237649      |
| train_0/fw_bonus          | -0.9999340489506722    |
| train_0/fw_loss           | 2.0264393765501153e-05 |
| train_0/mu_grads          | -0.04176385272294283   |
| train_0/mu_grads_std      | 0.3653772309422493     |
| train_0/mu_loss           | 9.64154590214467       |
| train_0/next_q            | -9.634133956019468     |
| train_0/q_grads           | 0.05220245709642768    |
| train_0/q_grads_std       | 0.27693235501646996    |
| train_0/q_loss            | 0.08887952702235061    |
| train_0/reward            | -0.8563348101233714    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.178564453125         |
| train_0/target_q          | -9.876470881838472     |
| train_1/avg_q             | -7.546038722969064     |
| train_1/current_q         | -15.488010889864693    |
| train_1/fw_bonus          | -1.001097133755684     |
| train_1/fw_loss           | 0.0005175706202862785  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.219398722558957     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.02908064443618059   |
| train_1/q_grads_std       | 0.5599077209830284     |
| train_1/q_loss            | 11.409070928438416     |
| train_1/reward            | -1.4852466735930647    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.832819915780572    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 499.14. Rollout time: 325.82, Training time: 173.29
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 3442655.0              |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.845953947165014     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.626519521011883     |
| train_0/fw_bonus          | -0.9999457865953445    |
| train_0/fw_loss           | 1.732369246383314e-05  |
| train_0/mu_grads          | -0.042017255537211896  |
| train_0/mu_grads_std      | 0.36754226982593535    |
| train_0/mu_loss           | 9.549560270912721      |
| train_0/next_q            | -9.541524139592045     |
| train_0/q_grads           | 0.05216062627732754    |
| train_0/q_grads_std       | 0.2762727625668049     |
| train_0/q_loss            | 0.08696170789809264    |
| train_0/reward            | -0.8550130471921875    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2447265625           |
| train_0/target_q          | -9.776967670398028     |
| train_1/avg_q             | -7.666220512688889     |
| train_1/current_q         | -15.428995765949685    |
| train_1/fw_bonus          | -1.0012495279312135    |
| train_1/fw_loss           | 0.00048168501380132513 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.192594058933754     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.029797576554119586  |
| train_1/q_grads_std       | 0.5660313114523887     |
| train_1/q_loss            | 10.230165975035613     |
| train_1/reward            | -1.51020229140413      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.783485982810385    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 500.68. Rollout time: 328.25, Training time: 172.40
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 3533780.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.70550989084738     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.649100032182528    |
| train_0/fw_bonus          | -0.9999463334679604   |
| train_0/fw_loss           | 1.718502276162326e-05 |
| train_0/mu_grads          | -0.04229066399857402  |
| train_0/mu_grads_std      | 0.3700663760304451    |
| train_0/mu_loss           | 9.569866357519583     |
| train_0/next_q            | -9.563051486831407    |
| train_0/q_grads           | 0.05214274022728205   |
| train_0/q_grads_std       | 0.27585379332304      |
| train_0/q_loss            | 0.08657230750026154   |
| train_0/reward            | -0.8556909528721007   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.20087890625         |
| train_0/target_q          | -9.803068716477993    |
| train_1/avg_q             | -7.606725727187095    |
| train_1/current_q         | -15.352875633106581   |
| train_1/fw_bonus          | -1.0015411049127578   |
| train_1/fw_loss           | 0.0004130348635953851 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.401014832029993    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.030244423309341073 |
| train_1/q_grads_std       | 0.5722537189722061    |
| train_1/q_loss            | 8.382219597699986     |
| train_1/reward            | -1.4853782434831373   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000634765625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.689540352858145   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 501.99. Rollout time: 328.29, Training time: 173.66
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 3624905.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.411704019384762    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.639916586650454    |
| train_0/fw_bonus          | -0.999956139922142    |
| train_0/fw_loss           | 1.472979115533235e-05 |
| train_0/mu_grads          | -0.04325693044811487  |
| train_0/mu_grads_std      | 0.3717169903218746    |
| train_0/mu_loss           | 9.560873959815705     |
| train_0/next_q            | -9.5545538706909      |
| train_0/q_grads           | 0.05212066248059273   |
| train_0/q_grads_std       | 0.27590220123529435   |
| train_0/q_loss            | 0.08232655790681283   |
| train_0/reward            | -0.8548438106750836   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2220947265625       |
| train_0/target_q          | -9.792330130383482    |
| train_1/avg_q             | -7.590900344730464    |
| train_1/current_q         | -15.085674982544948   |
| train_1/fw_bonus          | -1.0019796520471573   |
| train_1/fw_loss           | 0.0003097793480264954 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.288691637665547    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.030525236623361707 |
| train_1/q_grads_std       | 0.5760827362537384    |
| train_1/q_loss            | 5.123881737921691     |
| train_1/reward            | -1.515596067640581    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007568359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.482031614515586   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 499.70. Rollout time: 327.06, Training time: 172.60
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 3716030.0              |
| test/episodes             | 1025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.512626559531988     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.637276182286048     |
| train_0/fw_bonus          | -0.9999457925558091    |
| train_0/fw_loss           | 1.7322411304121486e-05 |
| train_0/mu_grads          | -0.043642552010715006  |
| train_0/mu_grads_std      | 0.37175359949469566    |
| train_0/mu_loss           | 9.561322555893426      |
| train_0/next_q            | -9.555119108844405     |
| train_0/q_grads           | 0.05218600099906325    |
| train_0/q_grads_std       | 0.27682444378733634    |
| train_0/q_loss            | 0.08220003575614984    |
| train_0/reward            | -0.8542562153190374    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.191943359375         |
| train_0/target_q          | -9.790461055399263     |
| train_1/avg_q             | -7.6315916026616035    |
| train_1/current_q         | -14.860725378599398    |
| train_1/fw_bonus          | -1.0019130825996398    |
| train_1/fw_loss           | 0.0003254546543757897  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.340755308046813     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.030494924215599895  |
| train_1/q_grads_std       | 0.5796116650104522     |
| train_1/q_loss            | 6.332803813956837      |
| train_1/reward            | -1.4842351010534913    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000341796875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.258809808084749    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 501.99. Rollout time: 327.14, Training time: 174.83
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 3807155.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.785003272336238     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.787451719438343     |
| train_0/fw_bonus          | -0.9999606430530548    |
| train_0/fw_loss           | 1.359922082428966e-05  |
| train_0/mu_grads          | -0.04441914595663547   |
| train_0/mu_grads_std      | 0.3710976779460907     |
| train_0/mu_loss           | 9.710082601125364      |
| train_0/next_q            | -9.70396240227068      |
| train_0/q_grads           | 0.05208408050239086    |
| train_0/q_grads_std       | 0.27773515060544013    |
| train_0/q_loss            | 0.08353727870624442    |
| train_0/reward            | -0.8558847930529737    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2368408203125        |
| train_0/target_q          | -9.943097793025292     |
| train_1/avg_q             | -7.546881263207715     |
| train_1/current_q         | -14.911609660086786    |
| train_1/fw_bonus          | -1.0020178824663162    |
| train_1/fw_loss           | 0.00030078002564550845 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.19730688066675      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.030581532325595618  |
| train_1/q_grads_std       | 0.584099268913269      |
| train_1/q_loss            | 4.745555052069385      |
| train_1/reward            | -1.4775204861041857    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000390625            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.31798679469794     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 500.44. Rollout time: 327.32, Training time: 173.09
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3898280.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.156201958778846     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.577907308673833     |
| train_0/fw_bonus          | -0.9999636679887771    |
| train_0/fw_loss           | 1.2841701084198575e-05 |
| train_0/mu_grads          | -0.044679352827370164  |
| train_0/mu_grads_std      | 0.3715239688754082     |
| train_0/mu_loss           | 9.50139993932639       |
| train_0/next_q            | -9.495482296409028     |
| train_0/q_grads           | 0.0518364860676229     |
| train_0/q_grads_std       | 0.27803431302309034    |
| train_0/q_loss            | 0.0809263132202859     |
| train_0/reward            | -0.8537508304289076    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2605224609375        |
| train_0/target_q          | -9.729587125267688     |
| train_1/avg_q             | -7.699914536428645     |
| train_1/current_q         | -14.739160224026538    |
| train_1/fw_bonus          | -1.0019617646932601    |
| train_1/fw_loss           | 0.0003139898049994372  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.159023036395674     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03088499130681157   |
| train_1/q_grads_std       | 0.5893440648913384     |
| train_1/q_loss            | 5.736918981894692      |
| train_1/reward            | -1.4962162004303536    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.139653700430358    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 500.44. Rollout time: 327.19, Training time: 173.23
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 3989405.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.281032371488045     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.594953216982047     |
| train_0/fw_bonus          | -0.9999722853302956    |
| train_0/fw_loss           | 1.0685093286610936e-05 |
| train_0/mu_grads          | -0.04486874230206013   |
| train_0/mu_grads_std      | 0.3719668246805668     |
| train_0/mu_loss           | 9.518393193769091      |
| train_0/next_q            | -9.512269512227109     |
| train_0/q_grads           | 0.05181630216538906    |
| train_0/q_grads_std       | 0.27877739518880845    |
| train_0/q_loss            | 0.08164972609386922    |
| train_0/reward            | -0.8537755971468869    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3247314453125        |
| train_0/target_q          | -9.746143410197567     |
| train_1/avg_q             | -7.46624991218313      |
| train_1/current_q         | -14.763663928051908    |
| train_1/fw_bonus          | -1.0015916049480438    |
| train_1/fw_loss           | 0.00040114628864103    |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.173180823180566     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03131876951083541   |
| train_1/q_grads_std       | 0.5939710572361946     |
| train_1/q_loss            | 6.500490723858493      |
| train_1/reward            | -1.4965184076398146    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.16644174748357     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 502.50. Rollout time: 328.51, Training time: 173.97
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 4080530.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.6510136744500565   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.795745366756396    |
| train_0/fw_bonus          | -0.9999602615833283   |
| train_0/fw_loss           | 1.369484191400261e-05 |
| train_0/mu_grads          | -0.04507029596716165  |
| train_0/mu_grads_std      | 0.372337157279253     |
| train_0/mu_loss           | 9.716263166035692     |
| train_0/next_q            | -9.710652186941036    |
| train_0/q_grads           | 0.051936497818678616  |
| train_0/q_grads_std       | 0.2799540117383003    |
| train_0/q_loss            | 0.08401342202674553   |
| train_0/reward            | -0.8564765477727633   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.26044921875         |
| train_0/target_q          | -9.95096798202285     |
| train_1/avg_q             | -7.414093335696501    |
| train_1/current_q         | -14.753930890142419   |
| train_1/fw_bonus          | -1.0019383013248444   |
| train_1/fw_loss           | 0.0003195140991010703 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.317675961655475    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.03162838397547603  |
| train_1/q_grads_std       | 0.5970080822706223    |
| train_1/q_loss            | 3.9547494546362985    |
| train_1/reward            | -1.501740595958836    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000341796875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.156160029552591   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 504.82. Rollout time: 329.46, Training time: 175.32
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 45                     |
| policy/steps              | 4171655.0              |
| test/episodes             | 1150.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.665145106108676     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.587872094189759     |
| train_0/fw_bonus          | -0.9999607041478157    |
| train_0/fw_loss           | 1.3584812018052617e-05 |
| train_0/mu_grads          | -0.04541646363213658   |
| train_0/mu_grads_std      | 0.37231611013412474    |
| train_0/mu_loss           | 9.511503911699924      |
| train_0/next_q            | -9.505801585084486     |
| train_0/q_grads           | 0.051867591217160225   |
| train_0/q_grads_std       | 0.2809757776558399     |
| train_0/q_loss            | 0.08247340623477417    |
| train_0/reward            | -0.8538523655588506    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.26123046875          |
| train_0/target_q          | -9.738530208523406     |
| train_1/avg_q             | -7.572449245274544     |
| train_1/current_q         | -14.642608069238202    |
| train_1/fw_bonus          | -1.0020168364048003    |
| train_1/fw_loss           | 0.00030101889205980115 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.25899724186433      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03193323099985719   |
| train_1/q_grads_std       | 0.5999332875013351     |
| train_1/q_loss            | 4.110190024515409      |
| train_1/reward            | -1.5011281238374068    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00029296875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.049604198056164    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 503.99. Rollout time: 326.06, Training time: 177.90
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 4262780.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.257126846373313     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.694529217543472     |
| train_0/fw_bonus          | -0.9999675139784813    |
| train_0/fw_loss           | 1.1880249041951174e-05 |
| train_0/mu_grads          | -0.04553368976339698   |
| train_0/mu_grads_std      | 0.3734233394265175     |
| train_0/mu_loss           | 9.61686196084314       |
| train_0/next_q            | -9.611601432317368     |
| train_0/q_grads           | 0.05189031632617116    |
| train_0/q_grads_std       | 0.2816424533724785     |
| train_0/q_loss            | 0.08437701186388111    |
| train_0/reward            | -0.8549805151895271    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.315576171875         |
| train_0/target_q          | -9.846293015900404     |
| train_1/avg_q             | -7.589288916523063     |
| train_1/current_q         | -14.665783556114286    |
| train_1/fw_bonus          | -1.0019713699817658    |
| train_1/fw_loss           | 0.00031173333336482757 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.27077805880749      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03252008203417063   |
| train_1/q_grads_std       | 0.6013933882117272     |
| train_1/q_loss            | 4.743971934999039      |
| train_1/reward            | -1.5032485350850038    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.05301660149126     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 502.67. Rollout time: 329.16, Training time: 173.48
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 4353905.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.469147880137938     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.626182318742348     |
| train_0/fw_bonus          | -0.9999749317765236    |
| train_0/fw_loss           | 1.0020600632287823e-05 |
| train_0/mu_grads          | -0.046102148666977885  |
| train_0/mu_grads_std      | 0.37378573790192604    |
| train_0/mu_loss           | 9.544766913449907      |
| train_0/next_q            | -9.54012646023288      |
| train_0/q_grads           | 0.05167959872633219    |
| train_0/q_grads_std       | 0.2827530801296234     |
| train_0/q_loss            | 0.0832490871934578     |
| train_0/reward            | -0.8554011215775972    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.313330078125         |
| train_0/target_q          | -9.779629550060331     |
| train_1/avg_q             | -7.42914999875128      |
| train_1/current_q         | -15.012927779157755    |
| train_1/fw_bonus          | -1.0020666927099229    |
| train_1/fw_loss           | 0.0002892857395636383  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.210082435846125     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.032719618640840054  |
| train_1/q_grads_std       | 0.6031173437833786     |
| train_1/q_loss            | 4.766441827436683      |
| train_1/reward            | -1.4998654493960202    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000390625            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.399117402521028    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 499.26. Rollout time: 326.12, Training time: 173.11
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 48                    |
| policy/steps              | 4445030.0             |
| test/episodes             | 1225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.668975856768986    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.79800395941957     |
| train_0/fw_bonus          | -0.9999429568648338   |
| train_0/fw_loss           | 1.802896713343216e-05 |
| train_0/mu_grads          | -0.04673631442710757  |
| train_0/mu_grads_std      | 0.3750837713479996    |
| train_0/mu_loss           | 9.722620466268543     |
| train_0/next_q            | -9.716179743401366    |
| train_0/q_grads           | 0.050579299498349425  |
| train_0/q_grads_std       | 0.28244071900844575   |
| train_0/q_loss            | 0.08950782612676163   |
| train_0/reward            | -0.8569335435066023   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2965087890625       |
| train_0/target_q          | -9.952954434954032    |
| train_1/avg_q             | -7.906201427887305    |
| train_1/current_q         | -14.946926660665046   |
| train_1/fw_bonus          | -1.0012965887784957   |
| train_1/fw_loss           | 0.0004706074389105197 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.10709143075681     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.033473325055092575 |
| train_1/q_grads_std       | 0.6054023504257202    |
| train_1/q_loss            | 5.558775712033722     |
| train_1/reward            | -1.5210713173059047   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0005859375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.318901883712162   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 498.82. Rollout time: 324.42, Training time: 174.37
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 4536155.0              |
| test/episodes             | 1250.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5946969165478855    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.68029212750439      |
| train_0/fw_bonus          | -0.999947464466095     |
| train_0/fw_loss           | 1.6901482445064177e-05 |
| train_0/mu_grads          | -0.045846810564398766  |
| train_0/mu_grads_std      | 0.3770293235778809     |
| train_0/mu_loss           | 9.602822887889687      |
| train_0/next_q            | -9.596406946241373     |
| train_0/q_grads           | 0.050084329955279824   |
| train_0/q_grads_std       | 0.28398067206144334    |
| train_0/q_loss            | 0.08680758214961753    |
| train_0/reward            | -0.8555209031343111    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2697509765625        |
| train_0/target_q          | -9.834959689012667     |
| train_1/avg_q             | -7.888347615955046     |
| train_1/current_q         | -15.132665798523544    |
| train_1/fw_bonus          | -1.0013770759105682    |
| train_1/fw_loss           | 0.00045165298361098393 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.137809495140807     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03399477656930685   |
| train_1/q_grads_std       | 0.60769182741642       |
| train_1/q_loss            | 5.69600044173656       |
| train_1/reward            | -1.524946392151469     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.517221782776474    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 501.51. Rollout time: 327.40, Training time: 174.08
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 50                     |
| policy/steps              | 4627280.0              |
| test/episodes             | 1275.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.434304474130225     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.622039009272209     |
| train_0/fw_bonus          | -0.9999473288655281    |
| train_0/fw_loss           | 1.6937146938289516e-05 |
| train_0/mu_grads          | -0.04567133896052837   |
| train_0/mu_grads_std      | 0.3797622472047806     |
| train_0/mu_loss           | 9.544342674120799      |
| train_0/next_q            | -9.536773654427272     |
| train_0/q_grads           | 0.05032720873132348    |
| train_0/q_grads_std       | 0.2859916232526302     |
| train_0/q_loss            | 0.08425814459589293    |
| train_0/reward            | -0.855020308138046     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.275830078125         |
| train_0/target_q          | -9.774869877450575     |
| train_1/avg_q             | -7.633651319961877     |
| train_1/current_q         | -15.302435214780346    |
| train_1/fw_bonus          | -1.0017039835453034    |
| train_1/fw_loss           | 0.0003746854032215197  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.236891241858526     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.034003210999071595  |
| train_1/q_grads_std       | 0.6103072598576545     |
| train_1/q_loss            | 4.519088459487682      |
| train_1/reward            | -1.4967613872882795    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.654411777913285    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 499.90. Rollout time: 326.64, Training time: 173.23
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 4718405.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.018280489381948    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.76066284162793     |
| train_0/fw_bonus          | -0.999955540895462    |
| train_0/fw_loss           | 1.488007980015027e-05 |
| train_0/mu_grads          | -0.047239338234066966 |
| train_0/mu_grads_std      | 0.38168583139777185   |
| train_0/mu_loss           | 9.684683772859245     |
| train_0/next_q            | -9.677274647167117    |
| train_0/q_grads           | 0.050257498025894166  |
| train_0/q_grads_std       | 0.2884434796869755    |
| train_0/q_loss            | 0.086021935067809     |
| train_0/reward            | -0.8560457532439614   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.269580078125        |
| train_0/target_q          | -9.91605369370551     |
| train_1/avg_q             | -7.735801954455481    |
| train_1/current_q         | -15.236148750764235   |
| train_1/fw_bonus          | -1.0016772001981735   |
| train_1/fw_loss           | 0.0003809891881246585 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.193633800475254    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.034345594607293604 |
| train_1/q_grads_std       | 0.6136815384030342    |
| train_1/q_loss            | 4.443738003747124     |
| train_1/reward            | -1.4998724108416355   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0002685546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.570313328810391   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 501.22. Rollout time: 327.85, Training time: 173.34
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 4809530.0              |
| test/episodes             | 1325.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.847616647848494     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.780225541207328     |
| train_0/fw_bonus          | -0.9999622523784637    |
| train_0/fw_loss           | 1.3198625720178824e-05 |
| train_0/mu_grads          | -0.047412451542913917  |
| train_0/mu_grads_std      | 0.38339555114507673    |
| train_0/mu_loss           | 9.703587536967074      |
| train_0/next_q            | -9.695751892058492     |
| train_0/q_grads           | 0.0503094038926065     |
| train_0/q_grads_std       | 0.2911762945353985     |
| train_0/q_loss            | 0.08464402510294523    |
| train_0/reward            | -0.8559653380521922    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2638916015625        |
| train_0/target_q          | -9.934266890649711     |
| train_1/avg_q             | -7.44717467374555      |
| train_1/current_q         | -15.109103179120794    |
| train_1/fw_bonus          | -1.0017850935459136    |
| train_1/fw_loss           | 0.00035558793679228983 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.21946461101395      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.034942696802318096  |
| train_1/q_grads_std       | 0.6169878751039505     |
| train_1/q_loss            | 4.802312227778184      |
| train_1/reward            | -1.4809286658317433    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000439453125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.438966263487998    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 503.27. Rollout time: 329.83, Training time: 173.41
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 4900655.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.494822171287788     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.736157890444975     |
| train_0/fw_bonus          | -0.9999689385294914    |
| train_0/fw_loss           | 1.1521065221131722e-05 |
| train_0/mu_grads          | -0.048169320356100796  |
| train_0/mu_grads_std      | 0.3848081402480602     |
| train_0/mu_loss           | 9.661053172299301      |
| train_0/next_q            | -9.65401823717131      |
| train_0/q_grads           | 0.050365581270307304   |
| train_0/q_grads_std       | 0.2935107558965683     |
| train_0/q_loss            | 0.08325745301842921    |
| train_0/reward            | -0.8553111802742933    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.322412109375         |
| train_0/target_q          | -9.890385162810816     |
| train_1/avg_q             | -7.422063703964997     |
| train_1/current_q         | -14.923904681121204    |
| train_1/fw_bonus          | -1.001802644133568     |
| train_1/fw_loss           | 0.0003514571668347344  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.263372501317626     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03531867414712906   |
| train_1/q_grads_std       | 0.6190306097269058     |
| train_1/q_loss            | 3.378060970707814      |
| train_1/reward            | -1.487393240191159     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004150390625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.238712087847414    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 502.50. Rollout time: 328.52, Training time: 173.95
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 4991780.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.649767002798967     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.601451395449548     |
| train_0/fw_bonus          | -0.9999714434146881    |
| train_0/fw_loss           | 1.0894184720200429e-05 |
| train_0/mu_grads          | -0.048764676041901114  |
| train_0/mu_grads_std      | 0.3847681857645512     |
| train_0/mu_loss           | 9.525688479343327      |
| train_0/next_q            | -9.519938799953485     |
| train_0/q_grads           | 0.05012148832902312    |
| train_0/q_grads_std       | 0.29457160010933875    |
| train_0/q_loss            | 0.08553521372372744    |
| train_0/reward            | -0.854238838305173     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.319287109375         |
| train_0/target_q          | -9.754013602015666     |
| train_1/avg_q             | -7.583624323608043     |
| train_1/current_q         | -14.685570326098674    |
| train_1/fw_bonus          | -1.0018649041652679    |
| train_1/fw_loss           | 0.0003367974124557804  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.115291844917277     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.035640855226665734  |
| train_1/q_grads_std       | 0.62066979855299       |
| train_1/q_loss            | 4.450914822182142      |
| train_1/reward            | -1.479474849073449     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.015676997510957    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 501.21. Rollout time: 326.48, Training time: 174.71
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 5082905.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.075538365932065     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.668104954994622     |
| train_0/fw_bonus          | -0.999969208240509     |
| train_0/fw_loss           | 1.1454665218479931e-05 |
| train_0/mu_grads          | -0.048112363554537296  |
| train_0/mu_grads_std      | 0.38649356216192243    |
| train_0/mu_loss           | 9.593703999726916      |
| train_0/next_q            | -9.58728666509702      |
| train_0/q_grads           | 0.04945343676954508    |
| train_0/q_grads_std       | 0.295578645914793      |
| train_0/q_loss            | 0.08747548430102887    |
| train_0/reward            | -0.8546766138533712    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3033203125           |
| train_0/target_q          | -9.82104135671357      |
| train_1/avg_q             | -7.594122768884577     |
| train_1/current_q         | -14.742715551080853    |
| train_1/fw_bonus          | -1.0015403091907502    |
| train_1/fw_loss           | 0.00041322171236970464 |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.143567978016968     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.036570318043231964  |
| train_1/q_grads_std       | 0.6232605606317521     |
| train_1/q_loss            | 6.385337880859176      |
| train_1/reward            | -1.4850602655380498    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.027722374913054    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 499.04. Rollout time: 325.10, Training time: 173.91
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 5174030.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.712000629549184    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.67245142552195     |
| train_0/fw_bonus          | -0.999956738948822    |
| train_0/fw_loss           | 1.457690843835735e-05 |
| train_0/mu_grads          | -0.04796275831758976  |
| train_0/mu_grads_std      | 0.388021819293499     |
| train_0/mu_loss           | 9.596683308734535     |
| train_0/next_q            | -9.58990294501047     |
| train_0/q_grads           | 0.049032912403345105  |
| train_0/q_grads_std       | 0.29419401064515116   |
| train_0/q_loss            | 0.08824275426539166   |
| train_0/reward            | -0.8551189267644077   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.277587890625        |
| train_0/target_q          | -9.825243410612158    |
| train_1/avg_q             | -7.484858138362624    |
| train_1/current_q         | -15.219179673456471   |
| train_1/fw_bonus          | -1.0008708149194718   |
| train_1/fw_loss           | 0.0005708523785870057 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.14112656229468     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.037515873089432716 |
| train_1/q_grads_std       | 0.6259071558713913    |
| train_1/q_loss            | 6.461616882752599     |
| train_1/reward            | -1.490887497231597    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000390625           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.476702926919103   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 498.78. Rollout time: 324.67, Training time: 174.08
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 5264934.0              |
| test/episodes             | 1450.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.6878066613985325    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.597805860967384     |
| train_0/fw_bonus          | -0.9999370202422142    |
| train_0/fw_loss           | 1.9521844001246792e-05 |
| train_0/mu_grads          | -0.047079721745103595  |
| train_0/mu_grads_std      | 0.39097354784607885    |
| train_0/mu_loss           | 9.519103266111074      |
| train_0/next_q            | -9.511455067277575     |
| train_0/q_grads           | 0.04836169946938753    |
| train_0/q_grads_std       | 0.29379293248057364    |
| train_0/q_loss            | 0.08835214562056797    |
| train_0/reward            | -0.8551468476842274    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2265869140625        |
| train_0/target_q          | -9.748599729337034     |
| train_1/avg_q             | -7.443682469479398     |
| train_1/current_q         | -15.256746773654257    |
| train_1/fw_bonus          | -1.000235639512539     |
| train_1/fw_loss           | 0.0007204083201941102  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.12816195728359      |
| train_1/n_subgoals        | 2692.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03795197131112218   |
| train_1/q_grads_std       | 0.6302763506770134     |
| train_1/q_loss            | 7.903043869567472      |
| train_1/reward            | -1.501659883800312     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006103515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.509439180675319    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 521.74. Rollout time: 339.13, Training time: 182.58
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 5356059.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.4722416185866445    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.767315869917528     |
| train_0/fw_bonus          | -0.9999242663383484    |
| train_0/fw_loss           | 2.2712695704285578e-05 |
| train_0/mu_grads          | -0.04735552752390504   |
| train_0/mu_grads_std      | 0.39362914860248566    |
| train_0/mu_loss           | 9.682642167885481      |
| train_0/next_q            | -9.675580694772856     |
| train_0/q_grads           | 0.04865951705724001    |
| train_0/q_grads_std       | 0.2936972536146641     |
| train_0/q_loss            | 0.0911293125925799     |
| train_0/reward            | -0.8578777739836368    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1845947265625        |
| train_0/target_q          | -9.92117954506469      |
| train_1/avg_q             | -8.566675367167806     |
| train_1/current_q         | -15.861570779529       |
| train_1/fw_bonus          | -1.0001141279935837    |
| train_1/fw_loss           | 0.0007490206946386025  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.122465335895974     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.03890062384307384   |
| train_1/q_grads_std       | 0.6326909363269806     |
| train_1/q_loss            | 9.988177658348494      |
| train_1/reward            | -1.504034563440655     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00087890625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.139076067346913    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 533.81. Rollout time: 344.10, Training time: 189.68
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 5447184.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -4.65486274731557      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.797486632737622     |
| train_0/fw_bonus          | -0.9999229878187179    |
| train_0/fw_loss           | 2.3032331932881787e-05 |
| train_0/mu_grads          | -0.04766523102298379   |
| train_0/mu_grads_std      | 0.39545624926686285    |
| train_0/mu_loss           | 9.712264181104885      |
| train_0/next_q            | -9.703267365808221     |
| train_0/q_grads           | 0.048706975486129525   |
| train_0/q_grads_std       | 0.29416815340518954    |
| train_0/q_loss            | 0.09160866355450023    |
| train_0/reward            | -0.8587618267600192    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1830810546875        |
| train_0/target_q          | -9.95094684767462      |
| train_1/avg_q             | -7.8299830184359305    |
| train_1/current_q         | -16.159743436419426    |
| train_1/fw_bonus          | -0.9994364231824875    |
| train_1/fw_loss           | 0.0009085835758014582  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.06941400402395      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.039887172915041444  |
| train_1/q_grads_std       | 0.6342871740460396     |
| train_1/q_loss            | 12.529882181678088     |
| train_1/reward            | -1.5126693609388895    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.417737232032646    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 528.14. Rollout time: 342.16, Training time: 185.95
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 5538309.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.537784375481179     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.721028720437005     |
| train_0/fw_bonus          | -0.9999205380678177    |
| train_0/fw_loss           | 2.3647967668694037e-05 |
| train_0/mu_grads          | -0.048733233101665975  |
| train_0/mu_grads_std      | 0.39873997047543525    |
| train_0/mu_loss           | 9.63946628043899       |
| train_0/next_q            | -9.630774943390872     |
| train_0/q_grads           | 0.04868688359856606    |
| train_0/q_grads_std       | 0.2956292860209942     |
| train_0/q_loss            | 0.08897199233101583    |
| train_0/reward            | -0.8573683820883161    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1961669921875        |
| train_0/target_q          | -9.875431873619444     |
| train_1/avg_q             | -6.752919796501061     |
| train_1/current_q         | -16.07256510415008     |
| train_1/fw_bonus          | -0.9992919996380806    |
| train_1/fw_loss           | 0.0009425871830899268  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.091128368340094     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04027728782966733   |
| train_1/q_grads_std       | 0.6365846708416939     |
| train_1/q_loss            | 13.173974016645966     |
| train_1/reward            | -1.493487558295601     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.350751718451857    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 528.08. Rollout time: 337.77, Training time: 190.29
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 61                     |
| policy/steps              | 5629434.0              |
| test/episodes             | 1550.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.309326570083338     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.764620339217734     |
| train_0/fw_bonus          | -0.999939177930355     |
| train_0/fw_loss           | 1.8979499463966933e-05 |
| train_0/mu_grads          | -0.04948132513090968   |
| train_0/mu_grads_std      | 0.4017395913600922     |
| train_0/mu_loss           | 9.682371472286144      |
| train_0/next_q            | -9.672776644006003     |
| train_0/q_grads           | 0.04856060380116105    |
| train_0/q_grads_std       | 0.29833274856209757    |
| train_0/q_loss            | 0.08767756439967125    |
| train_0/reward            | -0.858029330719728     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2055908203125        |
| train_0/target_q          | -9.918442755854183     |
| train_1/avg_q             | -7.349534830209005     |
| train_1/current_q         | -15.824755942572793    |
| train_1/fw_bonus          | -0.9992298439145089    |
| train_1/fw_loss           | 0.0009572228867909871  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.140044046981934     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04070016602054238   |
| train_1/q_grads_std       | 0.6393086433410644     |
| train_1/q_loss            | 13.25621083995921      |
| train_1/reward            | -1.4841574907797621    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009521484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.09142116265477     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 515.32. Rollout time: 334.54, Training time: 180.74
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 5719893.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -8.499335525276598    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.642004366361329    |
| train_0/fw_bonus          | -0.9999407887458801   |
| train_0/fw_loss           | 1.857699971878901e-05 |
| train_0/mu_grads          | -0.04960836442187429  |
| train_0/mu_grads_std      | 0.4041154131293297    |
| train_0/mu_loss           | 9.560316026008618     |
| train_0/next_q            | -9.550781256554988    |
| train_0/q_grads           | 0.04833173509687185   |
| train_0/q_grads_std       | 0.30097355768084527   |
| train_0/q_loss            | 0.0868532981796706    |
| train_0/reward            | -0.8567365901719313   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2000732421875       |
| train_0/target_q          | -9.793575243570837    |
| train_1/avg_q             | -7.652729593871217    |
| train_1/current_q         | -16.046083485814094   |
| train_1/fw_bonus          | -0.9989036858081818   |
| train_1/fw_loss           | 0.0010340135951992125 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.16575737994532     |
| train_1/n_subgoals        | 2676.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04101995611563325  |
| train_1/q_grads_std       | 0.6423821598291397    |
| train_1/q_loss            | 12.416484595220698    |
| train_1/reward            | -1.4972368590635596   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010009765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -16.32866117546982    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 562.34. Rollout time: 361.77, Training time: 200.55
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 5810918.0              |
| test/episodes             | 1600.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.521689646633647     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.651135378354553     |
| train_0/fw_bonus          | -0.999943695962429     |
| train_0/fw_loss           | 1.7847610865828756e-05 |
| train_0/mu_grads          | -0.05007050782442093   |
| train_0/mu_grads_std      | 0.4056902289390564     |
| train_0/mu_loss           | 9.573545912108012      |
| train_0/next_q            | -9.565191855672321     |
| train_0/q_grads           | 0.0480556127615273     |
| train_0/q_grads_std       | 0.30200154781341554    |
| train_0/q_loss            | 0.08618995216821039    |
| train_0/reward            | -0.855615727060649     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2017822265625        |
| train_0/target_q          | -9.803326702788848     |
| train_1/avg_q             | -8.067017988012966     |
| train_1/current_q         | -15.645766981122005    |
| train_1/fw_bonus          | -0.9989870548248291    |
| train_1/fw_loss           | 0.001014387201576028   |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.218537554756928     |
| train_1/n_subgoals        | 2697.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.041293886862695216  |
| train_1/q_grads_std       | 0.6454978197813034     |
| train_1/q_loss            | 11.880309674078932     |
| train_1/reward            | -1.4920381462550723    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.906148986098827    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 528.17. Rollout time: 346.92, Training time: 181.23
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 5902043.0             |
| test/episodes             | 1625.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.460557567146281    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.635807556935514    |
| train_0/fw_bonus          | -0.999931126832962    |
| train_0/fw_loss           | 2.099747885040415e-05 |
| train_0/mu_grads          | -0.050131027866154906 |
| train_0/mu_grads_std      | 0.4074074387550354    |
| train_0/mu_loss           | 9.559423824630823     |
| train_0/next_q            | -9.552748940724406    |
| train_0/q_grads           | 0.04802173525094986   |
| train_0/q_grads_std       | 0.30319376662373543   |
| train_0/q_loss            | 0.08609255232265807   |
| train_0/reward            | -0.854886082385201    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.15009765625         |
| train_0/target_q          | -9.787223651733902    |
| train_1/avg_q             | -7.744837658510889    |
| train_1/current_q         | -15.58167883092059    |
| train_1/fw_bonus          | -0.9999591588974      |
| train_1/fw_loss           | 0.0007855031115468591 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.157495915988683    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04124989323318005  |
| train_1/q_grads_std       | 0.6488554656505585    |
| train_1/q_loss            | 10.383025518905486    |
| train_1/reward            | -1.4964476485867635   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.846604875149268   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 566.63. Rollout time: 366.94, Training time: 199.66
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 65                     |
| policy/steps              | 5993168.0              |
| test/episodes             | 1650.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.853209296527448     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.65349518678798      |
| train_0/fw_bonus          | -0.9999512434005737    |
| train_0/fw_loss           | 1.5953262027323946e-05 |
| train_0/mu_grads          | -0.050178746692836285  |
| train_0/mu_grads_std      | 0.408455740660429      |
| train_0/mu_loss           | 9.578350380376651      |
| train_0/next_q            | -9.570950229568961     |
| train_0/q_grads           | 0.04779136758297682    |
| train_0/q_grads_std       | 0.3038991570472717     |
| train_0/q_loss            | 0.08507792248161025    |
| train_0/reward            | -0.8550354607636109    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2731689453125        |
| train_0/target_q          | -9.806417497679847     |
| train_1/avg_q             | -7.519616223751195     |
| train_1/current_q         | -15.577616910971017    |
| train_1/fw_bonus          | -1.00064876973629      |
| train_1/fw_loss           | 0.0006231334831682034  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.30765723193241      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.041623192839324474  |
| train_1/q_grads_std       | 0.6520036205649375     |
| train_1/q_loss            | 8.382992534945668      |
| train_1/reward            | -1.481583998730639     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.860811049511895    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 546.60. Rollout time: 355.78, Training time: 190.79
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 6084293.0              |
| test/episodes             | 1675.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.124589119037011     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.623388630472448     |
| train_0/fw_bonus          | -0.9999585524201393    |
| train_0/fw_loss           | 1.4127289432508405e-05 |
| train_0/mu_grads          | -0.049649060331285     |
| train_0/mu_grads_std      | 0.4093277841806412     |
| train_0/mu_loss           | 9.547067094748558      |
| train_0/next_q            | -9.537960793582663     |
| train_0/q_grads           | 0.04762512417510152    |
| train_0/q_grads_std       | 0.3044404797255993     |
| train_0/q_loss            | 0.08693529644773947    |
| train_0/reward            | -0.8555658294149907    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2714599609375        |
| train_0/target_q          | -9.775020103237187     |
| train_1/avg_q             | -7.405964926268655     |
| train_1/current_q         | -15.575194678377335    |
| train_1/fw_bonus          | -1.0012289375066756    |
| train_1/fw_loss           | 0.0004865377726673614  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.11529757489866      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04176321774721146   |
| train_1/q_grads_std       | 0.6572501167654992     |
| train_1/q_loss            | 5.607071141542822      |
| train_1/reward            | -1.497711247553525     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.880814274897281    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 599.57. Rollout time: 381.80, Training time: 217.74
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 6175418.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -5.217934555387551     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.72930991287063      |
| train_0/fw_bonus          | -0.9999274179339409    |
| train_0/fw_loss           | 2.1924708346432453e-05 |
| train_0/mu_grads          | -0.04955560937523842   |
| train_0/mu_grads_std      | 0.4090212881565094     |
| train_0/mu_loss           | 9.65374773420207       |
| train_0/next_q            | -9.645556193407407     |
| train_0/q_grads           | 0.04772512521594763    |
| train_0/q_grads_std       | 0.30537411496043204    |
| train_0/q_loss            | 0.08606798587843348    |
| train_0/reward            | -0.8558171444936307    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1298583984375        |
| train_0/target_q          | -9.883200829862854     |
| train_1/avg_q             | -7.419722274569735     |
| train_1/current_q         | -15.214194529160693    |
| train_1/fw_bonus          | -1.0012511223554612    |
| train_1/fw_loss           | 0.0004813102634216193  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.215270414894533     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.042568250093609095  |
| train_1/q_grads_std       | 0.6641615822911262     |
| train_1/q_loss            | 5.962880851322106      |
| train_1/reward            | -1.4965438167680987    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.510137078486855    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 582.96. Rollout time: 375.67, Training time: 207.25
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 6266543.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.344068653036473     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.661286512839723     |
| train_0/fw_bonus          | -0.9999644994735718    |
| train_0/fw_loss           | 1.2633448579890683e-05 |
| train_0/mu_grads          | -0.04976138724014163   |
| train_0/mu_grads_std      | 0.41021632254123686    |
| train_0/mu_loss           | 9.585757333563901      |
| train_0/next_q            | -9.578379418812387     |
| train_0/q_grads           | 0.04735080040991306    |
| train_0/q_grads_std       | 0.30738307610154153    |
| train_0/q_loss            | 0.08413865386455624    |
| train_0/reward            | -0.8551674692775123    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3121337890625        |
| train_0/target_q          | -9.815058640079636     |
| train_1/avg_q             | -6.88449854519023      |
| train_1/current_q         | -15.129717153019318    |
| train_1/fw_bonus          | -1.000959140062332     |
| train_1/fw_loss           | 0.0005500585626577959  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.179310347034004     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04306665044277906   |
| train_1/q_grads_std       | 0.6680388778448105     |
| train_1/q_loss            | 8.306611339324027      |
| train_1/reward            | -1.5028861066573882    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000537109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.391156126188644    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 619.96. Rollout time: 401.75, Training time: 218.17
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 6357668.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.173505074571269     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.602912807548973     |
| train_0/fw_bonus          | -0.9999635457992554    |
| train_0/fw_loss           | 1.2872840898126015e-05 |
| train_0/mu_grads          | -0.049869004357606175  |
| train_0/mu_grads_std      | 0.41090800166130065    |
| train_0/mu_loss           | 9.525167624761014      |
| train_0/next_q            | -9.51704774684428      |
| train_0/q_grads           | 0.047149240784347055   |
| train_0/q_grads_std       | 0.3095829106867313     |
| train_0/q_loss            | 0.08412905447074664    |
| train_0/reward            | -0.8550385789363645    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.26171875             |
| train_0/target_q          | -9.754575642697958     |
| train_1/avg_q             | -7.64055349619405      |
| train_1/current_q         | -15.178348019202293    |
| train_1/fw_bonus          | -1.0004509389400482    |
| train_1/fw_loss           | 0.0006697162039927207  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.216419845323735     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04378035785630345   |
| train_1/q_grads_std       | 0.6709615543484688     |
| train_1/q_loss            | 9.14516671629293       |
| train_1/reward            | -1.484829168888973     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.438344793888978    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 578.37. Rollout time: 376.46, Training time: 201.87
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 6448793.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.360785991327141     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.627184495392743     |
| train_0/fw_bonus          | -0.9999472081661225    |
| train_0/fw_loss           | 1.6969328987670453e-05 |
| train_0/mu_grads          | -0.050303293764591216  |
| train_0/mu_grads_std      | 0.41136882081627846    |
| train_0/mu_loss           | 9.550894004213339      |
| train_0/next_q            | -9.543090228258421     |
| train_0/q_grads           | 0.04722455954179168    |
| train_0/q_grads_std       | 0.3124361149966717     |
| train_0/q_loss            | 0.08578475027134604    |
| train_0/reward            | -0.8550568328122609    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2312744140625        |
| train_0/target_q          | -9.778909269169015     |
| train_1/avg_q             | -7.435296629537508     |
| train_1/current_q         | -15.275050632819813    |
| train_1/fw_bonus          | -0.9996754541993141    |
| train_1/fw_loss           | 0.0008523046504706145  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.207389676090862     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04397285468876362   |
| train_1/q_grads_std       | 0.6752063661813736     |
| train_1/q_loss            | 10.245759888406152     |
| train_1/reward            | -1.4764106412971159    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009033203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.524887692078371    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 670.22. Rollout time: 423.40, Training time: 246.77
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 6539918.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.540510794333386     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.61223185796961      |
| train_0/fw_bonus          | -0.9999661922454834    |
| train_0/fw_loss           | 1.2207956501697481e-05 |
| train_0/mu_grads          | -0.05088682975620031   |
| train_0/mu_grads_std      | 0.41285210102796555    |
| train_0/mu_loss           | 9.5339135714793        |
| train_0/next_q            | -9.526398921308669     |
| train_0/q_grads           | 0.04739406201988459    |
| train_0/q_grads_std       | 0.31530453115701673    |
| train_0/q_loss            | 0.0838251468852494     |
| train_0/reward            | -0.8551809502212564    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.266162109375         |
| train_0/target_q          | -9.764629473907187     |
| train_1/avg_q             | -7.454026360602225     |
| train_1/current_q         | -15.291370756206305    |
| train_1/fw_bonus          | -0.9988577038049697    |
| train_1/fw_loss           | 0.0010448421904584392  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.256640993317482     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04404991390183568   |
| train_1/q_grads_std       | 0.6786705628037453     |
| train_1/q_loss            | 9.922581046538383      |
| train_1/reward            | -1.4908730190683854    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.54774801906839     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 579.16. Rollout time: 373.52, Training time: 205.61
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 6631043.0             |
| test/episodes             | 1825.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.408194429011386    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.658884793330788    |
| train_0/fw_bonus          | -0.999978132545948    |
| train_0/fw_loss           | 9.217058777721832e-06 |
| train_0/mu_grads          | -0.05053782546892762  |
| train_0/mu_grads_std      | 0.41425793096423147   |
| train_0/mu_loss           | 9.583995434432994     |
| train_0/next_q            | -9.578340556874421    |
| train_0/q_grads           | 0.046994758490473035  |
| train_0/q_grads_std       | 0.31657554060220716   |
| train_0/q_loss            | 0.08378925606521007   |
| train_0/reward            | -0.8542560661604511   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3319091796875       |
| train_0/target_q          | -9.812869053061913    |
| train_1/avg_q             | -7.548595902734082    |
| train_1/current_q         | -15.170317658749843   |
| train_1/fw_bonus          | -0.9989134013652802   |
| train_1/fw_loss           | 0.0010317269610823133 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.23110335384747     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04383812714368105  |
| train_1/q_grads_std       | 0.6816713765263558    |
| train_1/q_loss            | 8.673756805557197     |
| train_1/reward            | -1.486733887945593    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.41505566528935    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 598.54. Rollout time: 390.56, Training time: 207.95
Evaluating epoch 73
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 73                     |
| policy/steps              | 6722168.0              |
| test/episodes             | 1850.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.371851298407941     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.669862764959793     |
| train_0/fw_bonus          | -0.9999637499451637    |
| train_0/fw_loss           | 1.2824785585507925e-05 |
| train_0/mu_grads          | -0.05067975213751197   |
| train_0/mu_grads_std      | 0.4153924100100994     |
| train_0/mu_loss           | 9.595849137323166      |
| train_0/next_q            | -9.58919267210066      |
| train_0/q_grads           | 0.04653322771191597    |
| train_0/q_grads_std       | 0.31817492470145226    |
| train_0/q_loss            | 0.08260861234071966    |
| train_0/reward            | -0.8542452657944523    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2417724609375        |
| train_0/target_q          | -9.821592313733694     |
| train_1/avg_q             | -7.460390862337304     |
| train_1/current_q         | -14.886683218607729    |
| train_1/fw_bonus          | -0.9987810254096985    |
| train_1/fw_loss           | 0.001062897748488467   |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.219587006241667     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.044182881619781254  |
| train_1/q_grads_std       | 0.6855054497718811     |
| train_1/q_loss            | 8.250839823471807      |
| train_1/reward            | -1.5081067650738986    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.127642409605155    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 566.56. Rollout time: 364.77, Training time: 201.76
Evaluating epoch 74
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 74                     |
| policy/steps              | 6813293.0              |
| test/episodes             | 1875.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.414211598411165     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.731622787395015     |
| train_0/fw_bonus          | -0.9999602511525154    |
| train_0/fw_loss           | 1.3696599728518776e-05 |
| train_0/mu_grads          | -0.0508758126758039    |
| train_0/mu_grads_std      | 0.41570296213030816    |
| train_0/mu_loss           | 9.65568699975166       |
| train_0/next_q            | -9.650583591307575     |
| train_0/q_grads           | 0.04605771526694298    |
| train_0/q_grads_std       | 0.31981957629323005    |
| train_0/q_loss            | 0.08346903685770139    |
| train_0/reward            | -0.8551581831721705    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.28291015625          |
| train_0/target_q          | -9.88560800853287      |
| train_1/avg_q             | -7.535681748887477     |
| train_1/current_q         | -14.918787224379471    |
| train_1/fw_bonus          | -0.9989775434136391    |
| train_1/fw_loss           | 0.0010166284788283519  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.24353492173005      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04423236446455121   |
| train_1/q_grads_std       | 0.6898771449923515     |
| train_1/q_loss            | 6.874753310122418      |
| train_1/reward            | -1.4899130856196279    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.156606444994633    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 636.42. Rollout time: 416.33, Training time: 220.05
Evaluating epoch 75
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 75                     |
| policy/steps              | 6904418.0              |
| test/episodes             | 1900.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -9.094565934320189     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.700596628109219     |
| train_0/fw_bonus          | -0.9999629512429238    |
| train_0/fw_loss           | 1.3021626534737151e-05 |
| train_0/mu_grads          | -0.05073967119678855   |
| train_0/mu_grads_std      | 0.4159932225942612     |
| train_0/mu_loss           | 9.623380898578194      |
| train_0/next_q            | -9.616851133934187     |
| train_0/q_grads           | 0.04567660177126527    |
| train_0/q_grads_std       | 0.3211999237537384     |
| train_0/q_loss            | 0.08430617801821035    |
| train_0/reward            | -0.8554043444702983    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.276953125            |
| train_0/target_q          | -9.85359273265255      |
| train_1/avg_q             | -8.011850374764112     |
| train_1/current_q         | -14.900296142900796    |
| train_1/fw_bonus          | -0.9991625219583511    |
| train_1/fw_loss           | 0.0009730749108712189  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.096245060677546     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04462042851373553   |
| train_1/q_grads_std       | 0.6937355294823646     |
| train_1/q_loss            | 10.640146008719096     |
| train_1/reward            | -1.5106084613827988    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.155337953570305    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 591.79. Rollout time: 385.17, Training time: 206.59
Evaluating epoch 76
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 76                     |
| policy/steps              | 6995543.0              |
| test/episodes             | 1925.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.20379704519602      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.66367613713463      |
| train_0/fw_bonus          | -0.9999451100826263    |
| train_0/fw_loss           | 1.7493299446869058e-05 |
| train_0/mu_grads          | -0.05048849880695343   |
| train_0/mu_grads_std      | 0.4173052549362183     |
| train_0/mu_loss           | 9.585371679563988      |
| train_0/next_q            | -9.577941097438577     |
| train_0/q_grads           | 0.04581683548167348    |
| train_0/q_grads_std       | 0.3226589858531952     |
| train_0/q_loss            | 0.08539435351176654    |
| train_0/reward            | -0.8553299226012314    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2221435546875        |
| train_0/target_q          | -9.815678016607237     |
| train_1/avg_q             | -7.753564092080104     |
| train_1/current_q         | -15.071236258934244    |
| train_1/fw_bonus          | -0.998945665359497     |
| train_1/fw_loss           | 0.0010241329582640901  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.809361910072763     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04530574325472116   |
| train_1/q_grads_std       | 0.6972961038351059     |
| train_1/q_loss            | 6.8020851232953365     |
| train_1/reward            | -1.4890713105662143    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.31338771681622     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 549.83. Rollout time: 359.37, Training time: 190.43
Evaluating epoch 77
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 77                     |
| policy/steps              | 7086668.0              |
| test/episodes             | 1950.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.879609857176563     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.595390617497682     |
| train_0/fw_bonus          | -0.9999485179781914    |
| train_0/fw_loss           | 1.6637537032693218e-05 |
| train_0/mu_grads          | -0.05048932516947389   |
| train_0/mu_grads_std      | 0.4182319909334183     |
| train_0/mu_loss           | 9.514883096978078      |
| train_0/next_q            | -9.506075021045223     |
| train_0/q_grads           | 0.0453933316282928     |
| train_0/q_grads_std       | 0.3233943544328213     |
| train_0/q_loss            | 0.08477199758077644    |
| train_0/reward            | -0.8556681777903578    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2007080078125        |
| train_0/target_q          | -9.74696071415222      |
| train_1/avg_q             | -7.54134491423651      |
| train_1/current_q         | -15.292376438688535    |
| train_1/fw_bonus          | -0.9992866605520249    |
| train_1/fw_loss           | 0.0009438454013434239  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.867539169040423     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04575577583163977   |
| train_1/q_grads_std       | 0.7009969025850296     |
| train_1/q_loss            | 7.0555281953021804     |
| train_1/reward            | -1.4896749575374997    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00107421875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.542673980975007    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 549.87. Rollout time: 359.26, Training time: 190.58
Evaluating epoch 78
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 78                    |
| policy/steps              | 7177793.0             |
| test/episodes             | 1975.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.775164124204878    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.704993722180133    |
| train_0/fw_bonus          | -0.9999566912651062   |
| train_0/fw_loss           | 1.459060579236393e-05 |
| train_0/mu_grads          | -0.050489156320691106 |
| train_0/mu_grads_std      | 0.4197003968060017    |
| train_0/mu_loss           | 9.625581043558665     |
| train_0/next_q            | -9.617275812058962    |
| train_0/q_grads           | 0.04505946738645435   |
| train_0/q_grads_std       | 0.3250431902706623    |
| train_0/q_loss            | 0.08644727582813302   |
| train_0/reward            | -0.8563640029067756   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.27880859375         |
| train_0/target_q          | -9.858372880654699    |
| train_1/avg_q             | -7.435709730075808    |
| train_1/current_q         | -15.145421556999395   |
| train_1/fw_bonus          | -0.9995084345340729   |
| train_1/fw_loss           | 0.0008916296224924736 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.056615462624382    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04592541661113501  |
| train_1/q_grads_std       | 0.7054910212755203    |
| train_1/q_loss            | 6.671729694269631     |
| train_1/reward            | -1.4965307377278805   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009033203125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.402888647884136   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 547.06. Rollout time: 356.70, Training time: 190.33
Evaluating epoch 79
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 7268918.0              |
| test/episodes             | 2000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.651505591081352     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.570786751044139     |
| train_0/fw_bonus          | -0.9999584510922432    |
| train_0/fw_loss           | 1.4149117055239912e-05 |
| train_0/mu_grads          | -0.049836055096238854  |
| train_0/mu_grads_std      | 0.4206825837492943     |
| train_0/mu_loss           | 9.492119457744447      |
| train_0/next_q            | -9.484274006139168     |
| train_0/q_grads           | 0.044517275504767896   |
| train_0/q_grads_std       | 0.326177242398262      |
| train_0/q_loss            | 0.08534188201044142    |
| train_0/reward            | -0.8549554123848793    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.26552734375          |
| train_0/target_q          | -9.721621560298951     |
| train_1/avg_q             | -7.60534100795352      |
| train_1/current_q         | -15.189528849587578    |
| train_1/fw_bonus          | -0.9997753798961639    |
| train_1/fw_loss           | 0.0008287756427307613  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.055112403765207     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04573494838550687   |
| train_1/q_grads_std       | 0.7093450501561165     |
| train_1/q_loss            | 5.30940404771836       |
| train_1/reward            | -1.507619624142535     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.43271142101754     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 548.14. Rollout time: 358.36, Training time: 189.75
Evaluating epoch 80
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 7360043.0              |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.406596090726726     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.786939896127524     |
| train_0/fw_bonus          | -0.9999559760093689    |
| train_0/fw_loss           | 1.4768700748390983e-05 |
| train_0/mu_grads          | -0.04983726181089878   |
| train_0/mu_grads_std      | 0.4216948553919792     |
| train_0/mu_loss           | 9.708620425993212      |
| train_0/next_q            | -9.70052187091764      |
| train_0/q_grads           | 0.04410544913262129    |
| train_0/q_grads_std       | 0.3273634597659111     |
| train_0/q_loss            | 0.08538711495533327    |
| train_0/reward            | -0.8567357840889599    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2615234375           |
| train_0/target_q          | -9.940475123665015     |
| train_1/avg_q             | -7.6437947584008805    |
| train_1/current_q         | -15.105203497552427    |
| train_1/fw_bonus          | -0.9998439267277718    |
| train_1/fw_loss           | 0.0008126378728775307  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.079061138350163     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.045775805879384276  |
| train_1/q_grads_std       | 0.7116658985614777     |
| train_1/q_loss            | 4.334195822129566      |
| train_1/reward            | -1.4899891439679778    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010009765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.357587288499236    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 546.75. Rollout time: 357.30, Training time: 189.42
Evaluating epoch 81
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 81                     |
| policy/steps              | 7451168.0              |
| test/episodes             | 2050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.476196778092712     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.583845091295014     |
| train_0/fw_bonus          | -0.9999592944979667    |
| train_0/fw_loss           | 1.3936093444044672e-05 |
| train_0/mu_grads          | -0.05013209087774158   |
| train_0/mu_grads_std      | 0.4225857563316822     |
| train_0/mu_loss           | 9.504258559335799      |
| train_0/next_q            | -9.496735108788906     |
| train_0/q_grads           | 0.04441640404984355    |
| train_0/q_grads_std       | 0.32995730713009835    |
| train_0/q_loss            | 0.0825582814793912     |
| train_0/reward            | -0.8550170853282907    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.302099609375         |
| train_0/target_q          | -9.734709171260342     |
| train_1/avg_q             | -7.565665474318794     |
| train_1/current_q         | -14.855153968861774    |
| train_1/fw_bonus          | -0.9999544709920883    |
| train_1/fw_loss           | 0.0007866063300753012  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.236542238690838     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04553371947258711   |
| train_1/q_grads_std       | 0.7144942611455918     |
| train_1/q_loss            | 4.710725255867564      |
| train_1/reward            | -1.4862817810993874    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.092251507661894    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 541.03. Rollout time: 352.74, Training time: 188.25
Evaluating epoch 82
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 7542293.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.581978048368699    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.63049442543199     |
| train_0/fw_bonus          | -0.9999793708324433   |
| train_0/fw_loss           | 8.907425672077806e-06 |
| train_0/mu_grads          | -0.05056372219696641  |
| train_0/mu_grads_std      | 0.4230561316013336    |
| train_0/mu_loss           | 9.554879459492486     |
| train_0/next_q            | -9.547250558039952    |
| train_0/q_grads           | 0.04428579201921821   |
| train_0/q_grads_std       | 0.33253786265850066   |
| train_0/q_loss            | 0.08136686045762843   |
| train_0/reward            | -0.8544278915840551   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2946044921875       |
| train_0/target_q          | -9.782894070522925    |
| train_1/avg_q             | -7.559401983360207    |
| train_1/current_q         | -14.748167601006788   |
| train_1/fw_bonus          | -0.9999977380037308   |
| train_1/fw_loss           | 0.0007764210211462341 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.298776337926284    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04554325062781572  |
| train_1/q_grads_std       | 0.7156344905495644    |
| train_1/q_loss            | 4.3091834362815975    |
| train_1/reward            | -1.4872541667384211   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -14.983404557363425   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 506.02. Rollout time: 328.51, Training time: 177.49
Evaluating epoch 83
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 7633418.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.669565660951009    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.695810543004294    |
| train_0/fw_bonus          | -0.9999798163771629   |
| train_0/fw_loss           | 8.797278871952585e-06 |
| train_0/mu_grads          | -0.0509104928933084   |
| train_0/mu_grads_std      | 0.42366815358400345   |
| train_0/mu_loss           | 9.618976152553712     |
| train_0/next_q            | -9.612868288034269    |
| train_0/q_grads           | 0.0442847334779799    |
| train_0/q_grads_std       | 0.3348019182682037    |
| train_0/q_loss            | 0.08210069419539774   |
| train_0/reward            | -0.8551118149523973   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3209228515625       |
| train_0/target_q          | -9.849737261728635    |
| train_1/avg_q             | -7.56513992602668     |
| train_1/current_q         | -14.65248311776946    |
| train_1/fw_bonus          | -1.0000420659780502   |
| train_1/fw_loss           | 0.0007659818074898794 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.206618017605404    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.045461111888289454 |
| train_1/q_grads_std       | 0.7162194967269897    |
| train_1/q_loss            | 4.524640754623569     |
| train_1/reward            | -1.507264226071129    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009765625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -14.885197331539882   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 508.06. Rollout time: 331.93, Training time: 176.10
Evaluating epoch 84
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 7724543.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.63857043333122     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.705384938317568    |
| train_0/fw_bonus          | -0.9999786838889122   |
| train_0/fw_loss           | 9.079842209303024e-06 |
| train_0/mu_grads          | -0.05110227037221193  |
| train_0/mu_grads_std      | 0.42485269606113435   |
| train_0/mu_loss           | 9.625494420250755     |
| train_0/next_q            | -9.618602457318184    |
| train_0/q_grads           | 0.04430082691833377   |
| train_0/q_grads_std       | 0.33668403699994087   |
| train_0/q_loss            | 0.08248213701535703   |
| train_0/reward            | -0.8560081861724029   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.30791015625         |
| train_0/target_q          | -9.858806556922058    |
| train_1/avg_q             | -7.611540135716466    |
| train_1/current_q         | -14.78368177808846    |
| train_1/fw_bonus          | -1.0000775754451752   |
| train_1/fw_loss           | 0.0007576231684652158 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.239263665345224    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04554220549762249  |
| train_1/q_grads_std       | 0.7189359918236733    |
| train_1/q_loss            | 5.40616021051133      |
| train_1/reward            | -1.4912508123918087   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.037788898329314   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 507.88. Rollout time: 330.80, Training time: 177.05
Evaluating epoch 85
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 7815668.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.404201646983579    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.688958503656119    |
| train_0/fw_bonus          | -0.9999762326478958   |
| train_0/fw_loss           | 9.695618780369842e-06 |
| train_0/mu_grads          | -0.05096564618870616  |
| train_0/mu_grads_std      | 0.4261364996433258    |
| train_0/mu_loss           | 9.614460187007868     |
| train_0/next_q            | -9.60827241855036     |
| train_0/q_grads           | 0.04444880047813058   |
| train_0/q_grads_std       | 0.3386165499687195    |
| train_0/q_loss            | 0.08149562810435884   |
| train_0/reward            | -0.8545476021696231   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3272216796875       |
| train_0/target_q          | -9.8432801720881      |
| train_1/avg_q             | -7.594713150354677    |
| train_1/current_q         | -14.831725636005075   |
| train_1/fw_bonus          | -1.0001563131809235   |
| train_1/fw_loss           | 0.0007390886268694886 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.30301774829074     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.045913401152938606 |
| train_1/q_grads_std       | 0.721876822412014     |
| train_1/q_loss            | 3.357434680165143     |
| train_1/reward            | -1.5082715218348313   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00078125            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.053517615584838   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 505.29. Rollout time: 330.06, Training time: 175.20
Evaluating epoch 86
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 86                     |
| policy/steps              | 7906793.0              |
| test/episodes             | 2175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.545714257603527     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.653668967200002     |
| train_0/fw_bonus          | -0.9999714463949203    |
| train_0/fw_loss           | 1.0894575461861678e-05 |
| train_0/mu_grads          | -0.051391462050378325  |
| train_0/mu_grads_std      | 0.4276656858623028     |
| train_0/mu_loss           | 9.580364901226895      |
| train_0/next_q            | -9.573844431172342     |
| train_0/q_grads           | 0.04413206716999411    |
| train_0/q_grads_std       | 0.33927193880081175    |
| train_0/q_loss            | 0.09214175461711749    |
| train_0/reward            | -0.8548369816446211    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3089599609375        |
| train_0/target_q          | -9.808786563834957     |
| train_1/avg_q             | -7.634327396220621     |
| train_1/current_q         | -14.950342447121736    |
| train_1/fw_bonus          | -1.000168077647686     |
| train_1/fw_loss           | 0.0007363176104263402  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.235189119646467     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04629444126039743   |
| train_1/q_grads_std       | 0.7245154112577439     |
| train_1/q_loss            | 4.8639188331025025     |
| train_1/reward            | -1.485697340851766     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.16983259475802     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 574.09. Rollout time: 368.81, Training time: 205.25
Evaluating epoch 87
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
----------------------------------------------------
| epoch                     | 87                   |
| policy/steps              | 7997918.0            |
| test/episodes             | 2200.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -27.0                |
| test_1/avg_q              | -7.515781878224122   |
| test_1/n_subgoals         | 675.0                |
| test_1/subgoal_succ_rate  | 0.0                  |
| train/episodes            | 8800.0               |
| train/success_rate        | 0.0                  |
| train_0/avg_q             | -27.0                |
| train_0/current_q         | -9.686203257127122   |
| train_0/fw_bonus          | -0.9999759823083878  |
| train_0/fw_loss           | 9.75851046405296e-06 |
| train_0/mu_grads          | -0.04958775034174323 |
| train_0/mu_grads_std      | 0.430858001857996    |
| train_0/mu_loss           | 9.611682785668698    |
| train_0/next_q            | -9.605607590586676   |
| train_0/q_grads           | 0.043588515091687444 |
| train_0/q_grads_std       | 0.33776339069008826  |
| train_0/q_loss            | 0.08771485606786962  |
| train_0/reward            | -0.8543948259743047  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.3416748046875      |
| train_0/target_q          | -9.838834932186135   |
| train_1/avg_q             | -7.579280834231552   |
| train_1/current_q         | -14.84352998934732   |
| train_1/fw_bonus          | -1.000188647210598   |
| train_1/fw_loss           | 0.000731469709717203 |
| train_1/mu_grads          | 0.015022383071482182 |
| train_1/mu_grads_std      | 0.09010138362646103  |
| train_1/mu_loss           | 19.190142812941197   |
| train_1/n_subgoals        | 2700.0               |
| train_1/next_q            | -27.0                |
| train_1/q_grads           | -0.04704266125336289 |
| train_1/q_grads_std       | 0.7259579375386238   |
| train_1/q_loss            | 4.477599431408642    |
| train_1/reward            | -1.4919139556761365  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0009521484375      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.0                  |
| train_1/target_q          | -15.064937881457393  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 671.51. Rollout time: 431.49, Training time: 239.98
Evaluating epoch 88
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 8089043.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.443399320791081    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.664909736020523    |
| train_0/fw_bonus          | -0.9999771818518639   |
| train_0/fw_loss           | 9.457066653340007e-06 |
| train_0/mu_grads          | -0.04904879620298743  |
| train_0/mu_grads_std      | 0.4329028621315956    |
| train_0/mu_loss           | 9.588745637176093     |
| train_0/next_q            | -9.582835527282807    |
| train_0/q_grads           | 0.043479960132390263  |
| train_0/q_grads_std       | 0.3357513748109341    |
| train_0/q_loss            | 0.08702385325451577   |
| train_0/reward            | -0.8545116954192054   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.332568359375        |
| train_0/target_q          | -9.81856846921801     |
| train_1/avg_q             | -7.70982223632895     |
| train_1/current_q         | -15.062396455533545   |
| train_1/fw_bonus          | -1.0000076845288277   |
| train_1/fw_loss           | 0.0007740794084384106 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.263506721412252    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.047509887255728245 |
| train_1/q_grads_std       | 0.7287370294332505    |
| train_1/q_loss            | 5.231747816364928     |
| train_1/reward            | -1.5135433643430587   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.314603911218066   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 649.22. Rollout time: 419.93, Training time: 229.24
Evaluating epoch 89
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 8180168.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.62530093577571     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.658460473061302    |
| train_0/fw_bonus          | -0.9999679177999496   |
| train_0/fw_loss           | 1.177665576506115e-05 |
| train_0/mu_grads          | -0.04979163333773613  |
| train_0/mu_grads_std      | 0.4346169844269753    |
| train_0/mu_loss           | 9.581744803869984     |
| train_0/next_q            | -9.576396088910013    |
| train_0/q_grads           | 0.043473588209599255  |
| train_0/q_grads_std       | 0.33384103551506994   |
| train_0/q_loss            | 0.0892790038561593    |
| train_0/reward            | -0.854382681028801    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3009521484375       |
| train_0/target_q          | -9.811624755535993    |
| train_1/avg_q             | -8.010263281029221    |
| train_1/current_q         | -15.128777496639165   |
| train_1/fw_bonus          | -0.9997501313686371   |
| train_1/fw_loss           | 0.0008347201350261457 |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 19.255109998963707    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04797177538275719  |
| train_1/q_grads_std       | 0.7301807418465615    |
| train_1/q_loss            | 6.430378570086165     |
| train_1/reward            | -1.505702494608704    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.386866557108709   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 665.22. Rollout time: 427.96, Training time: 237.21
Evaluating epoch 90
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 90                     |
| policy/steps              | 8271293.0              |
| test/episodes             | 2275.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.352582834231246     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.584761608498896     |
| train_0/fw_bonus          | -0.9999570950865746    |
| train_0/fw_loss           | 1.4489773911918747e-05 |
| train_0/mu_grads          | -0.050907550193369386  |
| train_0/mu_grads_std      | 0.4351275198161602     |
| train_0/mu_loss           | 9.504655443055608      |
| train_0/next_q            | -9.49922714034843      |
| train_0/q_grads           | 0.043509325757622716   |
| train_0/q_grads_std       | 0.3331151857972145     |
| train_0/q_loss            | 0.08793036640113112    |
| train_0/reward            | -0.8540815899017616    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2568115234375        |
| train_0/target_q          | -9.73581060444016      |
| train_1/avg_q             | -7.478376223155626     |
| train_1/current_q         | -15.119133132458776    |
| train_1/fw_bonus          | -0.9993228211998939    |
| train_1/fw_loss           | 0.0009353297180496156  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.20684126889921      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.048042035195976496  |
| train_1/q_grads_std       | 0.7332343429327011     |
| train_1/q_loss            | 7.725475575922919      |
| train_1/reward            | -1.4961779131845105    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.345042170997015    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 670.89. Rollout time: 431.03, Training time: 239.82
Evaluating epoch 91
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 91                     |
| policy/steps              | 8362418.0              |
| test/episodes             | 2300.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.677186131333387     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.69886386912431      |
| train_0/fw_bonus          | -0.9999613702297211    |
| train_0/fw_loss           | 1.3418899652606341e-05 |
| train_0/mu_grads          | -0.05107754552736878   |
| train_0/mu_grads_std      | 0.43578089103102685    |
| train_0/mu_loss           | 9.622075914406398      |
| train_0/next_q            | -9.615816871059545     |
| train_0/q_grads           | 0.04338033068925142    |
| train_0/q_grads_std       | 0.3322554290294647     |
| train_0/q_loss            | 0.08933490361252312    |
| train_0/reward            | -0.8546890436889953    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.247802734375         |
| train_0/target_q          | -9.851447623348896     |
| train_1/avg_q             | -7.482521842638143     |
| train_1/current_q         | -14.868213105864964    |
| train_1/fw_bonus          | -0.9988424390554428    |
| train_1/fw_loss           | 0.0010484375394298694  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.214521140157704     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.048453002516180274  |
| train_1/q_grads_std       | 0.739440530538559      |
| train_1/q_loss            | 8.7170042555953        |
| train_1/reward            | -1.4859421332323108    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.091911859794816    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 618.35. Rollout time: 394.69, Training time: 223.63
Evaluating epoch 92
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 8452853.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.453837435505794    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.753290720980484    |
| train_0/fw_bonus          | -0.9999624222517014   |
| train_0/fw_loss           | 1.315241709107795e-05 |
| train_0/mu_grads          | -0.051322328858077526 |
| train_0/mu_grads_std      | 0.43596966937184334   |
| train_0/mu_loss           | 9.673783401067222     |
| train_0/next_q            | -9.666836468917262    |
| train_0/q_grads           | 0.04285058444365859   |
| train_0/q_grads_std       | 0.33110868409276006   |
| train_0/q_loss            | 0.09051364208207031   |
| train_0/reward            | -0.8557579567554058   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2552978515625       |
| train_0/target_q          | -9.906368317175016    |
| train_1/avg_q             | -7.678585706719748    |
| train_1/current_q         | -15.007966617082271   |
| train_1/fw_bonus          | -0.998293760418892    |
| train_1/fw_loss           | 0.001177626574644819  |
| train_1/mu_grads          | 0.015022383071482182  |
| train_1/mu_grads_std      | 0.09010138362646103   |
| train_1/mu_loss           | 18.891812142392258    |
| train_1/n_subgoals        | 2675.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.04828318767249584  |
| train_1/q_grads_std       | 0.7466931626200676    |
| train_1/q_loss            | 7.0489327709065295    |
| train_1/reward            | -1.4994588390822172   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.254007667207224   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 93
Time for epoch 93: 613.01. Rollout time: 395.40, Training time: 217.57
Evaluating epoch 93
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 8543978.0              |
| test/episodes             | 2350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.8649504419722       |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.674286158593048     |
| train_0/fw_bonus          | -0.999962629377842     |
| train_0/fw_loss           | 1.3101653166813776e-05 |
| train_0/mu_grads          | -0.05168346064165234   |
| train_0/mu_grads_std      | 0.43656866922974585    |
| train_0/mu_loss           | 9.594484661689327      |
| train_0/next_q            | -9.587965051056097     |
| train_0/q_grads           | 0.0425884660333395     |
| train_0/q_grads_std       | 0.33097601160407064    |
| train_0/q_loss            | 0.08979463115773087    |
| train_0/reward            | -0.8552454134493018    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2686279296875        |
| train_0/target_q          | -9.82626942195078      |
| train_1/avg_q             | -7.637823001514976     |
| train_1/current_q         | -15.079953647379895    |
| train_1/fw_bonus          | -0.9978690221905708    |
| train_1/fw_loss           | 0.0012776288640452549  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 16.524274351666083     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04856799002736807   |
| train_1/q_grads_std       | 0.7535307601094245     |
| train_1/q_loss            | 7.496103463897524      |
| train_1/reward            | -1.4927316021377919    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006103515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.318985996669047    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 94
Time for epoch 94: 599.99. Rollout time: 391.30, Training time: 208.64
Evaluating epoch 94
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 94                     |
| policy/steps              | 8635103.0              |
| test/episodes             | 2375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.15338352468736      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.71369931121513      |
| train_0/fw_bonus          | -0.9999675184488297    |
| train_0/fw_loss           | 1.1878307554979984e-05 |
| train_0/mu_grads          | -0.05224825758486986   |
| train_0/mu_grads_std      | 0.4371274866163731     |
| train_0/mu_loss           | 9.629857714863864      |
| train_0/next_q            | -9.624864868976982     |
| train_0/q_grads           | 0.04217924550175667    |
| train_0/q_grads_std       | 0.3319058306515217     |
| train_0/q_loss            | 0.08853591669032582    |
| train_0/reward            | -0.8557922886626329    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.293896484375         |
| train_0/target_q          | -9.868715974970169     |
| train_1/avg_q             | -7.463163738909485     |
| train_1/current_q         | -14.978362738693752    |
| train_1/fw_bonus          | -0.9983684256672859    |
| train_1/fw_loss           | 0.0011600443831412122  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 16.928521636070844     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.048629182018339635  |
| train_1/q_grads_std       | 0.7606233283877373     |
| train_1/q_loss            | 6.373523281992976      |
| train_1/reward            | -1.4988434582584886    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010498046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.199774610602244    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 95
Time for epoch 95: 631.85. Rollout time: 407.98, Training time: 223.84
Evaluating epoch 95
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 8726228.0              |
| test/episodes             | 2400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.355212470703253     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.587846375978472     |
| train_0/fw_bonus          | -0.9999652609229088    |
| train_0/fw_loss           | 1.2442881302376919e-05 |
| train_0/mu_grads          | -0.05347209488973022   |
| train_0/mu_grads_std      | 0.43878196328878405    |
| train_0/mu_loss           | 9.505189059497956      |
| train_0/next_q            | -9.499830481317812     |
| train_0/q_grads           | 0.0421250818297267     |
| train_0/q_grads_std       | 0.33338676691055297    |
| train_0/q_loss            | 0.0868827945380743     |
| train_0/reward            | -0.854460032179486     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2536376953125        |
| train_0/target_q          | -9.738272736504982     |
| train_1/avg_q             | -7.593437138739881     |
| train_1/current_q         | -15.010431954300955    |
| train_1/fw_bonus          | -0.9988250344991684    |
| train_1/fw_loss           | 0.001052533990878146   |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.06960646837481      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04910317687317729   |
| train_1/q_grads_std       | 0.7680212289094925     |
| train_1/q_loss            | 6.075151270619751      |
| train_1/reward            | -1.4866126782944775    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.269585334544484    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 96
Time for epoch 96: 678.06. Rollout time: 435.01, Training time: 243.01
Evaluating epoch 96
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 8817353.0              |
| test/episodes             | 2425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.26402509958403      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.613813695220342     |
| train_0/fw_bonus          | -0.9999681055545807    |
| train_0/fw_loss           | 1.1730208404969744e-05 |
| train_0/mu_grads          | -0.05407679956406355   |
| train_0/mu_grads_std      | 0.4398416139185429     |
| train_0/mu_loss           | 9.532705790303009      |
| train_0/next_q            | -9.527833480215486     |
| train_0/q_grads           | 0.04173976322636008    |
| train_0/q_grads_std       | 0.3344884842634201     |
| train_0/q_loss            | 0.0866570020824208     |
| train_0/reward            | -0.8548283765951055    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.262646484375         |
| train_0/target_q          | -9.765330237191048     |
| train_1/avg_q             | -7.599552226278723     |
| train_1/current_q         | -15.045747507604574    |
| train_1/fw_bonus          | -0.9993121653795243    |
| train_1/fw_loss           | 0.0009378423928865232  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.154431147525862     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.04943512873724103   |
| train_1/q_grads_std       | 0.7730053558945655     |
| train_1/q_loss            | 3.88159759708647       |
| train_1/reward            | -1.5042936889338308    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001123046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.288558337371336    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 651.66. Rollout time: 421.76, Training time: 229.86
Evaluating epoch 97
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 97                     |
| policy/steps              | 8908478.0              |
| test/episodes             | 2450.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.463711128931474     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.660942538485344     |
| train_0/fw_bonus          | -0.9999716386198998    |
| train_0/fw_loss           | 1.0846762654637132e-05 |
| train_0/mu_grads          | -0.05370345171540976   |
| train_0/mu_grads_std      | 0.4422809429466724     |
| train_0/mu_loss           | 9.580504572000052      |
| train_0/next_q            | -9.57521021149628      |
| train_0/q_grads           | 0.04164349921047687    |
| train_0/q_grads_std       | 0.33606346026062967    |
| train_0/q_loss            | 0.08658008190149596    |
| train_0/reward            | -0.8547821930842474    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.309912109375         |
| train_0/target_q          | -9.811073877583365     |
| train_1/avg_q             | -7.712320355720068     |
| train_1/current_q         | -15.086542255765526    |
| train_1/fw_bonus          | -0.9995440140366554    |
| train_1/fw_loss           | 0.0008832523148157634  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 18.941286913311256     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.05025649126619101   |
| train_1/q_grads_std       | 0.7767168670892716     |
| train_1/q_loss            | 3.561229526235563      |
| train_1/reward            | -1.4945920910089625    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.315032520696468    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 664.45. Rollout time: 437.11, Training time: 227.27
Evaluating epoch 98
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 8999603.0              |
| test/episodes             | 2475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.576627052657817     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.777577316538634     |
| train_0/fw_bonus          | -0.99996208101511      |
| train_0/fw_loss           | 1.3238197152531938e-05 |
| train_0/mu_grads          | -0.054140700958669186  |
| train_0/mu_grads_std      | 0.4443420052528381     |
| train_0/mu_loss           | 9.696623860652188      |
| train_0/next_q            | -9.691272068952651     |
| train_0/q_grads           | 0.04160921135917306    |
| train_0/q_grads_std       | 0.33760712295770645    |
| train_0/q_loss            | 0.08650176991367657    |
| train_0/reward            | -0.8560262549275649    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.297216796875         |
| train_0/target_q          | -9.932085960094263     |
| train_1/avg_q             | -7.596537493700176     |
| train_1/current_q         | -14.98533519671987     |
| train_1/fw_bonus          | -0.9994461625814438    |
| train_1/fw_loss           | 0.0009062881057616323  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.055685623304306     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.05089893080294132   |
| train_1/q_grads_std       | 0.7796555802226066     |
| train_1/q_loss            | 5.277406960099545      |
| train_1/reward            | -1.4928036245837575    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.218928624583764    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 99
Time for epoch 99: 736.14. Rollout time: 485.66, Training time: 250.42
Evaluating epoch 99
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 99                     |
| policy/steps              | 9090728.0              |
| test/episodes             | 2500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.626619801291155     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 10000.0                |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.657222706678812     |
| train_0/fw_bonus          | -0.9999691307544708    |
| train_0/fw_loss           | 1.1475353517198528e-05 |
| train_0/mu_grads          | -0.05455205459147692   |
| train_0/mu_grads_std      | 0.4463626153767109     |
| train_0/mu_loss           | 9.575763950068566      |
| train_0/next_q            | -9.569245669073341     |
| train_0/q_grads           | 0.041455726604908705   |
| train_0/q_grads_std       | 0.33896458297967913    |
| train_0/q_loss            | 0.08653666491710839    |
| train_0/reward            | -0.8551282120359247    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2864501953125        |
| train_0/target_q          | -9.808748068870297     |
| train_1/avg_q             | -7.551516020556158     |
| train_1/current_q         | -14.904280856709045    |
| train_1/fw_bonus          | -0.9989504337310791    |
| train_1/fw_loss           | 0.0010230102256173269  |
| train_1/mu_grads          | 0.015022383071482182   |
| train_1/mu_grads_std      | 0.09010138362646103    |
| train_1/mu_loss           | 19.104555162042224     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.0514165423810482    |
| train_1/q_grads_std       | 0.78172677308321       |
| train_1/q_loss            | 4.215995783558799      |
| train_1/reward            | -1.4961854824563487    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00087890625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.131225033237603    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
All epochs are finished. Stopping the training now.
