Starting process id: 78915
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f852aa2e320>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 1052.36. Rollout time: 655.82, Training time: 396.41
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 81380.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -4.359735874070167     |
| test_1/avg_q              | -7.1257952694471545    |
| test_1/n_subgoals         | 703.0                  |
| test_1/subgoal_succ_rate  | 0.041251778093883355   |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.6204680931675943    |
| train_0/current_q         | -2.761066365917343     |
| train_0/fw_bonus          | -0.9991665557026863    |
| train_0/fw_loss           | 0.00021973911752866117 |
| train_0/mu_grads          | -0.0016049931669840588 |
| train_0/mu_grads_std      | 0.14136172756552695    |
| train_0/mu_loss           | 2.5518608830173477     |
| train_0/next_q            | -2.5975521912000445    |
| train_0/q_grads           | 0.026094655273482203   |
| train_0/q_grads_std       | 0.14605384618043898    |
| train_0/q_loss            | 0.45311937541038516    |
| train_0/reward            | -0.8632421012458508    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -2.9335184118314164    |
| train_1/avg_q             | -5.001276305646337     |
| train_1/current_q         | -6.2108508760713566    |
| train_1/fw_bonus          | -0.9971246540546417    |
| train_1/fw_loss           | 0.0015352485643234104  |
| train_1/mu_grads          | 0.002033374714665115   |
| train_1/mu_grads_std      | 0.11677266359329223    |
| train_1/mu_loss           | 7.2632532925725215     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.117590353242666     |
| train_1/q_grads           | 0.008787786215543747   |
| train_1/q_grads_std       | 0.18919860124588012    |
| train_1/q_loss            | 2.3260908666351807     |
| train_1/reward            | -1.4233134696725755    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015625              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14888888888888888    |
| train_1/target_q          | -6.215264750416912     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 979.83. Rollout time: 707.98, Training time: 271.68
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 156928.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -5.713260841056347     |
| test_1/avg_q              | -8.560824931885156     |
| test_1/n_subgoals         | 581.0                  |
| test_1/subgoal_succ_rate  | 0.4354561101549053     |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -4.1600761848443275    |
| train_0/current_q         | -4.251244376033604     |
| train_0/fw_bonus          | -0.9990747466683387    |
| train_0/fw_loss           | 0.00024322802055394278 |
| train_0/mu_grads          | -0.005390536203049123  |
| train_0/mu_grads_std      | 0.18473323993384838    |
| train_0/mu_loss           | 4.032743128229866      |
| train_0/next_q            | -4.027966886265871     |
| train_0/q_grads           | 0.026778126088902354   |
| train_0/q_grads_std       | 0.16080196537077426    |
| train_0/q_loss            | 0.42732470880559126    |
| train_0/reward            | -0.8675372640980641    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001220703125        |
| train_0/target_q          | -4.182115967725204     |
| train_1/avg_q             | -7.841934452470718     |
| train_1/current_q         | -6.219887365501327     |
| train_1/fw_bonus          | -0.9958587884902954    |
| train_1/fw_loss           | 0.001874713585129939   |
| train_1/mu_grads          | 0.0021154690883122386  |
| train_1/mu_grads_std      | 0.1335777912288904     |
| train_1/mu_loss           | 7.43035649875508       |
| train_1/n_subgoals        | 2685.0                 |
| train_1/next_q            | -6.264477045910044     |
| train_1/q_grads           | 0.00032922525679168757 |
| train_1/q_grads_std       | 0.22859467081725598    |
| train_1/q_loss            | 3.169988865129548      |
| train_1/reward            | -1.4452217372774612    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020751953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.16089385474860335    |
| train_1/target_q          | -6.2239898010815535    |
------------------------------------------------------
New best value for test/success_rate: 0.48. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 1299.47. Rollout time: 947.08, Training time: 352.20
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 235711.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999860704008     |
| test_1/avg_q              | -1.865087285131492     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.13                   |
| train_0/avg_q             | -15.01964838806625     |
| train_0/current_q         | -4.793227800033594     |
| train_0/fw_bonus          | -0.9989093855023384    |
| train_0/fw_loss           | 0.00028554027594509537 |
| train_0/mu_grads          | -0.00817219209857285   |
| train_0/mu_grads_std      | 0.2106937885284424     |
| train_0/mu_loss           | 4.616436449353186      |
| train_0/next_q            | -4.564293248259394     |
| train_0/q_grads           | 0.027849229238927364   |
| train_0/q_grads_std       | 0.1751919213682413     |
| train_0/q_loss            | 0.35179043796000453    |
| train_0/reward            | -0.8718016656770488    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001220703125        |
| train_0/target_q          | -4.7763600646192526    |
| train_1/avg_q             | -8.280392178563183     |
| train_1/current_q         | -2.7405753125787173    |
| train_1/fw_bonus          | -0.996271438896656     |
| train_1/fw_loss           | 0.0017640544509049505  |
| train_1/mu_grads          | 0.0052923284703865646  |
| train_1/mu_grads_std      | 0.15121544264256953    |
| train_1/mu_loss           | 2.7223000315284978     |
| train_1/n_subgoals        | 2512.0                 |
| train_1/next_q            | -1.7583822193103102    |
| train_1/q_grads           | -0.0029040225548669697 |
| train_1/q_grads_std       | 0.24547336995601654    |
| train_1/q_loss            | 2.160520779347224      |
| train_1/reward            | -1.4436513405191362    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001953125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.17197452229299362    |
| train_1/target_q          | -2.7328444439103494    |
------------------------------------------------------
Training epoch 3
Time for epoch 3: 1579.36. Rollout time: 1149.26, Training time: 429.97
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 326836.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -26.99999999994229     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999808417022     |
| train_0/current_q         | -6.266344744580498     |
| train_0/fw_bonus          | -0.9991816431283951    |
| train_0/fw_loss           | 0.00021587441260635388 |
| train_0/mu_grads          | -0.0156378359766677    |
| train_0/mu_grads_std      | 0.23011585250496863    |
| train_0/mu_loss           | 6.126757460289452      |
| train_0/next_q            | -6.097229513197568     |
| train_0/q_grads           | 0.02804315332323313    |
| train_0/q_grads_std       | 0.18639999963343143    |
| train_0/q_loss            | 0.30701256151547146    |
| train_0/reward            | -0.8677822379831923    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -6.301846983808465     |
| train_1/avg_q             | -11.854441991212072    |
| train_1/current_q         | -26.999996446264753    |
| train_1/fw_bonus          | -0.9971383601427078    |
| train_1/fw_loss           | 0.00153157593740616    |
| train_1/mu_grads          | 0.015153910033404827   |
| train_1/mu_grads_std      | 0.15993252396583557    |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.00329806178342551    |
| train_1/q_grads_std       | 0.25148571357131005    |
| train_1/q_loss            | 206.11012819904653     |
| train_1/reward            | -1.45825416091393      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00185546875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -19.05389576247644     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 4
Time for epoch 4: 1261.41. Rollout time: 915.81, Training time: 345.48
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 417961.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -26.99999988744836     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -6.95158571771996      |
| train_0/fw_bonus          | -0.9993703931570053    |
| train_0/fw_loss           | 0.00016758091951487585 |
| train_0/mu_grads          | -0.01959063094109297   |
| train_0/mu_grads_std      | 0.25097349360585214    |
| train_0/mu_loss           | 6.828934021579931      |
| train_0/next_q            | -6.792049141653384     |
| train_0/q_grads           | 0.030002532666549085   |
| train_0/q_grads_std       | 0.20513749830424785    |
| train_0/q_loss            | 0.23385506001162565    |
| train_0/reward            | -0.8638466479358613    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00068359375          |
| train_0/target_q          | -7.02034661689454      |
| train_1/avg_q             | -26.999999980558872    |
| train_1/current_q         | -26.999922836905505    |
| train_1/fw_bonus          | -0.9976745113730431    |
| train_1/fw_loss           | 0.0013877998135285452  |
| train_1/mu_grads          | 0.015153910033404827   |
| train_1/mu_grads_std      | 0.15993252396583557    |
| train_1/mu_loss           | 27.999999999999982     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -26.999999999999932    |
| train_1/q_grads           | 0.002601429185597226   |
| train_1/q_grads_std       | 0.2512727819383144     |
| train_1/q_loss            | 225.55212462896537     |
| train_1/reward            | -1.4716933764706481    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023681640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -18.28438771240809     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 5
Time for epoch 5: 1509.48. Rollout time: 1114.20, Training time: 394.96
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 509086.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.250179747905546     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -7.868378300406451     |
| train_0/fw_bonus          | -0.9993992879986763    |
| train_0/fw_loss           | 0.00016019001413951627 |
| train_0/mu_grads          | -0.022202896140515804  |
| train_0/mu_grads_std      | 0.2642043672502041     |
| train_0/mu_loss           | 7.717635026952936      |
| train_0/next_q            | -7.688915299394009     |
| train_0/q_grads           | 0.030652605462819338   |
| train_0/q_grads_std       | 0.21745597645640374    |
| train_0/q_loss            | 0.1465799906100044     |
| train_0/reward            | -0.8632030288557871    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0011474609375        |
| train_0/target_q          | -7.948398354004953     |
| train_1/avg_q             | -14.55441579946466     |
| train_1/current_q         | -17.51476788472923     |
| train_1/fw_bonus          | -0.9975199609994888    |
| train_1/fw_loss           | 0.0014292417152319103  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.001083098046365194  |
| train_1/q_grads_std       | 0.32041388750076294    |
| train_1/q_loss            | 33.78228606986861      |
| train_1/reward            | -1.4958999831826076    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017822265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -17.621254475370115    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 1248.76. Rollout time: 919.84, Training time: 328.75
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 600211.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -8.669194756012066     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.141163990580196     |
| train_0/fw_bonus          | -0.9996052429080009    |
| train_0/fw_loss           | 0.00010749538996606134 |
| train_0/mu_grads          | -0.023488513054326178  |
| train_0/mu_grads_std      | 0.2739601254463196     |
| train_0/mu_loss           | 9.0369531226882        |
| train_0/next_q            | -9.010863600935323     |
| train_0/q_grads           | 0.03099622777663171    |
| train_0/q_grads_std       | 0.2236796047538519     |
| train_0/q_loss            | 0.125207146571592      |
| train_0/reward            | -0.8620147141366032    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0057861328125        |
| train_0/target_q          | -9.27380828553665      |
| train_1/avg_q             | -8.08771334687648      |
| train_1/current_q         | -16.24386001187455     |
| train_1/fw_bonus          | -0.9982329905033112    |
| train_1/fw_loss           | 0.001238030579406768   |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0011960071395151317  |
| train_1/q_grads_std       | 0.3518135316669941     |
| train_1/q_loss            | 22.69088326594359      |
| train_1/reward            | -1.4849479373035137    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00166015625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.481747253709774    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 1445.06. Rollout time: 1039.87, Training time: 405.00
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 7                     |
| policy/steps              | 691336.0              |
| test/episodes             | 200.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -6.858399179984986    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 800.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.748935565880457    |
| train_0/fw_bonus          | -0.999825119972229    |
| train_0/fw_loss           | 5.123249902680982e-05 |
| train_0/mu_grads          | -0.027112083276733756 |
| train_0/mu_grads_std      | 0.2771927908062935    |
| train_0/mu_loss           | 9.668682494068298     |
| train_0/next_q            | -9.661649306495647    |
| train_0/q_grads           | 0.03126524854451418   |
| train_0/q_grads_std       | 0.2258110959082842    |
| train_0/q_loss            | 0.10686768685962189   |
| train_0/reward            | -0.8551056580923614   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0165283203125       |
| train_0/target_q          | -9.900153130805643    |
| train_1/avg_q             | -7.959002022764686    |
| train_1/current_q         | -14.888175066349936   |
| train_1/fw_bonus          | -0.9986230999231338   |
| train_1/fw_loss           | 0.0011334169248584658 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.003184273274382576  |
| train_1/q_grads_std       | 0.3715247273445129    |
| train_1/q_loss            | 17.02306091846586     |
| train_1/reward            | -1.4860339712744461   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013671875          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.119135533774454   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 6424.43. Rollout time: 4284.46, Training time: 2139.61
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 782461.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.305468128050084     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.551773447582132     |
| train_0/fw_bonus          | -0.9998689368367195    |
| train_0/fw_loss           | 4.0022855682764205e-05 |
| train_0/mu_grads          | -0.028597328113391995  |
| train_0/mu_grads_std      | 0.2804458260536194     |
| train_0/mu_loss           | 9.471687468669737      |
| train_0/next_q            | -9.466703036140192     |
| train_0/q_grads           | 0.030774812772870065   |
| train_0/q_grads_std       | 0.22532033436000348    |
| train_0/q_loss            | 0.10768632941376052    |
| train_0/reward            | -0.8532342188773328    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0400390625           |
| train_0/target_q          | -9.699135350805882     |
| train_1/avg_q             | -7.322424809269193     |
| train_1/current_q         | -14.948165907020515    |
| train_1/fw_bonus          | -0.9990315139293671    |
| train_1/fw_loss           | 0.0010238964707241394  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0058779184939339755  |
| train_1/q_grads_std       | 0.39162037149071693    |
| train_1/q_loss            | 12.597431463610388     |
| train_1/reward            | -1.5004699115364928    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0011474609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.181375184974002    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 1437.08. Rollout time: 1042.13, Training time: 394.84
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 9                     |
| policy/steps              | 873586.0              |
| test/episodes             | 250.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.096523536052358    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.605057328819763    |
| train_0/fw_bonus          | -0.9999204114079475   |
| train_0/fw_loss           | 2.685111689970654e-05 |
| train_0/mu_grads          | -0.029965332709252834 |
| train_0/mu_grads_std      | 0.2851712055504322    |
| train_0/mu_loss           | 9.518945858788374     |
| train_0/next_q            | -9.513398817737292    |
| train_0/q_grads           | 0.02958602262660861   |
| train_0/q_grads_std       | 0.22621853724122049   |
| train_0/q_loss            | 0.10074513928576043   |
| train_0/reward            | -0.8546461189631372   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.101123046875        |
| train_0/target_q          | -9.753284354628793    |
| train_1/avg_q             | -7.44377697108197     |
| train_1/current_q         | -14.925498655560068   |
| train_1/fw_bonus          | -0.9995709210634232   |
| train_1/fw_loss           | 0.0008792403474217281 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.007506497704889625  |
| train_1/q_grads_std       | 0.4090616650879383    |
| train_1/q_loss            | 11.611552607304748    |
| train_1/reward            | -1.4951127589549287   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0007080078125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.211547817548686   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 1398.73. Rollout time: 1025.27, Training time: 373.24
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 10                    |
| policy/steps              | 964711.0              |
| test/episodes             | 275.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.591030155199276    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.619763862721948    |
| train_0/fw_bonus          | -0.9999441117048263   |
| train_0/fw_loss           | 2.078608183637698e-05 |
| train_0/mu_grads          | -0.03354479819536209  |
| train_0/mu_grads_std      | 0.2900957889854908    |
| train_0/mu_loss           | 9.537334826600425     |
| train_0/next_q            | -9.532277945851991    |
| train_0/q_grads           | 0.028977273032069206  |
| train_0/q_grads_std       | 0.22730638794600963   |
| train_0/q_loss            | 0.09570509935653682   |
| train_0/reward            | -0.8547371389257024   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1748046875          |
| train_0/target_q          | -9.768540230741252    |
| train_1/avg_q             | -7.405067851731948    |
| train_1/current_q         | -14.822493003405839   |
| train_1/fw_bonus          | -0.9999937683343887   |
| train_1/fw_loss           | 0.0007658433620235883 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.008652940439060331  |
| train_1/q_grads_std       | 0.4205644644796848    |
| train_1/q_loss            | 10.254409183379826    |
| train_1/reward            | -1.4899672561732586   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.134050752267015   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 1532.30. Rollout time: 1116.53, Training time: 415.60
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 1055836.0              |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.846635784778358     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.656286324535944     |
| train_0/fw_bonus          | -0.9999458327889442    |
| train_0/fw_loss           | 2.0346619271549572e-05 |
| train_0/mu_grads          | -0.03461598847061396   |
| train_0/mu_grads_std      | 0.295455539226532      |
| train_0/mu_loss           | 9.573448285261964      |
| train_0/next_q            | -9.566537656203703     |
| train_0/q_grads           | 0.028555961279198527   |
| train_0/q_grads_std       | 0.22897915802896024    |
| train_0/q_loss            | 0.09534685301274663    |
| train_0/reward            | -0.8548849117432837    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.173681640625         |
| train_0/target_q          | -9.805948145812042     |
| train_1/avg_q             | -7.533274708647772     |
| train_1/current_q         | -14.83579609299269     |
| train_1/fw_bonus          | -1.0004259809851646    |
| train_1/fw_loss           | 0.0006499403112684377  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.009219722566194832   |
| train_1/q_grads_std       | 0.4296522341668606     |
| train_1/q_loss            | 9.629128165265067      |
| train_1/reward            | -1.4843954116091482    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.167238673327905    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 1459.45. Rollout time: 1065.30, Training time: 393.97
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 1146961.0              |
| test/episodes             | 325.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.373368744378881     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.744324713553349     |
| train_0/fw_bonus          | -0.9999255925416947    |
| train_0/fw_loss           | 2.5525403270876267e-05 |
| train_0/mu_grads          | -0.03545798175036907   |
| train_0/mu_grads_std      | 0.3046714000403881     |
| train_0/mu_loss           | 9.655438619926999      |
| train_0/next_q            | -9.649423131195068     |
| train_0/q_grads           | 0.028206440154463053   |
| train_0/q_grads_std       | 0.23075517266988754    |
| train_0/q_loss            | 0.091556112156901      |
| train_0/reward            | -0.8559866748546483    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1656494140625        |
| train_0/target_q          | -9.895882771417252     |
| train_1/avg_q             | -7.6077188576804335    |
| train_1/current_q         | -14.804267190605923    |
| train_1/fw_bonus          | -1.0004669651389122    |
| train_1/fw_loss           | 0.0006389481844962574  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.008797091199085116   |
| train_1/q_grads_std       | 0.44337194934487345    |
| train_1/q_loss            | 8.020881194195187      |
| train_1/reward            | -1.494704474484024     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010986328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.131682013546532    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 2253.61. Rollout time: 1924.67, Training time: 328.79
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 1238086.0              |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.784413198126041     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.666797066582916     |
| train_0/fw_bonus          | -0.9999249964952469    |
| train_0/fw_loss           | 2.5677429266579566e-05 |
| train_0/mu_grads          | -0.03480997262522578   |
| train_0/mu_grads_std      | 0.31253263652324675    |
| train_0/mu_loss           | 9.577102699200122      |
| train_0/next_q            | -9.567640134736644     |
| train_0/q_grads           | 0.028526798402890564   |
| train_0/q_grads_std       | 0.23424024060368537    |
| train_0/q_loss            | 0.08669426559628376    |
| train_0/reward            | -0.8549791491619544    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1619140625           |
| train_0/target_q          | -9.819087011918443     |
| train_1/avg_q             | -7.470373095341156     |
| train_1/current_q         | -14.908256608561265    |
| train_1/fw_bonus          | -1.000678864121437     |
| train_1/fw_loss           | 0.0005821245365950744  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.008461752673611045   |
| train_1/q_grads_std       | 0.4537045381963253     |
| train_1/q_loss            | 6.146978817400895      |
| train_1/reward            | -1.4863489914001549    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.233791862493911    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 1409.99. Rollout time: 1012.61, Training time: 397.15
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 1329211.0              |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.325674076164385     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.674209218083835     |
| train_0/fw_bonus          | -0.9999555766582489    |
| train_0/fw_loss           | 1.7851883740149788e-05 |
| train_0/mu_grads          | -0.03457472454756498   |
| train_0/mu_grads_std      | 0.32202289178967475    |
| train_0/mu_loss           | 9.584706617671054      |
| train_0/next_q            | -9.576536336877142     |
| train_0/q_grads           | 0.02822289280593395    |
| train_0/q_grads_std       | 0.23611617907881738    |
| train_0/q_loss            | 0.08495150918171512    |
| train_0/reward            | -0.8548861205927096    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2563720703125        |
| train_0/target_q          | -9.826305065339236     |
| train_1/avg_q             | -7.63988904651925      |
| train_1/current_q         | -14.998471266979957    |
| train_1/fw_bonus          | -1.000604286789894     |
| train_1/fw_loss           | 0.0006021196677465923  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.007584428321570158   |
| train_1/q_grads_std       | 0.46282542273402216    |
| train_1/q_loss            | 6.5783579377788515     |
| train_1/reward            | -1.4690933629943175    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001123046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.262401956744323    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 1889.61. Rollout time: 1361.88, Training time: 527.56
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1420336.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.6374131868990505   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.70996575020778     |
| train_0/fw_bonus          | -0.9999437272548676   |
| train_0/fw_loss           | 2.088581109092047e-05 |
| train_0/mu_grads          | -0.03475282648578286  |
| train_0/mu_grads_std      | 0.3276872061192989    |
| train_0/mu_loss           | 9.622778132645793     |
| train_0/next_q            | -9.61538735660091     |
| train_0/q_grads           | 0.027805973077192903  |
| train_0/q_grads_std       | 0.23804125301539897   |
| train_0/q_loss            | 0.08438316852407361   |
| train_0/reward            | -0.8552068174249143   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2045166015625       |
| train_0/target_q          | -9.862465681072553    |
| train_1/avg_q             | -7.40339313060718     |
| train_1/current_q         | -14.777503153662764   |
| train_1/fw_bonus          | -1.0009825587272645   |
| train_1/fw_loss           | 0.0005006839157431387 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.007363328116480261  |
| train_1/q_grads_std       | 0.4715035155415535    |
| train_1/q_loss            | 7.540671004343527     |
| train_1/reward            | -1.4773238309193402   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.065205666856846   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 2324.31. Rollout time: 1481.65, Training time: 841.83
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1511461.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.160908200598707    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.604216622299138    |
| train_0/fw_bonus          | -0.9999257028102875   |
| train_0/fw_loss           | 2.549701114276104e-05 |
| train_0/mu_grads          | -0.034725346975028513 |
| train_0/mu_grads_std      | 0.3337550312280655    |
| train_0/mu_loss           | 9.520915923575767     |
| train_0/next_q            | -9.51321511385925     |
| train_0/q_grads           | 0.027522965986281633  |
| train_0/q_grads_std       | 0.23920897357165813   |
| train_0/q_loss            | 0.08375381213073585   |
| train_0/reward            | -0.8539481838743086   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.191064453125        |
| train_0/target_q          | -9.75650343297673     |
| train_1/avg_q             | -7.563231346326499    |
| train_1/current_q         | -15.152682590387949   |
| train_1/fw_bonus          | -1.0008886814117433   |
| train_1/fw_loss           | 0.0005258579061774071 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.006304911954794079  |
| train_1/q_grads_std       | 0.4758106365799904    |
| train_1/q_loss            | 7.448084303086721     |
| train_1/reward            | -1.4994397047601524   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00107421875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.447141364916405   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 2139.64. Rollout time: 1424.46, Training time: 714.26
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1602586.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.722944283893587    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.742483075225362    |
| train_0/fw_bonus          | -0.9999139189720154   |
| train_0/fw_loss           | 2.851052117875952e-05 |
| train_0/mu_grads          | -0.03520042011514306  |
| train_0/mu_grads_std      | 0.3397540159523487    |
| train_0/mu_loss           | 9.659589673999672     |
| train_0/next_q            | -9.652072451544402    |
| train_0/q_grads           | 0.02725985795259476   |
| train_0/q_grads_std       | 0.24031559601426125   |
| train_0/q_loss            | 0.08477119919080076   |
| train_0/reward            | -0.8553065381987836   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1436279296875       |
| train_0/target_q          | -9.896810815237997    |
| train_1/avg_q             | -7.479506763008435    |
| train_1/current_q         | -15.849956777182651   |
| train_1/fw_bonus          | -1.000600403547287    |
| train_1/fw_loss           | 0.0006031684453773778 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.0062694872613064945 |
| train_1/q_grads_std       | 0.47879029661417005   |
| train_1/q_loss            | 8.36691504176896      |
| train_1/reward            | -1.512754980259342    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -16.160070409946847   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 1551.17. Rollout time: 1128.42, Training time: 422.58
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1693025.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.03171181253866      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.729079761080708     |
| train_0/fw_bonus          | -0.9998336344957351    |
| train_0/fw_loss           | 4.9057362048188224e-05 |
| train_0/mu_grads          | -0.035240466333925725  |
| train_0/mu_grads_std      | 0.34610274210572245    |
| train_0/mu_loss           | 9.649883259780065      |
| train_0/next_q            | -9.640135356521602     |
| train_0/q_grads           | 0.02686506914906204    |
| train_0/q_grads_std       | 0.2415815070271492     |
| train_0/q_loss            | 0.08520652073510368    |
| train_0/reward            | -0.8553988988962373    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0815673828125        |
| train_0/target_q          | -9.884151768669714     |
| train_1/avg_q             | -7.827012613783955     |
| train_1/current_q         | -16.509494893608196    |
| train_1/fw_bonus          | -0.9997268885374069    |
| train_1/fw_loss           | 0.0008374128665309399  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2675.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0063358090468682345  |
| train_1/q_grads_std       | 0.4854033775627613     |
| train_1/q_loss            | 7.034122067408239      |
| train_1/reward            | -1.4999904824609984    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001123046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.819141849648506    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 1399.35. Rollout time: 984.61, Training time: 414.51
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1784150.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.154827168368126     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.815963381739568     |
| train_0/fw_bonus          | -0.9998773545026779    |
| train_0/fw_loss           | 3.7867406217628743e-05 |
| train_0/mu_grads          | -0.03580941846594214   |
| train_0/mu_grads_std      | 0.35085434690117834    |
| train_0/mu_loss           | 9.739357684518946      |
| train_0/next_q            | -9.727490337467511     |
| train_0/q_grads           | 0.026750771049410104   |
| train_0/q_grads_std       | 0.24233697764575482    |
| train_0/q_loss            | 0.08628360931976657    |
| train_0/reward            | -0.8563228124417946    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.16806640625          |
| train_0/target_q          | -9.970577025536354     |
| train_1/avg_q             | -7.560579276876891     |
| train_1/current_q         | -17.24305560342277     |
| train_1/fw_bonus          | -0.9997275620698929    |
| train_1/fw_loss           | 0.0008372311887796969  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.005178638827055692   |
| train_1/q_grads_std       | 0.4934101618826389     |
| train_1/q_loss            | 5.9737045246777285     |
| train_1/reward            | -1.5227021714585134    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00126953125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -17.536299339427273    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 1433.41. Rollout time: 1008.24, Training time: 424.87
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 1875275.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.449467442447121     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.705568146535583     |
| train_0/fw_bonus          | -0.9998659759759903    |
| train_0/fw_loss           | 4.0781155212243904e-05 |
| train_0/mu_grads          | -0.03559046648442745   |
| train_0/mu_grads_std      | 0.35533594265580176    |
| train_0/mu_loss           | 9.629178663427524      |
| train_0/next_q            | -9.618019128681443     |
| train_0/q_grads           | 0.026634537475183608   |
| train_0/q_grads_std       | 0.24316264502704144    |
| train_0/q_loss            | 0.08555443176647906    |
| train_0/reward            | -0.8554414690748672    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1436279296875        |
| train_0/target_q          | -9.859055081335216     |
| train_1/avg_q             | -7.400960197349365     |
| train_1/current_q         | -17.793973696127786    |
| train_1/fw_bonus          | -0.9991407617926598    |
| train_1/fw_loss           | 0.0009945955884177239  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.004617990751285106   |
| train_1/q_grads_std       | 0.5009370058774948     |
| train_1/q_loss            | 5.482652231083874      |
| train_1/reward            | -1.5195582061031019    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001220703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -18.08419004204061     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 1403.88. Rollout time: 989.51, Training time: 414.22
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 1966400.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.250700201181796    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.668196761544738    |
| train_0/fw_bonus          | -0.9998790234327316   |
| train_0/fw_loss           | 3.744026330423367e-05 |
| train_0/mu_grads          | -0.03711993433535099  |
| train_0/mu_grads_std      | 0.3578418128192425    |
| train_0/mu_loss           | 9.594656096950212     |
| train_0/next_q            | -9.581021316796798    |
| train_0/q_grads           | 0.026523852394893764  |
| train_0/q_grads_std       | 0.24487615525722503   |
| train_0/q_loss            | 0.08483137973606679   |
| train_0/reward            | -0.8547859785350738   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1680908203125       |
| train_0/target_q          | -9.819297660416968    |
| train_1/avg_q             | -7.561156696977845    |
| train_1/current_q         | -18.157149482565835   |
| train_1/fw_bonus          | -0.9997317358851433   |
| train_1/fw_loss           | 0.0008361166561371647 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.003933032596250996  |
| train_1/q_grads_std       | 0.5074148595333099    |
| train_1/q_loss            | 5.75618425819699      |
| train_1/reward            | -1.5173891272279434   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001318359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -18.4508847326967     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 1442.31. Rollout time: 1020.04, Training time: 421.97
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 2057525.0              |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.385053696389484     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.665896814659728     |
| train_0/fw_bonus          | -0.9998807370662689    |
| train_0/fw_loss           | 3.7001750570198055e-05 |
| train_0/mu_grads          | -0.03845299407839775   |
| train_0/mu_grads_std      | 0.3610056981444359     |
| train_0/mu_loss           | 9.588177653649655      |
| train_0/next_q            | -9.576538975600593     |
| train_0/q_grads           | 0.026510973880067467   |
| train_0/q_grads_std       | 0.24642273262143136    |
| train_0/q_loss            | 0.08415186353448945    |
| train_0/reward            | -0.8554891681662411    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1655029296875        |
| train_0/target_q          | -9.818990475554457     |
| train_1/avg_q             | -7.421905889784756     |
| train_1/current_q         | -17.358895997878456    |
| train_1/fw_bonus          | -1.0002385169267654    |
| train_1/fw_loss           | 0.0007002146507147699  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0030688595841638746  |
| train_1/q_grads_std       | 0.513999791443348      |
| train_1/q_loss            | 5.1376287027692245     |
| train_1/reward            | -1.5070331270108       |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001513671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -17.653059494198306    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 1435.14. Rollout time: 1005.97, Training time: 428.96
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 2148650.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.526257529376959     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.67223327852243      |
| train_0/fw_bonus          | -0.9999350175261498    |
| train_0/fw_loss           | 2.3114159398573973e-05 |
| train_0/mu_grads          | -0.04054248491302133   |
| train_0/mu_grads_std      | 0.3636480629444122     |
| train_0/mu_loss           | 9.59632804882414       |
| train_0/next_q            | -9.586056169973585     |
| train_0/q_grads           | 0.026672311360016465   |
| train_0/q_grads_std       | 0.248559894785285      |
| train_0/q_loss            | 0.0827060911935222     |
| train_0/reward            | -0.8545899339471361    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2022705078125        |
| train_0/target_q          | -9.824550074267039     |
| train_1/avg_q             | -7.464923731576084     |
| train_1/current_q         | -16.432396419030255    |
| train_1/fw_bonus          | -1.0005615115165711    |
| train_1/fw_loss           | 0.0006135950825409964  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.002436015161219984   |
| train_1/q_grads_std       | 0.5209825813770295     |
| train_1/q_loss            | 5.232984046708889      |
| train_1/reward            | -1.5055297746323049    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013427734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.734241688694816    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 1439.09. Rollout time: 1012.09, Training time: 426.56
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 2239775.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.625553274138028    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.620751415465907    |
| train_0/fw_bonus          | -0.9999470353126526   |
| train_0/fw_loss           | 2.003708975735208e-05 |
| train_0/mu_grads          | -0.04087079064920544  |
| train_0/mu_grads_std      | 0.3672516480088234    |
| train_0/mu_loss           | 9.541261310164192     |
| train_0/next_q            | -9.531982461586395    |
| train_0/q_grads           | 0.025921672862023116  |
| train_0/q_grads_std       | 0.25266311317682266   |
| train_0/q_loss            | 0.08182017464105211   |
| train_0/reward            | -0.8544646764814388   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.244677734375        |
| train_0/target_q          | -9.77195917635403     |
| train_1/avg_q             | -7.52313689290578     |
| train_1/current_q         | -15.765499290043994   |
| train_1/fw_bonus          | -1.0007972091436386   |
| train_1/fw_loss           | 0.0005503882421180606 |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | 0.0022131111880298706 |
| train_1/q_grads_std       | 0.5252202689647675    |
| train_1/q_loss            | 5.042258993117503     |
| train_1/reward            | -1.491839360744052    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -16.05517529824406    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 1461.94. Rollout time: 1033.50, Training time: 428.23
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 25                     |
| policy/steps              | 2330900.0              |
| test/episodes             | 650.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.427698876186539     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.732299727374677     |
| train_0/fw_bonus          | -0.9999483242630959    |
| train_0/fw_loss           | 1.9709707498805073e-05 |
| train_0/mu_grads          | -0.04042779542505741   |
| train_0/mu_grads_std      | 0.37071970477700233    |
| train_0/mu_loss           | 9.655643764629025      |
| train_0/next_q            | -9.647886682224179     |
| train_0/q_grads           | 0.02567590926773846    |
| train_0/q_grads_std       | 0.25531288608908653    |
| train_0/q_loss            | 0.08225386120036302    |
| train_0/reward            | -0.854813536349684     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2239501953125        |
| train_0/target_q          | -9.886854116522233     |
| train_1/avg_q             | -7.566698497953016     |
| train_1/current_q         | -15.21515409998826     |
| train_1/fw_bonus          | -1.0010008931159973    |
| train_1/fw_loss           | 0.0004957689176080749  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.002148668508743867   |
| train_1/q_grads_std       | 0.5293384760618209     |
| train_1/q_loss            | 5.266620402393961      |
| train_1/reward            | -1.5035033485430176    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010009765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.488672782136774    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 1482.40. Rollout time: 1038.71, Training time: 443.42
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 2422025.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.321303208903149     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.601021766045179     |
| train_0/fw_bonus          | -0.9999561741948128    |
| train_0/fw_loss           | 1.7699841691865004e-05 |
| train_0/mu_grads          | -0.04089220575988293   |
| train_0/mu_grads_std      | 0.37418784499168395    |
| train_0/mu_loss           | 9.52390604682613       |
| train_0/next_q            | -9.516234132345977     |
| train_0/q_grads           | 0.025282436003908514   |
| train_0/q_grads_std       | 0.2576530046761036     |
| train_0/q_loss            | 0.07949447764854364    |
| train_0/reward            | -0.8535560000978876    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.22041015625          |
| train_0/target_q          | -9.752473452608783     |
| train_1/avg_q             | -7.445912260070538     |
| train_1/current_q         | -14.728110215312403    |
| train_1/fw_bonus          | -1.0012769013643266    |
| train_1/fw_loss           | 0.00042174971313215794 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0018427410279400647  |
| train_1/q_grads_std       | 0.5333161890506745     |
| train_1/q_loss            | 13.04988710399877      |
| train_1/reward            | -1.493712802779919     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.013765048873676    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 1457.90. Rollout time: 1012.62, Training time: 445.09
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 2513150.0              |
| test/episodes             | 700.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5206039375492875    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.68970491378855      |
| train_0/fw_bonus          | -0.9999706313014031    |
| train_0/fw_loss           | 1.4001092074522603e-05 |
| train_0/mu_grads          | -0.04114587111398578   |
| train_0/mu_grads_std      | 0.3771159045398235     |
| train_0/mu_loss           | 9.612157103347268      |
| train_0/next_q            | -9.604620831230386     |
| train_0/q_grads           | 0.024949073465541004   |
| train_0/q_grads_std       | 0.2603358246386051     |
| train_0/q_loss            | 0.08221288728124128    |
| train_0/reward            | -0.8547081990822335    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2152099609375        |
| train_0/target_q          | -9.843458241791382     |
| train_1/avg_q             | -7.392135905903145     |
| train_1/current_q         | -14.818391291247355    |
| train_1/fw_bonus          | -1.001335260272026     |
| train_1/fw_loss           | 0.00040610371288494205 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0021632423799019308  |
| train_1/q_grads_std       | 0.5373325929045677     |
| train_1/q_loss            | 5.231908648137444      |
| train_1/reward            | -1.508844451479672     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.090912322573427    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 1447.08. Rollout time: 1006.00, Training time: 440.75
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 2604275.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.436397582501909     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.498377642119545     |
| train_0/fw_bonus          | -0.9999773725867271    |
| train_0/fw_loss           | 1.2275728795430042e-05 |
| train_0/mu_grads          | -0.04241840485483408   |
| train_0/mu_grads_std      | 0.37893616408109665    |
| train_0/mu_loss           | 9.422786301871957      |
| train_0/next_q            | -9.414155131369503     |
| train_0/q_grads           | 0.024725754046812654   |
| train_0/q_grads_std       | 0.2612051129341125     |
| train_0/q_loss            | 0.07932830435691       |
| train_0/reward            | -0.8525648191251094    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2333251953125        |
| train_0/target_q          | -9.648624483456567     |
| train_1/avg_q             | -7.465897724397973     |
| train_1/current_q         | -14.89382899670515     |
| train_1/fw_bonus          | -1.0014168351888657    |
| train_1/fw_loss           | 0.0003842220816295594  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.0018802010308718309  |
| train_1/q_grads_std       | 0.541927057504654      |
| train_1/q_loss            | 7.8626031377031325     |
| train_1/reward            | -1.5107000825184513    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.160597543455959    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 1185.40. Rollout time: 846.73, Training time: 338.52
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 2695400.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.632792805298566     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.741522818895811     |
| train_0/fw_bonus          | -0.9999768123030662    |
| train_0/fw_loss           | 1.2418675601111317e-05 |
| train_0/mu_grads          | -0.041765347495675086  |
| train_0/mu_grads_std      | 0.3810220994055271     |
| train_0/mu_loss           | 9.662824253651163      |
| train_0/next_q            | -9.65490441382876      |
| train_0/q_grads           | 0.024546870356425644   |
| train_0/q_grads_std       | 0.26393323540687563    |
| train_0/q_loss            | 0.0816086638696106     |
| train_0/reward            | -0.8551278770959471    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.203076171875         |
| train_0/target_q          | -9.89611457472385      |
| train_1/avg_q             | -7.50947270153152      |
| train_1/current_q         | -14.9964821644828      |
| train_1/fw_bonus          | -1.0015367329120637    |
| train_1/fw_loss           | 0.0003520663274684921  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.001475076944916509   |
| train_1/q_grads_std       | 0.546469597518444      |
| train_1/q_loss            | 3.9970113334290174     |
| train_1/reward            | -1.4952016350944177    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.274298314781925    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 1032.33. Rollout time: 747.70, Training time: 284.48
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2786525.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.540055861721529     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.78607391566689      |
| train_0/fw_bonus          | -0.9999764665961266    |
| train_0/fw_loss           | 1.2509708039942779e-05 |
| train_0/mu_grads          | -0.042015521228313445  |
| train_0/mu_grads_std      | 0.3836058177053928     |
| train_0/mu_loss           | 9.704173829851493      |
| train_0/next_q            | -9.695791024728127     |
| train_0/q_grads           | 0.024349130177870392   |
| train_0/q_grads_std       | 0.26657743081450463    |
| train_0/q_loss            | 0.08141483635839128    |
| train_0/reward            | -0.8565436254852102    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2149169921875        |
| train_0/target_q          | -9.941032815597277     |
| train_1/avg_q             | -7.53568040581288      |
| train_1/current_q         | -14.976631553097974    |
| train_1/fw_bonus          | -1.0016143590211868    |
| train_1/fw_loss           | 0.00033124896581284704 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | 0.00026492488468647933 |
| train_1/q_grads_std       | 0.5500056222081184     |
| train_1/q_loss            | 3.3775772676514846     |
| train_1/reward            | -1.5001121508685173    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005615234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.234635100087274    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 1043.44. Rollout time: 750.90, Training time: 292.31
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 2877650.0              |
| test/episodes             | 800.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5387977121014345    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.720249543347663     |
| train_0/fw_bonus          | -0.9999658152461052    |
| train_0/fw_loss           | 1.5236326396461663e-05 |
| train_0/mu_grads          | -0.04277132721617818   |
| train_0/mu_grads_std      | 0.3857259161770344     |
| train_0/mu_loss           | 9.641068656208484      |
| train_0/next_q            | -9.633173017113247     |
| train_0/q_grads           | 0.02408871348015964    |
| train_0/q_grads_std       | 0.2690356485545635     |
| train_0/q_loss            | 0.07971433236538607    |
| train_0/reward            | -0.8550280645024031    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.26611328125          |
| train_0/target_q          | -9.874690822763611     |
| train_1/avg_q             | -7.506046909154496     |
| train_1/current_q         | -14.9161239946767      |
| train_1/fw_bonus          | -1.0017018020153046    |
| train_1/fw_loss           | 0.00030780269516981205 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.0002585089991043787 |
| train_1/q_grads_std       | 0.5556072413921356     |
| train_1/q_loss            | 5.404534236302105      |
| train_1/reward            | -1.519800527281768     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000634765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.185847890563025    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 1039.97. Rollout time: 755.82, Training time: 284.01
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-------------------------------------------------------
| epoch                     | 32                      |
| policy/steps              | 2968775.0               |
| test/episodes             | 825.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.592391463989877      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.676982403454707      |
| train_0/fw_bonus          | -0.999970979988575      |
| train_0/fw_loss           | 1.3910548977946746e-05  |
| train_0/mu_grads          | -0.042178311944007875   |
| train_0/mu_grads_std      | 0.3884988822042942      |
| train_0/mu_loss           | 9.595478321322961       |
| train_0/next_q            | -9.586501697216482      |
| train_0/q_grads           | 0.023850296484306456    |
| train_0/q_grads_std       | 0.2712157353758812      |
| train_0/q_loss            | 0.0795412673312692      |
| train_0/reward            | -0.8553859547522734     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.282373046875          |
| train_0/target_q          | -9.829533910341365      |
| train_1/avg_q             | -7.50350751196377       |
| train_1/current_q         | -14.93636886974079      |
| train_1/fw_bonus          | -1.0011448115110397     |
| train_1/fw_loss           | 0.0004571715398924425   |
| train_1/mu_grads          | 0.014354497194290161    |
| train_1/mu_grads_std      | 0.1595584601163864      |
| train_1/mu_loss           | 28.0                    |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -27.0                   |
| train_1/q_grads           | -0.00024431552992609795 |
| train_1/q_grads_std       | 0.5606061697006226      |
| train_1/q_loss            | 3.3748705996236765      |
| train_1/reward            | -1.4989726241619792     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001123046875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -15.202487760880734     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 1040.57. Rollout time: 746.54, Training time: 293.88
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 3059900.0              |
| test/episodes             | 850.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.44243503030804      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.630511079791557     |
| train_0/fw_bonus          | -0.9999815598130226    |
| train_0/fw_loss           | 1.1203101507817337e-05 |
| train_0/mu_grads          | -0.04232125962153077   |
| train_0/mu_grads_std      | 0.39108503982424736    |
| train_0/mu_loss           | 9.54938146043435       |
| train_0/next_q            | -9.54182577503462      |
| train_0/q_grads           | 0.02367040254175663    |
| train_0/q_grads_std       | 0.2729052513837814     |
| train_0/q_loss            | 0.07832812530689935    |
| train_0/reward            | -0.854484466771828     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.203466796875         |
| train_0/target_q          | -9.78240232141258      |
| train_1/avg_q             | -7.52164095843417      |
| train_1/current_q         | -15.049678008219667    |
| train_1/fw_bonus          | -1.0015745878219604    |
| train_1/fw_loss           | 0.00034192014136351644 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.0016115695529151709 |
| train_1/q_grads_std       | 0.5653535842895507     |
| train_1/q_loss            | 5.089765719853539      |
| train_1/reward            | -1.5111907049547881    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.322587189329795    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 1030.08. Rollout time: 733.56, Training time: 296.41
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 3151025.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.230682304121526    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.744317701933577    |
| train_0/fw_bonus          | -0.9999829068779945   |
| train_0/fw_loss           | 1.086000180521296e-05 |
| train_0/mu_grads          | -0.04348575109615922  |
| train_0/mu_grads_std      | 0.39391068816185      |
| train_0/mu_loss           | 9.664946738988013     |
| train_0/next_q            | -9.65723139566422     |
| train_0/q_grads           | 0.023689115419983864  |
| train_0/q_grads_std       | 0.27332639694213867   |
| train_0/q_loss            | 0.07871149408113842   |
| train_0/reward            | -0.8552728261740412   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2280029296875       |
| train_0/target_q          | -9.89775775068075     |
| train_1/avg_q             | -7.474612122492172    |
| train_1/current_q         | -15.104575963500935   |
| train_1/fw_bonus          | -1.0015213370323182   |
| train_1/fw_loss           | 0.000356198163353838  |
| train_1/mu_grads          | 0.014354497194290161  |
| train_1/mu_grads_std      | 0.1595584601163864    |
| train_1/mu_loss           | 28.0                  |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -27.0                 |
| train_1/q_grads           | -0.003625356202246621 |
| train_1/q_grads_std       | 0.5696296751499176    |
| train_1/q_loss            | 5.224421692421197     |
| train_1/reward            | -1.5130428622476757   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0008056640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -15.36772108490393    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 1075.60. Rollout time: 773.13, Training time: 302.30
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 3242150.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.45101940338198      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.68538353464154      |
| train_0/fw_bonus          | -0.9999434113502502    |
| train_0/fw_loss           | 2.0967086629752885e-05 |
| train_0/mu_grads          | -0.044202913623303176  |
| train_0/mu_grads_std      | 0.3968473434448242     |
| train_0/mu_loss           | 9.608536857742589      |
| train_0/next_q            | -9.601686349851011     |
| train_0/q_grads           | 0.023731618514284493   |
| train_0/q_grads_std       | 0.2739015564322472     |
| train_0/q_loss            | 0.08001764904249212    |
| train_0/reward            | -0.8544192256507813    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1885986328125        |
| train_0/target_q          | -9.839165855260855     |
| train_1/avg_q             | -7.4079753642136215    |
| train_1/current_q         | -15.197909318522488    |
| train_1/fw_bonus          | -1.001472333073616     |
| train_1/fw_loss           | 0.00036934310046490284 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.004371410654857755  |
| train_1/q_grads_std       | 0.5727461457252503     |
| train_1/q_loss            | 4.340489083198704      |
| train_1/reward            | -1.4909907186214695    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.422542476433975    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 1045.26. Rollout time: 749.23, Training time: 295.84
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 3333275.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.717286577051448     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.837397462028816     |
| train_0/fw_bonus          | -0.9999354496598244    |
| train_0/fw_loss           | 2.3004330410003603e-05 |
| train_0/mu_grads          | -0.04376207431778312   |
| train_0/mu_grads_std      | 0.4005174770951271     |
| train_0/mu_loss           | 9.759455702849099      |
| train_0/next_q            | -9.75149029182396      |
| train_0/q_grads           | 0.023736648401245473   |
| train_0/q_grads_std       | 0.2743757240474224     |
| train_0/q_loss            | 0.08032908242406933    |
| train_0/reward            | -0.8563175512754242    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2111572265625        |
| train_0/target_q          | -9.991973884757282     |
| train_1/avg_q             | -7.476973696813157     |
| train_1/current_q         | -15.568863124733975    |
| train_1/fw_bonus          | -1.001435822248459     |
| train_1/fw_loss           | 0.00037913367705186827 |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.005472605908289551  |
| train_1/q_grads_std       | 0.5764583826065064     |
| train_1/q_loss            | 3.656572675943862      |
| train_1/reward            | -1.4844325752404983    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -15.823607868209255    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 8725.27. Rollout time: 1986.45, Training time: 6738.60
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|100
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 3423103.0              |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.316049913060605     |
| test_1/n_subgoals         | 628.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.731229573723867     |
| train_0/fw_bonus          | -0.9998631998896599    |
| train_0/fw_loss           | 4.1490848752800956e-05 |
| train_0/mu_grads          | -0.044952450599521396  |
| train_0/mu_grads_std      | 0.40397702530026436    |
| train_0/mu_loss           | 9.65289870152199       |
| train_0/next_q            | -9.641918274226777     |
| train_0/q_grads           | 0.023548663826659322   |
| train_0/q_grads_std       | 0.2752253532409668     |
| train_0/q_loss            | 0.08205176621879058    |
| train_0/reward            | -0.8560436365645728    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.181396484375         |
| train_0/target_q          | -9.885849740490274     |
| train_1/avg_q             | -7.811536149926518     |
| train_1/current_q         | -16.465296683307514    |
| train_1/fw_bonus          | -1.0002629652619361    |
| train_1/fw_loss           | 0.0006936575853615067  |
| train_1/mu_grads          | 0.014354497194290161   |
| train_1/mu_grads_std      | 0.1595584601163864     |
| train_1/mu_loss           | 28.0                   |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -27.0                  |
| train_1/q_grads           | -0.006609822809696198  |
| train_1/q_grads_std       | 0.5854728013277054     |
| train_1/q_loss            | 6.691761559882323      |
| train_1/reward            | -1.5125751465573558    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0011474609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -16.690899365307363    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 38
