Starting process id: 55098
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f833165d8c0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 797.93. Rollout time: 471.83, Training time: 326.01
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 81203.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4350856738689028    |
| test_1/avg_q              | -7.500406202157291     |
| test_1/n_subgoals         | 4164.0                 |
| test_1/subgoal_succ_rate  | 0.877521613832853      |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.11                   |
| train_0/avg_q             | -3.115156716814017     |
| train_0/current_q         | -4.525799982321027     |
| train_0/fw_bonus          | -0.9987601444125176    |
| train_0/fw_loss           | 0.00033751430455595253 |
| train_0/mu_grads          | 0.0012246189930010588  |
| train_0/mu_grads_std      | 0.15641459152102472    |
| train_0/mu_loss           | 4.397069446581051      |
| train_0/next_q            | -4.350835205841969     |
| train_0/q_grads           | 0.0153423388954252     |
| train_0/q_grads_std       | 0.1409298688173294     |
| train_0/q_loss            | 0.6856156261512625     |
| train_0/reward            | -0.6365735807794408    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0033447265625        |
| train_0/target_q          | -4.46110489335223      |
| train_1/avg_q             | -10.287302624768177    |
| train_1/current_q         | -11.022525744479545    |
| train_1/fw_bonus          | -0.9967284083366394    |
| train_1/fw_loss           | 0.001610413461457938   |
| train_1/mu_grads          | 0.006519198103342205   |
| train_1/mu_grads_std      | 0.17897510156035423    |
| train_1/mu_loss           | 11.5463795082252       |
| train_1/n_subgoals        | 2577.0                 |
| train_1/next_q            | -11.617694060747121    |
| train_1/q_grads           | 0.013008162681944668   |
| train_1/q_grads_std       | 0.20462921187281607    |
| train_1/q_loss            | 19.184302754167582     |
| train_1/reward            | -2.4193481160520607    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0058837890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11059371362048893    |
| train_1/target_q          | -10.991114336483374    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_0.pkl ...
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 776.15. Rollout time: 513.56, Training time: 262.49
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 157530.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.4243395724185948   |
| test_1/avg_q              | -6.738979868173974    |
| test_1/n_subgoals         | 1424.0                |
| test_1/subgoal_succ_rate  | 0.5470505617977528    |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.22                  |
| train_0/avg_q             | -5.348353436586981    |
| train_0/current_q         | -4.970944627452016    |
| train_0/fw_bonus          | -0.9986270144581795   |
| train_0/fw_loss           | 0.0003731489661731757 |
| train_0/mu_grads          | -0.004487649002112448 |
| train_0/mu_grads_std      | 0.18604678474366665   |
| train_0/mu_loss           | 4.822646083077663     |
| train_0/next_q            | -4.781883836169314    |
| train_0/q_grads           | 0.01712365630082786   |
| train_0/q_grads_std       | 0.16617544889450073   |
| train_0/q_loss            | 0.5780684175378216    |
| train_0/reward            | -0.6487900555526721   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00244140625         |
| train_0/target_q          | -4.951532751209129    |
| train_1/avg_q             | -15.523597506233273   |
| train_1/current_q         | -9.519862216830782    |
| train_1/fw_bonus          | -0.9970696344971657   |
| train_1/fw_loss           | 0.0015296413737814873 |
| train_1/mu_grads          | 0.004094018251635134  |
| train_1/mu_grads_std      | 0.24433702565729618   |
| train_1/mu_loss           | 9.473877310878974     |
| train_1/n_subgoals        | 2341.0                |
| train_1/next_q            | -9.530251393250031    |
| train_1/q_grads           | 0.0019333289499627426 |
| train_1/q_grads_std       | 0.24652039334177972   |
| train_1/q_loss            | 11.689271091939386    |
| train_1/reward            | -2.433862136056632    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.006787109375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10636480136693721   |
| train_1/target_q          | -9.534827194467466    |
-----------------------------------------------------
Training epoch 2
Time for epoch 2: 711.86. Rollout time: 468.09, Training time: 243.67
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 233503.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.31750808588561386  |
| test_1/avg_q              | -20.50603550205903    |
| test_1/n_subgoals         | 677.0                 |
| test_1/subgoal_succ_rate  | 0.0029542097488921715 |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.28                  |
| train_0/avg_q             | -5.511680399571933    |
| train_0/current_q         | -2.944068312082589    |
| train_0/fw_bonus          | -0.9984685972332954   |
| train_0/fw_loss           | 0.000415553185302997  |
| train_0/mu_grads          | -0.004182796081295237 |
| train_0/mu_grads_std      | 0.20992192327976228   |
| train_0/mu_loss           | 2.82801636011792      |
| train_0/next_q            | -2.89064887235987     |
| train_0/q_grads           | 0.018985060276463628  |
| train_0/q_grads_std       | 0.18406675904989242   |
| train_0/q_loss            | 1.0726178540494087    |
| train_0/reward            | -0.6731584107528761   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00048828125         |
| train_0/target_q          | -3.2478649407722004   |
| train_1/avg_q             | -13.567558833603846   |
| train_1/current_q         | -9.44745916925479     |
| train_1/fw_bonus          | -0.9959197625517845   |
| train_1/fw_loss           | 0.0018018257047515362 |
| train_1/mu_grads          | 0.003619340236764401  |
| train_1/mu_grads_std      | 0.2601341277360916    |
| train_1/mu_loss           | 9.319826403219157     |
| train_1/n_subgoals        | 2317.0                |
| train_1/next_q            | -9.337774794149567    |
| train_1/q_grads           | -0.00173268195358105  |
| train_1/q_grads_std       | 0.2737385414540768    |
| train_1/q_loss            | 9.180134826175763     |
| train_1/reward            | -2.4118766676212546   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007275390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10876132930513595   |
| train_1/target_q          | -9.473250726333239    |
-----------------------------------------------------
Training epoch 3
Time for epoch 3: 1901.81. Rollout time: 375.02, Training time: 1526.69
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 303646.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.8664430344935388   |
| test_1/avg_q              | -11.921456995169006   |
| test_1/n_subgoals         | 6853.0                |
| test_1/subgoal_succ_rate  | 0.9390048154093098    |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.31                  |
| train_0/avg_q             | -4.858697688148687    |
| train_0/current_q         | -5.502489503158745    |
| train_0/fw_bonus          | -0.9985352858901024   |
| train_0/fw_loss           | 0.0003977052620030008 |
| train_0/mu_grads          | -0.009696287359111011 |
| train_0/mu_grads_std      | 0.23820214979350568   |
| train_0/mu_loss           | 5.30948132238418      |
| train_0/next_q            | -5.226489831891523    |
| train_0/q_grads           | 0.01975060091353953   |
| train_0/q_grads_std       | 0.19171004146337509   |
| train_0/q_loss            | 0.42009536182534896   |
| train_0/reward            | -0.6749878240952967   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.001123046875        |
| train_0/target_q          | -5.452492212482194    |
| train_1/avg_q             | -17.42662657622172    |
| train_1/current_q         | -10.369737491151074   |
| train_1/fw_bonus          | -0.9966735184192658   |
| train_1/fw_loss           | 0.0016234058508416637 |
| train_1/mu_grads          | 0.0036472597799729555 |
| train_1/mu_grads_std      | 0.28133788555860517   |
| train_1/mu_loss           | 11.386846537219611    |
| train_1/n_subgoals        | 2307.0                |
| train_1/next_q            | -11.37874905835729    |
| train_1/q_grads           | -0.005253956583328545 |
| train_1/q_grads_std       | 0.30403814986348154   |
| train_1/q_loss            | 16.546825343555813    |
| train_1/reward            | -2.4245712120497047   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007568359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.22280017338534894   |
| train_1/target_q          | -10.40627085889012    |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 4
Time for epoch 4: 592.24. Rollout time: 349.12, Training time: 243.01
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 361804.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.8194705941187581    |
| test_1/avg_q              | -11.578885223243125    |
| test_1/n_subgoals         | 9171.0                 |
| test_1/subgoal_succ_rate  | 0.9668520335841239     |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.45                   |
| train_0/avg_q             | -10.46060808668026     |
| train_0/current_q         | -5.585587426138771     |
| train_0/fw_bonus          | -0.9984390869736671    |
| train_0/fw_loss           | 0.00042345464244135654 |
| train_0/mu_grads          | -0.017539807269349693  |
| train_0/mu_grads_std      | 0.2612467683851719     |
| train_0/mu_loss           | 5.397540795649062      |
| train_0/next_q            | -5.299163428842418     |
| train_0/q_grads           | 0.01949300682172179    |
| train_0/q_grads_std       | 0.19799690805375575    |
| train_0/q_loss            | 0.45920784548374793    |
| train_0/reward            | -0.681665435355535     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.001171875            |
| train_0/target_q          | -5.509871224024299     |
| train_1/avg_q             | -14.64655928597142     |
| train_1/current_q         | -10.006401866946153    |
| train_1/fw_bonus          | -0.9965342864394188    |
| train_1/fw_loss           | 0.0016563615208724514  |
| train_1/mu_grads          | 0.0026271665119566023  |
| train_1/mu_grads_std      | 0.3035503178834915     |
| train_1/mu_loss           | 10.799938647127922     |
| train_1/n_subgoals        | 2124.0                 |
| train_1/next_q            | -10.752469145969041    |
| train_1/q_grads           | -0.008219088427722454  |
| train_1/q_grads_std       | 0.3240496151149273     |
| train_1/q_loss            | 14.210156220654431     |
| train_1/reward            | -2.3058474389217736    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00693359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4063088512241055     |
| train_1/target_q          | -10.00422465763817     |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 5
Time for epoch 5: 640.14. Rollout time: 379.56, Training time: 260.40
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 419429.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.8522576086330735    |
| test_1/avg_q              | -11.586088583853616    |
| test_1/n_subgoals         | 1468.0                 |
| test_1/subgoal_succ_rate  | 0.5626702997275205     |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.54                   |
| train_0/avg_q             | -10.089570664621146    |
| train_0/current_q         | -5.525903812914935     |
| train_0/fw_bonus          | -0.9985084518790245    |
| train_0/fw_loss           | 0.00040488546655979005 |
| train_0/mu_grads          | -0.028350090608000755  |
| train_0/mu_grads_std      | 0.28436858877539634    |
| train_0/mu_loss           | 5.446644701071089      |
| train_0/next_q            | -5.307314403146519     |
| train_0/q_grads           | 0.017374811647459864   |
| train_0/q_grads_std       | 0.2057785265147686     |
| train_0/q_loss            | 0.767383942540397      |
| train_0/reward            | -0.6949396141215403    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0018310546875        |
| train_0/target_q          | -5.440241678250389     |
| train_1/avg_q             | -14.313149403289424    |
| train_1/current_q         | -9.874089870155345     |
| train_1/fw_bonus          | -0.9956272721290589    |
| train_1/fw_loss           | 0.0018710559903411194  |
| train_1/mu_grads          | 0.001838634256273508   |
| train_1/mu_grads_std      | 0.3202322870492935     |
| train_1/mu_loss           | 10.554393043953345     |
| train_1/n_subgoals        | 2057.0                 |
| train_1/next_q            | -10.520568940600239    |
| train_1/q_grads           | -0.010552062909118832  |
| train_1/q_grads_std       | 0.33984398394823073    |
| train_1/q_loss            | 12.794144079540512     |
| train_1/reward            | -2.246770592008397     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006640625            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.39183276616431695    |
| train_1/target_q          | -9.8748913408046       |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 6
Time for epoch 6: 594.56. Rollout time: 358.69, Training time: 235.77
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 480786.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -5.554240257110602    |
| test_1/avg_q              | -18.886269916991328   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.48                  |
| train_0/avg_q             | -9.46612251399244     |
| train_0/current_q         | -4.154021900807768    |
| train_0/fw_bonus          | -0.9985272884368896   |
| train_0/fw_loss           | 0.0003998432177468203 |
| train_0/mu_grads          | -0.03827987564727664  |
| train_0/mu_grads_std      | 0.3051140375435352    |
| train_0/mu_loss           | 3.9757924838034255    |
| train_0/next_q            | -3.891814759689306    |
| train_0/q_grads           | 0.01786605454981327   |
| train_0/q_grads_std       | 0.21572827287018298   |
| train_0/q_loss            | 0.6794265388418408    |
| train_0/reward            | -0.7003459345556621   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.001708984375        |
| train_0/target_q          | -4.2253885951601635   |
| train_1/avg_q             | -14.940434401301601   |
| train_1/current_q         | -9.72381563121086     |
| train_1/fw_bonus          | -0.9950811848044395   |
| train_1/fw_loss           | 0.00200032324064523   |
| train_1/mu_grads          | 0.0013924949074862526 |
| train_1/mu_grads_std      | 0.3401954747736454    |
| train_1/mu_loss           | 10.081721587117482    |
| train_1/n_subgoals        | 2025.0                |
| train_1/next_q            | -9.994173381848245    |
| train_1/q_grads           | -0.01196921314112842  |
| train_1/q_grads_std       | 0.3561352573335171    |
| train_1/q_loss            | 11.340772834663047    |
| train_1/reward            | -2.2176484689862264   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0068115234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2948148148148148    |
| train_1/target_q          | -9.718629252464675    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 7
Time for epoch 7: 674.62. Rollout time: 417.69, Training time: 256.85
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 550015.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.8583547344793747    |
| test_1/avg_q              | -10.740727442158864    |
| test_1/n_subgoals         | 682.0                  |
| test_1/subgoal_succ_rate  | 0.011730205278592375   |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.42                   |
| train_0/avg_q             | -8.60338987066365      |
| train_0/current_q         | -5.130229196625484     |
| train_0/fw_bonus          | -0.998469166457653     |
| train_0/fw_loss           | 0.00041540186502970756 |
| train_0/mu_grads          | -0.046981983538717034  |
| train_0/mu_grads_std      | 0.31865141838788985    |
| train_0/mu_loss           | 4.946394116104495      |
| train_0/next_q            | -4.826950849581185     |
| train_0/q_grads           | 0.017422069096937776   |
| train_0/q_grads_std       | 0.22512185834348203    |
| train_0/q_loss            | 0.6509653949660722     |
| train_0/reward            | -0.7128924386084691    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0009033203125        |
| train_0/target_q          | -5.0769807168106045    |
| train_1/avg_q             | -17.231237797493176    |
| train_1/current_q         | -10.109225737568988    |
| train_1/fw_bonus          | -0.9951178759336472    |
| train_1/fw_loss           | 0.001991638130857609   |
| train_1/mu_grads          | -0.0006526403114548885 |
| train_1/mu_grads_std      | 0.3682492807507515     |
| train_1/mu_loss           | 10.337936542925549     |
| train_1/n_subgoals        | 2128.0                 |
| train_1/next_q            | -10.289887649227271    |
| train_1/q_grads           | -0.014507906604558229  |
| train_1/q_grads_std       | 0.37031773179769517    |
| train_1/q_loss            | 9.469474158507087      |
| train_1/reward            | -2.1953370852537772    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0079345703125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.15601503759398497    |
| train_1/target_q          | -10.127363962051424    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 8
Time for epoch 8: 599.33. Rollout time: 342.49, Training time: 256.74
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 608414.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -0.6599367436918236   |
| test_1/avg_q              | -16.41294806671592    |
| test_1/n_subgoals         | 1021.0                |
| test_1/subgoal_succ_rate  | 0.3535749265426053    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.64                  |
| train_0/avg_q             | -8.422348959262177    |
| train_0/current_q         | -2.589629030440778    |
| train_0/fw_bonus          | -0.9985667735338211   |
| train_0/fw_loss           | 0.0003892763998010196 |
| train_0/mu_grads          | -0.05410435451194644  |
| train_0/mu_grads_std      | 0.333698732405901     |
| train_0/mu_loss           | 2.446141148186797     |
| train_0/next_q            | -2.3832377238954563   |
| train_0/q_grads           | 0.01715457309037447   |
| train_0/q_grads_std       | 0.23895905315876007   |
| train_0/q_loss            | 0.6104769105527423    |
| train_0/reward            | -0.7154803153171088   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020263671875       |
| train_0/target_q          | -2.853440744123958    |
| train_1/avg_q             | -14.987046902620623   |
| train_1/current_q         | -10.621283386935952   |
| train_1/fw_bonus          | -0.9952013358473778   |
| train_1/fw_loss           | 0.001971880576456897  |
| train_1/mu_grads          | -0.00393686363240704  |
| train_1/mu_grads_std      | 0.3845771819353104    |
| train_1/mu_loss           | 10.939129663512443    |
| train_1/n_subgoals        | 1794.0                |
| train_1/next_q            | -10.833708243873783   |
| train_1/q_grads           | -0.0174216796644032   |
| train_1/q_grads_std       | 0.3850836805999279    |
| train_1/q_loss            | 10.833742703115615    |
| train_1/reward            | -2.162270794095093    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0077392578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.24024526198439242   |
| train_1/target_q          | -10.659745789016807   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 9
Time for epoch 9: 678.46. Rollout time: 416.35, Training time: 262.01
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 670344.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -0.9244553907499056    |
| test_1/avg_q              | -17.49063320652126     |
| test_1/n_subgoals         | 5067.0                 |
| test_1/subgoal_succ_rate  | 0.9208604697059404     |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -8.8296695757101       |
| train_0/current_q         | -6.088491143020399     |
| train_0/fw_bonus          | -0.9985782027244567    |
| train_0/fw_loss           | 0.00038621411149506455 |
| train_0/mu_grads          | -0.06208614651113749   |
| train_0/mu_grads_std      | 0.3510004296898842     |
| train_0/mu_loss           | 5.8976835433521355     |
| train_0/next_q            | -5.771113993286233     |
| train_0/q_grads           | 0.01643668655306101    |
| train_0/q_grads_std       | 0.24981167912483215    |
| train_0/q_loss            | 0.6454007337121743     |
| train_0/reward            | -0.7233567104718531    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0020263671875        |
| train_0/target_q          | -6.0105104578587545    |
| train_1/avg_q             | -16.16122666700725     |
| train_1/current_q         | -11.480086109253396    |
| train_1/fw_bonus          | -0.9954387694597244    |
| train_1/fw_loss           | 0.0019156817201292143  |
| train_1/mu_grads          | -0.006702834332827479  |
| train_1/mu_grads_std      | 0.40189523845911024    |
| train_1/mu_loss           | 11.750492780920842     |
| train_1/n_subgoals        | 2051.0                 |
| train_1/next_q            | -11.56294494467014     |
| train_1/q_grads           | -0.02056189253926277   |
| train_1/q_grads_std       | 0.3995587877929211     |
| train_1/q_loss            | 7.66990401923218       |
| train_1/reward            | -2.1497691151016625    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0077392578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2637737688932228     |
| train_1/target_q          | -11.551947564898857    |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 10
Time for epoch 10: 665.38. Rollout time: 395.50, Training time: 269.76
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 730904.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.3632618004521586    |
| test_1/avg_q              | -10.902362872650178    |
| test_1/n_subgoals         | 677.0                  |
| test_1/subgoal_succ_rate  | 0.11964549483013294    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -12.061524618937426    |
| train_0/current_q         | -4.741121402421428     |
| train_0/fw_bonus          | -0.9986966073513031    |
| train_0/fw_loss           | 0.00035452415104373356 |
| train_0/mu_grads          | -0.06595198176801205   |
| train_0/mu_grads_std      | 0.36406695321202276    |
| train_0/mu_loss           | 4.53815399647989       |
| train_0/next_q            | -4.367985192624166     |
| train_0/q_grads           | 0.014674014504998922   |
| train_0/q_grads_std       | 0.2563228152692318     |
| train_0/q_loss            | 0.43767792864176336    |
| train_0/reward            | -0.7198340613696927    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0073974609375        |
| train_0/target_q          | -4.789896491293954     |
| train_1/avg_q             | -17.363417577021075    |
| train_1/current_q         | -12.159627928129563    |
| train_1/fw_bonus          | -0.9957398161292076    |
| train_1/fw_loss           | 0.0018444190209265798  |
| train_1/mu_grads          | -0.008248988958075642  |
| train_1/mu_grads_std      | 0.4168868213891983     |
| train_1/mu_loss           | 12.296516858913023     |
| train_1/n_subgoals        | 2019.0                 |
| train_1/next_q            | -12.184307189200144    |
| train_1/q_grads           | -0.024971190420910717  |
| train_1/q_grads_std       | 0.41267216503620147    |
| train_1/q_loss            | 7.442182662247667      |
| train_1/reward            | -2.1208587820143294    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080810546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27835562159484895    |
| train_1/target_q          | -12.226551045785893    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_10.pkl ...
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 11
Time for epoch 11: 710.68. Rollout time: 417.34, Training time: 293.21
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 788525.0               |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -4.535635757944701     |
| test_1/avg_q              | -17.750594484438462    |
| test_1/n_subgoals         | 2687.0                 |
| test_1/subgoal_succ_rate  | 0.7971715668031262     |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -9.605231392916261     |
| train_0/current_q         | -4.413089526644391     |
| train_0/fw_bonus          | -0.998726698756218     |
| train_0/fw_loss           | 0.00034646521671675143 |
| train_0/mu_grads          | -0.07019789144396782   |
| train_0/mu_grads_std      | 0.3787748418748379     |
| train_0/mu_loss           | 4.299452299952227      |
| train_0/next_q            | -4.134714592033731     |
| train_0/q_grads           | 0.015487883635796607   |
| train_0/q_grads_std       | 0.26436610966920854    |
| train_0/q_loss            | 0.7489813943998851     |
| train_0/reward            | -0.7273672228540817    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0166015625           |
| train_0/target_q          | -4.371561057794045     |
| train_1/avg_q             | -15.050476021658197    |
| train_1/current_q         | -11.879957305062508    |
| train_1/fw_bonus          | -0.9962350308895112    |
| train_1/fw_loss           | 0.001727197240688838   |
| train_1/mu_grads          | -0.01023936492856592   |
| train_1/mu_grads_std      | 0.42900445237755774    |
| train_1/mu_loss           | 11.941170706310825     |
| train_1/n_subgoals        | 1787.0                 |
| train_1/next_q            | -11.762257468489532    |
| train_1/q_grads           | -0.028927203686907887  |
| train_1/q_grads_std       | 0.4247927464544773     |
| train_1/q_loss            | 5.854993411563781      |
| train_1/reward            | -2.148430095965159     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0072021484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23391158365976497    |
| train_1/target_q          | -11.895202895667978    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09000000000000001
Training epoch 12
Time for epoch 12: 772.91. Rollout time: 493.90, Training time: 278.90
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 857169.0              |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.3559886345168863   |
| test_1/avg_q              | -7.906970246868752    |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -9.202128632628176    |
| train_0/current_q         | -1.7008431260222383   |
| train_0/fw_bonus          | -0.9987286761403084   |
| train_0/fw_loss           | 0.0003459404266322963 |
| train_0/mu_grads          | -0.0709245327860117   |
| train_0/mu_grads_std      | 0.39294293820858      |
| train_0/mu_loss           | 1.477497161164208     |
| train_0/next_q            | -1.5058497292151667   |
| train_0/q_grads           | 0.016276559419929983  |
| train_0/q_grads_std       | 0.2714165195822716    |
| train_0/q_loss            | 1.011330151099238     |
| train_0/reward            | -0.7245845099732833   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.008837890625        |
| train_0/target_q          | -1.970462050899906    |
| train_1/avg_q             | -16.305977442551782   |
| train_1/current_q         | -12.355663671405875   |
| train_1/fw_bonus          | -0.9961309060454369   |
| train_1/fw_loss           | 0.001751845912076533  |
| train_1/mu_grads          | -0.011524263536557555 |
| train_1/mu_grads_std      | 0.4406124837696552    |
| train_1/mu_loss           | 12.470243810931695    |
| train_1/n_subgoals        | 2099.0                |
| train_1/next_q            | -12.376898088874947   |
| train_1/q_grads           | -0.0317774779163301   |
| train_1/q_grads_std       | 0.4355108134448528    |
| train_1/q_loss            | 6.794358536651586     |
| train_1/reward            | -2.2802583114189474   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0079345703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1557884707003335    |
| train_1/target_q          | -12.37656732741578    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 13
Time for epoch 13: 1003.61. Rollout time: 702.43, Training time: 300.99
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 934591.0               |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.1085121717018156    |
| test_1/avg_q              | -19.01465322986941     |
| test_1/n_subgoals         | 696.0                  |
| test_1/subgoal_succ_rate  | 0.03017241379310345    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.27                   |
| train_0/avg_q             | -4.392725257891612     |
| train_0/current_q         | -2.9315981737781187    |
| train_0/fw_bonus          | -0.9989141434431076    |
| train_0/fw_loss           | 0.00029629361197294204 |
| train_0/mu_grads          | -0.07568495068699121   |
| train_0/mu_grads_std      | 0.4100606992840767     |
| train_0/mu_loss           | 2.725746185401004      |
| train_0/next_q            | -2.73074099657085      |
| train_0/q_grads           | 0.015074592526070773   |
| train_0/q_grads_std       | 0.2755571410059929     |
| train_0/q_loss            | 0.8198795957979378     |
| train_0/reward            | -0.7241364931509452    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0331298828125        |
| train_0/target_q          | -3.200856324626521     |
| train_1/avg_q             | -15.697887246090392    |
| train_1/current_q         | -12.795416484017219    |
| train_1/fw_bonus          | -0.995613032579422     |
| train_1/fw_loss           | 0.0018744308094028384  |
| train_1/mu_grads          | -0.012765036849305033  |
| train_1/mu_grads_std      | 0.45318872928619386    |
| train_1/mu_loss           | 13.1026944393966       |
| train_1/n_subgoals        | 2339.0                 |
| train_1/next_q            | -12.993997506727458    |
| train_1/q_grads           | -0.03271408434957266   |
| train_1/q_grads_std       | 0.4467887535691261     |
| train_1/q_loss            | 6.216680728338416      |
| train_1/reward            | -2.338154967734954     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0074462890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.09234715690466011    |
| train_1/target_q          | -12.837523180654255    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 14
Time for epoch 14: 857.68. Rollout time: 555.43, Training time: 302.10
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 1008307.0              |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0626792886190504    |
| test_1/avg_q              | -14.162223910773337    |
| test_1/n_subgoals         | 1174.0                 |
| test_1/subgoal_succ_rate  | 0.44293015332197616    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.3                    |
| train_0/avg_q             | -5.6117286420835635    |
| train_0/current_q         | -5.578776543593328     |
| train_0/fw_bonus          | -0.998899158835411     |
| train_0/fw_loss           | 0.00030030156594875736 |
| train_0/mu_grads          | -0.08271660078316927   |
| train_0/mu_grads_std      | 0.42401655241847036    |
| train_0/mu_loss           | 5.358001665698859      |
| train_0/next_q            | -5.259655193260942     |
| train_0/q_grads           | 0.016022498114034535   |
| train_0/q_grads_std       | 0.28230492025613785    |
| train_0/q_loss            | 0.5642394751631551     |
| train_0/reward            | -0.7256159042968647    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.028271484375         |
| train_0/target_q          | -5.545897810322088     |
| train_1/avg_q             | -17.95155631405426     |
| train_1/current_q         | -12.822905266635422    |
| train_1/fw_bonus          | -0.9964292243123054    |
| train_1/fw_loss           | 0.001681229067617096   |
| train_1/mu_grads          | -0.015309115638956428  |
| train_1/mu_grads_std      | 0.46497486904263496    |
| train_1/mu_loss           | 12.934398689096287     |
| train_1/n_subgoals        | 2293.0                 |
| train_1/next_q            | -12.868332946026978    |
| train_1/q_grads           | -0.03671984160318971   |
| train_1/q_grads_std       | 0.4572913728654385     |
| train_1/q_loss            | 6.445390651214629      |
| train_1/reward            | -2.3274093117935992    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0087890625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.15569123419101613    |
| train_1/target_q          | -12.858174357891565    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 15
Time for epoch 15: 661.39. Rollout time: 397.39, Training time: 263.88
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1072520.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.16                  |
| test_0/avg_q              | -1.6629674463570105   |
| test_1/avg_q              | -14.921239198644633   |
| test_1/n_subgoals         | 2158.0                |
| test_1/subgoal_succ_rate  | 0.7613531047265987    |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -8.178363453311007    |
| train_0/current_q         | -4.379150185326683    |
| train_0/fw_bonus          | -0.9989683210849762   |
| train_0/fw_loss           | 0.0002817899254296208 |
| train_0/mu_grads          | -0.08586382381618023  |
| train_0/mu_grads_std      | 0.4353691816329956    |
| train_0/mu_loss           | 4.191808374326607     |
| train_0/next_q            | -4.0184987618076065   |
| train_0/q_grads           | 0.014654255332425236  |
| train_0/q_grads_std       | 0.289238753169775     |
| train_0/q_loss            | 0.47459843459972023   |
| train_0/reward            | -0.7336165918106416   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0256591796875       |
| train_0/target_q          | -4.387311130738711    |
| train_1/avg_q             | -16.79371518259354    |
| train_1/current_q         | -12.814077400772854   |
| train_1/fw_bonus          | -0.9966715261340141   |
| train_1/fw_loss           | 0.001623880077386275  |
| train_1/mu_grads          | -0.01654030503705144  |
| train_1/mu_grads_std      | 0.47587187588214874   |
| train_1/mu_loss           | 13.017714587728118    |
| train_1/n_subgoals        | 2118.0                |
| train_1/next_q            | -12.886274945053108   |
| train_1/q_grads           | -0.039009549841284755 |
| train_1/q_grads_std       | 0.46762763410806657   |
| train_1/q_loss            | 5.805648556569459     |
| train_1/reward            | -2.315256745654915    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0078857421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.24173748819641172   |
| train_1/target_q          | -12.853316353140698   |
-----------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 16
Time for epoch 16: 662.77. Rollout time: 373.47, Training time: 289.17
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1131967.0              |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -2.3383213825065883    |
| test_1/avg_q              | -14.892404388735342    |
| test_1/n_subgoals         | 1826.0                 |
| test_1/subgoal_succ_rate  | 0.671960569550931      |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -8.952738875019627     |
| train_0/current_q         | -5.109683215323123     |
| train_0/fw_bonus          | -0.9990937605500221    |
| train_0/fw_loss           | 0.00024820964681566694 |
| train_0/mu_grads          | -0.09044361859560013   |
| train_0/mu_grads_std      | 0.4448616556823254     |
| train_0/mu_loss           | 4.924700265357362      |
| train_0/next_q            | -4.751935523100654     |
| train_0/q_grads           | 0.016890547098591925   |
| train_0/q_grads_std       | 0.2998529329895973     |
| train_0/q_loss            | 0.6653888116099346     |
| train_0/reward            | -0.7420341847155214    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.052099609375         |
| train_0/target_q          | -5.0579144553560225    |
| train_1/avg_q             | -18.114266010755045    |
| train_1/current_q         | -13.417416617064125    |
| train_1/fw_bonus          | -0.9970729768276214    |
| train_1/fw_loss           | 0.0015288520895410328  |
| train_1/mu_grads          | -0.01760015469044447   |
| train_1/mu_grads_std      | 0.4864723190665245     |
| train_1/mu_loss           | 13.691991237699316     |
| train_1/n_subgoals        | 1926.0                 |
| train_1/next_q            | -13.618438677918126    |
| train_1/q_grads           | -0.041016850341111424  |
| train_1/q_grads_std       | 0.4798011861741543     |
| train_1/q_loss            | 6.6789071477686        |
| train_1/reward            | -2.357965751033407     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078369140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.29698857736240913    |
| train_1/target_q          | -13.466645237540282    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 17
Time for epoch 17: 745.85. Rollout time: 450.11, Training time: 295.60
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1194783.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -0.5737724194623071   |
| test_1/avg_q              | -13.252478884958458   |
| test_1/n_subgoals         | 4107.0                |
| test_1/subgoal_succ_rate  | 0.8775261748234722    |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.52                  |
| train_0/avg_q             | -10.14825365522445    |
| train_0/current_q         | -4.910018400906095    |
| train_0/fw_bonus          | -0.9991260409355164   |
| train_0/fw_loss           | 0.0002395695853920188 |
| train_0/mu_grads          | -0.09785935152322053  |
| train_0/mu_grads_std      | 0.45636831000447275   |
| train_0/mu_loss           | 4.640255407351084     |
| train_0/next_q            | -4.602493079580604    |
| train_0/q_grads           | 0.01813760371878743   |
| train_0/q_grads_std       | 0.3092569775879383    |
| train_0/q_loss            | 0.6943504148866984    |
| train_0/reward            | -0.743360613663026    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.059326171875        |
| train_0/target_q          | -4.961551233350984    |
| train_1/avg_q             | -17.44241992489265    |
| train_1/current_q         | -13.84059142300922    |
| train_1/fw_bonus          | -0.997364017367363    |
| train_1/fw_loss           | 0.001459958401392214  |
| train_1/mu_grads          | -0.018073050165548922 |
| train_1/mu_grads_std      | 0.5003389462828636    |
| train_1/mu_loss           | 14.074020752396176    |
| train_1/n_subgoals        | 1997.0                |
| train_1/next_q            | -13.959914433539897   |
| train_1/q_grads           | -0.043472493253648284 |
| train_1/q_grads_std       | 0.4943881340324879    |
| train_1/q_loss            | 5.231595509823364     |
| train_1/reward            | -2.3130128791104654   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00751953125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2398597896845268    |
| train_1/target_q          | -13.907076100867522   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 18
Time for epoch 18: 682.53. Rollout time: 388.69, Training time: 293.72
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1252351.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -1.5822002413710734    |
| test_1/avg_q              | -18.965478967555295    |
| test_1/n_subgoals         | 4024.0                 |
| test_1/subgoal_succ_rate  | 0.8921471172962226     |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -7.908012262198345     |
| train_0/current_q         | -5.35576750483882      |
| train_0/fw_bonus          | -0.9991733282804489    |
| train_0/fw_loss           | 0.00022691480480716564 |
| train_0/mu_grads          | -0.10278162136673927   |
| train_0/mu_grads_std      | 0.4673698902130127     |
| train_0/mu_loss           | 5.156809425172615      |
| train_0/next_q            | -4.997126800124322     |
| train_0/q_grads           | 0.018538308003917335   |
| train_0/q_grads_std       | 0.3163738869130611     |
| train_0/q_loss            | 0.5342829012293647     |
| train_0/reward            | -0.7509896201281663    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0603515625           |
| train_0/target_q          | -5.370490643163789     |
| train_1/avg_q             | -16.02282830703097     |
| train_1/current_q         | -13.272500231081697    |
| train_1/fw_bonus          | -0.9976943910121918    |
| train_1/fw_loss           | 0.0013817586965160444  |
| train_1/mu_grads          | -0.01933587868697941   |
| train_1/mu_grads_std      | 0.50774946808815       |
| train_1/mu_loss           | 13.382115671242781     |
| train_1/n_subgoals        | 1894.0                 |
| train_1/next_q            | -13.295725258394913    |
| train_1/q_grads           | -0.04599731648340821   |
| train_1/q_grads_std       | 0.5048422187566757     |
| train_1/q_loss            | 4.231022649428709      |
| train_1/reward            | -2.2753574341753846    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006982421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27666314677930304    |
| train_1/target_q          | -13.327681378750786    |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 19
Time for epoch 19: 686.07. Rollout time: 395.74, Training time: 290.18
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1308547.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.24                   |
| test_0/avg_q              | -1.5919512515092038    |
| test_1/avg_q              | -20.035070333953946    |
| test_1/n_subgoals         | 4378.0                 |
| test_1/subgoal_succ_rate  | 0.9198264047510278     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -10.569720487568507    |
| train_0/current_q         | -5.775716714542231     |
| train_0/fw_bonus          | -0.9991971284151078    |
| train_0/fw_loss           | 0.00022054335749999154 |
| train_0/mu_grads          | -0.10788010768592357   |
| train_0/mu_grads_std      | 0.478019305318594      |
| train_0/mu_loss           | 5.5281131658168094     |
| train_0/next_q            | -5.353189535284644     |
| train_0/q_grads           | 0.018457895889878274   |
| train_0/q_grads_std       | 0.32195499166846275    |
| train_0/q_loss            | 0.4850573478858884     |
| train_0/reward            | -0.7591071429862495    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0501220703125        |
| train_0/target_q          | -5.681823594417198     |
| train_1/avg_q             | -16.36184511068632     |
| train_1/current_q         | -12.794706494040826    |
| train_1/fw_bonus          | -0.9980003505945205    |
| train_1/fw_loss           | 0.0013093361398205162  |
| train_1/mu_grads          | -0.021335255727171897  |
| train_1/mu_grads_std      | 0.5155008867383003     |
| train_1/mu_loss           | 12.815730396852283     |
| train_1/n_subgoals        | 2000.0                 |
| train_1/next_q            | -12.609267265143416    |
| train_1/q_grads           | -0.05044863913208246   |
| train_1/q_grads_std       | 0.5153210803866386     |
| train_1/q_loss            | 5.522720044715217      |
| train_1/reward            | -2.2002508160763683    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00810546875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3535                 |
| train_1/target_q          | -12.861222060188396    |
------------------------------------------------------
New best value for test/success_rate: 0.24. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 20
Time for epoch 20: 589.84. Rollout time: 309.67, Training time: 280.04
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 1359506.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.2374447888095084    |
| test_1/avg_q              | -14.979716417365907    |
| test_1/n_subgoals         | 740.0                  |
| test_1/subgoal_succ_rate  | 0.1                    |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -11.763356758586673    |
| train_0/current_q         | -4.66384308939495      |
| train_0/fw_bonus          | -0.99916160851717      |
| train_0/fw_loss           | 0.00023004837676126043 |
| train_0/mu_grads          | -0.1110477901995182    |
| train_0/mu_grads_std      | 0.48739335834980013    |
| train_0/mu_loss           | 4.501631724108243      |
| train_0/next_q            | -4.338576897111146     |
| train_0/q_grads           | 0.01863784994930029    |
| train_0/q_grads_std       | 0.33089593052864075    |
| train_0/q_loss            | 0.7122118095163292     |
| train_0/reward            | -0.7659830313037673    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0750244140625        |
| train_0/target_q          | -4.714897004854587     |
| train_1/avg_q             | -16.34016411531519     |
| train_1/current_q         | -12.44477552778873     |
| train_1/fw_bonus          | -0.9980730220675469    |
| train_1/fw_loss           | 0.0012921313813421876  |
| train_1/mu_grads          | -0.024255281453952192  |
| train_1/mu_grads_std      | 0.5217637047171593     |
| train_1/mu_loss           | 12.313146332148097     |
| train_1/n_subgoals        | 1653.0                 |
| train_1/next_q            | -12.131200330976522    |
| train_1/q_grads           | -0.05401237728074193   |
| train_1/q_grads_std       | 0.5255477860569954     |
| train_1/q_loss            | 6.3436198983020216     |
| train_1/reward            | -2.1623661566471126    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007373046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4089534180278282     |
| train_1/target_q          | -12.501517635496949    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 21
Time for epoch 21: 613.04. Rollout time: 352.15, Training time: 260.77
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 1411502.0              |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.44                   |
| test_0/avg_q              | -1.3206849801567273    |
| test_1/avg_q              | -16.184062577800432    |
| test_1/n_subgoals         | 4106.0                 |
| test_1/subgoal_succ_rate  | 0.939113492450073      |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -10.591788847015573    |
| train_0/current_q         | -5.291965561849521     |
| train_0/fw_bonus          | -0.9991842433810234    |
| train_0/fw_loss           | 0.00022399330555344932 |
| train_0/mu_grads          | -0.1142238076776266    |
| train_0/mu_grads_std      | 0.4966425642371178     |
| train_0/mu_loss           | 5.043064375686896      |
| train_0/next_q            | -4.910773749523197     |
| train_0/q_grads           | 0.018414929369464518   |
| train_0/q_grads_std       | 0.3360175773501396     |
| train_0/q_loss            | 0.5180033907570119     |
| train_0/reward            | -0.7696507960092276    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0565673828125        |
| train_0/target_q          | -5.309404825790753     |
| train_1/avg_q             | -15.02459955654926     |
| train_1/current_q         | -11.698714770780693    |
| train_1/fw_bonus          | -0.9982134953141213    |
| train_1/fw_loss           | 0.0012588808458531275  |
| train_1/mu_grads          | -0.026178493769839405  |
| train_1/mu_grads_std      | 0.5275748685002327     |
| train_1/mu_loss           | 11.562217238798643     |
| train_1/n_subgoals        | 1892.0                 |
| train_1/next_q            | -11.37053911663045     |
| train_1/q_grads           | -0.058914735447615385  |
| train_1/q_grads_std       | 0.5361395969986915     |
| train_1/q_loss            | 4.8930394858468365     |
| train_1/reward            | -2.0770924362339427    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008154296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.30655391120507397    |
| train_1/target_q          | -11.750760261700737    |
------------------------------------------------------
New best value for test/success_rate: 0.44. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.21000000000000002
Training epoch 22
Time for epoch 22: 519.21. Rollout time: 272.47, Training time: 246.60
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 1465286.0              |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.7960736672710749    |
| test_1/avg_q              | -11.006219479329134    |
| test_1/n_subgoals         | 706.0                  |
| test_1/subgoal_succ_rate  | 0.043909348441926344   |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -11.250692507612714    |
| train_0/current_q         | -5.499290251974468     |
| train_0/fw_bonus          | -0.9992248475551605    |
| train_0/fw_loss           | 0.00021312627104634884 |
| train_0/mu_grads          | -0.1197882866486907    |
| train_0/mu_grads_std      | 0.5045503720641136     |
| train_0/mu_loss           | 5.230067040730201      |
| train_0/next_q            | -5.064119736639431     |
| train_0/q_grads           | 0.01921665817499161    |
| train_0/q_grads_std       | 0.3434323832392693     |
| train_0/q_loss            | 0.491755911060635      |
| train_0/reward            | -0.7760696365163312    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0984619140625        |
| train_0/target_q          | -5.4591222677107885    |
| train_1/avg_q             | -15.242819305691034    |
| train_1/current_q         | -12.035363614597975    |
| train_1/fw_bonus          | -0.9984101399779319    |
| train_1/fw_loss           | 0.001212336352909915   |
| train_1/mu_grads          | -0.02837359462864697   |
| train_1/mu_grads_std      | 0.5340865328907967     |
| train_1/mu_loss           | 11.94763683586876      |
| train_1/n_subgoals        | 1730.0                 |
| train_1/next_q            | -11.808040210161947    |
| train_1/q_grads           | -0.060783847514539954  |
| train_1/q_grads_std       | 0.5481025502085686     |
| train_1/q_loss            | 4.344832340873657      |
| train_1/reward            | -2.0712089769673185    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080322265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35722543352601155    |
| train_1/target_q          | -12.087206715355489    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16999999999999998
Training epoch 23
Time for epoch 23: 3614.93. Rollout time: 1484.37, Training time: 2130.45
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 1527364.0             |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.24                  |
| test_0/avg_q              | -2.360513066182541    |
| test_1/avg_q              | -18.78084443541464    |
| test_1/n_subgoals         | 1302.0                |
| test_1/subgoal_succ_rate  | 0.6113671274961597    |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.46                  |
| train_0/avg_q             | -10.907586909189288   |
| train_0/current_q         | -6.169933651532803    |
| train_0/fw_bonus          | -0.9992094665765763   |
| train_0/fw_loss           | 0.000217240149868303  |
| train_0/mu_grads          | -0.1234439354389906   |
| train_0/mu_grads_std      | 0.514032444357872     |
| train_0/mu_loss           | 6.052001710963072     |
| train_0/next_q            | -5.843358131015342    |
| train_0/q_grads           | 0.019082761975005268  |
| train_0/q_grads_std       | 0.3493168972432613    |
| train_0/q_loss            | 0.7544781304863848    |
| train_0/reward            | -0.7682655013155454   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0855224609375       |
| train_0/target_q          | -6.087403228633503    |
| train_1/avg_q             | -12.9924370004008     |
| train_1/current_q         | -12.365890542964248   |
| train_1/fw_bonus          | -0.9981645926833153   |
| train_1/fw_loss           | 0.001270454269251786  |
| train_1/mu_grads          | -0.029644459346309306 |
| train_1/mu_grads_std      | 0.5408773601055146    |
| train_1/mu_loss           | 12.467013304277966    |
| train_1/n_subgoals        | 2043.0                |
| train_1/next_q            | -12.252242048197123   |
| train_1/q_grads           | -0.06198130333796144  |
| train_1/q_grads_std       | 0.5598973110318184    |
| train_1/q_loss            | 5.399262806296925     |
| train_1/reward            | -2.1193958861047575   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00810546875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.20704845814977973   |
| train_1/target_q          | -12.448076215659498   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16999999999999998
Training epoch 24
Time for epoch 24: 2192.24. Rollout time: 297.30, Training time: 1894.83
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 24                     |
| policy/steps              | 1582276.0              |
| test/episodes             | 625.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.1238068228656894    |
| test_1/avg_q              | -3.7233453548130626    |
| test_1/n_subgoals         | 672.0                  |
| test_1/subgoal_succ_rate  | 0.002976190476190476   |
| train/episodes            | 2500.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -13.040880619044028    |
| train_0/current_q         | -6.900901234741869     |
| train_0/fw_bonus          | -0.9991517141461372    |
| train_0/fw_loss           | 0.00023269904850167222 |
| train_0/mu_grads          | -0.12467958405613899   |
| train_0/mu_grads_std      | 0.5222485780715942     |
| train_0/mu_loss           | 6.715117296832         |
| train_0/next_q            | -6.539124986620965     |
| train_0/q_grads           | 0.019297868106514217   |
| train_0/q_grads_std       | 0.3561318390071392     |
| train_0/q_loss            | 0.5236973523073196     |
| train_0/reward            | -0.7695328019086446    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0721923828125        |
| train_0/target_q          | -6.845110604257627     |
| train_1/avg_q             | -16.042026988791626    |
| train_1/current_q         | -8.615381890591626     |
| train_1/fw_bonus          | -0.9985516726970672    |
| train_1/fw_loss           | 0.0011788332456490024  |
| train_1/mu_grads          | -0.03215763168409467   |
| train_1/mu_grads_std      | 0.5475629061460495     |
| train_1/mu_loss           | 7.823249158751599      |
| train_1/n_subgoals        | 1714.0                 |
| train_1/next_q            | -7.836337801092161     |
| train_1/q_grads           | -0.06459697932004929   |
| train_1/q_grads_std       | 0.5739853501319885     |
| train_1/q_loss            | 13.394598217929007     |
| train_1/reward            | -2.0351359645599585    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078369140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3144690781796966     |
| train_1/target_q          | -8.7024752462167       |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18999999999999997
Training epoch 25
Time for epoch 25: 627.57. Rollout time: 341.24, Training time: 286.22
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 1639188.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.686726775919488    |
| test_1/avg_q              | -13.747575572594076   |
| test_1/n_subgoals         | 680.0                 |
| test_1/subgoal_succ_rate  | 0.007352941176470588  |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -11.74802801824545    |
| train_0/current_q         | -5.037832203691965    |
| train_0/fw_bonus          | -0.9991727188229561   |
| train_0/fw_loss           | 0.0002270780998514965 |
| train_0/mu_grads          | -0.12907908037304877  |
| train_0/mu_grads_std      | 0.5293984562158585    |
| train_0/mu_loss           | 4.789853588506789     |
| train_0/next_q            | -4.657047683032566    |
| train_0/q_grads           | 0.018949681706726552  |
| train_0/q_grads_std       | 0.3607055626809597    |
| train_0/q_loss            | 0.5606940496550846    |
| train_0/reward            | -0.7713141744581662   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.05625               |
| train_0/target_q          | -5.055110200078749    |
| train_1/avg_q             | -12.27458070026601    |
| train_1/current_q         | -10.751961628113737   |
| train_1/fw_bonus          | -0.9985760599374771   |
| train_1/fw_loss           | 0.0011730600192095153 |
| train_1/mu_grads          | -0.03258960172533989  |
| train_1/mu_grads_std      | 0.5517775431275368    |
| train_1/mu_loss           | 10.434647597616195    |
| train_1/n_subgoals        | 1799.0                |
| train_1/next_q            | -10.322020548915628   |
| train_1/q_grads           | -0.0689294222742319   |
| train_1/q_grads_std       | 0.5850586622953415    |
| train_1/q_loss            | 6.287811149909755     |
| train_1/reward            | -2.0450480661682375   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00791015625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.28627015008337964   |
| train_1/target_q          | -10.73048912409502    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 26
Time for epoch 26: 673.43. Rollout time: 397.54, Training time: 275.78
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1705723.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8648714348365072    |
| test_1/avg_q              | -17.01924522317873     |
| test_1/n_subgoals         | 692.0                  |
| test_1/subgoal_succ_rate  | 0.024566473988439308   |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -9.878553446265665     |
| train_0/current_q         | -4.162211054490697     |
| train_0/fw_bonus          | -0.9991770252585411    |
| train_0/fw_loss           | 0.00022592354871449062 |
| train_0/mu_grads          | -0.13192564472556115   |
| train_0/mu_grads_std      | 0.536826841533184      |
| train_0/mu_loss           | 4.05980189000943       |
| train_0/next_q            | -3.9194217729269534    |
| train_0/q_grads           | 0.01898035886697471    |
| train_0/q_grads_std       | 0.36588556692004204    |
| train_0/q_loss            | 0.7133372752958677     |
| train_0/reward            | -0.7644671082598506    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0804443359375        |
| train_0/target_q          | -4.276111175372518     |
| train_1/avg_q             | -14.089126691505388    |
| train_1/current_q         | -11.792535875788795    |
| train_1/fw_bonus          | -0.9986127898097038    |
| train_1/fw_loss           | 0.00116436337120831    |
| train_1/mu_grads          | -0.03246857188642025   |
| train_1/mu_grads_std      | 0.5577788800001144     |
| train_1/mu_loss           | 11.790122745824359     |
| train_1/n_subgoals        | 2051.0                 |
| train_1/next_q            | -11.592381551910552    |
| train_1/q_grads           | -0.0711376117542386    |
| train_1/q_grads_std       | 0.5955084383487701     |
| train_1/q_loss            | 6.502112630224931      |
| train_1/reward            | -2.098450806721303     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0082763671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19307654802535348    |
| train_1/target_q          | -11.862334119786876    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 27
Time for epoch 27: 591.66. Rollout time: 309.23, Training time: 282.31
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 1757644.0              |
| test/episodes             | 700.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.1653831248464628    |
| test_1/avg_q              | -14.36491062356706     |
| test_1/n_subgoals         | 8506.0                 |
| test_1/subgoal_succ_rate  | 0.9580296261462498     |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -8.967893841058812     |
| train_0/current_q         | -5.52781742585067      |
| train_0/fw_bonus          | -0.9991425484418869    |
| train_0/fw_loss           | 0.00023515435023000464 |
| train_0/mu_grads          | -0.13036864884197713   |
| train_0/mu_grads_std      | 0.5437401965260505     |
| train_0/mu_loss           | 5.28659097625629       |
| train_0/next_q            | -5.103955729135753     |
| train_0/q_grads           | 0.018282687244936823   |
| train_0/q_grads_std       | 0.3689069181680679     |
| train_0/q_loss            | 0.5457797117440962     |
| train_0/reward            | -0.7652458406886581    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0698974609375        |
| train_0/target_q          | -5.436884829163288     |
| train_1/avg_q             | -14.80796902412694     |
| train_1/current_q         | -11.446460680638202    |
| train_1/fw_bonus          | -0.9985221281647683    |
| train_1/fw_loss           | 0.0011858251644298434  |
| train_1/mu_grads          | -0.03207057463005185   |
| train_1/mu_grads_std      | 0.5646579504013062     |
| train_1/mu_loss           | 11.484270314751337     |
| train_1/n_subgoals        | 1656.0                 |
| train_1/next_q            | -11.33564235428664     |
| train_1/q_grads           | -0.07310460396111011   |
| train_1/q_grads_std       | 0.6086382701992988     |
| train_1/q_loss            | 5.934602359429215      |
| train_1/reward            | -2.0592801917202452    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007080078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3466183574879227     |
| train_1/target_q          | -11.548341667615949    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 28
Time for epoch 28: 663.40. Rollout time: 383.72, Training time: 279.57
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 1814602.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -0.5732808242845615    |
| test_1/avg_q              | -17.755429525128086    |
| test_1/n_subgoals         | 8294.0                 |
| test_1/subgoal_succ_rate  | 0.9688931757897276     |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -12.478105785697391    |
| train_0/current_q         | -5.76992586647416      |
| train_0/fw_bonus          | -0.9992070958018303    |
| train_0/fw_loss           | 0.00021787499463243876 |
| train_0/mu_grads          | -0.13017635941505432   |
| train_0/mu_grads_std      | 0.5493119791150093     |
| train_0/mu_loss           | 5.556866783330019      |
| train_0/next_q            | -5.391114807977209     |
| train_0/q_grads           | 0.019224056554958225   |
| train_0/q_grads_std       | 0.37442387714982034    |
| train_0/q_loss            | 0.5408260558021534     |
| train_0/reward            | -0.7653901528039568    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0997802734375        |
| train_0/target_q          | -5.746377619299096     |
| train_1/avg_q             | -15.615130561796601    |
| train_1/current_q         | -11.81250198284876     |
| train_1/fw_bonus          | -0.998832854628563     |
| train_1/fw_loss           | 0.0011122739102574996  |
| train_1/mu_grads          | -0.03594906879588962   |
| train_1/mu_grads_std      | 0.5722265556454659     |
| train_1/mu_loss           | 12.07039737645468      |
| train_1/n_subgoals        | 1958.0                 |
| train_1/next_q            | -11.82448922983394     |
| train_1/q_grads           | -0.07650656644254923   |
| train_1/q_grads_std       | 0.6191512957215309     |
| train_1/q_loss            | 5.424622065648634      |
| train_1/reward            | -2.114106406854262     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078857421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3503575076608784     |
| train_1/target_q          | -11.924296632878427    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.060000000000000005
Training epoch 29
Time for epoch 29: 575.36. Rollout time: 300.36, Training time: 274.88
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 1864217.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -0.6820868904455342    |
| test_1/avg_q              | -5.665544958670286     |
| test_1/n_subgoals         | 8161.0                 |
| test_1/subgoal_succ_rate  | 0.9566229628721971     |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -10.245511916861673    |
| train_0/current_q         | -5.656097486708581     |
| train_0/fw_bonus          | -0.9991536796092987    |
| train_0/fw_loss           | 0.00023216993577079847 |
| train_0/mu_grads          | -0.13183458149433136   |
| train_0/mu_grads_std      | 0.5565429925918579     |
| train_0/mu_loss           | 5.427978105018667      |
| train_0/next_q            | -5.2709036217120655    |
| train_0/q_grads           | 0.018500719452276826   |
| train_0/q_grads_std       | 0.3792667254805565     |
| train_0/q_loss            | 0.5276482903803446     |
| train_0/reward            | -0.7626851513461588    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0763671875           |
| train_0/target_q          | -5.616480662064125     |
| train_1/avg_q             | -14.80897202049401     |
| train_1/current_q         | -10.448547558643387    |
| train_1/fw_bonus          | -0.9990520969033241    |
| train_1/fw_loss           | 0.0010603775663184933  |
| train_1/mu_grads          | -0.03648954480886459   |
| train_1/mu_grads_std      | 0.5774053290486336     |
| train_1/mu_loss           | 10.148950215246346     |
| train_1/n_subgoals        | 1679.0                 |
| train_1/next_q            | -10.224613791814047    |
| train_1/q_grads           | -0.07789440900087356   |
| train_1/q_grads_std       | 0.6304404765367508     |
| train_1/q_loss            | 10.26561432531604      |
| train_1/reward            | -2.052820885321853     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071044921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.44312090530077425    |
| train_1/target_q          | -10.646721097583418    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 30
Time for epoch 30: 564.44. Rollout time: 295.30, Training time: 269.01
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 1914024.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.2532038218739305    |
| test_1/avg_q              | -13.263652826438625    |
| test_1/n_subgoals         | 10418.0                |
| test_1/subgoal_succ_rate  | 0.9894413515070071     |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -9.801127518121168     |
| train_0/current_q         | -6.0003428390484075    |
| train_0/fw_bonus          | -0.999184787273407     |
| train_0/fw_loss           | 0.00022384660078387242 |
| train_0/mu_grads          | -0.13613388501107693   |
| train_0/mu_grads_std      | 0.5645023509860039     |
| train_0/mu_loss           | 5.746760394352877      |
| train_0/next_q            | -5.557725990017595     |
| train_0/q_grads           | 0.018818213045597075   |
| train_0/q_grads_std       | 0.38389522656798364    |
| train_0/q_loss            | 0.40084319475807784    |
| train_0/reward            | -0.7674170463200426    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1041748046875        |
| train_0/target_q          | -5.960705705851037     |
| train_1/avg_q             | -13.082693274840413    |
| train_1/current_q         | -8.823597404006609     |
| train_1/fw_bonus          | -0.9992157578468323    |
| train_1/fw_loss           | 0.001021640132239554   |
| train_1/mu_grads          | -0.03819474168121815   |
| train_1/mu_grads_std      | 0.5818795830011367     |
| train_1/mu_loss           | 8.454547124200406      |
| train_1/n_subgoals        | 1859.0                 |
| train_1/next_q            | -8.294782239653648     |
| train_1/q_grads           | -0.08055532760918141   |
| train_1/q_grads_std       | 0.6409836083650589     |
| train_1/q_loss            | 6.096692698950994      |
| train_1/reward            | -2.0175041320610037    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075439453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.44163528778913397    |
| train_1/target_q          | -8.920955584309487     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.16
Training epoch 31
Time for epoch 31: 578.48. Rollout time: 309.63, Training time: 268.73
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 1964633.0              |
| test/episodes             | 800.0                  |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -1.296927410847658     |
| test_1/avg_q              | -9.354258260569495     |
| test_1/n_subgoals         | 3687.0                 |
| test_1/subgoal_succ_rate  | 0.880661784648766      |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -13.401853659434007    |
| train_0/current_q         | -6.447030329440246     |
| train_0/fw_bonus          | -0.9991482600569725    |
| train_0/fw_loss           | 0.00023362497886409984 |
| train_0/mu_grads          | -0.13628533929586412   |
| train_0/mu_grads_std      | 0.5706719130277633     |
| train_0/mu_loss           | 6.204964211506011      |
| train_0/next_q            | -6.039149361312619     |
| train_0/q_grads           | 0.01990467170253396    |
| train_0/q_grads_std       | 0.38897953778505323    |
| train_0/q_loss            | 0.39258697440802737    |
| train_0/reward            | -0.7643683627742576    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0726806640625        |
| train_0/target_q          | -6.418565036311115     |
| train_1/avg_q             | -13.968311180691769    |
| train_1/current_q         | -11.582808529277244    |
| train_1/fw_bonus          | -0.999183577299118     |
| train_1/fw_loss           | 0.0010292578241205773  |
| train_1/mu_grads          | -0.04114208677783608   |
| train_1/mu_grads_std      | 0.5881709381937981     |
| train_1/mu_loss           | 11.657737515929732     |
| train_1/n_subgoals        | 1821.0                 |
| train_1/next_q            | -11.476240904220283    |
| train_1/q_grads           | -0.08116066753864289   |
| train_1/q_grads_std       | 0.6555978864431381     |
| train_1/q_loss            | 6.677936671855894      |
| train_1/reward            | -1.9712253358429734    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078857421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.414607358594179      |
| train_1/target_q          | -11.686565217267454    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.22000000000000003
Training epoch 32
Time for epoch 32: 621.47. Rollout time: 321.94, Training time: 299.40
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 32                     |
| policy/steps              | 2016123.0              |
| test/episodes             | 825.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.8221796871737117    |
| test_1/avg_q              | -16.69588720577793     |
| test_1/n_subgoals         | 5010.0                 |
| test_1/subgoal_succ_rate  | 0.9369261477045908     |
| train/episodes            | 3300.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -12.393787034152874    |
| train_0/current_q         | -6.161301178461207     |
| train_0/fw_bonus          | -0.9991964504122735    |
| train_0/fw_loss           | 0.00022072751016821712 |
| train_0/mu_grads          | -0.13762518279254438   |
| train_0/mu_grads_std      | 0.5778069734573364     |
| train_0/mu_loss           | 5.945987936635253      |
| train_0/next_q            | -5.7614591074525165    |
| train_0/q_grads           | 0.01964439358562231    |
| train_0/q_grads_std       | 0.39264959618449213    |
| train_0/q_loss            | 0.4788932437105675     |
| train_0/reward            | -0.7723088753769843    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.09404296875          |
| train_0/target_q          | -6.145557234194089     |
| train_1/avg_q             | -12.7366578401632      |
| train_1/current_q         | -12.260927704330268    |
| train_1/fw_bonus          | -0.9989750355482101    |
| train_1/fw_loss           | 0.0010786210434162058  |
| train_1/mu_grads          | -0.04066798537969589   |
| train_1/mu_grads_std      | 0.5949704706668854     |
| train_1/mu_loss           | 12.465905909968514     |
| train_1/n_subgoals        | 1867.0                 |
| train_1/next_q            | -12.224705348077483    |
| train_1/q_grads           | -0.08020540643483401   |
| train_1/q_grads_std       | 0.663297264277935      |
| train_1/q_loss            | 4.559688816847299      |
| train_1/reward            | -1.9625672430083796    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0068115234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43331547937868237    |
| train_1/target_q          | -12.401421406949444    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 33
Time for epoch 33: 601.08. Rollout time: 305.85, Training time: 295.09
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 2066974.0              |
| test/episodes             | 850.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.7873057338660987    |
| test_1/avg_q              | -14.393579393013779    |
| test_1/n_subgoals         | 685.0                  |
| test_1/subgoal_succ_rate  | 0.014598540145985401   |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -12.554570130359783    |
| train_0/current_q         | -4.797254421125745     |
| train_0/fw_bonus          | -0.9992165759205818    |
| train_0/fw_loss           | 0.00021533945910050533 |
| train_0/mu_grads          | -0.13916237093508244   |
| train_0/mu_grads_std      | 0.5835749000310898     |
| train_0/mu_loss           | 4.512970173238276      |
| train_0/next_q            | -4.417425874825009     |
| train_0/q_grads           | 0.019862351566553117   |
| train_0/q_grads_std       | 0.3953587763011456     |
| train_0/q_loss            | 0.4502857217941438     |
| train_0/reward            | -0.7786676671381428    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.092626953125         |
| train_0/target_q          | -4.9806876160083995    |
| train_1/avg_q             | -15.045140448636042    |
| train_1/current_q         | -11.054977952263487    |
| train_1/fw_bonus          | -0.9991969883441925    |
| train_1/fw_loss           | 0.0010260823139105924  |
| train_1/mu_grads          | -0.04221732076257467   |
| train_1/mu_grads_std      | 0.602846673130989      |
| train_1/mu_loss           | 10.995542240326753     |
| train_1/n_subgoals        | 1688.0                 |
| train_1/next_q            | -10.79886269168308     |
| train_1/q_grads           | -0.0825157530605793    |
| train_1/q_grads_std       | 0.6722791239619255     |
| train_1/q_loss            | 4.638630277387282      |
| train_1/reward            | -1.889691823567773     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078125              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4324644549763033     |
| train_1/target_q          | -11.164008886140044    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18000000000000002
Training epoch 34
Time for epoch 34: 732.35. Rollout time: 416.13, Training time: 316.12
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 2126974.0              |
| test/episodes             | 875.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5538923567613179    |
| test_1/avg_q              | -3.3247877517045334    |
| test_1/n_subgoals         | 3668.0                 |
| test_1/subgoal_succ_rate  | 0.8478735005452562     |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -10.137143410326184    |
| train_0/current_q         | -6.149953577712243     |
| train_0/fw_bonus          | -0.9991279020905495    |
| train_0/fw_loss           | 0.00023907344257168006 |
| train_0/mu_grads          | -0.13913508430123328   |
| train_0/mu_grads_std      | 0.5896094486117363     |
| train_0/mu_loss           | 5.907239815918876      |
| train_0/next_q            | -5.760051593064948     |
| train_0/q_grads           | 0.020624079508706927   |
| train_0/q_grads_std       | 0.39988476783037186    |
| train_0/q_loss            | 0.5089894579444679     |
| train_0/reward            | -0.7755327078040863    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.096240234375         |
| train_0/target_q          | -6.126704545720051     |
| train_1/avg_q             | -12.398384085866278    |
| train_1/current_q         | -10.636557460670797    |
| train_1/fw_bonus          | -0.9992271214723587    |
| train_1/fw_loss           | 0.0010189470427576452  |
| train_1/mu_grads          | -0.04181265560910106   |
| train_1/mu_grads_std      | 0.6078257158398628     |
| train_1/mu_loss           | 10.50273763131926      |
| train_1/n_subgoals        | 1811.0                 |
| train_1/next_q            | -10.391676812249191    |
| train_1/q_grads           | -0.08304198533296585   |
| train_1/q_grads_std       | 0.6829532146453857     |
| train_1/q_loss            | 7.366517642413915      |
| train_1/reward            | -1.916139788703731     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075927734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.20706791827719492    |
| train_1/target_q          | -10.807216589372695    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 35
Time for epoch 35: 610.39. Rollout time: 316.61, Training time: 293.67
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 2176904.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -1.5602477814924622    |
| test_1/avg_q              | -16.59833479822055     |
| test_1/n_subgoals         | 2412.0                 |
| test_1/subgoal_succ_rate  | 0.798922056384743      |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -12.942302801896423    |
| train_0/current_q         | -6.655538325979222     |
| train_0/fw_bonus          | -0.9991276279091835    |
| train_0/fw_loss           | 0.00023914747434901075 |
| train_0/mu_grads          | -0.1426995385438204    |
| train_0/mu_grads_std      | 0.597218994796276      |
| train_0/mu_loss           | 6.429260775084934      |
| train_0/next_q            | -6.259084859040355     |
| train_0/q_grads           | 0.02081562620587647    |
| train_0/q_grads_std       | 0.40519958138465884    |
| train_0/q_loss            | 0.4492427433369766     |
| train_0/reward            | -0.775056564503393     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0944091796875        |
| train_0/target_q          | -6.629535351237555     |
| train_1/avg_q             | -12.10653414476194     |
| train_1/current_q         | -11.239744421746442    |
| train_1/fw_bonus          | -0.9993407458066941    |
| train_1/fw_loss           | 0.000992051030334551   |
| train_1/mu_grads          | -0.04250987898558378   |
| train_1/mu_grads_std      | 0.6176091998815536     |
| train_1/mu_loss           | 11.30421685636978      |
| train_1/n_subgoals        | 1688.0                 |
| train_1/next_q            | -11.078088343311151    |
| train_1/q_grads           | -0.08571880906820298   |
| train_1/q_grads_std       | 0.6922305077314377     |
| train_1/q_loss            | 6.721304158858194      |
| train_1/reward            | -1.9030395326069993    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075927734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36018957345971564    |
| train_1/target_q          | -11.42863614677915     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 36
Time for epoch 36: 644.03. Rollout time: 358.47, Training time: 285.44
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 2229894.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -1.2600023225216161    |
| test_1/avg_q              | -20.483311433181946    |
| test_1/n_subgoals         | 5970.0                 |
| test_1/subgoal_succ_rate  | 0.9244556113902848     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -12.898464389337516    |
| train_0/current_q         | -6.3693028184260765    |
| train_0/fw_bonus          | -0.9992182731628418    |
| train_0/fw_loss           | 0.00021488417114596815 |
| train_0/mu_grads          | -0.14537899047136307   |
| train_0/mu_grads_std      | 0.6053363934159279     |
| train_0/mu_loss           | 6.125360083109957      |
| train_0/next_q            | -5.960014789955302     |
| train_0/q_grads           | 0.020206177420914174   |
| train_0/q_grads_std       | 0.40918069928884504    |
| train_0/q_loss            | 0.5254166387241508     |
| train_0/reward            | -0.7787596450994897    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.100732421875         |
| train_0/target_q          | -6.316638630597455     |
| train_1/avg_q             | -14.729152771072451    |
| train_1/current_q         | -12.405423670926599    |
| train_1/fw_bonus          | -0.9996273562312126    |
| train_1/fw_loss           | 0.0009242127809557133  |
| train_1/mu_grads          | -0.04554281737655401   |
| train_1/mu_grads_std      | 0.6270068392157555     |
| train_1/mu_loss           | 12.689016411124552     |
| train_1/n_subgoals        | 1680.0                 |
| train_1/next_q            | -12.393413698975488    |
| train_1/q_grads           | -0.09025894310325384   |
| train_1/q_grads_std       | 0.7028746202588081     |
| train_1/q_loss            | 6.479678809448811      |
| train_1/reward            | -1.9405013169543963    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0062744140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3267857142857143     |
| train_1/target_q          | -12.491098778480978    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11000000000000001
Training epoch 37
Time for epoch 37: 714.84. Rollout time: 420.88, Training time: 293.73
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 2285007.0              |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.5614642049434848    |
| test_1/avg_q              | -11.192286743405726    |
| test_1/n_subgoals         | 1776.0                 |
| test_1/subgoal_succ_rate  | 0.7032657657657657     |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -11.892998294161876    |
| train_0/current_q         | -6.3819943611943915    |
| train_0/fw_bonus          | -0.9991895020008087    |
| train_0/fw_loss           | 0.00022258503049670252 |
| train_0/mu_grads          | -0.14765808247029782   |
| train_0/mu_grads_std      | 0.6136268690228462     |
| train_0/mu_loss           | 6.218202007389783      |
| train_0/next_q            | -6.035568928630022     |
| train_0/q_grads           | 0.020993199804797767   |
| train_0/q_grads_std       | 0.4145047150552273     |
| train_0/q_loss            | 0.7235080896302535     |
| train_0/reward            | -0.7773608514016814    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0836669921875        |
| train_0/target_q          | -6.327844409174049     |
| train_1/avg_q             | -15.137647720871948    |
| train_1/current_q         | -12.472450237275329    |
| train_1/fw_bonus          | -0.999417231976986     |
| train_1/fw_loss           | 0.0009739496585098095  |
| train_1/mu_grads          | -0.04594798581674695   |
| train_1/mu_grads_std      | 0.6367457136511803     |
| train_1/mu_loss           | 12.737448953466913     |
| train_1/n_subgoals        | 1780.0                 |
| train_1/next_q            | -12.544071764454628    |
| train_1/q_grads           | -0.09089199882000684   |
| train_1/q_grads_std       | 0.7102386102080345     |
| train_1/q_loss            | 5.1396538321693495     |
| train_1/reward            | -1.9470588967291405    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078857421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2792134831460674     |
| train_1/target_q          | -12.570783322260407    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16000000000000003
Training epoch 38
Time for epoch 38: 662.73. Rollout time: 380.11, Training time: 282.55
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 2337716.0              |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.7571979413134537    |
| test_1/avg_q              | -12.001901800131288    |
| test_1/n_subgoals         | 5892.0                 |
| test_1/subgoal_succ_rate  | 0.9630006788866259     |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.67                   |
| train_0/avg_q             | -10.451504121180788    |
| train_0/current_q         | -5.223270790532644     |
| train_0/fw_bonus          | -0.9991641819477082    |
| train_0/fw_loss           | 0.00022936411332921124 |
| train_0/mu_grads          | -0.148412449285388     |
| train_0/mu_grads_std      | 0.6190547317266464     |
| train_0/mu_loss           | 5.079390680056449      |
| train_0/next_q            | -4.841756571692715     |
| train_0/q_grads           | 0.020285269105806948   |
| train_0/q_grads_std       | 0.41772763058543205    |
| train_0/q_loss            | 0.7490090014770663     |
| train_0/reward            | -0.7764023716415978    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.07138671875          |
| train_0/target_q          | -5.1398090013787225    |
| train_1/avg_q             | -14.902090317592732    |
| train_1/current_q         | -9.551799852977519     |
| train_1/fw_bonus          | -0.9991814389824867    |
| train_1/fw_loss           | 0.0010297611603164113  |
| train_1/mu_grads          | -0.046071077976375815  |
| train_1/mu_grads_std      | 0.647401288151741      |
| train_1/mu_loss           | 9.385316862023572      |
| train_1/n_subgoals        | 1801.0                 |
| train_1/next_q            | -9.176837042136418     |
| train_1/q_grads           | -0.0946035236120224    |
| train_1/q_grads_std       | 0.7193902626633644     |
| train_1/q_loss            | 6.730659021830057      |
| train_1/reward            | -1.9851225082340533    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0067138671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25818989450305385    |
| train_1/target_q          | -9.724240424897989     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.26
Training epoch 39
Time for epoch 39: 709.44. Rollout time: 387.64, Training time: 321.66
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 2389340.0              |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -0.7262963427867766    |
| test_1/avg_q              | -20.10354699287065     |
| test_1/n_subgoals         | 2171.0                 |
| test_1/subgoal_succ_rate  | 0.7333026255181944     |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -10.781325242813123    |
| train_0/current_q         | -5.603706402696853     |
| train_0/fw_bonus          | -0.9991808712482453    |
| train_0/fw_loss           | 0.00022489440852950792 |
| train_0/mu_grads          | -0.1492749448865652    |
| train_0/mu_grads_std      | 0.6247241407632828     |
| train_0/mu_loss           | 5.352171138234333      |
| train_0/next_q            | -5.188897155188904     |
| train_0/q_grads           | 0.019883596524596214   |
| train_0/q_grads_std       | 0.420145870000124      |
| train_0/q_loss            | 0.48698677675084906    |
| train_0/reward            | -0.7747585968794738    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.093212890625         |
| train_0/target_q          | -5.597853344193988     |
| train_1/avg_q             | -14.31705570049428     |
| train_1/current_q         | -10.17559554584485     |
| train_1/fw_bonus          | -0.9993741318583489    |
| train_1/fw_loss           | 0.000984149018768221   |
| train_1/mu_grads          | -0.04748021988198161   |
| train_1/mu_grads_std      | 0.6548649683594704     |
| train_1/mu_loss           | 10.230784437536027     |
| train_1/n_subgoals        | 1713.0                 |
| train_1/next_q            | -9.958691616599712     |
| train_1/q_grads           | -0.09789712559431792   |
| train_1/q_grads_std       | 0.7300448194146156     |
| train_1/q_loss            | 7.411418730915796      |
| train_1/reward            | -2.0057517373068547    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0073974609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36544074722708697    |
| train_1/target_q          | -10.36747140636064     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.21
Training epoch 40
Time for epoch 40: 825.12. Rollout time: 508.50, Training time: 316.44
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 2438979.0              |
| test/episodes             | 1025.0                 |
| test/success_rate         | 0.24                   |
| test_0/avg_q              | -1.3412502372049955    |
| test_1/avg_q              | -17.907522429731053    |
| test_1/n_subgoals         | 3219.0                 |
| test_1/subgoal_succ_rate  | 0.8720099409754583     |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -10.50901552234152     |
| train_0/current_q         | -5.685703052071572     |
| train_0/fw_bonus          | -0.999222582578659     |
| train_0/fw_loss           | 0.00021372903283918278 |
| train_0/mu_grads          | -0.1480175420641899    |
| train_0/mu_grads_std      | 0.6322082415223121     |
| train_0/mu_loss           | 5.4445480761831035     |
| train_0/next_q            | -5.29369533601519      |
| train_0/q_grads           | 0.020934946835041046   |
| train_0/q_grads_std       | 0.42201189920306204    |
| train_0/q_loss            | 0.6205321497716106     |
| train_0/reward            | -0.774219708416058     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1111328125           |
| train_0/target_q          | -5.62464541277499      |
| train_1/avg_q             | -14.938931610255363    |
| train_1/current_q         | -12.491924754814567    |
| train_1/fw_bonus          | -0.9990270629525184    |
| train_1/fw_loss           | 0.001066304580308497   |
| train_1/mu_grads          | -0.048520000744611026  |
| train_1/mu_grads_std      | 0.6645998060703278     |
| train_1/mu_loss           | 12.715063669300182     |
| train_1/n_subgoals        | 1727.0                 |
| train_1/next_q            | -12.506098414579231    |
| train_1/q_grads           | -0.09924400206655264   |
| train_1/q_grads_std       | 0.7443915918469429     |
| train_1/q_loss            | 5.999944361075203      |
| train_1/reward            | -2.0119088625400763    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007763671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36479444122756227    |
| train_1/target_q          | -12.61822156040569     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.23
Training epoch 41
Time for epoch 41: 33059.13. Rollout time: 17838.51, Training time: 15220.25
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2489257.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.6981806627950136    |
| test_1/avg_q              | -16.4774474526628      |
| test_1/n_subgoals         | 3299.0                 |
| test_1/subgoal_succ_rate  | 0.8933010003031222     |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -11.868404075821251    |
| train_0/current_q         | -5.820065227802485     |
| train_0/fw_bonus          | -0.9991150930523872    |
| train_0/fw_loss           | 0.00024250254573416897 |
| train_0/mu_grads          | -0.1506087753921747    |
| train_0/mu_grads_std      | 0.6379905313253402     |
| train_0/mu_loss           | 5.590804124444541      |
| train_0/next_q            | -5.426563519938793     |
| train_0/q_grads           | 0.022137099551036953   |
| train_0/q_grads_std       | 0.4260522723197937     |
| train_0/q_loss            | 0.5319138779786571     |
| train_0/reward            | -0.7703659309470823    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.059326171875         |
| train_0/target_q          | -5.793777970238073     |
| train_1/avg_q             | -16.398962180224867    |
| train_1/current_q         | -12.453950583284975    |
| train_1/fw_bonus          | -0.999513067305088     |
| train_1/fw_loss           | 0.0009512627395452001  |
| train_1/mu_grads          | -0.048520783241838214  |
| train_1/mu_grads_std      | 0.6745681554079056     |
| train_1/mu_loss           | 12.62824589903698      |
| train_1/n_subgoals        | 1716.0                 |
| train_1/next_q            | -12.486864471264113    |
| train_1/q_grads           | -0.10027960054576397   |
| train_1/q_grads_std       | 0.7562784254550934     |
| train_1/q_loss            | 5.906590903170122      |
| train_1/reward            | -2.0213138143273683    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00693359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.30128205128205127    |
| train_1/target_q          | -12.551972138542206    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.28
Training epoch 42
Time for epoch 42: 2304.06. Rollout time: 1461.51, Training time: 842.15
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 2538994.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.925878595354241     |
| test_1/avg_q              | -14.819078743416583    |
| test_1/n_subgoals         | 2057.0                 |
| test_1/subgoal_succ_rate  | 0.7870685464268352     |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -14.5352460046937      |
| train_0/current_q         | -6.327668588367905     |
| train_0/fw_bonus          | -0.9991991639137268    |
| train_0/fw_loss           | 0.00022000072567607276 |
| train_0/mu_grads          | -0.15479303598403932   |
| train_0/mu_grads_std      | 0.6431521117687226     |
| train_0/mu_loss           | 6.149492498866621      |
| train_0/next_q            | -5.94735262955985      |
| train_0/q_grads           | 0.022360472520813347   |
| train_0/q_grads_std       | 0.43050303012132646    |
| train_0/q_loss            | 0.5709923990181072     |
| train_0/reward            | -0.7685925129855604    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.107080078125         |
| train_0/target_q          | -6.278168349714364     |
| train_1/avg_q             | -14.831467120899472    |
| train_1/current_q         | -12.84557216630825     |
| train_1/fw_bonus          | -0.9993378758430481    |
| train_1/fw_loss           | 0.0009927316365065052  |
| train_1/mu_grads          | -0.049133222363889215  |
| train_1/mu_grads_std      | 0.6830469816923141     |
| train_1/mu_loss           | 13.159136336628496     |
| train_1/n_subgoals        | 1687.0                 |
| train_1/next_q            | -12.953150026108029    |
| train_1/q_grads           | -0.10226974748075009   |
| train_1/q_grads_std       | 0.7672569319605828     |
| train_1/q_loss            | 5.942204839589428      |
| train_1/reward            | -1.975823238025987     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0062744140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.34617664493183165    |
| train_1/target_q          | -12.984872264383762    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.26
Training epoch 43
Time for epoch 43: 853.62. Rollout time: 502.02, Training time: 351.45
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 2587647.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.56                   |
| test_0/avg_q              | -1.633490320329494     |
| test_1/avg_q              | -16.334280960854784    |
| test_1/n_subgoals         | 5697.0                 |
| test_1/subgoal_succ_rate  | 0.9710373880989994     |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -14.133600921749876    |
| train_0/current_q         | -6.879423617395003     |
| train_0/fw_bonus          | -0.9987445026636124    |
| train_0/fw_loss           | 0.00034170006110798565 |
| train_0/mu_grads          | -0.15360504500567912   |
| train_0/mu_grads_std      | 0.6493539229035378     |
| train_0/mu_loss           | 6.643350070482633      |
| train_0/next_q            | -6.462109301694295     |
| train_0/q_grads           | 0.022773962793871762   |
| train_0/q_grads_std       | 0.43561294600367545    |
| train_0/q_loss            | 0.40428240411322075    |
| train_0/reward            | -0.7652745052484533    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0648681640625        |
| train_0/target_q          | -6.8420274703374515    |
| train_1/avg_q             | -14.768444025507868    |
| train_1/current_q         | -13.246629599286214    |
| train_1/fw_bonus          | -0.9842206418514252    |
| train_1/fw_loss           | 0.004571092559490353   |
| train_1/mu_grads          | -0.04853655649349094   |
| train_1/mu_grads_std      | 0.6896568685770035     |
| train_1/mu_loss           | 13.641667670067068     |
| train_1/n_subgoals        | 1799.0                 |
| train_1/next_q            | -13.463744907748998    |
| train_1/q_grads           | -0.10307870246469975   |
| train_1/q_grads_std       | 0.7764952555298805     |
| train_1/q_loss            | 5.328458805874146      |
| train_1/reward            | -2.039133773897265     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0041259765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3451917732073374     |
| train_1/target_q          | -13.372260103629449    |
------------------------------------------------------
New best value for test/success_rate: 0.56. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 44
Time for epoch 44: 831.11. Rollout time: 472.09, Training time: 358.76
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 2632881.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.24                  |
| test_0/avg_q              | -1.9124038065987687   |
| test_1/avg_q              | -12.79925754172282    |
| test_1/n_subgoals         | 3304.0                |
| test_1/subgoal_succ_rate  | 0.8992130750605327    |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.79                  |
| train_0/avg_q             | -13.293975846799361   |
| train_0/current_q         | -6.894640234548646    |
| train_0/fw_bonus          | -0.9987899750471115   |
| train_0/fw_loss           | 0.0003295277354482096 |
| train_0/mu_grads          | -0.15779306441545488  |
| train_0/mu_grads_std      | 0.6551002398133278    |
| train_0/mu_loss           | 6.695386219873853     |
| train_0/next_q            | -6.539524422648364    |
| train_0/q_grads           | 0.022976698400452734  |
| train_0/q_grads_std       | 0.4401423178613186    |
| train_0/q_loss            | 0.5431034853240372    |
| train_0/reward            | -0.767409897259131    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0757568359375       |
| train_0/target_q          | -6.862634618482875    |
| train_1/avg_q             | -14.640876045563779   |
| train_1/current_q         | -11.926317235839395   |
| train_1/fw_bonus          | -0.989079338312149    |
| train_1/fw_loss           | 0.003421002172399312  |
| train_1/mu_grads          | -0.048606493044644594 |
| train_1/mu_grads_std      | 0.6931583672761917    |
| train_1/mu_loss           | 12.08755122115565     |
| train_1/n_subgoals        | 1544.0                |
| train_1/next_q            | -11.913481025856386   |
| train_1/q_grads           | -0.10417913496494294  |
| train_1/q_grads_std       | 0.7871555119752884    |
| train_1/q_loss            | 6.122524684593484     |
| train_1/reward            | -2.017734924613978    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00615234375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.37305699481865284   |
| train_1/target_q          | -12.039746269931989   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 45
Time for epoch 45: 896.17. Rollout time: 493.97, Training time: 402.01
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 2674061.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.36                  |
| test_0/avg_q              | -1.5339458676271625   |
| test_1/avg_q              | -13.148665363696656   |
| test_1/n_subgoals         | 4423.0                |
| test_1/subgoal_succ_rate  | 0.9579470947320823    |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -15.173298858888588   |
| train_0/current_q         | -6.7135631370896975   |
| train_0/fw_bonus          | -0.9989989623427391   |
| train_0/fw_loss           | 0.0002735887832386652 |
| train_0/mu_grads          | -0.15708346515893937  |
| train_0/mu_grads_std      | 0.6624386221170425    |
| train_0/mu_loss           | 6.499206080642597     |
| train_0/next_q            | -6.355908168262263    |
| train_0/q_grads           | 0.023083999333903194  |
| train_0/q_grads_std       | 0.4448652774095535    |
| train_0/q_loss            | 0.5986004370844276    |
| train_0/reward            | -0.7700805501201102   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0685791015625       |
| train_0/target_q          | -6.684194736072745    |
| train_1/avg_q             | -14.100122578653389   |
| train_1/current_q         | -12.251951298258266   |
| train_1/fw_bonus          | -0.9915109097957611   |
| train_1/fw_loss           | 0.002845435304334387  |
| train_1/mu_grads          | -0.04827389130368829  |
| train_1/mu_grads_std      | 0.6968023687601089    |
| train_1/mu_loss           | 12.444128158875278    |
| train_1/n_subgoals        | 1468.0                |
| train_1/next_q            | -12.33024911157255    |
| train_1/q_grads           | -0.10707106012851     |
| train_1/q_grads_std       | 0.7984830304980278    |
| train_1/q_loss            | 5.577268329001567     |
| train_1/reward            | -1.9976885165771818   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0057373046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.40667574931880107   |
| train_1/target_q          | -12.36831731988947    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.37
Training epoch 46
Time for epoch 46: 1006.56. Rollout time: 616.47, Training time: 389.82
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 2717325.0             |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -2.9845464226387146   |
| test_1/avg_q              | -11.062820295141977   |
| test_1/n_subgoals         | 883.0                 |
| test_1/subgoal_succ_rate  | 0.6727066817667045    |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.73                  |
| train_0/avg_q             | -13.019223488676728   |
| train_0/current_q         | -6.294957288785306    |
| train_0/fw_bonus          | -0.9985727086663246   |
| train_0/fw_loss           | 0.0003876871287502581 |
| train_0/mu_grads          | -0.15994659513235093  |
| train_0/mu_grads_std      | 0.6720537662506103    |
| train_0/mu_loss           | 6.083385568889472     |
| train_0/next_q            | -5.918913861043777    |
| train_0/q_grads           | 0.0229116216301918    |
| train_0/q_grads_std       | 0.44918189719319346   |
| train_0/q_loss            | 0.5263963826722268    |
| train_0/reward            | -0.7710909299756168   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.097265625           |
| train_0/target_q          | -6.290274642706656    |
| train_1/avg_q             | -13.324007449543332   |
| train_1/current_q         | -12.268166001033544   |
| train_1/fw_bonus          | -0.9932820856571197   |
| train_1/fw_loss           | 0.002426184358773753  |
| train_1/mu_grads          | -0.04821384325623512  |
| train_1/mu_grads_std      | 0.6993401303887368    |
| train_1/mu_loss           | 12.527100107147968    |
| train_1/n_subgoals        | 1625.0                |
| train_1/next_q            | -12.418891404072275   |
| train_1/q_grads           | -0.10902542602270841  |
| train_1/q_grads_std       | 0.8094084098935127    |
| train_1/q_loss            | 5.838110658388656     |
| train_1/reward            | -1.9660329222031578   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00634765625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.34892307692307695   |
| train_1/target_q          | -12.375002529345632   |
-----------------------------------------------------
New best value for test/success_rate: 0.6. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.44000000000000006
Training epoch 47
Time for epoch 47: 897.73. Rollout time: 504.29, Training time: 393.21
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 2764173.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -2.9714363644501       |
| test_1/avg_q              | -10.487595734752233    |
| test_1/n_subgoals         | 632.0                  |
| test_1/subgoal_succ_rate  | 0.05379746835443038    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -14.273755624598577    |
| train_0/current_q         | -5.694016018879369     |
| train_0/fw_bonus          | -0.9989941731095314    |
| train_0/fw_loss           | 0.00027486715734994507 |
| train_0/mu_grads          | -0.16200222373008727   |
| train_0/mu_grads_std      | 0.6772744908928872     |
| train_0/mu_loss           | 5.5373836042781015     |
| train_0/next_q            | -5.346214914429801     |
| train_0/q_grads           | 0.02338845287449658    |
| train_0/q_grads_std       | 0.4540488734841347     |
| train_0/q_loss            | 0.5970037201690779     |
| train_0/reward            | -0.7728442488132714    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0778564453125        |
| train_0/target_q          | -5.7008511021997       |
| train_1/avg_q             | -13.77001489530953     |
| train_1/current_q         | -11.967626371400256    |
| train_1/fw_bonus          | -0.9938248947262764    |
| train_1/fw_loss           | 0.0022976969601586463  |
| train_1/mu_grads          | -0.04809190109372139   |
| train_1/mu_grads_std      | 0.7027318596839904     |
| train_1/mu_loss           | 12.149273711645288     |
| train_1/n_subgoals        | 1469.0                 |
| train_1/next_q            | -12.067622314325451    |
| train_1/q_grads           | -0.11108725238591433   |
| train_1/q_grads_std       | 0.8230073735117912     |
| train_1/q_loss            | 5.757904691710988      |
| train_1/reward            | -1.941540939634433     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075439453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35398230088495575    |
| train_1/target_q          | -12.075983545635612    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.32999999999999996
Training epoch 48
Time for epoch 48: 949.35. Rollout time: 577.12, Training time: 372.02
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 2812068.0              |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -2.159656780116499     |
| test_1/avg_q              | -11.328736235635548    |
| test_1/n_subgoals         | 3246.0                 |
| test_1/subgoal_succ_rate  | 0.9328404189772027     |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -12.393000046341337    |
| train_0/current_q         | -6.754669989615668     |
| train_0/fw_bonus          | -0.9987372785806656    |
| train_0/fw_loss           | 0.00034363641316303983 |
| train_0/mu_grads          | -0.1613157007843256    |
| train_0/mu_grads_std      | 0.6837883681058884     |
| train_0/mu_loss           | 6.566374228815446      |
| train_0/next_q            | -6.38789772800664      |
| train_0/q_grads           | 0.023779648588970304   |
| train_0/q_grads_std       | 0.4589823096990585     |
| train_0/q_loss            | 0.5190732755989764     |
| train_0/reward            | -0.7696855386497191    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.10048828125          |
| train_0/target_q          | -6.738806338963485     |
| train_1/avg_q             | -12.047559550896876    |
| train_1/current_q         | -11.962746685208769    |
| train_1/fw_bonus          | -0.9944445088505744    |
| train_1/fw_loss           | 0.0021510262944502757  |
| train_1/mu_grads          | -0.04845051746815443   |
| train_1/mu_grads_std      | 0.7057869404554367     |
| train_1/mu_loss           | 12.085842822393346     |
| train_1/n_subgoals        | 1669.0                 |
| train_1/next_q            | -12.01743429702373     |
| train_1/q_grads           | -0.11305836290121078   |
| train_1/q_grads_std       | 0.8334868058562279     |
| train_1/q_loss            | 6.296742074044346      |
| train_1/reward            | -2.0048672338354665    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007373046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.243858597962852      |
| train_1/target_q          | -12.070700129740178    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.39
Training epoch 49
Time for epoch 49: 884.87. Rollout time: 509.06, Training time: 375.54
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 2856295.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.24                  |
| test_0/avg_q              | -1.0272736809612564   |
| test_1/avg_q              | -10.70360765101898    |
| test_1/n_subgoals         | 7047.0                |
| test_1/subgoal_succ_rate  | 0.9625372498935717    |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -13.645145649559096   |
| train_0/current_q         | -5.2468107678845035   |
| train_0/fw_bonus          | -0.9991104394197464   |
| train_0/fw_loss           | 0.000243746497653774  |
| train_0/mu_grads          | -0.1611705504357815   |
| train_0/mu_grads_std      | 0.6896059900522232    |
| train_0/mu_loss           | 5.0568132190677275    |
| train_0/next_q            | -4.889383695864764    |
| train_0/q_grads           | 0.023343278933316468  |
| train_0/q_grads_std       | 0.4639956921339035    |
| train_0/q_loss            | 0.5417154183641363    |
| train_0/reward            | -0.7751255112667422   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.094189453125        |
| train_0/target_q          | -5.358124827037672    |
| train_1/avg_q             | -12.860139585663134   |
| train_1/current_q         | -11.486626757282036   |
| train_1/fw_bonus          | -0.9944033935666085   |
| train_1/fw_loss           | 0.0021607609145576135 |
| train_1/mu_grads          | -0.048253164533525704 |
| train_1/mu_grads_std      | 0.7092316716909408    |
| train_1/mu_loss           | 11.608050144741535    |
| train_1/n_subgoals        | 1498.0                |
| train_1/next_q            | -11.497439269283756   |
| train_1/q_grads           | -0.11395631525665521  |
| train_1/q_grads_std       | 0.8438916459679604    |
| train_1/q_loss            | 6.210392066055113     |
| train_1/reward            | -1.9391037780391343   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0080810546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3985313751668892    |
| train_1/target_q          | -11.593964122444003   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.36
Training epoch 50
Time for epoch 50: 883.57. Rollout time: 480.01, Training time: 403.36
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 2891124.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -1.473306560280968    |
| test_1/avg_q              | -9.06187598155475     |
| test_1/n_subgoals         | 4479.0                |
| test_1/subgoal_succ_rate  | 0.9821388702835454    |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -10.71778107180088    |
| train_0/current_q         | -6.14949353219867     |
| train_0/fw_bonus          | -0.9987595483660698   |
| train_0/fw_loss           | 0.0003376700060471194 |
| train_0/mu_grads          | -0.16359035409986972  |
| train_0/mu_grads_std      | 0.6945487156510353    |
| train_0/mu_loss           | 5.932214863706248     |
| train_0/next_q            | -5.7503189814336135   |
| train_0/q_grads           | 0.023629413824528454  |
| train_0/q_grads_std       | 0.46691111102700233   |
| train_0/q_loss            | 0.5834352047307361    |
| train_0/reward            | -0.7786449683590035   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.080859375           |
| train_0/target_q          | -6.106373207120411    |
| train_1/avg_q             | -12.127441109188247   |
| train_1/current_q         | -11.393540408680646   |
| train_1/fw_bonus          | -0.9940074115991593   |
| train_1/fw_loss           | 0.0022544950887095185 |
| train_1/mu_grads          | -0.048619665391743186 |
| train_1/mu_grads_std      | 0.7121698066592217    |
| train_1/mu_loss           | 11.381360287152892    |
| train_1/n_subgoals        | 1401.0                |
| train_1/next_q            | -11.333485884104874   |
| train_1/q_grads           | -0.11516052056103945  |
| train_1/q_grads_std       | 0.8568298876285553    |
| train_1/q_loss            | 7.4608964885115       |
| train_1/reward            | -1.9317721148800047   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0070556640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.396859386152748     |
| train_1/target_q          | -11.442468065557083   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_50.pkl ...
New best value for test/success_rate: 0.76. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.4
Training epoch 51
Time for epoch 51: 704.05. Rollout time: 367.13, Training time: 336.73
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 2928277.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.3866253023741848   |
| test_1/avg_q              | -11.741381123900304   |
| test_1/n_subgoals         | 1903.0                |
| test_1/subgoal_succ_rate  | 0.8281660535995796    |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.79                  |
| train_0/avg_q             | -11.401632795925952   |
| train_0/current_q         | -6.560624581503649    |
| train_0/fw_bonus          | -0.9988204210996627   |
| train_0/fw_loss           | 0.0003213772924937075 |
| train_0/mu_grads          | -0.16639452911913394  |
| train_0/mu_grads_std      | 0.699368679523468     |
| train_0/mu_loss           | 6.403732788180764     |
| train_0/next_q            | -6.2158137382784435   |
| train_0/q_grads           | 0.023596643609926103  |
| train_0/q_grads_std       | 0.4696956627070904    |
| train_0/q_loss            | 0.6835197204034904    |
| train_0/reward            | -0.7796123335272569   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0828369140625       |
| train_0/target_q          | -6.526502237867744    |
| train_1/avg_q             | -11.667394594522278   |
| train_1/current_q         | -10.887806392527      |
| train_1/fw_bonus          | -0.9938766762614251   |
| train_1/fw_loss           | 0.002285436526290141  |
| train_1/mu_grads          | -0.05025647934526205  |
| train_1/mu_grads_std      | 0.714847457408905     |
| train_1/mu_loss           | 10.76837299178462     |
| train_1/n_subgoals        | 1420.0                |
| train_1/next_q            | -10.67568550109296    |
| train_1/q_grads           | -0.11623737867921591  |
| train_1/q_grads_std       | 0.8681094825267792    |
| train_1/q_loss            | 6.28164648512097      |
| train_1/reward            | -1.9686718090481008   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0065185546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4556338028169014    |
| train_1/target_q          | -10.98208366795821    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.49
Training epoch 52
Time for epoch 52: 896.09. Rollout time: 473.47, Training time: 422.41
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 52                    |
| policy/steps              | 2970358.0             |
| test/episodes             | 1325.0                |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.0105732343892582   |
| test_1/avg_q              | -10.46409793683405    |
| test_1/n_subgoals         | 4556.0                |
| test_1/subgoal_succ_rate  | 0.9122036874451273    |
| train/episodes            | 5300.0                |
| train/success_rate        | 0.81                  |
| train_0/avg_q             | -12.314000768366451   |
| train_0/current_q         | -6.652260808104184    |
| train_0/fw_bonus          | -0.9990258350968361   |
| train_0/fw_loss           | 0.0002663935472810408 |
| train_0/mu_grads          | -0.16972039230167865  |
| train_0/mu_grads_std      | 0.7058764934539795    |
| train_0/mu_loss           | 6.458007797271804     |
| train_0/next_q            | -6.281597771782183    |
| train_0/q_grads           | 0.02359860176220536   |
| train_0/q_grads_std       | 0.47159905806183816   |
| train_0/q_loss            | 0.5723894215291173    |
| train_0/reward            | -0.782337025839297    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1094970703125       |
| train_0/target_q          | -6.643255064997687    |
| train_1/avg_q             | -12.76310548510785    |
| train_1/current_q         | -10.360281375161545   |
| train_1/fw_bonus          | -0.9940967664122582   |
| train_1/fw_loss           | 0.0022333411092404277 |
| train_1/mu_grads          | -0.05025896402075887  |
| train_1/mu_grads_std      | 0.7183455437421798    |
| train_1/mu_loss           | 10.232607131689255    |
| train_1/n_subgoals        | 1403.0                |
| train_1/next_q            | -10.127323138141506   |
| train_1/q_grads           | -0.11764858402311802  |
| train_1/q_grads_std       | 0.8787233412265778    |
| train_1/q_loss            | 5.810712823775276     |
| train_1/reward            | -1.9553235080562446   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0076904296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.41696364932287955   |
| train_1/target_q          | -10.493574653959044   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.42
Training epoch 53
Time for epoch 53: 765.88. Rollout time: 396.64, Training time: 369.01
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 3008059.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -1.4194454646729697    |
| test_1/avg_q              | -9.00169061353332      |
| test_1/n_subgoals         | 3514.0                 |
| test_1/subgoal_succ_rate  | 0.9433693796243597     |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -12.090050927311937    |
| train_0/current_q         | -6.506926177954161     |
| train_0/fw_bonus          | -0.9986844033002853    |
| train_0/fw_loss           | 0.00035778575802396516 |
| train_0/mu_grads          | -0.1733729351311922    |
| train_0/mu_grads_std      | 0.7118690922856331     |
| train_0/mu_loss           | 6.290482283352293      |
| train_0/next_q            | -6.109113861576672     |
| train_0/q_grads           | 0.023358471831306814   |
| train_0/q_grads_std       | 0.47338286936283114    |
| train_0/q_loss            | 0.5477519437323917     |
| train_0/reward            | -0.7859503998966829    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.107666015625         |
| train_0/target_q          | -6.47960476544722      |
| train_1/avg_q             | -12.444131513617616    |
| train_1/current_q         | -9.998664373864315     |
| train_1/fw_bonus          | -0.9939938127994538    |
| train_1/fw_loss           | 0.002257711149286479   |
| train_1/mu_grads          | -0.05044365450739861   |
| train_1/mu_grads_std      | 0.7211517259478569     |
| train_1/mu_loss           | 9.931127544300246      |
| train_1/n_subgoals        | 1418.0                 |
| train_1/next_q            | -9.799762010794092     |
| train_1/q_grads           | -0.11826104912906885   |
| train_1/q_grads_std       | 0.8882896929979325     |
| train_1/q_loss            | 5.909223302272628      |
| train_1/reward            | -1.9062255048429506    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007763671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4139633286318759     |
| train_1/target_q          | -10.122029167884879    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.48
Training epoch 54
Time for epoch 54: 791.08. Rollout time: 446.42, Training time: 344.43
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 3048109.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.52                   |
| test_0/avg_q              | -1.3398441994198405    |
| test_1/avg_q              | -9.358413064362205     |
| test_1/n_subgoals         | 7294.0                 |
| test_1/subgoal_succ_rate  | 0.9934192486975596     |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.82                   |
| train_0/avg_q             | -12.858304237588012    |
| train_0/current_q         | -6.819811963451332     |
| train_0/fw_bonus          | -0.9991540715098381    |
| train_0/fw_loss           | 0.00023206645455502438 |
| train_0/mu_grads          | -0.17582265697419644   |
| train_0/mu_grads_std      | 0.7170399740338326     |
| train_0/mu_loss           | 6.577857227144977      |
| train_0/next_q            | -6.408946439599606     |
| train_0/q_grads           | 0.023800392914563418   |
| train_0/q_grads_std       | 0.4763579308986664     |
| train_0/q_loss            | 0.46238349540066137    |
| train_0/reward            | -0.787019964981664     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1035400390625        |
| train_0/target_q          | -6.801822067745737     |
| train_1/avg_q             | -12.812716626135332    |
| train_1/current_q         | -9.871980223136308     |
| train_1/fw_bonus          | -0.9940898671746254    |
| train_1/fw_loss           | 0.00223497643310111    |
| train_1/mu_grads          | -0.050166362430900335  |
| train_1/mu_grads_std      | 0.7250186264514923     |
| train_1/mu_loss           | 9.671837392903274      |
| train_1/n_subgoals        | 1551.0                 |
| train_1/next_q            | -9.59109549572566      |
| train_1/q_grads           | -0.12128319274634122   |
| train_1/q_grads_std       | 0.8988411471247673     |
| train_1/q_loss            | 6.334769339005292      |
| train_1/reward            | -1.8243281295202904    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078125              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3971631205673759     |
| train_1/target_q          | -9.952639272452483     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.42
Training epoch 55
Time for epoch 55: 1398.96. Rollout time: 982.39, Training time: 416.29
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 3087045.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -0.9638334964014229   |
| test_1/avg_q              | -11.691278311099413   |
| test_1/n_subgoals         | 2404.0                |
| test_1/subgoal_succ_rate  | 0.8935108153078203    |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.78                  |
| train_0/avg_q             | -12.552676332381633   |
| train_0/current_q         | -6.9446241017801045   |
| train_0/fw_bonus          | -0.9991507634520531   |
| train_0/fw_loss           | 0.0002329523311345838 |
| train_0/mu_grads          | -0.17449965551495553  |
| train_0/mu_grads_std      | 0.7225623697042465    |
| train_0/mu_loss           | 6.705890435381377     |
| train_0/next_q            | -6.526414678397169    |
| train_0/q_grads           | 0.023952757846564053  |
| train_0/q_grads_std       | 0.4800547532737255    |
| train_0/q_loss            | 0.46004584029157874   |
| train_0/reward            | -0.7932081022408966   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.124658203125        |
| train_0/target_q          | -6.944477792790826    |
| train_1/avg_q             | -11.811412161897087   |
| train_1/current_q         | -9.75300893157566     |
| train_1/fw_bonus          | -0.9940122693777085   |
| train_1/fw_loss           | 0.002253343310439959  |
| train_1/mu_grads          | -0.05017083147540689  |
| train_1/mu_grads_std      | 0.7289601653814316    |
| train_1/mu_loss           | 9.546776984376466     |
| train_1/n_subgoals        | 1511.0                |
| train_1/next_q            | -9.480761044966417    |
| train_1/q_grads           | -0.1224061606451869   |
| train_1/q_grads_std       | 0.9079487890005111    |
| train_1/q_loss            | 6.349980531000634     |
| train_1/reward            | -1.882664444729744    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007470703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4493712772998015    |
| train_1/target_q          | -9.855001403864156    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.44999999999999996
Training epoch 56
Time for epoch 56: 989.05. Rollout time: 548.62, Training time: 440.20
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 3125376.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.52                   |
| test_0/avg_q              | -1.6271729918231257    |
| test_1/avg_q              | -11.040528962147317    |
| test_1/n_subgoals         | 1682.0                 |
| test_1/subgoal_succ_rate  | 0.8263971462544589     |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -13.232061058730276    |
| train_0/current_q         | -6.780692226017626     |
| train_0/fw_bonus          | -0.9991367354989051    |
| train_0/fw_loss           | 0.00023671000853937586 |
| train_0/mu_grads          | -0.1747912358492613    |
| train_0/mu_grads_std      | 0.728068046271801      |
| train_0/mu_loss           | 6.55825487507722       |
| train_0/next_q            | -6.391064258033113     |
| train_0/q_grads           | 0.02413204754702747    |
| train_0/q_grads_std       | 0.4825874984264374     |
| train_0/q_loss            | 0.5652120342430637     |
| train_0/reward            | -0.7901650421394152    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.09873046875          |
| train_0/target_q          | -6.759130523150992     |
| train_1/avg_q             | -12.904430413068958    |
| train_1/current_q         | -9.621440674310659     |
| train_1/fw_bonus          | -0.994000680744648     |
| train_1/fw_loss           | 0.0022560857149073856  |
| train_1/mu_grads          | -0.0492530413903296    |
| train_1/mu_grads_std      | 0.7335306242108345     |
| train_1/mu_loss           | 9.415673732236863      |
| train_1/n_subgoals        | 1459.0                 |
| train_1/next_q            | -9.322626396338233     |
| train_1/q_grads           | -0.12324921526014805   |
| train_1/q_grads_std       | 0.9152400732040405     |
| train_1/q_loss            | 6.268975473181704      |
| train_1/reward            | -1.8321061267721235    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00751953125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4139821795750514     |
| train_1/target_q          | -9.74710345241933      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.53
Training epoch 57
Time for epoch 57: 2105.88. Rollout time: 1422.61, Training time: 683.05
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 3158682.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.76                  |
| test_0/avg_q              | -1.3783628931744398   |
| test_1/avg_q              | -12.472595450602531   |
| test_1/n_subgoals         | 2353.0                |
| test_1/subgoal_succ_rate  | 0.9192520186995325    |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.82                  |
| train_0/avg_q             | -11.791950348550142   |
| train_0/current_q         | -6.600100880446094    |
| train_0/fw_bonus          | -0.999199016392231    |
| train_0/fw_loss           | 0.0002200359889684478 |
| train_0/mu_grads          | -0.17604454085230828  |
| train_0/mu_grads_std      | 0.7352213814854622    |
| train_0/mu_loss           | 6.413842368768866     |
| train_0/next_q            | -6.181804703615951    |
| train_0/q_grads           | 0.02451926819048822   |
| train_0/q_grads_std       | 0.4858041450381279    |
| train_0/q_loss            | 0.4260734750929128    |
| train_0/reward            | -0.7925609860922123   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.115625              |
| train_0/target_q          | -6.6264873763199645   |
| train_1/avg_q             | -11.940187800081215   |
| train_1/current_q         | -9.348634670788275    |
| train_1/fw_bonus          | -0.9943372026085854   |
| train_1/fw_loss           | 0.0021764254342997447 |
| train_1/mu_grads          | -0.04996821321547031  |
| train_1/mu_grads_std      | 0.7390603393316268    |
| train_1/mu_loss           | 9.106948554270717     |
| train_1/n_subgoals        | 1362.0                |
| train_1/next_q            | -8.98508302192283     |
| train_1/q_grads           | -0.12387720178812742  |
| train_1/q_grads_std       | 0.9211880430579186    |
| train_1/q_loss            | 6.289779075328066     |
| train_1/reward            | -1.8174868914702529   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0082275390625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4456681350954479    |
| train_1/target_q          | -9.454372657418725    |
-----------------------------------------------------
New best value for test/success_rate: 0.76. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6000000000000001
Training epoch 58
Time for epoch 58: 939.02. Rollout time: 471.64, Training time: 467.11
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 3188391.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -1.3161301541528967    |
| test_1/avg_q              | -13.02180502200416     |
| test_1/n_subgoals         | 3503.0                 |
| test_1/subgoal_succ_rate  | 0.9880102769055096     |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.82                   |
| train_0/avg_q             | -13.400434720606517    |
| train_0/current_q         | -6.484161686468684     |
| train_0/fw_bonus          | -0.9991468206048012    |
| train_0/fw_loss           | 0.00023401018443109934 |
| train_0/mu_grads          | -0.17611434757709504   |
| train_0/mu_grads_std      | 0.7390208095312119     |
| train_0/mu_loss           | 6.214983364280695      |
| train_0/next_q            | -6.034657926534954     |
| train_0/q_grads           | 0.0246215614490211     |
| train_0/q_grads_std       | 0.4890733450651169     |
| train_0/q_loss            | 0.3944152124628041     |
| train_0/reward            | -0.7905154638890963    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1166015625           |
| train_0/target_q          | -6.480725767471085     |
| train_1/avg_q             | -12.108357797578684    |
| train_1/current_q         | -9.256140310951068     |
| train_1/fw_bonus          | -0.9942856416106224    |
| train_1/fw_loss           | 0.0021886353613808753  |
| train_1/mu_grads          | -0.05036013247445226   |
| train_1/mu_grads_std      | 0.7418835178017616     |
| train_1/mu_loss           | 8.947733309797329      |
| train_1/n_subgoals        | 1256.0                 |
| train_1/next_q            | -8.880264348391075     |
| train_1/q_grads           | -0.1247872281819582    |
| train_1/q_grads_std       | 0.9281786054372787     |
| train_1/q_loss            | 5.642596140953168      |
| train_1/reward            | -1.7701595436403295    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007421875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4124203821656051     |
| train_1/target_q          | -9.368726243436962     |
------------------------------------------------------
New best value for test/success_rate: 0.88. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 59
Time for epoch 59: 1003.71. Rollout time: 537.50, Training time: 465.93
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 3222438.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.8                    |
| test_0/avg_q              | -0.9205511769641752    |
| test_1/avg_q              | -8.626061166132569     |
| test_1/n_subgoals         | 2196.0                 |
| test_1/subgoal_succ_rate  | 0.9599271402550091     |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -13.691001273421028    |
| train_0/current_q         | -6.651069677015639     |
| train_0/fw_bonus          | -0.9991640090942383    |
| train_0/fw_loss           | 0.00022940924027352593 |
| train_0/mu_grads          | -0.17555566802620887   |
| train_0/mu_grads_std      | 0.7452176317572594     |
| train_0/mu_loss           | 6.350945476294899      |
| train_0/next_q            | -6.1902915825625255    |
| train_0/q_grads           | 0.02498082211241126    |
| train_0/q_grads_std       | 0.4916925571858883     |
| train_0/q_loss            | 0.47133955061973226    |
| train_0/reward            | -0.7972763530284283    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1043701171875        |
| train_0/target_q          | -6.603663034068504     |
| train_1/avg_q             | -12.758475216221827    |
| train_1/current_q         | -9.590734170065623     |
| train_1/fw_bonus          | -0.9940615177154541    |
| train_1/fw_loss           | 0.002241687651257962   |
| train_1/mu_grads          | -0.050215940456837416  |
| train_1/mu_grads_std      | 0.7444418966770172     |
| train_1/mu_loss           | 9.38402135671948       |
| train_1/n_subgoals        | 1442.0                 |
| train_1/next_q            | -9.310136334171847     |
| train_1/q_grads           | -0.1253158777952194    |
| train_1/q_grads_std       | 0.9378410965204239     |
| train_1/q_loss            | 6.760724490428624      |
| train_1/reward            | -1.7888352010035304    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078857421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4001386962552011     |
| train_1/target_q          | -9.68387457104674      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.74
Training epoch 60
Time for epoch 60: 949.38. Rollout time: 546.06, Training time: 403.07
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 3265776.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.1857075160522699    |
| test_1/avg_q              | -9.119004187147693     |
| test_1/n_subgoals         | 3587.0                 |
| test_1/subgoal_succ_rate  | 0.9077223306384165     |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -14.75323118423599     |
| train_0/current_q         | -6.789853309828549     |
| train_0/fw_bonus          | -0.9992231130599976    |
| train_0/fw_loss           | 0.00021358633057388943 |
| train_0/mu_grads          | -0.17787837237119675   |
| train_0/mu_grads_std      | 0.7509979158639908     |
| train_0/mu_loss           | 6.532025991666737      |
| train_0/next_q            | -6.388712786619028     |
| train_0/q_grads           | 0.025787780759856105   |
| train_0/q_grads_std       | 0.4942601636052132     |
| train_0/q_loss            | 0.4688130304959994     |
| train_0/reward            | -0.792914910151012     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1346435546875        |
| train_0/target_q          | -6.809135706486091     |
| train_1/avg_q             | -13.70682683295027     |
| train_1/current_q         | -7.858499378430793     |
| train_1/fw_bonus          | -0.9942934945225715    |
| train_1/fw_loss           | 0.0021867714734980837  |
| train_1/mu_grads          | -0.051005045976489784  |
| train_1/mu_grads_std      | 0.7475551322102547     |
| train_1/mu_loss           | 7.496039429691571      |
| train_1/n_subgoals        | 1466.0                 |
| train_1/next_q            | -7.466763307488617     |
| train_1/q_grads           | -0.1264543529599905    |
| train_1/q_grads_std       | 0.9484701946377754     |
| train_1/q_loss            | 6.581127164073149      |
| train_1/reward            | -1.8155899779067113    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080810546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35948158253751705    |
| train_1/target_q          | -7.999860758959608     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 61
Time for epoch 61: 1889.52. Rollout time: 533.44, Training time: 1355.89
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 3310174.0             |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -3.4421127389587074   |
| test_1/avg_q              | -11.562551302435232   |
| test_1/n_subgoals         | 6107.0                |
| test_1/subgoal_succ_rate  | 0.9780579662682168    |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -11.794944876457931   |
| train_0/current_q         | -6.517345993226504    |
| train_0/fw_bonus          | -0.9991832986474037   |
| train_0/fw_loss           | 0.0002242457001557341 |
| train_0/mu_grads          | -0.1804740060120821   |
| train_0/mu_grads_std      | 0.7587437346577645    |
| train_0/mu_loss           | 6.347584938958265     |
| train_0/next_q            | -6.130656955868236    |
| train_0/q_grads           | 0.02612862610258162   |
| train_0/q_grads_std       | 0.4962134785950184    |
| train_0/q_loss            | 0.72023045695686      |
| train_0/reward            | -0.7940951402280916   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1227294921875       |
| train_0/target_q          | -6.46523736316625     |
| train_1/avg_q             | -11.231373905380702   |
| train_1/current_q         | -8.842525595128285    |
| train_1/fw_bonus          | -0.9938106551766396   |
| train_1/fw_loss           | 0.002301068318774924  |
| train_1/mu_grads          | -0.05114117199555039  |
| train_1/mu_grads_std      | 0.7510767713189125    |
| train_1/mu_loss           | 8.625115267508018     |
| train_1/n_subgoals        | 1665.0                |
| train_1/next_q            | -8.534957117214       |
| train_1/q_grads           | -0.12861970588564872  |
| train_1/q_grads_std       | 0.9576206296682358    |
| train_1/q_loss            | 6.800911254641562     |
| train_1/reward            | -1.8004179940835456   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00732421875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4042042042042042    |
| train_1/target_q          | -8.94932545869935     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6
Training epoch 62
Time for epoch 62: 1075.96. Rollout time: 600.64, Training time: 475.16
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 3355412.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.12                  |
| test_0/avg_q              | -0.9975675852277348   |
| test_1/avg_q              | -12.081502497339207   |
| test_1/n_subgoals         | 654.0                 |
| test_1/subgoal_succ_rate  | 0.035168195718654434  |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.77                  |
| train_0/avg_q             | -10.732509568346078   |
| train_0/current_q         | -5.7445249687308575   |
| train_0/fw_bonus          | -0.9991577208042145   |
| train_0/fw_loss           | 0.0002310911331733223 |
| train_0/mu_grads          | -0.18357004411518574  |
| train_0/mu_grads_std      | 0.7676788941025734    |
| train_0/mu_loss           | 5.541679398254983     |
| train_0/next_q            | -5.372425135285975    |
| train_0/q_grads           | 0.025623720278963445  |
| train_0/q_grads_std       | 0.49817394390702247   |
| train_0/q_loss            | 0.733516986398122     |
| train_0/reward            | -0.7931549090229965   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1122802734375       |
| train_0/target_q          | -5.7359856277287395   |
| train_1/avg_q             | -10.63137504852046    |
| train_1/current_q         | -9.129369799344229    |
| train_1/fw_bonus          | -0.9937506899237633   |
| train_1/fw_loss           | 0.002315262466436252  |
| train_1/mu_grads          | -0.050332503486424686 |
| train_1/mu_grads_std      | 0.755037260055542     |
| train_1/mu_loss           | 8.864304723434381     |
| train_1/n_subgoals        | 1388.0                |
| train_1/next_q            | -8.849446761074251    |
| train_1/q_grads           | -0.12941391691565513  |
| train_1/q_grads_std       | 0.9635027632117271    |
| train_1/q_loss            | 7.400083549239359     |
| train_1/reward            | -1.8316591062066436   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007763671875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.35662824207492794   |
| train_1/target_q          | -9.243025934430621    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.41000000000000003
Training epoch 63
Time for epoch 63: 1176.68. Rollout time: 721.13, Training time: 455.34
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 3409287.0             |
| test/episodes             | 1600.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.297249698644955    |
| test_1/avg_q              | -12.492651646675332   |
| test_1/n_subgoals         | 4060.0                |
| test_1/subgoal_succ_rate  | 0.8766009852216748    |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.66                  |
| train_0/avg_q             | -9.247396646565218    |
| train_0/current_q         | -6.145567882547046    |
| train_0/fw_bonus          | -0.9992006868124008   |
| train_0/fw_loss           | 0.0002195928551373072 |
| train_0/mu_grads          | -0.1862908974289894   |
| train_0/mu_grads_std      | 0.7749737069010735    |
| train_0/mu_loss           | 5.9632674399524195    |
| train_0/next_q            | -5.76869929010793     |
| train_0/q_grads           | 0.025725065218284725  |
| train_0/q_grads_std       | 0.5002688646316529    |
| train_0/q_loss            | 0.7774520247447263    |
| train_0/reward            | -0.7865372298634611   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.119677734375        |
| train_0/target_q          | -6.072324592929545    |
| train_1/avg_q             | -10.515498424680262   |
| train_1/current_q         | -8.31284202577223     |
| train_1/fw_bonus          | -0.9935701355338097   |
| train_1/fw_loss           | 0.00235799930524081   |
| train_1/mu_grads          | -0.04947071867063642  |
| train_1/mu_grads_std      | 0.7584629639983177    |
| train_1/mu_loss           | 7.931688600850224     |
| train_1/n_subgoals        | 1573.0                |
| train_1/next_q            | -7.9053431627133195   |
| train_1/q_grads           | -0.13195335678756237  |
| train_1/q_grads_std       | 0.9723541140556335    |
| train_1/q_loss            | 7.605724434102501     |
| train_1/reward            | -1.8649940959367086   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007568359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.22759059122695485   |
| train_1/target_q          | -8.447241781856212    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.21
Training epoch 64
Time for epoch 64: 943.93. Rollout time: 576.80, Training time: 366.95
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 64                    |
| policy/steps              | 3452998.0             |
| test/episodes             | 1625.0                |
| test/success_rate         | 0.72                  |
| test_0/avg_q              | -1.6614229323706453   |
| test_1/avg_q              | -11.013716719288848   |
| test_1/n_subgoals         | 1761.0                |
| test_1/subgoal_succ_rate  | 0.8852924474730267    |
| train/episodes            | 6500.0                |
| train/success_rate        | 0.69                  |
| train_0/avg_q             | -9.861076112641037    |
| train_0/current_q         | -6.6296857099058055   |
| train_0/fw_bonus          | -0.9992209553718567   |
| train_0/fw_loss           | 0.0002141642427886836 |
| train_0/mu_grads          | -0.18839436434209347  |
| train_0/mu_grads_std      | 0.7804565832018853    |
| train_0/mu_loss           | 6.390816627849942     |
| train_0/next_q            | -6.256130281802488    |
| train_0/q_grads           | 0.026292884768918157  |
| train_0/q_grads_std       | 0.5036019369959831    |
| train_0/q_loss            | 0.755145372850718     |
| train_0/reward            | -0.7831548488909903   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.106396484375        |
| train_0/target_q          | -6.569289724571101    |
| train_1/avg_q             | -12.1649469683545     |
| train_1/current_q         | -9.500423712778959    |
| train_1/fw_bonus          | -0.9936324879527092   |
| train_1/fw_loss           | 0.00234324072371237   |
| train_1/mu_grads          | -0.05018151979893446  |
| train_1/mu_grads_std      | 0.7623760178685188    |
| train_1/mu_loss           | 9.166198771475607     |
| train_1/n_subgoals        | 1585.0                |
| train_1/next_q            | -9.12153491839852     |
| train_1/q_grads           | -0.13389678113162518  |
| train_1/q_grads_std       | 0.9811087146401405    |
| train_1/q_loss            | 7.27865031905952      |
| train_1/reward            | -1.9167369787217468   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007861328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21451104100946372   |
| train_1/target_q          | -9.595387115958358    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.31
Training epoch 65
Time for epoch 65: 786.23. Rollout time: 408.26, Training time: 377.68
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 65                     |
| policy/steps              | 3482735.0              |
| test/episodes             | 1650.0                 |
| test/success_rate         | 0.88                   |
| test_0/avg_q              | -2.5344342038533645    |
| test_1/avg_q              | -8.387297530584334     |
| test_1/n_subgoals         | 1061.0                 |
| test_1/subgoal_succ_rate  | 0.9330819981149858     |
| train/episodes            | 6600.0                 |
| train/success_rate        | 0.83                   |
| train_0/avg_q             | -11.922660754920319    |
| train_0/current_q         | -6.350217715930759     |
| train_0/fw_bonus          | -0.9991749063134193    |
| train_0/fw_loss           | 0.00022648885278613305 |
| train_0/mu_grads          | -0.1904273647814989    |
| train_0/mu_grads_std      | 0.7855676233768463     |
| train_0/mu_loss           | 6.189663618330682      |
| train_0/next_q            | -5.970722815552968     |
| train_0/q_grads           | 0.026467881817370652   |
| train_0/q_grads_std       | 0.5061896488070488     |
| train_0/q_loss            | 0.679227030962477      |
| train_0/reward            | -0.7832715121239744    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.119140625            |
| train_0/target_q          | -6.315574969201843     |
| train_1/avg_q             | -12.437755309808317    |
| train_1/current_q         | -9.572875528471574     |
| train_1/fw_bonus          | -0.9936841443181038    |
| train_1/fw_loss           | 0.002331014379160479   |
| train_1/mu_grads          | -0.05129245780408383   |
| train_1/mu_grads_std      | 0.7664931580424309     |
| train_1/mu_loss           | 9.29967389048895       |
| train_1/n_subgoals        | 1327.0                 |
| train_1/next_q            | -9.226343009678326     |
| train_1/q_grads           | -0.13537726290524005   |
| train_1/q_grads_std       | 0.9913048774003983     |
| train_1/q_loss            | 6.759620215148749      |
| train_1/reward            | -1.8856402729805268    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080810546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.41446872645064053    |
| train_1/target_q          | -9.64554913601356      |
------------------------------------------------------
New best value for test/success_rate: 0.88. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.43
Training epoch 66
Time for epoch 66: 753.82. Rollout time: 380.96, Training time: 372.70
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
----------------------------------------------------
| epoch                     | 66                   |
| policy/steps              | 3515755.0            |
| test/episodes             | 1675.0               |
| test/success_rate         | 0.56                 |
| test_0/avg_q              | -1.6970531799099522  |
| test_1/avg_q              | -14.558256488556786  |
| test_1/n_subgoals         | 1519.0               |
| test_1/subgoal_succ_rate  | 0.826201448321264    |
| train/episodes            | 6700.0               |
| train/success_rate        | 0.84                 |
| train_0/avg_q             | -12.323967613159065  |
| train_0/current_q         | -6.5246590587726185  |
| train_0/fw_bonus          | -0.999111370742321   |
| train_0/fw_loss           | 0.000243499275893555 |
| train_0/mu_grads          | -0.1943763505667448  |
| train_0/mu_grads_std      | 0.7915520131587982   |
| train_0/mu_loss           | 6.333701410530736    |
| train_0/next_q            | -6.119522526457634   |
| train_0/q_grads           | 0.026239879475906492 |
| train_0/q_grads_std       | 0.5076958447694778   |
| train_0/q_loss            | 0.8094997430453572   |
| train_0/reward            | -0.7821020605104423  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.1021240234375      |
| train_0/target_q          | -6.419995189885017   |
| train_1/avg_q             | -12.007057274546728  |
| train_1/current_q         | -10.428658564459838  |
| train_1/fw_bonus          | -0.9930117860436439  |
| train_1/fw_loss           | 0.002490164351183921 |
| train_1/mu_grads          | -0.05284754680469632 |
| train_1/mu_grads_std      | 0.76861020475626     |
| train_1/mu_loss           | 10.183408853564027   |
| train_1/n_subgoals        | 1196.0               |
| train_1/next_q            | -10.184069309364716  |
| train_1/q_grads           | -0.13636602126061917 |
| train_1/q_grads_std       | 0.9989100098609924   |
| train_1/q_loss            | 7.392068036111462    |
| train_1/reward            | -1.9372177900942915  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.0079345703125      |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.3737458193979933   |
| train_1/target_q          | -10.506837766678856  |
----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.54
Training epoch 67
Time for epoch 67: 951.51. Rollout time: 516.48, Training time: 434.88
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 3557284.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.833121818033161     |
| test_1/avg_q              | -10.919685579023135    |
| test_1/n_subgoals         | 2052.0                 |
| test_1/subgoal_succ_rate  | 0.8352826510721247     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -12.481911724459176    |
| train_0/current_q         | -4.888882616890482     |
| train_0/fw_bonus          | -0.9992549225687981    |
| train_0/fw_loss           | 0.00020507248991634696 |
| train_0/mu_grads          | -0.19505824372172356   |
| train_0/mu_grads_std      | 0.7975284337997437     |
| train_0/mu_loss           | 4.663135285394056      |
| train_0/next_q            | -4.485728266540186     |
| train_0/q_grads           | 0.026873033493757248   |
| train_0/q_grads_std       | 0.5108615294098854     |
| train_0/q_loss            | 0.663280225886476      |
| train_0/reward            | -0.784756357733204     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1383544921875        |
| train_0/target_q          | -4.873761514947217     |
| train_1/avg_q             | -13.191562820078646    |
| train_1/current_q         | -10.158197053777238    |
| train_1/fw_bonus          | -0.9932495936751365    |
| train_1/fw_loss           | 0.0024338734743651     |
| train_1/mu_grads          | -0.05317201288416982   |
| train_1/mu_grads_std      | 0.7709045767784118     |
| train_1/mu_loss           | 9.820824092124354      |
| train_1/n_subgoals        | 1414.0                 |
| train_1/next_q            | -9.858044801076648     |
| train_1/q_grads           | -0.13818651475012303   |
| train_1/q_grads_std       | 1.007332867383957      |
| train_1/q_loss            | 7.335794086071246      |
| train_1/reward            | -1.9636810508927738    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0078857421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3698727015558699     |
| train_1/target_q          | -10.223943496670213    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.64
Training epoch 68
Time for epoch 68: 950.74. Rollout time: 490.40, Training time: 460.12
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 3591403.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.72                   |
| test_0/avg_q              | -1.3483977447978956    |
| test_1/avg_q              | -12.495357124705846    |
| test_1/n_subgoals         | 2103.0                 |
| test_1/subgoal_succ_rate  | 0.9281978126485972     |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -8.024289512925904     |
| train_0/current_q         | -6.084249838224602     |
| train_0/fw_bonus          | -0.9992187961935997    |
| train_0/fw_loss           | 0.00021474121203937102 |
| train_0/mu_grads          | -0.19824945963919163   |
| train_0/mu_grads_std      | 0.802810138463974      |
| train_0/mu_loss           | 5.8493096285486805     |
| train_0/next_q            | -5.652900366484866     |
| train_0/q_grads           | 0.02686771578155458    |
| train_0/q_grads_std       | 0.513289387524128      |
| train_0/q_loss            | 0.5862045221333411     |
| train_0/reward            | -0.7846557748711348    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1530029296875        |
| train_0/target_q          | -6.006705291050708     |
| train_1/avg_q             | -12.467398914132183    |
| train_1/current_q         | -10.38948357020407     |
| train_1/fw_bonus          | -0.9931235685944557    |
| train_1/fw_loss           | 0.002463705837726593   |
| train_1/mu_grads          | -0.053166871517896654  |
| train_1/mu_grads_std      | 0.7736873626708984     |
| train_1/mu_loss           | 10.148366262675596     |
| train_1/n_subgoals        | 1335.0                 |
| train_1/next_q            | -10.135871903954328    |
| train_1/q_grads           | -0.14018783681094646   |
| train_1/q_grads_std       | 1.016614991426468      |
| train_1/q_loss            | 7.095417816461788      |
| train_1/reward            | -1.9344076007124387    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007666015625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4209737827715356     |
| train_1/target_q          | -10.468268040049121    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6399999999999999
Training epoch 69
Time for epoch 69: 981.97. Rollout time: 500.25, Training time: 481.48
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 3629378.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.44                   |
| test_0/avg_q              | -1.3348183373826308    |
| test_1/avg_q              | -10.990332135045898    |
| test_1/n_subgoals         | 3281.0                 |
| test_1/subgoal_succ_rate  | 0.9006400487656202     |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.78                   |
| train_0/avg_q             | -9.446238082746168     |
| train_0/current_q         | -5.575414826336479     |
| train_0/fw_bonus          | -0.999218362569809     |
| train_0/fw_loss           | 0.00021486028308572713 |
| train_0/mu_grads          | -0.20085946880280972   |
| train_0/mu_grads_std      | 0.8090518042445183     |
| train_0/mu_loss           | 5.33991051546153       |
| train_0/next_q            | -5.1694984975986475    |
| train_0/q_grads           | 0.026902643078938127   |
| train_0/q_grads_std       | 0.516468633711338      |
| train_0/q_loss            | 0.5729990406382285     |
| train_0/reward            | -0.7870726558136084    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1355712890625        |
| train_0/target_q          | -5.590647936583658     |
| train_1/avg_q             | -12.552627662661312    |
| train_1/current_q         | -9.826026373475269     |
| train_1/fw_bonus          | -0.9925470694899559    |
| train_1/fw_loss           | 0.002600167749915272   |
| train_1/mu_grads          | -0.0534470927901566    |
| train_1/mu_grads_std      | 0.7771623224020004     |
| train_1/mu_loss           | 9.526947271659747      |
| train_1/n_subgoals        | 1317.0                 |
| train_1/next_q            | -9.505891636717712     |
| train_1/q_grads           | -0.14153193309903145   |
| train_1/q_grads_std       | 1.024826428294182      |
| train_1/q_loss            | 7.335803532952484      |
| train_1/reward            | -1.8805037091431587    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00869140625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4548215641609719     |
| train_1/target_q          | -9.923206333860495     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.53
Training epoch 70
Time for epoch 70: 948.68. Rollout time: 528.31, Training time: 420.15
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 3664761.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.76                   |
| test_0/avg_q              | -1.676038254316309     |
| test_1/avg_q              | -12.187831067076727    |
| test_1/n_subgoals         | 4253.0                 |
| test_1/subgoal_succ_rate  | 0.9931812837996709     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -11.532705522764541    |
| train_0/current_q         | -6.3770002726944615    |
| train_0/fw_bonus          | -0.9991589307785034    |
| train_0/fw_loss           | 0.00023076868128555362 |
| train_0/mu_grads          | -0.20145670808851718   |
| train_0/mu_grads_std      | 0.8142853274941444     |
| train_0/mu_loss           | 6.12949937502731       |
| train_0/next_q            | -5.932320369821995     |
| train_0/q_grads           | 0.027355357958003878   |
| train_0/q_grads_std       | 0.5208019271492959     |
| train_0/q_loss            | 0.4708246847349704     |
| train_0/reward            | -0.7833956887541718    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.110498046875         |
| train_0/target_q          | -6.325136342504014     |
| train_1/avg_q             | -13.21281890907709     |
| train_1/current_q         | -10.337812619189654    |
| train_1/fw_bonus          | -0.9928270414471626    |
| train_1/fw_loss           | 0.0025338943931274118  |
| train_1/mu_grads          | -0.05446287160739303   |
| train_1/mu_grads_std      | 0.7794853031635285     |
| train_1/mu_loss           | 10.07194831774693      |
| train_1/n_subgoals        | 1469.0                 |
| train_1/next_q            | -10.089197295062236    |
| train_1/q_grads           | -0.14330932013690473   |
| train_1/q_grads_std       | 1.0339768379926682     |
| train_1/q_loss            | 7.417294043203718      |
| train_1/reward            | -1.925306371763145     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075927734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.41388699795779443    |
| train_1/target_q          | -10.46132575066687     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.5800000000000001
Training epoch 71
Time for epoch 71: 1061.46. Rollout time: 586.38, Training time: 474.83
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 3701215.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.76                   |
| test_0/avg_q              | -1.0360981906649986    |
| test_1/avg_q              | -8.886026524254321     |
| test_1/n_subgoals         | 2555.0                 |
| test_1/subgoal_succ_rate  | 0.9542074363992172     |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -13.132162744384594    |
| train_0/current_q         | -6.201460055252838     |
| train_0/fw_bonus          | -0.9992013856768608    |
| train_0/fw_loss           | 0.00021940535261819605 |
| train_0/mu_grads          | -0.2027524970471859    |
| train_0/mu_grads_std      | 0.8192170977592468     |
| train_0/mu_loss           | 5.978390609285164      |
| train_0/next_q            | -5.771374329143777     |
| train_0/q_grads           | 0.027368074236437678   |
| train_0/q_grads_std       | 0.5239714816212654     |
| train_0/q_loss            | 0.6187091427825473     |
| train_0/reward            | -0.7880205593017309    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.153466796875         |
| train_0/target_q          | -6.132274530472904     |
| train_1/avg_q             | -13.974307894721855    |
| train_1/current_q         | -10.321743174201297    |
| train_1/fw_bonus          | -0.9928870782256126    |
| train_1/fw_loss           | 0.0025196863687597217  |
| train_1/mu_grads          | -0.054128220025449994  |
| train_1/mu_grads_std      | 0.7819612711668015     |
| train_1/mu_loss           | 10.084807227775027     |
| train_1/n_subgoals        | 1500.0                 |
| train_1/next_q            | -10.074893755305363    |
| train_1/q_grads           | -0.14515942186117173   |
| train_1/q_grads_std       | 1.042738339304924      |
| train_1/q_loss            | 6.412641698871623      |
| train_1/reward            | -1.9423318730503525    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008056640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.39666666666666667    |
| train_1/target_q          | -10.44353283775812     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6699999999999999
Training epoch 72
Time for epoch 72: 946.81. Rollout time: 469.08, Training time: 477.47
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 72                     |
| policy/steps              | 3732290.0              |
| test/episodes             | 1825.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -2.445070431436999     |
| test_1/avg_q              | -13.425277190711702    |
| test_1/n_subgoals         | 2764.0                 |
| test_1/subgoal_succ_rate  | 0.965629522431259      |
| train/episodes            | 7300.0                 |
| train/success_rate        | 0.82                   |
| train_0/avg_q             | -10.107457910372762    |
| train_0/current_q         | -5.831320005052591     |
| train_0/fw_bonus          | -0.9991965189576149    |
| train_0/fw_loss           | 0.00022070800077926832 |
| train_0/mu_grads          | -0.2040289707481861    |
| train_0/mu_grads_std      | 0.8241027265787124     |
| train_0/mu_loss           | 5.6064989194812895     |
| train_0/next_q            | -5.4016873785214585    |
| train_0/q_grads           | 0.027121518505737185   |
| train_0/q_grads_std       | 0.5268761411309242     |
| train_0/q_loss            | 0.5372943172067316     |
| train_0/reward            | -0.7938420967064304    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1453369140625        |
| train_0/target_q          | -5.804811210520034     |
| train_1/avg_q             | -12.371071550223808    |
| train_1/current_q         | -10.209480538595155    |
| train_1/fw_bonus          | -0.9927480682730675    |
| train_1/fw_loss           | 0.0025525889708660544  |
| train_1/mu_grads          | -0.053850069642066956  |
| train_1/mu_grads_std      | 0.7849355816841126     |
| train_1/mu_loss           | 9.990919474775072      |
| train_1/n_subgoals        | 1272.0                 |
| train_1/next_q            | -9.974839142395714     |
| train_1/q_grads           | -0.14747020974755287   |
| train_1/q_grads_std       | 1.0535010695457458     |
| train_1/q_loss            | 6.483818408000521      |
| train_1/reward            | -1.9173215398855974    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008203125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.45990566037735847    |
| train_1/target_q          | -10.33147395671163     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.66
Training epoch 73
Time for epoch 73: 993.51. Rollout time: 503.03, Training time: 490.27
Evaluating epoch 73
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 3766380.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.6483660211233464   |
| test_1/avg_q              | -11.610646432604232   |
| test_1/n_subgoals         | 3226.0                |
| test_1/subgoal_succ_rate  | 0.9460632362058277    |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.8                   |
| train_0/avg_q             | -11.146439787077176   |
| train_0/current_q         | -5.287804989952166    |
| train_0/fw_bonus          | -0.9992119506001472   |
| train_0/fw_loss           | 0.0002165783997043036 |
| train_0/mu_grads          | -0.2017389964312315   |
| train_0/mu_grads_std      | 0.826794558763504     |
| train_0/mu_loss           | 5.093100451143119     |
| train_0/next_q            | -4.862538667978365    |
| train_0/q_grads           | 0.02723435005173087   |
| train_0/q_grads_std       | 0.5296333521604538    |
| train_0/q_loss            | 0.6482495055370887    |
| train_0/reward            | -0.7922346253035357   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1537841796875       |
| train_0/target_q          | -5.281673113284752    |
| train_1/avg_q             | -13.080512212803242   |
| train_1/current_q         | -9.739438494879437    |
| train_1/fw_bonus          | -0.9930334225296974   |
| train_1/fw_loss           | 0.002485044422792271  |
| train_1/mu_grads          | -0.05290508884936571  |
| train_1/mu_grads_std      | 0.7869427189230919    |
| train_1/mu_loss           | 9.373349465567        |
| train_1/n_subgoals        | 1363.0                |
| train_1/next_q            | -9.32766476290207     |
| train_1/q_grads           | -0.1480786506086588   |
| train_1/q_grads_std       | 1.0612295806407928    |
| train_1/q_loss            | 6.930923575317041     |
| train_1/reward            | -1.8632119683406927   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.008056640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4431401320616288    |
| train_1/target_q          | -9.835948796180391    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7000000000000001
Training epoch 74
Time for epoch 74: 1057.04. Rollout time: 566.01, Training time: 490.77
Evaluating epoch 74
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 74                     |
| policy/steps              | 3802845.0              |
| test/episodes             | 1875.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -1.8528886952343406    |
| test_1/avg_q              | -11.393239789427861    |
| test_1/n_subgoals         | 3107.0                 |
| test_1/subgoal_succ_rate  | 0.9594464113292566     |
| train/episodes            | 7500.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -9.034288644120377     |
| train_0/current_q         | -5.278493305485553     |
| train_0/fw_bonus          | -0.9992008104920387    |
| train_0/fw_loss           | 0.00021955815973342396 |
| train_0/mu_grads          | -0.20345952324569225   |
| train_0/mu_grads_std      | 0.8303493648767472     |
| train_0/mu_loss           | 5.025911978651047      |
| train_0/next_q            | -4.835600576602323     |
| train_0/q_grads           | 0.02743307766504586    |
| train_0/q_grads_std       | 0.5340836197137833     |
| train_0/q_loss            | 0.5165623160572143     |
| train_0/reward            | -0.7963150944873633    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1796875              |
| train_0/target_q          | -5.2746174524778       |
| train_1/avg_q             | -12.665524168272775    |
| train_1/current_q         | -8.766550734319733     |
| train_1/fw_bonus          | -0.9921019360423088    |
| train_1/fw_loss           | 0.002705533237894997   |
| train_1/mu_grads          | -0.051974558364599945  |
| train_1/mu_grads_std      | 0.7885245606303215     |
| train_1/mu_loss           | 8.4139254141887        |
| train_1/n_subgoals        | 1541.0                 |
| train_1/next_q            | -8.307998772974807     |
| train_1/q_grads           | -0.14915803037583827   |
| train_1/q_grads_std       | 1.0670597463846208     |
| train_1/q_loss            | 6.232503340973946      |
| train_1/reward            | -1.8136871061484272    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007421875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4536015574302401     |
| train_1/target_q          | -8.891454773036699     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.68
Training epoch 75
Time for epoch 75: 1071.17. Rollout time: 584.25, Training time: 486.59
Evaluating epoch 75
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 75                     |
| policy/steps              | 3837242.0              |
| test/episodes             | 1900.0                 |
| test/success_rate         | 0.84                   |
| test_0/avg_q              | -1.9931370816270992    |
| test_1/avg_q              | -11.79581758135239     |
| test_1/n_subgoals         | 3703.0                 |
| test_1/subgoal_succ_rate  | 0.998109640831758      |
| train/episodes            | 7600.0                 |
| train/success_rate        | 0.73                   |
| train_0/avg_q             | -10.525415605854404    |
| train_0/current_q         | -6.431635789703881     |
| train_0/fw_bonus          | -0.999175301194191     |
| train_0/fw_loss           | 0.00022638839291175828 |
| train_0/mu_grads          | -0.20347648710012436   |
| train_0/mu_grads_std      | 0.8352846965193749     |
| train_0/mu_loss           | 6.176370959455525      |
| train_0/next_q            | -5.964824959548187     |
| train_0/q_grads           | 0.02780502256937325    |
| train_0/q_grads_std       | 0.5376621171832084     |
| train_0/q_loss            | 0.4688965384303458     |
| train_0/reward            | -0.7997327875269548    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1229248046875        |
| train_0/target_q          | -6.387604459154902     |
| train_1/avg_q             | -12.36620872731503     |
| train_1/current_q         | -9.793117070191585     |
| train_1/fw_bonus          | -0.9922906026244164    |
| train_1/fw_loss           | 0.0026608759362716228  |
| train_1/mu_grads          | -0.051753430254757406  |
| train_1/mu_grads_std      | 0.7896575585007668     |
| train_1/mu_loss           | 9.508085762323208      |
| train_1/n_subgoals        | 1465.0                 |
| train_1/next_q            | -9.456991701657818     |
| train_1/q_grads           | -0.1495040126144886    |
| train_1/q_grads_std       | 1.0731063961982727     |
| train_1/q_loss            | 5.427631957507034      |
| train_1/reward            | -1.8124159115257499    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007080078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4129692832764505     |
| train_1/target_q          | -9.888507719659447     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.7
Training epoch 76
Time for epoch 76: 1028.20. Rollout time: 561.62, Training time: 466.35
Evaluating epoch 76
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 76                     |
| policy/steps              | 3878606.0              |
| test/episodes             | 1925.0                 |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.8817750748888171    |
| test_1/avg_q              | -8.35839583424945      |
| test_1/n_subgoals         | 2058.0                 |
| test_1/subgoal_succ_rate  | 0.826044703595724      |
| train/episodes            | 7700.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -11.987505617902498    |
| train_0/current_q         | -6.057345495442827     |
| train_0/fw_bonus          | -0.9992089465260505    |
| train_0/fw_loss           | 0.00021737897950515616 |
| train_0/mu_grads          | -0.20224825404584407   |
| train_0/mu_grads_std      | 0.8364525303244591     |
| train_0/mu_loss           | 5.832180262623214      |
| train_0/next_q            | -5.638637465334723     |
| train_0/q_grads           | 0.029306000843644143   |
| train_0/q_grads_std       | 0.539770320057869      |
| train_0/q_loss            | 0.5293126009510094     |
| train_0/reward            | -0.8025976471770264    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1575439453125        |
| train_0/target_q          | -6.0937012854890416    |
| train_1/avg_q             | -12.117063893986087    |
| train_1/current_q         | -10.24891019832133     |
| train_1/fw_bonus          | -0.9930786311626434    |
| train_1/fw_loss           | 0.0024743446905631573  |
| train_1/mu_grads          | -0.05229424983263016   |
| train_1/mu_grads_std      | 0.7915278404951096     |
| train_1/mu_loss           | 10.058115639174675     |
| train_1/n_subgoals        | 1508.0                 |
| train_1/next_q            | -10.034979055230384    |
| train_1/q_grads           | -0.15083648450672626   |
| train_1/q_grads_std       | 1.0814588606357574     |
| train_1/q_loss            | 5.728903010145072      |
| train_1/reward            | -1.7599884061986812    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076171875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4383289124668435     |
| train_1/target_q          | -10.372820828642423    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.63
Training epoch 77
Time for epoch 77: 965.70. Rollout time: 519.04, Training time: 446.42
Evaluating epoch 77
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 3914404.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.68                  |
| test_0/avg_q              | -1.6033963852656794   |
| test_1/avg_q              | -13.264428764919005   |
| test_1/n_subgoals         | 3795.0                |
| test_1/subgoal_succ_rate  | 0.986034255599473     |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -12.659621252650645   |
| train_0/current_q         | -6.564025531876064    |
| train_0/fw_bonus          | -0.999226713180542    |
| train_0/fw_loss           | 0.0002126214993040776 |
| train_0/mu_grads          | -0.20343348644673825  |
| train_0/mu_grads_std      | 0.8394492238759994    |
| train_0/mu_loss           | 6.304537355784371     |
| train_0/next_q            | -6.078460700030663    |
| train_0/q_grads           | 0.029390372894704343  |
| train_0/q_grads_std       | 0.5412441223859787    |
| train_0/q_loss            | 0.4074412243109786    |
| train_0/reward            | -0.810915078713515    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.172119140625        |
| train_0/target_q          | -6.548354928059178    |
| train_1/avg_q             | -11.401155432501042   |
| train_1/current_q         | -10.414763226671056   |
| train_1/fw_bonus          | -0.9927246049046516   |
| train_1/fw_loss           | 0.0025581441179383544 |
| train_1/mu_grads          | -0.05246354155242443  |
| train_1/mu_grads_std      | 0.7920133277773858    |
| train_1/mu_loss           | 10.300587223881069    |
| train_1/n_subgoals        | 1484.0                |
| train_1/next_q            | -10.299066738799862   |
| train_1/q_grads           | -0.15198311470448972  |
| train_1/q_grads_std       | 1.090084618330002     |
| train_1/q_loss            | 5.579114591315519     |
| train_1/reward            | -1.756842038765535    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0083251953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3881401617250674    |
| train_1/target_q          | -10.538414873940672   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.65
Training epoch 78
Time for epoch 78: 894.83. Rollout time: 475.29, Training time: 419.34
Evaluating epoch 78
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 78                     |
| policy/steps              | 3949421.0              |
| test/episodes             | 1975.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -2.332770892057969     |
| test_1/avg_q              | -7.6275748156774315    |
| test_1/n_subgoals         | 2705.0                 |
| test_1/subgoal_succ_rate  | 0.944547134935305      |
| train/episodes            | 7900.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -12.22071066422808     |
| train_0/current_q         | -6.847974430319712     |
| train_0/fw_bonus          | -0.999234002828598     |
| train_0/fw_loss           | 0.00021067372654215433 |
| train_0/mu_grads          | -0.208537258207798     |
| train_0/mu_grads_std      | 0.8450462430715561     |
| train_0/mu_loss           | 6.673148476336751      |
| train_0/next_q            | -6.44240596632832      |
| train_0/q_grads           | 0.029911717819049954   |
| train_0/q_grads_std       | 0.5438530206680298     |
| train_0/q_loss            | 0.5355769434980535     |
| train_0/reward            | -0.807950589342363     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1890380859375        |
| train_0/target_q          | -6.834701985727412     |
| train_1/avg_q             | -11.838526786485053    |
| train_1/current_q         | -10.368394337288134    |
| train_1/fw_bonus          | -0.992661964893341     |
| train_1/fw_loss           | 0.002572971151676029   |
| train_1/mu_grads          | -0.052667225059121844  |
| train_1/mu_grads_std      | 0.7939979940652847     |
| train_1/mu_loss           | 10.248604444490173     |
| train_1/n_subgoals        | 1407.0                 |
| train_1/next_q            | -10.283386513864482    |
| train_1/q_grads           | -0.15334623865783215   |
| train_1/q_grads_std       | 1.0973088294267654     |
| train_1/q_loss            | 5.599358790911284      |
| train_1/reward            | -1.748842980117115     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075439453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.410092395167022      |
| train_1/target_q          | -10.50762184702804     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.65
Training epoch 79
Time for epoch 79: 403.91. Rollout time: 200.44, Training time: 203.41
Evaluating epoch 79
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 79                    |
| policy/steps              | 3982843.0             |
| test/episodes             | 2000.0                |
| test/success_rate         | 0.64                  |
| test_0/avg_q              | -1.8447615005572513   |
| test_1/avg_q              | -10.81736784642211    |
| test_1/n_subgoals         | 3729.0                |
| test_1/subgoal_succ_rate  | 0.9584338964869938    |
| train/episodes            | 8000.0                |
| train/success_rate        | 0.8                   |
| train_0/avg_q             | -13.079011348213921   |
| train_0/current_q         | -5.849438047626755    |
| train_0/fw_bonus          | -0.9992278441786766   |
| train_0/fw_loss           | 0.0002123213325830875 |
| train_0/mu_grads          | -0.2120526112616062   |
| train_0/mu_grads_std      | 0.8509270295500755    |
| train_0/mu_loss           | 5.573329003639022     |
| train_0/next_q            | -5.35696810981813     |
| train_0/q_grads           | 0.03072149185463786   |
| train_0/q_grads_std       | 0.5452649429440498    |
| train_0/q_loss            | 0.4328117192095817    |
| train_0/reward            | -0.8113731227243989   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1677001953125       |
| train_0/target_q          | -5.831011780065586    |
| train_1/avg_q             | -11.09657305175604    |
| train_1/current_q         | -10.707222992604958   |
| train_1/fw_bonus          | -0.9934601560235023   |
| train_1/fw_loss           | 0.002384033950511366  |
| train_1/mu_grads          | -0.05279972394928336  |
| train_1/mu_grads_std      | 0.7956385508179664    |
| train_1/mu_loss           | 10.653979520107665    |
| train_1/n_subgoals        | 1312.0                |
| train_1/next_q            | -10.667434167167176   |
| train_1/q_grads           | -0.15391925759613515  |
| train_1/q_grads_std       | 1.1043030738830566    |
| train_1/q_loss            | 5.513447468588066     |
| train_1/reward            | -1.7420845205986553   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0080078125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4344512195121951    |
| train_1/target_q          | -10.83537814370924    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6000000000000001
Training epoch 80
Time for epoch 80: 385.16. Rollout time: 167.64, Training time: 217.48
Evaluating epoch 80
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 4013706.0              |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.84                   |
| test_0/avg_q              | -1.788693644358983     |
| test_1/avg_q              | -4.510402003249458     |
| test_1/n_subgoals         | 3626.0                 |
| test_1/subgoal_succ_rate  | 0.9837286265857694     |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -12.703987547328097    |
| train_0/current_q         | -6.844132594431099     |
| train_0/fw_bonus          | -0.9992231622338295    |
| train_0/fw_loss           | 0.00021357703444664368 |
| train_0/mu_grads          | -0.21547955311834813   |
| train_0/mu_grads_std      | 0.854334919154644      |
| train_0/mu_loss           | 6.622073762251304      |
| train_0/next_q            | -6.413468070791646     |
| train_0/q_grads           | 0.03131143171340227    |
| train_0/q_grads_std       | 0.5473621964454651     |
| train_0/q_loss            | 0.44776460105142       |
| train_0/reward            | -0.8073619403712655    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1554931640625        |
| train_0/target_q          | -6.841116284988283     |
| train_1/avg_q             | -12.930193756018545    |
| train_1/current_q         | -10.496426896348732    |
| train_1/fw_bonus          | -0.9935682579874993    |
| train_1/fw_loss           | 0.0023584459151607005  |
| train_1/mu_grads          | -0.053599150758236645  |
| train_1/mu_grads_std      | 0.7972046002745629     |
| train_1/mu_loss           | 10.345265038367925     |
| train_1/n_subgoals        | 1234.0                 |
| train_1/next_q            | -10.461923001777777    |
| train_1/q_grads           | -0.1555464059114456    |
| train_1/q_grads_std       | 1.1128008365631104     |
| train_1/q_loss            | 5.70553741559969       |
| train_1/reward            | -1.768222385442641     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0089111328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3581847649918963     |
| train_1/target_q          | -10.622093949387885    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.71
Training epoch 81
Time for epoch 81: 354.07. Rollout time: 145.46, Training time: 208.57
Evaluating epoch 81
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 4045732.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -2.4129785897291827   |
| test_1/avg_q              | -13.377042110341803   |
| test_1/n_subgoals         | 1017.0                |
| test_1/subgoal_succ_rate  | 0.7305801376597837    |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.81                  |
| train_0/avg_q             | -12.89920378871151    |
| train_0/current_q         | -6.6643744524442      |
| train_0/fw_bonus          | -0.9991565689444541   |
| train_0/fw_loss           | 0.0002313980476174038 |
| train_0/mu_grads          | -0.21814761571586133  |
| train_0/mu_grads_std      | 0.8581485196948051    |
| train_0/mu_loss           | 6.478564436359463     |
| train_0/next_q            | -6.236033140118519    |
| train_0/q_grads           | 0.031550315022468564  |
| train_0/q_grads_std       | 0.5483710184693337    |
| train_0/q_loss            | 0.5113528840676118    |
| train_0/reward            | -0.8089200032380177   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.133740234375        |
| train_0/target_q          | -6.6620715942750595   |
| train_1/avg_q             | -11.764345526652946   |
| train_1/current_q         | -10.451049160423851   |
| train_1/fw_bonus          | -0.9931340903043747   |
| train_1/fw_loss           | 0.0024612153472844513 |
| train_1/mu_grads          | -0.052940156869590284 |
| train_1/mu_grads_std      | 0.7992028340697288    |
| train_1/mu_loss           | 10.386374965711836    |
| train_1/n_subgoals        | 1274.0                |
| train_1/next_q            | -10.412277642188661   |
| train_1/q_grads           | -0.15741389952600002  |
| train_1/q_grads_std       | 1.1196547538042068    |
| train_1/q_loss            | 5.535314576095251     |
| train_1/reward            | -1.7475877208864403   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0084716796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.45682888540031397   |
| train_1/target_q          | -10.569265294278832   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.6900000000000001
Training epoch 82
Time for epoch 82: 372.17. Rollout time: 159.94, Training time: 212.14
Evaluating epoch 82
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|104
------------------------------------------------------
| epoch                     | 82                     |
| policy/steps              | 4078282.0              |
| test/episodes             | 2075.0                 |
| test/success_rate         | 0.6                    |
| test_0/avg_q              | -1.6017327796395266    |
| test_1/avg_q              | -8.058731514840003     |
| test_1/n_subgoals         | 1580.0                 |
| test_1/subgoal_succ_rate  | 0.8335443037974684     |
| train/episodes            | 8300.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -11.901621557815307    |
| train_0/current_q         | -6.605813211204809     |
| train_0/fw_bonus          | -0.999254098534584     |
| train_0/fw_loss           | 0.00020529342982626985 |
| train_0/mu_grads          | -0.21984137929975986   |
| train_0/mu_grads_std      | 0.8608828783035278     |
| train_0/mu_loss           | 6.356407770745849      |
| train_0/next_q            | -6.145185406423332     |
| train_0/q_grads           | 0.03170111831277609    |
| train_0/q_grads_std       | 0.550454780459404      |
| train_0/q_loss            | 0.4116643973048097     |
| train_0/reward            | -0.8096951163799531    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.13271484375          |
| train_0/target_q          | -6.611016341068991     |
| train_1/avg_q             | -11.921681171130787    |
| train_1/current_q         | -10.25242826310849     |
| train_1/fw_bonus          | -0.9929850175976753    |
| train_1/fw_loss           | 0.0024965026357676836  |
| train_1/mu_grads          | -0.052194836735725406  |
| train_1/mu_grads_std      | 0.8021334365010262     |
| train_1/mu_loss           | 10.141376989116187     |
| train_1/n_subgoals        | 1299.0                 |
| train_1/next_q            | -10.18710271280805     |
| train_1/q_grads           | -0.15925025194883347   |
| train_1/q_grads_std       | 1.1261716842651368     |
| train_1/q_loss            | 5.644101575996389      |
| train_1/reward            | -1.7469095824966643    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00810546875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.45958429561200925    |
| train_1/target_q          | -10.37735309205658     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.67
Training epoch 83
