Starting process id: 51899
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f8f01b6aef0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 754.78. Rollout time: 459.84, Training time: 294.90
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 86213.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.3606307142114593   |
| test_1/avg_q              | -19.666165729345725   |
| test_1/n_subgoals         | 683.0                 |
| test_1/subgoal_succ_rate  | 0.01171303074670571   |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.03                  |
| train_0/avg_q             | -1.9228908601826307   |
| train_0/current_q         | -1.7772952576204113   |
| train_0/fw_bonus          | -0.998837299644947    |
| train_0/fw_loss           | 0.0003143712710880209 |
| train_0/mu_grads          | -0.013548454130068421 |
| train_0/mu_grads_std      | 0.1516219113022089    |
| train_0/mu_loss           | 1.647255520098982     |
| train_0/next_q            | -1.6639410055157182   |
| train_0/q_grads           | 0.022922914242371917  |
| train_0/q_grads_std       | 0.1281667347997427    |
| train_0/q_loss            | 0.47690396416450653   |
| train_0/reward            | -0.6545005860225501   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0009765625          |
| train_0/target_q          | -2.1107610279593656   |
| train_1/avg_q             | -9.629509251660041    |
| train_1/current_q         | -12.007209644377372   |
| train_1/fw_bonus          | -0.997672164440155    |
| train_1/fw_loss           | 0.001462070908746682  |
| train_1/mu_grads          | 0.014960606908425688  |
| train_1/mu_grads_std      | 0.15995850823819638   |
| train_1/mu_loss           | 12.440860889015244    |
| train_1/n_subgoals        | 2655.0                |
| train_1/next_q            | -12.4703243781661     |
| train_1/q_grads           | 0.016189347254112363  |
| train_1/q_grads_std       | 0.20655900985002518   |
| train_1/q_loss            | 18.053811714294092    |
| train_1/reward            | -2.6628579792082747   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.004443359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.06629001883239172   |
| train_1/target_q          | -11.987486481072741   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 702.98. Rollout time: 476.23, Training time: 226.70
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 173744.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.073105625186831     |
| test_1/avg_q              | -11.000770486905768    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -5.023501116496849     |
| train_0/current_q         | -4.5518736946949945    |
| train_0/fw_bonus          | -0.9986169651150704    |
| train_0/fw_loss           | 0.00037299877512850796 |
| train_0/mu_grads          | -0.01866160295903683   |
| train_0/mu_grads_std      | 0.19784256257116795    |
| train_0/mu_loss           | 4.348039241213604      |
| train_0/next_q            | -4.293174996787288     |
| train_0/q_grads           | 0.02491242722608149    |
| train_0/q_grads_std       | 0.1594510342925787     |
| train_0/q_loss            | 0.590472040792673      |
| train_0/reward            | -0.6692587348734378    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0007568359375        |
| train_0/target_q          | -4.45982100564208      |
| train_1/avg_q             | -18.099620726524677    |
| train_1/current_q         | -12.021342769498792    |
| train_1/fw_bonus          | -0.9967936009168625    |
| train_1/fw_loss           | 0.0016662647860357538  |
| train_1/mu_grads          | 0.014300839533098042   |
| train_1/mu_grads_std      | 0.20789674967527388    |
| train_1/mu_loss           | 12.495448591899969     |
| train_1/n_subgoals        | 2651.0                 |
| train_1/next_q            | -12.500748684372514    |
| train_1/q_grads           | 0.012831989955157042   |
| train_1/q_grads_std       | 0.24668190330266954    |
| train_1/q_loss            | 12.683696674830712     |
| train_1/reward            | -2.6162943450082823    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004931640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.044511505092417955   |
| train_1/target_q          | -12.100462915062014    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 584.10. Rollout time: 363.03, Training time: 221.02
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 242818.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.1200869491986591   |
| test_1/avg_q              | -15.644036099278654   |
| test_1/n_subgoals         | 2975.0                |
| test_1/subgoal_succ_rate  | 0.8023529411764706    |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.41                  |
| train_0/avg_q             | -6.632864502598865    |
| train_0/current_q         | -3.0185137784621023   |
| train_0/fw_bonus          | -0.9982869058847428   |
| train_0/fw_loss           | 0.00046082667686278   |
| train_0/mu_grads          | -0.023217628011479974 |
| train_0/mu_grads_std      | 0.21921799406409265   |
| train_0/mu_loss           | 2.963805627625445     |
| train_0/next_q            | -2.8290660573170636   |
| train_0/q_grads           | 0.023541080951690673  |
| train_0/q_grads_std       | 0.16489666439592837   |
| train_0/q_loss            | 0.4699251888711897    |
| train_0/reward            | -0.6846669388625741   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0003662109375       |
| train_0/target_q          | -3.2416445123298177   |
| train_1/avg_q             | -16.682592838292905   |
| train_1/current_q         | -12.075813917591821   |
| train_1/fw_bonus          | -0.9962067529559135   |
| train_1/fw_loss           | 0.0018026546575129032 |
| train_1/mu_grads          | 0.013782530324533582  |
| train_1/mu_grads_std      | 0.2338482316583395    |
| train_1/mu_loss           | 12.436295579763149    |
| train_1/n_subgoals        | 2161.0                |
| train_1/next_q            | -12.4131876875705     |
| train_1/q_grads           | 0.007895965117495508  |
| train_1/q_grads_std       | 0.28173142224550246   |
| train_1/q_loss            | 9.40792621621783      |
| train_1/reward            | -2.567203544347649    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0059326171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.17630726515502082   |
| train_1/target_q          | -12.19571842486177    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 601.80. Rollout time: 375.70, Training time: 226.04
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 311615.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.583439957934861    |
| test_1/avg_q              | -12.042561662797464   |
| test_1/n_subgoals         | 1730.0                |
| test_1/subgoal_succ_rate  | 0.6526011560693642    |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.4                   |
| train_0/avg_q             | -7.093518165862971    |
| train_0/current_q         | -5.010393573969566    |
| train_0/fw_bonus          | -0.9983441770076752   |
| train_0/fw_loss           | 0.0004455830981896725 |
| train_0/mu_grads          | -0.028410640452057122 |
| train_0/mu_grads_std      | 0.239157148078084     |
| train_0/mu_loss           | 4.779161447615654     |
| train_0/next_q            | -4.694769540245771    |
| train_0/q_grads           | 0.023977128928527235  |
| train_0/q_grads_std       | 0.17267600260674953   |
| train_0/q_loss            | 0.4878131576317058    |
| train_0/reward            | -0.695777452344555    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00126953125         |
| train_0/target_q          | -4.909810266143474    |
| train_1/avg_q             | -16.671388395447494   |
| train_1/current_q         | -12.858584021882052   |
| train_1/fw_bonus          | -0.9958311259746552   |
| train_1/fw_loss           | 0.001889957772800699  |
| train_1/mu_grads          | 0.010901204426772892  |
| train_1/mu_grads_std      | 0.2539670877158642    |
| train_1/mu_loss           | 13.364360027171333    |
| train_1/n_subgoals        | 2241.0                |
| train_1/next_q            | -13.30478619585666    |
| train_1/q_grads           | 0.00470390081172809   |
| train_1/q_grads_std       | 0.30949323028326037   |
| train_1/q_loss            | 9.54887873336722      |
| train_1/reward            | -2.478047137129397    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00634765625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2222222222222222    |
| train_1/target_q          | -12.937721702032656   |
-----------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 4
Time for epoch 4: 522.31. Rollout time: 299.32, Training time: 222.95
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 370159.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.0229060663262783    |
| test_1/avg_q              | -10.401591225940052    |
| test_1/n_subgoals         | 6302.0                 |
| test_1/subgoal_succ_rate  | 0.9360520469692161     |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -7.0985525128532       |
| train_0/current_q         | -5.2124730734460005    |
| train_0/fw_bonus          | -0.9982573688030243    |
| train_0/fw_loss           | 0.00046868395147612316 |
| train_0/mu_grads          | -0.02900946610607207   |
| train_0/mu_grads_std      | 0.25011244118213655    |
| train_0/mu_loss           | 4.928406132355116      |
| train_0/next_q            | -4.793882529876005     |
| train_0/q_grads           | 0.025379515159875153   |
| train_0/q_grads_std       | 0.18135982006788254    |
| train_0/q_loss            | 0.281972178179345      |
| train_0/reward            | -0.7018348495181271    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -5.137233910058856     |
| train_1/avg_q             | -15.450760350254688    |
| train_1/current_q         | -12.5211656953358      |
| train_1/fw_bonus          | -0.996375884115696     |
| train_1/fw_loss           | 0.001763345961808227   |
| train_1/mu_grads          | 0.007549346296582371   |
| train_1/mu_grads_std      | 0.27741539999842646    |
| train_1/mu_loss           | 12.860891725283679     |
| train_1/n_subgoals        | 2040.0                 |
| train_1/next_q            | -12.836106822097275    |
| train_1/q_grads           | 0.0015883216896327213  |
| train_1/q_grads_std       | 0.32948962450027464    |
| train_1/q_loss            | 10.734666872747647     |
| train_1/reward            | -2.373428687901833     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006103515625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3686274509803922     |
| train_1/target_q          | -12.602017779650629    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 5
Time for epoch 5: 550.73. Rollout time: 320.37, Training time: 230.30
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 430161.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.0857472691600307    |
| test_1/avg_q              | -11.271934170842087    |
| test_1/n_subgoals         | 2756.0                 |
| test_1/subgoal_succ_rate  | 0.7906386066763426     |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -8.628371260559994     |
| train_0/current_q         | -4.877384716571937     |
| train_0/fw_bonus          | -0.9984050005674362    |
| train_0/fw_loss           | 0.0004293988255085424  |
| train_0/mu_grads          | -0.034505173470824956  |
| train_0/mu_grads_std      | 0.26593582779169084    |
| train_0/mu_loss           | 4.793256677732647      |
| train_0/next_q            | -4.612531694127277     |
| train_0/q_grads           | 0.02627790397964418    |
| train_0/q_grads_std       | 0.19631904028356076    |
| train_0/q_loss            | 0.5058009037163727     |
| train_0/reward            | -0.7078959297155961    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00048828125          |
| train_0/target_q          | -4.9112948685073965    |
| train_1/avg_q             | -14.280844933717937    |
| train_1/current_q         | -13.29096800259731     |
| train_1/fw_bonus          | -0.9959456458687782    |
| train_1/fw_loss           | 0.001863342267461121   |
| train_1/mu_grads          | 0.005005027400329709   |
| train_1/mu_grads_std      | 0.28974617198109626    |
| train_1/mu_loss           | 13.744190422154295     |
| train_1/n_subgoals        | 2046.0                 |
| train_1/next_q            | -13.731733242822083    |
| train_1/q_grads           | 0.00029927357209089676 |
| train_1/q_grads_std       | 0.3552885837852955     |
| train_1/q_loss            | 8.977419265543542      |
| train_1/reward            | -2.3266109211454022    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3421309872922776     |
| train_1/target_q          | -13.348627477653702    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 6
Time for epoch 6: 557.99. Rollout time: 328.34, Training time: 229.60
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 491432.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.3020859684373935    |
| test_1/avg_q              | -14.679609788715878    |
| test_1/n_subgoals         | 10115.0                |
| test_1/subgoal_succ_rate  | 0.9766683143845774     |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -9.219205051037616     |
| train_0/current_q         | -5.92571475805482      |
| train_0/fw_bonus          | -0.9984415784478188    |
| train_0/fw_loss           | 0.00041966924036387356 |
| train_0/mu_grads          | -0.041330930404365064  |
| train_0/mu_grads_std      | 0.28156750053167345    |
| train_0/mu_loss           | 5.670996358687553      |
| train_0/next_q            | -5.513269942420343     |
| train_0/q_grads           | 0.026428043050691484   |
| train_0/q_grads_std       | 0.20931039452552797    |
| train_0/q_loss            | 0.29237589807412856    |
| train_0/reward            | -0.7170054129397613    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0009033203125        |
| train_0/target_q          | -5.894368518320879     |
| train_1/avg_q             | -15.391157319055027    |
| train_1/current_q         | -13.25518069558172     |
| train_1/fw_bonus          | -0.9954916536808014    |
| train_1/fw_loss           | 0.0019688550441060216  |
| train_1/mu_grads          | -0.0009302715741796419 |
| train_1/mu_grads_std      | 0.30355735048651694    |
| train_1/mu_loss           | 13.591590693854425     |
| train_1/n_subgoals        | 2070.0                 |
| train_1/next_q            | -13.512794583112921    |
| train_1/q_grads           | -0.003937286749714985  |
| train_1/q_grads_std       | 0.3739285208284855     |
| train_1/q_loss            | 6.5919650556577665     |
| train_1/reward            | -2.300880972064988     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006396484375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3309178743961353     |
| train_1/target_q          | -13.29749655205913     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 7
Time for epoch 7: 569.68. Rollout time: 329.26, Training time: 240.36
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 549872.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -0.34804012435759746   |
| test_1/avg_q              | -16.328312975417727    |
| test_1/n_subgoals         | 2778.0                 |
| test_1/subgoal_succ_rate  | 0.822174226061915      |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -10.586861290335918    |
| train_0/current_q         | -4.871742194077004     |
| train_0/fw_bonus          | -0.9984641671180725    |
| train_0/fw_loss           | 0.00041365585857420226 |
| train_0/mu_grads          | -0.04576813718304038   |
| train_0/mu_grads_std      | 0.2944451034069061     |
| train_0/mu_loss           | 4.604502130596144      |
| train_0/next_q            | -4.522624289278118     |
| train_0/q_grads           | 0.0247155059594661     |
| train_0/q_grads_std       | 0.2199176326394081     |
| train_0/q_loss            | 0.5240024782357724     |
| train_0/reward            | -0.7279424593561998    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.001025390625         |
| train_0/target_q          | -4.917048759666269     |
| train_1/avg_q             | -15.24912690361813     |
| train_1/current_q         | -12.205328947694555    |
| train_1/fw_bonus          | -0.9950733795762062    |
| train_1/fw_loss           | 0.0020660714770201595  |
| train_1/mu_grads          | -0.0035782629624009133 |
| train_1/mu_grads_std      | 0.31403534710407255    |
| train_1/mu_loss           | 12.26821417743425      |
| train_1/n_subgoals        | 2010.0                 |
| train_1/next_q            | -12.138828053859491    |
| train_1/q_grads           | -0.006563412258401513  |
| train_1/q_grads_std       | 0.38796250596642495    |
| train_1/q_loss            | 6.614806769220332      |
| train_1/reward            | -2.2203564802628533    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071044921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3427860696517413     |
| train_1/target_q          | -12.236319361682519    |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 8
Time for epoch 8: 608.45. Rollout time: 351.36, Training time: 257.01
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 609645.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.8930184398888222   |
| test_1/avg_q              | -14.570334391613592   |
| test_1/n_subgoals         | 8559.0                |
| test_1/subgoal_succ_rate  | 0.9578221754877906    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -8.33460367486132     |
| train_0/current_q         | -6.010355080620995    |
| train_0/fw_bonus          | -0.9985280930995941   |
| train_0/fw_loss           | 0.000396645424189046  |
| train_0/mu_grads          | -0.051902530062943694 |
| train_0/mu_grads_std      | 0.31309539899230004   |
| train_0/mu_loss           | 5.6959703636032435    |
| train_0/next_q            | -5.547244539282639    |
| train_0/q_grads           | 0.025150424893945457  |
| train_0/q_grads_std       | 0.23387277126312256   |
| train_0/q_loss            | 0.24236487238874654   |
| train_0/reward            | -0.7348065861224313   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020751953125       |
| train_0/target_q          | -5.990403314998644    |
| train_1/avg_q             | -16.2709445122179     |
| train_1/current_q         | -11.808613983721715   |
| train_1/fw_bonus          | -0.9952304989099503   |
| train_1/fw_loss           | 0.002029554671025835  |
| train_1/mu_grads          | -0.00491279085399583  |
| train_1/mu_grads_std      | 0.3235893823206425    |
| train_1/mu_loss           | 11.71121184915317     |
| train_1/n_subgoals        | 1966.0                |
| train_1/next_q            | -11.539066688091921   |
| train_1/q_grads           | -0.009532510372810065 |
| train_1/q_grads_std       | 0.3975195653736591    |
| train_1/q_loss            | 6.558556712917449     |
| train_1/reward            | -2.1293007881096857   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00625               |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.32044760935910477   |
| train_1/target_q          | -11.806722515889843   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 9
Time for epoch 9: 503.85. Rollout time: 298.55, Training time: 205.22
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 672403.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.7525356262148983    |
| test_1/avg_q              | -14.639999827216537    |
| test_1/n_subgoals         | 688.0                  |
| test_1/subgoal_succ_rate  | 0.0188953488372093     |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -10.149105323235023    |
| train_0/current_q         | -5.660575827700646     |
| train_0/fw_bonus          | -0.9985619276762009    |
| train_0/fw_loss           | 0.00038764231649111023 |
| train_0/mu_grads          | -0.05756311397999525   |
| train_0/mu_grads_std      | 0.3297228701412678     |
| train_0/mu_loss           | 5.372342606002282      |
| train_0/next_q            | -5.20731358858396      |
| train_0/q_grads           | 0.023310278449207543   |
| train_0/q_grads_std       | 0.24062741212546826    |
| train_0/q_loss            | 0.3756573168270938     |
| train_0/reward            | -0.7438421445363929    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00283203125          |
| train_0/target_q          | -5.616741741070529     |
| train_1/avg_q             | -15.717086185983137    |
| train_1/current_q         | -12.49249985274172     |
| train_1/fw_bonus          | -0.9959053337574005    |
| train_1/fw_loss           | 0.001872708901646547   |
| train_1/mu_grads          | -0.006973247020505368  |
| train_1/mu_grads_std      | 0.33595241904258727    |
| train_1/mu_loss           | 12.497961607817864     |
| train_1/n_subgoals        | 1978.0                 |
| train_1/next_q            | -12.358916577799329    |
| train_1/q_grads           | -0.01114028780721128   |
| train_1/q_grads_std       | 0.4083789087831974     |
| train_1/q_loss            | 6.006530612656325      |
| train_1/reward            | -2.1265764326242786    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070068359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2537917087967644     |
| train_1/target_q          | -12.5257114774819      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 10
Time for epoch 10: 21999.81. Rollout time: 20525.21, Training time: 1474.37
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 733935.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5655457364585703    |
| test_1/avg_q              | -8.461763648139206     |
| test_1/n_subgoals         | 721.0                  |
| test_1/subgoal_succ_rate  | 0.0651872399445215     |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -9.273496543241018     |
| train_0/current_q         | -5.354742964104758     |
| train_0/fw_bonus          | -0.9986872568726539    |
| train_0/fw_loss           | 0.00035429622657829897 |
| train_0/mu_grads          | -0.06087735388427973   |
| train_0/mu_grads_std      | 0.34518384337425234    |
| train_0/mu_loss           | 5.026521496775508      |
| train_0/next_q            | -4.921651187916636     |
| train_0/q_grads           | 0.023602012265473604   |
| train_0/q_grads_std       | 0.24974247738718985    |
| train_0/q_loss            | 0.36679140624974743    |
| train_0/reward            | -0.7381422736438253    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0046142578125        |
| train_0/target_q          | -5.33210796289246      |
| train_1/avg_q             | -16.299694460939595    |
| train_1/current_q         | -11.934693504137826    |
| train_1/fw_bonus          | -0.9961698383092881    |
| train_1/fw_loss           | 0.0018112372985342518  |
| train_1/mu_grads          | -0.010423975554294885  |
| train_1/mu_grads_std      | 0.3531807713210583     |
| train_1/mu_loss           | 11.71485767130142      |
| train_1/n_subgoals        | 1916.0                 |
| train_1/next_q            | -11.65069650935072     |
| train_1/q_grads           | -0.01346944395918399   |
| train_1/q_grads_std       | 0.42015518322587014    |
| train_1/q_loss            | 6.100473226547099      |
| train_1/reward            | -2.131201880066874     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007666015625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24843423799582465    |
| train_1/target_q          | -11.935101278636974    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 11
Time for epoch 11: 535.03. Rollout time: 326.29, Training time: 208.68
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 801655.0               |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -0.9633985627827724    |
| test_1/avg_q              | -14.205049911395422    |
| test_1/n_subgoals         | 746.0                  |
| test_1/subgoal_succ_rate  | 0.19973190348525469    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.48                   |
| train_0/avg_q             | -6.95336107844472      |
| train_0/current_q         | -4.629784302752877     |
| train_0/fw_bonus          | -0.9987782940268517    |
| train_0/fw_loss           | 0.00033007494785124435 |
| train_0/mu_grads          | -0.06737266033887863   |
| train_0/mu_grads_std      | 0.3613386869430542     |
| train_0/mu_loss           | 4.468721463538641      |
| train_0/next_q            | -4.316645482957884     |
| train_0/q_grads           | 0.02468637186102569    |
| train_0/q_grads_std       | 0.25707644000649454    |
| train_0/q_loss            | 0.8078056081095625     |
| train_0/reward            | -0.7430356361612211    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0160888671875        |
| train_0/target_q          | -4.59333076788329      |
| train_1/avg_q             | -13.32598467293682     |
| train_1/current_q         | -7.157665085761105     |
| train_1/fw_bonus          | -0.9961247652769089    |
| train_1/fw_loss           | 0.0018217110016848892  |
| train_1/mu_grads          | -0.011770044034346939  |
| train_1/mu_grads_std      | 0.36416357904672625    |
| train_1/mu_loss           | 6.555439788177722      |
| train_1/n_subgoals        | 2168.0                 |
| train_1/next_q            | -6.455904741470692     |
| train_1/q_grads           | -0.02166834962554276   |
| train_1/q_grads_std       | 0.4291258752346039     |
| train_1/q_loss            | 4.2433724470264345     |
| train_1/reward            | -2.163820009398478     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0073974609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19280442804428044    |
| train_1/target_q          | -7.362890571671817     |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 12
Time for epoch 12: 5746.39. Rollout time: 3313.46, Training time: 2432.61
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 857809.0              |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.7886429941422368   |
| test_1/avg_q              | -13.927743338103593   |
| test_1/n_subgoals         | 677.0                 |
| test_1/subgoal_succ_rate  | 0.011816838995568686  |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.74                  |
| train_0/avg_q             | -9.874920126164648    |
| train_0/current_q         | -6.123786119133618    |
| train_0/fw_bonus          | -0.9987865820527076   |
| train_0/fw_loss           | 0.0003278687683632597 |
| train_0/mu_grads          | -0.07166194580495358  |
| train_0/mu_grads_std      | 0.3740641064941883    |
| train_0/mu_loss           | 5.917446604233801     |
| train_0/next_q            | -5.717221753962167    |
| train_0/q_grads           | 0.025184379937127233  |
| train_0/q_grads_std       | 0.2683047793805599    |
| train_0/q_loss            | 0.40017147090373595   |
| train_0/reward            | -0.7400347795417475   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0185302734375       |
| train_0/target_q          | -6.0767289144981405   |
| train_1/avg_q             | -15.306975701624939   |
| train_1/current_q         | -11.656015480965342   |
| train_1/fw_bonus          | -0.9967702507972718   |
| train_1/fw_loss           | 0.0016716896730940788 |
| train_1/mu_grads          | -0.015352790872566403 |
| train_1/mu_grads_std      | 0.37706971615552903   |
| train_1/mu_loss           | 11.53863311558411     |
| train_1/n_subgoals        | 1687.0                |
| train_1/next_q            | -11.345374989894768   |
| train_1/q_grads           | -0.024651106726378203 |
| train_1/q_grads_std       | 0.43683034628629686   |
| train_1/q_loss            | 7.417304099320603     |
| train_1/reward            | -2.191904965224603    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00732421875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.23532898636633076   |
| train_1/target_q          | -11.721684262288719   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 13
Time for epoch 13: 8268.72. Rollout time: 1406.31, Training time: 6862.19
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 922116.0               |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -0.5722529331857439    |
| test_1/avg_q              | -18.47806471495788     |
| test_1/n_subgoals         | 627.0                  |
| test_1/subgoal_succ_rate  | 0.03668261562998405    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -10.3861015278882      |
| train_0/current_q         | -4.400393346610168     |
| train_0/fw_bonus          | -0.9988020792603493    |
| train_0/fw_loss           | 0.00032374669463024474 |
| train_0/mu_grads          | -0.0755196800455451    |
| train_0/mu_grads_std      | 0.39268123507499697    |
| train_0/mu_loss           | 4.140679296775081      |
| train_0/next_q            | -4.042500813073197     |
| train_0/q_grads           | 0.024066254124045373   |
| train_0/q_grads_std       | 0.27804185897111894    |
| train_0/q_loss            | 0.48565562224286385    |
| train_0/reward            | -0.7421626756695332    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0113037109375        |
| train_0/target_q          | -4.496112019732879     |
| train_1/avg_q             | -16.47232081578617     |
| train_1/current_q         | -11.955041025368203    |
| train_1/fw_bonus          | -0.9964572176337242    |
| train_1/fw_loss           | 0.0017444436904042958  |
| train_1/mu_grads          | -0.017387397540733217  |
| train_1/mu_grads_std      | 0.3888215012848377     |
| train_1/mu_loss           | 11.946097522529232     |
| train_1/n_subgoals        | 2059.0                 |
| train_1/next_q            | -11.75708276797707     |
| train_1/q_grads           | -0.026486084749922156  |
| train_1/q_grads_std       | 0.438948679715395      |
| train_1/q_loss            | 5.605879175856282      |
| train_1/reward            | -2.191259080134478     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070068359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21321029626032054    |
| train_1/target_q          | -12.005433399396038    |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 14
Time for epoch 14: 662.59. Rollout time: 441.22, Training time: 221.30
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 992708.0               |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.638436350496076     |
| test_1/avg_q              | -17.387739287034563    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -6.798916848304611     |
| train_0/current_q         | -3.722116013174668     |
| train_0/fw_bonus          | -0.9988444909453392    |
| train_0/fw_loss           | 0.00031245678874256553 |
| train_0/mu_grads          | -0.07655658908188342   |
| train_0/mu_grads_std      | 0.40674441754817964    |
| train_0/mu_loss           | 3.464199642743394      |
| train_0/next_q            | -3.318883653400543     |
| train_0/q_grads           | 0.024865916557610036   |
| train_0/q_grads_std       | 0.2841894321143627     |
| train_0/q_loss            | 0.43767524412136416    |
| train_0/reward            | -0.7360392499344016    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.019580078125         |
| train_0/target_q          | -3.77215810641176      |
| train_1/avg_q             | -16.864202574153484    |
| train_1/current_q         | -11.930687860660587    |
| train_1/fw_bonus          | -0.9963247060775757    |
| train_1/fw_loss           | 0.0017752426356310025  |
| train_1/mu_grads          | -0.019182297959923746  |
| train_1/mu_grads_std      | 0.3971354529261589     |
| train_1/mu_loss           | 11.989051010873983     |
| train_1/n_subgoals        | 2133.0                 |
| train_1/next_q            | -11.792044020464825    |
| train_1/q_grads           | -0.02809163713827729   |
| train_1/q_grads_std       | 0.44871280416846276    |
| train_1/q_loss            | 5.614632245742018      |
| train_1/reward            | -2.2350613994716695    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075439453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14064697609001406    |
| train_1/target_q          | -12.01607681144074     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 15
Time for epoch 15: 561.55. Rollout time: 346.27, Training time: 215.22
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1057773.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.238048675235628    |
| test_1/avg_q              | -14.262202784626002   |
| test_1/n_subgoals         | 681.0                 |
| test_1/subgoal_succ_rate  | 0.00881057268722467   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.58                  |
| train_0/avg_q             | -7.770072206719855    |
| train_0/current_q         | -4.917653563072931    |
| train_0/fw_bonus          | -0.9988994479179383   |
| train_0/fw_loss           | 0.0002978337524837116 |
| train_0/mu_grads          | -0.07974143736064435  |
| train_0/mu_grads_std      | 0.42056881338357927   |
| train_0/mu_loss           | 4.713916235155726     |
| train_0/next_q            | -4.542171820801224    |
| train_0/q_grads           | 0.02710800589993596   |
| train_0/q_grads_std       | 0.292263999581337     |
| train_0/q_loss            | 0.4739045984939413    |
| train_0/reward            | -0.7377009383657424   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.028466796875        |
| train_0/target_q          | -4.899574442492567    |
| train_1/avg_q             | -16.96788186421008    |
| train_1/current_q         | -12.697858674608034   |
| train_1/fw_bonus          | -0.9963115483522416   |
| train_1/fw_loss           | 0.0017782986484235152 |
| train_1/mu_grads          | -0.021164359431713818 |
| train_1/mu_grads_std      | 0.410126268863678     |
| train_1/mu_loss           | 12.749624295968406    |
| train_1/n_subgoals        | 1948.0                |
| train_1/next_q            | -12.575659271647703   |
| train_1/q_grads           | -0.02834267681464553  |
| train_1/q_grads_std       | 0.45776784867048265   |
| train_1/q_loss            | 5.511954738394888     |
| train_1/reward            | -2.291344733198275    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0075439453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.15349075975359344   |
| train_1/target_q          | -12.731697178952317   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 16
Time for epoch 16: 584.54. Rollout time: 340.63, Training time: 243.81
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1113164.0              |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.9219907650960535    |
| test_1/avg_q              | -15.83469092786707     |
| test_1/n_subgoals         | 5635.0                 |
| test_1/subgoal_succ_rate  | 0.9524401064773735     |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -11.028532635664826    |
| train_0/current_q         | -5.673429417418494     |
| train_0/fw_bonus          | -0.9988675162196159    |
| train_0/fw_loss           | 0.00030633313726866616 |
| train_0/mu_grads          | -0.08215261530131102   |
| train_0/mu_grads_std      | 0.43276364356279373    |
| train_0/mu_loss           | 5.445723675774602      |
| train_0/next_q            | -5.2712406078804355    |
| train_0/q_grads           | 0.028305363934487106   |
| train_0/q_grads_std       | 0.30311196148395536    |
| train_0/q_loss            | 0.3662140503262342     |
| train_0/reward            | -0.7387732749266434    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0255615234375        |
| train_0/target_q          | -5.632181692661442     |
| train_1/avg_q             | -16.7197241741493      |
| train_1/current_q         | -13.003503027031348    |
| train_1/fw_bonus          | -0.9967993274331093    |
| train_1/fw_loss           | 0.0016649319790303708  |
| train_1/mu_grads          | -0.02430381756275892   |
| train_1/mu_grads_std      | 0.4204513534903526     |
| train_1/mu_loss           | 13.182975023968709     |
| train_1/n_subgoals        | 1741.0                 |
| train_1/next_q            | -13.075562595094613    |
| train_1/q_grads           | -0.03139919014647603   |
| train_1/q_grads_std       | 0.471105045825243      |
| train_1/q_loss            | 5.5312251670200245     |
| train_1/reward            | -2.3115716575757688    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007470703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27627800114876505    |
| train_1/target_q          | -13.103826068207102    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 17
Time for epoch 17: 588.86. Rollout time: 339.26, Training time: 249.51
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1167186.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.12                  |
| test_0/avg_q              | -1.0814357411106856   |
| test_1/avg_q              | -18.071945315624824   |
| test_1/n_subgoals         | 1152.0                |
| test_1/subgoal_succ_rate  | 0.5060763888888888    |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -11.802672266250475   |
| train_0/current_q         | -5.323325892610839    |
| train_0/fw_bonus          | -0.9989171847701073   |
| train_0/fw_loss           | 0.0002931183400505688 |
| train_0/mu_grads          | -0.08886001855134965  |
| train_0/mu_grads_std      | 0.4453945726156235    |
| train_0/mu_loss           | 5.079555545127528     |
| train_0/next_q            | -4.959657989840445    |
| train_0/q_grads           | 0.028066412033513188  |
| train_0/q_grads_std       | 0.31153549030423167   |
| train_0/q_loss            | 0.4790866329278261    |
| train_0/reward            | -0.7432717749052244   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0362548828125       |
| train_0/target_q          | -5.329090986628498    |
| train_1/avg_q             | -16.296717186430758   |
| train_1/current_q         | -12.742081432543396   |
| train_1/fw_bonus          | -0.996407388150692    |
| train_1/fw_loss           | 0.0017560234089614823 |
| train_1/mu_grads          | -0.027307241270318628 |
| train_1/mu_grads_std      | 0.42851041853427885   |
| train_1/mu_loss           | 12.8511241581126      |
| train_1/n_subgoals        | 1873.0                |
| train_1/next_q            | -12.720910233497252   |
| train_1/q_grads           | -0.0321971096098423   |
| train_1/q_grads_std       | 0.4838686116039753    |
| train_1/q_loss            | 6.0524447123094145    |
| train_1/reward            | -2.248412149612341    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007470703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.399893219434063     |
| train_1/target_q          | -12.772501489463234   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 18
Time for epoch 18: 673.72. Rollout time: 405.14, Training time: 268.46
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1226783.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -1.4077785699757372    |
| test_1/avg_q              | -15.736996669793797    |
| test_1/n_subgoals         | 4482.0                 |
| test_1/subgoal_succ_rate  | 0.9016064257028112     |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.54                   |
| train_0/avg_q             | -12.318236071080834    |
| train_0/current_q         | -5.373015174547166     |
| train_0/fw_bonus          | -0.9988895609974862    |
| train_0/fw_loss           | 0.00030046448737266476 |
| train_0/mu_grads          | -0.09236223492771387   |
| train_0/mu_grads_std      | 0.456646878272295      |
| train_0/mu_loss           | 5.1662021678123295     |
| train_0/next_q            | -5.017454852296323     |
| train_0/q_grads           | 0.030085285613313317   |
| train_0/q_grads_std       | 0.3199994668364525     |
| train_0/q_loss            | 0.45984575640349706    |
| train_0/reward            | -0.7403168748427561    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0413818359375        |
| train_0/target_q          | -5.395700501564235     |
| train_1/avg_q             | -16.540798603922998    |
| train_1/current_q         | -12.384410662872204    |
| train_1/fw_bonus          | -0.9965851873159408    |
| train_1/fw_loss           | 0.0017147007718449458  |
| train_1/mu_grads          | -0.029009412229061126  |
| train_1/mu_grads_std      | 0.43654054775834084    |
| train_1/mu_loss           | 12.400700551814282     |
| train_1/n_subgoals        | 2010.0                 |
| train_1/next_q            | -12.27365072458351     |
| train_1/q_grads           | -0.03393400767818093   |
| train_1/q_grads_std       | 0.4909796372056007     |
| train_1/q_loss            | 5.803248042144995      |
| train_1/reward            | -2.2984810130899858    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076171875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3164179104477612     |
| train_1/target_q          | -12.435363149908515    |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 19
Time for epoch 19: 699.18. Rollout time: 431.77, Training time: 267.28
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1280214.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.1033114416105356    |
| test_1/avg_q              | -15.651569393729922    |
| test_1/n_subgoals         | 3530.0                 |
| test_1/subgoal_succ_rate  | 0.8943342776203966     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -13.78525485058068     |
| train_0/current_q         | -5.796232054570072     |
| train_0/fw_bonus          | -0.9988685503602028    |
| train_0/fw_loss           | 0.00030606038453697695 |
| train_0/mu_grads          | -0.09422506149858237   |
| train_0/mu_grads_std      | 0.46703421548008917    |
| train_0/mu_loss           | 5.540301217904356      |
| train_0/next_q            | -5.416342611883265     |
| train_0/q_grads           | 0.030955473706126214   |
| train_0/q_grads_std       | 0.32719545513391496    |
| train_0/q_loss            | 0.4598315787668265     |
| train_0/reward            | -0.7468118612840045    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0384765625           |
| train_0/target_q          | -5.749759397545018     |
| train_1/avg_q             | -15.246193676590352    |
| train_1/current_q         | -11.766259638487265    |
| train_1/fw_bonus          | -0.9969662949442863    |
| train_1/fw_loss           | 0.0016261225624475627  |
| train_1/mu_grads          | -0.02966161952354014   |
| train_1/mu_grads_std      | 0.4431817792356014     |
| train_1/mu_loss           | 11.76055666060976      |
| train_1/n_subgoals        | 2021.0                 |
| train_1/next_q            | -11.602475859807592    |
| train_1/q_grads           | -0.03499149959534407   |
| train_1/q_grads_std       | 0.4982982836663723     |
| train_1/q_loss            | 5.415651324543835      |
| train_1/reward            | -2.2499068589822855    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006689453125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4334487877288471     |
| train_1/target_q          | -11.818787145811157    |
------------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 20
Time for epoch 20: 609.99. Rollout time: 349.49, Training time: 260.40
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1327141.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.7012731320807326   |
| test_1/avg_q              | -15.725365894456678   |
| test_1/n_subgoals         | 1730.0                |
| test_1/subgoal_succ_rate  | 0.8445086705202313    |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -12.63437032004629    |
| train_0/current_q         | -6.493660339892145    |
| train_0/fw_bonus          | -0.9989170029759407   |
| train_0/fw_loss           | 0.0002931641323812073 |
| train_0/mu_grads          | -0.09612769298255444  |
| train_0/mu_grads_std      | 0.4791359156370163    |
| train_0/mu_loss           | 6.270050418482592     |
| train_0/next_q            | -6.104776729335297    |
| train_0/q_grads           | 0.031652787886559966  |
| train_0/q_grads_std       | 0.3375467650592327    |
| train_0/q_loss            | 0.39273403449174243   |
| train_0/reward            | -0.7509438510602194   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0421142578125       |
| train_0/target_q          | -6.4506355608011345   |
| train_1/avg_q             | -15.404923393223145   |
| train_1/current_q         | -11.908991666241361   |
| train_1/fw_bonus          | -0.9966483905911445   |
| train_1/fw_loss           | 0.001700013704248704  |
| train_1/mu_grads          | -0.03256960567086935  |
| train_1/mu_grads_std      | 0.453384718298912     |
| train_1/mu_loss           | 12.008692486958216    |
| train_1/n_subgoals        | 1956.0                |
| train_1/next_q            | -11.856759636083073   |
| train_1/q_grads           | -0.036018391326069835 |
| train_1/q_grads_std       | 0.5121105879545211    |
| train_1/q_loss            | 5.847676227124284     |
| train_1/reward            | -2.1201703951250237   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00771484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.44683026584867075   |
| train_1/target_q          | -11.983591750297455   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_20.pkl ...
New best value for test/success_rate: 0.48. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.24
Training epoch 21
Time for epoch 21: 757.88. Rollout time: 407.90, Training time: 349.84
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 1367979.0              |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.1806894942880877    |
| test_1/avg_q              | -16.354054096684862    |
| test_1/n_subgoals         | 8029.0                 |
| test_1/subgoal_succ_rate  | 0.990409764603313      |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -14.696470569169621    |
| train_0/current_q         | -6.591161439374636     |
| train_0/fw_bonus          | -0.998929412662983     |
| train_0/fw_loss           | 0.00028986024190089663 |
| train_0/mu_grads          | -0.09806895796209573   |
| train_0/mu_grads_std      | 0.48901706337928774    |
| train_0/mu_loss           | 6.403397111303818      |
| train_0/next_q            | -6.230389030891203     |
| train_0/q_grads           | 0.03230342892929912    |
| train_0/q_grads_std       | 0.34644423574209215    |
| train_0/q_loss            | 0.5130318927503142     |
| train_0/reward            | -0.7533822577741376    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0451171875           |
| train_0/target_q          | -6.526280191535328     |
| train_1/avg_q             | -14.486430127759604    |
| train_1/current_q         | -11.533242670197364    |
| train_1/fw_bonus          | -0.9973607495427131    |
| train_1/fw_loss           | 0.001534447236917913   |
| train_1/mu_grads          | -0.034079066943377256  |
| train_1/mu_grads_std      | 0.46260870397090914    |
| train_1/mu_loss           | 11.559474373618057     |
| train_1/n_subgoals        | 1557.0                 |
| train_1/next_q            | -11.438874641333953    |
| train_1/q_grads           | -0.03637876929715276   |
| train_1/q_grads_std       | 0.526654577255249      |
| train_1/q_loss            | 5.313433197423279      |
| train_1/reward            | -2.05787290143453      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076904296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4598587026332691     |
| train_1/target_q          | -11.587079668663709    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.29
Training epoch 22
Time for epoch 22: 1024.21. Rollout time: 636.55, Training time: 387.51
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 1418727.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -1.144658064138819    |
| test_1/avg_q              | -11.959743241847345   |
| test_1/n_subgoals         | 634.0                 |
| test_1/subgoal_succ_rate  | 0.26498422712933756   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -10.38944285184305    |
| train_0/current_q         | -4.776254552134652    |
| train_0/fw_bonus          | -0.9989099979400635   |
| train_0/fw_loss           | 0.0002950309881271096 |
| train_0/mu_grads          | -0.09923591259866953  |
| train_0/mu_grads_std      | 0.49910300597548485   |
| train_0/mu_loss           | 4.601333662003535     |
| train_0/next_q            | -4.48324949647452     |
| train_0/q_grads           | 0.033685298170894384  |
| train_0/q_grads_std       | 0.3542126268148422    |
| train_0/q_loss            | 0.7286372406304918    |
| train_0/reward            | -0.7589621163944684   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04453125            |
| train_0/target_q          | -4.864003282091976    |
| train_1/avg_q             | -14.285931525661988   |
| train_1/current_q         | -11.233761486964521   |
| train_1/fw_bonus          | -0.9968790069222451   |
| train_1/fw_loss           | 0.0016464108426589518 |
| train_1/mu_grads          | -0.03466215431690216  |
| train_1/mu_grads_std      | 0.4699620954692364    |
| train_1/mu_loss           | 11.228086040504916    |
| train_1/n_subgoals        | 1847.0                |
| train_1/next_q            | -11.160550995959166   |
| train_1/q_grads           | -0.03638294460251927  |
| train_1/q_grads_std       | 0.5423092007637024    |
| train_1/q_loss            | 4.930525601558327     |
| train_1/reward            | -1.986524441110305    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0074951171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3486735246345425    |
| train_1/target_q          | -11.304098317859246   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.33
Training epoch 23
Time for epoch 23: 1087.90. Rollout time: 623.28, Training time: 464.42
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 1462120.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.2800480500900868    |
| test_1/avg_q              | -9.62158554604178      |
| test_1/n_subgoals         | 4491.0                 |
| test_1/subgoal_succ_rate  | 0.9585838343353373     |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.78                   |
| train_0/avg_q             | -10.821557319194486    |
| train_0/current_q         | -6.166539060322431     |
| train_0/fw_bonus          | -0.9988955557346344    |
| train_0/fw_loss           | 0.00029887441669416146 |
| train_0/mu_grads          | -0.10236134454607963   |
| train_0/mu_grads_std      | 0.5069031268358231     |
| train_0/mu_loss           | 5.95577580004194       |
| train_0/next_q            | -5.800109484002388     |
| train_0/q_grads           | 0.03512497367337346    |
| train_0/q_grads_std       | 0.36426248773932457    |
| train_0/q_loss            | 0.526139311056968      |
| train_0/reward            | -0.7597824799911905    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0439208984375        |
| train_0/target_q          | -6.141566310042874     |
| train_1/avg_q             | -14.037293252935433    |
| train_1/current_q         | -11.185326491094163    |
| train_1/fw_bonus          | -0.9972116902470589    |
| train_1/fw_loss           | 0.0015690915344748646  |
| train_1/mu_grads          | -0.03578835129737854   |
| train_1/mu_grads_std      | 0.4761858269572258     |
| train_1/mu_loss           | 11.119583331016923     |
| train_1/n_subgoals        | 1534.0                 |
| train_1/next_q            | -11.052280207384635    |
| train_1/q_grads           | -0.036265643499791625  |
| train_1/q_grads_std       | 0.5558637052774429     |
| train_1/q_loss            | 4.9520655662226805     |
| train_1/reward            | -1.9845018955278646    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0077392578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.34028683181225555    |
| train_1/target_q          | -11.273210243536536    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 24
Time for epoch 24: 711.39. Rollout time: 371.05, Training time: 340.20
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 1500040.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.36                  |
| test_0/avg_q              | -1.8239125003679637   |
| test_1/avg_q              | -9.46425770618846     |
| test_1/n_subgoals         | 889.0                 |
| test_1/subgoal_succ_rate  | 0.4983127109111361    |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.83                  |
| train_0/avg_q             | -11.786860531167926   |
| train_0/current_q         | -5.65694902626595     |
| train_0/fw_bonus          | -0.9989160731434822   |
| train_0/fw_loss           | 0.0002934127678599907 |
| train_0/mu_grads          | -0.10522018261253833  |
| train_0/mu_grads_std      | 0.5145112589001656    |
| train_0/mu_loss           | 5.479252835661667     |
| train_0/next_q            | -5.319308655754465    |
| train_0/q_grads           | 0.0346797869540751    |
| train_0/q_grads_std       | 0.37128067910671236   |
| train_0/q_loss            | 0.6329331447661348    |
| train_0/reward            | -0.7611975235166029   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04091796875         |
| train_0/target_q          | -5.631145369632515    |
| train_1/avg_q             | -11.72837500097648    |
| train_1/current_q         | -10.731791285823125   |
| train_1/fw_bonus          | -0.9968276128172875   |
| train_1/fw_loss           | 0.0016583563323365525 |
| train_1/mu_grads          | -0.03779756501317024  |
| train_1/mu_grads_std      | 0.4848338283598423    |
| train_1/mu_loss           | 10.652476824074842    |
| train_1/n_subgoals        | 1383.0                |
| train_1/next_q            | -10.59372597782441    |
| train_1/q_grads           | -0.038314147386699915 |
| train_1/q_grads_std       | 0.5679317027330398    |
| train_1/q_loss            | 4.872411898691277     |
| train_1/reward            | -1.9082340033950458   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007421875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.47216196673897326   |
| train_1/target_q          | -10.817550821163554   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.35
Training epoch 25
Time for epoch 25: 808.80. Rollout time: 424.41, Training time: 384.21
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 1540951.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -1.2326384139233981   |
| test_1/avg_q              | -8.099632565327575    |
| test_1/n_subgoals         | 5706.0                |
| test_1/subgoal_succ_rate  | 0.9900105152471083    |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.76                  |
| train_0/avg_q             | -10.600773199756095   |
| train_0/current_q         | -6.384677459358375    |
| train_0/fw_bonus          | -0.9989031195640564   |
| train_0/fw_loss           | 0.0002968562333990121 |
| train_0/mu_grads          | -0.10783749837428332  |
| train_0/mu_grads_std      | 0.5221437618136406    |
| train_0/mu_loss           | 6.163142355352725     |
| train_0/next_q            | -6.003711861385382    |
| train_0/q_grads           | 0.03700228668749332   |
| train_0/q_grads_std       | 0.3816773422062397    |
| train_0/q_loss            | 0.5863445221008765    |
| train_0/reward            | -0.7726017590463016   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0491455078125       |
| train_0/target_q          | -6.339104419422178    |
| train_1/avg_q             | -11.885683184961852   |
| train_1/current_q         | -10.748946014910716   |
| train_1/fw_bonus          | -0.9971962302923203   |
| train_1/fw_loss           | 0.0015726851561339572 |
| train_1/mu_grads          | -0.03919364251196385  |
| train_1/mu_grads_std      | 0.4906232960522175    |
| train_1/mu_loss           | 10.636475995593477    |
| train_1/n_subgoals        | 1440.0                |
| train_1/next_q            | -10.572564759133702   |
| train_1/q_grads           | -0.04057695800438523  |
| train_1/q_grads_std       | 0.5793141946196556    |
| train_1/q_loss            | 4.972078502579537     |
| train_1/reward            | -1.8918832835784998   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0077880859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.39166666666666666   |
| train_1/target_q          | -10.822923181646313   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 26
Time for epoch 26: 867.64. Rollout time: 452.70, Training time: 414.75
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1574177.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.64                   |
| test_0/avg_q              | -0.9157709587300165    |
| test_1/avg_q              | -10.756025523464789    |
| test_1/n_subgoals         | 3399.0                 |
| test_1/subgoal_succ_rate  | 0.9911738746690203     |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -12.504538289698734    |
| train_0/current_q         | -6.854134048516608     |
| train_0/fw_bonus          | -0.9988823369145393    |
| train_0/fw_loss           | 0.00030239060943131334 |
| train_0/mu_grads          | -0.10943022128194571   |
| train_0/mu_grads_std      | 0.5302075415849685     |
| train_0/mu_loss           | 6.604036512933615      |
| train_0/next_q            | -6.4387627248337065    |
| train_0/q_grads           | 0.03742204047739506    |
| train_0/q_grads_std       | 0.39252000749111177    |
| train_0/q_loss            | 0.4971212729696443     |
| train_0/reward            | -0.7748487564171228    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0529541015625        |
| train_0/target_q          | -6.799390917372236     |
| train_1/avg_q             | -11.085066916689943    |
| train_1/current_q         | -10.443671356373958    |
| train_1/fw_bonus          | -0.9965569242835045    |
| train_1/fw_loss           | 0.0017212710779858753  |
| train_1/mu_grads          | -0.040757544338703156  |
| train_1/mu_grads_std      | 0.4942174591124058     |
| train_1/mu_loss           | 10.26677648080863      |
| train_1/n_subgoals        | 1403.0                 |
| train_1/next_q            | -10.225416083359779    |
| train_1/q_grads           | -0.04204742275178432   |
| train_1/q_grads_std       | 0.5933131411671638     |
| train_1/q_loss            | 5.063233637720823      |
| train_1/reward            | -1.8874570997435511    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080322265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4953670705630791     |
| train_1/target_q          | -10.534209344608731    |
------------------------------------------------------
New best value for test/success_rate: 0.64. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.45999999999999996
Training epoch 27
Time for epoch 27: 941.26. Rollout time: 528.54, Training time: 412.57
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 1617779.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.28                  |
| test_0/avg_q              | -1.4984732477608966   |
| test_1/avg_q              | -10.21285846018624    |
| test_1/n_subgoals         | 6517.0                |
| test_1/subgoal_succ_rate  | 0.9665490256252877    |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.74                  |
| train_0/avg_q             | -12.20272799979421    |
| train_0/current_q         | -6.487542267339987    |
| train_0/fw_bonus          | -0.9988826006650925   |
| train_0/fw_loss           | 0.0003023162182216765 |
| train_0/mu_grads          | -0.1124873636290431   |
| train_0/mu_grads_std      | 0.5373213738203049    |
| train_0/mu_loss           | 6.263832217765467     |
| train_0/next_q            | -6.059861367664108    |
| train_0/q_grads           | 0.03772060014307499   |
| train_0/q_grads_std       | 0.4012462720274925    |
| train_0/q_loss            | 0.44271155621720465   |
| train_0/reward            | -0.7751234843970451   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.031787109375        |
| train_0/target_q          | -6.4406035676699105   |
| train_1/avg_q             | -11.501324810874266   |
| train_1/current_q         | -9.504240011418933    |
| train_1/fw_bonus          | -0.9969081670045853   |
| train_1/fw_loss           | 0.0016396347840782256 |
| train_1/mu_grads          | -0.042295395582914355 |
| train_1/mu_grads_std      | 0.49943997263908385   |
| train_1/mu_loss           | 9.238057548237418     |
| train_1/n_subgoals        | 1640.0                |
| train_1/next_q            | -9.160174533413246    |
| train_1/q_grads           | -0.04279984766617417  |
| train_1/q_grads_std       | 0.6028191477060318    |
| train_1/q_loss            | 4.677828723500747     |
| train_1/reward            | -1.850520985960611    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.008056640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4847560975609756    |
| train_1/target_q          | -9.542541253645021    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.43
Training epoch 28
Time for epoch 28: 698.87. Rollout time: 363.83, Training time: 334.85
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 1652315.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -2.24272039772379     |
| test_1/avg_q              | -10.335400942010555   |
| test_1/n_subgoals         | 4284.0                |
| test_1/subgoal_succ_rate  | 0.9745564892623716    |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -12.704325313185203   |
| train_0/current_q         | -6.541273807900035    |
| train_0/fw_bonus          | -0.9989188268780709   |
| train_0/fw_loss           | 0.0002926834858953953 |
| train_0/mu_grads          | -0.11631098538637161  |
| train_0/mu_grads_std      | 0.5454456254839897    |
| train_0/mu_loss           | 6.369598259075852     |
| train_0/next_q            | -6.144074014408758    |
| train_0/q_grads           | 0.038010317273437975  |
| train_0/q_grads_std       | 0.4092647969722748    |
| train_0/q_loss            | 0.5494423159209468    |
| train_0/reward            | -0.7810468416817458   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0385986328125       |
| train_0/target_q          | -6.4781265754913235   |
| train_1/avg_q             | -12.389853405469118   |
| train_1/current_q         | -9.917168469193673    |
| train_1/fw_bonus          | -0.996795092523098    |
| train_1/fw_loss           | 0.0016659150714986026 |
| train_1/mu_grads          | -0.04314684346318245  |
| train_1/mu_grads_std      | 0.5067536354064941    |
| train_1/mu_loss           | 9.751982092441569     |
| train_1/n_subgoals        | 1317.0                |
| train_1/next_q            | -9.668296189119506    |
| train_1/q_grads           | -0.043523242231458426 |
| train_1/q_grads_std       | 0.6155313983559608    |
| train_1/q_loss            | 5.719767886728308     |
| train_1/reward            | -1.861295940976197    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007861328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.41002277904328016   |
| train_1/target_q          | -10.014650613299317   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.48000000000000004
Training epoch 29
Time for epoch 29: 810.08. Rollout time: 460.14, Training time: 349.79
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 1690364.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -1.2515853859129757    |
| test_1/avg_q              | -9.902957091358289     |
| test_1/n_subgoals         | 2444.0                 |
| test_1/subgoal_succ_rate  | 0.9590834697217676     |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -11.442816082118968    |
| train_0/current_q         | -6.574410559810121     |
| train_0/fw_bonus          | -0.9988954097032547    |
| train_0/fw_loss           | 0.00029891022204537877 |
| train_0/mu_grads          | -0.1170465461909771    |
| train_0/mu_grads_std      | 0.5512357816100121     |
| train_0/mu_loss           | 6.334902226213776      |
| train_0/next_q            | -6.098220438702266     |
| train_0/q_grads           | 0.03814373621717095    |
| train_0/q_grads_std       | 0.4164727672934532     |
| train_0/q_loss            | 0.42416070434244996    |
| train_0/reward            | -0.7803268798594217    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0489990234375        |
| train_0/target_q          | -6.504782201735535     |
| train_1/avg_q             | -11.88562570087126     |
| train_1/current_q         | -10.00827090573929     |
| train_1/fw_bonus          | -0.9966793462634087    |
| train_1/fw_loss           | 0.0016928130877204239  |
| train_1/mu_grads          | -0.04435185715556145   |
| train_1/mu_grads_std      | 0.5122841596603394     |
| train_1/mu_loss           | 9.78038109878155       |
| train_1/n_subgoals        | 1552.0                 |
| train_1/next_q            | -9.687440963232884     |
| train_1/q_grads           | -0.04529248913750052   |
| train_1/q_grads_std       | 0.6289323851466179     |
| train_1/q_loss            | 5.992410079215523      |
| train_1/reward            | -1.90184318137035      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00771484375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.42332474226804123    |
| train_1/target_q          | -10.090228854443804    |
------------------------------------------------------
New best value for test/success_rate: 0.68. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.54
Training epoch 30
Time for epoch 30: 974.14. Rollout time: 546.53, Training time: 427.43
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 1733274.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.36                   |
| test_0/avg_q              | -1.2044352792954152    |
| test_1/avg_q              | -11.844428263968378    |
| test_1/n_subgoals         | 4030.0                 |
| test_1/subgoal_succ_rate  | 0.9535980148883375     |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.77                   |
| train_0/avg_q             | -11.124874699390155    |
| train_0/current_q         | -5.74864307089667      |
| train_0/fw_bonus          | -0.9989089608192444    |
| train_0/fw_loss           | 0.00029530425745178946 |
| train_0/mu_grads          | -0.12072575092315674   |
| train_0/mu_grads_std      | 0.5585101008415222     |
| train_0/mu_loss           | 5.503449038668924      |
| train_0/next_q            | -5.350831936809635     |
| train_0/q_grads           | 0.03826597826555371    |
| train_0/q_grads_std       | 0.4207915745675564     |
| train_0/q_loss            | 0.5084748134057802     |
| train_0/reward            | -0.7863178167135629    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0475830078125        |
| train_0/target_q          | -5.770225758446684     |
| train_1/avg_q             | -12.278903592744555    |
| train_1/current_q         | -9.800347202712235     |
| train_1/fw_bonus          | -0.9970896169543266    |
| train_1/fw_loss           | 0.0015974630863638596  |
| train_1/mu_grads          | -0.044260304793715476  |
| train_1/mu_grads_std      | 0.5211278140544892     |
| train_1/mu_loss           | 9.572091681224116      |
| train_1/n_subgoals        | 1549.0                 |
| train_1/next_q            | -9.471018529617155     |
| train_1/q_grads           | -0.04688553921878338   |
| train_1/q_grads_std       | 0.6393299505114556     |
| train_1/q_loss            | 5.205450673433911      |
| train_1/reward            | -1.8647387116245226    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075927734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.42027114267269206    |
| train_1/target_q          | -9.885652858797595     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.47
Training epoch 31
Time for epoch 31: 661.63. Rollout time: 318.82, Training time: 342.65
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 1762602.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.64                  |
| test_0/avg_q              | -2.151099013294065    |
| test_1/avg_q              | -10.088074099787253   |
| test_1/n_subgoals         | 4066.0                |
| test_1/subgoal_succ_rate  | 0.9790949335956715    |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -10.445499493662698   |
| train_0/current_q         | -6.84342227570353     |
| train_0/fw_bonus          | -0.9988477408885956   |
| train_0/fw_loss           | 0.0003115947765763849 |
| train_0/mu_grads          | -0.12087235171347857  |
| train_0/mu_grads_std      | 0.5637453123927116    |
| train_0/mu_loss           | 6.664708380559071     |
| train_0/next_q            | -6.431418463003093    |
| train_0/q_grads           | 0.03817690378054976   |
| train_0/q_grads_std       | 0.4261165648698807    |
| train_0/q_loss            | 0.47936940102387693   |
| train_0/reward            | -0.7856067102205998   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0430908203125       |
| train_0/target_q          | -6.800143457885821    |
| train_1/avg_q             | -11.060421433373731   |
| train_1/current_q         | -9.677671754282226    |
| train_1/fw_bonus          | -0.9967963352799416   |
| train_1/fw_loss           | 0.0016656252584652976 |
| train_1/mu_grads          | -0.04577108807861805  |
| train_1/mu_grads_std      | 0.527857880294323     |
| train_1/mu_loss           | 9.356056454846264     |
| train_1/n_subgoals        | 1136.0                |
| train_1/next_q            | -9.281653817202326    |
| train_1/q_grads           | -0.04851110093295574  |
| train_1/q_grads_std       | 0.6520767346024513    |
| train_1/q_loss            | 5.35898119338094      |
| train_1/reward            | -1.886747912802457    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0083251953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4779929577464789    |
| train_1/target_q          | -9.733548687334373    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 32
Time for epoch 32: 5880.92. Rollout time: 5487.46, Training time: 393.34
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 1794453.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.4208625754122812   |
| test_1/avg_q              | -9.89154165576928     |
| test_1/n_subgoals         | 3808.0                |
| test_1/subgoal_succ_rate  | 0.9745273109243697    |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -14.747949421354395   |
| train_0/current_q         | -6.492091411466262    |
| train_0/fw_bonus          | -0.9988807559013366   |
| train_0/fw_loss           | 0.0003028077375347493 |
| train_0/mu_grads          | -0.12225618176162242  |
| train_0/mu_grads_std      | 0.5703418463468551    |
| train_0/mu_loss           | 6.221748063830285     |
| train_0/next_q            | -6.00197353564227     |
| train_0/q_grads           | 0.037819938454777005  |
| train_0/q_grads_std       | 0.43177986741065977   |
| train_0/q_loss            | 0.29828358147196454   |
| train_0/reward            | -0.7859079349273088   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.049609375           |
| train_0/target_q          | -6.474292204802775    |
| train_1/avg_q             | -11.898060477401804   |
| train_1/current_q         | -9.306804034112236    |
| train_1/fw_bonus          | -0.9969778567552566   |
| train_1/fw_loss           | 0.0016234373644692824 |
| train_1/mu_grads          | -0.0467616586945951   |
| train_1/mu_grads_std      | 0.5340699300169944    |
| train_1/mu_loss           | 8.997618280789395     |
| train_1/n_subgoals        | 1262.0                |
| train_1/next_q            | -8.926301603306433    |
| train_1/q_grads           | -0.0503047151491046   |
| train_1/q_grads_std       | 0.6646128967404366    |
| train_1/q_loss            | 7.157683799377909     |
| train_1/reward            | -1.83872810624016     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007275390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4437400950871632    |
| train_1/target_q          | -9.409654228923461    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5700000000000001
Training epoch 33
Time for epoch 33: 821.60. Rollout time: 413.96, Training time: 407.46
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 1830654.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -1.9389651077728363   |
| test_1/avg_q              | -5.1610108110728214   |
| test_1/n_subgoals         | 6581.0                |
| test_1/subgoal_succ_rate  | 0.9917945600972496    |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -10.392580482827535   |
| train_0/current_q         | -6.574530354145554    |
| train_0/fw_bonus          | -0.9988363012671471   |
| train_0/fw_loss           | 0.0003146400162222562 |
| train_0/mu_grads          | -0.11854980122298002  |
| train_0/mu_grads_std      | 0.5797012612223625    |
| train_0/mu_loss           | 6.328925263193729     |
| train_0/next_q            | -6.107147187233504    |
| train_0/q_grads           | 0.038631259277462957  |
| train_0/q_grads_std       | 0.4367389865219593    |
| train_0/q_loss            | 0.41608031126062367   |
| train_0/reward            | -0.7884969154467398   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.038134765625        |
| train_0/target_q          | -6.506407006927451    |
| train_1/avg_q             | -11.638674914254194   |
| train_1/current_q         | -8.777778320802636    |
| train_1/fw_bonus          | -0.9965100586414337   |
| train_1/fw_loss           | 0.001732164787244983  |
| train_1/mu_grads          | -0.04920765431597829  |
| train_1/mu_grads_std      | 0.539484791457653     |
| train_1/mu_loss           | 8.487990343144526     |
| train_1/n_subgoals        | 1298.0                |
| train_1/next_q            | -8.430397884334932    |
| train_1/q_grads           | -0.05101145152002573  |
| train_1/q_grads_std       | 0.6764545187354087    |
| train_1/q_loss            | 6.062714600071378     |
| train_1/reward            | -1.7783877659101563   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0076904296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.40215716486902925   |
| train_1/target_q          | -8.851985359317933    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 34
Time for epoch 34: 834.72. Rollout time: 424.24, Training time: 410.32
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 1863178.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -1.3255964539727956   |
| test_1/avg_q              | -6.51586483543194     |
| test_1/n_subgoals         | 3175.0                |
| test_1/subgoal_succ_rate  | 0.9533858267716535    |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -12.200068476168392   |
| train_0/current_q         | -6.494639813287543    |
| train_0/fw_bonus          | -0.9989033147692681   |
| train_0/fw_loss           | 0.0002968086784676416 |
| train_0/mu_grads          | -0.12137857060879469  |
| train_0/mu_grads_std      | 0.5869202181696892    |
| train_0/mu_loss           | 6.219332531795089     |
| train_0/next_q            | -5.981215965880739    |
| train_0/q_grads           | 0.03890640577301383   |
| train_0/q_grads_std       | 0.44193762317299845   |
| train_0/q_loss            | 0.299258045108537     |
| train_0/reward            | -0.7886967744780122   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0642333984375       |
| train_0/target_q          | -6.451937500995061    |
| train_1/avg_q             | -10.621042299805273   |
| train_1/current_q         | -9.00378975357886     |
| train_1/fw_bonus          | -0.996864227950573    |
| train_1/fw_loss           | 0.0016498442069860174 |
| train_1/mu_grads          | -0.050884751696139575 |
| train_1/mu_grads_std      | 0.5453457221388817    |
| train_1/mu_loss           | 8.641258917251378     |
| train_1/n_subgoals        | 1249.0                |
| train_1/next_q            | -8.563790547324698    |
| train_1/q_grads           | -0.05232855742797256  |
| train_1/q_grads_std       | 0.6877256453037262    |
| train_1/q_loss            | 6.235227536826763     |
| train_1/reward            | -1.8721896939438012   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0080322265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4475580464371497    |
| train_1/target_q          | -9.081759538319583    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 35
Time for epoch 35: 734.89. Rollout time: 353.15, Training time: 381.56
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 1895484.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.44                   |
| test_0/avg_q              | -1.1168534119710096    |
| test_1/avg_q              | -8.806403584485878     |
| test_1/n_subgoals         | 1649.0                 |
| test_1/subgoal_succ_rate  | 0.821710127349909      |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.87                   |
| train_0/avg_q             | -12.942273011076935    |
| train_0/current_q         | -6.7074832004774       |
| train_0/fw_bonus          | -0.9988684520125389    |
| train_0/fw_loss           | 0.00030608178458351175 |
| train_0/mu_grads          | -0.1228481201454997    |
| train_0/mu_grads_std      | 0.5938696041703224     |
| train_0/mu_loss           | 6.409725408143198      |
| train_0/next_q            | -6.188431240971357     |
| train_0/q_grads           | 0.03908206019550562    |
| train_0/q_grads_std       | 0.44779644832015036    |
| train_0/q_loss            | 0.2659916447452497     |
| train_0/reward            | -0.792789624420766     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.04775390625          |
| train_0/target_q          | -6.689734879245518     |
| train_1/avg_q             | -10.4213744459328      |
| train_1/current_q         | -8.971876315180388     |
| train_1/fw_bonus          | -0.9969839960336685    |
| train_1/fw_loss           | 0.0016220119985518977  |
| train_1/mu_grads          | -0.05354411918669939   |
| train_1/mu_grads_std      | 0.5530217930674552     |
| train_1/mu_loss           | 8.652725403640943      |
| train_1/n_subgoals        | 1200.0                 |
| train_1/next_q            | -8.59328409958042      |
| train_1/q_grads           | -0.054282948933541776  |
| train_1/q_grads_std       | 0.6988412752747536     |
| train_1/q_loss            | 6.099871631032186      |
| train_1/reward            | -1.8274686532487976    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007861328125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4625                 |
| train_1/target_q          | -9.030211969018406     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 36
Time for epoch 36: 901.86. Rollout time: 501.73, Training time: 399.91
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 1934608.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -0.9299870336518147    |
| test_1/avg_q              | -7.744029830757399     |
| test_1/n_subgoals         | 4605.0                 |
| test_1/subgoal_succ_rate  | 0.9745928338762215     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -11.457280394035433    |
| train_0/current_q         | -6.495189820356552     |
| train_0/fw_bonus          | -0.9989174053072929    |
| train_0/fw_loss           | 0.00029305583084351385 |
| train_0/mu_grads          | -0.12306767329573631   |
| train_0/mu_grads_std      | 0.5991328820586205     |
| train_0/mu_loss           | 6.256196507484701      |
| train_0/next_q            | -6.050681459216721     |
| train_0/q_grads           | 0.03977638706564903    |
| train_0/q_grads_std       | 0.454653749614954      |
| train_0/q_loss            | 0.38876790788254845    |
| train_0/reward            | -0.7882791577583703    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.07158203125          |
| train_0/target_q          | -6.546072406932599     |
| train_1/avg_q             | -10.618679014804318    |
| train_1/current_q         | -8.892019263512221     |
| train_1/fw_bonus          | -0.9969713464379311    |
| train_1/fw_loss           | 0.0016249518608674406  |
| train_1/mu_grads          | -0.05359362149611115   |
| train_1/mu_grads_std      | 0.5595338463783264     |
| train_1/mu_loss           | 8.553312914755987      |
| train_1/n_subgoals        | 1385.0                 |
| train_1/next_q            | -8.53827726073662      |
| train_1/q_grads           | -0.05498739527538419   |
| train_1/q_grads_std       | 0.7101442635059356     |
| train_1/q_loss            | 5.983607526786522      |
| train_1/reward            | -1.8405941540975619    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008056640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36606498194945847    |
| train_1/target_q          | -8.935503870703528     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.48
Training epoch 37
Time for epoch 37: 872.26. Rollout time: 436.82, Training time: 435.27
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 1966560.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.9611921589829924   |
| test_1/avg_q              | -6.740074202548661    |
| test_1/n_subgoals         | 3626.0                |
| test_1/subgoal_succ_rate  | 0.9718698290126861    |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -11.835359829022467   |
| train_0/current_q         | -6.761221375947164    |
| train_0/fw_bonus          | -0.9988881796598434   |
| train_0/fw_loss           | 0.000300834988229326  |
| train_0/mu_grads          | -0.12680164650082587  |
| train_0/mu_grads_std      | 0.606156912446022     |
| train_0/mu_loss           | 6.488915234396634     |
| train_0/next_q            | -6.251109403193166    |
| train_0/q_grads           | 0.040145619120448825  |
| train_0/q_grads_std       | 0.4607217937707901    |
| train_0/q_loss            | 0.27063440724496196   |
| train_0/reward            | -0.7932156965118338   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.06337890625         |
| train_0/target_q          | -6.749255291454953    |
| train_1/avg_q             | -9.990941344065053    |
| train_1/current_q         | -8.758811926859176    |
| train_1/fw_bonus          | -0.9974531412124634   |
| train_1/fw_loss           | 0.001512976348749362  |
| train_1/mu_grads          | -0.05439204666763544  |
| train_1/mu_grads_std      | 0.565137180685997     |
| train_1/mu_loss           | 8.411120823664945     |
| train_1/n_subgoals        | 1229.0                |
| train_1/next_q            | -8.309515887920105    |
| train_1/q_grads           | -0.056166574265807866 |
| train_1/q_grads_std       | 0.7230244234204293    |
| train_1/q_loss            | 6.550558753386781     |
| train_1/reward            | -1.8391398941428634   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00888671875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.46379170056956875   |
| train_1/target_q          | -8.79109209074311     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.52
Training epoch 38
Time for epoch 38: 774.41. Rollout time: 370.15, Training time: 404.00
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 1999761.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.2472905456153598   |
| test_1/avg_q              | -6.708339130524234    |
| test_1/n_subgoals         | 4615.0                |
| test_1/subgoal_succ_rate  | 0.9599133261105092    |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.9                   |
| train_0/avg_q             | -12.827163041040276   |
| train_0/current_q         | -6.722301535525746    |
| train_0/fw_bonus          | -0.9989059284329415   |
| train_0/fw_loss           | 0.0002961079964734381 |
| train_0/mu_grads          | -0.1316910207271576   |
| train_0/mu_grads_std      | 0.6137561738491059    |
| train_0/mu_loss           | 6.466417969043912     |
| train_0/next_q            | -6.2362163961188735   |
| train_0/q_grads           | 0.03968759449198842   |
| train_0/q_grads_std       | 0.46398849636316297   |
| train_0/q_loss            | 0.3029646135798854    |
| train_0/reward            | -0.7974315636456595   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.051171875           |
| train_0/target_q          | -6.729507142642538    |
| train_1/avg_q             | -10.316060434175032   |
| train_1/current_q         | -8.624869675445893    |
| train_1/fw_bonus          | -0.9973184496164322   |
| train_1/fw_loss           | 0.0015442797302966937 |
| train_1/mu_grads          | -0.05630961675196886  |
| train_1/mu_grads_std      | 0.5712786987423897    |
| train_1/mu_loss           | 8.322802080818335     |
| train_1/n_subgoals        | 1248.0                |
| train_1/next_q            | -8.260657771103109    |
| train_1/q_grads           | -0.05632080119103193  |
| train_1/q_grads_std       | 0.7360103920102119    |
| train_1/q_loss            | 6.6377614556560145    |
| train_1/reward            | -1.7986399119319685   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007568359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.484775641025641     |
| train_1/target_q          | -8.71086453538509     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 39
Time for epoch 39: 785.77. Rollout time: 434.97, Training time: 350.58
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 2033295.0              |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -0.8535544302922811    |
| test_1/avg_q              | -4.804358564633797     |
| test_1/n_subgoals         | 358.0                  |
| test_1/subgoal_succ_rate  | 0.32122905027932963    |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -13.235176560185213    |
| train_0/current_q         | -5.992893380505557     |
| train_0/fw_bonus          | -0.9989091649651527    |
| train_0/fw_loss           | 0.00029525077043217606 |
| train_0/mu_grads          | -0.13448187261819838   |
| train_0/mu_grads_std      | 0.6209589630365372     |
| train_0/mu_loss           | 5.769484347254904      |
| train_0/next_q            | -5.5475473890856986    |
| train_0/q_grads           | 0.03906845878809691    |
| train_0/q_grads_std       | 0.4675359144806862     |
| train_0/q_loss            | 0.43746376213032095    |
| train_0/reward            | -0.7964619099609991    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0888427734375        |
| train_0/target_q          | -6.007547594463544     |
| train_1/avg_q             | -11.429777347569573    |
| train_1/current_q         | -8.730412462706218     |
| train_1/fw_bonus          | -0.9975991547107697    |
| train_1/fw_loss           | 0.001479036797536537   |
| train_1/mu_grads          | -0.0564250685274601    |
| train_1/mu_grads_std      | 0.578460519015789      |
| train_1/mu_loss           | 8.34640579944202       |
| train_1/n_subgoals        | 1410.0                 |
| train_1/next_q            | -8.330208366950625     |
| train_1/q_grads           | -0.05724336821585894   |
| train_1/q_grads_std       | 0.7481251195073128     |
| train_1/q_loss            | 6.295155991145156      |
| train_1/reward            | -1.7719217606969324    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076171875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43829787234042555    |
| train_1/target_q          | -8.778483300406801     |
------------------------------------------------------
New best value for test/success_rate: 0.68. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 40
Time for epoch 40: 706.78. Rollout time: 379.36, Training time: 327.21
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 2070822.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.9994341455823088   |
| test_1/avg_q              | -6.507253358947523    |
| test_1/n_subgoals         | 2914.0                |
| test_1/subgoal_succ_rate  | 0.9296499656829101    |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -11.540047702046133   |
| train_0/current_q         | -7.012661250472116    |
| train_0/fw_bonus          | -0.9989133104681969   |
| train_0/fw_loss           | 0.0002941453509265557 |
| train_0/mu_grads          | -0.1344643708318472   |
| train_0/mu_grads_std      | 0.6271097436547279    |
| train_0/mu_loss           | 6.72748966767804      |
| train_0/next_q            | -6.489967697787935    |
| train_0/q_grads           | 0.0390865471214056    |
| train_0/q_grads_std       | 0.4714532010257244    |
| train_0/q_loss            | 0.23605385875766655   |
| train_0/reward            | -0.7945403412421002   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.087255859375        |
| train_0/target_q          | -7.004869060268396    |
| train_1/avg_q             | -10.972202063021163   |
| train_1/current_q         | -8.952221087482366    |
| train_1/fw_bonus          | -0.9973441138863564   |
| train_1/fw_loss           | 0.001538314067875035  |
| train_1/mu_grads          | -0.056844229158014056 |
| train_1/mu_grads_std      | 0.5854042679071426    |
| train_1/mu_loss           | 8.697018361486176     |
| train_1/n_subgoals        | 1258.0                |
| train_1/next_q            | -8.663001960116162    |
| train_1/q_grads           | -0.058443070575594905 |
| train_1/q_grads_std       | 0.7587181448936462    |
| train_1/q_loss            | 6.23352052490311      |
| train_1/reward            | -1.7859571205557585   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007958984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3481717011128776    |
| train_1/target_q          | -9.026708880777472    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 41
Time for epoch 41: 966.55. Rollout time: 622.04, Training time: 344.36
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2130150.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.8375997548719083    |
| test_1/avg_q              | -12.333207540179943    |
| test_1/n_subgoals         | 678.0                  |
| test_1/subgoal_succ_rate  | 0.004424778761061947   |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -8.955982142297904     |
| train_0/current_q         | -5.734312548438049     |
| train_0/fw_bonus          | -0.998863622546196     |
| train_0/fw_loss           | 0.00030736908702237996 |
| train_0/mu_grads          | -0.1327838446944952    |
| train_0/mu_grads_std      | 0.6298905313014984     |
| train_0/mu_loss           | 5.498985778910011      |
| train_0/next_q            | -5.319451883673655     |
| train_0/q_grads           | 0.03814774071797729    |
| train_0/q_grads_std       | 0.4731602676212788     |
| train_0/q_loss            | 0.5301680602877334     |
| train_0/reward            | -0.7882473992303858    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0727783203125        |
| train_0/target_q          | -5.714633565236832     |
| train_1/avg_q             | -10.999079041991447    |
| train_1/current_q         | -8.979549428010293     |
| train_1/fw_bonus          | -0.9961524173617363    |
| train_1/fw_loss           | 0.0018152836477383972  |
| train_1/mu_grads          | -0.059342315513640644  |
| train_1/mu_grads_std      | 0.5923532277345658     |
| train_1/mu_loss           | 8.708292959781039      |
| train_1/n_subgoals        | 1769.0                 |
| train_1/next_q            | -8.685113102853284     |
| train_1/q_grads           | -0.05866267178207636   |
| train_1/q_grads_std       | 0.7657903507351875     |
| train_1/q_loss            | 6.472829984140226      |
| train_1/reward            | -1.8766809268345241    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0082763671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21424533634821932    |
| train_1/target_q          | -9.058985536032424     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.41000000000000003
Training epoch 42
Time for epoch 42: 1815.63. Rollout time: 1327.15, Training time: 488.29
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 2218337.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5273839535530909    |
| test_1/avg_q              | -11.744982502296583    |
| test_1/n_subgoals         | 692.0                  |
| test_1/subgoal_succ_rate  | 0.024566473988439308   |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -7.29854189254853      |
| train_0/current_q         | -2.1759671726051395    |
| train_0/fw_bonus          | -0.9988379523158073    |
| train_0/fw_loss           | 0.00031419920996995644 |
| train_0/mu_grads          | -0.13083477094769477   |
| train_0/mu_grads_std      | 0.6348354533314705     |
| train_0/mu_loss           | 1.960111375650967      |
| train_0/next_q            | -1.8925699042267516    |
| train_0/q_grads           | 0.03717450127005577    |
| train_0/q_grads_std       | 0.47903580591082573    |
| train_0/q_loss            | 0.7043790051217782     |
| train_0/reward            | -0.7677331694605527    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0654296875           |
| train_0/target_q          | -2.3550125964245674    |
| train_1/avg_q             | -16.186559024860372    |
| train_1/current_q         | -11.653205476957812    |
| train_1/fw_bonus          | -0.9945815205574036    |
| train_1/fw_loss           | 0.0021803885465487838  |
| train_1/mu_grads          | -0.05987200811505318   |
| train_1/mu_grads_std      | 0.5966238781809807     |
| train_1/mu_loss           | 11.72599971219274      |
| train_1/n_subgoals        | 2642.0                 |
| train_1/next_q            | -11.744593069155787    |
| train_1/q_grads           | -0.06019400460645556   |
| train_1/q_grads_std       | 0.7708687037229538     |
| train_1/q_loss            | 7.943579484740811      |
| train_1/reward            | -2.084460809560187     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080322265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.029901589704769114   |
| train_1/target_q          | -11.745466725210811    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.29000000000000004
Training epoch 43
Time for epoch 43: 2167.59. Rollout time: 1539.39, Training time: 627.65
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 2307971.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.412360193067462     |
| test_1/avg_q              | -15.407339216183487    |
| test_1/n_subgoals         | 679.0                  |
| test_1/subgoal_succ_rate  | 0.005891016200294551   |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -1.3235669015706926    |
| train_0/current_q         | -2.894379809359612     |
| train_0/fw_bonus          | -0.9989251151680947    |
| train_0/fw_loss           | 0.00029100842657499016 |
| train_0/mu_grads          | -0.13085647597908973   |
| train_0/mu_grads_std      | 0.635153952240944      |
| train_0/mu_loss           | 2.755207158362235      |
| train_0/next_q            | -2.6754754227093147    |
| train_0/q_grads           | 0.038284685276448724   |
| train_0/q_grads_std       | 0.481185469776392      |
| train_0/q_loss            | 0.882930048532019      |
| train_0/reward            | -0.7539488060465374    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0590576171875        |
| train_0/target_q          | -2.9277424563139625    |
| train_1/avg_q             | -14.810869293000724    |
| train_1/current_q         | -13.921961336242779    |
| train_1/fw_bonus          | -0.9946421727538108    |
| train_1/fw_loss           | 0.0021662899845978243  |
| train_1/mu_grads          | -0.060006798803806306  |
| train_1/mu_grads_std      | 0.6017103508114815     |
| train_1/mu_loss           | 14.223296484872671     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.294905370829474    |
| train_1/q_grads           | -0.06197163118049502   |
| train_1/q_grads_std       | 0.7754412591457367     |
| train_1/q_loss            | 8.607511716261378      |
| train_1/reward            | -2.2265658174306737    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080810546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.027777777777777776   |
| train_1/target_q          | -13.992865510203625    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 44
