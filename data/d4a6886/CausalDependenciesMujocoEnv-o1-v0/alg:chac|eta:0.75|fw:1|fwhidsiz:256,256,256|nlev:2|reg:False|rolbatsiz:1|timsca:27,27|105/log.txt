Starting process id: 51899
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7f8f01b6aef0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 754.78. Rollout time: 459.84, Training time: 294.90
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 0                     |
| policy/steps              | 86213.0               |
| test/episodes             | 25.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.3606307142114593   |
| test_1/avg_q              | -19.666165729345725   |
| test_1/n_subgoals         | 683.0                 |
| test_1/subgoal_succ_rate  | 0.01171303074670571   |
| train/episodes            | 100.0                 |
| train/success_rate        | 0.03                  |
| train_0/avg_q             | -1.9228908601826307   |
| train_0/current_q         | -1.7772952576204113   |
| train_0/fw_bonus          | -0.998837299644947    |
| train_0/fw_loss           | 0.0003143712710880209 |
| train_0/mu_grads          | -0.013548454130068421 |
| train_0/mu_grads_std      | 0.1516219113022089    |
| train_0/mu_loss           | 1.647255520098982     |
| train_0/next_q            | -1.6639410055157182   |
| train_0/q_grads           | 0.022922914242371917  |
| train_0/q_grads_std       | 0.1281667347997427    |
| train_0/q_loss            | 0.47690396416450653   |
| train_0/reward            | -0.6545005860225501   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0009765625          |
| train_0/target_q          | -2.1107610279593656   |
| train_1/avg_q             | -9.629509251660041    |
| train_1/current_q         | -12.007209644377372   |
| train_1/fw_bonus          | -0.997672164440155    |
| train_1/fw_loss           | 0.001462070908746682  |
| train_1/mu_grads          | 0.014960606908425688  |
| train_1/mu_grads_std      | 0.15995850823819638   |
| train_1/mu_loss           | 12.440860889015244    |
| train_1/n_subgoals        | 2655.0                |
| train_1/next_q            | -12.4703243781661     |
| train_1/q_grads           | 0.016189347254112363  |
| train_1/q_grads_std       | 0.20655900985002518   |
| train_1/q_loss            | 18.053811714294092    |
| train_1/reward            | -2.6628579792082747   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.004443359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.06629001883239172   |
| train_1/target_q          | -11.987486481072741   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 702.98. Rollout time: 476.23, Training time: 226.70
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 173744.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.073105625186831     |
| test_1/avg_q              | -11.000770486905768    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -5.023501116496849     |
| train_0/current_q         | -4.5518736946949945    |
| train_0/fw_bonus          | -0.9986169651150704    |
| train_0/fw_loss           | 0.00037299877512850796 |
| train_0/mu_grads          | -0.01866160295903683   |
| train_0/mu_grads_std      | 0.19784256257116795    |
| train_0/mu_loss           | 4.348039241213604      |
| train_0/next_q            | -4.293174996787288     |
| train_0/q_grads           | 0.02491242722608149    |
| train_0/q_grads_std       | 0.1594510342925787     |
| train_0/q_loss            | 0.590472040792673      |
| train_0/reward            | -0.6692587348734378    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0007568359375        |
| train_0/target_q          | -4.45982100564208      |
| train_1/avg_q             | -18.099620726524677    |
| train_1/current_q         | -12.021342769498792    |
| train_1/fw_bonus          | -0.9967936009168625    |
| train_1/fw_loss           | 0.0016662647860357538  |
| train_1/mu_grads          | 0.014300839533098042   |
| train_1/mu_grads_std      | 0.20789674967527388    |
| train_1/mu_loss           | 12.495448591899969     |
| train_1/n_subgoals        | 2651.0                 |
| train_1/next_q            | -12.500748684372514    |
| train_1/q_grads           | 0.012831989955157042   |
| train_1/q_grads_std       | 0.24668190330266954    |
| train_1/q_loss            | 12.683696674830712     |
| train_1/reward            | -2.6162943450082823    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.004931640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.044511505092417955   |
| train_1/target_q          | -12.100462915062014    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 584.10. Rollout time: 363.03, Training time: 221.02
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 242818.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.1200869491986591   |
| test_1/avg_q              | -15.644036099278654   |
| test_1/n_subgoals         | 2975.0                |
| test_1/subgoal_succ_rate  | 0.8023529411764706    |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.41                  |
| train_0/avg_q             | -6.632864502598865    |
| train_0/current_q         | -3.0185137784621023   |
| train_0/fw_bonus          | -0.9982869058847428   |
| train_0/fw_loss           | 0.00046082667686278   |
| train_0/mu_grads          | -0.023217628011479974 |
| train_0/mu_grads_std      | 0.21921799406409265   |
| train_0/mu_loss           | 2.963805627625445     |
| train_0/next_q            | -2.8290660573170636   |
| train_0/q_grads           | 0.023541080951690673  |
| train_0/q_grads_std       | 0.16489666439592837   |
| train_0/q_loss            | 0.4699251888711897    |
| train_0/reward            | -0.6846669388625741   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0003662109375       |
| train_0/target_q          | -3.2416445123298177   |
| train_1/avg_q             | -16.682592838292905   |
| train_1/current_q         | -12.075813917591821   |
| train_1/fw_bonus          | -0.9962067529559135   |
| train_1/fw_loss           | 0.0018026546575129032 |
| train_1/mu_grads          | 0.013782530324533582  |
| train_1/mu_grads_std      | 0.2338482316583395    |
| train_1/mu_loss           | 12.436295579763149    |
| train_1/n_subgoals        | 2161.0                |
| train_1/next_q            | -12.4131876875705     |
| train_1/q_grads           | 0.007895965117495508  |
| train_1/q_grads_std       | 0.28173142224550246   |
| train_1/q_loss            | 9.40792621621783      |
| train_1/reward            | -2.567203544347649    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0059326171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.17630726515502082   |
| train_1/target_q          | -12.19571842486177    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 601.80. Rollout time: 375.70, Training time: 226.04
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 311615.0              |
| test/episodes             | 100.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.583439957934861    |
| test_1/avg_q              | -12.042561662797464   |
| test_1/n_subgoals         | 1730.0                |
| test_1/subgoal_succ_rate  | 0.6526011560693642    |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.4                   |
| train_0/avg_q             | -7.093518165862971    |
| train_0/current_q         | -5.010393573969566    |
| train_0/fw_bonus          | -0.9983441770076752   |
| train_0/fw_loss           | 0.0004455830981896725 |
| train_0/mu_grads          | -0.028410640452057122 |
| train_0/mu_grads_std      | 0.239157148078084     |
| train_0/mu_loss           | 4.779161447615654     |
| train_0/next_q            | -4.694769540245771    |
| train_0/q_grads           | 0.023977128928527235  |
| train_0/q_grads_std       | 0.17267600260674953   |
| train_0/q_loss            | 0.4878131576317058    |
| train_0/reward            | -0.695777452344555    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00126953125         |
| train_0/target_q          | -4.909810266143474    |
| train_1/avg_q             | -16.671388395447494   |
| train_1/current_q         | -12.858584021882052   |
| train_1/fw_bonus          | -0.9958311259746552   |
| train_1/fw_loss           | 0.001889957772800699  |
| train_1/mu_grads          | 0.010901204426772892  |
| train_1/mu_grads_std      | 0.2539670877158642    |
| train_1/mu_loss           | 13.364360027171333    |
| train_1/n_subgoals        | 2241.0                |
| train_1/next_q            | -13.30478619585666    |
| train_1/q_grads           | 0.00470390081172809   |
| train_1/q_grads_std       | 0.30949323028326037   |
| train_1/q_loss            | 9.54887873336722      |
| train_1/reward            | -2.478047137129397    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00634765625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2222222222222222    |
| train_1/target_q          | -12.937721702032656   |
-----------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 4
Time for epoch 4: 522.31. Rollout time: 299.32, Training time: 222.95
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 370159.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.0229060663262783    |
| test_1/avg_q              | -10.401591225940052    |
| test_1/n_subgoals         | 6302.0                 |
| test_1/subgoal_succ_rate  | 0.9360520469692161     |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -7.0985525128532       |
| train_0/current_q         | -5.2124730734460005    |
| train_0/fw_bonus          | -0.9982573688030243    |
| train_0/fw_loss           | 0.00046868395147612316 |
| train_0/mu_grads          | -0.02900946610607207   |
| train_0/mu_grads_std      | 0.25011244118213655    |
| train_0/mu_loss           | 4.928406132355116      |
| train_0/next_q            | -4.793882529876005     |
| train_0/q_grads           | 0.025379515159875153   |
| train_0/q_grads_std       | 0.18135982006788254    |
| train_0/q_loss            | 0.281972178179345      |
| train_0/reward            | -0.7018348495181271    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -5.137233910058856     |
| train_1/avg_q             | -15.450760350254688    |
| train_1/current_q         | -12.5211656953358      |
| train_1/fw_bonus          | -0.996375884115696     |
| train_1/fw_loss           | 0.001763345961808227   |
| train_1/mu_grads          | 0.007549346296582371   |
| train_1/mu_grads_std      | 0.27741539999842646    |
| train_1/mu_loss           | 12.860891725283679     |
| train_1/n_subgoals        | 2040.0                 |
| train_1/next_q            | -12.836106822097275    |
| train_1/q_grads           | 0.0015883216896327213  |
| train_1/q_grads_std       | 0.32948962450027464    |
| train_1/q_loss            | 10.734666872747647     |
| train_1/reward            | -2.373428687901833     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006103515625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3686274509803922     |
| train_1/target_q          | -12.602017779650629    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 5
Time for epoch 5: 550.73. Rollout time: 320.37, Training time: 230.30
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 430161.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.0857472691600307    |
| test_1/avg_q              | -11.271934170842087    |
| test_1/n_subgoals         | 2756.0                 |
| test_1/subgoal_succ_rate  | 0.7906386066763426     |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -8.628371260559994     |
| train_0/current_q         | -4.877384716571937     |
| train_0/fw_bonus          | -0.9984050005674362    |
| train_0/fw_loss           | 0.0004293988255085424  |
| train_0/mu_grads          | -0.034505173470824956  |
| train_0/mu_grads_std      | 0.26593582779169084    |
| train_0/mu_loss           | 4.793256677732647      |
| train_0/next_q            | -4.612531694127277     |
| train_0/q_grads           | 0.02627790397964418    |
| train_0/q_grads_std       | 0.19631904028356076    |
| train_0/q_loss            | 0.5058009037163727     |
| train_0/reward            | -0.7078959297155961    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00048828125          |
| train_0/target_q          | -4.9112948685073965    |
| train_1/avg_q             | -14.280844933717937    |
| train_1/current_q         | -13.29096800259731     |
| train_1/fw_bonus          | -0.9959456458687782    |
| train_1/fw_loss           | 0.001863342267461121   |
| train_1/mu_grads          | 0.005005027400329709   |
| train_1/mu_grads_std      | 0.28974617198109626    |
| train_1/mu_loss           | 13.744190422154295     |
| train_1/n_subgoals        | 2046.0                 |
| train_1/next_q            | -13.731733242822083    |
| train_1/q_grads           | 0.00029927357209089676 |
| train_1/q_grads_std       | 0.3552885837852955     |
| train_1/q_loss            | 8.977419265543542      |
| train_1/reward            | -2.3266109211454022    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3421309872922776     |
| train_1/target_q          | -13.348627477653702    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 6
Time for epoch 6: 557.99. Rollout time: 328.34, Training time: 229.60
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 491432.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.3020859684373935    |
| test_1/avg_q              | -14.679609788715878    |
| test_1/n_subgoals         | 10115.0                |
| test_1/subgoal_succ_rate  | 0.9766683143845774     |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -9.219205051037616     |
| train_0/current_q         | -5.92571475805482      |
| train_0/fw_bonus          | -0.9984415784478188    |
| train_0/fw_loss           | 0.00041966924036387356 |
| train_0/mu_grads          | -0.041330930404365064  |
| train_0/mu_grads_std      | 0.28156750053167345    |
| train_0/mu_loss           | 5.670996358687553      |
| train_0/next_q            | -5.513269942420343     |
| train_0/q_grads           | 0.026428043050691484   |
| train_0/q_grads_std       | 0.20931039452552797    |
| train_0/q_loss            | 0.29237589807412856    |
| train_0/reward            | -0.7170054129397613    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0009033203125        |
| train_0/target_q          | -5.894368518320879     |
| train_1/avg_q             | -15.391157319055027    |
| train_1/current_q         | -13.25518069558172     |
| train_1/fw_bonus          | -0.9954916536808014    |
| train_1/fw_loss           | 0.0019688550441060216  |
| train_1/mu_grads          | -0.0009302715741796419 |
| train_1/mu_grads_std      | 0.30355735048651694    |
| train_1/mu_loss           | 13.591590693854425     |
| train_1/n_subgoals        | 2070.0                 |
| train_1/next_q            | -13.512794583112921    |
| train_1/q_grads           | -0.003937286749714985  |
| train_1/q_grads_std       | 0.3739285208284855     |
| train_1/q_loss            | 6.5919650556577665     |
| train_1/reward            | -2.300880972064988     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006396484375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3309178743961353     |
| train_1/target_q          | -13.29749655205913     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 7
Time for epoch 7: 569.68. Rollout time: 329.26, Training time: 240.36
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 549872.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -0.34804012435759746   |
| test_1/avg_q              | -16.328312975417727    |
| test_1/n_subgoals         | 2778.0                 |
| test_1/subgoal_succ_rate  | 0.822174226061915      |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -10.586861290335918    |
| train_0/current_q         | -4.871742194077004     |
| train_0/fw_bonus          | -0.9984641671180725    |
| train_0/fw_loss           | 0.00041365585857420226 |
| train_0/mu_grads          | -0.04576813718304038   |
| train_0/mu_grads_std      | 0.2944451034069061     |
| train_0/mu_loss           | 4.604502130596144      |
| train_0/next_q            | -4.522624289278118     |
| train_0/q_grads           | 0.0247155059594661     |
| train_0/q_grads_std       | 0.2199176326394081     |
| train_0/q_loss            | 0.5240024782357724     |
| train_0/reward            | -0.7279424593561998    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.001025390625         |
| train_0/target_q          | -4.917048759666269     |
| train_1/avg_q             | -15.24912690361813     |
| train_1/current_q         | -12.205328947694555    |
| train_1/fw_bonus          | -0.9950733795762062    |
| train_1/fw_loss           | 0.0020660714770201595  |
| train_1/mu_grads          | -0.0035782629624009133 |
| train_1/mu_grads_std      | 0.31403534710407255    |
| train_1/mu_loss           | 12.26821417743425      |
| train_1/n_subgoals        | 2010.0                 |
| train_1/next_q            | -12.138828053859491    |
| train_1/q_grads           | -0.006563412258401513  |
| train_1/q_grads_std       | 0.38796250596642495    |
| train_1/q_loss            | 6.614806769220332      |
| train_1/reward            | -2.2203564802628533    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0071044921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3427860696517413     |
| train_1/target_q          | -12.236319361682519    |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 8
Time for epoch 8: 608.45. Rollout time: 351.36, Training time: 257.01
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 609645.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.8930184398888222   |
| test_1/avg_q              | -14.570334391613592   |
| test_1/n_subgoals         | 8559.0                |
| test_1/subgoal_succ_rate  | 0.9578221754877906    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -8.33460367486132     |
| train_0/current_q         | -6.010355080620995    |
| train_0/fw_bonus          | -0.9985280930995941   |
| train_0/fw_loss           | 0.000396645424189046  |
| train_0/mu_grads          | -0.051902530062943694 |
| train_0/mu_grads_std      | 0.31309539899230004   |
| train_0/mu_loss           | 5.6959703636032435    |
| train_0/next_q            | -5.547244539282639    |
| train_0/q_grads           | 0.025150424893945457  |
| train_0/q_grads_std       | 0.23387277126312256   |
| train_0/q_loss            | 0.24236487238874654   |
| train_0/reward            | -0.7348065861224313   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020751953125       |
| train_0/target_q          | -5.990403314998644    |
| train_1/avg_q             | -16.2709445122179     |
| train_1/current_q         | -11.808613983721715   |
| train_1/fw_bonus          | -0.9952304989099503   |
| train_1/fw_loss           | 0.002029554671025835  |
| train_1/mu_grads          | -0.00491279085399583  |
| train_1/mu_grads_std      | 0.3235893823206425    |
| train_1/mu_loss           | 11.71121184915317     |
| train_1/n_subgoals        | 1966.0                |
| train_1/next_q            | -11.539066688091921   |
| train_1/q_grads           | -0.009532510372810065 |
| train_1/q_grads_std       | 0.3975195653736591    |
| train_1/q_loss            | 6.558556712917449     |
| train_1/reward            | -2.1293007881096857   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00625               |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.32044760935910477   |
| train_1/target_q          | -11.806722515889843   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 9
Time for epoch 9: 503.85. Rollout time: 298.55, Training time: 205.22
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 672403.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.7525356262148983    |
| test_1/avg_q              | -14.639999827216537    |
| test_1/n_subgoals         | 688.0                  |
| test_1/subgoal_succ_rate  | 0.0188953488372093     |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -10.149105323235023    |
| train_0/current_q         | -5.660575827700646     |
| train_0/fw_bonus          | -0.9985619276762009    |
| train_0/fw_loss           | 0.00038764231649111023 |
| train_0/mu_grads          | -0.05756311397999525   |
| train_0/mu_grads_std      | 0.3297228701412678     |
| train_0/mu_loss           | 5.372342606002282      |
| train_0/next_q            | -5.20731358858396      |
| train_0/q_grads           | 0.023310278449207543   |
| train_0/q_grads_std       | 0.24062741212546826    |
| train_0/q_loss            | 0.3756573168270938     |
| train_0/reward            | -0.7438421445363929    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00283203125          |
| train_0/target_q          | -5.616741741070529     |
| train_1/avg_q             | -15.717086185983137    |
| train_1/current_q         | -12.49249985274172     |
| train_1/fw_bonus          | -0.9959053337574005    |
| train_1/fw_loss           | 0.001872708901646547   |
| train_1/mu_grads          | -0.006973247020505368  |
| train_1/mu_grads_std      | 0.33595241904258727    |
| train_1/mu_loss           | 12.497961607817864     |
| train_1/n_subgoals        | 1978.0                 |
| train_1/next_q            | -12.358916577799329    |
| train_1/q_grads           | -0.01114028780721128   |
| train_1/q_grads_std       | 0.4083789087831974     |
| train_1/q_loss            | 6.006530612656325      |
| train_1/reward            | -2.1265764326242786    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070068359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2537917087967644     |
| train_1/target_q          | -12.5257114774819      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 10
Time for epoch 10: 21999.81. Rollout time: 20525.21, Training time: 1474.37
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 733935.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5655457364585703    |
| test_1/avg_q              | -8.461763648139206     |
| test_1/n_subgoals         | 721.0                  |
| test_1/subgoal_succ_rate  | 0.0651872399445215     |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -9.273496543241018     |
| train_0/current_q         | -5.354742964104758     |
| train_0/fw_bonus          | -0.9986872568726539    |
| train_0/fw_loss           | 0.00035429622657829897 |
| train_0/mu_grads          | -0.06087735388427973   |
| train_0/mu_grads_std      | 0.34518384337425234    |
| train_0/mu_loss           | 5.026521496775508      |
| train_0/next_q            | -4.921651187916636     |
| train_0/q_grads           | 0.023602012265473604   |
| train_0/q_grads_std       | 0.24974247738718985    |
| train_0/q_loss            | 0.36679140624974743    |
| train_0/reward            | -0.7381422736438253    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0046142578125        |
| train_0/target_q          | -5.33210796289246      |
| train_1/avg_q             | -16.299694460939595    |
| train_1/current_q         | -11.934693504137826    |
| train_1/fw_bonus          | -0.9961698383092881    |
| train_1/fw_loss           | 0.0018112372985342518  |
| train_1/mu_grads          | -0.010423975554294885  |
| train_1/mu_grads_std      | 0.3531807713210583     |
| train_1/mu_loss           | 11.71485767130142      |
| train_1/n_subgoals        | 1916.0                 |
| train_1/next_q            | -11.65069650935072     |
| train_1/q_grads           | -0.01346944395918399   |
| train_1/q_grads_std       | 0.42015518322587014    |
| train_1/q_loss            | 6.100473226547099      |
| train_1/reward            | -2.131201880066874     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007666015625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24843423799582465    |
| train_1/target_q          | -11.935101278636974    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 11
Time for epoch 11: 535.03. Rollout time: 326.29, Training time: 208.68
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 801655.0               |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -0.9633985627827724    |
| test_1/avg_q              | -14.205049911395422    |
| test_1/n_subgoals         | 746.0                  |
| test_1/subgoal_succ_rate  | 0.19973190348525469    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.48                   |
| train_0/avg_q             | -6.95336107844472      |
| train_0/current_q         | -4.629784302752877     |
| train_0/fw_bonus          | -0.9987782940268517    |
| train_0/fw_loss           | 0.00033007494785124435 |
| train_0/mu_grads          | -0.06737266033887863   |
| train_0/mu_grads_std      | 0.3613386869430542     |
| train_0/mu_loss           | 4.468721463538641      |
| train_0/next_q            | -4.316645482957884     |
| train_0/q_grads           | 0.02468637186102569    |
| train_0/q_grads_std       | 0.25707644000649454    |
| train_0/q_loss            | 0.8078056081095625     |
| train_0/reward            | -0.7430356361612211    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0160888671875        |
| train_0/target_q          | -4.59333076788329      |
| train_1/avg_q             | -13.32598467293682     |
| train_1/current_q         | -7.157665085761105     |
| train_1/fw_bonus          | -0.9961247652769089    |
| train_1/fw_loss           | 0.0018217110016848892  |
| train_1/mu_grads          | -0.011770044034346939  |
| train_1/mu_grads_std      | 0.36416357904672625    |
| train_1/mu_loss           | 6.555439788177722      |
| train_1/n_subgoals        | 2168.0                 |
| train_1/next_q            | -6.455904741470692     |
| train_1/q_grads           | -0.02166834962554276   |
| train_1/q_grads_std       | 0.4291258752346039     |
| train_1/q_loss            | 4.2433724470264345     |
| train_1/reward            | -2.163820009398478     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0073974609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19280442804428044    |
| train_1/target_q          | -7.362890571671817     |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 12
Time for epoch 12: 5746.39. Rollout time: 3313.46, Training time: 2432.61
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 857809.0              |
| test/episodes             | 325.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.7886429941422368   |
| test_1/avg_q              | -13.927743338103593   |
| test_1/n_subgoals         | 677.0                 |
| test_1/subgoal_succ_rate  | 0.011816838995568686  |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.74                  |
| train_0/avg_q             | -9.874920126164648    |
| train_0/current_q         | -6.123786119133618    |
| train_0/fw_bonus          | -0.9987865820527076   |
| train_0/fw_loss           | 0.0003278687683632597 |
| train_0/mu_grads          | -0.07166194580495358  |
| train_0/mu_grads_std      | 0.3740641064941883    |
| train_0/mu_loss           | 5.917446604233801     |
| train_0/next_q            | -5.717221753962167    |
| train_0/q_grads           | 0.025184379937127233  |
| train_0/q_grads_std       | 0.2683047793805599    |
| train_0/q_loss            | 0.40017147090373595   |
| train_0/reward            | -0.7400347795417475   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0185302734375       |
| train_0/target_q          | -6.0767289144981405   |
| train_1/avg_q             | -15.306975701624939   |
| train_1/current_q         | -11.656015480965342   |
| train_1/fw_bonus          | -0.9967702507972718   |
| train_1/fw_loss           | 0.0016716896730940788 |
| train_1/mu_grads          | -0.015352790872566403 |
| train_1/mu_grads_std      | 0.37706971615552903   |
| train_1/mu_loss           | 11.53863311558411     |
| train_1/n_subgoals        | 1687.0                |
| train_1/next_q            | -11.345374989894768   |
| train_1/q_grads           | -0.024651106726378203 |
| train_1/q_grads_std       | 0.43683034628629686   |
| train_1/q_loss            | 7.417304099320603     |
| train_1/reward            | -2.191904965224603    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00732421875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.23532898636633076   |
| train_1/target_q          | -11.721684262288719   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 13
Time for epoch 13: 8268.72. Rollout time: 1406.31, Training time: 6862.19
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 922116.0               |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -0.5722529331857439    |
| test_1/avg_q              | -18.47806471495788     |
| test_1/n_subgoals         | 627.0                  |
| test_1/subgoal_succ_rate  | 0.03668261562998405    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -10.3861015278882      |
| train_0/current_q         | -4.400393346610168     |
| train_0/fw_bonus          | -0.9988020792603493    |
| train_0/fw_loss           | 0.00032374669463024474 |
| train_0/mu_grads          | -0.0755196800455451    |
| train_0/mu_grads_std      | 0.39268123507499697    |
| train_0/mu_loss           | 4.140679296775081      |
| train_0/next_q            | -4.042500813073197     |
| train_0/q_grads           | 0.024066254124045373   |
| train_0/q_grads_std       | 0.27804185897111894    |
| train_0/q_loss            | 0.48565562224286385    |
| train_0/reward            | -0.7421626756695332    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0113037109375        |
| train_0/target_q          | -4.496112019732879     |
| train_1/avg_q             | -16.47232081578617     |
| train_1/current_q         | -11.955041025368203    |
| train_1/fw_bonus          | -0.9964572176337242    |
| train_1/fw_loss           | 0.0017444436904042958  |
| train_1/mu_grads          | -0.017387397540733217  |
| train_1/mu_grads_std      | 0.3888215012848377     |
| train_1/mu_loss           | 11.946097522529232     |
| train_1/n_subgoals        | 2059.0                 |
| train_1/next_q            | -11.75708276797707     |
| train_1/q_grads           | -0.026486084749922156  |
| train_1/q_grads_std       | 0.438948679715395      |
| train_1/q_loss            | 5.605879175856282      |
| train_1/reward            | -2.191259080134478     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0070068359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21321029626032054    |
| train_1/target_q          | -12.005433399396038    |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 14
Time for epoch 14: 662.59. Rollout time: 441.22, Training time: 221.30
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 992708.0               |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.638436350496076     |
| test_1/avg_q              | -17.387739287034563    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -6.798916848304611     |
| train_0/current_q         | -3.722116013174668     |
| train_0/fw_bonus          | -0.9988444909453392    |
| train_0/fw_loss           | 0.00031245678874256553 |
| train_0/mu_grads          | -0.07655658908188342   |
| train_0/mu_grads_std      | 0.40674441754817964    |
| train_0/mu_loss           | 3.464199642743394      |
| train_0/next_q            | -3.318883653400543     |
| train_0/q_grads           | 0.024865916557610036   |
| train_0/q_grads_std       | 0.2841894321143627     |
| train_0/q_loss            | 0.43767524412136416    |
| train_0/reward            | -0.7360392499344016    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.019580078125         |
| train_0/target_q          | -3.77215810641176      |
| train_1/avg_q             | -16.864202574153484    |
| train_1/current_q         | -11.930687860660587    |
| train_1/fw_bonus          | -0.9963247060775757    |
| train_1/fw_loss           | 0.0017752426356310025  |
| train_1/mu_grads          | -0.019182297959923746  |
| train_1/mu_grads_std      | 0.3971354529261589     |
| train_1/mu_loss           | 11.989051010873983     |
| train_1/n_subgoals        | 2133.0                 |
| train_1/next_q            | -11.792044020464825    |
| train_1/q_grads           | -0.02809163713827729   |
| train_1/q_grads_std       | 0.44871280416846276    |
| train_1/q_loss            | 5.614632245742018      |
| train_1/reward            | -2.2350613994716695    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075439453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14064697609001406    |
| train_1/target_q          | -12.01607681144074     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 15
Time for epoch 15: 561.55. Rollout time: 346.27, Training time: 215.22
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1057773.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.238048675235628    |
| test_1/avg_q              | -14.262202784626002   |
| test_1/n_subgoals         | 681.0                 |
| test_1/subgoal_succ_rate  | 0.00881057268722467   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.58                  |
| train_0/avg_q             | -7.770072206719855    |
| train_0/current_q         | -4.917653563072931    |
| train_0/fw_bonus          | -0.9988994479179383   |
| train_0/fw_loss           | 0.0002978337524837116 |
| train_0/mu_grads          | -0.07974143736064435  |
| train_0/mu_grads_std      | 0.42056881338357927   |
| train_0/mu_loss           | 4.713916235155726     |
| train_0/next_q            | -4.542171820801224    |
| train_0/q_grads           | 0.02710800589993596   |
| train_0/q_grads_std       | 0.292263999581337     |
| train_0/q_loss            | 0.4739045984939413    |
| train_0/reward            | -0.7377009383657424   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.028466796875        |
| train_0/target_q          | -4.899574442492567    |
| train_1/avg_q             | -16.96788186421008    |
| train_1/current_q         | -12.697858674608034   |
| train_1/fw_bonus          | -0.9963115483522416   |
| train_1/fw_loss           | 0.0017782986484235152 |
| train_1/mu_grads          | -0.021164359431713818 |
| train_1/mu_grads_std      | 0.410126268863678     |
| train_1/mu_loss           | 12.749624295968406    |
| train_1/n_subgoals        | 1948.0                |
| train_1/next_q            | -12.575659271647703   |
| train_1/q_grads           | -0.02834267681464553  |
| train_1/q_grads_std       | 0.45776784867048265   |
| train_1/q_loss            | 5.511954738394888     |
| train_1/reward            | -2.291344733198275    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0075439453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.15349075975359344   |
| train_1/target_q          | -12.731697178952317   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 16
Time for epoch 16: 584.54. Rollout time: 340.63, Training time: 243.81
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1113164.0              |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.9219907650960535    |
| test_1/avg_q              | -15.83469092786707     |
| test_1/n_subgoals         | 5635.0                 |
| test_1/subgoal_succ_rate  | 0.9524401064773735     |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -11.028532635664826    |
| train_0/current_q         | -5.673429417418494     |
| train_0/fw_bonus          | -0.9988675162196159    |
| train_0/fw_loss           | 0.00030633313726866616 |
| train_0/mu_grads          | -0.08215261530131102   |
| train_0/mu_grads_std      | 0.43276364356279373    |
| train_0/mu_loss           | 5.445723675774602      |
| train_0/next_q            | -5.2712406078804355    |
| train_0/q_grads           | 0.028305363934487106   |
| train_0/q_grads_std       | 0.30311196148395536    |
| train_0/q_loss            | 0.3662140503262342     |
| train_0/reward            | -0.7387732749266434    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0255615234375        |
| train_0/target_q          | -5.632181692661442     |
| train_1/avg_q             | -16.7197241741493      |
| train_1/current_q         | -13.003503027031348    |
| train_1/fw_bonus          | -0.9967993274331093    |
| train_1/fw_loss           | 0.0016649319790303708  |
| train_1/mu_grads          | -0.02430381756275892   |
| train_1/mu_grads_std      | 0.4204513534903526     |
| train_1/mu_loss           | 13.182975023968709     |
| train_1/n_subgoals        | 1741.0                 |
| train_1/next_q            | -13.075562595094613    |
| train_1/q_grads           | -0.03139919014647603   |
| train_1/q_grads_std       | 0.471105045825243      |
| train_1/q_loss            | 5.5312251670200245     |
| train_1/reward            | -2.3115716575757688    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007470703125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27627800114876505    |
| train_1/target_q          | -13.103826068207102    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 17
Time for epoch 17: 588.86. Rollout time: 339.26, Training time: 249.51
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1167186.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.12                  |
| test_0/avg_q              | -1.0814357411106856   |
| test_1/avg_q              | -18.071945315624824   |
| test_1/n_subgoals         | 1152.0                |
| test_1/subgoal_succ_rate  | 0.5060763888888888    |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.67                  |
| train_0/avg_q             | -11.802672266250475   |
| train_0/current_q         | -5.323325892610839    |
| train_0/fw_bonus          | -0.9989171847701073   |
| train_0/fw_loss           | 0.0002931183400505688 |
| train_0/mu_grads          | -0.08886001855134965  |
| train_0/mu_grads_std      | 0.4453945726156235    |
| train_0/mu_loss           | 5.079555545127528     |
| train_0/next_q            | -4.959657989840445    |
| train_0/q_grads           | 0.028066412033513188  |
| train_0/q_grads_std       | 0.31153549030423167   |
| train_0/q_loss            | 0.4790866329278261    |
| train_0/reward            | -0.7432717749052244   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0362548828125       |
| train_0/target_q          | -5.329090986628498    |
| train_1/avg_q             | -16.296717186430758   |
| train_1/current_q         | -12.742081432543396   |
| train_1/fw_bonus          | -0.996407388150692    |
| train_1/fw_loss           | 0.0017560234089614823 |
| train_1/mu_grads          | -0.027307241270318628 |
| train_1/mu_grads_std      | 0.42851041853427885   |
| train_1/mu_loss           | 12.8511241581126      |
| train_1/n_subgoals        | 1873.0                |
| train_1/next_q            | -12.720910233497252   |
| train_1/q_grads           | -0.0321971096098423   |
| train_1/q_grads_std       | 0.4838686116039753    |
| train_1/q_loss            | 6.0524447123094145    |
| train_1/reward            | -2.248412149612341    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007470703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.399893219434063     |
| train_1/target_q          | -12.772501489463234   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 18
Time for epoch 18: 673.72. Rollout time: 405.14, Training time: 268.46
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1226783.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -1.4077785699757372    |
| test_1/avg_q              | -15.736996669793797    |
| test_1/n_subgoals         | 4482.0                 |
| test_1/subgoal_succ_rate  | 0.9016064257028112     |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.54                   |
| train_0/avg_q             | -12.318236071080834    |
| train_0/current_q         | -5.373015174547166     |
| train_0/fw_bonus          | -0.9988895609974862    |
| train_0/fw_loss           | 0.00030046448737266476 |
| train_0/mu_grads          | -0.09236223492771387   |
| train_0/mu_grads_std      | 0.456646878272295      |
| train_0/mu_loss           | 5.1662021678123295     |
| train_0/next_q            | -5.017454852296323     |
| train_0/q_grads           | 0.030085285613313317   |
| train_0/q_grads_std       | 0.3199994668364525     |
| train_0/q_loss            | 0.45984575640349706    |
| train_0/reward            | -0.7403168748427561    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0413818359375        |
| train_0/target_q          | -5.395700501564235     |
| train_1/avg_q             | -16.540798603922998    |
| train_1/current_q         | -12.384410662872204    |
| train_1/fw_bonus          | -0.9965851873159408    |
| train_1/fw_loss           | 0.0017147007718449458  |
| train_1/mu_grads          | -0.029009412229061126  |
| train_1/mu_grads_std      | 0.43654054775834084    |
| train_1/mu_loss           | 12.400700551814282     |
| train_1/n_subgoals        | 2010.0                 |
| train_1/next_q            | -12.27365072458351     |
| train_1/q_grads           | -0.03393400767818093   |
| train_1/q_grads_std       | 0.4909796372056007     |
| train_1/q_loss            | 5.803248042144995      |
| train_1/reward            | -2.2984810130899858    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076171875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3164179104477612     |
| train_1/target_q          | -12.435363149908515    |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 19
Time for epoch 19: 699.18. Rollout time: 431.77, Training time: 267.28
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1280214.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.1033114416105356    |
| test_1/avg_q              | -15.651569393729922    |
| test_1/n_subgoals         | 3530.0                 |
| test_1/subgoal_succ_rate  | 0.8943342776203966     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -13.78525485058068     |
| train_0/current_q         | -5.796232054570072     |
| train_0/fw_bonus          | -0.9988685503602028    |
| train_0/fw_loss           | 0.00030606038453697695 |
| train_0/mu_grads          | -0.09422506149858237   |
| train_0/mu_grads_std      | 0.46703421548008917    |
| train_0/mu_loss           | 5.540301217904356      |
| train_0/next_q            | -5.416342611883265     |
| train_0/q_grads           | 0.030955473706126214   |
| train_0/q_grads_std       | 0.32719545513391496    |
| train_0/q_loss            | 0.4598315787668265     |
| train_0/reward            | -0.7468118612840045    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0384765625           |
| train_0/target_q          | -5.749759397545018     |
| train_1/avg_q             | -15.246193676590352    |
| train_1/current_q         | -11.766259638487265    |
| train_1/fw_bonus          | -0.9969662949442863    |
| train_1/fw_loss           | 0.0016261225624475627  |
| train_1/mu_grads          | -0.02966161952354014   |
| train_1/mu_grads_std      | 0.4431817792356014     |
| train_1/mu_loss           | 11.76055666060976      |
| train_1/n_subgoals        | 2021.0                 |
| train_1/next_q            | -11.602475859807592    |
| train_1/q_grads           | -0.03499149959534407   |
| train_1/q_grads_std       | 0.4982982836663723     |
| train_1/q_loss            | 5.415651324543835      |
| train_1/reward            | -2.2499068589822855    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006689453125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4334487877288471     |
| train_1/target_q          | -11.818787145811157    |
------------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 20
Time for epoch 20: 609.99. Rollout time: 349.49, Training time: 260.40
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1327141.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.7012731320807326   |
| test_1/avg_q              | -15.725365894456678   |
| test_1/n_subgoals         | 1730.0                |
| test_1/subgoal_succ_rate  | 0.8445086705202313    |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -12.63437032004629    |
| train_0/current_q         | -6.493660339892145    |
| train_0/fw_bonus          | -0.9989170029759407   |
| train_0/fw_loss           | 0.0002931641323812073 |
| train_0/mu_grads          | -0.09612769298255444  |
| train_0/mu_grads_std      | 0.4791359156370163    |
| train_0/mu_loss           | 6.270050418482592     |
| train_0/next_q            | -6.104776729335297    |
| train_0/q_grads           | 0.031652787886559966  |
| train_0/q_grads_std       | 0.3375467650592327    |
| train_0/q_loss            | 0.39273403449174243   |
| train_0/reward            | -0.7509438510602194   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0421142578125       |
| train_0/target_q          | -6.4506355608011345   |
| train_1/avg_q             | -15.404923393223145   |
| train_1/current_q         | -11.908991666241361   |
| train_1/fw_bonus          | -0.9966483905911445   |
| train_1/fw_loss           | 0.001700013704248704  |
| train_1/mu_grads          | -0.03256960567086935  |
| train_1/mu_grads_std      | 0.453384718298912     |
| train_1/mu_loss           | 12.008692486958216    |
| train_1/n_subgoals        | 1956.0                |
| train_1/next_q            | -11.856759636083073   |
| train_1/q_grads           | -0.036018391326069835 |
| train_1/q_grads_std       | 0.5121105879545211    |
| train_1/q_loss            | 5.847676227124284     |
| train_1/reward            | -2.1201703951250237   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00771484375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.44683026584867075   |
| train_1/target_q          | -11.983591750297455   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_20.pkl ...
New best value for test/success_rate: 0.48. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.24
Training epoch 21
Time for epoch 21: 757.88. Rollout time: 407.90, Training time: 349.84
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 1367979.0              |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.1806894942880877    |
| test_1/avg_q              | -16.354054096684862    |
| test_1/n_subgoals         | 8029.0                 |
| test_1/subgoal_succ_rate  | 0.990409764603313      |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.76                   |
| train_0/avg_q             | -14.696470569169621    |
| train_0/current_q         | -6.591161439374636     |
| train_0/fw_bonus          | -0.998929412662983     |
| train_0/fw_loss           | 0.00028986024190089663 |
| train_0/mu_grads          | -0.09806895796209573   |
| train_0/mu_grads_std      | 0.48901706337928774    |
| train_0/mu_loss           | 6.403397111303818      |
| train_0/next_q            | -6.230389030891203     |
| train_0/q_grads           | 0.03230342892929912    |
| train_0/q_grads_std       | 0.34644423574209215    |
| train_0/q_loss            | 0.5130318927503142     |
| train_0/reward            | -0.7533822577741376    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0451171875           |
| train_0/target_q          | -6.526280191535328     |
| train_1/avg_q             | -14.486430127759604    |
| train_1/current_q         | -11.533242670197364    |
| train_1/fw_bonus          | -0.9973607495427131    |
| train_1/fw_loss           | 0.001534447236917913   |
| train_1/mu_grads          | -0.034079066943377256  |
| train_1/mu_grads_std      | 0.46260870397090914    |
| train_1/mu_loss           | 11.559474373618057     |
| train_1/n_subgoals        | 1557.0                 |
| train_1/next_q            | -11.438874641333953    |
| train_1/q_grads           | -0.03637876929715276   |
| train_1/q_grads_std       | 0.526654577255249      |
| train_1/q_loss            | 5.313433197423279      |
| train_1/reward            | -2.05787290143453      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076904296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4598587026332691     |
| train_1/target_q          | -11.587079668663709    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.29
Training epoch 22
Time for epoch 22: 1024.21. Rollout time: 636.55, Training time: 387.51
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 1418727.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -1.144658064138819    |
| test_1/avg_q              | -11.959743241847345   |
| test_1/n_subgoals         | 634.0                 |
| test_1/subgoal_succ_rate  | 0.26498422712933756   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -10.38944285184305    |
| train_0/current_q         | -4.776254552134652    |
| train_0/fw_bonus          | -0.9989099979400635   |
| train_0/fw_loss           | 0.0002950309881271096 |
| train_0/mu_grads          | -0.09923591259866953  |
| train_0/mu_grads_std      | 0.49910300597548485   |
| train_0/mu_loss           | 4.601333662003535     |
| train_0/next_q            | -4.48324949647452     |
| train_0/q_grads           | 0.033685298170894384  |
| train_0/q_grads_std       | 0.3542126268148422    |
| train_0/q_loss            | 0.7286372406304918    |
| train_0/reward            | -0.7589621163944684   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04453125            |
| train_0/target_q          | -4.864003282091976    |
| train_1/avg_q             | -14.285931525661988   |
| train_1/current_q         | -11.233761486964521   |
| train_1/fw_bonus          | -0.9968790069222451   |
| train_1/fw_loss           | 0.0016464108426589518 |
| train_1/mu_grads          | -0.03466215431690216  |
| train_1/mu_grads_std      | 0.4699620954692364    |
| train_1/mu_loss           | 11.228086040504916    |
| train_1/n_subgoals        | 1847.0                |
| train_1/next_q            | -11.160550995959166   |
| train_1/q_grads           | -0.03638294460251927  |
| train_1/q_grads_std       | 0.5423092007637024    |
| train_1/q_loss            | 4.930525601558327     |
| train_1/reward            | -1.986524441110305    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0074951171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3486735246345425    |
| train_1/target_q          | -11.304098317859246   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.33
Training epoch 23
Time for epoch 23: 1087.90. Rollout time: 623.28, Training time: 464.42
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 1462120.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.2800480500900868    |
| test_1/avg_q              | -9.62158554604178      |
| test_1/n_subgoals         | 4491.0                 |
| test_1/subgoal_succ_rate  | 0.9585838343353373     |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.78                   |
| train_0/avg_q             | -10.821557319194486    |
| train_0/current_q         | -6.166539060322431     |
| train_0/fw_bonus          | -0.9988955557346344    |
| train_0/fw_loss           | 0.00029887441669416146 |
| train_0/mu_grads          | -0.10236134454607963   |
| train_0/mu_grads_std      | 0.5069031268358231     |
| train_0/mu_loss           | 5.95577580004194       |
| train_0/next_q            | -5.800109484002388     |
| train_0/q_grads           | 0.03512497367337346    |
| train_0/q_grads_std       | 0.36426248773932457    |
| train_0/q_loss            | 0.526139311056968      |
| train_0/reward            | -0.7597824799911905    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0439208984375        |
| train_0/target_q          | -6.141566310042874     |
| train_1/avg_q             | -14.037293252935433    |
| train_1/current_q         | -11.185326491094163    |
| train_1/fw_bonus          | -0.9972116902470589    |
| train_1/fw_loss           | 0.0015690915344748646  |
| train_1/mu_grads          | -0.03578835129737854   |
| train_1/mu_grads_std      | 0.4761858269572258     |
| train_1/mu_loss           | 11.119583331016923     |
| train_1/n_subgoals        | 1534.0                 |
| train_1/next_q            | -11.052280207384635    |
| train_1/q_grads           | -0.036265643499791625  |
| train_1/q_grads_std       | 0.5558637052774429     |
| train_1/q_loss            | 4.9520655662226805     |
| train_1/reward            | -1.9845018955278646    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0077392578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.34028683181225555    |
| train_1/target_q          | -11.273210243536536    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 24
Time for epoch 24: 711.39. Rollout time: 371.05, Training time: 340.20
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 1500040.0             |
| test/episodes             | 625.0                 |
| test/success_rate         | 0.36                  |
| test_0/avg_q              | -1.8239125003679637   |
| test_1/avg_q              | -9.46425770618846     |
| test_1/n_subgoals         | 889.0                 |
| test_1/subgoal_succ_rate  | 0.4983127109111361    |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.83                  |
| train_0/avg_q             | -11.786860531167926   |
| train_0/current_q         | -5.65694902626595     |
| train_0/fw_bonus          | -0.9989160731434822   |
| train_0/fw_loss           | 0.0002934127678599907 |
| train_0/mu_grads          | -0.10522018261253833  |
| train_0/mu_grads_std      | 0.5145112589001656    |
| train_0/mu_loss           | 5.479252835661667     |
| train_0/next_q            | -5.319308655754465    |
| train_0/q_grads           | 0.0346797869540751    |
| train_0/q_grads_std       | 0.37128067910671236   |
| train_0/q_loss            | 0.6329331447661348    |
| train_0/reward            | -0.7611975235166029   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.04091796875         |
| train_0/target_q          | -5.631145369632515    |
| train_1/avg_q             | -11.72837500097648    |
| train_1/current_q         | -10.731791285823125   |
| train_1/fw_bonus          | -0.9968276128172875   |
| train_1/fw_loss           | 0.0016583563323365525 |
| train_1/mu_grads          | -0.03779756501317024  |
| train_1/mu_grads_std      | 0.4848338283598423    |
| train_1/mu_loss           | 10.652476824074842    |
| train_1/n_subgoals        | 1383.0                |
| train_1/next_q            | -10.59372597782441    |
| train_1/q_grads           | -0.038314147386699915 |
| train_1/q_grads_std       | 0.5679317027330398    |
| train_1/q_loss            | 4.872411898691277     |
| train_1/reward            | -1.9082340033950458   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007421875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.47216196673897326   |
| train_1/target_q          | -10.817550821163554   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.35
Training epoch 25
Time for epoch 25: 808.80. Rollout time: 424.41, Training time: 384.21
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 25                    |
| policy/steps              | 1540951.0             |
| test/episodes             | 650.0                 |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -1.2326384139233981   |
| test_1/avg_q              | -8.099632565327575    |
| test_1/n_subgoals         | 5706.0                |
| test_1/subgoal_succ_rate  | 0.9900105152471083    |
| train/episodes            | 2600.0                |
| train/success_rate        | 0.76                  |
| train_0/avg_q             | -10.600773199756095   |
| train_0/current_q         | -6.384677459358375    |
| train_0/fw_bonus          | -0.9989031195640564   |
| train_0/fw_loss           | 0.0002968562333990121 |
| train_0/mu_grads          | -0.10783749837428332  |
| train_0/mu_grads_std      | 0.5221437618136406    |
| train_0/mu_loss           | 6.163142355352725     |
| train_0/next_q            | -6.003711861385382    |
| train_0/q_grads           | 0.03700228668749332   |
| train_0/q_grads_std       | 0.3816773422062397    |
| train_0/q_loss            | 0.5863445221008765    |
| train_0/reward            | -0.7726017590463016   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0491455078125       |
| train_0/target_q          | -6.339104419422178    |
| train_1/avg_q             | -11.885683184961852   |
| train_1/current_q         | -10.748946014910716   |
| train_1/fw_bonus          | -0.9971962302923203   |
| train_1/fw_loss           | 0.0015726851561339572 |
| train_1/mu_grads          | -0.03919364251196385  |
| train_1/mu_grads_std      | 0.4906232960522175    |
| train_1/mu_loss           | 10.636475995593477    |
| train_1/n_subgoals        | 1440.0                |
| train_1/next_q            | -10.572564759133702   |
| train_1/q_grads           | -0.04057695800438523  |
| train_1/q_grads_std       | 0.5793141946196556    |
| train_1/q_loss            | 4.972078502579537     |
| train_1/reward            | -1.8918832835784998   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0077880859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.39166666666666666   |
| train_1/target_q          | -10.822923181646313   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.38
Training epoch 26
Time for epoch 26: 867.64. Rollout time: 452.70, Training time: 414.75
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1574177.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.64                   |
| test_0/avg_q              | -0.9157709587300165    |
| test_1/avg_q              | -10.756025523464789    |
| test_1/n_subgoals         | 3399.0                 |
| test_1/subgoal_succ_rate  | 0.9911738746690203     |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -12.504538289698734    |
| train_0/current_q         | -6.854134048516608     |
| train_0/fw_bonus          | -0.9988823369145393    |
| train_0/fw_loss           | 0.00030239060943131334 |
| train_0/mu_grads          | -0.10943022128194571   |
| train_0/mu_grads_std      | 0.5302075415849685     |
| train_0/mu_loss           | 6.604036512933615      |
| train_0/next_q            | -6.4387627248337065    |
| train_0/q_grads           | 0.03742204047739506    |
| train_0/q_grads_std       | 0.39252000749111177    |
| train_0/q_loss            | 0.4971212729696443     |
| train_0/reward            | -0.7748487564171228    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0529541015625        |
| train_0/target_q          | -6.799390917372236     |
| train_1/avg_q             | -11.085066916689943    |
| train_1/current_q         | -10.443671356373958    |
| train_1/fw_bonus          | -0.9965569242835045    |
| train_1/fw_loss           | 0.0017212710779858753  |
| train_1/mu_grads          | -0.040757544338703156  |
| train_1/mu_grads_std      | 0.4942174591124058     |
| train_1/mu_loss           | 10.26677648080863      |
| train_1/n_subgoals        | 1403.0                 |
| train_1/next_q            | -10.225416083359779    |
| train_1/q_grads           | -0.04204742275178432   |
| train_1/q_grads_std       | 0.5933131411671638     |
| train_1/q_loss            | 5.063233637720823      |
| train_1/reward            | -1.8874570997435511    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080322265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4953670705630791     |
| train_1/target_q          | -10.534209344608731    |
------------------------------------------------------
New best value for test/success_rate: 0.64. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.45999999999999996
Training epoch 27
Time for epoch 27: 941.26. Rollout time: 528.54, Training time: 412.57
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 27                    |
| policy/steps              | 1617779.0             |
| test/episodes             | 700.0                 |
| test/success_rate         | 0.28                  |
| test_0/avg_q              | -1.4984732477608966   |
| test_1/avg_q              | -10.21285846018624    |
| test_1/n_subgoals         | 6517.0                |
| test_1/subgoal_succ_rate  | 0.9665490256252877    |
| train/episodes            | 2800.0                |
| train/success_rate        | 0.74                  |
| train_0/avg_q             | -12.20272799979421    |
| train_0/current_q         | -6.487542267339987    |
| train_0/fw_bonus          | -0.9988826006650925   |
| train_0/fw_loss           | 0.0003023162182216765 |
| train_0/mu_grads          | -0.1124873636290431   |
| train_0/mu_grads_std      | 0.5373213738203049    |
| train_0/mu_loss           | 6.263832217765467     |
| train_0/next_q            | -6.059861367664108    |
| train_0/q_grads           | 0.03772060014307499   |
| train_0/q_grads_std       | 0.4012462720274925    |
| train_0/q_loss            | 0.44271155621720465   |
| train_0/reward            | -0.7751234843970451   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.031787109375        |
| train_0/target_q          | -6.4406035676699105   |
| train_1/avg_q             | -11.501324810874266   |
| train_1/current_q         | -9.504240011418933    |
| train_1/fw_bonus          | -0.9969081670045853   |
| train_1/fw_loss           | 0.0016396347840782256 |
| train_1/mu_grads          | -0.042295395582914355 |
| train_1/mu_grads_std      | 0.49943997263908385   |
| train_1/mu_loss           | 9.238057548237418     |
| train_1/n_subgoals        | 1640.0                |
| train_1/next_q            | -9.160174533413246    |
| train_1/q_grads           | -0.04279984766617417  |
| train_1/q_grads_std       | 0.6028191477060318    |
| train_1/q_loss            | 4.677828723500747     |
| train_1/reward            | -1.850520985960611    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.008056640625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4847560975609756    |
| train_1/target_q          | -9.542541253645021    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.43
Training epoch 28
Time for epoch 28: 698.87. Rollout time: 363.83, Training time: 334.85
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 1652315.0             |
| test/episodes             | 725.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -2.24272039772379     |
| test_1/avg_q              | -10.335400942010555   |
| test_1/n_subgoals         | 4284.0                |
| test_1/subgoal_succ_rate  | 0.9745564892623716    |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -12.704325313185203   |
| train_0/current_q         | -6.541273807900035    |
| train_0/fw_bonus          | -0.9989188268780709   |
| train_0/fw_loss           | 0.0002926834858953953 |
| train_0/mu_grads          | -0.11631098538637161  |
| train_0/mu_grads_std      | 0.5454456254839897    |
| train_0/mu_loss           | 6.369598259075852     |
| train_0/next_q            | -6.144074014408758    |
| train_0/q_grads           | 0.038010317273437975  |
| train_0/q_grads_std       | 0.4092647969722748    |
| train_0/q_loss            | 0.5494423159209468    |
| train_0/reward            | -0.7810468416817458   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0385986328125       |
| train_0/target_q          | -6.4781265754913235   |
| train_1/avg_q             | -12.389853405469118   |
| train_1/current_q         | -9.917168469193673    |
| train_1/fw_bonus          | -0.996795092523098    |
| train_1/fw_loss           | 0.0016659150714986026 |
| train_1/mu_grads          | -0.04314684346318245  |
| train_1/mu_grads_std      | 0.5067536354064941    |
| train_1/mu_loss           | 9.751982092441569     |
| train_1/n_subgoals        | 1317.0                |
| train_1/next_q            | -9.668296189119506    |
| train_1/q_grads           | -0.043523242231458426 |
| train_1/q_grads_std       | 0.6155313983559608    |
| train_1/q_loss            | 5.719767886728308     |
| train_1/reward            | -1.861295940976197    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007861328125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.41002277904328016   |
| train_1/target_q          | -10.014650613299317   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.48000000000000004
Training epoch 29
Time for epoch 29: 810.08. Rollout time: 460.14, Training time: 349.79
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 1690364.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -1.2515853859129757    |
| test_1/avg_q              | -9.902957091358289     |
| test_1/n_subgoals         | 2444.0                 |
| test_1/subgoal_succ_rate  | 0.9590834697217676     |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -11.442816082118968    |
| train_0/current_q         | -6.574410559810121     |
| train_0/fw_bonus          | -0.9988954097032547    |
| train_0/fw_loss           | 0.00029891022204537877 |
| train_0/mu_grads          | -0.1170465461909771    |
| train_0/mu_grads_std      | 0.5512357816100121     |
| train_0/mu_loss           | 6.334902226213776      |
| train_0/next_q            | -6.098220438702266     |
| train_0/q_grads           | 0.03814373621717095    |
| train_0/q_grads_std       | 0.4164727672934532     |
| train_0/q_loss            | 0.42416070434244996    |
| train_0/reward            | -0.7803268798594217    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0489990234375        |
| train_0/target_q          | -6.504782201735535     |
| train_1/avg_q             | -11.88562570087126     |
| train_1/current_q         | -10.00827090573929     |
| train_1/fw_bonus          | -0.9966793462634087    |
| train_1/fw_loss           | 0.0016928130877204239  |
| train_1/mu_grads          | -0.04435185715556145   |
| train_1/mu_grads_std      | 0.5122841596603394     |
| train_1/mu_loss           | 9.78038109878155       |
| train_1/n_subgoals        | 1552.0                 |
| train_1/next_q            | -9.687440963232884     |
| train_1/q_grads           | -0.04529248913750052   |
| train_1/q_grads_std       | 0.6289323851466179     |
| train_1/q_loss            | 5.992410079215523      |
| train_1/reward            | -1.90184318137035      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00771484375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.42332474226804123    |
| train_1/target_q          | -10.090228854443804    |
------------------------------------------------------
New best value for test/success_rate: 0.68. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.54
Training epoch 30
Time for epoch 30: 974.14. Rollout time: 546.53, Training time: 427.43
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 1733274.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.36                   |
| test_0/avg_q              | -1.2044352792954152    |
| test_1/avg_q              | -11.844428263968378    |
| test_1/n_subgoals         | 4030.0                 |
| test_1/subgoal_succ_rate  | 0.9535980148883375     |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.77                   |
| train_0/avg_q             | -11.124874699390155    |
| train_0/current_q         | -5.74864307089667      |
| train_0/fw_bonus          | -0.9989089608192444    |
| train_0/fw_loss           | 0.00029530425745178946 |
| train_0/mu_grads          | -0.12072575092315674   |
| train_0/mu_grads_std      | 0.5585101008415222     |
| train_0/mu_loss           | 5.503449038668924      |
| train_0/next_q            | -5.350831936809635     |
| train_0/q_grads           | 0.03826597826555371    |
| train_0/q_grads_std       | 0.4207915745675564     |
| train_0/q_loss            | 0.5084748134057802     |
| train_0/reward            | -0.7863178167135629    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0475830078125        |
| train_0/target_q          | -5.770225758446684     |
| train_1/avg_q             | -12.278903592744555    |
| train_1/current_q         | -9.800347202712235     |
| train_1/fw_bonus          | -0.9970896169543266    |
| train_1/fw_loss           | 0.0015974630863638596  |
| train_1/mu_grads          | -0.044260304793715476  |
| train_1/mu_grads_std      | 0.5211278140544892     |
| train_1/mu_loss           | 9.572091681224116      |
| train_1/n_subgoals        | 1549.0                 |
| train_1/next_q            | -9.471018529617155     |
| train_1/q_grads           | -0.04688553921878338   |
| train_1/q_grads_std       | 0.6393299505114556     |
| train_1/q_loss            | 5.205450673433911      |
| train_1/reward            | -1.8647387116245226    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0075927734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.42027114267269206    |
| train_1/target_q          | -9.885652858797595     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.47
Training epoch 31
Time for epoch 31: 661.63. Rollout time: 318.82, Training time: 342.65
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 31                    |
| policy/steps              | 1762602.0             |
| test/episodes             | 800.0                 |
| test/success_rate         | 0.64                  |
| test_0/avg_q              | -2.151099013294065    |
| test_1/avg_q              | -10.088074099787253   |
| test_1/n_subgoals         | 4066.0                |
| test_1/subgoal_succ_rate  | 0.9790949335956715    |
| train/episodes            | 3200.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -10.445499493662698   |
| train_0/current_q         | -6.84342227570353     |
| train_0/fw_bonus          | -0.9988477408885956   |
| train_0/fw_loss           | 0.0003115947765763849 |
| train_0/mu_grads          | -0.12087235171347857  |
| train_0/mu_grads_std      | 0.5637453123927116    |
| train_0/mu_loss           | 6.664708380559071     |
| train_0/next_q            | -6.431418463003093    |
| train_0/q_grads           | 0.03817690378054976   |
| train_0/q_grads_std       | 0.4261165648698807    |
| train_0/q_loss            | 0.47936940102387693   |
| train_0/reward            | -0.7856067102205998   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0430908203125       |
| train_0/target_q          | -6.800143457885821    |
| train_1/avg_q             | -11.060421433373731   |
| train_1/current_q         | -9.677671754282226    |
| train_1/fw_bonus          | -0.9967963352799416   |
| train_1/fw_loss           | 0.0016656252584652976 |
| train_1/mu_grads          | -0.04577108807861805  |
| train_1/mu_grads_std      | 0.527857880294323     |
| train_1/mu_loss           | 9.356056454846264     |
| train_1/n_subgoals        | 1136.0                |
| train_1/next_q            | -9.281653817202326    |
| train_1/q_grads           | -0.04851110093295574  |
| train_1/q_grads_std       | 0.6520767346024513    |
| train_1/q_loss            | 5.35898119338094      |
| train_1/reward            | -1.886747912802457    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0083251953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4779929577464789    |
| train_1/target_q          | -9.733548687334373    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 32
Time for epoch 32: 5880.92. Rollout time: 5487.46, Training time: 393.34
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 1794453.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.4208625754122812   |
| test_1/avg_q              | -9.89154165576928     |
| test_1/n_subgoals         | 3808.0                |
| test_1/subgoal_succ_rate  | 0.9745273109243697    |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -14.747949421354395   |
| train_0/current_q         | -6.492091411466262    |
| train_0/fw_bonus          | -0.9988807559013366   |
| train_0/fw_loss           | 0.0003028077375347493 |
| train_0/mu_grads          | -0.12225618176162242  |
| train_0/mu_grads_std      | 0.5703418463468551    |
| train_0/mu_loss           | 6.221748063830285     |
| train_0/next_q            | -6.00197353564227     |
| train_0/q_grads           | 0.037819938454777005  |
| train_0/q_grads_std       | 0.43177986741065977   |
| train_0/q_loss            | 0.29828358147196454   |
| train_0/reward            | -0.7859079349273088   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.049609375           |
| train_0/target_q          | -6.474292204802775    |
| train_1/avg_q             | -11.898060477401804   |
| train_1/current_q         | -9.306804034112236    |
| train_1/fw_bonus          | -0.9969778567552566   |
| train_1/fw_loss           | 0.0016234373644692824 |
| train_1/mu_grads          | -0.0467616586945951   |
| train_1/mu_grads_std      | 0.5340699300169944    |
| train_1/mu_loss           | 8.997618280789395     |
| train_1/n_subgoals        | 1262.0                |
| train_1/next_q            | -8.926301603306433    |
| train_1/q_grads           | -0.0503047151491046   |
| train_1/q_grads_std       | 0.6646128967404366    |
| train_1/q_loss            | 7.157683799377909     |
| train_1/reward            | -1.83872810624016     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007275390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4437400950871632    |
| train_1/target_q          | -9.409654228923461    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5700000000000001
Training epoch 33
Time for epoch 33: 821.60. Rollout time: 413.96, Training time: 407.46
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 1830654.0             |
| test/episodes             | 850.0                 |
| test/success_rate         | 0.44                  |
| test_0/avg_q              | -1.9389651077728363   |
| test_1/avg_q              | -5.1610108110728214   |
| test_1/n_subgoals         | 6581.0                |
| test_1/subgoal_succ_rate  | 0.9917945600972496    |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -10.392580482827535   |
| train_0/current_q         | -6.574530354145554    |
| train_0/fw_bonus          | -0.9988363012671471   |
| train_0/fw_loss           | 0.0003146400162222562 |
| train_0/mu_grads          | -0.11854980122298002  |
| train_0/mu_grads_std      | 0.5797012612223625    |
| train_0/mu_loss           | 6.328925263193729     |
| train_0/next_q            | -6.107147187233504    |
| train_0/q_grads           | 0.038631259277462957  |
| train_0/q_grads_std       | 0.4367389865219593    |
| train_0/q_loss            | 0.41608031126062367   |
| train_0/reward            | -0.7884969154467398   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.038134765625        |
| train_0/target_q          | -6.506407006927451    |
| train_1/avg_q             | -11.638674914254194   |
| train_1/current_q         | -8.777778320802636    |
| train_1/fw_bonus          | -0.9965100586414337   |
| train_1/fw_loss           | 0.001732164787244983  |
| train_1/mu_grads          | -0.04920765431597829  |
| train_1/mu_grads_std      | 0.539484791457653     |
| train_1/mu_loss           | 8.487990343144526     |
| train_1/n_subgoals        | 1298.0                |
| train_1/next_q            | -8.430397884334932    |
| train_1/q_grads           | -0.05101145152002573  |
| train_1/q_grads_std       | 0.6764545187354087    |
| train_1/q_loss            | 6.062714600071378     |
| train_1/reward            | -1.7783877659101563   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0076904296875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.40215716486902925   |
| train_1/target_q          | -8.851985359317933    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 34
Time for epoch 34: 834.72. Rollout time: 424.24, Training time: 410.32
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 34                    |
| policy/steps              | 1863178.0             |
| test/episodes             | 875.0                 |
| test/success_rate         | 0.56                  |
| test_0/avg_q              | -1.3255964539727956   |
| test_1/avg_q              | -6.51586483543194     |
| test_1/n_subgoals         | 3175.0                |
| test_1/subgoal_succ_rate  | 0.9533858267716535    |
| train/episodes            | 3500.0                |
| train/success_rate        | 0.86                  |
| train_0/avg_q             | -12.200068476168392   |
| train_0/current_q         | -6.494639813287543    |
| train_0/fw_bonus          | -0.9989033147692681   |
| train_0/fw_loss           | 0.0002968086784676416 |
| train_0/mu_grads          | -0.12137857060879469  |
| train_0/mu_grads_std      | 0.5869202181696892    |
| train_0/mu_loss           | 6.219332531795089     |
| train_0/next_q            | -5.981215965880739    |
| train_0/q_grads           | 0.03890640577301383   |
| train_0/q_grads_std       | 0.44193762317299845   |
| train_0/q_loss            | 0.299258045108537     |
| train_0/reward            | -0.7886967744780122   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0642333984375       |
| train_0/target_q          | -6.451937500995061    |
| train_1/avg_q             | -10.621042299805273   |
| train_1/current_q         | -9.00378975357886     |
| train_1/fw_bonus          | -0.996864227950573    |
| train_1/fw_loss           | 0.0016498442069860174 |
| train_1/mu_grads          | -0.050884751696139575 |
| train_1/mu_grads_std      | 0.5453457221388817    |
| train_1/mu_loss           | 8.641258917251378     |
| train_1/n_subgoals        | 1249.0                |
| train_1/next_q            | -8.563790547324698    |
| train_1/q_grads           | -0.05232855742797256  |
| train_1/q_grads_std       | 0.6877256453037262    |
| train_1/q_loss            | 6.235227536826763     |
| train_1/reward            | -1.8721896939438012   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0080322265625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4475580464371497    |
| train_1/target_q          | -9.081759538319583    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 35
Time for epoch 35: 734.89. Rollout time: 353.15, Training time: 381.56
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 1895484.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.44                   |
| test_0/avg_q              | -1.1168534119710096    |
| test_1/avg_q              | -8.806403584485878     |
| test_1/n_subgoals         | 1649.0                 |
| test_1/subgoal_succ_rate  | 0.821710127349909      |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.87                   |
| train_0/avg_q             | -12.942273011076935    |
| train_0/current_q         | -6.7074832004774       |
| train_0/fw_bonus          | -0.9988684520125389    |
| train_0/fw_loss           | 0.00030608178458351175 |
| train_0/mu_grads          | -0.1228481201454997    |
| train_0/mu_grads_std      | 0.5938696041703224     |
| train_0/mu_loss           | 6.409725408143198      |
| train_0/next_q            | -6.188431240971357     |
| train_0/q_grads           | 0.03908206019550562    |
| train_0/q_grads_std       | 0.44779644832015036    |
| train_0/q_loss            | 0.2659916447452497     |
| train_0/reward            | -0.792789624420766     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.04775390625          |
| train_0/target_q          | -6.689734879245518     |
| train_1/avg_q             | -10.4213744459328      |
| train_1/current_q         | -8.971876315180388     |
| train_1/fw_bonus          | -0.9969839960336685    |
| train_1/fw_loss           | 0.0016220119985518977  |
| train_1/mu_grads          | -0.05354411918669939   |
| train_1/mu_grads_std      | 0.5530217930674552     |
| train_1/mu_loss           | 8.652725403640943      |
| train_1/n_subgoals        | 1200.0                 |
| train_1/next_q            | -8.59328409958042      |
| train_1/q_grads           | -0.054282948933541776  |
| train_1/q_grads_std       | 0.6988412752747536     |
| train_1/q_loss            | 6.099871631032186      |
| train_1/reward            | -1.8274686532487976    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007861328125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4625                 |
| train_1/target_q          | -9.030211969018406     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.51
Training epoch 36
Time for epoch 36: 901.86. Rollout time: 501.73, Training time: 399.91
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 1934608.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -0.9299870336518147    |
| test_1/avg_q              | -7.744029830757399     |
| test_1/n_subgoals         | 4605.0                 |
| test_1/subgoal_succ_rate  | 0.9745928338762215     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -11.457280394035433    |
| train_0/current_q         | -6.495189820356552     |
| train_0/fw_bonus          | -0.9989174053072929    |
| train_0/fw_loss           | 0.00029305583084351385 |
| train_0/mu_grads          | -0.12306767329573631   |
| train_0/mu_grads_std      | 0.5991328820586205     |
| train_0/mu_loss           | 6.256196507484701      |
| train_0/next_q            | -6.050681459216721     |
| train_0/q_grads           | 0.03977638706564903    |
| train_0/q_grads_std       | 0.454653749614954      |
| train_0/q_loss            | 0.38876790788254845    |
| train_0/reward            | -0.7882791577583703    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.07158203125          |
| train_0/target_q          | -6.546072406932599     |
| train_1/avg_q             | -10.618679014804318    |
| train_1/current_q         | -8.892019263512221     |
| train_1/fw_bonus          | -0.9969713464379311    |
| train_1/fw_loss           | 0.0016249518608674406  |
| train_1/mu_grads          | -0.05359362149611115   |
| train_1/mu_grads_std      | 0.5595338463783264     |
| train_1/mu_loss           | 8.553312914755987      |
| train_1/n_subgoals        | 1385.0                 |
| train_1/next_q            | -8.53827726073662      |
| train_1/q_grads           | -0.05498739527538419   |
| train_1/q_grads_std       | 0.7101442635059356     |
| train_1/q_loss            | 5.983607526786522      |
| train_1/reward            | -1.8405941540975619    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.008056640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36606498194945847    |
| train_1/target_q          | -8.935503870703528     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.48
Training epoch 37
Time for epoch 37: 872.26. Rollout time: 436.82, Training time: 435.27
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 37                    |
| policy/steps              | 1966560.0             |
| test/episodes             | 950.0                 |
| test/success_rate         | 0.6                   |
| test_0/avg_q              | -1.9611921589829924   |
| test_1/avg_q              | -6.740074202548661    |
| test_1/n_subgoals         | 3626.0                |
| test_1/subgoal_succ_rate  | 0.9718698290126861    |
| train/episodes            | 3800.0                |
| train/success_rate        | 0.89                  |
| train_0/avg_q             | -11.835359829022467   |
| train_0/current_q         | -6.761221375947164    |
| train_0/fw_bonus          | -0.9988881796598434   |
| train_0/fw_loss           | 0.000300834988229326  |
| train_0/mu_grads          | -0.12680164650082587  |
| train_0/mu_grads_std      | 0.606156912446022     |
| train_0/mu_loss           | 6.488915234396634     |
| train_0/next_q            | -6.251109403193166    |
| train_0/q_grads           | 0.040145619120448825  |
| train_0/q_grads_std       | 0.4607217937707901    |
| train_0/q_loss            | 0.27063440724496196   |
| train_0/reward            | -0.7932156965118338   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.06337890625         |
| train_0/target_q          | -6.749255291454953    |
| train_1/avg_q             | -9.990941344065053    |
| train_1/current_q         | -8.758811926859176    |
| train_1/fw_bonus          | -0.9974531412124634   |
| train_1/fw_loss           | 0.001512976348749362  |
| train_1/mu_grads          | -0.05439204666763544  |
| train_1/mu_grads_std      | 0.565137180685997     |
| train_1/mu_loss           | 8.411120823664945     |
| train_1/n_subgoals        | 1229.0                |
| train_1/next_q            | -8.309515887920105    |
| train_1/q_grads           | -0.056166574265807866 |
| train_1/q_grads_std       | 0.7230244234204293    |
| train_1/q_loss            | 6.550558753386781     |
| train_1/reward            | -1.8391398941428634   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00888671875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.46379170056956875   |
| train_1/target_q          | -8.79109209074311     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.52
Training epoch 38
Time for epoch 38: 774.41. Rollout time: 370.15, Training time: 404.00
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 1999761.0             |
| test/episodes             | 975.0                 |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.2472905456153598   |
| test_1/avg_q              | -6.708339130524234    |
| test_1/n_subgoals         | 4615.0                |
| test_1/subgoal_succ_rate  | 0.9599133261105092    |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.9                   |
| train_0/avg_q             | -12.827163041040276   |
| train_0/current_q         | -6.722301535525746    |
| train_0/fw_bonus          | -0.9989059284329415   |
| train_0/fw_loss           | 0.0002961079964734381 |
| train_0/mu_grads          | -0.1316910207271576   |
| train_0/mu_grads_std      | 0.6137561738491059    |
| train_0/mu_loss           | 6.466417969043912     |
| train_0/next_q            | -6.2362163961188735   |
| train_0/q_grads           | 0.03968759449198842   |
| train_0/q_grads_std       | 0.46398849636316297   |
| train_0/q_loss            | 0.3029646135798854    |
| train_0/reward            | -0.7974315636456595   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.051171875           |
| train_0/target_q          | -6.729507142642538    |
| train_1/avg_q             | -10.316060434175032   |
| train_1/current_q         | -8.624869675445893    |
| train_1/fw_bonus          | -0.9973184496164322   |
| train_1/fw_loss           | 0.0015442797302966937 |
| train_1/mu_grads          | -0.05630961675196886  |
| train_1/mu_grads_std      | 0.5712786987423897    |
| train_1/mu_loss           | 8.322802080818335     |
| train_1/n_subgoals        | 1248.0                |
| train_1/next_q            | -8.260657771103109    |
| train_1/q_grads           | -0.05632080119103193  |
| train_1/q_grads_std       | 0.7360103920102119    |
| train_1/q_loss            | 6.6377614556560145    |
| train_1/reward            | -1.7986399119319685   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007568359375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.484775641025641     |
| train_1/target_q          | -8.71086453538509     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.5
Training epoch 39
Time for epoch 39: 785.77. Rollout time: 434.97, Training time: 350.58
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 2033295.0              |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.68                   |
| test_0/avg_q              | -0.8535544302922811    |
| test_1/avg_q              | -4.804358564633797     |
| test_1/n_subgoals         | 358.0                  |
| test_1/subgoal_succ_rate  | 0.32122905027932963    |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -13.235176560185213    |
| train_0/current_q         | -5.992893380505557     |
| train_0/fw_bonus          | -0.9989091649651527    |
| train_0/fw_loss           | 0.00029525077043217606 |
| train_0/mu_grads          | -0.13448187261819838   |
| train_0/mu_grads_std      | 0.6209589630365372     |
| train_0/mu_loss           | 5.769484347254904      |
| train_0/next_q            | -5.5475473890856986    |
| train_0/q_grads           | 0.03906845878809691    |
| train_0/q_grads_std       | 0.4675359144806862     |
| train_0/q_loss            | 0.43746376213032095    |
| train_0/reward            | -0.7964619099609991    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0888427734375        |
| train_0/target_q          | -6.007547594463544     |
| train_1/avg_q             | -11.429777347569573    |
| train_1/current_q         | -8.730412462706218     |
| train_1/fw_bonus          | -0.9975991547107697    |
| train_1/fw_loss           | 0.001479036797536537   |
| train_1/mu_grads          | -0.0564250685274601    |
| train_1/mu_grads_std      | 0.578460519015789      |
| train_1/mu_loss           | 8.34640579944202       |
| train_1/n_subgoals        | 1410.0                 |
| train_1/next_q            | -8.330208366950625     |
| train_1/q_grads           | -0.05724336821585894   |
| train_1/q_grads_std       | 0.7481251195073128     |
| train_1/q_loss            | 6.295155991145156      |
| train_1/reward            | -1.7719217606969324    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0076171875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43829787234042555    |
| train_1/target_q          | -8.778483300406801     |
------------------------------------------------------
New best value for test/success_rate: 0.68. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 40
Time for epoch 40: 706.78. Rollout time: 379.36, Training time: 327.21
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 2070822.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.48                  |
| test_0/avg_q              | -1.9994341455823088   |
| test_1/avg_q              | -6.507253358947523    |
| test_1/n_subgoals         | 2914.0                |
| test_1/subgoal_succ_rate  | 0.9296499656829101    |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.84                  |
| train_0/avg_q             | -11.540047702046133   |
| train_0/current_q         | -7.012661250472116    |
| train_0/fw_bonus          | -0.9989133104681969   |
| train_0/fw_loss           | 0.0002941453509265557 |
| train_0/mu_grads          | -0.1344643708318472   |
| train_0/mu_grads_std      | 0.6271097436547279    |
| train_0/mu_loss           | 6.72748966767804      |
| train_0/next_q            | -6.489967697787935    |
| train_0/q_grads           | 0.0390865471214056    |
| train_0/q_grads_std       | 0.4714532010257244    |
| train_0/q_loss            | 0.23605385875766655   |
| train_0/reward            | -0.7945403412421002   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.087255859375        |
| train_0/target_q          | -7.004869060268396    |
| train_1/avg_q             | -10.972202063021163   |
| train_1/current_q         | -8.952221087482366    |
| train_1/fw_bonus          | -0.9973441138863564   |
| train_1/fw_loss           | 0.001538314067875035  |
| train_1/mu_grads          | -0.056844229158014056 |
| train_1/mu_grads_std      | 0.5854042679071426    |
| train_1/mu_loss           | 8.697018361486176     |
| train_1/n_subgoals        | 1258.0                |
| train_1/next_q            | -8.663001960116162    |
| train_1/q_grads           | -0.058443070575594905 |
| train_1/q_grads_std       | 0.7587181448936462    |
| train_1/q_loss            | 6.23352052490311      |
| train_1/reward            | -1.7859571205557585   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.007958984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3481717011128776    |
| train_1/target_q          | -9.026708880777472    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.56
Training epoch 41
Time for epoch 41: 966.55. Rollout time: 622.04, Training time: 344.36
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2130150.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.8375997548719083    |
| test_1/avg_q              | -12.333207540179943    |
| test_1/n_subgoals         | 678.0                  |
| test_1/subgoal_succ_rate  | 0.004424778761061947   |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -8.955982142297904     |
| train_0/current_q         | -5.734312548438049     |
| train_0/fw_bonus          | -0.998863622546196     |
| train_0/fw_loss           | 0.00030736908702237996 |
| train_0/mu_grads          | -0.1327838446944952    |
| train_0/mu_grads_std      | 0.6298905313014984     |
| train_0/mu_loss           | 5.498985778910011      |
| train_0/next_q            | -5.319451883673655     |
| train_0/q_grads           | 0.03814774071797729    |
| train_0/q_grads_std       | 0.4731602676212788     |
| train_0/q_loss            | 0.5301680602877334     |
| train_0/reward            | -0.7882473992303858    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0727783203125        |
| train_0/target_q          | -5.714633565236832     |
| train_1/avg_q             | -10.999079041991447    |
| train_1/current_q         | -8.979549428010293     |
| train_1/fw_bonus          | -0.9961524173617363    |
| train_1/fw_loss           | 0.0018152836477383972  |
| train_1/mu_grads          | -0.059342315513640644  |
| train_1/mu_grads_std      | 0.5923532277345658     |
| train_1/mu_loss           | 8.708292959781039      |
| train_1/n_subgoals        | 1769.0                 |
| train_1/next_q            | -8.685113102853284     |
| train_1/q_grads           | -0.05866267178207636   |
| train_1/q_grads_std       | 0.7657903507351875     |
| train_1/q_loss            | 6.472829984140226      |
| train_1/reward            | -1.8766809268345241    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0082763671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21424533634821932    |
| train_1/target_q          | -9.058985536032424     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.41000000000000003
Training epoch 42
Time for epoch 42: 1815.63. Rollout time: 1327.15, Training time: 488.29
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 2218337.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5273839535530909    |
| test_1/avg_q              | -11.744982502296583    |
| test_1/n_subgoals         | 692.0                  |
| test_1/subgoal_succ_rate  | 0.024566473988439308   |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -7.29854189254853      |
| train_0/current_q         | -2.1759671726051395    |
| train_0/fw_bonus          | -0.9988379523158073    |
| train_0/fw_loss           | 0.00031419920996995644 |
| train_0/mu_grads          | -0.13083477094769477   |
| train_0/mu_grads_std      | 0.6348354533314705     |
| train_0/mu_loss           | 1.960111375650967      |
| train_0/next_q            | -1.8925699042267516    |
| train_0/q_grads           | 0.03717450127005577    |
| train_0/q_grads_std       | 0.47903580591082573    |
| train_0/q_loss            | 0.7043790051217782     |
| train_0/reward            | -0.7677331694605527    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0654296875           |
| train_0/target_q          | -2.3550125964245674    |
| train_1/avg_q             | -16.186559024860372    |
| train_1/current_q         | -11.653205476957812    |
| train_1/fw_bonus          | -0.9945815205574036    |
| train_1/fw_loss           | 0.0021803885465487838  |
| train_1/mu_grads          | -0.05987200811505318   |
| train_1/mu_grads_std      | 0.5966238781809807     |
| train_1/mu_loss           | 11.72599971219274      |
| train_1/n_subgoals        | 2642.0                 |
| train_1/next_q            | -11.744593069155787    |
| train_1/q_grads           | -0.06019400460645556   |
| train_1/q_grads_std       | 0.7708687037229538     |
| train_1/q_loss            | 7.943579484740811      |
| train_1/reward            | -2.084460809560187     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080322265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.029901589704769114   |
| train_1/target_q          | -11.745466725210811    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.29000000000000004
Training epoch 43
Time for epoch 43: 2167.59. Rollout time: 1539.39, Training time: 627.65
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 2307971.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.412360193067462     |
| test_1/avg_q              | -15.407339216183487    |
| test_1/n_subgoals         | 679.0                  |
| test_1/subgoal_succ_rate  | 0.005891016200294551   |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -1.3235669015706926    |
| train_0/current_q         | -2.894379809359612     |
| train_0/fw_bonus          | -0.9989251151680947    |
| train_0/fw_loss           | 0.00029100842657499016 |
| train_0/mu_grads          | -0.13085647597908973   |
| train_0/mu_grads_std      | 0.635153952240944      |
| train_0/mu_loss           | 2.755207158362235      |
| train_0/next_q            | -2.6754754227093147    |
| train_0/q_grads           | 0.038284685276448724   |
| train_0/q_grads_std       | 0.481185469776392      |
| train_0/q_loss            | 0.882930048532019      |
| train_0/reward            | -0.7539488060465374    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0590576171875        |
| train_0/target_q          | -2.9277424563139625    |
| train_1/avg_q             | -14.810869293000724    |
| train_1/current_q         | -13.921961336242779    |
| train_1/fw_bonus          | -0.9946421727538108    |
| train_1/fw_loss           | 0.0021662899845978243  |
| train_1/mu_grads          | -0.060006798803806306  |
| train_1/mu_grads_std      | 0.6017103508114815     |
| train_1/mu_loss           | 14.223296484872671     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -14.294905370829474    |
| train_1/q_grads           | -0.06197163118049502   |
| train_1/q_grads_std       | 0.7754412591457367     |
| train_1/q_loss            | 8.607511716261378      |
| train_1/reward            | -2.2265658174306737    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0080810546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.027777777777777776   |
| train_1/target_q          | -13.992865510203625    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 44
Time for epoch 44: 2689.60. Rollout time: 1851.40, Training time: 836.93
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 44                    |
| policy/steps              | 2397850.0             |
| test/episodes             | 1125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.580014267748715    |
| test_1/avg_q              | -15.458490294140883   |
| test_1/n_subgoals         | 682.0                 |
| test_1/subgoal_succ_rate  | 0.010263929618768328  |
| train/episodes            | 4500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.0834628609735306   |
| train_0/current_q         | -2.097353960693233    |
| train_0/fw_bonus          | -0.9989690482616425   |
| train_0/fw_loss           | 0.0002793175630358746 |
| train_0/mu_grads          | -0.1309198573231697   |
| train_0/mu_grads_std      | 0.6352777481079102    |
| train_0/mu_loss           | 2.0525326131274277    |
| train_0/next_q            | -2.0248404840048004   |
| train_0/q_grads           | 0.0390847397968173    |
| train_0/q_grads_std       | 0.4787265807390213    |
| train_0/q_loss            | 1.2006328090319969    |
| train_0/reward            | -0.734257641727163    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0478759765625       |
| train_0/target_q          | -2.180730541263373    |
| train_1/avg_q             | -16.68359407887559    |
| train_1/current_q         | -16.159854717775467   |
| train_1/fw_bonus          | -0.9949075952172279   |
| train_1/fw_loss           | 0.002104604308260605  |
| train_1/mu_grads          | -0.0603151997551322   |
| train_1/mu_grads_std      | 0.6056249856948852    |
| train_1/mu_loss           | 16.937817927859918    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -17.087772729106277   |
| train_1/q_grads           | -0.06398664098232984  |
| train_1/q_grads_std       | 0.7832176312804222    |
| train_1/q_loss            | 9.26546599286414      |
| train_1/reward            | -2.4076136155530548   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0069091796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.024444444444444446  |
| train_1/target_q          | -16.252835221913053   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 1709.68. Rollout time: 1283.58, Training time: 425.89
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 2484563.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.1165068372402902   |
| test_1/avg_q              | -14.07385216971652    |
| test_1/n_subgoals         | 772.0                 |
| test_1/subgoal_succ_rate  | 0.16839378238341968   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.06                  |
| train_0/avg_q             | -5.048079851788658    |
| train_0/current_q         | -3.8235711077000283   |
| train_0/fw_bonus          | -0.9990702867507935   |
| train_0/fw_loss           | 0.0002523802391806385 |
| train_0/mu_grads          | -0.13196242563426494  |
| train_0/mu_grads_std      | 0.6385926768183708    |
| train_0/mu_loss           | 3.5981009791992293    |
| train_0/next_q            | -3.558900942941199    |
| train_0/q_grads           | 0.03934634225443005   |
| train_0/q_grads_std       | 0.47731033638119696   |
| train_0/q_loss            | 0.5820044427305966    |
| train_0/reward            | -0.7174738687426725   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.06513671875         |
| train_0/target_q          | -3.850070131954541    |
| train_1/avg_q             | -15.922735768034775   |
| train_1/current_q         | -18.173652741259286   |
| train_1/fw_bonus          | -0.9944055765867233   |
| train_1/fw_loss           | 0.0022212811629287897 |
| train_1/mu_grads          | -0.059164207149297    |
| train_1/mu_grads_std      | 0.611448360979557     |
| train_1/mu_loss           | 19.580687216990224    |
| train_1/n_subgoals        | 2637.0                |
| train_1/next_q            | -19.678823989076353   |
| train_1/q_grads           | -0.06650105472654104  |
| train_1/q_grads_std       | 0.7916070088744164    |
| train_1/q_loss            | 6.254627187656417     |
| train_1/reward            | -2.5527090598570794   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0062744140625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.04854000758437618   |
| train_1/target_q          | -18.312030819502375   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 46
Time for epoch 46: 1393.48. Rollout time: 980.63, Training time: 412.53
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 2568361.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.9841371005972636    |
| test_1/avg_q              | -14.659587716428419    |
| test_1/n_subgoals         | 678.0                  |
| test_1/subgoal_succ_rate  | 0.004424778761061947   |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.17                   |
| train_0/avg_q             | -6.705323217518919     |
| train_0/current_q         | -4.387850453288515     |
| train_0/fw_bonus          | -0.999104055762291     |
| train_0/fw_loss           | 0.00024339103074453306 |
| train_0/mu_grads          | -0.13044313490390777   |
| train_0/mu_grads_std      | 0.6407418072223663     |
| train_0/mu_loss           | 4.146996257258377      |
| train_0/next_q            | -4.055239064354374     |
| train_0/q_grads           | 0.04018527679145336    |
| train_0/q_grads_std       | 0.47964415028691293    |
| train_0/q_loss            | 0.4467219164782124     |
| train_0/reward            | -0.7121905664422229    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.067578125            |
| train_0/target_q          | -4.358641398752698     |
| train_1/avg_q             | -18.646696730000443    |
| train_1/current_q         | -19.049912293919043    |
| train_1/fw_bonus          | -0.9951359897851944    |
| train_1/fw_loss           | 0.002051517754443921   |
| train_1/mu_grads          | -0.05970847168937325   |
| train_1/mu_grads_std      | 0.6138772234320641     |
| train_1/mu_loss           | 20.760461240720332     |
| train_1/n_subgoals        | 2510.0                 |
| train_1/next_q            | -20.787906566529113    |
| train_1/q_grads           | -0.06772882789373398   |
| train_1/q_grads_std       | 0.7995135203003884     |
| train_1/q_loss            | 4.1666068105657965     |
| train_1/reward            | -2.5955918591891534    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0072998046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.050597609561752986   |
| train_1/target_q          | -19.20850376124445     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 47
Time for epoch 47: 1184.04. Rollout time: 786.18, Training time: 397.58
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 2638769.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2642662409005816    |
| test_1/avg_q              | -10.697584891978396    |
| test_1/n_subgoals         | 784.0                  |
| test_1/subgoal_succ_rate  | 0.1441326530612245     |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.39                   |
| train_0/avg_q             | -7.3026500069854166    |
| train_0/current_q         | -4.85246458432613      |
| train_0/fw_bonus          | -0.9991826996207237    |
| train_0/fw_loss           | 0.00022246796179388185 |
| train_0/mu_grads          | -0.12796150408685208   |
| train_0/mu_grads_std      | 0.6422691628336906     |
| train_0/mu_loss           | 4.597686037549437      |
| train_0/next_q            | -4.483583151131549     |
| train_0/q_grads           | 0.0405690835788846     |
| train_0/q_grads_std       | 0.4793945044279099     |
| train_0/q_loss            | 0.4039817603550434     |
| train_0/reward            | -0.7229218947089976    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0871337890625        |
| train_0/target_q          | -4.786008593660841     |
| train_1/avg_q             | -18.168699584170632    |
| train_1/current_q         | -15.903689763339386    |
| train_1/fw_bonus          | -0.9963489189743996    |
| train_1/fw_loss           | 0.0017696129594696685  |
| train_1/mu_grads          | -0.061789702903479335  |
| train_1/mu_grads_std      | 0.617809708416462      |
| train_1/mu_loss           | 16.604259014978673     |
| train_1/n_subgoals        | 2244.0                 |
| train_1/next_q            | -16.674156077928693    |
| train_1/q_grads           | -0.06830965522676706   |
| train_1/q_grads_std       | 0.8041191801428795     |
| train_1/q_loss            | 5.550786545869437      |
| train_1/reward            | -2.566286939077327     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0069580078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21122994652406418    |
| train_1/target_q          | -16.00004336953645     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 48
Time for epoch 48: 1053.34. Rollout time: 654.56, Training time: 398.49
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 2699852.0              |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0615705527076589    |
| test_1/avg_q              | -12.798255274052426    |
| test_1/n_subgoals         | 676.0                  |
| test_1/subgoal_succ_rate  | 0.0014792899408284023  |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -8.624027799939217     |
| train_0/current_q         | -4.829643049382883     |
| train_0/fw_bonus          | -0.9992240026593209    |
| train_0/fw_loss           | 0.00021147662700968795 |
| train_0/mu_grads          | -0.12924281433224677   |
| train_0/mu_grads_std      | 0.6435863569378852     |
| train_0/mu_loss           | 4.544964405458179      |
| train_0/next_q            | -4.4166083160746625    |
| train_0/q_grads           | 0.04035799112170935    |
| train_0/q_grads_std       | 0.4799067974090576     |
| train_0/q_loss            | 0.366597099109368      |
| train_0/reward            | -0.728095795797708     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.086376953125         |
| train_0/target_q          | -4.751365313422895     |
| train_1/avg_q             | -15.711702530831596    |
| train_1/current_q         | -17.466586135605063    |
| train_1/fw_bonus          | -0.9975119829177856    |
| train_1/fw_loss           | 0.0014992991666076705  |
| train_1/mu_grads          | -0.0631934493780136    |
| train_1/mu_grads_std      | 0.6215096563100815     |
| train_1/mu_loss           | 18.733206105288872     |
| train_1/n_subgoals        | 2005.0                 |
| train_1/next_q            | -18.743526377780114    |
| train_1/q_grads           | -0.06729823406785726   |
| train_1/q_grads_std       | 0.8096856281161309     |
| train_1/q_loss            | 5.325533164308712      |
| train_1/reward            | -2.5207464035749583    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0065185546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3311720698254364     |
| train_1/target_q          | -17.62823650717125     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 49
Time for epoch 49: 993.76. Rollout time: 590.49, Training time: 403.05
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 2752799.0              |
| test/episodes             | 1250.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -0.974674907241984     |
| test_1/avg_q              | -18.319378350080246    |
| test_1/n_subgoals         | 1563.0                 |
| test_1/subgoal_succ_rate  | 0.6423544465770953     |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -9.042698576522143     |
| train_0/current_q         | -5.203131218004678     |
| train_0/fw_bonus          | -0.9992052733898162    |
| train_0/fw_loss           | 0.00021645921806339173 |
| train_0/mu_grads          | -0.13015912249684333   |
| train_0/mu_grads_std      | 0.6446669146418571     |
| train_0/mu_loss           | 4.934058548649201      |
| train_0/next_q            | -4.812031220245657     |
| train_0/q_grads           | 0.04044349631294608    |
| train_0/q_grads_std       | 0.4818460501730442     |
| train_0/q_loss            | 0.38424122121315757    |
| train_0/reward            | -0.7340969736556872    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.10185546875          |
| train_0/target_q          | -5.144626029612278     |
| train_1/avg_q             | -16.898421367946042    |
| train_1/current_q         | -15.705798240441112    |
| train_1/fw_bonus          | -0.9976031392812729    |
| train_1/fw_loss           | 0.0014781102945562452  |
| train_1/mu_grads          | -0.06431100592017173   |
| train_1/mu_grads_std      | 0.6260731130838394     |
| train_1/mu_loss           | 16.692200770407702     |
| train_1/n_subgoals        | 1733.0                 |
| train_1/next_q            | -16.62361664043994     |
| train_1/q_grads           | -0.06660878043621779   |
| train_1/q_grads_std       | 0.8183540120720864     |
| train_1/q_loss            | 4.660377820066628      |
| train_1/reward            | -2.420024564852065     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00693359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.33121754183496827    |
| train_1/target_q          | -15.845491224569491    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 50
Time for epoch 50: 1068.01. Rollout time: 648.47, Training time: 419.36
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
----------------------------------------------------
| epoch                     | 50                   |
| policy/steps              | 2810018.0            |
| test/episodes             | 1275.0               |
| test/success_rate         | 0.0                  |
| test_0/avg_q              | -1.0500544275008366  |
| test_1/avg_q              | -13.65369137982887   |
| test_1/n_subgoals         | 9699.0               |
| test_1/subgoal_succ_rate  | 0.9686565625322198   |
| train/episodes            | 5100.0               |
| train/success_rate        | 0.55                 |
| train_0/avg_q             | -9.2847565315989     |
| train_0/current_q         | -5.3369378033631785  |
| train_0/fw_bonus          | -0.9992891415953636  |
| train_0/fw_loss           | 0.000194145381465205 |
| train_0/mu_grads          | -0.132811027020216   |
| train_0/mu_grads_std      | 0.6461256504058838   |
| train_0/mu_loss           | 5.084596942025854    |
| train_0/next_q            | -4.951841279508093   |
| train_0/q_grads           | 0.040602415706962346 |
| train_0/q_grads_std       | 0.48384499177336693  |
| train_0/q_loss            | 0.46008083903762576  |
| train_0/reward            | -0.7395561711025949  |
| train_0/reward_-0.0_frac  | 0.0                  |
| train_0/reward_-1.0_frac  | 0.1166015625         |
| train_0/target_q          | -5.2700894025382805  |
| train_1/avg_q             | -17.560179471153912  |
| train_1/current_q         | -11.86692636039228   |
| train_1/fw_bonus          | -0.9978826448321343  |
| train_1/fw_loss           | 0.001413150114240125 |
| train_1/mu_grads          | -0.06636138372123242 |
| train_1/mu_grads_std      | 0.6299804404377938   |
| train_1/mu_loss           | 11.923174177487155   |
| train_1/n_subgoals        | 1974.0               |
| train_1/next_q            | -11.912925878047155  |
| train_1/q_grads           | -0.06857333462685347 |
| train_1/q_grads_std       | 0.8262482285499573   |
| train_1/q_loss            | 5.094057221386135    |
| train_1/reward            | -2.2764665110986244  |
| train_1/reward_-0.0_frac  | 0.0                  |
| train_1/reward_-1.0_frac  | 0.007666015625       |
| train_1/reward_-27.0_frac | 0.0                  |
| train_1/subgoal_succ_rate | 0.414387031408308    |
| train_1/target_q          | -11.965200652882462  |
----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 51
Time for epoch 51: 960.49. Rollout time: 556.98, Training time: 403.35
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 51                    |
| policy/steps              | 2857448.0             |
| test/episodes             | 1300.0                |
| test/success_rate         | 0.36                  |
| test_0/avg_q              | -1.6735886514364342   |
| test_1/avg_q              | -11.69831372505803    |
| test_1/n_subgoals         | 4194.0                |
| test_1/subgoal_succ_rate  | 0.9258464473056748    |
| train/episodes            | 5200.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -9.632496189116127    |
| train_0/current_q         | -5.619733957202446    |
| train_0/fw_bonus          | -0.9992792174220085   |
| train_0/fw_loss           | 0.0001967883919860469 |
| train_0/mu_grads          | -0.13447507619857788  |
| train_0/mu_grads_std      | 0.650389452278614     |
| train_0/mu_loss           | 5.400354956524104     |
| train_0/next_q            | -5.232431725901418    |
| train_0/q_grads           | 0.04091497072950005   |
| train_0/q_grads_std       | 0.48662537932395933   |
| train_0/q_loss            | 0.47761967094530666   |
| train_0/reward            | -0.7494230727312242   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1003173828125       |
| train_0/target_q          | -5.563477399457791    |
| train_1/avg_q             | -15.615076799969339   |
| train_1/current_q         | -13.99270004375919    |
| train_1/fw_bonus          | -0.9980675905942917   |
| train_1/fw_loss           | 0.0013701631047297268 |
| train_1/mu_grads          | -0.06789896544069052  |
| train_1/mu_grads_std      | 0.6333859413862228    |
| train_1/mu_loss           | 14.234105437066182    |
| train_1/n_subgoals        | 1883.0                |
| train_1/next_q            | -14.20947152119353    |
| train_1/q_grads           | -0.06940981056541204  |
| train_1/q_grads_std       | 0.8374455749988556    |
| train_1/q_loss            | 5.095071529009175     |
| train_1/reward            | -2.1888784715243674   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0072998046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.45831120552310145   |
| train_1/target_q          | -14.109007888257597   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 52
Time for epoch 52: 943.55. Rollout time: 557.73, Training time: 385.60
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 2911866.0              |
| test/episodes             | 1325.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4998505221661989    |
| test_1/avg_q              | -14.799613064730787    |
| test_1/n_subgoals         | 955.0                  |
| test_1/subgoal_succ_rate  | 0.3068062827225131     |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -10.410838323352312    |
| train_0/current_q         | -5.9857570182704       |
| train_0/fw_bonus          | -0.9992993280291558    |
| train_0/fw_loss           | 0.00019143530080327763 |
| train_0/mu_grads          | -0.13699113726615905   |
| train_0/mu_grads_std      | 0.6561289340257644     |
| train_0/mu_loss           | 5.7575968431921485     |
| train_0/next_q            | -5.592728578918218     |
| train_0/q_grads           | 0.041155589185655116   |
| train_0/q_grads_std       | 0.489146264642477      |
| train_0/q_loss            | 0.48171115396521974    |
| train_0/reward            | -0.7581256119348836    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.14326171875          |
| train_0/target_q          | -5.924053157351834     |
| train_1/avg_q             | -15.61634820440074     |
| train_1/current_q         | -13.116884260989488    |
| train_1/fw_bonus          | -0.9985726654529572    |
| train_1/fw_loss           | 0.001252777167246677   |
| train_1/mu_grads          | -0.07036412097513675   |
| train_1/mu_grads_std      | 0.6351564198732376     |
| train_1/mu_loss           | 13.260121567179747     |
| train_1/n_subgoals        | 1954.0                 |
| train_1/next_q            | -13.176595389327028    |
| train_1/q_grads           | -0.07203951440751552   |
| train_1/q_grads_std       | 0.8441719934344292     |
| train_1/q_loss            | 5.9984636341223325     |
| train_1/reward            | -2.05537436607774      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00693359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4687819856704197     |
| train_1/target_q          | -13.153914593107407    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 53
Time for epoch 53: 1044.82. Rollout time: 637.46, Training time: 407.06
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 2965058.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -1.4993994212288977    |
| test_1/avg_q              | -15.585756222350934    |
| test_1/n_subgoals         | 4142.0                 |
| test_1/subgoal_succ_rate  | 0.9128440366972477     |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -12.856341153277654    |
| train_0/current_q         | -5.943098714844191     |
| train_0/fw_bonus          | -0.9992912232875824    |
| train_0/fw_loss           | 0.00019359191319381352 |
| train_0/mu_grads          | -0.13644994385540485   |
| train_0/mu_grads_std      | 0.6627073183655738     |
| train_0/mu_loss           | 5.712878150506718      |
| train_0/next_q            | -5.547731077410186     |
| train_0/q_grads           | 0.041452756896615026   |
| train_0/q_grads_std       | 0.492889541387558      |
| train_0/q_loss            | 0.46949765378059494    |
| train_0/reward            | -0.7641294451368594    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.126123046875         |
| train_0/target_q          | -5.904097532101623     |
| train_1/avg_q             | -16.109365424996046    |
| train_1/current_q         | -12.765213312543416    |
| train_1/fw_bonus          | -0.9986844509840012    |
| train_1/fw_loss           | 0.00122679396008607    |
| train_1/mu_grads          | -0.06911062560975552   |
| train_1/mu_grads_std      | 0.6366173297166824     |
| train_1/mu_loss           | 13.003861721916461     |
| train_1/n_subgoals        | 1962.0                 |
| train_1/next_q            | -12.832220267116758    |
| train_1/q_grads           | -0.07382037471979856   |
| train_1/q_grads_std       | 0.8481631577014923     |
| train_1/q_loss            | 3.6881416602804498     |
| train_1/reward            | -1.9803473846684938    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0064208984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3934760448521916     |
| train_1/target_q          | -12.85274767179664     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16999999999999998
Training epoch 54
Time for epoch 54: 1017.18. Rollout time: 606.96, Training time: 409.95
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 3017288.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.2629943420310568    |
| test_1/avg_q              | -16.87341843456165     |
| test_1/n_subgoals         | 4803.0                 |
| test_1/subgoal_succ_rate  | 0.9206745783885072     |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -12.420204423222321    |
| train_0/current_q         | -6.109398030769593     |
| train_0/fw_bonus          | -0.999318365752697     |
| train_0/fw_loss           | 0.00018636825152498204 |
| train_0/mu_grads          | -0.1370531652122736    |
| train_0/mu_grads_std      | 0.6661071434617043     |
| train_0/mu_loss           | 5.873361833260394      |
| train_0/next_q            | -5.704590381482051     |
| train_0/q_grads           | 0.041526241693645716   |
| train_0/q_grads_std       | 0.49842038974165914    |
| train_0/q_loss            | 0.5116165948208556     |
| train_0/reward            | -0.7660588395443483    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1381591796875        |
| train_0/target_q          | -6.04055388894424      |
| train_1/avg_q             | -15.15284789291654     |
| train_1/current_q         | -12.216230235797346    |
| train_1/fw_bonus          | -0.9991669669747353    |
| train_1/fw_loss           | 0.0011146494318381884  |
| train_1/mu_grads          | -0.06918595265597105   |
| train_1/mu_grads_std      | 0.6398500978946686     |
| train_1/mu_loss           | 12.46006951623311      |
| train_1/n_subgoals        | 1914.0                 |
| train_1/next_q            | -12.26145195058005     |
| train_1/q_grads           | -0.07668808083981275   |
| train_1/q_grads_std       | 0.8537502810359001     |
| train_1/q_loss            | 4.4800514085701035     |
| train_1/reward            | -1.8539055119108525    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006787109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4320794148380355     |
| train_1/target_q          | -12.324248349859761    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.21999999999999997
Training epoch 55
Time for epoch 55: 1063.88. Rollout time: 648.26, Training time: 415.28
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 3070286.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.24                   |
| test_0/avg_q              | -1.3174870406120902    |
| test_1/avg_q              | -13.70377175501233     |
| test_1/n_subgoals         | 8008.0                 |
| test_1/subgoal_succ_rate  | 0.9797702297702298     |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.61                   |
| train_0/avg_q             | -12.855505987056302    |
| train_0/current_q         | -5.973021227143045     |
| train_0/fw_bonus          | -0.9993275359272957    |
| train_0/fw_loss           | 0.00018392830206721557 |
| train_0/mu_grads          | -0.1390889972448349    |
| train_0/mu_grads_std      | 0.6689529165625572     |
| train_0/mu_loss           | 5.745970453223305      |
| train_0/next_q            | -5.563103361533334     |
| train_0/q_grads           | 0.04145189868286252    |
| train_0/q_grads_std       | 0.5046820595860482     |
| train_0/q_loss            | 0.4885560901722788     |
| train_0/reward            | -0.7707120108705567    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.145458984375         |
| train_0/target_q          | -5.924353080660643     |
| train_1/avg_q             | -15.3654909952129      |
| train_1/current_q         | -10.86511978856332     |
| train_1/fw_bonus          | -0.999388524889946     |
| train_1/fw_loss           | 0.0010631524768541568  |
| train_1/mu_grads          | -0.07154629826545715   |
| train_1/mu_grads_std      | 0.6403830647468567     |
| train_1/mu_loss           | 10.83172291183473      |
| train_1/n_subgoals        | 1836.0                 |
| train_1/next_q            | -10.585804339852038    |
| train_1/q_grads           | -0.08181465193629264   |
| train_1/q_grads_std       | 0.863786718249321      |
| train_1/q_loss            | 4.057374377473938      |
| train_1/reward            | -1.8720517252739228    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006787109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3311546840958606     |
| train_1/target_q          | -10.933916200338114    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.19
Training epoch 56
Time for epoch 56: 989.57. Rollout time: 589.17, Training time: 400.11
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 3118275.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.36                   |
| test_0/avg_q              | -1.1969984706920194    |
| test_1/avg_q              | -9.401286442236348     |
| test_1/n_subgoals         | 4420.0                 |
| test_1/subgoal_succ_rate  | 0.9468325791855203     |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -11.826892145342013    |
| train_0/current_q         | -5.820829530860869     |
| train_0/fw_bonus          | -0.9993091925978661    |
| train_0/fw_loss           | 0.00018881238320318517 |
| train_0/mu_grads          | -0.14189721271395683   |
| train_0/mu_grads_std      | 0.6731202185153962     |
| train_0/mu_loss           | 5.565176546190188      |
| train_0/next_q            | -5.4156577282303955    |
| train_0/q_grads           | 0.041478111408650875   |
| train_0/q_grads_std       | 0.511360077559948      |
| train_0/q_loss            | 0.5053161133820655     |
| train_0/reward            | -0.7635846192082681    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1414306640625        |
| train_0/target_q          | -5.777958480326559     |
| train_1/avg_q             | -15.285833873734315    |
| train_1/current_q         | -11.161302512341692    |
| train_1/fw_bonus          | -0.9992302343249321    |
| train_1/fw_loss           | 0.0010999451740644872  |
| train_1/mu_grads          | -0.07256754767149687   |
| train_1/mu_grads_std      | 0.6423611685633659     |
| train_1/mu_loss           | 11.143343056473        |
| train_1/n_subgoals        | 1719.0                 |
| train_1/next_q            | -10.984005164252537    |
| train_1/q_grads           | -0.08217497374862433   |
| train_1/q_grads_std       | 0.8666238382458686     |
| train_1/q_loss            | 4.5933687957864775     |
| train_1/reward            | -1.8628385654745216    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0065185546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3426410703897615     |
| train_1/target_q          | -11.216976766603398    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.27
Training epoch 57
Time for epoch 57: 1041.43. Rollout time: 626.92, Training time: 414.29
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 3175546.0              |
| test/episodes             | 1450.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.9022251648319751    |
| test_1/avg_q              | -6.950062118580001     |
| test_1/n_subgoals         | 1658.0                 |
| test_1/subgoal_succ_rate  | 0.6188178528347407     |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.64                   |
| train_0/avg_q             | -10.041514791270616    |
| train_0/current_q         | -5.697789488880859     |
| train_0/fw_bonus          | -0.9992688685655594    |
| train_0/fw_loss           | 0.00019953806331614033 |
| train_0/mu_grads          | -0.14317769035696984   |
| train_0/mu_grads_std      | 0.6752791255712509     |
| train_0/mu_loss           | 5.455922472969993      |
| train_0/next_q            | -5.284058383822826     |
| train_0/q_grads           | 0.041266781836748125   |
| train_0/q_grads_std       | 0.5156629115343094     |
| train_0/q_loss            | 0.5177350129728001     |
| train_0/reward            | -0.7666507139489113    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1231201171875        |
| train_0/target_q          | -5.635746333394492     |
| train_1/avg_q             | -12.357313808833034    |
| train_1/current_q         | -10.468781690419979    |
| train_1/fw_bonus          | -0.9991549700498581    |
| train_1/fw_loss           | 0.0011174377170391381  |
| train_1/mu_grads          | -0.07342553343623877   |
| train_1/mu_grads_std      | 0.6465175747871399     |
| train_1/mu_loss           | 10.261454059053603     |
| train_1/n_subgoals        | 1901.0                 |
| train_1/next_q            | -10.089614518431977    |
| train_1/q_grads           | -0.08293743133544922   |
| train_1/q_grads_std       | 0.8724061936140061     |
| train_1/q_loss            | 6.063533892005795      |
| train_1/reward            | -1.8862023164703714    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0069091796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35981062598632296    |
| train_1/target_q          | -10.522357198385643    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 58
Time for epoch 58: 1114.59. Rollout time: 711.01, Training time: 403.42
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 3238090.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.5052886655992703    |
| test_1/avg_q              | -14.144279382931147    |
| test_1/n_subgoals         | 2323.0                 |
| test_1/subgoal_succ_rate  | 0.7765820060266896     |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -9.212324896884782     |
| train_0/current_q         | -4.997457523235034     |
| train_0/fw_bonus          | -0.9992449805140495    |
| train_0/fw_loss           | 0.00020589266241586302 |
| train_0/mu_grads          | -0.14213626123964787   |
| train_0/mu_grads_std      | 0.6775752693414688     |
| train_0/mu_loss           | 4.83931203570892       |
| train_0/next_q            | -4.626908588173378     |
| train_0/q_grads           | 0.0408757708966732     |
| train_0/q_grads_std       | 0.5179974272847175     |
| train_0/q_loss            | 0.8068474957355736     |
| train_0/reward            | -0.7693913252765924    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.139453125            |
| train_0/target_q          | -4.8995271369563085    |
| train_1/avg_q             | -12.359750264948644    |
| train_1/current_q         | -10.782357311502924    |
| train_1/fw_bonus          | -0.9989516630768775    |
| train_1/fw_loss           | 0.0011646908038528635  |
| train_1/mu_grads          | -0.07574284598231315   |
| train_1/mu_grads_std      | 0.6502267003059388     |
| train_1/mu_loss           | 10.774726552679851     |
| train_1/n_subgoals        | 1999.0                 |
| train_1/next_q            | -10.528483289585356    |
| train_1/q_grads           | -0.08406766280531883   |
| train_1/q_grads_std       | 0.8824311479926109     |
| train_1/q_loss            | 6.255725963888895      |
| train_1/reward            | -1.9151737060561573    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00673828125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.208104052026013      |
| train_1/target_q          | -10.874156852015142    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18
Training epoch 59
Time for epoch 59: 841.60. Rollout time: 509.84, Training time: 331.61
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 3294218.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -0.9267990163194127    |
| test_1/avg_q              | -9.105609082394945     |
| test_1/n_subgoals         | 650.0                  |
| test_1/subgoal_succ_rate  | 0.003076923076923077   |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -9.315454884016837     |
| train_0/current_q         | -5.6114252446197765    |
| train_0/fw_bonus          | -0.9992062628269196    |
| train_0/fw_loss           | 0.00021619701146846637 |
| train_0/mu_grads          | -0.14375634640455245   |
| train_0/mu_grads_std      | 0.6808682203292846     |
| train_0/mu_loss           | 5.368388951723283      |
| train_0/next_q            | -5.217530842486473     |
| train_0/q_grads           | 0.0415594476275146     |
| train_0/q_grads_std       | 0.5225049123167992     |
| train_0/q_loss            | 0.5612229502606205     |
| train_0/reward            | -0.7709563509422879    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.096533203125         |
| train_0/target_q          | -5.567899873362334     |
| train_1/avg_q             | -13.189708106064325    |
| train_1/current_q         | -10.592587509807888    |
| train_1/fw_bonus          | -0.9990876540541649    |
| train_1/fw_loss           | 0.0011330857625580393  |
| train_1/mu_grads          | -0.07547896374017      |
| train_1/mu_grads_std      | 0.6550091594457627     |
| train_1/mu_loss           | 10.551662598061728     |
| train_1/n_subgoals        | 1714.0                 |
| train_1/next_q            | -10.389622376048004    |
| train_1/q_grads           | -0.08475554045289754   |
| train_1/q_grads_std       | 0.888020695745945      |
| train_1/q_loss            | 8.360193347561196      |
| train_1/reward            | -1.9405861204435495    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0072021484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25787631271878647    |
| train_1/target_q          | -10.735602215435703    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13
Training epoch 60
Time for epoch 60: 775.49. Rollout time: 493.02, Training time: 282.37
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 3353256.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.3239482764537374    |
| test_1/avg_q              | -14.286607076052631    |
| test_1/n_subgoals         | 957.0                  |
| test_1/subgoal_succ_rate  | 0.3928944618599791     |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -9.102715723098077     |
| train_0/current_q         | -5.655693157527662     |
| train_0/fw_bonus          | -0.999240729212761     |
| train_0/fw_loss           | 0.00020702555193565785 |
| train_0/mu_grads          | -0.14607755690813065   |
| train_0/mu_grads_std      | 0.6842299252748489     |
| train_0/mu_loss           | 5.4000852630621905     |
| train_0/next_q            | -5.247848199503936     |
| train_0/q_grads           | 0.04228977663442492    |
| train_0/q_grads_std       | 0.5256545260548592     |
| train_0/q_loss            | 0.6098615102059889     |
| train_0/reward            | -0.7720636008900328    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1369873046875        |
| train_0/target_q          | -5.589069055243233     |
| train_1/avg_q             | -12.896469832172762    |
| train_1/current_q         | -11.113848838722975    |
| train_1/fw_bonus          | -0.9988409519195557    |
| train_1/fw_loss           | 0.001190421829232946   |
| train_1/mu_grads          | -0.0759189309552312    |
| train_1/mu_grads_std      | 0.6593656733632087     |
| train_1/mu_loss           | 11.298662875907828     |
| train_1/n_subgoals        | 1902.0                 |
| train_1/next_q            | -11.016782862129123    |
| train_1/q_grads           | -0.086830466799438     |
| train_1/q_grads_std       | 0.8953964546322822     |
| train_1/q_loss            | 6.236510564024266      |
| train_1/reward            | -2.026803744142671     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.007763671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25920084121976866    |
| train_1/target_q          | -11.233819627741749    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 61
Time for epoch 61: 754.90. Rollout time: 475.62, Training time: 279.20
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 61                     |
| policy/steps              | 3405121.0              |
| test/episodes             | 1550.0                 |
| test/success_rate         | 0.48                   |
| test_0/avg_q              | -1.0839634224929209    |
| test_1/avg_q              | -14.393807322705955    |
| test_1/n_subgoals         | 5325.0                 |
| test_1/subgoal_succ_rate  | 0.96                   |
| train/episodes            | 6200.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -9.371703886493963     |
| train_0/current_q         | -4.9197014614794625    |
| train_0/fw_bonus          | -0.9992594376206398    |
| train_0/fw_loss           | 0.00020204569154884665 |
| train_0/mu_grads          | -0.14717420674860476   |
| train_0/mu_grads_std      | 0.6871730521321296     |
| train_0/mu_loss           | 4.638197110312298      |
| train_0/next_q            | -4.514974114039033     |
| train_0/q_grads           | 0.041996915079653266   |
| train_0/q_grads_std       | 0.5270680487155914     |
| train_0/q_loss            | 0.6116027266842579     |
| train_0/reward            | -0.7681132015917683    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.134375               |
| train_0/target_q          | -4.8615076256375005    |
| train_1/avg_q             | -13.971827840587801    |
| train_1/current_q         | -11.922781658305363    |
| train_1/fw_bonus          | -0.9990951433777809    |
| train_1/fw_loss           | 0.00113134461134905    |
| train_1/mu_grads          | -0.07815794683992863   |
| train_1/mu_grads_std      | 0.6628826260566711     |
| train_1/mu_loss           | 12.148646629311683     |
| train_1/n_subgoals        | 1815.0                 |
| train_1/next_q            | -11.909641634733994    |
| train_1/q_grads           | -0.08882581163197756   |
| train_1/q_grads_std       | 0.9024537950754166     |
| train_1/q_loss            | 6.323156496174566      |
| train_1/reward            | -2.0608699765391068    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0059326171875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27603305785123966    |
| train_1/target_q          | -12.022252301606919    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.19
Training epoch 62
Time for epoch 62: 700.04. Rollout time: 409.71, Training time: 290.18
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 62                     |
| policy/steps              | 3452607.0              |
| test/episodes             | 1575.0                 |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.3115836908542169    |
| test_1/avg_q              | -11.060986474903345    |
| test_1/n_subgoals         | 2636.0                 |
| test_1/subgoal_succ_rate  | 0.8615326251896813     |
| train/episodes            | 6300.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -8.359428457498144     |
| train_0/current_q         | -4.452363247898324     |
| train_0/fw_bonus          | -0.999242103099823     |
| train_0/fw_loss           | 0.00020665909178205766 |
| train_0/mu_grads          | -0.1446831241250038    |
| train_0/mu_grads_std      | 0.6898102313280106     |
| train_0/mu_loss           | 4.202706908320721      |
| train_0/next_q            | -4.0751993581774535    |
| train_0/q_grads           | 0.04189645266160369    |
| train_0/q_grads_std       | 0.5254869848489762     |
| train_0/q_loss            | 0.5947333474593821     |
| train_0/reward            | -0.765710185367061     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1322021484375        |
| train_0/target_q          | -4.410253069778567     |
| train_1/avg_q             | -14.372077780877662    |
| train_1/current_q         | -11.744911958803687    |
| train_1/fw_bonus          | -0.9992520779371261    |
| train_1/fw_loss           | 0.0010948681097943335  |
| train_1/mu_grads          | -0.07962827477604151   |
| train_1/mu_grads_std      | 0.6666012898087501     |
| train_1/mu_loss           | 11.895669250578013     |
| train_1/n_subgoals        | 1630.0                 |
| train_1/next_q            | -11.696023469124176    |
| train_1/q_grads           | -0.08974501322954893   |
| train_1/q_grads_std       | 0.9079984322190284     |
| train_1/q_loss            | 6.204295639519242      |
| train_1/reward            | -2.0685447090778326    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0068115234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3098159509202454     |
| train_1/target_q          | -11.847137533634974    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.24
Training epoch 63
Time for epoch 63: 633.50. Rollout time: 346.69, Training time: 286.67
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 3494450.0              |
| test/episodes             | 1600.0                 |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.319102741408901     |
| test_1/avg_q              | -13.286917151255025    |
| test_1/n_subgoals         | 3997.0                 |
| test_1/subgoal_succ_rate  | 0.9214410808106079     |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -7.798705387298876     |
| train_0/current_q         | -4.9639283079269365    |
| train_0/fw_bonus          | -0.9991975456476212    |
| train_0/fw_loss           | 0.00021851909841643646 |
| train_0/mu_grads          | -0.1430318418890238    |
| train_0/mu_grads_std      | 0.6926039904356003     |
| train_0/mu_loss           | 4.699685422966262      |
| train_0/next_q            | -4.562577546374239     |
| train_0/q_grads           | 0.04204936735332012    |
| train_0/q_grads_std       | 0.525267131626606      |
| train_0/q_loss            | 0.5338927957305362     |
| train_0/reward            | -0.7617622747791757    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.049609375            |
| train_0/target_q          | -4.904625750877537     |
| train_1/avg_q             | -14.502962624674291    |
| train_1/current_q         | -12.238605904056081    |
| train_1/fw_bonus          | -0.9991555899381638    |
| train_1/fw_loss           | 0.0011172952144988813  |
| train_1/mu_grads          | -0.07994043137878179   |
| train_1/mu_grads_std      | 0.6721104785799981     |
| train_1/mu_loss           | 12.589386338237684     |
| train_1/n_subgoals        | 1369.0                 |
| train_1/next_q            | -12.368509922888611    |
| train_1/q_grads           | -0.09019979368895292   |
| train_1/q_grads_std       | 0.91511490046978       |
| train_1/q_loss            | 5.920480460599966      |
| train_1/reward            | -2.0983850874428756    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00654296875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3389335281227173     |
| train_1/target_q          | -12.338231800925858    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.31
Training epoch 64
Time for epoch 64: 749.50. Rollout time: 466.34, Training time: 283.02
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 3548990.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.407400739781931     |
| test_1/avg_q              | -10.882112551051312    |
| test_1/n_subgoals         | 1123.0                 |
| test_1/subgoal_succ_rate  | 0.5547640249332146     |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -7.676166672099338     |
| train_0/current_q         | -4.9167926409686835    |
| train_0/fw_bonus          | -0.9992337971925735    |
| train_0/fw_loss           | 0.00020887422469968443 |
| train_0/mu_grads          | -0.14394135773181915   |
| train_0/mu_grads_std      | 0.698419214785099      |
| train_0/mu_loss           | 4.691961358813872      |
| train_0/next_q            | -4.556788743274973     |
| train_0/q_grads           | 0.04228071048855782    |
| train_0/q_grads_std       | 0.5240950509905815     |
| train_0/q_loss            | 0.6969321811942903     |
| train_0/reward            | -0.7606360826124728    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1202392578125        |
| train_0/target_q          | -4.839383483304096     |
| train_1/avg_q             | -16.19584189078735     |
| train_1/current_q         | -11.873340807253644    |
| train_1/fw_bonus          | -0.9988310724496842    |
| train_1/fw_loss           | 0.0011927177634788676  |
| train_1/mu_grads          | -0.08148058466613292   |
| train_1/mu_grads_std      | 0.676534178853035      |
| train_1/mu_loss           | 12.031701572793057     |
| train_1/n_subgoals        | 1822.0                 |
| train_1/next_q            | -11.834932661141215    |
| train_1/q_grads           | -0.09025542866438627   |
| train_1/q_grads_std       | 0.921772351861         |
| train_1/q_loss            | 6.1304391334429225     |
| train_1/reward            | -2.122034428922416     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0064453125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27607025246981337    |
| train_1/target_q          | -11.988496368563569    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.33
Training epoch 65
Time for epoch 65: 714.75. Rollout time: 433.22, Training time: 281.42
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 65                     |
| policy/steps              | 3599798.0              |
| test/episodes             | 1650.0                 |
| test/success_rate         | 0.24                   |
| test_0/avg_q              | -1.2768675511447882    |
| test_1/avg_q              | -18.194743753474103    |
| test_1/n_subgoals         | 10040.0                |
| test_1/subgoal_succ_rate  | 0.9861553784860557     |
| train/episodes            | 6600.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -7.981231286368995     |
| train_0/current_q         | -5.281267599821062     |
| train_0/fw_bonus          | -0.9992854624986649    |
| train_0/fw_loss           | 0.00019512376093189232 |
| train_0/mu_grads          | -0.14568463303148746   |
| train_0/mu_grads_std      | 0.7008754640817643     |
| train_0/mu_loss           | 5.0497329236600805     |
| train_0/next_q            | -4.922342254894342     |
| train_0/q_grads           | 0.04234007438644767    |
| train_0/q_grads_std       | 0.5241911381483078     |
| train_0/q_loss            | 0.6618505652807178     |
| train_0/reward            | -0.7548994902241247    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1366943359375        |
| train_0/target_q          | -5.197400401813073     |
| train_1/avg_q             | -15.08452332000837     |
| train_1/current_q         | -11.866153875132934    |
| train_1/fw_bonus          | -0.9985379666090012    |
| train_1/fw_loss           | 0.0012608391902176664  |
| train_1/mu_grads          | -0.08208084739744663   |
| train_1/mu_grads_std      | 0.681839756667614      |
| train_1/mu_loss           | 12.09280202329455      |
| train_1/n_subgoals        | 1743.0                 |
| train_1/next_q            | -11.871616963861811    |
| train_1/q_grads           | -0.0904803778976202    |
| train_1/q_grads_std       | 0.9271888986229897     |
| train_1/q_loss            | 4.988738594599745      |
| train_1/reward            | -2.117017305007175     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0073974609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3304647160068847     |
| train_1/target_q          | -11.984642960262914    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.27
Training epoch 66
Time for epoch 66: 666.79. Rollout time: 378.33, Training time: 288.33
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 3645725.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -1.3566306860732544   |
| test_1/avg_q              | -13.53801122458352    |
| test_1/n_subgoals         | 4303.0                |
| test_1/subgoal_succ_rate  | 0.9312107831745294    |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.72                  |
| train_0/avg_q             | -10.098393228479194   |
| train_0/current_q         | -5.058326062384614    |
| train_0/fw_bonus          | -0.9992332547903061   |
| train_0/fw_loss           | 0.0002090153833705699 |
| train_0/mu_grads          | -0.1468950942158699   |
| train_0/mu_grads_std      | 0.7018079951405525    |
| train_0/mu_loss           | 4.896800743903432     |
| train_0/next_q            | -4.720386495441055    |
| train_0/q_grads           | 0.041618299297988416  |
| train_0/q_grads_std       | 0.5236683771014213    |
| train_0/q_loss            | 0.7185704741348499    |
| train_0/reward            | -0.7558019655731186   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1229248046875       |
| train_0/target_q          | -4.96893117877128     |
| train_1/avg_q             | -16.328060347996495   |
| train_1/current_q         | -11.567170617759226   |
| train_1/fw_bonus          | -0.9988590002059936   |
| train_1/fw_loss           | 0.0011862257932079956 |
| train_1/mu_grads          | -0.08075410425662995  |
| train_1/mu_grads_std      | 0.6865947142243385    |
| train_1/mu_loss           | 11.741802574823712    |
| train_1/n_subgoals        | 1697.0                |
| train_1/next_q            | -11.550192845524485   |
| train_1/q_grads           | -0.09084727689623832  |
| train_1/q_grads_std       | 0.9321359008550644    |
| train_1/q_loss            | 4.847596502584989     |
| train_1/reward            | -2.0535965863869934   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0070068359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4242781378903948    |
| train_1/target_q          | -11.666433521964342   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.27
Training epoch 67
Time for epoch 67: 685.27. Rollout time: 373.94, Training time: 311.19
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 3690084.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.4183075260994762    |
| test_1/avg_q              | -13.872960234823058    |
| test_1/n_subgoals         | 7079.0                 |
| test_1/subgoal_succ_rate  | 0.9662381692329425     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.77                   |
| train_0/avg_q             | -8.608270525565088     |
| train_0/current_q         | -4.905908888159014     |
| train_0/fw_bonus          | -0.9992562249302864    |
| train_0/fw_loss           | 0.00020290363536332734 |
| train_0/mu_grads          | -0.1468117531388998    |
| train_0/mu_grads_std      | 0.7002705112099648     |
| train_0/mu_loss           | 4.6437926693917655     |
| train_0/next_q            | -4.512012008394077     |
| train_0/q_grads           | 0.04144501704722643    |
| train_0/q_grads_std       | 0.5234547629952431     |
| train_0/q_loss            | 0.537562497983133      |
| train_0/reward            | -0.7565950616324699    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1416015625           |
| train_0/target_q          | -4.811076309058701     |
| train_1/avg_q             | -14.531888227792578    |
| train_1/current_q         | -11.802656334233504    |
| train_1/fw_bonus          | -0.99916902333498      |
| train_1/fw_loss           | 0.0011141697672428564  |
| train_1/mu_grads          | -0.0796493288129568    |
| train_1/mu_grads_std      | 0.6900640979409218     |
| train_1/mu_loss           | 12.109741258489473     |
| train_1/n_subgoals        | 1443.0                 |
| train_1/next_q            | -11.893717951459395    |
| train_1/q_grads           | -0.09219484366476535   |
| train_1/q_grads_std       | 0.9368842765688896     |
| train_1/q_loss            | 5.097924629472706      |
| train_1/reward            | -2.03554665263473      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0058837890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36036036036036034    |
| train_1/target_q          | -11.89823072722194     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.24
Training epoch 68
Time for epoch 68: 678.94. Rollout time: 383.94, Training time: 294.86
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 3735653.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -1.56184442795615      |
| test_1/avg_q              | -17.724737971247297    |
| test_1/n_subgoals         | 8200.0                 |
| test_1/subgoal_succ_rate  | 0.9769512195121951     |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -8.876254400048612     |
| train_0/current_q         | -4.827511176624526     |
| train_0/fw_bonus          | -0.9992403030395508    |
| train_0/fw_loss           | 0.00020713690828415564 |
| train_0/mu_grads          | -0.14574616514146327   |
| train_0/mu_grads_std      | 0.6996715530753136     |
| train_0/mu_loss           | 4.590784989563498      |
| train_0/next_q            | -4.434864264482011     |
| train_0/q_grads           | 0.04097978845238685    |
| train_0/q_grads_std       | 0.5244328156113625     |
| train_0/q_loss            | 0.5428163059041035     |
| train_0/reward            | -0.7611504102424078    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1351318359375        |
| train_0/target_q          | -4.747403207852128     |
| train_1/avg_q             | -14.157665907680864    |
| train_1/current_q         | -11.794656909908566    |
| train_1/fw_bonus          | -0.9992090538144112    |
| train_1/fw_loss           | 0.0011048691099858842  |
| train_1/mu_grads          | -0.07971170097589493   |
| train_1/mu_grads_std      | 0.6920729264616966     |
| train_1/mu_loss           | 12.241218775158497     |
| train_1/n_subgoals        | 1533.0                 |
| train_1/next_q            | -12.015033967297352    |
| train_1/q_grads           | -0.0927857244387269    |
| train_1/q_grads_std       | 0.9416898295283318     |
| train_1/q_loss            | 5.135657365233679      |
| train_1/reward            | -2.024387223658414     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0055908203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3724722765818656     |
| train_1/target_q          | -11.910676652937042    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.26
Training epoch 69
Time for epoch 69: 611.99. Rollout time: 322.96, Training time: 288.94
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 3775847.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -1.7098548586586533    |
| test_1/avg_q              | -18.012483972165708    |
| test_1/n_subgoals         | 5396.0                 |
| test_1/subgoal_succ_rate  | 0.963306152705708      |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.81                   |
| train_0/avg_q             | -9.467240090277613     |
| train_0/current_q         | -5.2762482794764995    |
| train_0/fw_bonus          | -0.9992630422115326    |
| train_0/fw_loss           | 0.00020108771313971375 |
| train_0/mu_grads          | -0.14685296416282653   |
| train_0/mu_grads_std      | 0.7020199120044708     |
| train_0/mu_loss           | 5.064465645200871      |
| train_0/next_q            | -4.899292160194067     |
| train_0/q_grads           | 0.041495104972273114   |
| train_0/q_grads_std       | 0.5273703321814537     |
| train_0/q_loss            | 0.6216437874704568     |
| train_0/reward            | -0.7597278710542014    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.131640625            |
| train_0/target_q          | -5.180547935459527     |
| train_1/avg_q             | -14.544280046686858    |
| train_1/current_q         | -11.056313996504919    |
| train_1/fw_bonus          | -0.9992436036467552    |
| train_1/fw_loss           | 0.001096839537785854   |
| train_1/mu_grads          | -0.07973675709217787   |
| train_1/mu_grads_std      | 0.6940265163779259     |
| train_1/mu_loss           | 11.362651128841167     |
| train_1/n_subgoals        | 1431.0                 |
| train_1/next_q            | -11.109218708103084    |
| train_1/q_grads           | -0.09687337838113308   |
| train_1/q_grads_std       | 0.9474237486720085     |
| train_1/q_loss            | 4.935239185273697      |
| train_1/reward            | -1.9685120704471046    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.006640625            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4444444444444444     |
| train_1/target_q          | -11.153315062952114    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.28
Training epoch 70
Time for epoch 70: 614.29. Rollout time: 327.67, Training time: 286.53
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 3815505.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.4                    |
| test_0/avg_q              | -1.874443481993456     |
| test_1/avg_q              | -19.175179284910815    |
| test_1/n_subgoals         | 5726.0                 |
| test_1/subgoal_succ_rate  | 0.9708347886831994     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.79                   |
| train_0/avg_q             | -10.040677962548525    |
| train_0/current_q         | -4.975209973995807     |
| train_0/fw_bonus          | -0.999237097799778     |
| train_0/fw_loss           | 0.00020799233279831242 |
| train_0/mu_grads          | -0.14509319327771664   |
| train_0/mu_grads_std      | 0.7053714632987976     |
| train_0/mu_loss           | 4.726103036853544      |
| train_0/next_q            | -4.5805050658854904    |
| train_0/q_grads           | 0.041229195706546304   |
| train_0/q_grads_std       | 0.5311329811811447     |
| train_0/q_loss            | 0.5656214366763106     |
| train_0/reward            | -0.7576889130486961    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.148291015625         |
| train_0/target_q          | -4.883395615631055     |
| train_1/avg_q             | -15.289581099036432    |
| train_1/current_q         | -10.395817879763785    |
| train_1/fw_bonus          | -0.9990933254361153    |
| train_1/fw_loss           | 0.0011317675263853744  |
| train_1/mu_grads          | -0.08177077453583478   |
| train_1/mu_grads_std      | 0.695185762643814      |
| train_1/mu_loss           | 10.672193477828818     |
| train_1/n_subgoals        | 1452.0                 |
| train_1/next_q            | -10.417563963532093    |
| train_1/q_grads           | -0.09767494592815637   |
| train_1/q_grads_std       | 0.9520633205771446     |
| train_1/q_loss            | 4.6500394723340515     |
| train_1/reward            | -1.9138358289492317    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0061279296875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4290633608815427     |
| train_1/target_q          | -10.505328242717754    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.30000000000000004
Training epoch 71
Time for epoch 71: 8279.48. Rollout time: 7824.80, Training time: 454.49
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|105
-----------------------------------------------------
| epoch                     | 71                    |
| policy/steps              | 3855452.0             |
| test/episodes             | 1800.0                |
| test/success_rate         | 0.36                  |
| test_0/avg_q              | -1.1515326213019215   |
| test_1/avg_q              | -13.962830592573473   |
| test_1/n_subgoals         | 5946.0                |
| test_1/subgoal_succ_rate  | 0.9714093508240834    |
| train/episodes            | 7200.0                |
| train/success_rate        | 0.81                  |
| train_0/avg_q             | -9.972706920643631    |
| train_0/current_q         | -5.304841271823863    |
| train_0/fw_bonus          | -0.9992120906710624   |
| train_0/fw_loss           | 0.0002146473285392858 |
| train_0/mu_grads          | -0.14571357183158398  |
| train_0/mu_grads_std      | 0.7083932116627694    |
| train_0/mu_loss           | 5.043631448843269     |
| train_0/next_q            | -4.883905748847155    |
| train_0/q_grads           | 0.04123865570873022   |
| train_0/q_grads_std       | 0.5348542407155037    |
| train_0/q_loss            | 0.5133774615365687    |
| train_0/reward            | -0.7630659614009346   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1112060546875       |
| train_0/target_q          | -5.220035516914777    |
| train_1/avg_q             | -15.529894238126891   |
| train_1/current_q         | -10.727003740662116   |
| train_1/fw_bonus          | -0.9991949990391731   |
| train_1/fw_loss           | 0.00110813348001102   |
| train_1/mu_grads          | -0.08403832595795394  |
| train_1/mu_grads_std      | 0.6974266573786736    |
| train_1/mu_loss           | 11.003940246402184    |
| train_1/n_subgoals        | 1455.0                |
| train_1/next_q            | -10.836133163188384   |
| train_1/q_grads           | -0.09872379936277867  |
| train_1/q_grads_std       | 0.9573035597801208    |
| train_1/q_loss            | 5.076606699796545     |
| train_1/reward            | -1.8592592006130872   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0064208984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.41580756013745707   |
| train_1/target_q          | -10.820981250899468   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.33999999999999997
Training epoch 72
