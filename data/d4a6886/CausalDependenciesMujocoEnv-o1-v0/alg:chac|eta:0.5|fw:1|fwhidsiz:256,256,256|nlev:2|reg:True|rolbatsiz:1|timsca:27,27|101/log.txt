Starting process id: 85751
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.5
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fd8d957b710>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 558.37. Rollout time: 279.90, Training time: 278.42
Evaluating epoch 0
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 63913.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.9046954892411962    |
| test_1/avg_q              | -10.945252490212999    |
| test_1/n_subgoals         | 4182.0                 |
| test_1/subgoal_succ_rate  | 0.8787661406025825     |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -1.708049365552305     |
| train_0/current_q         | -2.715415751221212     |
| train_0/fw_bonus          | -0.9990147203207016    |
| train_0/fw_loss           | 0.00022956586981308645 |
| train_0/mu_grads          | 0.005015999532770365   |
| train_0/mu_grads_std      | 0.17529342584311963    |
| train_0/mu_loss           | 2.5054557797953696     |
| train_0/next_q            | -2.4968615881683283    |
| train_0/q_grads           | 0.02909796084277332    |
| train_0/q_grads_std       | 0.15705337859690188    |
| train_0/q_loss            | 0.35753069183828273    |
| train_0/reward            | -0.7142046323577234    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00029296875          |
| train_0/target_q          | -2.664880544226358     |
| train_1/avg_q             | -4.7803108511183785    |
| train_1/current_q         | -7.447665305670034     |
| train_1/fw_bonus          | -0.9965246051549912    |
| train_1/fw_loss           | 0.0014766633772524073  |
| train_1/mu_grads          | 0.014070666045881808   |
| train_1/mu_grads_std      | 0.18142998442053795    |
| train_1/mu_loss           | 6.914374929999552      |
| train_1/n_subgoals        | 2681.0                 |
| train_1/next_q            | -7.544020988297424     |
| train_1/q_grads           | 0.0018901905248640105  |
| train_1/q_grads_std       | 0.24408817216753959    |
| train_1/q_loss            | 6.248072465556795      |
| train_1/reward            | -1.6232256824638172    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001806640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.39537486012681833    |
| train_1/target_q          | -7.344051739954454     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_0.pkl ...
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 494.31. Rollout time: 270.07, Training time: 224.19
Evaluating epoch 1
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 127835.0              |
| test/episodes             | 50.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.777298173126632    |
| test_1/avg_q              | -11.820473446071171   |
| test_1/n_subgoals         | 2081.0                |
| test_1/subgoal_succ_rate  | 0.735223450264296     |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.06                  |
| train_0/avg_q             | -3.4442365671891033   |
| train_0/current_q         | -3.255966360899879    |
| train_0/fw_bonus          | -0.9987274646759033   |
| train_0/fw_loss           | 0.0002951284212031169 |
| train_0/mu_grads          | 0.0013617079617688431 |
| train_0/mu_grads_std      | 0.20521883554756642   |
| train_0/mu_loss           | 3.0730458793695616    |
| train_0/next_q            | -3.0612381108341635   |
| train_0/q_grads           | 0.028394500678405165  |
| train_0/q_grads_std       | 0.1877467181533575    |
| train_0/q_loss            | 0.421753761611902     |
| train_0/reward            | -0.7163193008222152   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000390625           |
| train_0/target_q          | -3.1811217170971227   |
| train_1/avg_q             | -9.841849799301135    |
| train_1/current_q         | -7.877120060970141    |
| train_1/fw_bonus          | -0.9945671036839485   |
| train_1/fw_loss           | 0.0018765962595352903 |
| train_1/mu_grads          | 0.011556738312356174  |
| train_1/mu_grads_std      | 0.20816898457705973   |
| train_1/mu_loss           | 7.5893109178272935    |
| train_1/n_subgoals        | 2580.0                |
| train_1/next_q            | -7.66630017974888     |
| train_1/q_grads           | -0.005304526514373719 |
| train_1/q_grads_std       | 0.2836358115077019    |
| train_1/q_loss            | 4.758510415931668     |
| train_1/reward            | -1.640838242881       |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00283203125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4077519379844961    |
| train_1/target_q          | -7.81829258508874     |
-----------------------------------------------------
Training epoch 2
Time for epoch 2: 421.34. Rollout time: 192.10, Training time: 229.20
Evaluating epoch 2
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 179647.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.7744662442723766    |
| test_1/avg_q              | -13.06173761644195     |
| test_1/n_subgoals         | 2175.0                 |
| test_1/subgoal_succ_rate  | 0.7177011494252874     |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -2.724542791541067     |
| train_0/current_q         | -2.9661701132424683    |
| train_0/fw_bonus          | -0.9987974762916565    |
| train_0/fw_loss           | 0.00027915062273677906 |
| train_0/mu_grads          | -0.003738487750524655  |
| train_0/mu_grads_std      | 0.234557481482625      |
| train_0/mu_loss           | 2.811173622095075      |
| train_0/next_q            | -2.7652703855592558    |
| train_0/q_grads           | 0.02677332516759634    |
| train_0/q_grads_std       | 0.1946573991328478     |
| train_0/q_loss            | 0.3906475053761384     |
| train_0/reward            | -0.7184172926405153    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0005126953125        |
| train_0/target_q          | -2.9052605377543195    |
| train_1/avg_q             | -12.360244367401306    |
| train_1/current_q         | -8.301768839533917     |
| train_1/fw_bonus          | -0.9937883853912354    |
| train_1/fw_loss           | 0.00203569688310381    |
| train_1/mu_grads          | 0.008301371685229242   |
| train_1/mu_grads_std      | 0.24393512345850468    |
| train_1/mu_loss           | 8.048624582862566      |
| train_1/n_subgoals        | 2654.0                 |
| train_1/next_q            | -8.119118281113424     |
| train_1/q_grads           | -0.006978761090431362  |
| train_1/q_grads_std       | 0.30213832929730416    |
| train_1/q_loss            | 4.676404716935574      |
| train_1/reward            | -1.5517281758286117    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0026611328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.6386586284853052     |
| train_1/target_q          | -8.299267692681815     |
------------------------------------------------------
Training epoch 3
Time for epoch 3: 468.60. Rollout time: 239.87, Training time: 228.70
Evaluating epoch 3
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 237111.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.7109129009983883    |
| test_1/avg_q              | -13.36752024568257     |
| test_1/n_subgoals         | 6324.0                 |
| test_1/subgoal_succ_rate  | 0.9478178368121443     |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -2.5328917827943713    |
| train_0/current_q         | -2.6155740735378217    |
| train_0/fw_bonus          | -0.9989506810903549    |
| train_0/fw_loss           | 0.0002441862387058791  |
| train_0/mu_grads          | -0.0067587985657155515 |
| train_0/mu_grads_std      | 0.2556404538452625     |
| train_0/mu_loss           | 2.438056509182284      |
| train_0/next_q            | -2.399618255856342     |
| train_0/q_grads           | 0.023434518184512854   |
| train_0/q_grads_std       | 0.2024573225528002     |
| train_0/q_loss            | 0.37176304086000045    |
| train_0/reward            | -0.7132082468619046    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000927734375         |
| train_0/target_q          | -2.547333651109815     |
| train_1/avg_q             | -14.067444006568628    |
| train_1/current_q         | -8.814081459612094     |
| train_1/fw_bonus          | -0.9936293840408326    |
| train_1/fw_loss           | 0.0020681801688624546  |
| train_1/mu_grads          | 0.003115042217541486   |
| train_1/mu_grads_std      | 0.2877718165516853     |
| train_1/mu_loss           | 8.481880156035142      |
| train_1/n_subgoals        | 2679.0                 |
| train_1/next_q            | -8.70449903417821      |
| train_1/q_grads           | -0.004010054911486804  |
| train_1/q_grads_std       | 0.32426201179623604    |
| train_1/q_loss            | 5.407635017957796      |
| train_1/reward            | -1.5330817853217014    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0027587890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.5139977603583427     |
| train_1/target_q          | -8.825071064997289     |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 4
Time for epoch 4: 399.70. Rollout time: 165.93, Training time: 233.72
Evaluating epoch 4
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 280049.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.8245797505424       |
| test_1/avg_q              | -10.46176264795745     |
| test_1/n_subgoals         | 6097.0                 |
| test_1/subgoal_succ_rate  | 0.9439068394292275     |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.2675294139303244    |
| train_0/current_q         | -2.6523740984317534    |
| train_0/fw_bonus          | -0.9990682914853096    |
| train_0/fw_loss           | 0.00021734183646913153 |
| train_0/mu_grads          | -0.012305446295067668  |
| train_0/mu_grads_std      | 0.275389052182436      |
| train_0/mu_loss           | 2.4448823861875137     |
| train_0/next_q            | -2.4104290950212026    |
| train_0/q_grads           | 0.022722408547997473   |
| train_0/q_grads_std       | 0.20916955061256887    |
| train_0/q_loss            | 0.3267724947055139     |
| train_0/reward            | -0.7136454748761025    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0004150390625        |
| train_0/target_q          | -2.585461548381596     |
| train_1/avg_q             | -14.126853656313804    |
| train_1/current_q         | -8.781875327342195     |
| train_1/fw_bonus          | -0.9933964505791664    |
| train_1/fw_loss           | 0.0021157729730475693  |
| train_1/mu_grads          | 0.0004205715500575025  |
| train_1/mu_grads_std      | 0.3161397226154804     |
| train_1/mu_loss           | 8.381995508876283      |
| train_1/n_subgoals        | 2694.0                 |
| train_1/next_q            | -8.680443532096259     |
| train_1/q_grads           | -0.002232304512290284  |
| train_1/q_grads_std       | 0.3445604518055916     |
| train_1/q_loss            | 5.678522919621491      |
| train_1/reward            | -1.4905092576125754    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0024169921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7435040831477358     |
| train_1/target_q          | -8.794889954689282     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 5
Time for epoch 5: 374.25. Rollout time: 161.03, Training time: 213.18
Evaluating epoch 5
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 326134.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.3384741778722484    |
| test_1/avg_q              | -11.997267876660192    |
| test_1/n_subgoals         | 2897.0                 |
| test_1/subgoal_succ_rate  | 0.8277528477735588     |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.043100505741937     |
| train_0/current_q         | -2.130668339945038     |
| train_0/fw_bonus          | -0.999091961979866     |
| train_0/fw_loss           | 0.00021193924876570236 |
| train_0/mu_grads          | -0.011465302109718323  |
| train_0/mu_grads_std      | 0.2942681089043617     |
| train_0/mu_loss           | 1.9598537608924929     |
| train_0/next_q            | -1.9219041882111632    |
| train_0/q_grads           | 0.021721070865169168   |
| train_0/q_grads_std       | 0.21227376945316792    |
| train_0/q_loss            | 0.41192334019455856    |
| train_0/reward            | -0.7115454942424548    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0007080078125        |
| train_0/target_q          | -2.0672423458763958    |
| train_1/avg_q             | -14.087871619847505    |
| train_1/current_q         | -8.44338417204094      |
| train_1/fw_bonus          | -0.9912711530923843    |
| train_1/fw_loss           | 0.0025499857729300857  |
| train_1/mu_grads          | -0.0010835650726221501 |
| train_1/mu_grads_std      | 0.34048409685492514    |
| train_1/mu_loss           | 8.081786463461277      |
| train_1/n_subgoals        | 2697.0                 |
| train_1/next_q            | -8.25342204429766      |
| train_1/q_grads           | -0.002719385240925476  |
| train_1/q_grads_std       | 0.3617593593895435     |
| train_1/q_loss            | 4.536237221620043      |
| train_1/reward            | -1.4101009120800883    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018798828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.6722284019280682     |
| train_1/target_q          | -8.485318319798518     |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 6
Time for epoch 6: 316.26. Rollout time: 101.16, Training time: 215.06
Evaluating epoch 6
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 362161.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.202516277551381     |
| test_1/avg_q              | -18.51697302860558     |
| test_1/n_subgoals         | 1569.0                 |
| test_1/subgoal_succ_rate  | 0.6003824091778203     |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.04                   |
| train_0/avg_q             | -1.6306409695774664    |
| train_0/current_q         | -2.386023730347595     |
| train_0/fw_bonus          | -0.9991966411471367    |
| train_0/fw_loss           | 0.0001880487470771186  |
| train_0/mu_grads          | -0.01529028641525656   |
| train_0/mu_grads_std      | 0.3106231026351452     |
| train_0/mu_loss           | 2.2671261159328155     |
| train_0/next_q            | -2.2064725018106106    |
| train_0/q_grads           | 0.02134433975443244    |
| train_0/q_grads_std       | 0.21278323009610176    |
| train_0/q_loss            | 0.41724839667043134    |
| train_0/reward            | -0.7105846491576813    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0008544921875        |
| train_0/target_q          | -2.3141171123299005    |
| train_1/avg_q             | -16.49795209998269     |
| train_1/current_q         | -8.508829235770648     |
| train_1/fw_bonus          | -0.9912679776549339    |
| train_1/fw_loss           | 0.0025506357604172082  |
| train_1/mu_grads          | -0.0026999642548616977 |
| train_1/mu_grads_std      | 0.347079112380743      |
| train_1/mu_loss           | 8.289710746792187      |
| train_1/n_subgoals        | 2637.0                 |
| train_1/next_q            | -8.359635906321962     |
| train_1/q_grads           | -0.0033626743592321874 |
| train_1/q_grads_std       | 0.3730475425720215     |
| train_1/q_loss            | 3.9194521890457934     |
| train_1/reward            | -1.3142741254763677    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023193359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8357982555934774     |
| train_1/target_q          | -8.544810709027308     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 7
Time for epoch 7: 350.83. Rollout time: 135.74, Training time: 215.06
Evaluating epoch 7
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 402791.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.7392660925890775    |
| test_1/avg_q              | -15.31686265129984     |
| test_1/n_subgoals         | 8788.0                 |
| test_1/subgoal_succ_rate  | 0.9717796995903505     |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.07                   |
| train_0/avg_q             | -2.5504576402337067    |
| train_0/current_q         | -2.3071485261780516    |
| train_0/fw_bonus          | -0.9992742523550987    |
| train_0/fw_loss           | 0.00017034081447491188 |
| train_0/mu_grads          | -0.020984010817483068  |
| train_0/mu_grads_std      | 0.3212453737854958     |
| train_0/mu_loss           | 2.105193135964498      |
| train_0/next_q            | -2.068160901712242     |
| train_0/q_grads           | 0.02218600632622838    |
| train_0/q_grads_std       | 0.22339132837951184    |
| train_0/q_loss            | 0.31543723274691304    |
| train_0/reward            | -0.7070223689079285    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0028564453125        |
| train_0/target_q          | -2.2602191431908247    |
| train_1/avg_q             | -18.981119628298348    |
| train_1/current_q         | -8.414655827811515     |
| train_1/fw_bonus          | -0.9926107347011566    |
| train_1/fw_loss           | 0.002276300877565518   |
| train_1/mu_grads          | -0.007389122049789876  |
| train_1/mu_grads_std      | 0.36317744478583336    |
| train_1/mu_loss           | 8.241220268859601      |
| train_1/n_subgoals        | 2605.0                 |
| train_1/next_q            | -8.252477691348734     |
| train_1/q_grads           | -0.005003149132244289  |
| train_1/q_grads_std       | 0.3883423015475273     |
| train_1/q_loss            | 3.203427415451497      |
| train_1/reward            | -1.2619669843712473    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00244140625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7439539347408829     |
| train_1/target_q          | -8.450129375663904     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 8
Time for epoch 8: 304.43. Rollout time: 96.44, Training time: 207.95
Evaluating epoch 8
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 437559.0              |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.7132576979170209   |
| test_1/avg_q              | -20.21781532688444    |
| test_1/n_subgoals         | 10968.0               |
| test_1/subgoal_succ_rate  | 0.9829504011670314    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -2.6135656427351956   |
| train_0/current_q         | -2.359335946875899    |
| train_0/fw_bonus          | -0.9993047952651978   |
| train_0/fw_loss           | 0.0001633636111364467 |
| train_0/mu_grads          | -0.027965917019173503 |
| train_0/mu_grads_std      | 0.3396904207766056    |
| train_0/mu_loss           | 2.1848940938421335    |
| train_0/next_q            | -2.1229603286453873   |
| train_0/q_grads           | 0.02207613275386393   |
| train_0/q_grads_std       | 0.23438885770738124   |
| train_0/q_loss            | 0.3466913842900033    |
| train_0/reward            | -0.7042300370856538   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020751953125       |
| train_0/target_q          | -2.298497402980513    |
| train_1/avg_q             | -19.869593903713852   |
| train_1/current_q         | -8.753887023411973    |
| train_1/fw_bonus          | -0.99389908015728     |
| train_1/fw_loss           | 0.0020130786986555906 |
| train_1/mu_grads          | -0.012619574391283094 |
| train_1/mu_grads_std      | 0.3920282952487469    |
| train_1/mu_loss           | 8.6381803026901       |
| train_1/n_subgoals        | 2665.0                |
| train_1/next_q            | -8.620737900189397    |
| train_1/q_grads           | -0.006737047724891454 |
| train_1/q_grads_std       | 0.40156357660889624   |
| train_1/q_loss            | 2.931476000657552     |
| train_1/reward            | -1.1900281563575845   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0019287109375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.825140712945591     |
| train_1/target_q          | -8.799475854479144    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 9
Time for epoch 9: 349.51. Rollout time: 147.49, Training time: 201.99
Evaluating epoch 9
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 480550.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -3.465334019597961     |
| test_1/avg_q              | -20.142508377572558    |
| test_1/n_subgoals         | 6013.0                 |
| test_1/subgoal_succ_rate  | 0.9687344087809746     |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.05                   |
| train_0/avg_q             | -3.0648046198893115    |
| train_0/current_q         | -2.37439171874093      |
| train_0/fw_bonus          | -0.9993148759007454    |
| train_0/fw_loss           | 0.00016106629482237622 |
| train_0/mu_grads          | -0.029908248409628867  |
| train_0/mu_grads_std      | 0.35214644148945806    |
| train_0/mu_loss           | 2.0606423641262346     |
| train_0/next_q            | -2.006250986955877     |
| train_0/q_grads           | 0.024873656360432504   |
| train_0/q_grads_std       | 0.24927820824086666    |
| train_0/q_loss            | 0.1723114436149172     |
| train_0/reward            | -0.7081657341943355    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0060302734375        |
| train_0/target_q          | -2.3542281094143727    |
| train_1/avg_q             | -19.890324699135377    |
| train_1/current_q         | -8.66230814645588      |
| train_1/fw_bonus          | -0.9927318453788757    |
| train_1/fw_loss           | 0.00225155571824871    |
| train_1/mu_grads          | -0.01740965894423425   |
| train_1/mu_grads_std      | 0.42070271372795104    |
| train_1/mu_loss           | 8.524010647029542      |
| train_1/n_subgoals        | 2626.0                 |
| train_1/next_q            | -8.52629187033828      |
| train_1/q_grads           | -0.009155605337582529  |
| train_1/q_grads_std       | 0.41151284277439115    |
| train_1/q_loss            | 2.7730802344302306     |
| train_1/reward            | -1.158402055073384     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002294921875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7098248286367098     |
| train_1/target_q          | -8.718567713723603     |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 10
Time for epoch 10: 390.19. Rollout time: 178.04, Training time: 212.12
Evaluating epoch 10
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 528551.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4441362076530895    |
| test_1/avg_q              | -17.186190038800277    |
| test_1/n_subgoals         | 2004.0                 |
| test_1/subgoal_succ_rate  | 0.7015968063872255     |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.09                   |
| train_0/avg_q             | -2.4171954559719304    |
| train_0/current_q         | -2.412847863419626     |
| train_0/fw_bonus          | -0.9992682963609696    |
| train_0/fw_loss           | 0.00017169660059153103 |
| train_0/mu_grads          | -0.034085717611014844  |
| train_0/mu_grads_std      | 0.36556006222963333    |
| train_0/mu_loss           | 2.196780357460752      |
| train_0/next_q            | -2.130877092081178     |
| train_0/q_grads           | 0.027039668709039687   |
| train_0/q_grads_std       | 0.25894249603152275    |
| train_0/q_loss            | 0.27522443378395317    |
| train_0/reward            | -0.7088260393691599    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0042724609375        |
| train_0/target_q          | -2.4028344510931015    |
| train_1/avg_q             | -19.83719652140669     |
| train_1/current_q         | -8.818120689201553     |
| train_1/fw_bonus          | -0.991926272213459     |
| train_1/fw_loss           | 0.0024161412729881704  |
| train_1/mu_grads          | -0.023833826696500183  |
| train_1/mu_grads_std      | 0.4442003838717937     |
| train_1/mu_loss           | 8.699362646684762      |
| train_1/n_subgoals        | 2558.0                 |
| train_1/next_q            | -8.668882379491885     |
| train_1/q_grads           | -0.011659967550076544  |
| train_1/q_grads_std       | 0.4210288390517235     |
| train_1/q_loss            | 2.810181825109122      |
| train_1/reward            | -1.2204992668092018    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0019775390625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.6563721657544958     |
| train_1/target_q          | -8.87145103265421      |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 11
Time for epoch 11: 502.00. Rollout time: 273.35, Training time: 228.60
Evaluating epoch 11
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 590167.0               |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.24                   |
| test_0/avg_q              | -3.3001344156590697    |
| test_1/avg_q              | -16.848400793424652    |
| test_1/n_subgoals         | 2463.0                 |
| test_1/subgoal_succ_rate  | 0.8656110434429557     |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.12                   |
| train_0/avg_q             | -1.8204365712900197    |
| train_0/current_q         | -2.094812473699777     |
| train_0/fw_bonus          | -0.9993462204933167    |
| train_0/fw_loss           | 0.00015391082924907096 |
| train_0/mu_grads          | -0.04015567405149341   |
| train_0/mu_grads_std      | 0.37203125581145285    |
| train_0/mu_loss           | 1.8530726310295897     |
| train_0/next_q            | -1.8032357651030106    |
| train_0/q_grads           | 0.02696824260056019    |
| train_0/q_grads_std       | 0.26329139098525045    |
| train_0/q_loss            | 0.3066746799734566     |
| train_0/reward            | -0.7117214492602215    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.008740234375         |
| train_0/target_q          | -2.037417747040915     |
| train_1/avg_q             | -17.977119897716012    |
| train_1/current_q         | -8.592704345846716     |
| train_1/fw_bonus          | -0.9938187509775162    |
| train_1/fw_loss           | 0.002029492615838535   |
| train_1/mu_grads          | -0.026632788171991707  |
| train_1/mu_grads_std      | 0.465824443846941      |
| train_1/mu_loss           | 8.423680425591366      |
| train_1/n_subgoals        | 2538.0                 |
| train_1/next_q            | -8.445434889798985     |
| train_1/q_grads           | -0.013060393976047635  |
| train_1/q_grads_std       | 0.4292456038296223     |
| train_1/q_loss            | 2.7077898435731336     |
| train_1/reward            | -1.2578712890623138    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002392578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3806146572104019     |
| train_1/target_q          | -8.638396801851579     |
------------------------------------------------------
New best value for test/success_rate: 0.24. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.13
Training epoch 12
Time for epoch 12: 374.44. Rollout time: 142.43, Training time: 231.97
Evaluating epoch 12
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 629844.0               |
| test/episodes             | 325.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.6245489013581405    |
| test_1/avg_q              | -18.635669911102227    |
| test_1/n_subgoals         | 1096.0                 |
| test_1/subgoal_succ_rate  | 0.45894160583941607    |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.17                   |
| train_0/avg_q             | -3.553008175143373     |
| train_0/current_q         | -1.6346643273401806    |
| train_0/fw_bonus          | -0.9993602067232132    |
| train_0/fw_loss           | 0.00015071718298713676 |
| train_0/mu_grads          | -0.043972510192543265  |
| train_0/mu_grads_std      | 0.38320447877049446    |
| train_0/mu_loss           | 1.4278316961014201     |
| train_0/next_q            | -1.4068038107079572    |
| train_0/q_grads           | 0.0270098190754652     |
| train_0/q_grads_std       | 0.27082561105489733    |
| train_0/q_loss            | 0.4001905197170935     |
| train_0/reward            | -0.7112279574852437    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.012939453125         |
| train_0/target_q          | -1.623464277321715     |
| train_1/avg_q             | -18.991874031990697    |
| train_1/current_q         | -8.624505871385987     |
| train_1/fw_bonus          | -0.9925335451960564    |
| train_1/fw_loss           | 0.0022920687217265366  |
| train_1/mu_grads          | -0.03116680490784347   |
| train_1/mu_grads_std      | 0.4844283998012543     |
| train_1/mu_loss           | 8.439490437728129      |
| train_1/n_subgoals        | 2531.0                 |
| train_1/next_q            | -8.459126134240531     |
| train_1/q_grads           | -0.0139460489153862    |
| train_1/q_grads_std       | 0.4383890345692635     |
| train_1/q_loss            | 2.897691256076255      |
| train_1/reward            | -1.2815939237858402    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00224609375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7965231133939155     |
| train_1/target_q          | -8.646399100633818     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 13
Time for epoch 13: 543.61. Rollout time: 318.83, Training time: 224.74
Evaluating epoch 13
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 13                      |
| policy/steps              | 701058.0                |
| test/episodes             | 350.0                   |
| test/success_rate         | 0.04                    |
| test_0/avg_q              | -0.00015892614384449848 |
| test_1/avg_q              | -15.988375087732738     |
| test_1/n_subgoals         | 670.0                   |
| test_1/subgoal_succ_rate  | 0.01791044776119403     |
| train/episodes            | 1400.0                  |
| train/success_rate        | 0.11                    |
| train_0/avg_q             | -2.1949722722638065     |
| train_0/current_q         | -0.0005476640788156401  |
| train_0/fw_bonus          | -0.9992502704262733     |
| train_0/fw_loss           | 0.00017581125066499226  |
| train_0/mu_grads          | -0.046337191574275495   |
| train_0/mu_grads_std      | 0.3927593544125557      |
| train_0/mu_loss           | 0.0005941734140327234   |
| train_0/next_q            | -0.000635617039539874   |
| train_0/q_grads           | 0.02672644848935306     |
| train_0/q_grads_std       | 0.2767358712852001      |
| train_0/q_loss            | 0.5754731500002946      |
| train_0/reward            | -0.7170811852935003     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.005908203125          |
| train_0/target_q          | -0.717444250251454      |
| train_1/avg_q             | -17.063452185159097     |
| train_1/current_q         | -8.569478526194533      |
| train_1/fw_bonus          | -0.9893928408622742     |
| train_1/fw_loss           | 0.0029337410465814172   |
| train_1/mu_grads          | -0.03768881475552917    |
| train_1/mu_grads_std      | 0.4988639779388905      |
| train_1/mu_loss           | 8.33462226678661        |
| train_1/n_subgoals        | 2602.0                  |
| train_1/next_q            | -8.388287665748155      |
| train_1/q_grads           | -0.014297605026513338   |
| train_1/q_grads_std       | 0.44930330738425256     |
| train_1/q_loss            | 2.9047755888460562      |
| train_1/reward            | -1.3884342140219814     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0025390625            |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.292467332820907       |
| train_1/target_q          | -8.579736843006199      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.10999999999999999
Training epoch 14
Time for epoch 14: 632.05. Rollout time: 411.26, Training time: 220.73
Evaluating epoch 14
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 783821.0               |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -0.8841101575978577    |
| test_1/avg_q              | -14.047448892465395    |
| test_1/n_subgoals         | 724.0                  |
| test_1/subgoal_succ_rate  | 0.2058011049723757     |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.08                   |
| train_0/avg_q             | -2.0237538821365577    |
| train_0/current_q         | -1.5353939876354865    |
| train_0/fw_bonus          | -0.9991857692599296    |
| train_0/fw_loss           | 0.00019053007672482637 |
| train_0/mu_grads          | -0.0400034979917109    |
| train_0/mu_grads_std      | 0.4011607483029366     |
| train_0/mu_loss           | 1.2003205776117192     |
| train_0/next_q            | -1.1785925618322612    |
| train_0/q_grads           | 0.025610218476504087   |
| train_0/q_grads_std       | 0.28095343708992004    |
| train_0/q_loss            | 0.26388173413720917    |
| train_0/reward            | -0.7226153457479085    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0075927734375        |
| train_0/target_q          | -1.5742058833149533    |
| train_1/avg_q             | -15.288982787256883    |
| train_1/current_q         | -8.655923351414435     |
| train_1/fw_bonus          | -0.9879832178354263    |
| train_1/fw_loss           | 0.003221738466527313   |
| train_1/mu_grads          | -0.04327038386836648   |
| train_1/mu_grads_std      | 0.5060062631964684     |
| train_1/mu_loss           | 8.318101582407936      |
| train_1/n_subgoals        | 2612.0                 |
| train_1/next_q            | -8.495558538924811     |
| train_1/q_grads           | -0.016143531491979956  |
| train_1/q_grads_std       | 0.46089979261159897    |
| train_1/q_loss            | 3.1801954534471606     |
| train_1/reward            | -1.5932103613835351    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0025390625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.07618683001531394    |
| train_1/target_q          | -8.657428682096121     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13999999999999999
Training epoch 15
Time for epoch 15: 513.10. Rollout time: 262.56, Training time: 250.47
Evaluating epoch 15
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 839481.0               |
| test/episodes             | 400.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.6678242503909204    |
| test_1/avg_q              | -17.69280267153716     |
| test_1/n_subgoals         | 685.0                  |
| test_1/subgoal_succ_rate  | 0.052554744525547446   |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.2                    |
| train_0/avg_q             | -1.5867455778544997    |
| train_0/current_q         | -2.0975848527674836    |
| train_0/fw_bonus          | -0.9991962939500809    |
| train_0/fw_loss           | 0.00018812720118148717 |
| train_0/mu_grads          | -0.046619227062910794  |
| train_0/mu_grads_std      | 0.4030882142484188     |
| train_0/mu_loss           | 1.9196425615640351     |
| train_0/next_q            | -1.8517533412676983    |
| train_0/q_grads           | 0.025894402991980314   |
| train_0/q_grads_std       | 0.2808798119425774     |
| train_0/q_loss            | 0.3526650691048651     |
| train_0/reward            | -0.7297983443320846    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0131103515625        |
| train_0/target_q          | -2.0842509354204535    |
| train_1/avg_q             | -15.81983795366209     |
| train_1/current_q         | -8.520749130323306     |
| train_1/fw_bonus          | -0.9885952264070511    |
| train_1/fw_loss           | 0.003096702869515866   |
| train_1/mu_grads          | -0.04904398042708635   |
| train_1/mu_grads_std      | 0.5136196196079255     |
| train_1/mu_loss           | 8.192072917311515      |
| train_1/n_subgoals        | 2443.0                 |
| train_1/next_q            | -8.344313847745918     |
| train_1/q_grads           | -0.016948227398097516  |
| train_1/q_grads_std       | 0.4729963853955269     |
| train_1/q_loss            | 3.081289589070809      |
| train_1/reward            | -1.645030029535701     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021240234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.5341792877609497     |
| train_1/target_q          | -8.527392916542217     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 16
Time for epoch 16: 444.60. Rollout time: 216.32, Training time: 228.23
Evaluating epoch 16
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 887211.0               |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -3.118178388585802     |
| test_1/avg_q              | -16.01961171230217     |
| test_1/n_subgoals         | 4005.0                 |
| test_1/subgoal_succ_rate  | 0.9328339575530586     |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.07                   |
| train_0/avg_q             | -2.833048500368116     |
| train_0/current_q         | -2.3170796811995453    |
| train_0/fw_bonus          | -0.9992392808198929    |
| train_0/fw_loss           | 0.00017831657805800205 |
| train_0/mu_grads          | -0.05128071708604694   |
| train_0/mu_grads_std      | 0.4111624576151371     |
| train_0/mu_loss           | 2.1192080186373006     |
| train_0/next_q            | -2.0679402510015032    |
| train_0/q_grads           | 0.02542523224838078    |
| train_0/q_grads_std       | 0.2829009972512722     |
| train_0/q_loss            | 0.36845217117314066    |
| train_0/reward            | -0.7340190560113115    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0126708984375        |
| train_0/target_q          | -2.2699652134415924    |
| train_1/avg_q             | -17.028930774251275    |
| train_1/current_q         | -8.427455359958259     |
| train_1/fw_bonus          | -0.9896638125181199    |
| train_1/fw_loss           | 0.002878380287438631   |
| train_1/mu_grads          | -0.05332513200119138   |
| train_1/mu_grads_std      | 0.5229026436805725     |
| train_1/mu_loss           | 8.069391680681498      |
| train_1/n_subgoals        | 2554.0                 |
| train_1/next_q            | -8.26676842674807      |
| train_1/q_grads           | -0.017704982357099653  |
| train_1/q_grads_std       | 0.486511704325676      |
| train_1/q_loss            | 2.859208977800743      |
| train_1/reward            | -1.5802811231158558    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020263671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7012529365700861     |
| train_1/target_q          | -8.439819479612186     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11000000000000001
Training epoch 17
Time for epoch 17: 397.76. Rollout time: 176.51, Training time: 221.22
Evaluating epoch 17
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 933500.0               |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -3.1834058236129317    |
| test_1/avg_q              | -15.38647973837062     |
| test_1/n_subgoals         | 3566.0                 |
| test_1/subgoal_succ_rate  | 0.9049355019629838     |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.18                   |
| train_0/avg_q             | -3.968574659787353     |
| train_0/current_q         | -2.5536599752170726    |
| train_0/fw_bonus          | -0.9992689698934555    |
| train_0/fw_loss           | 0.00017153975568362512 |
| train_0/mu_grads          | -0.05696896342560649   |
| train_0/mu_grads_std      | 0.422983917593956      |
| train_0/mu_loss           | 2.3176161041702144     |
| train_0/next_q            | -2.2483282941075218    |
| train_0/q_grads           | 0.024521286133676767   |
| train_0/q_grads_std       | 0.2844084076583385     |
| train_0/q_loss            | 0.36670414228595866    |
| train_0/reward            | -0.7445197423126956    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0142578125           |
| train_0/target_q          | -2.4876609124378524    |
| train_1/avg_q             | -17.493080243994548    |
| train_1/current_q         | -8.52270367848732      |
| train_1/fw_bonus          | -0.9903884649276733    |
| train_1/fw_loss           | 0.0027303243172354997  |
| train_1/mu_grads          | -0.058325210213661195  |
| train_1/mu_grads_std      | 0.5378282055258751     |
| train_1/mu_loss           | 8.246102719515875      |
| train_1/n_subgoals        | 2390.0                 |
| train_1/next_q            | -8.380429463563123     |
| train_1/q_grads           | -0.017877996107563375  |
| train_1/q_grads_std       | 0.4997349664568901     |
| train_1/q_loss            | 3.123325048411113      |
| train_1/reward            | -1.5412635757384123    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0027587890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7196652719665272     |
| train_1/target_q          | -8.528607469461155     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 18
Time for epoch 18: 447.72. Rollout time: 197.33, Training time: 250.34
Evaluating epoch 18
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 976636.0               |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -2.063409439499309     |
| test_1/avg_q              | -16.051793348174364    |
| test_1/n_subgoals         | 5947.0                 |
| test_1/subgoal_succ_rate  | 0.9598116697494535     |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.15                   |
| train_0/avg_q             | -4.352617135065359     |
| train_0/current_q         | -2.5265950530626484    |
| train_0/fw_bonus          | -0.9992400839924812    |
| train_0/fw_loss           | 0.00017813439590099733 |
| train_0/mu_grads          | -0.06142766159027815   |
| train_0/mu_grads_std      | 0.4377958387136459     |
| train_0/mu_loss           | 2.3052577615544876     |
| train_0/next_q            | -2.238759053992473     |
| train_0/q_grads           | 0.023934749886393547   |
| train_0/q_grads_std       | 0.28406022787094115    |
| train_0/q_loss            | 0.37711252796885886    |
| train_0/reward            | -0.7534042206250888    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0111572265625        |
| train_0/target_q          | -2.4870727338671452    |
| train_1/avg_q             | -16.748098962481272    |
| train_1/current_q         | -8.546292036430719     |
| train_1/fw_bonus          | -0.9907374009490013    |
| train_1/fw_loss           | 0.0026590365858282896  |
| train_1/mu_grads          | -0.062264620512723926  |
| train_1/mu_grads_std      | 0.5545307561755181     |
| train_1/mu_loss           | 8.226928690146812      |
| train_1/n_subgoals        | 2411.0                 |
| train_1/next_q            | -8.418934863090445     |
| train_1/q_grads           | -0.019353166129440068  |
| train_1/q_grads_std       | 0.5086202770471573     |
| train_1/q_loss            | 3.0598504064765186     |
| train_1/reward            | -1.478754931325966     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0026123046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.758606387391124      |
| train_1/target_q          | -8.5373136091834       |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 19
Time for epoch 19: 463.74. Rollout time: 214.69, Training time: 248.98
Evaluating epoch 19
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1020399.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -4.006457129561327     |
| test_1/avg_q              | -13.670456160814679    |
| test_1/n_subgoals         | 4691.0                 |
| test_1/subgoal_succ_rate  | 0.9492645491366446     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.16                   |
| train_0/avg_q             | -4.390563746609297     |
| train_0/current_q         | -2.6571693175339615    |
| train_0/fw_bonus          | -0.9993115589022636    |
| train_0/fw_loss           | 0.00016182361432584002 |
| train_0/mu_grads          | -0.06350441668182612   |
| train_0/mu_grads_std      | 0.44833921268582344    |
| train_0/mu_loss           | 2.4067838298990853     |
| train_0/next_q            | -2.3065776083978022    |
| train_0/q_grads           | 0.02336543849669397    |
| train_0/q_grads_std       | 0.2855875097215176     |
| train_0/q_loss            | 0.30159733535193717    |
| train_0/reward            | -0.7546362428729481    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0196044921875        |
| train_0/target_q          | -2.6111463133257122    |
| train_1/avg_q             | -18.037976033809098    |
| train_1/current_q         | -8.649917274095804     |
| train_1/fw_bonus          | -0.992298749089241     |
| train_1/fw_loss           | 0.0023400409671012314  |
| train_1/mu_grads          | -0.06611547730863095   |
| train_1/mu_grads_std      | 0.5709668561816216     |
| train_1/mu_loss           | 8.345373754402507      |
| train_1/n_subgoals        | 2467.0                 |
| train_1/next_q            | -8.50675620371842      |
| train_1/q_grads           | -0.020128985960036518  |
| train_1/q_grads_std       | 0.5188736543059349     |
| train_1/q_loss            | 2.8739789042190482     |
| train_1/reward            | -1.3282294526208716    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0026611328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7430077016619375     |
| train_1/target_q          | -8.657856291857964     |
------------------------------------------------------
New best value for test/success_rate: 0.28. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 20
Time for epoch 20: 461.79. Rollout time: 210.34, Training time: 251.39
Evaluating epoch 20
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 1063725.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.32                   |
| test_0/avg_q              | -4.493065087940193     |
| test_1/avg_q              | -17.130234860467134    |
| test_1/n_subgoals         | 3127.0                 |
| test_1/subgoal_succ_rate  | 0.9449952030700352     |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.18                   |
| train_0/avg_q             | -4.589935749363399     |
| train_0/current_q         | -3.113407789745694     |
| train_0/fw_bonus          | -0.9993356913328171    |
| train_0/fw_loss           | 0.00015631146434316178 |
| train_0/mu_grads          | -0.07028218619525432   |
| train_0/mu_grads_std      | 0.4603600732982159     |
| train_0/mu_loss           | 2.852538904670376      |
| train_0/next_q            | -2.7457932908349783    |
| train_0/q_grads           | 0.022886663628742098   |
| train_0/q_grads_std       | 0.28653177469968794    |
| train_0/q_loss            | 0.3364682415295939     |
| train_0/reward            | -0.762949100019614     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.024365234375         |
| train_0/target_q          | -3.0290690179448303    |
| train_1/avg_q             | -17.938560744254954    |
| train_1/current_q         | -8.598671350304752     |
| train_1/fw_bonus          | -0.9927360251545906    |
| train_1/fw_loss           | 0.0022507010027766226  |
| train_1/mu_grads          | -0.07025275658816099   |
| train_1/mu_grads_std      | 0.5851877495646477     |
| train_1/mu_loss           | 8.349954704144565      |
| train_1/n_subgoals        | 2402.0                 |
| train_1/next_q            | -8.467151385025605     |
| train_1/q_grads           | -0.02032071785070002   |
| train_1/q_grads_std       | 0.5301872566342354     |
| train_1/q_loss            | 3.3831888592777957     |
| train_1/reward            | -1.2350520955391402    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0031494140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7447960033305578     |
| train_1/target_q          | -8.604655605422858     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_20.pkl ...
New best value for test/success_rate: 0.32. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.23000000000000004
Training epoch 21
Time for epoch 21: 575.14. Rollout time: 321.67, Training time: 253.40
Evaluating epoch 21
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 1127670.0              |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.003356519732128478  |
| test_1/avg_q              | -15.082952798280822    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.29                   |
| train_0/avg_q             | -3.1188930085226203    |
| train_0/current_q         | -0.01113239283534525   |
| train_0/fw_bonus          | -0.9992809504270553    |
| train_0/fw_loss           | 0.00016880779876373708 |
| train_0/mu_grads          | -0.06895991303026676   |
| train_0/mu_grads_std      | 0.4666925221681595     |
| train_0/mu_loss           | 0.003130504374151444   |
| train_0/next_q            | -0.0027440610793307944 |
| train_0/q_grads           | 0.022786274179816247   |
| train_0/q_grads_std       | 0.2902831226587296     |
| train_0/q_loss            | 0.6448106744998441     |
| train_0/reward            | -0.7717229930094618    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03125                |
| train_0/target_q          | -0.7741737778536713    |
| train_1/avg_q             | -17.64148687520244     |
| train_1/current_q         | -8.58248123240713      |
| train_1/fw_bonus          | -0.9926759272813797    |
| train_1/fw_loss           | 0.0022629806306213142  |
| train_1/mu_grads          | -0.07181159351021052   |
| train_1/mu_grads_std      | 0.5955418795347214     |
| train_1/mu_loss           | 8.322945303001342      |
| train_1/n_subgoals        | 2298.0                 |
| train_1/next_q            | -8.450730849225012     |
| train_1/q_grads           | -0.02012143824249506   |
| train_1/q_grads_std       | 0.5415619805455207     |
| train_1/q_loss            | 3.0921328190745108     |
| train_1/reward            | -1.264465405111696     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002978515625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3951261966927763     |
| train_1/target_q          | -8.59049741243394      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.19
Training epoch 22
Time for epoch 22: 689.12. Rollout time: 433.71, Training time: 255.34
Evaluating epoch 22
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 1211677.0              |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.0013377550657085156 |
| test_1/avg_q              | -15.01779019791272     |
| test_1/n_subgoals         | 690.0                  |
| test_1/subgoal_succ_rate  | 0.021739130434782608   |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.1                    |
| train_0/avg_q             | -0.25978735768813144   |
| train_0/current_q         | -0.023254893714853647  |
| train_0/fw_bonus          | -0.9992956176400185    |
| train_0/fw_loss           | 0.00016545744656468742 |
| train_0/mu_grads          | -0.06882484965026378   |
| train_0/mu_grads_std      | 0.46952851489186287    |
| train_0/mu_loss           | 0.002446418026942818   |
| train_0/next_q            | -0.00250137461710762   |
| train_0/q_grads           | 0.02231631730683148    |
| train_0/q_grads_std       | 0.2906111001968384     |
| train_0/q_loss            | 0.6441463418195147     |
| train_0/reward            | -0.7729266219321289    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0344970703125        |
| train_0/target_q          | -0.7752482403000117    |
| train_1/avg_q             | -15.48809460361747     |
| train_1/current_q         | -8.612784295222568     |
| train_1/fw_bonus          | -0.9917050018906594    |
| train_1/fw_loss           | 0.002461346803465858   |
| train_1/mu_grads          | -0.07517274357378483   |
| train_1/mu_grads_std      | 0.6054556399583817     |
| train_1/mu_loss           | 8.312104243263652      |
| train_1/n_subgoals        | 2543.0                 |
| train_1/next_q            | -8.526496996207221     |
| train_1/q_grads           | -0.019990470027551055  |
| train_1/q_grads_std       | 0.5544142037630081     |
| train_1/q_loss            | 3.5503130404005923     |
| train_1/reward            | -1.3951933240896324    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.003173828125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0526936688950059     |
| train_1/target_q          | -8.615622011257702     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 23
Time for epoch 23: 734.48. Rollout time: 472.25, Training time: 262.16
Evaluating epoch 23
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 23                      |
| policy/steps              | 1297745.0               |
| test/episodes             | 600.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -3.9974123894542455e-07 |
| test_1/avg_q              | -12.528656548548353     |
| test_1/n_subgoals         | 684.0                   |
| test_1/subgoal_succ_rate  | 0.013157894736842105    |
| train/episodes            | 2400.0                  |
| train/success_rate        | 0.07                    |
| train_0/avg_q             | -0.6465635969806096     |
| train_0/current_q         | -5.86098011911684e-06   |
| train_0/fw_bonus          | -0.9993864461779595     |
| train_0/fw_loss           | 0.0001447315102268476   |
| train_0/mu_grads          | -0.06827588155865669    |
| train_0/mu_grads_std      | 0.47442713379859924     |
| train_0/mu_loss           | 1.536792659671549e-06   |
| train_0/next_q            | -1.3465876907299332e-06 |
| train_0/q_grads           | 0.022372951870784162    |
| train_0/q_grads_std       | 0.2909944951534271      |
| train_0/q_loss            | 0.6553937218728516      |
| train_0/reward            | -0.7702864809740276     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0443359375            |
| train_0/target_q          | -0.7702876986559828     |
| train_1/avg_q             | -14.715147223655348     |
| train_1/current_q         | -9.059606667724834      |
| train_1/fw_bonus          | -0.9903194844722748     |
| train_1/fw_loss           | 0.002744420024100691    |
| train_1/mu_grads          | -0.07597141098231078    |
| train_1/mu_grads_std      | 0.6123855099081993      |
| train_1/mu_loss           | 10.0213925178725        |
| train_1/n_subgoals        | 2626.0                  |
| train_1/next_q            | -10.335006020062341     |
| train_1/q_grads           | -0.022404772555455567   |
| train_1/q_grads_std       | 0.5688425958156585      |
| train_1/q_loss            | 12.747817435608845      |
| train_1/reward            | -1.539007399768161      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.002978515625          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.05635948210205636     |
| train_1/target_q          | -9.09341926881468       |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 24
Time for epoch 24: 762.87. Rollout time: 507.13, Training time: 255.66
Evaluating epoch 24
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 24                      |
| policy/steps              | 1388483.0               |
| test/episodes             | 625.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -3.247808382031287e-08  |
| test_1/avg_q              | -13.76619524828185      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.6769327601547174e-06 |
| train_0/current_q         | -1.5163417770345715e-06 |
| train_0/fw_bonus          | -0.9995429441332817     |
| train_0/fw_loss           | 0.00010901074056164361  |
| train_0/mu_grads          | -0.0682740831747651     |
| train_0/mu_grads_std      | 0.4744168221950531      |
| train_0/mu_loss           | 2.0873934007307043e-07  |
| train_0/next_q            | -1.846697810138771e-07  |
| train_0/q_grads           | 0.022735743131488562    |
| train_0/q_grads_std       | 0.2911425828933716      |
| train_0/q_loss            | 0.6445160532665184      |
| train_0/reward            | -0.7630283109516313     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.05400390625           |
| train_0/target_q          | -0.763028472480453      |
| train_1/avg_q             | -13.68794169952972      |
| train_1/current_q         | -9.55045477331694       |
| train_1/fw_bonus          | -0.9875756099820137     |
| train_1/fw_loss           | 0.003305016574449837    |
| train_1/mu_grads          | -0.080194085650146      |
| train_1/mu_grads_std      | 0.6198352634906769      |
| train_1/mu_loss           | 12.22627245881992       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -12.934794269237978     |
| train_1/q_grads           | -0.0240432717371732     |
| train_1/q_grads_std       | 0.5824962690472603      |
| train_1/q_loss            | 18.394393378777615      |
| train_1/reward            | -1.7141003057309718     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0022705078125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.006296296296296296    |
| train_1/target_q          | -9.542265141505405      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 757.88. Rollout time: 491.68, Training time: 266.12
Evaluating epoch 25
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 25                      |
| policy/steps              | 1479421.0               |
| test/episodes             | 650.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -1.4056626514748636e-17 |
| test_1/avg_q              | -13.562303172157655     |
| test_1/n_subgoals         | 687.0                   |
| test_1/subgoal_succ_rate  | 0.017467248908296942    |
| train/episodes            | 2600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -0.18486948008639104    |
| train_0/current_q         | -2.415456357401872e-16  |
| train_0/fw_bonus          | -0.999637308716774      |
| train_0/fw_loss           | 8.747435449549812e-05   |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 3.2438469310387924e-16  |
| train_0/next_q            | -2.7430505882113757e-16 |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.6263743022490627      |
| train_0/reward            | -0.7509294961404521     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0416015625            |
| train_0/target_q          | -0.7509294961404522     |
| train_1/avg_q             | -13.296821868226703     |
| train_1/current_q         | -10.23881923462223      |
| train_1/fw_bonus          | -0.9879058241844177     |
| train_1/fw_loss           | 0.0032375491457059978   |
| train_1/mu_grads          | -0.08205956649035215    |
| train_1/mu_grads_std      | 0.6242982894182205      |
| train_1/mu_loss           | 14.957764475790265      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -15.904379043691558     |
| train_1/q_grads           | -0.024636396439746022   |
| train_1/q_grads_std       | 0.5955508694052696      |
| train_1/q_loss            | 14.912052743987232      |
| train_1/reward            | -1.859809850246529      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0024658203125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0033333333333333335   |
| train_1/target_q          | -10.300145967896118     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 727.55. Rollout time: 471.72, Training time: 255.75
Evaluating epoch 26
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 26                      |
| policy/steps              | 1568399.0               |
| test/episodes             | 675.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -7.61792083914833e-13   |
| test_1/avg_q              | -14.663187266852345     |
| test_1/n_subgoals         | 682.0                   |
| test_1/subgoal_succ_rate  | 0.010263929618768328    |
| train/episodes            | 2700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.6598349231258955e-13 |
| train_0/current_q         | -4.3788297158094575e-15 |
| train_0/fw_bonus          | -0.9997615113854408     |
| train_0/fw_loss           | 5.912883152632275e-05   |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 3.05031363388804e-15    |
| train_0/next_q            | -3.034560361974009e-15  |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.6016238797190507      |
| train_0/reward            | -0.7344266531632456     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.082080078125          |
| train_0/target_q          | -0.7344266531632486     |
| train_1/avg_q             | -13.312635283498656     |
| train_1/current_q         | -11.651677734462115     |
| train_1/fw_bonus          | -0.9896299123764039     |
| train_1/fw_loss           | 0.00288530639372766     |
| train_1/mu_grads          | -0.08015637341886758    |
| train_1/mu_grads_std      | 0.6281515970826149      |
| train_1/mu_loss           | 18.41233907333125       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -19.349050028804918     |
| train_1/q_grads           | -0.025587728898972272   |
| train_1/q_grads_std       | 0.6081010669469833      |
| train_1/q_loss            | 14.54004959198222       |
| train_1/reward            | -1.9584990348928841     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0017333984375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.03259259259259259     |
| train_1/target_q          | -11.772681848308775     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 929.95. Rollout time: 639.26, Training time: 290.58
Evaluating epoch 27
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 27                      |
| policy/steps              | 1657674.0               |
| test/episodes             | 700.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -9.070708136305558e-16  |
| test_1/avg_q              | -13.657982172161129     |
| test_1/n_subgoals         | 680.0                   |
| test_1/subgoal_succ_rate  | 0.007352941176470588    |
| train/episodes            | 2800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.0996355062243291e-12 |
| train_0/current_q         | -1.7496161837224293e-13 |
| train_0/fw_bonus          | -0.9998803794384002     |
| train_0/fw_loss           | 3.199970637979277e-05   |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 4.316655111486435e-14   |
| train_0/next_q            | -4.658145721359936e-14  |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5844553401474271      |
| train_0/reward            | -0.7229748562240275     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.130029296875          |
| train_0/target_q          | -0.7229748562240731     |
| train_1/avg_q             | -13.928656813345459     |
| train_1/current_q         | -11.75206876070613      |
| train_1/fw_bonus          | -0.9925151169300079     |
| train_1/fw_loss           | 0.0022958343557547777   |
| train_1/mu_grads          | -0.08079751897603274    |
| train_1/mu_grads_std      | 0.6332711175084114      |
| train_1/mu_loss           | 20.62858760166257       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -20.949478015792078     |
| train_1/q_grads           | -0.026109857484698296   |
| train_1/q_grads_std       | 0.6193004488945008      |
| train_1/q_loss            | 12.929569899120589      |
| train_1/reward            | -1.9821462317515397     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0014404296875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.02851851851851852     |
| train_1/target_q          | -11.8961582414879       |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 756.15. Rollout time: 482.64, Training time: 273.44
Evaluating epoch 28
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 28                      |
| policy/steps              | 1746881.0               |
| test/episodes             | 725.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -5.831038134923717e-16  |
| test_1/avg_q              | -14.252741737951949     |
| test_1/n_subgoals         | 677.0                   |
| test_1/subgoal_succ_rate  | 0.0029542097488921715   |
| train/episodes            | 2900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -2.1292966753188975e-13 |
| train_0/current_q         | -4.983843938002506e-14  |
| train_0/fw_bonus          | -0.999937079846859      |
| train_0/fw_loss           | 1.9060842032558866e-05  |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 3.20824287234627e-14    |
| train_0/next_q            | -3.3031148702974136e-14 |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.581405407298392       |
| train_0/reward            | -0.7209402140331804     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.24267578125           |
| train_0/target_q          | -0.7209402140332127     |
| train_1/avg_q             | -13.830306636776138     |
| train_1/current_q         | -11.815965568967389     |
| train_1/fw_bonus          | -0.9951602160930634     |
| train_1/fw_loss           | 0.0017554191639646889   |
| train_1/mu_grads          | -0.0813551688566804     |
| train_1/mu_grads_std      | 0.6374336361885071      |
| train_1/mu_loss           | 21.502321992538615      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.610722150861385     |
| train_1/q_grads           | -0.0265879028942436     |
| train_1/q_grads_std       | 0.6308442339301109      |
| train_1/q_loss            | 11.806815936007885      |
| train_1/reward            | -1.9518891899679147     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0016357421875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.02962962962962963     |
| train_1/target_q          | -11.998132701552155     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 979.79. Rollout time: 670.31, Training time: 309.34
Evaluating epoch 29
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 29                      |
| policy/steps              | 1835913.0               |
| test/episodes             | 750.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -4.624066847809361e-16  |
| test_1/avg_q              | -11.748226224844732     |
| test_1/n_subgoals         | 810.0                   |
| test_1/subgoal_succ_rate  | 0.1728395061728395      |
| train/episodes            | 3000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -3.7293088585098327e-14 |
| train_0/current_q         | -1.1170333411249612e-13 |
| train_0/fw_bonus          | -0.9999311074614525     |
| train_0/fw_loss           | 2.0421321073627043e-05  |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 4.539389157049579e-14   |
| train_0/next_q            | -4.6238556651408527e-14 |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5685668443698589      |
| train_0/reward            | -0.7123801047397137     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1775146484375         |
| train_0/target_q          | -0.712380104739759      |
| train_1/avg_q             | -14.087675895325935     |
| train_1/current_q         | -11.730393411113207     |
| train_1/fw_bonus          | -0.9978709250688553     |
| train_1/fw_loss           | 0.0012015992018859834   |
| train_1/mu_grads          | -0.08400935735553502    |
| train_1/mu_grads_std      | 0.6421137109398842      |
| train_1/mu_loss           | 21.623421140320012      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.72468813244629      |
| train_1/q_grads           | -0.0280416845344007     |
| train_1/q_grads_std       | 0.6415736839175225      |
| train_1/q_loss            | 10.331526643473975      |
| train_1/reward            | -1.9495336070358462     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001611328125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.03222222222222222     |
| train_1/target_q          | -11.879027993650926     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 958.41. Rollout time: 657.64, Training time: 300.66
Evaluating epoch 30
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 30                      |
| policy/steps              | 1922378.0               |
| test/episodes             | 775.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -3.4403915093931297e-16 |
| test_1/avg_q              | -14.032986511500436     |
| test_1/n_subgoals         | 681.0                   |
| test_1/subgoal_succ_rate  | 0.00881057268722467     |
| train/episodes            | 3100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.81106870228489e-15   |
| train_0/current_q         | -1.4122726282858667e-13 |
| train_0/fw_bonus          | -0.9999374642968177     |
| train_0/fw_loss           | 1.8969427287629514e-05  |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 5.961843271617615e-14   |
| train_0/next_q            | -6.273307211316803e-14  |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5669760191914381      |
| train_0/reward            | -0.7113212735588604     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2347412109375         |
| train_0/target_q          | -0.7113212735589218     |
| train_1/avg_q             | -13.673875353091555     |
| train_1/current_q         | -11.658392801981002     |
| train_1/fw_bonus          | -0.9990273550152778     |
| train_1/fw_loss           | 0.0009653322049416602   |
| train_1/mu_grads          | -0.08391103316098451    |
| train_1/mu_grads_std      | 0.6478940308094024      |
| train_1/mu_loss           | 21.50818382560926       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.566137742178267     |
| train_1/q_grads           | -0.028328303946182132   |
| train_1/q_grads_std       | 0.6545113697648048      |
| train_1/q_loss            | 8.784220876051501       |
| train_1/reward            | -1.9334248075152574     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001611328125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.07                    |
| train_1/target_q          | -11.847796101857407     |
-------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 907.89. Rollout time: 635.21, Training time: 272.51
Evaluating epoch 31
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 31                      |
| policy/steps              | 2012666.0               |
| test/episodes             | 800.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -1.3161725229725628e-12 |
| test_1/avg_q              | -14.712361425198084     |
| test_1/n_subgoals         | 689.0                   |
| test_1/subgoal_succ_rate  | 0.020319303338171262    |
| train/episodes            | 3200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.0256067475987256e-12 |
| train_0/current_q         | -1.231738763794774e-13  |
| train_0/fw_bonus          | -0.9999356970191002     |
| train_0/fw_loss           | 1.9374374869585153e-05  |
| train_0/mu_grads          | -0.06846975535154343    |
| train_0/mu_grads_std      | 0.4748847186565399      |
| train_0/mu_loss           | 6.006300817259084e-14   |
| train_0/next_q            | -5.952894051736047e-14  |
| train_0/q_grads           | 0.0232088565826416      |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5647772928980878      |
| train_0/reward            | -0.7098555427626707     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.25859375              |
| train_0/target_q          | -0.7098555427627289     |
| train_1/avg_q             | -14.100996504144812     |
| train_1/current_q         | -11.40025787605655      |
| train_1/fw_bonus          | -0.9992151856422424     |
| train_1/fw_loss           | 0.0009269575515645556   |
| train_1/mu_grads          | -0.08665814120322465    |
| train_1/mu_grads_std      | 0.6517631694674492      |
| train_1/mu_loss           | 21.40898777591522       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.43389279859104      |
| train_1/q_grads           | -0.030459227226674556   |
| train_1/q_grads_std       | 0.669619171321392       |
| train_1/q_loss            | 9.436513323399083       |
| train_1/reward            | -1.9538190139297513     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001318359375          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.012962962962962963    |
| train_1/target_q          | -11.629424161153874     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 900.91. Rollout time: 625.98, Training time: 274.83
Evaluating epoch 32
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 32                      |
| policy/steps              | 2102662.0               |
| test/episodes             | 825.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -7.858549532869966e-13  |
| test_1/avg_q              | -13.740328900873175     |
| test_1/n_subgoals         | 693.0                   |
| test_1/subgoal_succ_rate  | 0.027417027417027416    |
| train/episodes            | 3300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.9572657900513996e-12 |
| train_0/current_q         | -2.327219862784273e-13  |
| train_0/fw_bonus          | -0.9999394074082375     |
| train_0/fw_loss           | 1.8526633516557923e-05  |
| train_0/mu_grads          | -0.06846991926431656    |
| train_0/mu_grads_std      | 0.47488465905189514     |
| train_0/mu_loss           | 1.369354488737601e-13   |
| train_0/next_q            | -2.0918754074778663e-13 |
| train_0/q_grads           | 0.02320891749113798     |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.565951947229693       |
| train_0/reward            | -0.7106386499981454     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2579345703125         |
| train_0/target_q          | -0.7106386499983504     |
| train_1/avg_q             | -14.223884159745715     |
| train_1/current_q         | -11.436090067219613     |
| train_1/fw_bonus          | -0.9996123909950256     |
| train_1/fw_loss           | 0.0008458041105768643   |
| train_1/mu_grads          | -0.08885918166488409    |
| train_1/mu_grads_std      | 0.6544650122523308      |
| train_1/mu_loss           | 21.45717458042435       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.507403991568843     |
| train_1/q_grads           | -0.032302412670105696   |
| train_1/q_grads_std       | 0.6871622234582901      |
| train_1/q_loss            | 9.410829166641298       |
| train_1/reward            | -1.948011761448288      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001416015625          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.017777777777777778    |
| train_1/target_q          | -11.644134396741501     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 923.48. Rollout time: 642.26, Training time: 281.08
Evaluating epoch 33
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 33                      |
| policy/steps              | 2193318.0               |
| test/episodes             | 850.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -5.733267504881351e-13  |
| test_1/avg_q              | -14.044177495164469     |
| test_1/n_subgoals         | 678.0                   |
| test_1/subgoal_succ_rate  | 0.004424778761061947    |
| train/episodes            | 3400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -4.383530507032174e-13  |
| train_0/current_q         | -1.9743703651844054e-13 |
| train_0/fw_bonus          | -0.9999609261751174     |
| train_0/fw_loss           | 1.3616263913718285e-05  |
| train_0/mu_grads          | -0.06847003847360611    |
| train_0/mu_grads_std      | 0.47488462924957275     |
| train_0/mu_loss           | 1.268834424733704e-13   |
| train_0/next_q            | -1.3531041366111605e-13 |
| train_0/q_grads           | 0.02320898063480854     |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5695410376119664      |
| train_0/reward            | -0.7130297784700815     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2951171875            |
| train_0/target_q          | -0.713029778470214      |
| train_1/avg_q             | -13.795866784138585     |
| train_1/current_q         | -11.453111525651202     |
| train_1/fw_bonus          | -0.9999487027525902     |
| train_1/fw_loss           | 0.0007770920783514157   |
| train_1/mu_grads          | -0.0893641721457243     |
| train_1/mu_grads_std      | 0.6599487900733948      |
| train_1/mu_loss           | 21.50478718078281       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.55487726913199      |
| train_1/q_grads           | -0.033824972528964284   |
| train_1/q_grads_std       | 0.7074777156114578      |
| train_1/q_loss            | 7.41688328797868        |
| train_1/reward            | -1.9687243525382656     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0013916015625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.008148148148148147    |
| train_1/target_q          | -11.695626053426006     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 999.95. Rollout time: 694.97, Training time: 304.85
Evaluating epoch 34
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 34                      |
| policy/steps              | 2283329.0               |
| test/episodes             | 875.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -3.228042773360163e-13  |
| test_1/avg_q              | -14.511769236115216     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.164017050260673e-13  |
| train_0/current_q         | -1.6798840346629507e-13 |
| train_0/fw_bonus          | -0.9999697864055633     |
| train_0/fw_loss           | 1.1593465580972407e-05  |
| train_0/mu_grads          | -0.06847022473812103    |
| train_0/mu_grads_std      | 0.474884569644928       |
| train_0/mu_loss           | 1.4541722190366442e-13  |
| train_0/next_q            | -1.4911036597617767e-13 |
| train_0/q_grads           | 0.02320908196270466     |
| train_0/q_grads_std       | 0.29199478030204773     |
| train_0/q_loss            | 0.5639822008873908      |
| train_0/reward            | -0.7093232726569113     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.3244384765625         |
| train_0/target_q          | -0.7093232726570574     |
| train_1/avg_q             | -14.143954082424267     |
| train_1/current_q         | -11.669306750061043     |
| train_1/fw_bonus          | -1.0001343071460724     |
| train_1/fw_loss           | 0.0007391717284917831   |
| train_1/mu_grads          | -0.09109735209494829    |
| train_1/mu_grads_std      | 0.6638528048992157      |
| train_1/mu_loss           | 21.387003983674283      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.44813351802291      |
| train_1/q_grads           | -0.036370822414755824   |
| train_1/q_grads_std       | 0.7264202833175659      |
| train_1/q_loss            | 7.789418845055392       |
| train_1/reward            | -2.006060807225731      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.001513671875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.017407407407407406    |
| train_1/target_q          | -11.89495546742192      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 994.08. Rollout time: 700.17, Training time: 293.77
Evaluating epoch 35
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 35                      |
| policy/steps              | 2374123.0               |
| test/episodes             | 900.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -6.910815255062633e-15  |
| test_1/avg_q              | -14.063536181501313     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.218172722500967e-12  |
| train_0/current_q         | -1.5122839642789836e-13 |
| train_0/fw_bonus          | -0.9999591141939164     |
| train_0/fw_loss           | 1.4030438205736572e-05  |
| train_0/mu_grads          | -0.06847044825553894    |
| train_0/mu_grads_std      | 0.4748845100402832      |
| train_0/mu_loss           | 1.2900924095539586e-13  |
| train_0/next_q            | -1.456762512009966e-13  |
| train_0/q_grads           | 0.023209277959540486    |
| train_0/q_grads_std       | 0.2919948101043701      |
| train_0/q_loss            | 0.5629648958178729      |
| train_0/reward            | -0.7086465468841198     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2821044921875         |
| train_0/target_q          | -0.7086465468842624     |
| train_1/avg_q             | -14.226603700804501     |
| train_1/current_q         | -11.596326544009719     |
| train_1/fw_bonus          | -1.0001898169517518     |
| train_1/fw_loss           | 0.0007278296790900641   |
| train_1/mu_grads          | -0.09128956254571677    |
| train_1/mu_grads_std      | 0.6669529870152473      |
| train_1/mu_loss           | 21.59015376750427       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.687503139438284     |
| train_1/q_grads           | -0.03931321501731873    |
| train_1/q_grads_std       | 0.7430802926421165      |
| train_1/q_loss            | 7.23714071490546        |
| train_1/reward            | -2.0183810441660173     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0013671875            |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.005925925925925926    |
| train_1/target_q          | -11.835404785815511     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 1023.91. Rollout time: 723.14, Training time: 300.65
Evaluating epoch 36
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 36                      |
| policy/steps              | 2464721.0               |
| test/episodes             | 925.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -5.220686882548034e-15  |
| test_1/avg_q              | -14.026773402411003     |
| test_1/n_subgoals         | 678.0                   |
| test_1/subgoal_succ_rate  | 0.004424778761061947    |
| train/episodes            | 3700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.751847324996634e-12  |
| train_0/current_q         | -5.521543148424011e-13  |
| train_0/fw_bonus          | -0.9999652937054634     |
| train_0/fw_loss           | 1.2618552352705592e-05  |
| train_0/mu_grads          | -0.06847066525369883    |
| train_0/mu_grads_std      | 0.4748844802379608      |
| train_0/mu_loss           | 3.651384543624035e-13   |
| train_0/next_q            | -3.6756738130850366e-13 |
| train_0/q_grads           | 0.02320967768318951     |
| train_0/q_grads_std       | 0.2919948399066925      |
| train_0/q_loss            | 0.5642880270236056      |
| train_0/reward            | -0.7095285464143671     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.317041015625          |
| train_0/target_q          | -0.7095285464147274     |
| train_1/avg_q             | -13.990753940634248     |
| train_1/current_q         | -11.851363124961356     |
| train_1/fw_bonus          | -1.0004068285226821     |
| train_1/fw_loss           | 0.0006834933592472225   |
| train_1/mu_grads          | -0.09216294940561057    |
| train_1/mu_grads_std      | 0.6684966519474983      |
| train_1/mu_loss           | 21.624281005294854      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.726525868523176     |
| train_1/q_grads           | -0.041394214052706955   |
| train_1/q_grads_std       | 0.7586652651429177      |
| train_1/q_loss            | 6.787820264166254       |
| train_1/reward            | -1.9959797822069958     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0014892578125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.008148148148148147    |
| train_1/target_q          | -12.087361105353432     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 1042.42. Rollout time: 733.39, Training time: 308.92
Evaluating epoch 37
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-------------------------------------------------------
| epoch                     | 37                      |
| policy/steps              | 2554996.0               |
| test/episodes             | 950.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -1.410545254396279e-15  |
| test_1/avg_q              | -13.35935524088594      |
| test_1/n_subgoals         | 678.0                   |
| test_1/subgoal_succ_rate  | 0.004424778761061947    |
| train/episodes            | 3800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -1.890551972685411e-14  |
| train_0/current_q         | -4.258689755416272e-13  |
| train_0/fw_bonus          | -0.9999281942844391     |
| train_0/fw_loss           | 2.109004535668646e-05   |
| train_0/mu_grads          | -0.06847071647644043    |
| train_0/mu_grads_std      | 0.4748845100402832      |
| train_0/mu_loss           | 3.7916712669822613e-13  |
| train_0/next_q            | -3.8758729743158943e-13 |
| train_0/q_grads           | 0.02320987661369145     |
| train_0/q_grads_std       | 0.2919948399066925      |
| train_0/q_loss            | 0.564152110004398       |
| train_0/reward            | -0.7094367451813014     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1753662109375         |
| train_0/target_q          | -0.7094367451816812     |
| train_1/avg_q             | -14.118891386159978     |
| train_1/current_q         | -11.695624412662378     |
| train_1/fw_bonus          | -1.000700718164444      |
| train_1/fw_loss           | 0.0006234517190023325   |
| train_1/mu_grads          | -0.09248634725809098    |
| train_1/mu_grads_std      | 0.6720462456345558      |
| train_1/mu_loss           | 21.569357167921233      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -21.681874173722345     |
| train_1/q_grads           | -0.043439123686403035   |
| train_1/q_grads_std       | 0.7724532142281533      |
| train_1/q_loss            | 7.198187910747658       |
| train_1/reward            | -1.9699060177605134     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0010498046875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.013333333333333334    |
| train_1/target_q          | -11.937653202491669     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 1027.61. Rollout time: 740.00, Training time: 287.52
Evaluating epoch 38
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 2645858.0              |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.804203450700071e-15 |
| test_1/avg_q              | -14.127020579307597    |
| test_1/n_subgoals         | 680.0                  |
| test_1/subgoal_succ_rate  | 0.007352941176470588   |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -4.285985653537992e-12 |
| train_0/current_q         | -9.45675623420139e-13  |
| train_0/fw_bonus          | -0.9999765262007714    |
| train_0/fw_loss           | 1.0056548330794612e-05 |
| train_0/mu_grads          | -0.06847097724676132   |
| train_0/mu_grads_std      | 0.4748844802379608     |
| train_0/mu_loss           | 4.399895778701623e-13  |
| train_0/next_q            | -4.610406182509249e-13 |
| train_0/q_grads           | 0.023209909070283176   |
| train_0/q_grads_std       | 0.2919937275350094     |
| train_0/q_loss            | 0.5650679974159754     |
| train_0/reward            | -0.7100468546508637    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3239013671875        |
| train_0/target_q          | -0.7100468546513155    |
| train_1/avg_q             | -13.85685914839288     |
| train_1/current_q         | -11.687178864551006    |
| train_1/fw_bonus          | -1.0006685972213745    |
| train_1/fw_loss           | 0.0006300147972069681  |
| train_1/mu_grads          | -0.09327042736113071   |
| train_1/mu_grads_std      | 0.6737897470593452     |
| train_1/mu_loss           | 21.59380565691348      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.669116156192427    |
| train_1/q_grads           | -0.04545201603323221   |
| train_1/q_grads_std       | 0.7885376662015915     |
| train_1/q_loss            | 6.2114993102748555     |
| train_1/reward            | -1.9470139786943037    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013916015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.005555555555555556   |
| train_1/target_q          | -11.934253551565531    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 945.86. Rollout time: 659.65, Training time: 286.11
Evaluating epoch 39
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 2736694.0              |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.780917033786643    |
| test_1/avg_q              | -13.066292347773262    |
| test_1/n_subgoals         | 680.0                  |
| test_1/subgoal_succ_rate  | 0.007352941176470588   |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -9.921246165034704     |
| train_0/current_q         | -9.430888387928016     |
| train_0/fw_bonus          | -0.9999766021966934    |
| train_0/fw_loss           | 1.0039044991572154e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.486539630988045      |
| train_0/next_q            | -9.519671349434068     |
| train_0/q_grads           | 0.024229122092947364   |
| train_0/q_grads_std       | 0.2945752561092377     |
| train_0/q_loss            | 0.8345820769313537     |
| train_0/reward            | -0.7100224785106548    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3281494140625        |
| train_0/target_q          | -9.767251259427677     |
| train_1/avg_q             | -14.1165679657529      |
| train_1/current_q         | -11.567105895842014    |
| train_1/fw_bonus          | -1.0008497536182404    |
| train_1/fw_loss           | 0.0005930007144343108  |
| train_1/mu_grads          | -0.09069901704788208   |
| train_1/mu_grads_std      | 0.6760880902409554     |
| train_1/mu_loss           | 21.74391475982186      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.809302658038884    |
| train_1/q_grads           | -0.04698166493326426   |
| train_1/q_grads_std       | 0.8044573798775673     |
| train_1/q_loss            | 4.800512522841673      |
| train_1/reward            | -1.9397193096250702    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.005925925925925926   |
| train_1/target_q          | -11.803795582305357    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 901.64. Rollout time: 629.93, Training time: 271.59
Evaluating epoch 40
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 2826934.0              |
| test/episodes             | 1025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.87042065307907     |
| test_1/avg_q              | -14.385789534255942    |
| test_1/n_subgoals         | 678.0                  |
| test_1/subgoal_succ_rate  | 0.004424778761061947   |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.532719937702176    |
| train_0/current_q         | -9.432951501753829     |
| train_0/fw_bonus          | -0.9999750763177871    |
| train_0/fw_loss           | 1.0389037595359695e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.513768525528567      |
| train_0/next_q            | -9.521984319722787     |
| train_0/q_grads           | 0.02430414343252778    |
| train_0/q_grads_std       | 0.29793930277228353    |
| train_0/q_loss            | 0.9341969220346948     |
| train_0/reward            | -0.710094954330998     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.333056640625         |
| train_0/target_q          | -9.870501143481567     |
| train_1/avg_q             | -13.692287735348517    |
| train_1/current_q         | -11.694220742739185    |
| train_1/fw_bonus          | -1.00087713599205      |
| train_1/fw_loss           | 0.0005874074820894748  |
| train_1/mu_grads          | -0.09032427221536636   |
| train_1/mu_grads_std      | 0.6789796903729439     |
| train_1/mu_loss           | 21.659998650035117     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.69204489648356     |
| train_1/q_grads           | -0.048275997210294005  |
| train_1/q_grads_std       | 0.8184332579374314     |
| train_1/q_loss            | 5.223099243907418      |
| train_1/reward            | -1.9875357326993253    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013916015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.014444444444444444   |
| train_1/target_q          | -11.94430625036887     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 934.36. Rollout time: 648.26, Training time: 285.98
Evaluating epoch 41
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 2916687.0             |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.93787263354523    |
| test_1/avg_q              | -14.556515318673718   |
| test_1/n_subgoals         | 676.0                 |
| test_1/subgoal_succ_rate  | 0.0014792899408284023 |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.69904646528457    |
| train_0/current_q         | -9.57411420299663     |
| train_0/fw_bonus          | -0.9999742448329926   |
| train_0/fw_loss           | 1.057588618778027e-05 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.651968571622541     |
| train_0/next_q            | -9.650958561321286    |
| train_0/q_grads           | 0.024565637996420264  |
| train_0/q_grads_std       | 0.30568461716175077   |
| train_0/q_loss            | 0.8203344255693044    |
| train_0/reward            | -0.7108025524117693   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3450927734375       |
| train_0/target_q          | -10.041914153621365   |
| train_1/avg_q             | -14.238588533741956   |
| train_1/current_q         | -11.535587921961323   |
| train_1/fw_bonus          | -1.0011434704065323   |
| train_1/fw_loss           | 0.0005329909501597286 |
| train_1/mu_grads          | -0.0913148932158947   |
| train_1/mu_grads_std      | 0.683649368584156     |
| train_1/mu_loss           | 21.683674441307364    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.725970552706446   |
| train_1/q_grads           | -0.05056478697806597  |
| train_1/q_grads_std       | 0.8316808849573135    |
| train_1/q_loss            | 5.680203652476747     |
| train_1/reward            | -1.9572489832578868   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.022222222222222223  |
| train_1/target_q          | -11.769340685238603   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 930.99. Rollout time: 650.54, Training time: 280.34
Evaluating epoch 42
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3007760.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.98473083718226     |
| test_1/avg_q              | -14.576862541751439    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.973175786064292    |
| train_0/current_q         | -9.523702650186062     |
| train_0/fw_bonus          | -0.9999683991074562    |
| train_0/fw_loss           | 1.1906580618870067e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.588643622271231      |
| train_0/next_q            | -9.590900708562199     |
| train_0/q_grads           | 0.024468887178227306   |
| train_0/q_grads_std       | 0.31030615121126176    |
| train_0/q_loss            | 0.9564871190555506     |
| train_0/reward            | -0.7106165318233252    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3212646484375        |
| train_0/target_q          | -10.010219790251483    |
| train_1/avg_q             | -14.162847661527197    |
| train_1/current_q         | -11.554441697089965    |
| train_1/fw_bonus          | -1.00110684633255      |
| train_1/fw_loss           | 0.0005404755254858173  |
| train_1/mu_grads          | -0.09116164296865463   |
| train_1/mu_grads_std      | 0.6875361770391464     |
| train_1/mu_loss           | 21.652133173376047     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.666842747731817    |
| train_1/q_grads           | -0.052973049134016036  |
| train_1/q_grads_std       | 0.8442541867494583     |
| train_1/q_loss            | 5.511520711085684      |
| train_1/reward            | -1.9170451186626452    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0007407407407407407  |
| train_1/target_q          | -11.812076283924677    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 985.08. Rollout time: 697.56, Training time: 287.39
Evaluating epoch 43
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 3098885.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99979492380181     |
| test_1/avg_q              | -14.082456848698145    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.981076440737212    |
| train_0/current_q         | -9.630405517524908     |
| train_0/fw_bonus          | -0.999960869550705     |
| train_0/fw_loss           | 1.3626564259539009e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.703906889872355      |
| train_0/next_q            | -9.700172520874887     |
| train_0/q_grads           | 0.024246210837736724   |
| train_0/q_grads_std       | 0.3140925332903862     |
| train_0/q_loss            | 1.0795548015421188     |
| train_0/reward            | -0.711735810717073     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.310888671875         |
| train_0/target_q          | -10.124408732475818    |
| train_1/avg_q             | -14.129177261970472    |
| train_1/current_q         | -11.48774405581263     |
| train_1/fw_bonus          | -1.0013039499521255    |
| train_1/fw_loss           | 0.0005002052334020845  |
| train_1/mu_grads          | -0.09167678728699684   |
| train_1/mu_grads_std      | 0.6905787751078606     |
| train_1/mu_loss           | 21.59974124727355      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.61246613612342     |
| train_1/q_grads           | -0.05527854925021529   |
| train_1/q_grads_std       | 0.8550909027457237     |
| train_1/q_loss            | 5.091956622874934      |
| train_1/reward            | -1.9897755074060115    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010986328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.760210204758033    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 44
Time for epoch 44: 915.05. Rollout time: 645.05, Training time: 269.86
Evaluating epoch 44
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 3189964.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.980486873622286    |
| test_1/avg_q              | -14.050547090550396    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.978058729088968    |
| train_0/current_q         | -9.664546866246072     |
| train_0/fw_bonus          | -0.9999717757105827    |
| train_0/fw_loss           | 1.1139986565922299e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.742940648751475      |
| train_0/next_q            | -9.731848518235624     |
| train_0/q_grads           | 0.024119249358773232   |
| train_0/q_grads_std       | 0.3163011446595192     |
| train_0/q_loss            | 0.9146163713555364     |
| train_0/reward            | -0.7119487775853486    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3378662109375        |
| train_0/target_q          | -10.161149369136254    |
| train_1/avg_q             | -14.052982439723882    |
| train_1/current_q         | -11.52150796893785     |
| train_1/fw_bonus          | -1.0012803375720978    |
| train_1/fw_loss           | 0.0005050306877819821  |
| train_1/mu_grads          | -0.09041511192917824   |
| train_1/mu_grads_std      | 0.6924849912524224     |
| train_1/mu_loss           | 21.626852769171183     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.63244636961114     |
| train_1/q_grads           | -0.05612357761710882   |
| train_1/q_grads_std       | 0.8654581755399704     |
| train_1/q_loss            | 6.590477313842136      |
| train_1/reward            | -1.9531181911297608    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001513671875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0007407407407407407  |
| train_1/target_q          | -11.792188590461384    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 45
Time for epoch 45: 903.33. Rollout time: 633.06, Training time: 270.14
Evaluating epoch 45
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 45                    |
| policy/steps              | 3281008.0             |
| test/episodes             | 1150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.99914376250574    |
| test_1/avg_q              | -14.062107630808574   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.98602719999221    |
| train_0/current_q         | -9.53246728866842     |
| train_0/fw_bonus          | -0.9999868422746658   |
| train_0/fw_loss           | 7.699993659571192e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.610235112765796     |
| train_0/next_q            | -9.60686090739178     |
| train_0/q_grads           | 0.023808227386325598  |
| train_0/q_grads_std       | 0.318939308822155     |
| train_0/q_loss            | 1.0291886413026634    |
| train_0/reward            | -0.7092585600359598   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.359765625           |
| train_0/target_q          | -10.034108482239555   |
| train_1/avg_q             | -14.011213821743322   |
| train_1/current_q         | -11.453280813711611   |
| train_1/fw_bonus          | -1.001318797469139    |
| train_1/fw_loss           | 0.0004971664755430538 |
| train_1/mu_grads          | -0.09162838850170374  |
| train_1/mu_grads_std      | 0.6939597889780998    |
| train_1/mu_loss           | 21.717070668418806    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.720441605274416   |
| train_1/q_grads           | -0.058143737353384496 |
| train_1/q_grads_std       | 0.8749694332480431    |
| train_1/q_loss            | 4.7150007902351785    |
| train_1/reward            | -1.9648073594078597   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001123046875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0014814814814814814 |
| train_1/target_q          | -11.720235964305592   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 46
Time for epoch 46: 901.04. Rollout time: 632.42, Training time: 268.48
Evaluating epoch 46
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 3372099.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999996223256    |
| test_1/avg_q              | -13.91912097158355     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.98427162738915     |
| train_0/current_q         | -9.639407016637339     |
| train_0/fw_bonus          | -0.9999706462025643    |
| train_0/fw_loss           | 1.1396170384614379e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.697702858882996      |
| train_0/next_q            | -9.690531946337705     |
| train_0/q_grads           | 0.02351975655183196    |
| train_0/q_grads_std       | 0.32017752379179       |
| train_0/q_loss            | 0.6494726079915776     |
| train_0/reward            | -0.710959447069763     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3312744140625        |
| train_0/target_q          | -10.14435202658349     |
| train_1/avg_q             | -14.076058228870833    |
| train_1/current_q         | -11.48410161886622     |
| train_1/fw_bonus          | -1.0014703661203384    |
| train_1/fw_loss           | 0.0004662008439481724  |
| train_1/mu_grads          | -0.09084828291088343   |
| train_1/mu_grads_std      | 0.695142051577568      |
| train_1/mu_loss           | 21.747843770802085     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.753846952086374    |
| train_1/q_grads           | -0.05988155091181398   |
| train_1/q_grads_std       | 0.8819011360406875     |
| train_1/q_loss            | 4.269278395112561      |
| train_1/reward            | -1.9807400740544836    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0007407407407407407  |
| train_1/target_q          | -11.742050060827925    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 47
Time for epoch 47: 904.29. Rollout time: 638.68, Training time: 265.50
Evaluating epoch 47
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 3463224.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.487105632523186    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999957620705     |
| train_0/current_q         | -9.558182590800683     |
| train_0/fw_bonus          | -0.999975772202015     |
| train_0/fw_loss           | 1.0229663973859716e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.625365581357393      |
| train_0/next_q            | -9.613620410357337     |
| train_0/q_grads           | 0.023558370163664223   |
| train_0/q_grads_std       | 0.32153446823358534    |
| train_0/q_loss            | 0.8290976786871991     |
| train_0/reward            | -0.7090821198857157    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.34619140625          |
| train_0/target_q          | -10.060786192718174    |
| train_1/avg_q             | -14.041027567911692    |
| train_1/current_q         | -11.329255955208245    |
| train_1/fw_bonus          | -1.0014472395181655    |
| train_1/fw_loss           | 0.0004709264678240288  |
| train_1/mu_grads          | -0.09115829225629568   |
| train_1/mu_grads_std      | 0.6960071548819542     |
| train_1/mu_loss           | 21.78670955340834      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.793629208325388    |
| train_1/q_grads           | -0.06062148753553629   |
| train_1/q_grads_std       | 0.889171913266182      |
| train_1/q_loss            | 4.50348832465784       |
| train_1/reward            | -1.9909824154783564    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0012939453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.59540380000613     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 910.67. Rollout time: 643.86, Training time: 266.71
Evaluating epoch 48
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 3554349.0              |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.602614327084758    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999999996    |
| train_0/current_q         | -9.544079321497625     |
| train_0/fw_bonus          | -0.9999605745077134    |
| train_0/fw_loss           | 1.3698180237042833e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.612606303669654      |
| train_0/next_q            | -9.604345718410784     |
| train_0/q_grads           | 0.02354330914095044    |
| train_0/q_grads_std       | 0.3230501674115658     |
| train_0/q_loss            | 0.7432123150748625     |
| train_0/reward            | -0.70847637637562      |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3182861328125        |
| train_0/target_q          | -10.045245101928275    |
| train_1/avg_q             | -14.133631602908189    |
| train_1/current_q         | -11.29176256539446     |
| train_1/fw_bonus          | -1.0014421224594117    |
| train_1/fw_loss           | 0.00047197197636705823 |
| train_1/mu_grads          | -0.09143774472177028   |
| train_1/mu_grads_std      | 0.6966412097215653     |
| train_1/mu_loss           | 21.79000002346192      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.799194570182728    |
| train_1/q_grads           | -0.06135074989870191   |
| train_1/q_grads_std       | 0.895523051917553      |
| train_1/q_loss            | 5.069600005541185      |
| train_1/reward            | -1.9647835670977656    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009765625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.564237346829955    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 794.93. Rollout time: 554.29, Training time: 240.56
Evaluating epoch 49
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 3645474.0              |
| test/episodes             | 1250.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999115383435644    |
| test_1/avg_q              | -13.854751733205113    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.995842001330132    |
| train_0/current_q         | -9.546963464987684     |
| train_0/fw_bonus          | -0.9999800980091095    |
| train_0/fw_loss           | 9.238857023774471e-06  |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.576342777215132      |
| train_0/next_q            | -9.601509790762233     |
| train_0/q_grads           | 0.023628061497583987   |
| train_0/q_grads_std       | 0.3240201108157635     |
| train_0/q_loss            | 0.9488762111386706     |
| train_0/reward            | -0.709499329522805     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.352490234375         |
| train_0/target_q          | -10.051580907998783    |
| train_1/avg_q             | -14.177057337130693    |
| train_1/current_q         | -11.338437157637609    |
| train_1/fw_bonus          | -1.0016619622707368    |
| train_1/fw_loss           | 0.00042706089589046315 |
| train_1/mu_grads          | -0.09142745826393366   |
| train_1/mu_grads_std      | 0.6967925399541854     |
| train_1/mu_loss           | 21.709001030567137     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.718384590416626    |
| train_1/q_grads           | -0.06249381937086582   |
| train_1/q_grads_std       | 0.9022496566176414     |
| train_1/q_loss            | 3.717633540244269      |
| train_1/reward            | -1.9699593954683223    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.600776269401553    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 752.17. Rollout time: 507.56, Training time: 244.54
Evaluating epoch 50
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 3736599.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999955474387   |
| test_1/avg_q              | -14.403465422510722   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.997596973292097   |
| train_0/current_q         | -9.607190290826635    |
| train_0/fw_bonus          | -0.9999777674674988   |
| train_0/fw_loss           | 9.769922371560824e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.672480269985389     |
| train_0/next_q            | -9.67041965403884     |
| train_0/q_grads           | 0.023717670515179635  |
| train_0/q_grads_std       | 0.32535488680005076   |
| train_0/q_loss            | 0.9375725246395765    |
| train_0/reward            | -0.7097423066203191   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.328466796875        |
| train_0/target_q          | -10.108692807737635   |
| train_1/avg_q             | -13.95580542513856    |
| train_1/current_q         | -11.306789142716271   |
| train_1/fw_bonus          | -1.0018087387084962   |
| train_1/fw_loss           | 0.0003970735393522773 |
| train_1/mu_grads          | -0.0913984090089798   |
| train_1/mu_grads_std      | 0.6968136116862297    |
| train_1/mu_loss           | 21.77239087498768     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.723343707217197   |
| train_1/q_grads           | -0.06266918666660785  |
| train_1/q_grads_std       | 0.9073522195219994    |
| train_1/q_loss            | 5.827325723113203     |
| train_1/reward            | -1.9738169631680649   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.587432159278467   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 896.80. Rollout time: 608.63, Training time: 288.09
Evaluating epoch 51
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 3827724.0              |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999997601066344    |
| test_1/avg_q              | -14.258250162097042    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999972565     |
| train_0/current_q         | -9.624991425464511     |
| train_0/fw_bonus          | -0.9999757617712021    |
| train_0/fw_loss           | 1.0230765929009067e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.670689001383133      |
| train_0/next_q            | -9.677977367686344     |
| train_0/q_grads           | 0.024160789884626867   |
| train_0/q_grads_std       | 0.3271693423390388     |
| train_0/q_loss            | 0.7536023221608539     |
| train_0/reward            | -0.709497156303405     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.36767578125          |
| train_0/target_q          | -10.12636453583097     |
| train_1/avg_q             | -14.132359329849214    |
| train_1/current_q         | -11.414414876924942    |
| train_1/fw_bonus          | -1.0017511039972304    |
| train_1/fw_loss           | 0.0004088462927029468  |
| train_1/mu_grads          | -0.090096334554255     |
| train_1/mu_grads_std      | 0.699216715991497      |
| train_1/mu_loss           | 21.742465495739744     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.76829964817328     |
| train_1/q_grads           | -0.06255617467686533   |
| train_1/q_grads_std       | 0.9132438883185386     |
| train_1/q_loss            | 5.124501267276191      |
| train_1/reward            | -1.9941006519613438    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009765625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.696378520256019    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 750.15. Rollout time: 508.57, Training time: 241.49
Evaluating epoch 52
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 3918849.0              |
| test/episodes             | 1325.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999332908988     |
| test_1/avg_q              | -14.476848362240142    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.995775475750467    |
| train_0/current_q         | -9.658935887963999     |
| train_0/fw_bonus          | -0.9999853223562241    |
| train_0/fw_loss           | 8.0460924664294e-06    |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.729276349295587      |
| train_0/next_q            | -9.730599716649987     |
| train_0/q_grads           | 0.024122932413592934   |
| train_0/q_grads_std       | 0.32896674498915673    |
| train_0/q_loss            | 0.9327986346075061     |
| train_0/reward            | -0.7091601454478222    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.367529296875         |
| train_0/target_q          | -10.158329385191191    |
| train_1/avg_q             | -14.083847939622402    |
| train_1/current_q         | -11.558895402788412    |
| train_1/fw_bonus          | -1.001885685324669     |
| train_1/fw_loss           | 0.00038134678106871434 |
| train_1/mu_grads          | -0.08978398200124502   |
| train_1/mu_grads_std      | 0.6996897339820862     |
| train_1/mu_loss           | 21.72893543905411      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.745631009971294    |
| train_1/q_grads           | -0.06390054654330016   |
| train_1/q_grads_std       | 0.9198999434709549     |
| train_1/q_loss            | 5.159733216910285      |
| train_1/reward            | -1.9721220520572387    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.838865860613371    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 754.46. Rollout time: 511.20, Training time: 243.19
Evaluating epoch 53
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 4009974.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999990372    |
| test_1/avg_q              | -13.898920946196261    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99948015566663     |
| train_0/current_q         | -9.703181322038583     |
| train_0/fw_bonus          | -0.9999846190214157    |
| train_0/fw_loss           | 8.21085030793256e-06   |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.75353577754672       |
| train_0/next_q            | -9.761520645865314     |
| train_0/q_grads           | 0.024840327352285384   |
| train_0/q_grads_std       | 0.33053864762187       |
| train_0/q_loss            | 0.8125070236252551     |
| train_0/reward            | -0.7115157415857538    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3753662109375        |
| train_0/target_q          | -10.20717960565003     |
| train_1/avg_q             | -14.19769256210571     |
| train_1/current_q         | -11.586236645398092    |
| train_1/fw_bonus          | -1.0020147740840912    |
| train_1/fw_loss           | 0.00035497850549290886 |
| train_1/mu_grads          | -0.08913197033107281   |
| train_1/mu_grads_std      | 0.7019454181194306     |
| train_1/mu_loss           | 21.735409179544654     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.78233971180091     |
| train_1/q_grads           | -0.06513334494084119   |
| train_1/q_grads_std       | 0.9268287986516952     |
| train_1/q_loss            | 7.144607586194207      |
| train_1/reward            | -1.9803286734269931    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.875510540924619    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 749.14. Rollout time: 506.97, Training time: 242.09
Evaluating epoch 54
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 4101099.0              |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999999539     |
| test_1/avg_q              | -14.147733714055077    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999965038253    |
| train_0/current_q         | -9.725930997087415     |
| train_0/fw_bonus          | -0.9999854996800422    |
| train_0/fw_loss           | 8.006841153473942e-06  |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.776764758521065      |
| train_0/next_q            | -9.791126038041197     |
| train_0/q_grads           | 0.024920221883803606   |
| train_0/q_grads_std       | 0.33248575553298       |
| train_0/q_loss            | 0.8682608178032701     |
| train_0/reward            | -0.7117603293874708    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.377783203125         |
| train_0/target_q          | -10.232083914610788    |
| train_1/avg_q             | -13.985692482589814    |
| train_1/current_q         | -11.447452622660839    |
| train_1/fw_bonus          | -1.0018783390522004    |
| train_1/fw_loss           | 0.00038285408591036684 |
| train_1/mu_grads          | -0.08920835442841053   |
| train_1/mu_grads_std      | 0.7039201214909554     |
| train_1/mu_loss           | 21.73619571087904      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.77151950189587     |
| train_1/q_grads           | -0.06521250940859318   |
| train_1/q_grads_std       | 0.9355030104517936     |
| train_1/q_loss            | 4.130874355092457      |
| train_1/reward            | -1.979235062940279     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.702044262459953    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 758.61. Rollout time: 511.50, Training time: 247.04
Evaluating epoch 55
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 4192224.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999999677435    |
| test_1/avg_q              | -13.88800309056289     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.99999999946364     |
| train_0/current_q         | -9.59004586035539      |
| train_0/fw_bonus          | -0.9999663770198822    |
| train_0/fw_loss           | 1.2371120800480639e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.653122411546285      |
| train_0/next_q            | -9.650691794503867     |
| train_0/q_grads           | 0.024520491156727074   |
| train_0/q_grads_std       | 0.3338695473968983     |
| train_0/q_loss            | 1.017240092243569      |
| train_0/reward            | -0.7117019401368452    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.349658203125         |
| train_0/target_q          | -10.092319484242008    |
| train_1/avg_q             | -14.039175115585369    |
| train_1/current_q         | -11.567359586050161    |
| train_1/fw_bonus          | -1.001814168691635     |
| train_1/fw_loss           | 0.00039596444185008295 |
| train_1/mu_grads          | -0.08822461254894734   |
| train_1/mu_grads_std      | 0.7071057811379433     |
| train_1/mu_loss           | 21.74837748921125      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.78613861147069     |
| train_1/q_grads           | -0.06577165555208922   |
| train_1/q_grads_std       | 0.9453392520546913     |
| train_1/q_loss            | 4.139148926933872      |
| train_1/reward            | -2.002457372091885     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009521484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.833793347981707    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 762.24. Rollout time: 516.99, Training time: 245.16
Evaluating epoch 56
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 4283349.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99999999988079     |
| test_1/avg_q              | -14.163199075079563    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999996867903914    |
| train_0/current_q         | -9.528657187140293     |
| train_0/fw_bonus          | -0.9999741196632386    |
| train_0/fw_loss           | 1.0602665668102418e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.590382199857952      |
| train_0/next_q            | -9.585956143131279     |
| train_0/q_grads           | 0.024653309769928456   |
| train_0/q_grads_std       | 0.3346999198198318     |
| train_0/q_loss            | 0.6560207835912268     |
| train_0/reward            | -0.708043705050659     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3409423828125        |
| train_0/target_q          | -10.03311048183591     |
| train_1/avg_q             | -13.975751312337099    |
| train_1/current_q         | -11.775333024544494    |
| train_1/fw_bonus          | -1.0017768800258637    |
| train_1/fw_loss           | 0.00040358237092732454 |
| train_1/mu_grads          | -0.08489615153521299   |
| train_1/mu_grads_std      | 0.7106895089149475     |
| train_1/mu_loss           | 21.696820183881222     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.729950815572348    |
| train_1/q_grads           | -0.06805719174444676   |
| train_1/q_grads_std       | 0.953545731306076      |
| train_1/q_loss            | 3.823848873140752      |
| train_1/reward            | -1.9985935147866258    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008544921875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.047333811532045    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 751.48. Rollout time: 509.55, Training time: 241.85
Evaluating epoch 57
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 57                    |
| policy/steps              | 4374474.0             |
| test/episodes             | 1450.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999993216527   |
| test_1/avg_q              | -14.1719043238564     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999809816448   |
| train_0/current_q         | -9.620502061899018    |
| train_0/fw_bonus          | -0.9999777466058731   |
| train_0/fw_loss           | 9.774658008154801e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.674944518880173     |
| train_0/next_q            | -9.669048473188095    |
| train_0/q_grads           | 0.02532119881361723   |
| train_0/q_grads_std       | 0.3371996693313122    |
| train_0/q_loss            | 0.6829820957301991    |
| train_0/reward            | -0.7107921008500853   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.361669921875        |
| train_0/target_q          | -10.127357829696031   |
| train_1/avg_q             | -14.04159014294872    |
| train_1/current_q         | -11.62503477103656    |
| train_1/fw_bonus          | -1.0019804120063782   |
| train_1/fw_loss           | 0.000361998471635161  |
| train_1/mu_grads          | -0.08004398588091136  |
| train_1/mu_grads_std      | 0.7132346019148826    |
| train_1/mu_loss           | 21.71567462982715     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.7387107384484     |
| train_1/q_grads           | -0.06999139301478863  |
| train_1/q_grads_std       | 0.96249158680439      |
| train_1/q_loss            | 3.9774400114732473    |
| train_1/reward            | -1.9849135441225372   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.905205483843938   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 760.02. Rollout time: 514.10, Training time: 245.81
Evaluating epoch 58
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 4465599.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999999998183814   |
| test_1/avg_q              | -13.987715381883087   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999205772287   |
| train_0/current_q         | -9.510348566963192    |
| train_0/fw_bonus          | -0.9999810591340065   |
| train_0/fw_loss           | 9.019744516081118e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.563965760157496     |
| train_0/next_q            | -9.562097642564982    |
| train_0/q_grads           | 0.02520948206074536   |
| train_0/q_grads_std       | 0.3397636696696281    |
| train_0/q_loss            | 0.9067137545095623    |
| train_0/reward            | -0.7100247116475658   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3658935546875       |
| train_0/target_q          | -10.016371580708116   |
| train_1/avg_q             | -14.104307558169527   |
| train_1/current_q         | -11.635874612330388   |
| train_1/fw_bonus          | -1.0019733548164367   |
| train_1/fw_loss           | 0.0003634431879618205 |
| train_1/mu_grads          | -0.07881128899753094  |
| train_1/mu_grads_std      | 0.7146980330348015    |
| train_1/mu_loss           | 21.677368533059667    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.727388624407627   |
| train_1/q_grads           | -0.07140413038432598  |
| train_1/q_grads_std       | 0.9698657289147377    |
| train_1/q_loss            | 4.5102029437876325    |
| train_1/reward            | -1.986338230943511    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000830078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.9053506489763     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 763.90. Rollout time: 510.04, Training time: 253.79
Evaluating epoch 59
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 4556724.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -26.999977519954097   |
| test_1/avg_q              | -14.051186494276534   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999866435818   |
| train_0/current_q         | -9.428693894883953    |
| train_0/fw_bonus          | -0.999977944791317    |
| train_0/fw_loss           | 9.732311218613176e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.445761101932225     |
| train_0/next_q            | -9.458409321943165    |
| train_0/q_grads           | 0.024796572281047702  |
| train_0/q_grads_std       | 0.341343192756176     |
| train_0/q_loss            | 0.8002382232972132    |
| train_0/reward            | -0.7115734434359183   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3694580078125       |
| train_0/target_q          | -9.94407126032657     |
| train_1/avg_q             | -14.024428653429059   |
| train_1/current_q         | -11.54180287459292    |
| train_1/fw_bonus          | -1.0019451349973678   |
| train_1/fw_loss           | 0.0003692056066938676 |
| train_1/mu_grads          | -0.07851341366767883  |
| train_1/mu_grads_std      | 0.716054804623127     |
| train_1/mu_loss           | 21.65252435662918     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.69526827789468    |
| train_1/q_grads           | -0.07211993597447872  |
| train_1/q_grads_std       | 0.9765572533011436    |
| train_1/q_loss            | 3.049857449161586     |
| train_1/reward            | -2.006441315152915    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.813161984988207   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 752.41. Rollout time: 509.23, Training time: 243.08
Evaluating epoch 60
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 4647849.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.95748381203076     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.9995461360985      |
| train_0/current_q         | -9.575294938181298     |
| train_0/fw_bonus          | -0.9999588951468468    |
| train_0/fw_loss           | 1.4079030449920538e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.63041533016393       |
| train_0/next_q            | -9.628895755268479     |
| train_0/q_grads           | 0.024638938857242464   |
| train_0/q_grads_std       | 0.34366160482168195    |
| train_0/q_loss            | 0.9212052874936358     |
| train_0/reward            | -0.7125893116914085    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.32880859375          |
| train_0/target_q          | -10.088423222696813    |
| train_1/avg_q             | -14.034905729718972    |
| train_1/current_q         | -11.513154484953386    |
| train_1/fw_bonus          | -1.0018677443265915    |
| train_1/fw_loss           | 0.00038501746021211145 |
| train_1/mu_grads          | -0.07848690785467624   |
| train_1/mu_grads_std      | 0.7174655333161354     |
| train_1/mu_loss           | 21.726238011935088     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.74594041845263     |
| train_1/q_grads           | -0.07405923698097468   |
| train_1/q_grads_std       | 0.9824911385774613     |
| train_1/q_loss            | 3.628112251441121      |
| train_1/reward            | -1.9632873854265198    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.773026198693454    |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 754.29. Rollout time: 507.16, Training time: 247.06
Evaluating epoch 61
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 61                     |
| policy/steps              | 4738974.0              |
| test/episodes             | 1550.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.999999994284824    |
| test_1/avg_q              | -14.140608122933438    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999998967913964    |
| train_0/current_q         | -9.511925628105264     |
| train_0/fw_bonus          | -0.9999821841716766    |
| train_0/fw_loss           | 8.763984430970595e-06  |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.580169280166924      |
| train_0/next_q            | -9.585103246912425     |
| train_0/q_grads           | 0.02465083971619606    |
| train_0/q_grads_std       | 0.3466262839734554     |
| train_0/q_loss            | 0.8439933350291667     |
| train_0/reward            | -0.7084017368521017    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3575439453125        |
| train_0/target_q          | -10.014800930992012    |
| train_1/avg_q             | -13.996422557963708    |
| train_1/current_q         | -11.46828172352445     |
| train_1/fw_bonus          | -1.001950353384018     |
| train_1/fw_loss           | 0.00036813834303757177 |
| train_1/mu_grads          | -0.07781477700918912   |
| train_1/mu_grads_std      | 0.7176722049713135     |
| train_1/mu_loss           | 21.833981357708254     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.81090895639938     |
| train_1/q_grads           | -0.07537828981876374   |
| train_1/q_grads_std       | 0.9891797080636024     |
| train_1/q_loss            | 3.8116343599798066     |
| train_1/reward            | -1.9565537909162232    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.748990149579944    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 761.22. Rollout time: 516.16, Training time: 244.99
Evaluating epoch 62
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 4830099.0             |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.959349567565761   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999983694686   |
| train_0/current_q         | -9.64204547503292     |
| train_0/fw_bonus          | -0.9999905169010163   |
| train_0/fw_loss           | 6.863277258162271e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.707108073878954     |
| train_0/next_q            | -9.70519482228277     |
| train_0/q_grads           | 0.024729475565254688  |
| train_0/q_grads_std       | 0.349353189766407     |
| train_0/q_loss            | 0.7667304442507898    |
| train_0/reward            | -0.7107740651073982   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.375927734375        |
| train_0/target_q          | -10.147948869589694   |
| train_1/avg_q             | -14.089460093177602   |
| train_1/current_q         | -11.57218608123354    |
| train_1/fw_bonus          | -1.0019833624362946   |
| train_1/fw_loss           | 0.0003613956971094012 |
| train_1/mu_grads          | -0.07785372566431761  |
| train_1/mu_grads_std      | 0.7176823809742927    |
| train_1/mu_loss           | 21.81639500258524     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.782850014492208   |
| train_1/q_grads           | -0.0772067228332162   |
| train_1/q_grads_std       | 0.9945007562637329    |
| train_1/q_loss            | 4.224990104218271     |
| train_1/reward            | -2.005007792296965    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00068359375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.847753974801861   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 753.21. Rollout time: 508.43, Training time: 244.70
Evaluating epoch 63
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 4921224.0              |
| test/episodes             | 1600.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.905546430428958    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.643360748979925     |
| train_0/fw_bonus          | -0.999976459145546     |
| train_0/fw_loss           | 1.0072855275211623e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.72529510561514       |
| train_0/next_q            | -9.710330752975425     |
| train_0/q_grads           | 0.024445965234190226   |
| train_0/q_grads_std       | 0.35196527987718584    |
| train_0/q_loss            | 0.9348949921279729     |
| train_0/reward            | -0.7103397873994254    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3218017578125        |
| train_0/target_q          | -10.149846646106841    |
| train_1/avg_q             | -14.023192938409117    |
| train_1/current_q         | -11.41630339579722     |
| train_1/fw_bonus          | -1.00211081802845      |
| train_1/fw_loss           | 0.00033535103866597635 |
| train_1/mu_grads          | -0.07793979346752167   |
| train_1/mu_grads_std      | 0.7176179885864258     |
| train_1/mu_loss           | 21.81656876858239      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.824790325687466    |
| train_1/q_grads           | -0.07868567109107971   |
| train_1/q_grads_std       | 1.0012188255786896     |
| train_1/q_loss            | 6.374844129340102      |
| train_1/reward            | -1.9800715305922494    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.690430476244467    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 759.30. Rollout time: 514.92, Training time: 244.29
Evaluating epoch 64
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 5012349.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.977558416121981    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.526506542214216     |
| train_0/fw_bonus          | -0.9999727979302406    |
| train_0/fw_loss           | 1.09053563278394e-05   |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.581986390722705      |
| train_0/next_q            | -9.59096158552517      |
| train_0/q_grads           | 0.02402441422455013    |
| train_0/q_grads_std       | 0.3556527577340603     |
| train_0/q_loss            | 0.8827409876379566     |
| train_0/reward            | -0.7092881588236196    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3623291015625        |
| train_0/target_q          | -10.035492771369107    |
| train_1/avg_q             | -13.983328603303434    |
| train_1/current_q         | -11.575715894243775    |
| train_1/fw_bonus          | -1.0020852923393249    |
| train_1/fw_loss           | 0.00034056882068398406 |
| train_1/mu_grads          | -0.07622927371412516   |
| train_1/mu_grads_std      | 0.7209103733301163     |
| train_1/mu_loss           | 21.79853982179148      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.830154438086595    |
| train_1/q_grads           | -0.07896556723862887   |
| train_1/q_grads_std       | 1.0095469564199449     |
| train_1/q_loss            | 4.465556753444828      |
| train_1/reward            | -2.0152028044285544    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.828286006953615    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 756.60. Rollout time: 518.69, Training time: 237.82
Evaluating epoch 65
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 65                     |
| policy/steps              | 5103474.0              |
| test/episodes             | 1650.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.97287652244966     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.999999999999993    |
| train_0/current_q         | -9.528016164372778     |
| train_0/fw_bonus          | -0.9999795451760292    |
| train_0/fw_loss           | 9.36477796926738e-06   |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.58615907459488       |
| train_0/next_q            | -9.598700293918366     |
| train_0/q_grads           | 0.023802383104339242   |
| train_0/q_grads_std       | 0.3581176847219467     |
| train_0/q_loss            | 0.9008153498530742     |
| train_0/reward            | -0.7077900693373522    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3737060546875        |
| train_0/target_q          | -10.030792723770915    |
| train_1/avg_q             | -13.987252608597288    |
| train_1/current_q         | -11.53387430293572     |
| train_1/fw_bonus          | -1.0020451486110686    |
| train_1/fw_loss           | 0.00034876976496889256 |
| train_1/mu_grads          | -0.07628092654049397   |
| train_1/mu_grads_std      | 0.7221774965524673     |
| train_1/mu_loss           | 21.80232183359565      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.817210774711764    |
| train_1/q_grads           | -0.08044499233365059   |
| train_1/q_grads_std       | 1.0159705221652984     |
| train_1/q_loss            | 4.000134938333841      |
| train_1/reward            | -1.987277459865436     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.804676367067092    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 683.61. Rollout time: 451.86, Training time: 231.68
Evaluating epoch 66
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 5194599.0             |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.848264085815808   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.591511708205223    |
| train_0/fw_bonus          | -0.9999812200665474   |
| train_0/fw_loss           | 8.985665806449105e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.648142951301441     |
| train_0/next_q            | -9.657913804331134    |
| train_0/q_grads           | 0.02326490208506584   |
| train_0/q_grads_std       | 0.36128430962562563   |
| train_0/q_loss            | 0.7247705495387574    |
| train_0/reward            | -0.7089505675750842   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.334130859375        |
| train_0/target_q          | -10.094910010107549   |
| train_1/avg_q             | -14.001594906428023   |
| train_1/current_q         | -11.487563209188078   |
| train_1/fw_bonus          | -1.0020668983459473   |
| train_1/fw_loss           | 0.0003443280373176094 |
| train_1/mu_grads          | -0.07607020288705826  |
| train_1/mu_grads_std      | 0.7227007016539574    |
| train_1/mu_loss           | 21.676397833301735    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.731914905626944   |
| train_1/q_grads           | -0.08158097602427006  |
| train_1/q_grads_std       | 1.0242126435041428    |
| train_1/q_loss            | 6.13673743032638      |
| train_1/reward            | -2.0123615735203204   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00078125            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.774628676463962   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 640.53. Rollout time: 413.15, Training time: 227.33
Evaluating epoch 67
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 5285724.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.072954067785128    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.65746028703102      |
| train_0/fw_bonus          | -0.9999868720769882    |
| train_0/fw_loss           | 7.69224061514251e-06   |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.72451675036812       |
| train_0/next_q            | -9.715013659770474     |
| train_0/q_grads           | 0.022279118420556188   |
| train_0/q_grads_std       | 0.3655071444809437     |
| train_0/q_loss            | 0.7385016525959249     |
| train_0/reward            | -0.7121394364679873    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3800048828125        |
| train_0/target_q          | -10.164298224779074    |
| train_1/avg_q             | -13.977543907190134    |
| train_1/current_q         | -11.438359234278332    |
| train_1/fw_bonus          | -1.0020449489355088    |
| train_1/fw_loss           | 0.00034881109168054535 |
| train_1/mu_grads          | -0.07465345747768878   |
| train_1/mu_grads_std      | 0.7254126325249672     |
| train_1/mu_loss           | 21.71369665861087      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.784826005788368    |
| train_1/q_grads           | -0.08313219733536244   |
| train_1/q_grads_std       | 1.0329883456230164     |
| train_1/q_loss            | 5.120475330760201      |
| train_1/reward            | -1.9765229650955007    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.703377548463632    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 634.51. Rollout time: 411.12, Training time: 223.34
Evaluating epoch 68
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 5376849.0             |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.011255494690356   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.355593856615986    |
| train_0/fw_bonus          | -0.9999865874648094   |
| train_0/fw_loss           | 7.76098704591277e-06  |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.413843336781962     |
| train_0/next_q            | -9.406012484847883    |
| train_0/q_grads           | 0.021567871142178775  |
| train_0/q_grads_std       | 0.3688525542616844    |
| train_0/q_loss            | 0.6517528258482475    |
| train_0/reward            | -0.7068048132983676   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3569091796875       |
| train_0/target_q          | -9.864001108504912    |
| train_1/avg_q             | -14.020569930753847   |
| train_1/current_q         | -11.41517382081906    |
| train_1/fw_bonus          | -1.00207277238369     |
| train_1/fw_loss           | 0.0003431261400692165 |
| train_1/mu_grads          | -0.07340288646519184  |
| train_1/mu_grads_std      | 0.7263324081897735    |
| train_1/mu_loss           | 21.675047654866013    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.7169310657562     |
| train_1/q_grads           | -0.08479976486414671  |
| train_1/q_grads_std       | 1.0395754843950271    |
| train_1/q_loss            | 3.645298034765478     |
| train_1/reward            | -2.0184436164207      |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00068359375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.690688022873271   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 636.76. Rollout time: 408.31, Training time: 228.38
Evaluating epoch 69
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 5467974.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.993053494126125    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.673239357899442     |
| train_0/fw_bonus          | -0.9995189934968949    |
| train_0/fw_loss           | 0.00011447589693034388 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.741123408657607      |
| train_0/next_q            | -9.73103450096953      |
| train_0/q_grads           | 0.020647260500118135   |
| train_0/q_grads_std       | 0.370668076723814      |
| train_0/q_loss            | 0.800143258050495      |
| train_0/reward            | -0.7110632126976271    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3139404296875        |
| train_0/target_q          | -10.179466675040828    |
| train_1/avg_q             | -14.05056478168496     |
| train_1/current_q         | -11.638060808731433    |
| train_1/fw_bonus          | -0.9973174184560776    |
| train_1/fw_loss           | 0.0013146851910278202  |
| train_1/mu_grads          | -0.07364524900913239   |
| train_1/mu_grads_std      | 0.7271519303321838     |
| train_1/mu_loss           | 21.642063098730194     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.662979440442086    |
| train_1/q_grads           | -0.08637836724519729   |
| train_1/q_grads_std       | 1.047561025619507      |
| train_1/q_loss            | 4.288151585847244      |
| train_1/reward            | -2.0020278497904656    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009521484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.88606693908048     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 641.06. Rollout time: 409.53, Training time: 231.47
Evaluating epoch 70
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 70                    |
| policy/steps              | 5559099.0             |
| test/episodes             | 1775.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.955749081493597   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.595329829615187    |
| train_0/fw_bonus          | -0.9997917979955673   |
| train_0/fw_loss           | 5.221481444550591e-05 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.663872838386151     |
| train_0/next_q            | -9.663032709501131    |
| train_0/q_grads           | 0.02001461503095925   |
| train_0/q_grads_std       | 0.3729023352265358    |
| train_0/q_loss            | 1.0186456569886357    |
| train_0/reward            | -0.7076961944367213   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3120361328125       |
| train_0/target_q          | -10.090077133116193   |
| train_1/avg_q             | -14.010503718680035   |
| train_1/current_q         | -11.717622708972044   |
| train_1/fw_bonus          | -0.9983556061983109   |
| train_1/fw_loss           | 0.001102575247932691  |
| train_1/mu_grads          | -0.07364524900913239  |
| train_1/mu_grads_std      | 0.7271519303321838    |
| train_1/mu_loss           | 21.77724113993695     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.79086683120183    |
| train_1/q_grads           | -0.08650230672210454  |
| train_1/q_grads_std       | 1.0545347094535829    |
| train_1/q_loss            | 5.158060181039703     |
| train_1/reward            | -1.98819147451577     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012939453125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.947090935335348   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 635.87. Rollout time: 414.12, Training time: 221.70
Evaluating epoch 71
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 5650224.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.017956753268512    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.585149279123259     |
| train_0/fw_bonus          | -0.9994791209697723    |
| train_0/fw_loss           | 0.00012357870683672446 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.659258344310029      |
| train_0/next_q            | -9.654400995761279     |
| train_0/q_grads           | 0.01937777381390333    |
| train_0/q_grads_std       | 0.37449957728385924    |
| train_0/q_loss            | 1.2109814749794765     |
| train_0/reward            | -0.7095540125163098    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3384521484375        |
| train_0/target_q          | -10.081340663751938    |
| train_1/avg_q             | -13.991014946394042    |
| train_1/current_q         | -11.78030520887177     |
| train_1/fw_bonus          | -0.999208927154541     |
| train_1/fw_loss           | 0.0009282350569264963  |
| train_1/mu_grads          | -0.07364524900913239   |
| train_1/mu_grads_std      | 0.7271519303321838     |
| train_1/mu_loss           | 21.790039051364232     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.798207970795033    |
| train_1/q_grads           | -0.08780317045748234   |
| train_1/q_grads_std       | 1.0604112446308136     |
| train_1/q_loss            | 5.496416296799465      |
| train_1/reward            | -2.0266308286605637    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -12.048078582294798    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 625.76. Rollout time: 406.17, Training time: 219.53
Evaluating epoch 72
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 72                     |
| policy/steps              | 5741349.0              |
| test/episodes             | 1825.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.033056631947552    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.598164601214632     |
| train_0/fw_bonus          | -0.999395526945591     |
| train_0/fw_loss           | 0.00014265680669041104 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 9.6818911184073        |
| train_0/next_q            | -9.666818631624192     |
| train_0/q_grads           | 0.01917244796641171    |
| train_0/q_grads_std       | 0.3754140496253967     |
| train_0/q_loss            | 0.900460532241846      |
| train_0/reward            | -0.7095366311586986    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.317431640625         |
| train_0/target_q          | -10.098418590361916    |
| train_1/avg_q             | -14.030956202737064    |
| train_1/current_q         | -11.617911170609156    |
| train_1/fw_bonus          | -0.9996790155768395    |
| train_1/fw_loss           | 0.0008321944493218325  |
| train_1/mu_grads          | -0.07364531457424164   |
| train_1/mu_grads_std      | 0.7271518707275391     |
| train_1/mu_loss           | 21.874103543070113     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.871759726895522    |
| train_1/q_grads           | -0.08762619532644748   |
| train_1/q_grads_std       | 1.0648649215698243     |
| train_1/q_loss            | 3.5471928188564803     |
| train_1/reward            | -1.9898297351515795    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009765625           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.868031983674365    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 578.61. Rollout time: 367.24, Training time: 211.33
Evaluating epoch 73
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 5832474.0             |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.034000721650992   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.423756952979257    |
| train_0/fw_bonus          | -0.9996508106589317   |
| train_0/fw_loss           | 8.439174131353866e-05 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.471982778512437     |
| train_0/next_q            | -9.478933001118873    |
| train_0/q_grads           | 0.018461248418316246  |
| train_0/q_grads_std       | 0.3774224042892456    |
| train_0/q_loss            | 0.7823592599319531    |
| train_0/reward            | -0.7096154486564046   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.333935546875        |
| train_0/target_q          | -9.933054853141503    |
| train_1/avg_q             | -14.020483505922565   |
| train_1/current_q         | -11.689553582233994   |
| train_1/fw_bonus          | -0.9998686656355857   |
| train_1/fw_loss           | 0.0007934446228318847 |
| train_1/mu_grads          | -0.07364656031131744  |
| train_1/mu_grads_std      | 0.7271501421928406    |
| train_1/mu_loss           | 21.84465755479073     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.838945191770858   |
| train_1/q_grads           | -0.08800179939717054  |
| train_1/q_grads_std       | 1.0704656273126603    |
| train_1/q_loss            | 3.857028003497246     |
| train_1/reward            | -2.008930915036035    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000927734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.937380059515544   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 574.20. Rollout time: 365.07, Training time: 209.10
Evaluating epoch 74
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 74                    |
| policy/steps              | 5923599.0             |
| test/episodes             | 1875.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.099734536261105   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.590680368144039    |
| train_0/fw_bonus          | -0.9999840468168258   |
| train_0/fw_loss           | 8.339167698068195e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.660142539541207     |
| train_0/next_q            | -9.652551614871253    |
| train_0/q_grads           | 0.017973729223012925  |
| train_0/q_grads_std       | 0.3786137618124485    |
| train_0/q_loss            | 0.9247497656062823    |
| train_0/reward            | -0.7100872379262      |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3459716796875       |
| train_0/target_q          | -10.084595076364499   |
| train_1/avg_q             | -14.048310039222716   |
| train_1/current_q         | -11.588784524409656   |
| train_1/fw_bonus          | -1.0002913028001785   |
| train_1/fw_loss           | 0.0007070983978337608 |
| train_1/mu_grads          | -0.0736466646194458   |
| train_1/mu_grads_std      | 0.7271488308906555    |
| train_1/mu_loss           | 21.840090381021835    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.8342331135161     |
| train_1/q_grads           | -0.08817993812263011  |
| train_1/q_grads_std       | 1.075963106751442     |
| train_1/q_loss            | 3.2344129308853056    |
| train_1/reward            | -2.005699846143398    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010986328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.859299876063876   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 578.90. Rollout time: 371.14, Training time: 207.72
Evaluating epoch 75
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 6014724.0             |
| test/episodes             | 1900.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.950242906617031   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.252221453962438    |
| train_0/fw_bonus          | -0.9999781221151351   |
| train_0/fw_loss           | 9.691286709312408e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.272082047169173     |
| train_0/next_q            | -9.287075314392851    |
| train_0/q_grads           | 0.0180571710690856    |
| train_0/q_grads_std       | 0.38070452213287354   |
| train_0/q_loss            | 0.5341439054220614    |
| train_0/reward            | -0.707948045113153    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.334130859375        |
| train_0/target_q          | -9.77274747001451     |
| train_1/avg_q             | -14.15942014813791    |
| train_1/current_q         | -11.326139526213575   |
| train_1/fw_bonus          | -1.000251217186451    |
| train_1/fw_loss           | 0.0007152858219342306 |
| train_1/mu_grads          | -0.07364681363105774  |
| train_1/mu_grads_std      | 0.727148711681366     |
| train_1/mu_loss           | 21.818220426676838    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.813981765601646   |
| train_1/q_grads           | -0.08812865503132343  |
| train_1/q_grads_std       | 1.07882040143013      |
| train_1/q_loss            | 4.778029864388699     |
| train_1/reward            | -1.9933140852961515   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0011474609375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.59662432013545    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 576.99. Rollout time: 366.86, Training time: 210.09
Evaluating epoch 76
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 76                    |
| policy/steps              | 6105849.0             |
| test/episodes             | 1925.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.97673898412195    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 7700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.324245501845603    |
| train_0/fw_bonus          | -0.9999899700284004   |
| train_0/fw_loss           | 6.986403184328082e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 9.367263593498784     |
| train_0/next_q            | -9.375598599200845    |
| train_0/q_grads           | 0.0174585634842515    |
| train_0/q_grads_std       | 0.3805190086364746    |
| train_0/q_loss            | 0.6182673234139553    |
| train_0/reward            | -0.7080027993048134   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.34560546875         |
| train_0/target_q          | -9.828745075987388    |
| train_1/avg_q             | -13.99491532365996    |
| train_1/current_q         | -11.266209840471372   |
| train_1/fw_bonus          | -1.000219264626503    |
| train_1/fw_loss           | 0.000721816168515943  |
| train_1/mu_grads          | -0.0736469179391861   |
| train_1/mu_grads_std      | 0.7271485924720764    |
| train_1/mu_loss           | 21.83336540737917     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.830993218041865   |
| train_1/q_grads           | -0.0878505812957883   |
| train_1/q_grads_std       | 1.082982313632965     |
| train_1/q_loss            | 2.7796558032045477    |
| train_1/reward            | -1.9798581630180707   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0009521484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.54110465309941    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 77
Time for epoch 77: 580.95. Rollout time: 372.46, Training time: 208.45
Evaluating epoch 77
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 77                     |
| policy/steps              | 6196974.0              |
| test/episodes             | 1950.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -13.997081849434506    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -10.112644875635985    |
| train_0/fw_bonus          | -0.9999715328216553    |
| train_0/fw_loss           | 1.1195649938144924e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 10.189540001509481     |
| train_0/next_q            | -10.172072940845798    |
| train_0/q_grads           | 0.01790219028480351    |
| train_0/q_grads_std       | 0.37632899135351183    |
| train_0/q_loss            | 0.6854165159295688     |
| train_0/reward            | -0.7100931869761553    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.335595703125         |
| train_0/target_q          | -10.29603978371585     |
| train_1/avg_q             | -13.977575227026731    |
| train_1/current_q         | -11.513873954782602    |
| train_1/fw_bonus          | -1.0004014566540718    |
| train_1/fw_loss           | 0.0006845899421023205  |
| train_1/mu_grads          | -0.0736493319272995    |
| train_1/mu_grads_std      | 0.727146565914154      |
| train_1/mu_loss           | 21.863747758144694     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.865919731456987    |
| train_1/q_grads           | -0.08646724075078964   |
| train_1/q_grads_std       | 1.086288532614708      |
| train_1/q_loss            | 4.078777605691866      |
| train_1/reward            | -1.997502977203112     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00107421875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.772613033402184    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 78
Time for epoch 78: 579.53. Rollout time: 363.96, Training time: 215.54
Evaluating epoch 78
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 78                     |
| policy/steps              | 6288099.0              |
| test/episodes             | 1975.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.917503523206106    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -10.29384300790046     |
| train_0/fw_bonus          | -0.9999757900834083    |
| train_0/fw_loss           | 1.0222994978903443e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 10.355096291996295     |
| train_0/next_q            | -10.340958643725862    |
| train_0/q_grads           | 0.018573410995304584   |
| train_0/q_grads_std       | 0.3744238458573818     |
| train_0/q_loss            | 0.6350971813201978     |
| train_0/reward            | -0.7111329154169652    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.346240234375         |
| train_0/target_q          | -10.462019741113124    |
| train_1/avg_q             | -14.04915548022589     |
| train_1/current_q         | -11.500152385365777    |
| train_1/fw_bonus          | -1.000258395075798     |
| train_1/fw_loss           | 0.0007138181987102144  |
| train_1/mu_grads          | -0.0736493319272995    |
| train_1/mu_grads_std      | 0.727146565914154      |
| train_1/mu_loss           | 21.823138585455155     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.872719528363376    |
| train_1/q_grads           | -0.0879399299621582    |
| train_1/q_grads_std       | 1.0920981794595719     |
| train_1/q_loss            | 4.595613703728384      |
| train_1/reward            | -2.0144114279355563    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.78123022997505     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 79
Time for epoch 79: 577.70. Rollout time: 366.73, Training time: 210.94
Evaluating epoch 79
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 6379224.0              |
| test/episodes             | 2000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -14.005380954075049    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -10.175248511845616    |
| train_0/fw_bonus          | -0.9999733179807663    |
| train_0/fw_loss           | 1.0785643212329887e-05 |
| train_0/mu_grads          | -0.06874901801347733   |
| train_0/mu_grads_std      | 0.4749193489551544     |
| train_0/mu_loss           | 10.227720599573455     |
| train_0/next_q            | -10.21394677162947     |
| train_0/q_grads           | 0.018967687012627722   |
| train_0/q_grads_std       | 0.3739025168120861     |
| train_0/q_loss            | 0.7788874724512406     |
| train_0/reward            | -0.7106434016903223    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3295166015625        |
| train_0/target_q          | -10.348554455723706    |
| train_1/avg_q             | -14.443241663843278    |
| train_1/current_q         | -11.652014085730583    |
| train_1/fw_bonus          | -1.0003661334514617    |
| train_1/fw_loss           | 0.0006918094426509924  |
| train_1/mu_grads          | -0.0736493319272995    |
| train_1/mu_grads_std      | 0.727146565914154      |
| train_1/mu_loss           | 21.864687260501608     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -21.860447212407983    |
| train_1/q_grads           | -0.09001899119466543   |
| train_1/q_grads_std       | 1.0974398523569107     |
| train_1/q_loss            | 2.9316645797051337     |
| train_1/reward            | -1.9765136298985453    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -11.92604013212277     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 80
Time for epoch 80: 584.69. Rollout time: 369.07, Training time: 215.58
Evaluating epoch 80
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 6470349.0             |
| test/episodes             | 2025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.428506190363443   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.249409379900698   |
| train_0/fw_bonus          | -0.9999834105372429   |
| train_0/fw_loss           | 8.481469103571726e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.293507566273925    |
| train_0/next_q            | -10.293677577425544   |
| train_0/q_grads           | 0.018526184279471634  |
| train_0/q_grads_std       | 0.3742970071732998    |
| train_0/q_loss            | 0.6442581099000796    |
| train_0/reward            | -0.7116494262008928   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3343017578125       |
| train_0/target_q          | -10.445636130316588   |
| train_1/avg_q             | -14.071415055266623   |
| train_1/current_q         | -11.633830196281597   |
| train_1/fw_bonus          | -1.0002744138240813   |
| train_1/fw_loss           | 0.0007105467520887032 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.88523008028658     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.87798792978275    |
| train_1/q_grads           | -0.09138537421822548  |
| train_1/q_grads_std       | 1.1044912964105607    |
| train_1/q_loss            | 4.3585911237199735    |
| train_1/reward            | -1.9715849611253362   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.923159130933833   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 81
Time for epoch 81: 595.50. Rollout time: 377.80, Training time: 217.67
Evaluating epoch 81
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 6561474.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.309484849158023   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.322599578912476   |
| train_0/fw_bonus          | -0.9999870955944061   |
| train_0/fw_loss           | 7.645514472187642e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.397290112383539    |
| train_0/next_q            | -10.366325401608165   |
| train_0/q_grads           | 0.01896842154674232   |
| train_0/q_grads_std       | 0.3753886081278324    |
| train_0/q_loss            | 0.6155955754000806    |
| train_0/reward            | -0.7123104374833928   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.360595703125        |
| train_0/target_q          | -10.48315385023469    |
| train_1/avg_q             | -14.153606938018156   |
| train_1/current_q         | -11.698046431385203   |
| train_1/fw_bonus          | -1.0002555072307586   |
| train_1/fw_loss           | 0.0007144053583033383 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.867160702188606    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.87442543047513    |
| train_1/q_grads           | -0.09117827322334052  |
| train_1/q_grads_std       | 1.1108141154050828    |
| train_1/q_loss            | 4.0795585956292       |
| train_1/reward            | -1.9798885063049965   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.960817282426191   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 620.25. Rollout time: 386.72, Training time: 233.49
Evaluating epoch 82
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 6652599.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.249380155625103   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.208377713655745   |
| train_0/fw_bonus          | -0.9999842628836632   |
| train_0/fw_loss           | 8.290370612940023e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.269250239686675    |
| train_0/next_q            | -10.25424383743352    |
| train_0/q_grads           | 0.019249107362702488  |
| train_0/q_grads_std       | 0.3755913518369198    |
| train_0/q_loss            | 0.6582774043990297    |
| train_0/reward            | -0.710075138193497    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3593994140625       |
| train_0/target_q          | -10.373438700135996   |
| train_1/avg_q             | -14.113261363186526   |
| train_1/current_q         | -11.62365755583464    |
| train_1/fw_bonus          | -1.0002371937036514   |
| train_1/fw_loss           | 0.0007181510809459724 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.884714156597653    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.886288341490083   |
| train_1/q_grads           | -0.09069109745323659  |
| train_1/q_grads_std       | 1.1169732809066772    |
| train_1/q_loss            | 3.7432445818696665    |
| train_1/reward            | -1.9934413505550765   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0012451171875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.88958045622643    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 83
Time for epoch 83: 835.75. Rollout time: 551.87, Training time: 283.81
Evaluating epoch 83
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 6743724.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.995156857764755   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.246143148796955   |
| train_0/fw_bonus          | -0.999980865418911    |
| train_0/fw_loss           | 9.06429796714292e-06  |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.281568717186582    |
| train_0/next_q            | -10.274242456263138   |
| train_0/q_grads           | 0.019045715034008027  |
| train_0/q_grads_std       | 0.37648230567574503   |
| train_0/q_loss            | 0.6054459337460276    |
| train_0/reward            | -0.7106349657311511   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.35166015625         |
| train_0/target_q          | -10.42934199645966    |
| train_1/avg_q             | -14.003677215354504   |
| train_1/current_q         | -11.54155115141123    |
| train_1/fw_bonus          | -1.0003055796027183   |
| train_1/fw_loss           | 0.0007041767225018702 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.802316075309093    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.810801037740767   |
| train_1/q_grads           | -0.09041564967483282  |
| train_1/q_grads_std       | 1.1239190518856048    |
| train_1/q_loss            | 3.9201183093897116    |
| train_1/reward            | -2.0258119771177006   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001171875           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.829141292262225   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 84
Time for epoch 84: 1122.81. Rollout time: 783.68, Training time: 338.98
Evaluating epoch 84
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 84                    |
| policy/steps              | 6834849.0             |
| test/episodes             | 2125.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.09338258188104    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -26.999999999999993   |
| train_0/current_q         | -10.224362952982252   |
| train_0/fw_bonus          | -0.9999882191419601   |
| train_0/fw_loss           | 7.38410217877572e-06  |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.27649444702902     |
| train_0/next_q            | -10.25629742869506    |
| train_0/q_grads           | 0.018884175131097435  |
| train_0/q_grads_std       | 0.3782151289284229    |
| train_0/q_loss            | 0.7047227507460543    |
| train_0/reward            | -0.7112978266581195   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.36591796875         |
| train_0/target_q          | -10.405501004691963   |
| train_1/avg_q             | -14.001555039906375   |
| train_1/current_q         | -11.619128961497017   |
| train_1/fw_bonus          | -1.0002521082758904   |
| train_1/fw_loss           | 0.0007151044585043565 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.79305428077863     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.811861127703775   |
| train_1/q_grads           | -0.09112857244908809  |
| train_1/q_grads_std       | 1.1297506630420684    |
| train_1/q_loss            | 4.205036551574313     |
| train_1/reward            | -2.0258706825108677   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0006591796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.909318556961276   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 85
Time for epoch 85: 1070.20. Rollout time: 757.67, Training time: 312.43
Evaluating epoch 85
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 6925974.0             |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.966861326839355   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.157180940594003   |
| train_0/fw_bonus          | -0.9999865725636482   |
| train_0/fw_loss           | 7.75925873313099e-06  |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.21845242278798     |
| train_0/next_q            | -10.182795443261227   |
| train_0/q_grads           | 0.019042960600927472  |
| train_0/q_grads_std       | 0.37903917133808135   |
| train_0/q_loss            | 0.5667769800746749    |
| train_0/reward            | -0.709893195812765    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.360546875           |
| train_0/target_q          | -10.336081841369676   |
| train_1/avg_q             | -14.051395522413111   |
| train_1/current_q         | -11.491162595918881   |
| train_1/fw_bonus          | -1.0001432612538337   |
| train_1/fw_loss           | 0.0007373427128186449 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.756688544907483    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.777544042167477   |
| train_1/q_grads           | -0.0902773866429925   |
| train_1/q_grads_std       | 1.138141480088234     |
| train_1/q_loss            | 3.2261306739746125    |
| train_1/reward            | -1.992417821577692    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0013427734375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.773857084916166   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 86
Time for epoch 86: 1188.65. Rollout time: 837.51, Training time: 351.02
Evaluating epoch 86
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 86                    |
| policy/steps              | 7017099.0             |
| test/episodes             | 2175.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.879697534042073   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8700.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.270207485973547   |
| train_0/fw_bonus          | -0.9999787315726281   |
| train_0/fw_loss           | 9.549808476094768e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.319068470540108    |
| train_0/next_q            | -10.301436870960528   |
| train_0/q_grads           | 0.018826447380706667  |
| train_0/q_grads_std       | 0.3801089361310005    |
| train_0/q_loss            | 0.6383207866019147    |
| train_0/reward            | -0.7104141754702141   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.366650390625        |
| train_0/target_q          | -10.437169130478702   |
| train_1/avg_q             | -14.000097826409892   |
| train_1/current_q         | -11.368230934374438   |
| train_1/fw_bonus          | -0.9999852493405342   |
| train_1/fw_loss           | 0.0007696263157413342 |
| train_1/mu_grads          | -0.0736493319272995   |
| train_1/mu_grads_std      | 0.727146565914154     |
| train_1/mu_loss           | 21.816411529631488    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.8294861645062     |
| train_1/q_grads           | -0.09009715914726257  |
| train_1/q_grads_std       | 1.145643800497055     |
| train_1/q_loss            | 3.7180471992689563    |
| train_1/reward            | -2.0055956494717977   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.647399713899887   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 87
Time for epoch 87: 1183.77. Rollout time: 838.66, Training time: 344.89
Evaluating epoch 87
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 7108224.0             |
| test/episodes             | 2200.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.978118793079009   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.111217692625754   |
| train_0/fw_bonus          | -0.9999846160411835   |
| train_0/fw_loss           | 8.209049497054366e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.173255974088201    |
| train_0/next_q            | -10.139771190887563   |
| train_0/q_grads           | 0.018297938536852597  |
| train_0/q_grads_std       | 0.38201508298516273   |
| train_0/q_loss            | 0.744070364087784     |
| train_0/reward            | -0.708769163468969    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3569580078125       |
| train_0/target_q          | -10.289441448775015   |
| train_1/avg_q             | -13.989503030270495   |
| train_1/current_q         | -11.362473444846934   |
| train_1/fw_bonus          | -1.0001599729061126   |
| train_1/fw_loss           | 0.0007339271920500323 |
| train_1/mu_grads          | -0.07367458678781987  |
| train_1/mu_grads_std      | 0.7271449267864227    |
| train_1/mu_loss           | 21.79149733128142     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.792551039671928   |
| train_1/q_grads           | -0.0912911530584097   |
| train_1/q_grads_std       | 1.1508463382720948    |
| train_1/q_loss            | 2.804184007876057     |
| train_1/reward            | -1.984223055189068    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.627796744318841   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 88
Time for epoch 88: 1114.86. Rollout time: 801.95, Training time: 312.75
Evaluating epoch 88
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 88                    |
| policy/steps              | 7199349.0             |
| test/episodes             | 2225.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.945154673186307   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8900.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.409207642271994   |
| train_0/fw_bonus          | -0.9999807253479958   |
| train_0/fw_loss           | 9.098266536966548e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.469531320033434    |
| train_0/next_q            | -10.445088249810516   |
| train_0/q_grads           | 0.018550609471276402  |
| train_0/q_grads_std       | 0.3839315205812454    |
| train_0/q_loss            | 0.7937922294726156    |
| train_0/reward            | -0.7129420199125889   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3688720703125       |
| train_0/target_q          | -10.563905776401313   |
| train_1/avg_q             | -14.00722201596625    |
| train_1/current_q         | -11.254710785034828   |
| train_1/fw_bonus          | -1.000252754986286    |
| train_1/fw_loss           | 0.0007149738958105445 |
| train_1/mu_grads          | -0.07367497682571411  |
| train_1/mu_grads_std      | 0.7271448969841003    |
| train_1/mu_loss           | 21.82794620549236     |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.81582299851028    |
| train_1/q_grads           | -0.09133458454161883  |
| train_1/q_grads_std       | 1.154964229464531     |
| train_1/q_loss            | 3.452360693115503     |
| train_1/reward            | -1.959171782577323    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010009765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.540487795183477   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 89
Time for epoch 89: 1218.98. Rollout time: 849.59, Training time: 369.26
Evaluating epoch 89
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 89                    |
| policy/steps              | 7290474.0             |
| test/episodes             | 2250.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.012677750337854   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9000.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.160689437908507   |
| train_0/fw_bonus          | -0.9999866485595703   |
| train_0/fw_loss           | 7.746886660697783e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.21073288765117     |
| train_0/next_q            | -10.191094823083585   |
| train_0/q_grads           | 0.01806843588128686   |
| train_0/q_grads_std       | 0.3863480225205421    |
| train_0/q_loss            | 0.6385518034747802    |
| train_0/reward            | -0.7099542583506263   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.366650390625        |
| train_0/target_q          | -10.349575792998367   |
| train_1/avg_q             | -13.998156420738281   |
| train_1/current_q         | -11.144974081380147   |
| train_1/fw_bonus          | -1.000276318192482    |
| train_1/fw_loss           | 0.0007101583629264496 |
| train_1/mu_grads          | -0.07214074525982142  |
| train_1/mu_grads_std      | 0.7279847428202629    |
| train_1/mu_loss           | 21.878711274944347    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.8940350655051     |
| train_1/q_grads           | -0.09177257101982832  |
| train_1/q_grads_std       | 1.159345382452011     |
| train_1/q_loss            | 2.7222491636721378    |
| train_1/reward            | -1.9498085678169446   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00107421875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.417645925520727   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 90
Time for epoch 90: 1571.06. Rollout time: 1120.78, Training time: 450.12
Evaluating epoch 90
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 7381599.0             |
| test/episodes             | 2275.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.965034140782416   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.200717984568296   |
| train_0/fw_bonus          | -0.9999882221221924   |
| train_0/fw_loss           | 7.382672208677832e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.25991775166767     |
| train_0/next_q            | -10.227615234665938   |
| train_0/q_grads           | 0.018054053653031588  |
| train_0/q_grads_std       | 0.38788353055715563   |
| train_0/q_loss            | 0.6956482356234496    |
| train_0/reward            | -0.7106142355733027   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.368115234375        |
| train_0/target_q          | -10.391002881906687   |
| train_1/avg_q             | -14.005803929604868   |
| train_1/current_q         | -11.119088197657058   |
| train_1/fw_bonus          | -1.0002744391560554   |
| train_1/fw_loss           | 0.0007105406431946904 |
| train_1/mu_grads          | -0.07149551138281822  |
| train_1/mu_grads_std      | 0.7284830048680305    |
| train_1/mu_loss           | 21.846133160795105    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.846833902633335   |
| train_1/q_grads           | -0.09233073405921459  |
| train_1/q_grads_std       | 1.1639363437891006    |
| train_1/q_loss            | 2.575773971177248     |
| train_1/reward            | -1.972878921728261    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00087890625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.401528741932763   |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 91
Time for epoch 91: 1435.60. Rollout time: 1002.59, Training time: 432.83
Evaluating epoch 91
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 7472724.0             |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -14.00502617148921    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.195370306792643   |
| train_0/fw_bonus          | -0.999986144900322    |
| train_0/fw_loss           | 7.858491767365194e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.231022713189946    |
| train_0/next_q            | -10.223376121155633   |
| train_0/q_grads           | 0.01787081705406308   |
| train_0/q_grads_std       | 0.3895268298685551    |
| train_0/q_loss            | 0.8506164205084431    |
| train_0/reward            | -0.7092093848077639   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.359326171875        |
| train_0/target_q          | -10.36409539168216    |
| train_1/avg_q             | -14.061975007181927   |
| train_1/current_q         | -11.249333859607843   |
| train_1/fw_bonus          | -1.0004453033208847   |
| train_1/fw_loss           | 0.0006756296410458162 |
| train_1/mu_grads          | -0.0703384205698967   |
| train_1/mu_grads_std      | 0.7290005683898926    |
| train_1/mu_loss           | 21.750678870729065    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.75059633033728    |
| train_1/q_grads           | -0.0917463056743145   |
| train_1/q_grads_std       | 1.1686421632766724    |
| train_1/q_loss            | 3.677963405547955     |
| train_1/reward            | -1.9428007841503132   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0010498046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.538408368312139   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 92
Time for epoch 92: 1140.69. Rollout time: 823.64, Training time: 316.91
Evaluating epoch 92
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.5|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 92                    |
| policy/steps              | 7563849.0             |
| test/episodes             | 2325.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -13.980037542812518   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 9300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -10.324272503420907   |
| train_0/fw_bonus          | -0.9999946907162667   |
| train_0/fw_loss           | 5.910644671303089e-06 |
| train_0/mu_grads          | -0.06874901801347733  |
| train_0/mu_grads_std      | 0.4749193489551544    |
| train_0/mu_loss           | 10.398648623101769    |
| train_0/next_q            | -10.360455787777912   |
| train_0/q_grads           | 0.017786894040182234  |
| train_0/q_grads_std       | 0.39045323580503466   |
| train_0/q_loss            | 0.6207813222664358    |
| train_0/reward            | -0.7117527143651387   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.3807861328125       |
| train_0/target_q          | -10.506949040772891   |
| train_1/avg_q             | -13.996127217434799   |
| train_1/current_q         | -11.308320385362652   |
| train_1/fw_bonus          | -1.0002406239509583   |
| train_1/fw_loss           | 0.0007174510188633576 |
| train_1/mu_grads          | -0.0703384205698967   |
| train_1/mu_grads_std      | 0.7290005683898926    |
| train_1/mu_loss           | 21.7700244169804      |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -21.769348266444318   |
| train_1/q_grads           | -0.0915269486606121   |
| train_1/q_grads_std       | 1.1718913614749908    |
| train_1/q_loss            | 4.1673419069743645    |
| train_1/reward            | -1.9844831035516108   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001025390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -11.584990550678809   |
-----------------------------------------------------
