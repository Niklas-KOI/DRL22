Starting process id: 1975
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fcbaae7f5f0>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 630.25. Rollout time: 367.06, Training time: 263.16
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 87672.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.50365612696349      |
| test_1/avg_q              | -6.537333587272579     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -4.369768841520083     |
| train_0/current_q         | -2.763662937871641     |
| train_0/fw_bonus          | -0.9992026507854461    |
| train_0/fw_loss           | 0.00021819506873725912 |
| train_0/mu_grads          | -0.011120435013435782  |
| train_0/mu_grads_std      | 0.16455272436141968    |
| train_0/mu_loss           | 2.5920785602272813     |
| train_0/next_q            | -2.5681778800681174    |
| train_0/q_grads           | 0.0347665605135262     |
| train_0/q_grads_std       | 0.1573342751711607     |
| train_0/q_loss            | 0.60125670297782       |
| train_0/reward            | -0.8715699614258483    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003173828125        |
| train_0/target_q          | -2.7296533978019104    |
| train_1/avg_q             | -5.59287700299723      |
| train_1/current_q         | -9.666939157968088     |
| train_1/fw_bonus          | -0.9984359309077263    |
| train_1/fw_loss           | 0.0012745709071168676  |
| train_1/mu_grads          | 0.021415244741365313   |
| train_1/mu_grads_std      | 0.08488490525633097    |
| train_1/mu_loss           | 11.808166685834745     |
| train_1/n_subgoals        | 2682.0                 |
| train_1/next_q            | -11.788630807117261    |
| train_1/q_grads           | 0.02567337956279516    |
| train_1/q_grads_std       | 0.21648258045315744    |
| train_1/q_loss            | 22.71553864072652      |
| train_1/reward            | -1.487327913250192     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002099609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.049962714392244596   |
| train_1/target_q          | -9.752326446682835     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 555.73. Rollout time: 368.46, Training time: 187.23
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 172023.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.057553918985128     |
| test_1/avg_q              | -9.158195872817508     |
| test_1/n_subgoals         | 2322.0                 |
| test_1/subgoal_succ_rate  | 0.7403100775193798     |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.05                   |
| train_0/avg_q             | -5.975440408934182     |
| train_0/current_q         | -6.2152827476240216    |
| train_0/fw_bonus          | -0.9989473193883895    |
| train_0/fw_loss           | 0.00028613211361516733 |
| train_0/mu_grads          | -0.014785591280087829  |
| train_0/mu_grads_std      | 0.2022893290966749     |
| train_0/mu_loss           | 6.008905392223943      |
| train_0/next_q            | -5.96191666842107      |
| train_0/q_grads           | 0.03879189258441329    |
| train_0/q_grads_std       | 0.16893710792064667    |
| train_0/q_loss            | 0.2741370095509975     |
| train_0/reward            | -0.8772439333770308    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001953125           |
| train_0/target_q          | -6.178623964930862     |
| train_1/avg_q             | -7.735020611688972     |
| train_1/current_q         | -11.841496494589325    |
| train_1/fw_bonus          | -0.99817553460598      |
| train_1/fw_loss           | 0.0013415425171842798  |
| train_1/mu_grads          | 0.022312111034989358   |
| train_1/mu_grads_std      | 0.08571872152388096    |
| train_1/mu_loss           | 16.081447228686034     |
| train_1/n_subgoals        | 2634.0                 |
| train_1/next_q            | -16.08314356820535     |
| train_1/q_grads           | 0.017332239635288717   |
| train_1/q_grads_std       | 0.290445289760828      |
| train_1/q_loss            | 21.169321446113244     |
| train_1/reward            | -1.4816943899219042    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015625              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.10022779043280182    |
| train_1/target_q          | -11.872984024034634    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 506.28. Rollout time: 327.62, Training time: 178.63
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 249387.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.7108472194437394   |
| test_1/avg_q              | -9.476988327737654    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.08                  |
| train_0/avg_q             | -7.262617217836756    |
| train_0/current_q         | -5.162703260390115    |
| train_0/fw_bonus          | -0.9987508744001389   |
| train_0/fw_loss           | 0.0003383980474609416 |
| train_0/mu_grads          | -0.020250520622357725 |
| train_0/mu_grads_std      | 0.22741824798285962   |
| train_0/mu_loss           | 4.91097291947842      |
| train_0/next_q            | -4.875245921350223    |
| train_0/q_grads           | 0.04012431427836418   |
| train_0/q_grads_std       | 0.18458339534699916   |
| train_0/q_loss            | 0.42999048289871433   |
| train_0/reward            | -0.8860138381831348   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000341796875        |
| train_0/target_q          | -5.087424054184181    |
| train_1/avg_q             | -9.154969504118606    |
| train_1/current_q         | -12.2157022675862     |
| train_1/fw_bonus          | -0.9971916615962982   |
| train_1/fw_loss           | 0.001594593035406433  |
| train_1/mu_grads          | 0.02254337500780821   |
| train_1/mu_grads_std      | 0.08599121440201998   |
| train_1/mu_loss           | 15.604871385483682    |
| train_1/n_subgoals        | 2612.0                |
| train_1/next_q            | -15.577980377352537   |
| train_1/q_grads           | 0.015023036277852952  |
| train_1/q_grads_std       | 0.3155704490840435    |
| train_1/q_loss            | 14.400595373077476    |
| train_1/reward            | -1.4540277766020153   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020751953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.23392036753445636   |
| train_1/target_q          | -12.320541465213903   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 493.93. Rollout time: 312.33, Training time: 181.56
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 320574.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6325424442129912    |
| test_1/avg_q              | -10.22047915658927     |
| test_1/n_subgoals         | 14575.0                |
| test_1/subgoal_succ_rate  | 0.99073756432247       |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.12                   |
| train_0/avg_q             | -5.9752787717785605    |
| train_0/current_q         | -5.075621987479476     |
| train_0/fw_bonus          | -0.9986724689602852    |
| train_0/fw_loss           | 0.00035926278069382535 |
| train_0/mu_grads          | -0.028270098054781555  |
| train_0/mu_grads_std      | 0.24835559278726577    |
| train_0/mu_loss           | 4.83337570712577       |
| train_0/next_q            | -4.760295767301721     |
| train_0/q_grads           | 0.0401347266510129     |
| train_0/q_grads_std       | 0.19319589473307133    |
| train_0/q_loss            | 0.386042127193661      |
| train_0/reward            | -0.8882011169596808    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 2.44140625e-05         |
| train_0/target_q          | -5.000543003924371     |
| train_1/avg_q             | -9.921045768892885     |
| train_1/current_q         | -12.393704475297415    |
| train_1/fw_bonus          | -0.9962234333157539    |
| train_1/fw_loss           | 0.0018436198501149193  |
| train_1/mu_grads          | 0.02255333629436791    |
| train_1/mu_grads_std      | 0.08599848449230194    |
| train_1/mu_loss           | 15.382169241768372     |
| train_1/n_subgoals        | 2530.0                 |
| train_1/next_q            | -15.375216357188364    |
| train_1/q_grads           | 0.013983698678202927   |
| train_1/q_grads_std       | 0.3308128222823143     |
| train_1/q_loss            | 13.709172798223188     |
| train_1/reward            | -1.428979098716809     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00205078125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.29209486166007903    |
| train_1/target_q          | -12.493026321837306    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 504.83. Rollout time: 309.45, Training time: 195.34
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 391411.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8489020175115671    |
| test_1/avg_q              | -1.682038939433154     |
| test_1/n_subgoals         | 4330.0                 |
| test_1/subgoal_succ_rate  | 0.8840646651270208     |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.12                   |
| train_0/avg_q             | -7.489726745714601     |
| train_0/current_q         | -5.419128521562273     |
| train_0/fw_bonus          | -0.9986910745501518    |
| train_0/fw_loss           | 0.00035430802236078305 |
| train_0/mu_grads          | -0.0343249399214983    |
| train_0/mu_grads_std      | 0.2766699083149433     |
| train_0/mu_loss           | 5.216428504322214      |
| train_0/next_q            | -5.139684601116153     |
| train_0/q_grads           | 0.0389734797179699     |
| train_0/q_grads_std       | 0.20525255240499973    |
| train_0/q_loss            | 0.43628581216594603    |
| train_0/reward            | -0.8903452108250349    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0004150390625        |
| train_0/target_q          | -5.355218486690627     |
| train_1/avg_q             | -10.094447605908565    |
| train_1/current_q         | -8.630139716507696     |
| train_1/fw_bonus          | -0.9948908984661102    |
| train_1/fw_loss           | 0.0021863483503693714  |
| train_1/mu_grads          | 0.01408983615692705    |
| train_1/mu_grads_std      | 0.11875556148588658    |
| train_1/mu_loss           | 10.020224365192382     |
| train_1/n_subgoals        | 2538.0                 |
| train_1/next_q            | -10.030220447140845    |
| train_1/q_grads           | 0.0129272541962564     |
| train_1/q_grads_std       | 0.3404359586536884     |
| train_1/q_loss            | 10.266242979139188     |
| train_1/reward            | -1.434437212505145     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022216796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2986603624901497     |
| train_1/target_q          | -8.750635468800175     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 439.47. Rollout time: 239.55, Training time: 199.88
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 448748.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.530651680865624     |
| test_1/avg_q              | -2.24218596934821      |
| test_1/n_subgoals         | 2070.0                 |
| test_1/subgoal_succ_rate  | 0.7                    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -12.297884743029941    |
| train_0/current_q         | -4.284430036219308     |
| train_0/fw_bonus          | -0.998580327630043     |
| train_0/fw_loss           | 0.00038377298624254764 |
| train_0/mu_grads          | -0.03862674469128251   |
| train_0/mu_grads_std      | 0.2957421250641346     |
| train_0/mu_loss           | 4.146493966439085      |
| train_0/next_q            | -4.057465966118729     |
| train_0/q_grads           | 0.04123398680239916    |
| train_0/q_grads_std       | 0.23449486084282398    |
| train_0/q_loss            | 0.47945520346865356    |
| train_0/reward            | -0.8921298281420604    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -4.367773332926173     |
| train_1/avg_q             | -3.356773946490504     |
| train_1/current_q         | -3.8984796740644327    |
| train_1/fw_bonus          | -0.9957986742258071    |
| train_1/fw_loss           | 0.0019528689183061943  |
| train_1/mu_grads          | 0.009307474689558148   |
| train_1/mu_grads_std      | 0.16184150762856006    |
| train_1/mu_loss           | 4.0055043362772995     |
| train_1/n_subgoals        | 1739.0                 |
| train_1/next_q            | -4.013053650136291     |
| train_1/q_grads           | 0.00911428916733712    |
| train_1/q_grads_std       | 0.34012299627065656    |
| train_1/q_loss            | 4.091143234850292      |
| train_1/reward            | -1.426817263511475     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023681640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21564117308798159    |
| train_1/target_q          | -3.9855223065986136    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 517.66. Rollout time: 317.31, Training time: 200.30
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 518578.0              |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5489750932164255   |
| test_1/avg_q              | -1.6451359980162554   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.46                  |
| train_0/avg_q             | -10.47028669675474    |
| train_0/current_q         | -5.94991585776774     |
| train_0/fw_bonus          | -0.9985119760036468   |
| train_0/fw_loss           | 0.0004019573556433897 |
| train_0/mu_grads          | -0.04702666588127613  |
| train_0/mu_grads_std      | 0.3131507493555546    |
| train_0/mu_loss           | 5.728510267796443     |
| train_0/next_q            | -5.628367648420538    |
| train_0/q_grads           | 0.04276816323399544   |
| train_0/q_grads_std       | 0.2538232631981373    |
| train_0/q_loss            | 0.47148986347030064   |
| train_0/reward            | -0.8965646524462499   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 9.765625e-05          |
| train_0/target_q          | -5.975400143103149    |
| train_1/avg_q             | -3.3502055294121784   |
| train_1/current_q         | -5.8546765866603865   |
| train_1/fw_bonus          | -0.9957991361618042   |
| train_1/fw_loss           | 0.001952748349867761  |
| train_1/mu_grads          | 0.005573760496918112  |
| train_1/mu_grads_std      | 0.19922390319406985   |
| train_1/mu_loss           | 5.687956970230191     |
| train_1/n_subgoals        | 2169.0                |
| train_1/next_q            | -5.702583551671511    |
| train_1/q_grads           | 0.008421280630864203  |
| train_1/q_grads_std       | 0.35130511671304704   |
| train_1/q_loss            | 4.189494333876951     |
| train_1/reward            | -1.4128039424933376   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00224609375         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.16459197786998617   |
| train_1/target_q          | -5.902239457312069    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 495.60. Rollout time: 298.41, Training time: 197.14
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 583887.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.3876415649922669    |
| test_1/avg_q              | -3.974198841466103     |
| test_1/n_subgoals         | 4504.0                 |
| test_1/subgoal_succ_rate  | 0.8878774422735346     |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -10.511751188900263    |
| train_0/current_q         | -5.421559692678048     |
| train_0/fw_bonus          | -0.9985453456640243    |
| train_0/fw_loss           | 0.00039308027262450194 |
| train_0/mu_grads          | -0.052527740225195886  |
| train_0/mu_grads_std      | 0.3309398084878922     |
| train_0/mu_loss           | 5.217938511937804      |
| train_0/next_q            | -5.12316633584841      |
| train_0/q_grads           | 0.043713312689214946   |
| train_0/q_grads_std       | 0.270059734582901      |
| train_0/q_loss            | 0.5965053726445546     |
| train_0/reward            | -0.8994217074432527    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 7.32421875e-05         |
| train_0/target_q          | -5.412085141590154     |
| train_1/avg_q             | -3.8784416099506527    |
| train_1/current_q         | -7.704188515776941     |
| train_1/fw_bonus          | -0.9959845125675202    |
| train_1/fw_loss           | 0.001905071976943873   |
| train_1/mu_grads          | 0.001946970823337324   |
| train_1/mu_grads_std      | 0.22650945894420146    |
| train_1/mu_loss           | 7.7191090196158285     |
| train_1/n_subgoals        | 1956.0                 |
| train_1/next_q            | -7.712304348871763     |
| train_1/q_grads           | 0.005460203508846462   |
| train_1/q_grads_std       | 0.3654099673032761     |
| train_1/q_loss            | 3.7657431358573676     |
| train_1/reward            | -1.4143467761794455    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0025146484375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1278118609406953     |
| train_1/target_q          | -7.783647726070333     |
------------------------------------------------------
New best value for test/success_rate: 0.12. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 8
Time for epoch 8: 525.27. Rollout time: 326.71, Training time: 198.52
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 652947.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -2.39457352844377      |
| test_1/avg_q              | -1.7196804293616637    |
| test_1/n_subgoals         | 667.0                  |
| test_1/subgoal_succ_rate  | 0.004497751124437781   |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -10.215430850858457    |
| train_0/current_q         | -6.111077729731669     |
| train_0/fw_bonus          | -0.9985491648316384    |
| train_0/fw_loss           | 0.000392065235064365   |
| train_0/mu_grads          | -0.06050022579729557   |
| train_0/mu_grads_std      | 0.3503554828464985     |
| train_0/mu_loss           | 5.934007514249146      |
| train_0/next_q            | -5.7799877867692855    |
| train_0/q_grads           | 0.044013125170022246   |
| train_0/q_grads_std       | 0.2855941288173199     |
| train_0/q_loss            | 0.4966338342690193     |
| train_0/reward            | -0.9039228595211171    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000244140625         |
| train_0/target_q          | -6.0730519420451285    |
| train_1/avg_q             | -4.686787699776926     |
| train_1/current_q         | -8.768452938936596     |
| train_1/fw_bonus          | -0.996385994553566     |
| train_1/fw_loss           | 0.0018018096801824869  |
| train_1/mu_grads          | -0.0011919699318241328 |
| train_1/mu_grads_std      | 0.24441151767969133    |
| train_1/mu_loss           | 9.116607670269358      |
| train_1/n_subgoals        | 2120.0                 |
| train_1/next_q            | -9.121512369607228     |
| train_1/q_grads           | 0.001923096925020218   |
| train_1/q_grads_std       | 0.37708049044013026    |
| train_1/q_loss            | 3.9994056866705043     |
| train_1/reward            | -1.4241632725141244    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022705078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.15849056603773584    |
| train_1/target_q          | -8.857241043537003     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 9
Time for epoch 9: 493.40. Rollout time: 317.30, Training time: 176.07
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 724907.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -2.6050647957111885    |
| test_1/avg_q              | -2.8769980255461647    |
| test_1/n_subgoals         | 653.0                  |
| test_1/subgoal_succ_rate  | 0.004594180704441042   |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.32                   |
| train_0/avg_q             | -13.710841926730913    |
| train_0/current_q         | -6.11795434553067      |
| train_0/fw_bonus          | -0.9985851719975471    |
| train_0/fw_loss           | 0.00038248422715696505 |
| train_0/mu_grads          | -0.06441291403025388   |
| train_0/mu_grads_std      | 0.37236721590161326    |
| train_0/mu_loss           | 5.943739886790068      |
| train_0/next_q            | -5.823908187240955     |
| train_0/q_grads           | 0.043902709428220985   |
| train_0/q_grads_std       | 0.30188010782003405    |
| train_0/q_loss            | 0.6565102344511865     |
| train_0/reward            | -0.9019601211708504    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0011474609375        |
| train_0/target_q          | -6.0968082838915665    |
| train_1/avg_q             | -4.426797774807404     |
| train_1/current_q         | -8.3195826413628       |
| train_1/fw_bonus          | -0.9967034056782722    |
| train_1/fw_loss           | 0.0017201716749696062  |
| train_1/mu_grads          | -0.002754378435201943  |
| train_1/mu_grads_std      | 0.26072787269949915    |
| train_1/mu_loss           | 8.44880231321889       |
| train_1/n_subgoals        | 2204.0                 |
| train_1/next_q            | -8.429871516380187     |
| train_1/q_grads           | 0.00015225708211801247 |
| train_1/q_grads_std       | 0.38817533627152445    |
| train_1/q_loss            | 4.24864013952489       |
| train_1/reward            | -1.4384760384593391    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021728515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12522686025408347    |
| train_1/target_q          | -8.386910480696212     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 10
Time for epoch 10: 526.45. Rollout time: 325.13, Training time: 201.26
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 793364.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.1252442911195346    |
| test_1/avg_q              | -2.8975912801960098    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -11.556870770780751    |
| train_0/current_q         | -6.703847232727147     |
| train_0/fw_bonus          | -0.9986118912696839    |
| train_0/fw_loss           | 0.00037537365860771386 |
| train_0/mu_grads          | -0.06941526532173156   |
| train_0/mu_grads_std      | 0.38821164071559905    |
| train_0/mu_loss           | 6.578798514596483      |
| train_0/next_q            | -6.421507489988909     |
| train_0/q_grads           | 0.04480752907693386    |
| train_0/q_grads_std       | 0.3112112618982792     |
| train_0/q_loss            | 0.5766391149470541     |
| train_0/reward            | -0.9037684952432755    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000732421875         |
| train_0/target_q          | -6.643718785679167     |
| train_1/avg_q             | -4.7575296187379825    |
| train_1/current_q         | -8.562678112620082     |
| train_1/fw_bonus          | -0.9967450276017189    |
| train_1/fw_loss           | 0.0017094641661969945  |
| train_1/mu_grads          | -0.006430996779818088  |
| train_1/mu_grads_std      | 0.2857788622379303     |
| train_1/mu_loss           | 8.679961145646743      |
| train_1/n_subgoals        | 2063.0                 |
| train_1/next_q            | -8.696099963951653     |
| train_1/q_grads           | -0.00266951082739979   |
| train_1/q_grads_std       | 0.39903737008571627    |
| train_1/q_loss            | 3.5101335452002145     |
| train_1/reward            | -1.4569276717375033    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002099609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1303926320891905     |
| train_1/target_q          | -8.620309205545084     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 11
Time for epoch 11: 433.27. Rollout time: 235.72, Training time: 197.50
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 849615.0               |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.7246263498244863    |
| test_1/avg_q              | -1.95439044416879      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -12.659182753388393    |
| train_0/current_q         | -6.554872976575711     |
| train_0/fw_bonus          | -0.99874676913023      |
| train_0/fw_loss           | 0.00033949163334909824 |
| train_0/mu_grads          | -0.0760221928358078    |
| train_0/mu_grads_std      | 0.4000160351395607     |
| train_0/mu_loss           | 6.368924564391394      |
| train_0/next_q            | -6.222898971844164     |
| train_0/q_grads           | 0.04524398576468229    |
| train_0/q_grads_std       | 0.32130380868911745    |
| train_0/q_loss            | 0.37066405432241434    |
| train_0/reward            | -0.9050720350031043    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0016357421875        |
| train_0/target_q          | -6.566596076508835     |
| train_1/avg_q             | -4.423712738737828     |
| train_1/current_q         | -6.131272819416871     |
| train_1/fw_bonus          | -0.9971313595771789    |
| train_1/fw_loss           | 0.0016101013083243743  |
| train_1/mu_grads          | -0.010843442007899284  |
| train_1/mu_grads_std      | 0.29726854562759397    |
| train_1/mu_loss           | 5.750159345675916      |
| train_1/n_subgoals        | 1696.0                 |
| train_1/next_q            | -5.723058434876112     |
| train_1/q_grads           | -0.00850401206407696   |
| train_1/q_grads_std       | 0.408651814609766      |
| train_1/q_loss            | 3.135195008037133      |
| train_1/reward            | -1.4505157563588       |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021728515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2275943396226415     |
| train_1/target_q          | -6.190750517653277     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 12
Time for epoch 12: 531.94. Rollout time: 314.76, Training time: 217.13
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 910411.0               |
| test/episodes             | 325.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.481164332985933     |
| test_1/avg_q              | -0.7556535780118581    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.6                    |
| train_0/avg_q             | -11.794803889159523    |
| train_0/current_q         | -5.151733620159034     |
| train_0/fw_bonus          | -0.9987635746598243    |
| train_0/fw_loss           | 0.00033501903235446664 |
| train_0/mu_grads          | -0.080443518422544     |
| train_0/mu_grads_std      | 0.4118265837430954     |
| train_0/mu_loss           | 5.095368240083392      |
| train_0/next_q            | -4.894768499958731     |
| train_0/q_grads           | 0.04407469071447849    |
| train_0/q_grads_std       | 0.3243615999817848     |
| train_0/q_loss            | 0.7042103095619605     |
| train_0/reward            | -0.9062015860312386    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.002099609375         |
| train_0/target_q          | -5.226657702519868     |
| train_1/avg_q             | -4.438902551735644     |
| train_1/current_q         | -7.667214296582003     |
| train_1/fw_bonus          | -0.9973811954259872    |
| train_1/fw_loss           | 0.0015458441397640855  |
| train_1/mu_grads          | -0.01597753670066595   |
| train_1/mu_grads_std      | 0.3129086196422577     |
| train_1/mu_loss           | 7.479202730518739      |
| train_1/n_subgoals        | 1883.0                 |
| train_1/next_q            | -7.511766194989998     |
| train_1/q_grads           | -0.009930925141088665  |
| train_1/q_grads_std       | 0.42026943787932397    |
| train_1/q_loss            | 3.267301130378203      |
| train_1/reward            | -1.4620251537678997    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0027099609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.22623473181093998    |
| train_1/target_q          | -7.670741715768786     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 13
Time for epoch 13: 482.27. Rollout time: 289.95, Training time: 192.29
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 977635.0               |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6925365430209787    |
| test_1/avg_q              | -2.4094640727865797    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -11.519618496390033    |
| train_0/current_q         | -6.1829105306608785    |
| train_0/fw_bonus          | -0.9988604426383972    |
| train_0/fw_loss           | 0.00030924583770683964 |
| train_0/mu_grads          | -0.08541785329580306   |
| train_0/mu_grads_std      | 0.42218342870473863    |
| train_0/mu_loss           | 6.002894844394921      |
| train_0/next_q            | -5.848584620909142     |
| train_0/q_grads           | 0.04549000272527337    |
| train_0/q_grads_std       | 0.33097731322050095    |
| train_0/q_loss            | 0.4150725450550479     |
| train_0/reward            | -0.9063413763360586    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.003857421875         |
| train_0/target_q          | -6.156361064309422     |
| train_1/avg_q             | -3.908296091911354     |
| train_1/current_q         | -8.704982247444189     |
| train_1/fw_bonus          | -0.9971856191754341    |
| train_1/fw_loss           | 0.0015961459488607944  |
| train_1/mu_grads          | -0.017218683520331977  |
| train_1/mu_grads_std      | 0.3213322877883911     |
| train_1/mu_loss           | 8.867492386393355      |
| train_1/n_subgoals        | 2089.0                 |
| train_1/next_q            | -8.876045111458875     |
| train_1/q_grads           | -0.010085090971551835  |
| train_1/q_grads_std       | 0.4325063146650791     |
| train_1/q_loss            | 4.085968858871156      |
| train_1/reward            | -1.4381174858179293    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.003173828125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.17568214456677836    |
| train_1/target_q          | -8.78423911974221      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 474.18. Rollout time: 282.46, Training time: 191.68
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 1040574.0              |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8033659008754166    |
| test_1/avg_q              | -2.464777656581528     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -12.186850860861448    |
| train_0/current_q         | -5.444648711456068     |
| train_0/fw_bonus          | -0.9989091575145721    |
| train_0/fw_loss           | 0.00029628338306793013 |
| train_0/mu_grads          | -0.08657812941819429   |
| train_0/mu_grads_std      | 0.4314080484211445     |
| train_0/mu_loss           | 5.295483339201768      |
| train_0/next_q            | -5.125140434524768     |
| train_0/q_grads           | 0.04618920339271426    |
| train_0/q_grads_std       | 0.3373052030801773     |
| train_0/q_loss            | 0.47033780450587803    |
| train_0/reward            | -0.9078183455421822    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0034912109375        |
| train_0/target_q          | -5.551259282714669     |
| train_1/avg_q             | -4.731218964987428     |
| train_1/current_q         | -9.26717472571183      |
| train_1/fw_bonus          | -0.9977992892265319    |
| train_1/fw_loss           | 0.0014383093337528407  |
| train_1/mu_grads          | -0.016901976056396963  |
| train_1/mu_grads_std      | 0.3343163639307022     |
| train_1/mu_loss           | 9.474658484424358      |
| train_1/n_subgoals        | 1948.0                 |
| train_1/next_q            | -9.491311239418208     |
| train_1/q_grads           | -0.010215316247195006  |
| train_1/q_grads_std       | 0.4441559225320816     |
| train_1/q_loss            | 2.7787846404492527     |
| train_1/reward            | -1.4460789614735403    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0024658203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21149897330595482    |
| train_1/target_q          | -9.318173670210868     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 426.57. Rollout time: 244.03, Training time: 182.50
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 15                    |
| policy/steps              | 1102925.0             |
| test/episodes             | 400.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.086439309013378    |
| test_1/avg_q              | -2.9772640989944863   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1600.0                |
| train/success_rate        | 0.53                  |
| train_0/avg_q             | -12.71111152344421    |
| train_0/current_q         | -6.299500067403685    |
| train_0/fw_bonus          | -0.9989645853638649   |
| train_0/fw_loss           | 0.0002815357191138901 |
| train_0/mu_grads          | -0.08836491629481316  |
| train_0/mu_grads_std      | 0.4405399739742279    |
| train_0/mu_loss           | 6.138206395445836     |
| train_0/next_q            | -5.973993916162462    |
| train_0/q_grads           | 0.04686971046030521   |
| train_0/q_grads_std       | 0.341307482868433     |
| train_0/q_loss            | 0.5347099252416994    |
| train_0/reward            | -0.9097153862021514   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0041259765625       |
| train_0/target_q          | -6.314545633305936    |
| train_1/avg_q             | -4.734569831844619    |
| train_1/current_q         | -9.583340305326299    |
| train_1/fw_bonus          | -0.9978826195001602   |
| train_1/fw_loss           | 0.001416878611780703  |
| train_1/mu_grads          | -0.01793785863555968  |
| train_1/mu_grads_std      | 0.3440995059907436    |
| train_1/mu_loss           | 9.893723323823698     |
| train_1/n_subgoals        | 1875.0                |
| train_1/next_q            | -9.904876516803618    |
| train_1/q_grads           | -0.0103673912351951   |
| train_1/q_grads_std       | 0.4506723195314407    |
| train_1/q_loss            | 2.7352094846782427    |
| train_1/reward            | -1.4458606929940288   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00244140625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1808                |
| train_1/target_q          | -9.67766504695317     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 439.75. Rollout time: 262.85, Training time: 176.87
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 16                    |
| policy/steps              | 1171949.0             |
| test/episodes             | 425.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.9599810348822106   |
| test_1/avg_q              | -2.469741943934325    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1700.0                |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -11.20819283770091    |
| train_0/current_q         | -7.1529500610552175   |
| train_0/fw_bonus          | -0.9990695208311081   |
| train_0/fw_loss           | 0.0002536169118684484 |
| train_0/mu_grads          | -0.09010262042284012  |
| train_0/mu_grads_std      | 0.449604020267725     |
| train_0/mu_loss           | 7.094838404177539     |
| train_0/next_q            | -6.914416084074506    |
| train_0/q_grads           | 0.04726689960807562   |
| train_0/q_grads_std       | 0.3450027547776699    |
| train_0/q_loss            | 1.069345261725056     |
| train_0/reward            | -0.9105692323311814   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00517578125         |
| train_0/target_q          | -7.046805711079979    |
| train_1/avg_q             | -5.231701394414293    |
| train_1/current_q         | -9.362419437513715    |
| train_1/fw_bonus          | -0.9979379594326019   |
| train_1/fw_loss           | 0.0014026418910361826 |
| train_1/mu_grads          | -0.01826382027938962  |
| train_1/mu_grads_std      | 0.34757369831204415   |
| train_1/mu_loss           | 9.636121430488421     |
| train_1/n_subgoals        | 2149.0                |
| train_1/next_q            | -9.634867791205753    |
| train_1/q_grads           | -0.009137329924851657 |
| train_1/q_grads_std       | 0.4594152271747589    |
| train_1/q_loss            | 2.610865192480231     |
| train_1/reward            | -1.4326392688628402   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0025634765625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.18613308515588645   |
| train_1/target_q          | -9.444186162642051    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 461.15. Rollout time: 284.26, Training time: 176.86
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 17                    |
| policy/steps              | 1244916.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.827737288871586    |
| test_1/avg_q              | -1.9046385399513828   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1800.0                |
| train/success_rate        | 0.35                  |
| train_0/avg_q             | -10.34413529598973    |
| train_0/current_q         | -4.888155315264484    |
| train_0/fw_bonus          | -0.999046516418457    |
| train_0/fw_loss           | 0.0002597362210508436 |
| train_0/mu_grads          | -0.09345288965851069  |
| train_0/mu_grads_std      | 0.4619920067489147    |
| train_0/mu_loss           | 4.6817478584858865    |
| train_0/next_q            | -4.565291820443069    |
| train_0/q_grads           | 0.047073130309581754  |
| train_0/q_grads_std       | 0.34845596700906756   |
| train_0/q_loss            | 0.7396355595894384    |
| train_0/reward            | -0.9121450002901839   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0046630859375       |
| train_0/target_q          | -4.9612723456823264   |
| train_1/avg_q             | -4.709751214623779    |
| train_1/current_q         | -8.107618985614149    |
| train_1/fw_bonus          | -0.9976386144757271   |
| train_1/fw_loss           | 0.001479633743292652  |
| train_1/mu_grads          | -0.01841930071823299  |
| train_1/mu_grads_std      | 0.3555504359304905    |
| train_1/mu_loss           | 8.0664520892024       |
| train_1/n_subgoals        | 2277.0                |
| train_1/next_q            | -8.051444492653479    |
| train_1/q_grads           | -0.01142576104030013  |
| train_1/q_grads_std       | 0.46754288896918295   |
| train_1/q_loss            | 2.3641946172405937    |
| train_1/reward            | -1.4269460079522105   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0023193359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.1629336846728151    |
| train_1/target_q          | -8.209061572132299    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 420.44. Rollout time: 247.00, Training time: 173.41
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1311884.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -2.2259945410929696    |
| test_1/avg_q              | -2.1319630674271837    |
| test_1/n_subgoals         | 663.0                  |
| test_1/subgoal_succ_rate  | 0.00904977375565611    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -7.553601340153651     |
| train_0/current_q         | -6.073033681924533     |
| train_0/fw_bonus          | -0.9991670817136764    |
| train_0/fw_loss           | 0.00022766085057810415 |
| train_0/mu_grads          | -0.09758280646055936   |
| train_0/mu_grads_std      | 0.4718081995844841     |
| train_0/mu_loss           | 5.856974166310866      |
| train_0/next_q            | -5.696644026694815     |
| train_0/q_grads           | 0.047611950617283585   |
| train_0/q_grads_std       | 0.3522360108792782     |
| train_0/q_loss            | 0.41853523552101973    |
| train_0/reward            | -0.9136209150034119    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.01259765625          |
| train_0/target_q          | -6.073638909489387     |
| train_1/avg_q             | -4.173863398710242     |
| train_1/current_q         | -4.089420491126772     |
| train_1/fw_bonus          | -0.9982011675834656    |
| train_1/fw_loss           | 0.0013349501154152677  |
| train_1/mu_grads          | -0.019271172350272536  |
| train_1/mu_grads_std      | 0.36281776502728463    |
| train_1/mu_loss           | 3.2048474542769383     |
| train_1/n_subgoals        | 2078.0                 |
| train_1/next_q            | -3.2116894039236312    |
| train_1/q_grads           | -0.01973519562743604   |
| train_1/q_grads_std       | 0.4724263183772564     |
| train_1/q_loss            | 2.0690724383220696     |
| train_1/reward            | -1.4282468144621816    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002392578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1766121270452358     |
| train_1/target_q          | -4.130328172364716     |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 19
Time for epoch 19: 419.47. Rollout time: 241.75, Training time: 177.69
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1377225.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.9305052206736633    |
| test_1/avg_q              | -1.938976838173055     |
| test_1/n_subgoals         | 669.0                  |
| test_1/subgoal_succ_rate  | 0.004484304932735426   |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -13.116951761242737    |
| train_0/current_q         | -7.2028339565242305    |
| train_0/fw_bonus          | -0.9992499113082886    |
| train_0/fw_loss           | 0.00020562155077641364 |
| train_0/mu_grads          | -0.09920333940535783   |
| train_0/mu_grads_std      | 0.47681995704770086    |
| train_0/mu_loss           | 6.978185749046976      |
| train_0/next_q            | -6.77668496527067      |
| train_0/q_grads           | 0.04798440709710121    |
| train_0/q_grads_std       | 0.35889403745532034    |
| train_0/q_loss            | 0.3587331800587887     |
| train_0/reward            | -0.9137868008925579    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0234619140625        |
| train_0/target_q          | -7.168800770873108     |
| train_1/avg_q             | -4.050960019485613     |
| train_1/current_q         | -9.901935587816407     |
| train_1/fw_bonus          | -0.998257665336132     |
| train_1/fw_loss           | 0.0013204151735408231  |
| train_1/mu_grads          | -0.0208165327552706    |
| train_1/mu_grads_std      | 0.37555769830942154    |
| train_1/mu_loss           | 10.225169080894768     |
| train_1/n_subgoals        | 2098.0                 |
| train_1/next_q            | -10.239746324941091    |
| train_1/q_grads           | -0.01881281677633524   |
| train_1/q_grads_std       | 0.483600165694952      |
| train_1/q_loss            | 3.12647255629012       |
| train_1/reward            | -1.4134210360542057    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023681640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2440419447092469     |
| train_1/target_q          | -10.001169469978507    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 20
Time for epoch 20: 416.29. Rollout time: 238.31, Training time: 177.95
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 20                    |
| policy/steps              | 1442381.0             |
| test/episodes             | 525.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.4679578146626238   |
| test_1/avg_q              | -1.2585116045981324   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2100.0                |
| train/success_rate        | 0.52                  |
| train_0/avg_q             | -11.891333153214974   |
| train_0/current_q         | -4.836757225104511    |
| train_0/fw_bonus          | -0.9991722494363785   |
| train_0/fw_loss           | 0.0002262887872348074 |
| train_0/mu_grads          | -0.10222527962177992  |
| train_0/mu_grads_std      | 0.4820508323609829    |
| train_0/mu_loss           | 4.664337823108253     |
| train_0/next_q            | -4.527370339900637    |
| train_0/q_grads           | 0.04974813861772418   |
| train_0/q_grads_std       | 0.36337462067604065   |
| train_0/q_loss            | 0.7537445876741782    |
| train_0/reward            | -0.9139787867257837   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.011083984375        |
| train_0/target_q          | -4.75966486467591     |
| train_1/avg_q             | -4.458569719102236    |
| train_1/current_q         | -5.130633582908031    |
| train_1/fw_bonus          | -0.9983962833881378   |
| train_1/fw_loss           | 0.0012847630656324326 |
| train_1/mu_grads          | -0.022594730788841843 |
| train_1/mu_grads_std      | 0.3878339476883411    |
| train_1/mu_loss           | 4.2143383022728385    |
| train_1/n_subgoals        | 2037.0                |
| train_1/next_q            | -4.2377465700855845   |
| train_1/q_grads           | -0.020643887389451266 |
| train_1/q_grads_std       | 0.49388340562582017   |
| train_1/q_loss            | 2.583620297804264     |
| train_1/reward            | -1.4187007789223571   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00244140625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21993127147766323   |
| train_1/target_q          | -5.051312243459313    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 21
Time for epoch 21: 389.27. Rollout time: 213.18, Training time: 176.06
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 21                    |
| policy/steps              | 1501826.0             |
| test/episodes             | 550.0                 |
| test/success_rate         | 0.12                  |
| test_0/avg_q              | -1.9588494094385078   |
| test_1/avg_q              | -2.373971158179453    |
| test_1/n_subgoals         | 658.0                 |
| test_1/subgoal_succ_rate  | 0.007598784194528876  |
| train/episodes            | 2200.0                |
| train/success_rate        | 0.61                  |
| train_0/avg_q             | -8.833830711066863    |
| train_0/current_q         | -6.367133972170496    |
| train_0/fw_bonus          | -0.9992013797163963   |
| train_0/fw_loss           | 0.0002185358705901308 |
| train_0/mu_grads          | -0.10424436889588833  |
| train_0/mu_grads_std      | 0.4870109550654888    |
| train_0/mu_loss           | 6.154555778194194     |
| train_0/next_q            | -5.950598641002534    |
| train_0/q_grads           | 0.05013019219040871   |
| train_0/q_grads_std       | 0.3692663863301277    |
| train_0/q_loss            | 0.4181982004324302    |
| train_0/reward            | -0.9162772525887704   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0134033203125       |
| train_0/target_q          | -6.334297036536276    |
| train_1/avg_q             | -3.5309354362936345   |
| train_1/current_q         | -7.635182876435596    |
| train_1/fw_bonus          | -0.9986704930663108   |
| train_1/fw_loss           | 0.0012142346036853268 |
| train_1/mu_grads          | -0.02338424017652869  |
| train_1/mu_grads_std      | 0.40348585695028305   |
| train_1/mu_loss           | 7.262793534238654     |
| train_1/n_subgoals        | 1824.0                |
| train_1/next_q            | -7.265838377947749    |
| train_1/q_grads           | -0.023699377290904523 |
| train_1/q_grads_std       | 0.5049941837787628    |
| train_1/q_loss            | 2.7277280051275787    |
| train_1/reward            | -1.4178017065685709   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0030517578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.20888157894736842   |
| train_1/target_q          | -7.662094793121999    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 22
Time for epoch 22: 394.33. Rollout time: 217.73, Training time: 176.56
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 1561688.0             |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.7285196864130556   |
| test_1/avg_q              | -2.134327401674626    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -11.560802445262956   |
| train_0/current_q         | -6.726735296864081    |
| train_0/fw_bonus          | -0.9992322772741318   |
| train_0/fw_loss           | 0.0002103122213156894 |
| train_0/mu_grads          | -0.10472711585462094  |
| train_0/mu_grads_std      | 0.49292997270822525   |
| train_0/mu_loss           | 6.498982095435878     |
| train_0/next_q            | -6.361825154909006    |
| train_0/q_grads           | 0.04921446032822132   |
| train_0/q_grads_std       | 0.37457955777645113   |
| train_0/q_loss            | 0.4913099805521144    |
| train_0/reward            | -0.9149576605166658   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0158447265625       |
| train_0/target_q          | -6.711189977388964    |
| train_1/avg_q             | -4.368039444325878    |
| train_1/current_q         | -8.990197670667282    |
| train_1/fw_bonus          | -0.998675411939621    |
| train_1/fw_loss           | 0.0012129703041864558 |
| train_1/mu_grads          | -0.024470698507502674 |
| train_1/mu_grads_std      | 0.40794888883829117   |
| train_1/mu_loss           | 9.04951951727894      |
| train_1/n_subgoals        | 1840.0                |
| train_1/next_q            | -9.065070942109468    |
| train_1/q_grads           | -0.026225661300122736 |
| train_1/q_grads_std       | 0.5169609174132347    |
| train_1/q_loss            | 3.008726775090634     |
| train_1/reward            | -1.4322341032806434   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0025146484375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.22608695652173913   |
| train_1/target_q          | -9.08279493323953     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 23
Time for epoch 23: 406.33. Rollout time: 228.03, Training time: 178.27
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 1625002.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.1651076829440843    |
| test_1/avg_q              | -4.226194276319142     |
| test_1/n_subgoals         | 1394.0                 |
| test_1/subgoal_succ_rate  | 0.5351506456241033     |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.45                   |
| train_0/avg_q             | -11.108757553738442    |
| train_0/current_q         | -6.201888906567296     |
| train_0/fw_bonus          | -0.9992975115776062    |
| train_0/fw_loss           | 0.00019296011996630113 |
| train_0/mu_grads          | -0.11212883852422237   |
| train_0/mu_grads_std      | 0.4952062301337719     |
| train_0/mu_loss           | 5.993986753313081      |
| train_0/next_q            | -5.8478351171671985    |
| train_0/q_grads           | 0.04917986104264856    |
| train_0/q_grads_std       | 0.38120361492037774    |
| train_0/q_loss            | 0.5578543253812116     |
| train_0/reward            | -0.9161052068389836    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.028125               |
| train_0/target_q          | -6.167911114689078     |
| train_1/avg_q             | -4.467561203887773     |
| train_1/current_q         | -9.276951366999187     |
| train_1/fw_bonus          | -0.9990082606673241    |
| train_1/fw_loss           | 0.0011273616386461073  |
| train_1/mu_grads          | -0.024428620096296073  |
| train_1/mu_grads_std      | 0.41808212772011755    |
| train_1/mu_loss           | 9.518606209338733      |
| train_1/n_subgoals        | 2033.0                 |
| train_1/next_q            | -9.439883850113596     |
| train_1/q_grads           | -0.02717578983865678   |
| train_1/q_grads_std       | 0.5252290800213814     |
| train_1/q_loss            | 3.0785164574786954     |
| train_1/reward            | -1.4124397952662548    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018798828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2439744220363994     |
| train_1/target_q          | -9.445421589328589     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 24
Time for epoch 24: 417.09. Rollout time: 237.39, Training time: 179.66
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 24                     |
| policy/steps              | 1690477.0              |
| test/episodes             | 625.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.3046138654829766    |
| test_1/avg_q              | -2.940494230273479     |
| test_1/n_subgoals         | 677.0                  |
| test_1/subgoal_succ_rate  | 0.0029542097488921715  |
| train/episodes            | 2500.0                 |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -12.058050404113054    |
| train_0/current_q         | -5.740219270737906     |
| train_0/fw_bonus          | -0.9992638513445854    |
| train_0/fw_loss           | 0.00020191337280266451 |
| train_0/mu_grads          | -0.11096545029431581   |
| train_0/mu_grads_std      | 0.4988268420100212     |
| train_0/mu_loss           | 5.545453637000435      |
| train_0/next_q            | -5.335845829543229     |
| train_0/q_grads           | 0.049321623239666226   |
| train_0/q_grads_std       | 0.38608134612441064    |
| train_0/q_loss            | 0.5337293768568941     |
| train_0/reward            | -0.9182772344487603    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0172607421875        |
| train_0/target_q          | -5.6878929429734315    |
| train_1/avg_q             | -5.1657596875957275    |
| train_1/current_q         | -7.838725361680102     |
| train_1/fw_bonus          | -0.9989378735423088    |
| train_1/fw_loss           | 0.0011454658670118079  |
| train_1/mu_grads          | -0.024646915169432758  |
| train_1/mu_grads_std      | 0.42611399218440055    |
| train_1/mu_loss           | 7.5550832131717325     |
| train_1/n_subgoals        | 2048.0                 |
| train_1/next_q            | -7.543387909791133     |
| train_1/q_grads           | -0.027339514857158066  |
| train_1/q_grads_std       | 0.530168867111206      |
| train_1/q_loss            | 2.109035302607742      |
| train_1/reward            | -1.4160124912581522    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002392578125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21435546875          |
| train_1/target_q          | -7.961652885684626     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 25
Time for epoch 25: 440.11. Rollout time: 254.88, Training time: 185.20
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 25                     |
| policy/steps              | 1758572.0              |
| test/episodes             | 650.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.189874376006692     |
| test_1/avg_q              | -2.2122298065185575    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2600.0                 |
| train/success_rate        | 0.4                    |
| train_0/avg_q             | -11.145841282676002    |
| train_0/current_q         | -6.668037763903418     |
| train_0/fw_bonus          | -0.9993576437234879    |
| train_0/fw_loss           | 0.00017695860406092835 |
| train_0/mu_grads          | -0.11167697384953498   |
| train_0/mu_grads_std      | 0.5016764536499977     |
| train_0/mu_loss           | 6.4558271581050635     |
| train_0/next_q            | -6.2786414806621575    |
| train_0/q_grads           | 0.04946748474612832    |
| train_0/q_grads_std       | 0.39193678423762324    |
| train_0/q_loss            | 0.5175971743298257     |
| train_0/reward            | -0.9189274127347744    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0310302734375        |
| train_0/target_q          | -6.631403648686051     |
| train_1/avg_q             | -4.364443812393727     |
| train_1/current_q         | -7.75660970719081      |
| train_1/fw_bonus          | -0.999313423037529     |
| train_1/fw_loss           | 0.0010488761807209812  |
| train_1/mu_grads          | -0.026001077657565475  |
| train_1/mu_grads_std      | 0.4316252782940865     |
| train_1/mu_loss           | 7.513149815387578      |
| train_1/n_subgoals        | 2129.0                 |
| train_1/next_q            | -7.524658189787402     |
| train_1/q_grads           | -0.028463811706751586  |
| train_1/q_grads_std       | 0.5356272175908089     |
| train_1/q_loss            | 2.1444533462994797     |
| train_1/reward            | -1.399594930668536     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0021240234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19633630812588068    |
| train_1/target_q          | -7.883106869602616     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 433.50. Rollout time: 251.10, Training time: 182.37
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1826351.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.0780819414021847    |
| test_1/avg_q              | -2.3985956476817107    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.39                   |
| train_0/avg_q             | -12.025480256780124    |
| train_0/current_q         | -6.537268235508788     |
| train_0/fw_bonus          | -0.999329648911953     |
| train_0/fw_loss           | 0.00018440740641381125 |
| train_0/mu_grads          | -0.11300816684961319   |
| train_0/mu_grads_std      | 0.5066695243120194     |
| train_0/mu_loss           | 6.314474101265146      |
| train_0/next_q            | -6.149382670546269     |
| train_0/q_grads           | 0.04927295232191682    |
| train_0/q_grads_std       | 0.397315526008606      |
| train_0/q_loss            | 0.4923762868222402     |
| train_0/reward            | -0.9185951362116611    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.02109375             |
| train_0/target_q          | -6.4983150338847295    |
| train_1/avg_q             | -4.290727723431739     |
| train_1/current_q         | -8.825914756145707     |
| train_1/fw_bonus          | -0.9995408982038498    |
| train_1/fw_loss           | 0.0009903691287036053  |
| train_1/mu_grads          | -0.027305019646883012  |
| train_1/mu_grads_std      | 0.4383315935730934     |
| train_1/mu_loss           | 8.798644941264737      |
| train_1/n_subgoals        | 2156.0                 |
| train_1/next_q            | -8.806750324845526     |
| train_1/q_grads           | -0.02958860285580158   |
| train_1/q_grads_std       | 0.5375827834010124     |
| train_1/q_loss            | 2.24089957947158       |
| train_1/reward            | -1.4106420035328484    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00244140625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.20871985157699444    |
| train_1/target_q          | -8.919349588635196     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 424.36. Rollout time: 242.35, Training time: 181.98
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 1892466.0              |
| test/episodes             | 700.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.7363093522874455    |
| test_1/avg_q              | -3.1292276795102665    |
| test_1/n_subgoals         | 1264.0                 |
| test_1/subgoal_succ_rate  | 0.4849683544303797     |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -11.550039034456907    |
| train_0/current_q         | -6.370997390779993     |
| train_0/fw_bonus          | -0.9993513494729995    |
| train_0/fw_loss           | 0.00017863446519186254 |
| train_0/mu_grads          | -0.11289842892438173   |
| train_0/mu_grads_std      | 0.513044522702694      |
| train_0/mu_loss           | 6.075120880340514      |
| train_0/next_q            | -5.897650995000094     |
| train_0/q_grads           | 0.04978552469983697    |
| train_0/q_grads_std       | 0.40521893873810766    |
| train_0/q_loss            | 0.3220472026969599     |
| train_0/reward            | -0.9181719564759987    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0318603515625        |
| train_0/target_q          | -6.371435698083474     |
| train_1/avg_q             | -4.492423044214462     |
| train_1/current_q         | -3.8066022795048724    |
| train_1/fw_bonus          | -0.9994644612073899    |
| train_1/fw_loss           | 0.0010100296218297443  |
| train_1/mu_grads          | -0.026633277256041765  |
| train_1/mu_grads_std      | 0.44860507026314733    |
| train_1/mu_loss           | 3.3249715512630935     |
| train_1/n_subgoals        | 2092.0                 |
| train_1/next_q            | -3.3026445137816602    |
| train_1/q_grads           | -0.029741465486586093  |
| train_1/q_grads_std       | 0.5414153233170509     |
| train_1/q_loss            | 1.7637193547970582     |
| train_1/reward            | -1.425928911520168     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020263671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.22179732313575526    |
| train_1/target_q          | -4.036466044211724     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 412.55. Rollout time: 227.21, Training time: 185.31
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 1955115.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.9172425328664997    |
| test_1/avg_q              | -2.015564410935697     |
| test_1/n_subgoals         | 671.0                  |
| test_1/subgoal_succ_rate  | 0.0029806259314456036  |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.55                   |
| train_0/avg_q             | -11.262308388829267    |
| train_0/current_q         | -6.7310789317965005    |
| train_0/fw_bonus          | -0.9993903651833534    |
| train_0/fw_loss           | 0.00016825182756292635 |
| train_0/mu_grads          | -0.11724385526031256   |
| train_0/mu_grads_std      | 0.518053263425827      |
| train_0/mu_loss           | 6.525149843484513      |
| train_0/next_q            | -6.370847696823892     |
| train_0/q_grads           | 0.049805921781808135   |
| train_0/q_grads_std       | 0.4086627632379532     |
| train_0/q_loss            | 0.5592593032650681     |
| train_0/reward            | -0.9186162628553575    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03427734375          |
| train_0/target_q          | -6.683343952248526     |
| train_1/avg_q             | -4.523632184798155     |
| train_1/current_q         | -8.478845640468307     |
| train_1/fw_bonus          | -0.9998207882046699    |
| train_1/fw_loss           | 0.0009183814021525904  |
| train_1/mu_grads          | -0.02447970802895725   |
| train_1/mu_grads_std      | 0.4578976906836033     |
| train_1/mu_loss           | 8.330731826004161      |
| train_1/n_subgoals        | 1996.0                 |
| train_1/next_q            | -8.31415549287571      |
| train_1/q_grads           | -0.028916545677930117  |
| train_1/q_grads_std       | 0.5466645330190658     |
| train_1/q_loss            | 2.029319305135521      |
| train_1/reward            | -1.418865837949852     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001953125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.251503006012024      |
| train_1/target_q          | -8.553026215834834     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 29
Time for epoch 29: 434.02. Rollout time: 250.35, Training time: 183.64
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 2022666.0             |
| test/episodes             | 750.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.9562496204416713   |
| test_1/avg_q              | -2.7528194088473343   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -13.018933385146077   |
| train_0/current_q         | -6.821805215909352    |
| train_0/fw_bonus          | -0.9994241118431091   |
| train_0/fw_loss           | 0.0001592733919096645 |
| train_0/mu_grads          | -0.11862581111490726  |
| train_0/mu_grads_std      | 0.5232652768492698    |
| train_0/mu_loss           | 6.6330632273681       |
| train_0/next_q            | -6.463491359451685    |
| train_0/q_grads           | 0.05108076008036733   |
| train_0/q_grads_std       | 0.41451031938195226   |
| train_0/q_loss            | 0.5296507863262813    |
| train_0/reward            | -0.9171340036293258   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.02451171875         |
| train_0/target_q          | -6.779241018746402    |
| train_1/avg_q             | -4.776074249902421    |
| train_1/current_q         | -8.920673564960788    |
| train_1/fw_bonus          | -0.9998469308018685   |
| train_1/fw_loss           | 0.000911656575044617  |
| train_1/mu_grads          | -0.02601719619706273  |
| train_1/mu_grads_std      | 0.46302277147769927   |
| train_1/mu_loss           | 8.836110388578476     |
| train_1/n_subgoals        | 2133.0                |
| train_1/next_q            | -8.818332179880805    |
| train_1/q_grads           | -0.029569632140919566 |
| train_1/q_grads_std       | 0.5532698884606362    |
| train_1/q_loss            | 2.248448257416315     |
| train_1/reward            | -1.4186779279858457   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0022705078125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21518987341772153   |
| train_1/target_q          | -9.012929648277707    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 30
Time for epoch 30: 447.87. Rollout time: 265.31, Training time: 182.52
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2092228.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0951367388653444    |
| test_1/avg_q              | -2.9516731493706674    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -13.289013493549875    |
| train_0/current_q         | -6.735887465825433     |
| train_0/fw_bonus          | -0.9994134426116943    |
| train_0/fw_loss           | 0.00016211455222219228 |
| train_0/mu_grads          | -0.11640191115438939   |
| train_0/mu_grads_std      | 0.5310417979955673     |
| train_0/mu_loss           | 6.567581643233739      |
| train_0/next_q            | -6.409533414946497     |
| train_0/q_grads           | 0.0509854931384325     |
| train_0/q_grads_std       | 0.418453062325716      |
| train_0/q_loss            | 0.672158718591333      |
| train_0/reward            | -0.9181025572557701    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03046875             |
| train_0/target_q          | -6.70930668965719      |
| train_1/avg_q             | -5.000750722989446     |
| train_1/current_q         | -9.422974990212362     |
| train_1/fw_bonus          | -1.0000115469098092    |
| train_1/fw_loss           | 0.0008693214826053008  |
| train_1/mu_grads          | -0.026801363192498685  |
| train_1/mu_grads_std      | 0.4707299008965492     |
| train_1/mu_loss           | 9.434265071911398      |
| train_1/n_subgoals        | 2177.0                 |
| train_1/next_q            | -9.430993542856891     |
| train_1/q_grads           | -0.029466892965137957  |
| train_1/q_grads_std       | 0.5610923737287521     |
| train_1/q_loss            | 2.1150421347462887     |
| train_1/reward            | -1.4224024526251013    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0023193359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19016995865870465    |
| train_1/target_q          | -9.5041997208185       |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 31
Time for epoch 31: 449.95. Rollout time: 264.74, Training time: 185.17
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 2162188.0              |
| test/episodes             | 800.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5869052428813166    |
| test_1/avg_q              | -1.2007676484588685    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.42                   |
| train_0/avg_q             | -9.879788363192871     |
| train_0/current_q         | -6.455099890962552     |
| train_0/fw_bonus          | -0.9994512021541595    |
| train_0/fw_loss           | 0.00015206836251309143 |
| train_0/mu_grads          | -0.12038762848824262   |
| train_0/mu_grads_std      | 0.5386667877435685     |
| train_0/mu_loss           | 6.252104416099872      |
| train_0/next_q            | -6.080834633672489     |
| train_0/q_grads           | 0.05126108443364501    |
| train_0/q_grads_std       | 0.42114381641149523    |
| train_0/q_loss            | 0.524325573091391      |
| train_0/reward            | -0.9171176927615307    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0437255859375        |
| train_0/target_q          | -6.397744042657604     |
| train_1/avg_q             | -4.878801369815772     |
| train_1/current_q         | -9.631886105170178     |
| train_1/fw_bonus          | -0.9996580794453621    |
| train_1/fw_loss           | 0.0009602288118912838  |
| train_1/mu_grads          | -0.02734620594419539   |
| train_1/mu_grads_std      | 0.4767369955778122     |
| train_1/mu_loss           | 9.671274339780826      |
| train_1/n_subgoals        | 2148.0                 |
| train_1/next_q            | -9.678082788696901     |
| train_1/q_grads           | -0.030091954069212078  |
| train_1/q_grads_std       | 0.5657121375203132     |
| train_1/q_loss            | 2.2808165499608712     |
| train_1/reward            | -1.4237853129874565    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00234375             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.159683426443203      |
| train_1/target_q          | -9.707139314150727     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 32
Time for epoch 32: 438.02. Rollout time: 251.78, Training time: 186.22
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 2229787.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.1024117468070007   |
| test_1/avg_q              | -2.448422063782525    |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.48                  |
| train_0/avg_q             | -9.567313194341601    |
| train_0/current_q         | -6.3832266721583455   |
| train_0/fw_bonus          | -0.9994126096367836   |
| train_0/fw_loss           | 0.000162337368237786  |
| train_0/mu_grads          | -0.12363685108721256  |
| train_0/mu_grads_std      | 0.5421764105558395    |
| train_0/mu_loss           | 6.236166781856886     |
| train_0/next_q            | -6.059228758356657    |
| train_0/q_grads           | 0.05159742599353194   |
| train_0/q_grads_std       | 0.4242939926683903    |
| train_0/q_loss            | 0.6482221754746392    |
| train_0/reward            | -0.9177113041834672   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0301513671875       |
| train_0/target_q          | -6.3520692312154745   |
| train_1/avg_q             | -4.232738272653411    |
| train_1/current_q         | -8.820236524593671    |
| train_1/fw_bonus          | -0.9997918993234635   |
| train_1/fw_loss           | 0.000925812014611438  |
| train_1/mu_grads          | -0.027729549584910272 |
| train_1/mu_grads_std      | 0.48137196004390714   |
| train_1/mu_loss           | 8.654244803373695     |
| train_1/n_subgoals        | 2154.0                |
| train_1/next_q            | -8.638845552345419    |
| train_1/q_grads           | -0.029828883428126573 |
| train_1/q_grads_std       | 0.5717050671577454    |
| train_1/q_loss            | 2.1657384158450097    |
| train_1/reward            | -1.42202410131722     |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002001953125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21773444753946147   |
| train_1/target_q          | -8.883789694422388    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 449.49. Rollout time: 263.70, Training time: 185.76
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 2299336.0              |
| test/episodes             | 850.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9291236064278592    |
| test_1/avg_q              | -1.8548250700211726    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.4                    |
| train_0/avg_q             | -12.401468000610135    |
| train_0/current_q         | -7.024249190165024     |
| train_0/fw_bonus          | -0.9994409859180451    |
| train_0/fw_loss           | 0.00015478594395972322 |
| train_0/mu_grads          | -0.12335738763213158   |
| train_0/mu_grads_std      | 0.5465259179472923     |
| train_0/mu_loss           | 6.812817820937646      |
| train_0/next_q            | -6.658484095415778     |
| train_0/q_grads           | 0.051640561781823635   |
| train_0/q_grads_std       | 0.4319130353629589     |
| train_0/q_loss            | 0.5234570425575932     |
| train_0/reward            | -0.9162921609982732    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03232421875          |
| train_0/target_q          | -7.001647327950397     |
| train_1/avg_q             | -4.771829311517566     |
| train_1/current_q         | -9.45489345144534      |
| train_1/fw_bonus          | -0.9995664477348327    |
| train_1/fw_loss           | 0.0009837959878495894  |
| train_1/mu_grads          | -0.028660911740735172  |
| train_1/mu_grads_std      | 0.4852779783308506     |
| train_1/mu_loss           | 9.400332138235562      |
| train_1/n_subgoals        | 2172.0                 |
| train_1/next_q            | -9.407128459133585     |
| train_1/q_grads           | -0.02985976068302989   |
| train_1/q_grads_std       | 0.5778463438153267     |
| train_1/q_loss            | 2.821551999885814      |
| train_1/reward            | -1.4380659560265485    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0019287109375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1841620626151013     |
| train_1/target_q          | -9.542185351174592     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 444.24. Rollout time: 257.59, Training time: 186.62
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 2368005.0              |
| test/episodes             | 875.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5673718490955972    |
| test_1/avg_q              | -1.3675945835985417    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.45                   |
| train_0/avg_q             | -12.88613428092695     |
| train_0/current_q         | -6.021863280552774     |
| train_0/fw_bonus          | -0.9994188085198402    |
| train_0/fw_loss           | 0.00016068612821982243 |
| train_0/mu_grads          | -0.12499658446758985   |
| train_0/mu_grads_std      | 0.5509360015392304     |
| train_0/mu_loss           | 5.813971911284202      |
| train_0/next_q            | -5.644780740746038     |
| train_0/q_grads           | 0.05213749371469021    |
| train_0/q_grads_std       | 0.43395735025405885    |
| train_0/q_loss            | 0.5588764842318708     |
| train_0/reward            | -0.9166417398359045    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0275390625           |
| train_0/target_q          | -5.981595416072247     |
| train_1/avg_q             | -4.370469276149343     |
| train_1/current_q         | -9.20938768755527      |
| train_1/fw_bonus          | -0.9994671806693077    |
| train_1/fw_loss           | 0.0010093273551319726  |
| train_1/mu_grads          | -0.029608438024297357  |
| train_1/mu_grads_std      | 0.4874976731836796     |
| train_1/mu_loss           | 9.244277178763552      |
| train_1/n_subgoals        | 2136.0                 |
| train_1/next_q            | -9.225518935618103     |
| train_1/q_grads           | -0.03030877741985023   |
| train_1/q_grads_std       | 0.5877111688256264     |
| train_1/q_loss            | 2.308493518313612      |
| train_1/reward            | -1.4220796408888419    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022216796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.18773408239700373    |
| train_1/target_q          | -9.373808398436248     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 445.99. Rollout time: 262.60, Training time: 183.36
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 2438016.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -2.208647841318463     |
| test_1/avg_q              | -1.6741149357409268    |
| test_1/n_subgoals         | 728.0                  |
| test_1/subgoal_succ_rate  | 0.08241758241758242    |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.37                   |
| train_0/avg_q             | -10.946952038982106    |
| train_0/current_q         | -6.937640660825164     |
| train_0/fw_bonus          | -0.9994202122092247    |
| train_0/fw_loss           | 0.00016031358427426312 |
| train_0/mu_grads          | -0.12123902216553688   |
| train_0/mu_grads_std      | 0.5546378821134568     |
| train_0/mu_loss           | 6.730568083747395      |
| train_0/next_q            | -6.582207275920726     |
| train_0/q_grads           | 0.05211975267156958    |
| train_0/q_grads_std       | 0.43842885047197344    |
| train_0/q_loss            | 0.568551009433573      |
| train_0/reward            | -0.9162704757254687    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.04443359375          |
| train_0/target_q          | -6.886838743664472     |
| train_1/avg_q             | -4.495101622361304     |
| train_1/current_q         | -9.488004798348081     |
| train_1/fw_bonus          | -0.9997234031558037    |
| train_1/fw_loss           | 0.0009434277133550494  |
| train_1/mu_grads          | -0.030816220864653587  |
| train_1/mu_grads_std      | 0.49053479358553886    |
| train_1/mu_loss           | 9.427615057946014      |
| train_1/n_subgoals        | 2208.0                 |
| train_1/next_q            | -9.42312550749762      |
| train_1/q_grads           | -0.03078733370639384   |
| train_1/q_grads_std       | 0.5968909829854965     |
| train_1/q_loss            | 2.381093499281311      |
| train_1/reward            | -1.4479981238924666    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002001953125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19701086956521738    |
| train_1/target_q          | -9.535509453512734     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 36
Time for epoch 36: 414.40. Rollout time: 230.01, Training time: 184.35
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 2501586.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9916680400924638    |
| test_1/avg_q              | -3.1461099422987022    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -13.459913089487404    |
| train_0/current_q         | -6.493922324821232     |
| train_0/fw_bonus          | -0.9994841381907463    |
| train_0/fw_loss           | 0.00014330406029330333 |
| train_0/mu_grads          | -0.12313334103673697   |
| train_0/mu_grads_std      | 0.5588824927806855     |
| train_0/mu_loss           | 6.312770587430744      |
| train_0/next_q            | -6.153728611694077     |
| train_0/q_grads           | 0.05273131188005209    |
| train_0/q_grads_std       | 0.443131435662508      |
| train_0/q_loss            | 0.6032308449601317     |
| train_0/reward            | -0.9174414703680668    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.056591796875         |
| train_0/target_q          | -6.452145540415432     |
| train_1/avg_q             | -4.351286470026788     |
| train_1/current_q         | -9.402819227058725     |
| train_1/fw_bonus          | -0.9998634457588196    |
| train_1/fw_loss           | 0.0009074108194909059  |
| train_1/mu_grads          | -0.03138395249843597   |
| train_1/mu_grads_std      | 0.49474307894706726    |
| train_1/mu_loss           | 9.344918089542281      |
| train_1/n_subgoals        | 1985.0                 |
| train_1/next_q            | -9.351882266196373     |
| train_1/q_grads           | -0.032317081559449436  |
| train_1/q_grads_std       | 0.6084957689046859     |
| train_1/q_loss            | 2.7286074880874955     |
| train_1/reward            | -1.431306275720999     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002099609375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2141057934508816     |
| train_1/target_q          | -9.490580665545018     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 37
Time for epoch 37: 410.45. Rollout time: 231.95, Training time: 178.47
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 2565100.0              |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8431175516513387    |
| test_1/avg_q              | -3.58925275235906      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -11.346913341944044    |
| train_0/current_q         | -5.490154269501081     |
| train_0/fw_bonus          | -0.9994480028748512    |
| train_0/fw_loss           | 0.00015291618183255196 |
| train_0/mu_grads          | -0.12561651840806007   |
| train_0/mu_grads_std      | 0.5662943556904793     |
| train_0/mu_loss           | 5.211141903935747      |
| train_0/next_q            | -5.083432295780844     |
| train_0/q_grads           | 0.05143625009804964    |
| train_0/q_grads_std       | 0.44405872747302055    |
| train_0/q_loss            | 0.5195140933440963     |
| train_0/reward            | -0.916968818436726     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0794189453125        |
| train_0/target_q          | -5.428290056486641     |
| train_1/avg_q             | -5.192968192795557     |
| train_1/current_q         | -8.520231803068121     |
| train_1/fw_bonus          | -1.0000503987073899    |
| train_1/fw_loss           | 0.0008593231308623217  |
| train_1/mu_grads          | -0.030826497264206408  |
| train_1/mu_grads_std      | 0.49772212728857995    |
| train_1/mu_loss           | 8.35148102413968       |
| train_1/n_subgoals        | 1961.0                 |
| train_1/next_q            | -8.330215680763244     |
| train_1/q_grads           | -0.033807237166911364  |
| train_1/q_grads_std       | 0.6152280807495117     |
| train_1/q_loss            | 2.3321663549293477     |
| train_1/reward            | -1.4282909835266764    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00205078125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21009688934217235    |
| train_1/target_q          | -8.662753404141327     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 38
Time for epoch 38: 369.32. Rollout time: 192.38, Training time: 176.92
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 2620137.0              |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5496403851148428    |
| test_1/avg_q              | -1.9833258924342678    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -9.686542108423064     |
| train_0/current_q         | -5.676320644705709     |
| train_0/fw_bonus          | -0.9994049414992332    |
| train_0/fw_loss           | 0.00016437294289062265 |
| train_0/mu_grads          | -0.127744822204113     |
| train_0/mu_grads_std      | 0.571770490705967      |
| train_0/mu_loss           | 5.452896857243063      |
| train_0/next_q            | -5.331132267975979     |
| train_0/q_grads           | 0.05172235686331987    |
| train_0/q_grads_std       | 0.44763547256588937    |
| train_0/q_loss            | 0.6724902929401606     |
| train_0/reward            | -0.9165764158096863    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03134765625          |
| train_0/target_q          | -5.817756683652597     |
| train_1/avg_q             | -4.5483948477898695    |
| train_1/current_q         | -8.97056550299719      |
| train_1/fw_bonus          | -0.9996901229023933    |
| train_1/fw_loss           | 0.0009519898288999684  |
| train_1/mu_grads          | -0.029998453427106143  |
| train_1/mu_grads_std      | 0.5003738820552825     |
| train_1/mu_loss           | 9.030048509772536      |
| train_1/n_subgoals        | 1636.0                 |
| train_1/next_q            | -8.992400033354299     |
| train_1/q_grads           | -0.03597162337973714   |
| train_1/q_grads_std       | 0.623974159359932      |
| train_1/q_loss            | 2.9416238458060318     |
| train_1/reward            | -1.4223261840917985    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00205078125          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23166259168704156    |
| train_1/target_q          | -9.125371010285466     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 39
Time for epoch 39: 394.85. Rollout time: 216.49, Training time: 178.33
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 39                    |
| policy/steps              | 2680333.0             |
| test/episodes             | 1000.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.8916234105447447   |
| test_1/avg_q              | -3.4020151539660644   |
| test_1/n_subgoals         | 663.0                 |
| test_1/subgoal_succ_rate  | 0.0030165912518853697 |
| train/episodes            | 4000.0                |
| train/success_rate        | 0.54                  |
| train_0/avg_q             | -10.268498577953146   |
| train_0/current_q         | -5.948540620205522    |
| train_0/fw_bonus          | -0.9993963181972504   |
| train_0/fw_loss           | 0.0001666680174821522 |
| train_0/mu_grads          | -0.12708132676780223  |
| train_0/mu_grads_std      | 0.5742966294288635    |
| train_0/mu_loss           | 5.73782339016491      |
| train_0/next_q            | -5.564777294403116    |
| train_0/q_grads           | 0.05207010926678777   |
| train_0/q_grads_std       | 0.4491866149008274    |
| train_0/q_loss            | 0.5441407520575534    |
| train_0/reward            | -0.9162037351372418   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0427978515625       |
| train_0/target_q          | -5.896709802750411    |
| train_1/avg_q             | -4.94998269289984     |
| train_1/current_q         | -9.721262484730547    |
| train_1/fw_bonus          | -0.9996216401457787   |
| train_1/fw_loss           | 0.00096960431401385   |
| train_1/mu_grads          | -0.03132435465231538  |
| train_1/mu_grads_std      | 0.503367866575718     |
| train_1/mu_loss           | 9.82398471188794      |
| train_1/n_subgoals        | 1878.0                |
| train_1/next_q            | -9.826097478512668    |
| train_1/q_grads           | -0.03645859034731984  |
| train_1/q_grads_std       | 0.631790192425251     |
| train_1/q_loss            | 2.513088867766706     |
| train_1/reward            | -1.4349579255271236   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.24653887113951012   |
| train_1/target_q          | -9.75678315143486     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 40
Time for epoch 40: 409.96. Rollout time: 230.36, Training time: 179.58
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 40                    |
| policy/steps              | 2743166.0             |
| test/episodes             | 1025.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.2218139010734235   |
| test_1/avg_q              | -3.6742739236529944   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 4100.0                |
| train/success_rate        | 0.51                  |
| train_0/avg_q             | -10.973551015859096   |
| train_0/current_q         | -5.864338717076694    |
| train_0/fw_bonus          | -0.9994050174951553   |
| train_0/fw_loss           | 0.0001643551015149569 |
| train_0/mu_grads          | -0.12943514212965965  |
| train_0/mu_grads_std      | 0.5789687216281891    |
| train_0/mu_loss           | 5.710951549411701     |
| train_0/next_q            | -5.541952507921755    |
| train_0/q_grads           | 0.052351970411837104  |
| train_0/q_grads_std       | 0.452129827439785     |
| train_0/q_loss            | 0.7053083991836054    |
| train_0/reward            | -0.9169854014966404   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0442626953125       |
| train_0/target_q          | -5.878096180096515    |
| train_1/avg_q             | -5.173236746060358    |
| train_1/current_q         | -6.064629073204626    |
| train_1/fw_bonus          | -0.9997011482715606   |
| train_1/fw_loss           | 0.0009491545963101089 |
| train_1/mu_grads          | -0.032469498086720706 |
| train_1/mu_grads_std      | 0.5071338385343551    |
| train_1/mu_loss           | 5.629161509730426     |
| train_1/n_subgoals        | 1990.0                |
| train_1/next_q            | -5.510781875124293    |
| train_1/q_grads           | -0.03845011666417122  |
| train_1/q_grads_std       | 0.6367781341075898    |
| train_1/q_loss            | 3.769545783700333     |
| train_1/reward            | -1.4048356727813371   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0016845703125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2547738693467337    |
| train_1/target_q          | -6.1716111554272235   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 41
Time for epoch 41: 432.57. Rollout time: 250.18, Training time: 182.35
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2809469.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -2.1152112285520976    |
| test_1/avg_q              | -2.711030420211798     |
| test_1/n_subgoals         | 661.0                  |
| test_1/subgoal_succ_rate  | 0.02723146747352496    |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -10.851481116237416    |
| train_0/current_q         | -6.204588491204576     |
| train_0/fw_bonus          | -0.9993802368640899    |
| train_0/fw_loss           | 0.00017094742106564808 |
| train_0/mu_grads          | -0.1280992578715086    |
| train_0/mu_grads_std      | 0.5846857771277427     |
| train_0/mu_loss           | 6.001212453219995      |
| train_0/next_q            | -5.847031544631126     |
| train_0/q_grads           | 0.05284409392625093    |
| train_0/q_grads_std       | 0.4551626920700073     |
| train_0/q_loss            | 0.5759478684806469     |
| train_0/reward            | -0.9177541721175657    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.04912109375          |
| train_0/target_q          | -6.1470837375969944    |
| train_1/avg_q             | -5.36824285558918      |
| train_1/current_q         | -8.481124521271918     |
| train_1/fw_bonus          | -0.9994873896241188    |
| train_1/fw_loss           | 0.0010041318149887958  |
| train_1/mu_grads          | -0.03310466036200523   |
| train_1/mu_grads_std      | 0.5095632389187813     |
| train_1/mu_loss           | 8.382893390839445      |
| train_1/n_subgoals        | 2169.0                 |
| train_1/next_q            | -8.35596443949321      |
| train_1/q_grads           | -0.03671882329508662   |
| train_1/q_grads_std       | 0.6451593413949013     |
| train_1/q_loss            | 2.0964022553660433     |
| train_1/reward            | -1.4070313147938578    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001806640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24665744582757032    |
| train_1/target_q          | -8.563947335546112     |
------------------------------------------------------
New best value for test/success_rate: 0.16. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 42
Time for epoch 42: 444.71. Rollout time: 266.45, Training time: 178.22
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 2879657.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.6582179230818306    |
| test_1/avg_q              | -6.767223447435042     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.37                   |
| train_0/avg_q             | -11.57130353583504     |
| train_0/current_q         | -6.474226154192702     |
| train_0/fw_bonus          | -0.9993368342518807    |
| train_0/fw_loss           | 0.00018249402455694508 |
| train_0/mu_grads          | -0.12915382348001003   |
| train_0/mu_grads_std      | 0.5895025610923768     |
| train_0/mu_loss           | 6.292209956633258      |
| train_0/next_q            | -6.112378913816717     |
| train_0/q_grads           | 0.05304452003911138    |
| train_0/q_grads_std       | 0.4587853915989399     |
| train_0/q_loss            | 0.5524241429655351     |
| train_0/reward            | -0.9157684987279936    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.058984375            |
| train_0/target_q          | -6.459135677395638     |
| train_1/avg_q             | -5.543291749380524     |
| train_1/current_q         | -9.018428312564215     |
| train_1/fw_bonus          | -0.999537567794323     |
| train_1/fw_loss           | 0.0009912267123581842  |
| train_1/mu_grads          | -0.03436544304713607   |
| train_1/mu_grads_std      | 0.5142201215028763     |
| train_1/mu_loss           | 9.091845580532974      |
| train_1/n_subgoals        | 2231.0                 |
| train_1/next_q            | -9.041894572729593     |
| train_1/q_grads           | -0.036909142322838304  |
| train_1/q_grads_std       | 0.6544003397226333     |
| train_1/q_loss            | 1.939534073036866      |
| train_1/reward            | -1.3972056643979158    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020751953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.20708202599731063    |
| train_1/target_q          | -9.111935991086096     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 43
Time for epoch 43: 430.87. Rollout time: 253.55, Training time: 177.29
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 43                    |
| policy/steps              | 2945462.0             |
| test/episodes             | 1100.0                |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.4967175608762122   |
| test_1/avg_q              | -6.106230587171678    |
| test_1/n_subgoals         | 1302.0                |
| test_1/subgoal_succ_rate  | 0.5360983102918587    |
| train/episodes            | 4400.0                |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -13.143747986296201   |
| train_0/current_q         | -6.337735210997051    |
| train_0/fw_bonus          | -0.9993181601166725   |
| train_0/fw_loss           | 0.0001874637269793311 |
| train_0/mu_grads          | -0.12880160920321942  |
| train_0/mu_grads_std      | 0.5925286307930946    |
| train_0/mu_loss           | 6.173901258869728     |
| train_0/next_q            | -5.989610759881545    |
| train_0/q_grads           | 0.053140650037676096  |
| train_0/q_grads_std       | 0.45956693664193154   |
| train_0/q_loss            | 0.6329516566973208    |
| train_0/reward            | -0.9153760715169483   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.043505859375        |
| train_0/target_q          | -6.3312737233549345   |
| train_1/avg_q             | -6.67075041046441     |
| train_1/current_q         | -3.679247801437705    |
| train_1/fw_bonus          | -0.9998272731900215   |
| train_1/fw_loss           | 0.0009167170806904324 |
| train_1/mu_grads          | -0.033193009719252584 |
| train_1/mu_grads_std      | 0.518813006579876     |
| train_1/mu_loss           | 3.258904490057111     |
| train_1/n_subgoals        | 2119.0                |
| train_1/next_q            | -3.2290728506262356   |
| train_1/q_grads           | -0.03670790567994118  |
| train_1/q_grads_std       | 0.6576046019792556    |
| train_1/q_loss            | 1.3205407598754477    |
| train_1/reward            | -1.3971116577755311   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0018798828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.21708352996696556   |
| train_1/target_q          | -3.950891279562682    |
-----------------------------------------------------
New best value for test/success_rate: 0.2. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 44
Time for epoch 44: 412.24. Rollout time: 233.97, Training time: 178.24
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 3008642.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -2.0279232716198408    |
| test_1/avg_q              | -0.45002583430341875   |
| test_1/n_subgoals         | 769.0                  |
| test_1/subgoal_succ_rate  | 0.15214564369310793    |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.49                   |
| train_0/avg_q             | -12.086534354900088    |
| train_0/current_q         | -6.582489478785549     |
| train_0/fw_bonus          | -0.9993414536118508    |
| train_0/fw_loss           | 0.00018126552749890833 |
| train_0/mu_grads          | -0.13059291578829288   |
| train_0/mu_grads_std      | 0.597508105635643      |
| train_0/mu_loss           | 6.376902488697695      |
| train_0/next_q            | -6.21890514673853      |
| train_0/q_grads           | 0.05314204692840576    |
| train_0/q_grads_std       | 0.4615966886281967     |
| train_0/q_loss            | 0.4821792491639454     |
| train_0/reward            | -0.915448475262383     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0365234375           |
| train_0/target_q          | -6.579828908334941     |
| train_1/avg_q             | -5.830131369033917     |
| train_1/current_q         | -5.010933665347499     |
| train_1/fw_bonus          | -0.9997260183095932    |
| train_1/fw_loss           | 0.000942757043230813   |
| train_1/mu_grads          | -0.03527874257415533   |
| train_1/mu_grads_std      | 0.5205767884850502     |
| train_1/mu_loss           | 4.340354506450972      |
| train_1/n_subgoals        | 2039.0                 |
| train_1/next_q            | -4.283994540999246     |
| train_1/q_grads           | -0.036840823013335466  |
| train_1/q_grads_std       | 0.6630672127008438     |
| train_1/q_loss            | 4.082679841292953      |
| train_1/reward            | -1.3918416323445855    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00166015625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2491417361451692     |
| train_1/target_q          | -5.083830844559936     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.12
Training epoch 45
Time for epoch 45: 419.02. Rollout time: 242.70, Training time: 176.29
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 45                     |
| policy/steps              | 3073992.0              |
| test/episodes             | 1150.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.7975484129547648    |
| test_1/avg_q              | -4.63115203827736      |
| test_1/n_subgoals         | 2828.0                 |
| test_1/subgoal_succ_rate  | 0.7966760961810466     |
| train/episodes            | 4600.0                 |
| train/success_rate        | 0.44                   |
| train_0/avg_q             | -12.436014050002987    |
| train_0/current_q         | -6.8084515522910225    |
| train_0/fw_bonus          | -0.9993921890854836    |
| train_0/fw_loss           | 0.00016776732154539787 |
| train_0/mu_grads          | -0.1323389545083046    |
| train_0/mu_grads_std      | 0.602766889333725      |
| train_0/mu_loss           | 6.591658685602686      |
| train_0/next_q            | -6.41524726834785      |
| train_0/q_grads           | 0.053657153714448215   |
| train_0/q_grads_std       | 0.46414018198847773    |
| train_0/q_loss            | 0.4669939913204266     |
| train_0/reward            | -0.9158649431425147    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.058251953125         |
| train_0/target_q          | -6.758988849406305     |
| train_1/avg_q             | -3.638908503237307     |
| train_1/current_q         | -8.488433231673293     |
| train_1/fw_bonus          | -0.9999645218253136    |
| train_1/fw_loss           | 0.0008814117274596356  |
| train_1/mu_grads          | -0.03699211813509464   |
| train_1/mu_grads_std      | 0.5231944248080254     |
| train_1/mu_loss           | 8.327245336392178      |
| train_1/n_subgoals        | 2060.0                 |
| train_1/next_q            | -8.327066874958032     |
| train_1/q_grads           | -0.03495546383783221   |
| train_1/q_grads_std       | 0.667442587018013      |
| train_1/q_loss            | 3.085244708277447      |
| train_1/reward            | -1.3960610446811188    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00166015625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21796116504854368    |
| train_1/target_q          | -8.512032585449273     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11
Training epoch 46
Time for epoch 46: 396.59. Rollout time: 220.43, Training time: 176.14
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 3134662.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.841414614602868     |
| test_1/avg_q              | -1.707485129888311     |
| test_1/n_subgoals         | 1655.0                 |
| test_1/subgoal_succ_rate  | 0.6235649546827795     |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.55                   |
| train_0/avg_q             | -12.986158516015301    |
| train_0/current_q         | -6.913143119106389     |
| train_0/fw_bonus          | -0.9993563458323479    |
| train_0/fw_loss           | 0.00017730316030792893 |
| train_0/mu_grads          | -0.13387533389031886   |
| train_0/mu_grads_std      | 0.6073350176215172     |
| train_0/mu_loss           | 6.684662938353858      |
| train_0/next_q            | -6.526087851456038     |
| train_0/q_grads           | 0.05364761902019381    |
| train_0/q_grads_std       | 0.46771111860871317    |
| train_0/q_loss            | 0.4696295440738464     |
| train_0/reward            | -0.9161676525778603    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03740234375          |
| train_0/target_q          | -6.896991903590196     |
| train_1/avg_q             | -4.262795207147458     |
| train_1/current_q         | -9.030145130878697     |
| train_1/fw_bonus          | -1.0000181138515472    |
| train_1/fw_loss           | 0.0008676316880155355  |
| train_1/mu_grads          | -0.03681600904092193   |
| train_1/mu_grads_std      | 0.526324725151062      |
| train_1/mu_loss           | 8.87814226310798       |
| train_1/n_subgoals        | 1902.0                 |
| train_1/next_q            | -8.906338412571474     |
| train_1/q_grads           | -0.03484445801004767   |
| train_1/q_grads_std       | 0.6726921126246452     |
| train_1/q_loss            | 2.9649228838811164     |
| train_1/reward            | -1.4052381903878994    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022705078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2434279705573081     |
| train_1/target_q          | -9.071373017176851     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.14
Training epoch 47
Time for epoch 47: 409.54. Rollout time: 229.36, Training time: 180.15
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 3196856.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.5467577370805237    |
| test_1/avg_q              | -2.941819595924588     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -12.380730415553451    |
| train_0/current_q         | -6.314219023239012     |
| train_0/fw_bonus          | -0.999380074441433     |
| train_0/fw_loss           | 0.00017099306714953854 |
| train_0/mu_grads          | -0.13671698719263076   |
| train_0/mu_grads_std      | 0.6117664933204651     |
| train_0/mu_loss           | 6.156683573680265      |
| train_0/next_q            | -5.94149991164219      |
| train_0/q_grads           | 0.05327628469094634    |
| train_0/q_grads_std       | 0.46806700676679613    |
| train_0/q_loss            | 0.6390680626422474     |
| train_0/reward            | -0.915739883101196     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0545654296875        |
| train_0/target_q          | -6.2507352982169975    |
| train_1/avg_q             | -4.420769097792197     |
| train_1/current_q         | -9.229798694373537     |
| train_1/fw_bonus          | -1.0001427590847016    |
| train_1/fw_loss           | 0.000835572807409335   |
| train_1/mu_grads          | -0.03647122336551547   |
| train_1/mu_grads_std      | 0.5296196207404137     |
| train_1/mu_loss           | 9.293794790073495      |
| train_1/n_subgoals        | 1908.0                 |
| train_1/next_q            | -9.312939469633102     |
| train_1/q_grads           | -0.03383212126791477   |
| train_1/q_grads_std       | 0.6816496804356575     |
| train_1/q_loss            | 2.3683758868470512     |
| train_1/reward            | -1.4082918799904292    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00234375             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.22536687631027252    |
| train_1/target_q          | -9.298336559893531     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 48
Time for epoch 48: 428.80. Rollout time: 246.28, Training time: 182.49
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 3262423.0              |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.28                   |
| test_0/avg_q              | -1.4124871332079818    |
| test_1/avg_q              | -2.6710697863422777    |
| test_1/n_subgoals         | 653.0                  |
| test_1/subgoal_succ_rate  | 0.007656967840735069   |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -12.023886146379539    |
| train_0/current_q         | -6.440394987387194     |
| train_0/fw_bonus          | -0.9993970453739166    |
| train_0/fw_loss           | 0.00016647752927383407 |
| train_0/mu_grads          | -0.1389563761651516    |
| train_0/mu_grads_std      | 0.6160855680704117     |
| train_0/mu_loss           | 6.21165661004662       |
| train_0/next_q            | -6.054210984128722     |
| train_0/q_grads           | 0.05294463336467743    |
| train_0/q_grads_std       | 0.46880908608436583    |
| train_0/q_loss            | 0.6229295523086487     |
| train_0/reward            | -0.9159967526633409    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.061328125            |
| train_0/target_q          | -6.413177995781217     |
| train_1/avg_q             | -4.948677331537469     |
| train_1/current_q         | -10.002483109784986    |
| train_1/fw_bonus          | -1.000060786306858     |
| train_1/fw_loss           | 0.0008566593809518963  |
| train_1/mu_grads          | -0.03608049228787422   |
| train_1/mu_grads_std      | 0.5355845525860786     |
| train_1/mu_loss           | 10.188951547401237     |
| train_1/n_subgoals        | 2105.0                 |
| train_1/next_q            | -10.214171212025127    |
| train_1/q_grads           | -0.03418897772207856   |
| train_1/q_grads_std       | 0.6920996621251106     |
| train_1/q_loss            | 2.3629021643973402     |
| train_1/reward            | -1.4046903515336453    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23705463182897862    |
| train_1/target_q          | -10.101416483042769    |
------------------------------------------------------
New best value for test/success_rate: 0.28. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.13
Training epoch 49
Time for epoch 49: 400.98. Rollout time: 220.37, Training time: 180.58
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 49                    |
| policy/steps              | 3322564.0             |
| test/episodes             | 1250.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -2.7707794372280348   |
| test_1/avg_q              | -2.7852757036095994   |
| test_1/n_subgoals         | 654.0                 |
| test_1/subgoal_succ_rate  | 0.0015290519877675841 |
| train/episodes            | 5000.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -10.926129894996812   |
| train_0/current_q         | -6.142963446469919    |
| train_0/fw_bonus          | -0.9993910759687423   |
| train_0/fw_loss           | 0.0001680648940237006 |
| train_0/mu_grads          | -0.13964321836829185  |
| train_0/mu_grads_std      | 0.6197748705744743    |
| train_0/mu_loss           | 5.94929860239562      |
| train_0/next_q            | -5.757802195319364    |
| train_0/q_grads           | 0.05252883806824684   |
| train_0/q_grads_std       | 0.46974133253097533   |
| train_0/q_loss            | 0.6060584102701922    |
| train_0/reward            | -0.9161143484685453   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0623779296875       |
| train_0/target_q          | -6.060802949774181    |
| train_1/avg_q             | -4.682848009752583    |
| train_1/current_q         | -8.679771195146637    |
| train_1/fw_bonus          | -1.0000559523701669   |
| train_1/fw_loss           | 0.0008578987384680658 |
| train_1/mu_grads          | -0.03644838212057948  |
| train_1/mu_grads_std      | 0.5385222509503365    |
| train_1/mu_loss           | 8.64524664813907      |
| train_1/n_subgoals        | 1871.0                |
| train_1/next_q            | -8.65534704215747     |
| train_1/q_grads           | -0.033850702177733186 |
| train_1/q_grads_std       | 0.6981591388583184    |
| train_1/q_loss            | 2.3240871639037564    |
| train_1/reward            | -1.396465301734861    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001953125           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.24532335649385356   |
| train_1/target_q          | -8.7877198840485      |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11
Training epoch 50
Time for epoch 50: 401.36. Rollout time: 223.90, Training time: 177.43
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 3383251.0             |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -2.352841865752155    |
| test_1/avg_q              | -2.6713456727430858   |
| test_1/n_subgoals         | 650.0                 |
| test_1/subgoal_succ_rate  | 0.0015384615384615385 |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -11.81871494396922    |
| train_0/current_q         | -6.351195637290519    |
| train_0/fw_bonus          | -0.9993736103177071   |
| train_0/fw_loss           | 0.0001727097696857527 |
| train_0/mu_grads          | -0.14139262437820435  |
| train_0/mu_grads_std      | 0.6237638846039772    |
| train_0/mu_loss           | 6.155835787167659     |
| train_0/next_q            | -5.964669166300987    |
| train_0/q_grads           | 0.05240068277344108   |
| train_0/q_grads_std       | 0.470564404129982     |
| train_0/q_loss            | 0.547205889458775     |
| train_0/reward            | -0.9159120458818506   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.05224609375         |
| train_0/target_q          | -6.288605855897854    |
| train_1/avg_q             | -4.86188499614009     |
| train_1/current_q         | -10.0527229913851     |
| train_1/fw_bonus          | -1.0001839220523834   |
| train_1/fw_loss           | 0.0008249839171185158 |
| train_1/mu_grads          | -0.03693422554060817  |
| train_1/mu_grads_std      | 0.5420800492167472    |
| train_1/mu_loss           | 10.235722601665845    |
| train_1/n_subgoals        | 1902.0                |
| train_1/next_q            | -10.248376220523577   |
| train_1/q_grads           | -0.03271428449079394  |
| train_1/q_grads_std       | 0.7005265414714813    |
| train_1/q_loss            | 2.2562053913393108    |
| train_1/reward            | -1.384195560021908    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001953125           |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2444794952681388    |
| train_1/target_q          | -10.161873568423061   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 51
Time for epoch 51: 397.94. Rollout time: 218.48, Training time: 179.43
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 3443361.0              |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.5597435726751996    |
| test_1/avg_q              | -2.9772551715418745    |
| test_1/n_subgoals         | 667.0                  |
| test_1/subgoal_succ_rate  | 0.0029985007496251873  |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -11.91271754617681     |
| train_0/current_q         | -7.37768591061798      |
| train_0/fw_bonus          | -0.9993466690182686    |
| train_0/fw_loss           | 0.00017987402206927073 |
| train_0/mu_grads          | -0.14097418300807477   |
| train_0/mu_grads_std      | 0.6280691683292389     |
| train_0/mu_loss           | 7.191158734365788      |
| train_0/next_q            | -7.018896966435596     |
| train_0/q_grads           | 0.05224226405844092    |
| train_0/q_grads_std       | 0.47370298728346827    |
| train_0/q_loss            | 0.5575626643664855     |
| train_0/reward            | -0.9174421438758145    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0647216796875        |
| train_0/target_q          | -7.34861546326002      |
| train_1/avg_q             | -4.55983872309686      |
| train_1/current_q         | -10.07418197081793     |
| train_1/fw_bonus          | -1.0000217631459236    |
| train_1/fw_loss           | 0.0008666916808579117  |
| train_1/mu_grads          | -0.037552314531058076  |
| train_1/mu_grads_std      | 0.5467458754777909     |
| train_1/mu_loss           | 10.312616674110327     |
| train_1/n_subgoals        | 1832.0                 |
| train_1/next_q            | -10.31305884259601     |
| train_1/q_grads           | -0.032535978872328994  |
| train_1/q_grads_std       | 0.7053584635257721     |
| train_1/q_loss            | 2.5930515751108807     |
| train_1/reward            | -1.399845423916122     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0020751953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2177947598253275     |
| train_1/target_q          | -10.198509897778873    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11
Training epoch 52
Time for epoch 52: 446.33. Rollout time: 239.14, Training time: 207.16
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 3498548.0              |
| test/episodes             | 1325.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -2.7752581626556236    |
| test_1/avg_q              | -1.2034160750718865    |
| test_1/n_subgoals         | 1112.0                 |
| test_1/subgoal_succ_rate  | 0.41636690647482016    |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.69                   |
| train_0/avg_q             | -13.535887832844487    |
| train_0/current_q         | -6.596300568857856     |
| train_0/fw_bonus          | -0.9993698418140411    |
| train_0/fw_loss           | 0.00017371317953802646 |
| train_0/mu_grads          | -0.14308824576437473   |
| train_0/mu_grads_std      | 0.63240747153759       |
| train_0/mu_loss           | 6.497644296711917      |
| train_0/next_q            | -6.282036655980892     |
| train_0/q_grads           | 0.052528442908078433   |
| train_0/q_grads_std       | 0.47521476820111275    |
| train_0/q_loss            | 0.7696441045949645     |
| train_0/reward            | -0.9180210339211043    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.06259765625          |
| train_0/target_q          | -6.522572373791206     |
| train_1/avg_q             | -4.614656779960789     |
| train_1/current_q         | -9.480430245552105     |
| train_1/fw_bonus          | -0.9999525725841523    |
| train_1/fw_loss           | 0.000884491071337834   |
| train_1/mu_grads          | -0.038062282186001536  |
| train_1/mu_grads_std      | 0.5533955588936805     |
| train_1/mu_loss           | 9.636497903354893      |
| train_1/n_subgoals        | 1694.0                 |
| train_1/next_q            | -9.667122143456663     |
| train_1/q_grads           | -0.03216439066454768   |
| train_1/q_grads_std       | 0.7106327027082443     |
| train_1/q_loss            | 2.9877349459981546     |
| train_1/reward            | -1.3957896136955241    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0024658203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.26741440377804016    |
| train_1/target_q          | -9.599441865993747     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 53
Time for epoch 53: 380.34. Rollout time: 194.92, Training time: 185.38
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 3552902.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.4807915484513963    |
| test_1/avg_q              | -1.7316748973248781    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.75                   |
| train_0/avg_q             | -11.732578614832626    |
| train_0/current_q         | -6.562722132914393     |
| train_0/fw_bonus          | -0.9993237599730491    |
| train_0/fw_loss           | 0.00018597464877530002 |
| train_0/mu_grads          | -0.14485937245190145   |
| train_0/mu_grads_std      | 0.6347318857908248     |
| train_0/mu_loss           | 6.3749529229295545     |
| train_0/next_q            | -6.196879730846145     |
| train_0/q_grads           | 0.05284298555925489    |
| train_0/q_grads_std       | 0.4768935553729534     |
| train_0/q_loss            | 0.5386027741421726     |
| train_0/reward            | -0.9185785113193561    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0677734375           |
| train_0/target_q          | -6.5389128845607845    |
| train_1/avg_q             | -4.08865729066167      |
| train_1/current_q         | -9.269652160828286     |
| train_1/fw_bonus          | -0.9998641774058342    |
| train_1/fw_loss           | 0.0009072220476809889  |
| train_1/mu_grads          | -0.03881904482841492   |
| train_1/mu_grads_std      | 0.5555053025484085     |
| train_1/mu_loss           | 9.384664674625288      |
| train_1/n_subgoals        | 1655.0                 |
| train_1/next_q            | -9.427171922016303     |
| train_1/q_grads           | -0.030994392186403274  |
| train_1/q_grads_std       | 0.7169330760836601     |
| train_1/q_loss            | 2.7783930910066816     |
| train_1/reward            | -1.3873248917167076    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017822265625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2797583081570997     |
| train_1/target_q          | -9.382795775553298     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 54
Time for epoch 54: 379.20. Rollout time: 194.38, Training time: 184.79
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 3606998.0             |
| test/episodes             | 1375.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.1744469151843084   |
| test_1/avg_q              | -2.8130061208023736   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.71                  |
| train_0/avg_q             | -12.951971502000077   |
| train_0/current_q         | -6.226835143416295    |
| train_0/fw_bonus          | -0.999339935183525    |
| train_0/fw_loss           | 0.0001816732921724906 |
| train_0/mu_grads          | -0.1451741736382246   |
| train_0/mu_grads_std      | 0.6382312923669815    |
| train_0/mu_loss           | 6.0925551532707685    |
| train_0/next_q            | -5.883618324328252    |
| train_0/q_grads           | 0.052880068123340604  |
| train_0/q_grads_std       | 0.4794661596417427    |
| train_0/q_loss            | 0.526267117284556     |
| train_0/reward            | -0.9168999625384459   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0546875             |
| train_0/target_q          | -6.290745105541479    |
| train_1/avg_q             | -4.118730079296968    |
| train_1/current_q         | -9.42980187967899     |
| train_1/fw_bonus          | -1.0000072181224824   |
| train_1/fw_loss           | 0.000870432380179409  |
| train_1/mu_grads          | -0.03966996818780899  |
| train_1/mu_grads_std      | 0.5592043831944465    |
| train_1/mu_loss           | 9.710732658548235     |
| train_1/n_subgoals        | 1605.0                |
| train_1/next_q            | -9.737803590090815    |
| train_1/q_grads           | -0.030559886945411563 |
| train_1/q_grads_std       | 0.7244196861982346    |
| train_1/q_loss            | 2.9765409544309804    |
| train_1/reward            | -1.3894036073223106   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2498442367601246    |
| train_1/target_q          | -9.5714617513616      |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 55
Time for epoch 55: 368.70. Rollout time: 183.86, Training time: 184.82
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 3659464.0             |
| test/episodes             | 1400.0                |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -2.0618113985977478   |
| test_1/avg_q              | -2.7926638822658667   |
| test_1/n_subgoals         | 674.0                 |
| test_1/subgoal_succ_rate  | 0.017804154302670624  |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.8                   |
| train_0/avg_q             | -12.876373669976003   |
| train_0/current_q         | -6.529221444657091    |
| train_0/fw_bonus          | -0.999327403306961    |
| train_0/fw_loss           | 0.000185007552136085  |
| train_0/mu_grads          | -0.14716671779751778  |
| train_0/mu_grads_std      | 0.6424027562141419    |
| train_0/mu_loss           | 6.340479548880942     |
| train_0/next_q            | -6.18997449036207     |
| train_0/q_grads           | 0.0532887164503336    |
| train_0/q_grads_std       | 0.4816724620759487    |
| train_0/q_loss            | 0.6069679349692934    |
| train_0/reward            | -0.9179586788450251   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0633056640625       |
| train_0/target_q          | -6.574433506237094    |
| train_1/avg_q             | -3.962870146848243    |
| train_1/current_q         | -9.22466869250545     |
| train_1/fw_bonus          | -1.0000075533986093   |
| train_1/fw_loss           | 0.0008703469968168065 |
| train_1/mu_grads          | -0.04006532216444612  |
| train_1/mu_grads_std      | 0.5641364946961402    |
| train_1/mu_loss           | 9.329990914707817     |
| train_1/n_subgoals        | 1620.0                |
| train_1/next_q            | -9.360257918747353    |
| train_1/q_grads           | -0.030523465061560274 |
| train_1/q_grads_std       | 0.7280370548367501    |
| train_1/q_loss            | 2.5653414080561516    |
| train_1/reward            | -1.377624071635364    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0021728515625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.29074074074074074   |
| train_1/target_q          | -9.333939863395566    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 56
Time for epoch 56: 363.67. Rollout time: 176.94, Training time: 186.70
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 56                    |
| policy/steps              | 3709477.0             |
| test/episodes             | 1425.0                |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.9069913550456397   |
| test_1/avg_q              | -4.159676613065156    |
| test_1/n_subgoals         | 1235.0                |
| test_1/subgoal_succ_rate  | 0.5052631578947369    |
| train/episodes            | 5700.0                |
| train/success_rate        | 0.73                  |
| train_0/avg_q             | -12.80178187430387    |
| train_0/current_q         | -6.758693050656175    |
| train_0/fw_bonus          | -0.9993343532085419   |
| train_0/fw_loss           | 0.0001831584617320914 |
| train_0/mu_grads          | -0.14756897799670696  |
| train_0/mu_grads_std      | 0.6471074014902115    |
| train_0/mu_loss           | 6.571655701729959     |
| train_0/next_q            | -6.418858225367882    |
| train_0/q_grads           | 0.05359725384041667   |
| train_0/q_grads_std       | 0.48372500389814377   |
| train_0/q_loss            | 0.7667478606557415    |
| train_0/reward            | -0.9203869870965719   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0546875             |
| train_0/target_q          | -6.8297009605102375   |
| train_1/avg_q             | -4.028204766918249    |
| train_1/current_q         | -8.651767897235013    |
| train_1/fw_bonus          | -1.0000460982322692   |
| train_1/fw_loss           | 0.000860430859029293  |
| train_1/mu_grads          | -0.04037605347111821  |
| train_1/mu_grads_std      | 0.5677082657814025    |
| train_1/mu_loss           | 8.753437791192678     |
| train_1/n_subgoals        | 1543.0                |
| train_1/next_q            | -8.742873029876591    |
| train_1/q_grads           | -0.030510287918150424 |
| train_1/q_grads_std       | 0.7315209254622459    |
| train_1/q_loss            | 2.7918796071573113    |
| train_1/reward            | -1.354429110311321    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002392578125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.304601425793908     |
| train_1/target_q          | -8.801537080515754    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 57
Time for epoch 57: 376.35. Rollout time: 186.99, Training time: 189.34
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 3761341.0              |
| test/episodes             | 1450.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -2.2736209992607463    |
| test_1/avg_q              | -3.3914095157209707    |
| test_1/n_subgoals         | 657.0                  |
| test_1/subgoal_succ_rate  | 0.0091324200913242     |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.8                    |
| train_0/avg_q             | -12.310781917295648    |
| train_0/current_q         | -6.629340362735283     |
| train_0/fw_bonus          | -0.9992872640490532    |
| train_0/fw_loss           | 0.00019568339339457453 |
| train_0/mu_grads          | -0.14823185987770557   |
| train_0/mu_grads_std      | 0.651633994281292      |
| train_0/mu_loss           | 6.423306639807606      |
| train_0/next_q            | -6.2443926765102225    |
| train_0/q_grads           | 0.053729329351335765   |
| train_0/q_grads_std       | 0.4849561400711536     |
| train_0/q_loss            | 0.5604502440285482     |
| train_0/reward            | -0.9194361534493509    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.035302734375         |
| train_0/target_q          | -6.562540171296514     |
| train_1/avg_q             | -4.673133401349822     |
| train_1/current_q         | -8.247610056868165     |
| train_1/fw_bonus          | -1.0001463875174523    |
| train_1/fw_loss           | 0.0008346351998625324  |
| train_1/mu_grads          | -0.03979276884347201   |
| train_1/mu_grads_std      | 0.5738697201013565     |
| train_1/mu_loss           | 8.212689513278113      |
| train_1/n_subgoals        | 1555.0                 |
| train_1/next_q            | -8.234364379405662     |
| train_1/q_grads           | -0.03097600475884974   |
| train_1/q_grads_std       | 0.734642793238163      |
| train_1/q_loss            | 2.2037390151482783     |
| train_1/reward            | -1.3578368507543928    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001806640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2733118971061093     |
| train_1/target_q          | -8.343635357897574     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13
Training epoch 58
Time for epoch 58: 380.41. Rollout time: 191.56, Training time: 188.82
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 3814280.0             |
| test/episodes             | 1475.0                |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -1.8635819766227888   |
| test_1/avg_q              | -3.5956400854171338   |
| test_1/n_subgoals         | 651.0                 |
| test_1/subgoal_succ_rate  | 0.013824884792626729  |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.71                  |
| train_0/avg_q             | -12.303471776105175   |
| train_0/current_q         | -6.546615656436522    |
| train_0/fw_bonus          | -0.9992435649037361   |
| train_0/fw_loss           | 0.0002073090599878924 |
| train_0/mu_grads          | -0.15134531408548355  |
| train_0/mu_grads_std      | 0.6555664330720902    |
| train_0/mu_loss           | 6.462402720618053     |
| train_0/next_q            | -6.244117350509298    |
| train_0/q_grads           | 0.05389063004404306   |
| train_0/q_grads_std       | 0.48638836964964866   |
| train_0/q_loss            | 0.9246492724366651    |
| train_0/reward            | -0.9203189092615502   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0218017578125       |
| train_0/target_q          | -6.53030769191156     |
| train_1/avg_q             | -4.4926057377531805   |
| train_1/current_q         | -8.26757391625886     |
| train_1/fw_bonus          | -1.0001479491591454   |
| train_1/fw_loss           | 0.0008342323999386281 |
| train_1/mu_grads          | -0.03868110151961446  |
| train_1/mu_grads_std      | 0.5800631985068321    |
| train_1/mu_loss           | 8.40116516061472      |
| train_1/n_subgoals        | 1652.0                |
| train_1/next_q            | -8.378913298063882    |
| train_1/q_grads           | -0.030760868173092603 |
| train_1/q_grads_std       | 0.736595906317234     |
| train_1/q_loss            | 2.824006603808795     |
| train_1/reward            | -1.3617808962866547   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017578125          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2838983050847458    |
| train_1/target_q          | -8.417711364952277    |
-----------------------------------------------------
New best value for test/success_rate: 0.32. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.21000000000000002
Training epoch 59
Time for epoch 59: 385.08. Rollout time: 198.60, Training time: 186.45
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 59                    |
| policy/steps              | 3869659.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -2.599709774669427    |
| test_1/avg_q              | -2.1965039437389833   |
| test_1/n_subgoals         | 673.0                 |
| test_1/subgoal_succ_rate  | 0.004457652303120356  |
| train/episodes            | 6000.0                |
| train/success_rate        | 0.7                   |
| train_0/avg_q             | -11.478950813653357   |
| train_0/current_q         | -6.659045478842158    |
| train_0/fw_bonus          | -0.9993022054433822   |
| train_0/fw_loss           | 0.0001917054716614075 |
| train_0/mu_grads          | -0.15172484740614892  |
| train_0/mu_grads_std      | 0.6605611488223075    |
| train_0/mu_loss           | 6.452093364652347     |
| train_0/next_q            | -6.2807907772019345   |
| train_0/q_grads           | 0.05378381703048944   |
| train_0/q_grads_std       | 0.48782873079180716   |
| train_0/q_loss            | 0.6008000242888263    |
| train_0/reward            | -0.9203201692012953   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0305908203125       |
| train_0/target_q          | -6.589689580157142    |
| train_1/avg_q             | -4.575778523587068    |
| train_1/current_q         | -5.083446969531261    |
| train_1/fw_bonus          | -1.0002159461379052   |
| train_1/fw_loss           | 0.0008167482010321692 |
| train_1/mu_grads          | -0.038934029545634984 |
| train_1/mu_grads_std      | 0.5863141238689422    |
| train_1/mu_loss           | 4.545597223485001     |
| train_1/n_subgoals        | 1714.0                |
| train_1/next_q            | -4.511980412415829    |
| train_1/q_grads           | -0.032975686341524126 |
| train_1/q_grads_std       | 0.735109205543995     |
| train_1/q_loss            | 2.81644267586711      |
| train_1/reward            | -1.3564974077933585   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001904296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2864644107351225    |
| train_1/target_q          | -5.11690360072614     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.17
Training epoch 60
Time for epoch 60: 404.59. Rollout time: 230.09, Training time: 174.48
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 60                    |
| policy/steps              | 3933335.0             |
| test/episodes             | 1525.0                |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -2.500256809475848    |
| test_1/avg_q              | -3.288413668402181    |
| test_1/n_subgoals         | 1552.0                |
| test_1/subgoal_succ_rate  | 0.6076030927835051    |
| train/episodes            | 6100.0                |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -10.545864805521232   |
| train_0/current_q         | -6.6017420198622885   |
| train_0/fw_bonus          | -0.9993259146809578   |
| train_0/fw_loss           | 0.0001854015947174048 |
| train_0/mu_grads          | -0.15379077494144439  |
| train_0/mu_grads_std      | 0.6645875096321106    |
| train_0/mu_loss           | 6.39845266586281      |
| train_0/next_q            | -6.215318599878169    |
| train_0/q_grads           | 0.053864848148077724  |
| train_0/q_grads_std       | 0.48917254954576495   |
| train_0/q_loss            | 0.570585664722245     |
| train_0/reward            | -0.9195688962558052   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0409423828125       |
| train_0/target_q          | -6.534189008035821    |
| train_1/avg_q             | -3.8546318055109103   |
| train_1/current_q         | -8.037148733290158    |
| train_1/fw_bonus          | -1.0001788884401321   |
| train_1/fw_loss           | 0.000826276559382677  |
| train_1/mu_grads          | -0.04023515526205301  |
| train_1/mu_grads_std      | 0.5892287969589234    |
| train_1/mu_loss           | 8.06373839325262      |
| train_1/n_subgoals        | 2094.0                |
| train_1/next_q            | -8.034053577163172    |
| train_1/q_grads           | -0.0329240545630455   |
| train_1/q_grads_std       | 0.7377530202269554    |
| train_1/q_loss            | 3.199063512997361     |
| train_1/reward            | -1.3364073666147305   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.00205078125         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.27889207258834764   |
| train_1/target_q          | -8.109373534555434    |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.13999999999999999
Training epoch 61
Time for epoch 61: 381.23. Rollout time: 216.83, Training time: 164.37
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 61                     |
| policy/steps              | 3996878.0              |
| test/episodes             | 1550.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -2.51838494596724      |
| test_1/avg_q              | -1.7093559697229377    |
| test_1/n_subgoals         | 6972.0                 |
| test_1/subgoal_succ_rate  | 0.9443488238668961     |
| train/episodes            | 6200.0                 |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -10.53058550391071     |
| train_0/current_q         | -6.430581875655628     |
| train_0/fw_bonus          | -0.9993688598275184    |
| train_0/fw_loss           | 0.00017397152878402268 |
| train_0/mu_grads          | -0.15561369843780995   |
| train_0/mu_grads_std      | 0.669664753973484      |
| train_0/mu_loss           | 6.226140459277849      |
| train_0/next_q            | -6.036401919867391     |
| train_0/q_grads           | 0.0538136581890285     |
| train_0/q_grads_std       | 0.48984154462814333    |
| train_0/q_loss            | 0.5166590516196198     |
| train_0/reward            | -0.9203213311557192    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0587646484375        |
| train_0/target_q          | -6.381766942445688     |
| train_1/avg_q             | -3.9741976654826234    |
| train_1/current_q         | -7.802983222282558     |
| train_1/fw_bonus          | -1.000199368596077     |
| train_1/fw_loss           | 0.0008210081839933991  |
| train_1/mu_grads          | -0.040733414329588415  |
| train_1/mu_grads_std      | 0.5912052825093269     |
| train_1/mu_loss           | 7.706008884765675      |
| train_1/n_subgoals        | 2119.0                 |
| train_1/next_q            | -7.692748804114956     |
| train_1/q_grads           | -0.03314323350787163   |
| train_1/q_grads_std       | 0.7427486762404442     |
| train_1/q_loss            | 2.4416712917888774     |
| train_1/reward            | -1.342044067682582     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2864558754129306     |
| train_1/target_q          | -7.871134039316563     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16
Training epoch 62
Time for epoch 62: 363.42. Rollout time: 196.83, Training time: 166.56
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 62                     |
| policy/steps              | 4057493.0              |
| test/episodes             | 1575.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.4786708450010133    |
| test_1/avg_q              | -3.154048472247623     |
| test_1/n_subgoals         | 7476.0                 |
| test_1/subgoal_succ_rate  | 0.9460941680042804     |
| train/episodes            | 6300.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -10.070395035363369    |
| train_0/current_q         | -6.179264112559433     |
| train_0/fw_bonus          | -0.9993894562125206    |
| train_0/fw_loss           | 0.00016849379699124256 |
| train_0/mu_grads          | -0.1568844188004732    |
| train_0/mu_grads_std      | 0.6742498680949212     |
| train_0/mu_loss           | 5.949377151746523      |
| train_0/next_q            | -5.778838289627558     |
| train_0/q_grads           | 0.053716757055372      |
| train_0/q_grads_std       | 0.4900713451206684     |
| train_0/q_loss            | 0.5556224682794385     |
| train_0/reward            | -0.919988871802343     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.06416015625          |
| train_0/target_q          | -6.1313684723976545    |
| train_1/avg_q             | -3.8128706771316363    |
| train_1/current_q         | -8.140998442159269     |
| train_1/fw_bonus          | -1.0002125948667526    |
| train_1/fw_loss           | 0.0008176061674021184  |
| train_1/mu_grads          | -0.0419669333845377    |
| train_1/mu_grads_std      | 0.5943232238292694     |
| train_1/mu_loss           | 8.09111946290118       |
| train_1/n_subgoals        | 2048.0                 |
| train_1/next_q            | -8.08917582100816      |
| train_1/q_grads           | -0.033567138109356166  |
| train_1/q_grads_std       | 0.744124422967434      |
| train_1/q_loss            | 2.5340438322901333     |
| train_1/reward            | -1.3428840663575101    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001904296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3271484375           |
| train_1/target_q          | -8.247700395982264     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 63
Time for epoch 63: 365.30. Rollout time: 201.82, Training time: 163.45
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 4118956.0              |
| test/episodes             | 1600.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -2.8179806516052155    |
| test_1/avg_q              | -3.632533787742989     |
| test_1/n_subgoals         | 9788.0                 |
| test_1/subgoal_succ_rate  | 0.9711892112791173     |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -10.652201735571492    |
| train_0/current_q         | -6.246043946318023     |
| train_0/fw_bonus          | -0.9993770569562912    |
| train_0/fw_loss           | 0.00017179375099658501 |
| train_0/mu_grads          | -0.1575002271682024    |
| train_0/mu_grads_std      | 0.6790392443537712     |
| train_0/mu_loss           | 6.061625527658087      |
| train_0/next_q            | -5.854288073483569     |
| train_0/q_grads           | 0.053554251603782174   |
| train_0/q_grads_std       | 0.49062084779143333    |
| train_0/q_loss            | 0.6752332095329814     |
| train_0/reward            | -0.9220913859462598    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05419921875          |
| train_0/target_q          | -6.229605059508062     |
| train_1/avg_q             | -4.047563906827697     |
| train_1/current_q         | -8.370223230945578     |
| train_1/fw_bonus          | -1.00011016279459      |
| train_1/fw_loss           | 0.0008439564902801066  |
| train_1/mu_grads          | -0.04319061497226358   |
| train_1/mu_grads_std      | 0.5973476439714431     |
| train_1/mu_loss           | 8.357777879484704      |
| train_1/n_subgoals        | 2130.0                 |
| train_1/next_q            | -8.349408243883756     |
| train_1/q_grads           | -0.03320210641250014   |
| train_1/q_grads_std       | 0.7456999003887177     |
| train_1/q_loss            | 2.235424063597205      |
| train_1/reward            | -1.331363136258733     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0016845703125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.33380281690140845    |
| train_1/target_q          | -8.46694408027004      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09000000000000001
Training epoch 64
Time for epoch 64: 374.41. Rollout time: 214.26, Training time: 160.12
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 4183253.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.0778425907470617    |
| test_1/avg_q              | -3.5807539016756684    |
| test_1/n_subgoals         | 8874.0                 |
| test_1/subgoal_succ_rate  | 0.9617985125084516     |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.37                   |
| train_0/avg_q             | -10.125437198725132    |
| train_0/current_q         | -5.844273758371484     |
| train_0/fw_bonus          | -0.9994547292590141    |
| train_0/fw_loss           | 0.00015112503788259347 |
| train_0/mu_grads          | -0.1564500540494919    |
| train_0/mu_grads_std      | 0.6809660479426384     |
| train_0/mu_loss           | 5.5866655270119185     |
| train_0/next_q            | -5.405552315903379     |
| train_0/q_grads           | 0.052985170669853685   |
| train_0/q_grads_std       | 0.4924441009759903     |
| train_0/q_loss            | 0.49648805858564904    |
| train_0/reward            | -0.9209594632702647    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0604248046875        |
| train_0/target_q          | -5.876862612167646     |
| train_1/avg_q             | -4.239001699309029     |
| train_1/current_q         | -8.989516098584918     |
| train_1/fw_bonus          | -1.0001430273056031    |
| train_1/fw_loss           | 0.0008355045778444037  |
| train_1/mu_grads          | -0.043871686421334745  |
| train_1/mu_grads_std      | 0.5998885795474053     |
| train_1/mu_loss           | 9.067584016546018      |
| train_1/n_subgoals        | 2221.0                 |
| train_1/next_q            | -9.046803182834015     |
| train_1/q_grads           | -0.03437213441357016   |
| train_1/q_grads_std       | 0.7509848192334175     |
| train_1/q_loss            | 2.512043947807391      |
| train_1/reward            | -1.3474217170180054    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0019287109375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.32958126969833407    |
| train_1/target_q          | -9.100525380029381     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09000000000000001
Training epoch 65
Time for epoch 65: 371.13. Rollout time: 212.78, Training time: 158.32
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 4246731.0             |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.16                  |
| test_0/avg_q              | -2.0521465308163434   |
| test_1/avg_q              | -3.730390473033755    |
| test_1/n_subgoals         | 4848.0                |
| test_1/subgoal_succ_rate  | 0.8995462046204621    |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.44                  |
| train_0/avg_q             | -11.238631210895877   |
| train_0/current_q         | -6.690124344578021    |
| train_0/fw_bonus          | -0.9994998335838318   |
| train_0/fw_loss           | 0.0001391284045894281 |
| train_0/mu_grads          | -0.15725774206221105  |
| train_0/mu_grads_std      | 0.6818586751818657    |
| train_0/mu_loss           | 6.448126017103583     |
| train_0/next_q            | -6.238270503406274    |
| train_0/q_grads           | 0.05288284756243229   |
| train_0/q_grads_std       | 0.494937364757061     |
| train_0/q_loss            | 0.44040508101787273   |
| train_0/reward            | -0.9225924012280302   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1155029296875       |
| train_0/target_q          | -6.674934634049109    |
| train_1/avg_q             | -4.843352241216155    |
| train_1/current_q         | -9.276957150679909    |
| train_1/fw_bonus          | -1.0003398060798645   |
| train_1/fw_loss           | 0.0007848893495975062 |
| train_1/mu_grads          | -0.04384043011814356  |
| train_1/mu_grads_std      | 0.6004229485988617    |
| train_1/mu_loss           | 9.310596757789828     |
| train_1/n_subgoals        | 2131.0                |
| train_1/next_q            | -9.302618769847603    |
| train_1/q_grads           | -0.03361406298354268  |
| train_1/q_grads_std       | 0.7557577684521675    |
| train_1/q_loss            | 2.3507742372981117    |
| train_1/reward            | -1.3406113056567848   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0020751953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2900046926325669    |
| train_1/target_q          | -9.375418933081635    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 66
Time for epoch 66: 361.03. Rollout time: 201.10, Training time: 159.90
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 4308897.0              |
| test/episodes             | 1675.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.8278479702999013    |
| test_1/avg_q              | -3.4910010930084616    |
| test_1/n_subgoals         | 1677.0                 |
| test_1/subgoal_succ_rate  | 0.6290995825879547     |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -12.150485676951718    |
| train_0/current_q         | -6.629054861695209     |
| train_0/fw_bonus          | -0.9995158314704895    |
| train_0/fw_loss           | 0.00013486914576787967 |
| train_0/mu_grads          | -0.15738877430558204   |
| train_0/mu_grads_std      | 0.683716955780983      |
| train_0/mu_loss           | 6.40067271585391       |
| train_0/next_q            | -6.187890851436949     |
| train_0/q_grads           | 0.0521936378441751     |
| train_0/q_grads_std       | 0.49579438343644144    |
| train_0/q_loss            | 0.41959305341671327    |
| train_0/reward            | -0.9213898080197396    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11728515625          |
| train_0/target_q          | -6.606095806862146     |
| train_1/avg_q             | -4.590559887397437     |
| train_1/current_q         | -9.529656875380478     |
| train_1/fw_bonus          | -1.0004217505455018    |
| train_1/fw_loss           | 0.0007638152936124242  |
| train_1/mu_grads          | -0.0442581681534648    |
| train_1/mu_grads_std      | 0.5993442147970199     |
| train_1/mu_loss           | 9.559351142783118      |
| train_1/n_subgoals        | 2117.0                 |
| train_1/next_q            | -9.595134829205085     |
| train_1/q_grads           | -0.03373610274866223   |
| train_1/q_grads_std       | 0.7592845320701599     |
| train_1/q_loss            | 2.700918074331587      |
| train_1/reward            | -1.3451283243106444    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017578125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.32026452527161076    |
| train_1/target_q          | -9.64013804217997      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 67
Time for epoch 67: 381.65. Rollout time: 218.79, Training time: 162.83
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 4374545.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -2.5130276706204193    |
| test_1/avg_q              | -2.987015896855047     |
| test_1/n_subgoals         | 1524.0                 |
| test_1/subgoal_succ_rate  | 0.6062992125984252     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.44                   |
| train_0/avg_q             | -12.097233127869869    |
| train_0/current_q         | -6.751083755053793     |
| train_0/fw_bonus          | -0.9994984328746795    |
| train_0/fw_loss           | 0.00013949830608908086 |
| train_0/mu_grads          | -0.15828677862882615   |
| train_0/mu_grads_std      | 0.6851306468248367     |
| train_0/mu_loss           | 6.499116164203111      |
| train_0/next_q            | -6.2854101822692785    |
| train_0/q_grads           | 0.05205325623974204    |
| train_0/q_grads_std       | 0.49631799533963206    |
| train_0/q_loss            | 0.42961975101079497    |
| train_0/reward            | -0.9229941905185115    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0630859375           |
| train_0/target_q          | -6.708601989342165     |
| train_1/avg_q             | -4.366417988359453     |
| train_1/current_q         | -9.91943039275173      |
| train_1/fw_bonus          | -1.000297050178051     |
| train_1/fw_loss           | 0.0007958938876981847  |
| train_1/mu_grads          | -0.04456305997446179   |
| train_1/mu_grads_std      | 0.5999613612890243     |
| train_1/mu_loss           | 9.959866739539759      |
| train_1/n_subgoals        | 2164.0                 |
| train_1/next_q            | -9.9552184904035       |
| train_1/q_grads           | -0.03347612461075187   |
| train_1/q_grads_std       | 0.7641214817762375     |
| train_1/q_loss            | 2.7934513296386845     |
| train_1/reward            | -1.3475433273109956    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27171903881700554    |
| train_1/target_q          | -10.045351505487284    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.10999999999999999
Training epoch 68
Time for epoch 68: 391.23. Rollout time: 226.40, Training time: 164.80
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 4441532.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.2888615586950496    |
| test_1/avg_q              | -2.708156788084345     |
| test_1/n_subgoals         | 2234.0                 |
| test_1/subgoal_succ_rate  | 0.7273948075201433     |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -10.795374553747143    |
| train_0/current_q         | -7.0284109702211826    |
| train_0/fw_bonus          | -0.9995436266064643    |
| train_0/fw_loss           | 0.00012747526179737178 |
| train_0/mu_grads          | -0.15989315286278724   |
| train_0/mu_grads_std      | 0.6879409417510033     |
| train_0/mu_loss           | 6.847926214492207      |
| train_0/next_q            | -6.65909441172018      |
| train_0/q_grads           | 0.05193076189607382    |
| train_0/q_grads_std       | 0.49478180557489393    |
| train_0/q_loss            | 0.5721566107215551     |
| train_0/reward            | -0.9238947813064442    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0882568359375        |
| train_0/target_q          | -7.00798537533461      |
| train_1/avg_q             | -4.0984751589379655    |
| train_1/current_q         | -9.692283422030144     |
| train_1/fw_bonus          | -1.0001790776848793    |
| train_1/fw_loss           | 0.0008262279152404517  |
| train_1/mu_grads          | -0.045330644119530916  |
| train_1/mu_grads_std      | 0.6024343326687813     |
| train_1/mu_loss           | 9.738553446786403      |
| train_1/n_subgoals        | 2187.0                 |
| train_1/next_q            | -9.72322738015247      |
| train_1/q_grads           | -0.034339357540011405  |
| train_1/q_grads_std       | 0.7679220706224441     |
| train_1/q_loss            | 2.2606183800023443     |
| train_1/reward            | -1.3494141004543052    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022216796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.26108824874256975    |
| train_1/target_q          | -9.821540851037614     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09
Training epoch 69
Time for epoch 69: 356.61. Rollout time: 190.53, Training time: 166.04
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 4498980.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.12                   |
| test_0/avg_q              | -1.0332201644738632    |
| test_1/avg_q              | -4.06490318631419      |
| test_1/n_subgoals         | 7628.0                 |
| test_1/subgoal_succ_rate  | 0.9504457262716308     |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -12.791227222574824    |
| train_0/current_q         | -6.420331607742787     |
| train_0/fw_bonus          | -0.9994978457689285    |
| train_0/fw_loss           | 0.00013965342714072904 |
| train_0/mu_grads          | -0.1634705662727356    |
| train_0/mu_grads_std      | 0.6910594820976257     |
| train_0/mu_loss           | 6.1471529878189015     |
| train_0/next_q            | -6.055805600386913     |
| train_0/q_grads           | 0.05002921912819147    |
| train_0/q_grads_std       | 0.49298683628439904    |
| train_0/q_loss            | 0.5852719557352036     |
| train_0/reward            | -0.9232073763691006    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.083935546875         |
| train_0/target_q          | -6.484848319103333     |
| train_1/avg_q             | -4.491668560719506     |
| train_1/current_q         | -9.568260277910081     |
| train_1/fw_bonus          | -1.0002973183989525    |
| train_1/fw_loss           | 0.0007958192858495749  |
| train_1/mu_grads          | -0.04608731614425778   |
| train_1/mu_grads_std      | 0.6080997049808502     |
| train_1/mu_loss           | 9.603598839850454      |
| train_1/n_subgoals        | 1860.0                 |
| train_1/next_q            | -9.582419147940065     |
| train_1/q_grads           | -0.03508998118340969   |
| train_1/q_grads_std       | 0.7723237425088882     |
| train_1/q_loss            | 2.646448391060473      |
| train_1/reward            | -1.3644808001976343    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017333984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2779569892473118     |
| train_1/target_q          | -9.665302911371452     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 70
Time for epoch 70: 320.30. Rollout time: 157.77, Training time: 162.50
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 4549819.0              |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.8854888189281944    |
| test_1/avg_q              | -2.07908560476859      |
| test_1/n_subgoals         | 776.0                  |
| test_1/subgoal_succ_rate  | 0.1791237113402062     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.7                    |
| train_0/avg_q             | -11.459124453581804    |
| train_0/current_q         | -5.639747700044883     |
| train_0/fw_bonus          | -0.9994798138737678    |
| train_0/fw_loss           | 0.00014445540218730458 |
| train_0/mu_grads          | -0.16457377783954144   |
| train_0/mu_grads_std      | 0.6922288715839386     |
| train_0/mu_loss           | 5.32572004647779       |
| train_0/next_q            | -5.16793839867892      |
| train_0/q_grads           | 0.04945290870964527    |
| train_0/q_grads_std       | 0.4923304721713066     |
| train_0/q_loss            | 0.4252740369416424     |
| train_0/reward            | -0.9234074631560361    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0955322265625        |
| train_0/target_q          | -5.594418287574561     |
| train_1/avg_q             | -4.203994609199166     |
| train_1/current_q         | -8.938836976755706     |
| train_1/fw_bonus          | -1.0000315576791763    |
| train_1/fw_loss           | 0.0008641721942694858  |
| train_1/mu_grads          | -0.04609819119796157   |
| train_1/mu_grads_std      | 0.6101324364542962     |
| train_1/mu_loss           | 8.83410933226217       |
| train_1/n_subgoals        | 1645.0                 |
| train_1/next_q            | -8.850779568841958     |
| train_1/q_grads           | -0.03501921035349369   |
| train_1/q_grads_std       | 0.7810652926564217     |
| train_1/q_loss            | 2.640392855769161      |
| train_1/reward            | -1.3534965692604601    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015869140625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3161094224924012     |
| train_1/target_q          | -9.047055574854243     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.12000000000000001
Training epoch 71
Time for epoch 71: 426.29. Rollout time: 263.96, Training time: 162.30
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 4626006.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0099545547220494    |
| test_1/avg_q              | -1.7554761151349645    |
| test_1/n_subgoals         | 684.0                  |
| test_1/subgoal_succ_rate  | 0.013157894736842105   |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.25                   |
| train_0/avg_q             | -7.606066634187278     |
| train_0/current_q         | -4.600083572743078     |
| train_0/fw_bonus          | -0.9994458079338073    |
| train_0/fw_loss           | 0.00015350091671280098 |
| train_0/mu_grads          | -0.16152556985616684   |
| train_0/mu_grads_std      | 0.6935976833105088     |
| train_0/mu_loss           | 4.280540990177405      |
| train_0/next_q            | -4.179524562021161     |
| train_0/q_grads           | 0.048886630591005086   |
| train_0/q_grads_std       | 0.4928597159683704     |
| train_0/q_loss            | 0.5167205795659104     |
| train_0/reward            | -0.9205255197332007    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11220703125          |
| train_0/target_q          | -4.580134946023601     |
| train_1/avg_q             | -3.9094666068063146    |
| train_1/current_q         | -9.298427386437572     |
| train_1/fw_bonus          | -0.9987123399972916    |
| train_1/fw_loss           | 0.0012034764004056342  |
| train_1/mu_grads          | -0.04557319609448314   |
| train_1/mu_grads_std      | 0.6146207958459854     |
| train_1/mu_loss           | 9.413294525915802      |
| train_1/n_subgoals        | 2356.0                 |
| train_1/next_q            | -9.39800172802351      |
| train_1/q_grads           | -0.035574198514223096  |
| train_1/q_grads_std       | 0.7875698581337929     |
| train_1/q_loss            | 3.347564133921439      |
| train_1/reward            | -1.3816331258392893    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0022216796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.13539898132427844    |
| train_1/target_q          | -9.44602922479439      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 72
Time for epoch 72: 439.34. Rollout time: 278.90, Training time: 160.41
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 72                     |
| policy/steps              | 4701949.0              |
| test/episodes             | 1825.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8649867593106153    |
| test_1/avg_q              | -1.6903892895603971    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7300.0                 |
| train/success_rate        | 0.24                   |
| train_0/avg_q             | -5.823871121840031     |
| train_0/current_q         | -4.4592377462634225    |
| train_0/fw_bonus          | -0.9994591996073723    |
| train_0/fw_loss           | 0.00014993842523836065 |
| train_0/mu_grads          | -0.1613584466278553    |
| train_0/mu_grads_std      | 0.6937006831169128     |
| train_0/mu_loss           | 4.170921724040141      |
| train_0/next_q            | -4.043221854449971     |
| train_0/q_grads           | 0.04901145854964852    |
| train_0/q_grads_std       | 0.4947544477880001     |
| train_0/q_loss            | 0.48805174663845907    |
| train_0/reward            | -0.9164462065018597    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.100537109375         |
| train_0/target_q          | -4.403267345522176     |
| train_1/avg_q             | -3.9633209515827996    |
| train_1/current_q         | -9.306073381225405     |
| train_1/fw_bonus          | -0.9991732686758041    |
| train_1/fw_loss           | 0.001084927367628552   |
| train_1/mu_grads          | -0.04586335401982069   |
| train_1/mu_grads_std      | 0.6191289439797402     |
| train_1/mu_loss           | 9.372137430662082      |
| train_1/n_subgoals        | 2340.0                 |
| train_1/next_q            | -9.37776100584366      |
| train_1/q_grads           | -0.03545302590355277   |
| train_1/q_grads_std       | 0.7895681083202362     |
| train_1/q_loss            | 2.9198421749168424     |
| train_1/reward            | -1.415578671284311     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.002197265625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.12863247863247862    |
| train_1/target_q          | -9.40204433677541      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 73
Time for epoch 73: 369.95. Rollout time: 210.21, Training time: 159.71
Evaluating epoch 73
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 73                     |
| policy/steps              | 4764435.0              |
| test/episodes             | 1850.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2034139026772885    |
| test_1/avg_q              | -1.995231992108542     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7400.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -5.582339152379718     |
| train_0/current_q         | -5.20035668273792      |
| train_0/fw_bonus          | -0.9993042513728142    |
| train_0/fw_loss           | 0.00019116382973152212 |
| train_0/mu_grads          | -0.15920591689646243   |
| train_0/mu_grads_std      | 0.6961727917194367     |
| train_0/mu_loss           | 4.963127322913434      |
| train_0/next_q            | -4.8101917342455405    |
| train_0/q_grads           | 0.04909869991242886    |
| train_0/q_grads_std       | 0.49452456310391424    |
| train_0/q_loss            | 0.5379177899175425     |
| train_0/reward            | -0.9174835614729091    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0254150390625        |
| train_0/target_q          | -5.156617844073807     |
| train_1/avg_q             | -4.098579450645543     |
| train_1/current_q         | -9.228250426404134     |
| train_1/fw_bonus          | -0.9910759389400482    |
| train_1/fw_loss           | 0.0031675498583354058  |
| train_1/mu_grads          | -0.04732463834807277   |
| train_1/mu_grads_std      | 0.6242738783359527     |
| train_1/mu_loss           | 9.43360980846388       |
| train_1/n_subgoals        | 1897.0                 |
| train_1/next_q            | -9.431701568697601     |
| train_1/q_grads           | -0.035443443432450296  |
| train_1/q_grads_std       | 0.7938466727733612     |
| train_1/q_loss            | 3.0073728073084167     |
| train_1/reward            | -1.4330469531327252    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00185546875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19557195571955718    |
| train_1/target_q          | -9.355404881109587     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 74
Time for epoch 74: 361.43. Rollout time: 201.60, Training time: 159.81
Evaluating epoch 74
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 74                     |
| policy/steps              | 4825138.0              |
| test/episodes             | 1875.0                 |
| test/success_rate         | 0.16                   |
| test_0/avg_q              | -1.832790618014068     |
| test_1/avg_q              | -3.2667260488888274    |
| test_1/n_subgoals         | 1152.0                 |
| test_1/subgoal_succ_rate  | 0.4600694444444444     |
| train/episodes            | 7500.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -7.745905103781966     |
| train_0/current_q         | -5.6775289037896615    |
| train_0/fw_bonus          | -0.9994286924600602    |
| train_0/fw_loss           | 0.00015805445273144869 |
| train_0/mu_grads          | -0.15998170375823975   |
| train_0/mu_grads_std      | 0.6962833046913147     |
| train_0/mu_loss           | 5.490275344423906      |
| train_0/next_q            | -5.302615067876746     |
| train_0/q_grads           | 0.0494107186794281     |
| train_0/q_grads_std       | 0.4945185586810112     |
| train_0/q_loss            | 0.47036101457320073    |
| train_0/reward            | -0.915080554940505     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0750244140625        |
| train_0/target_q          | -5.641455667659516     |
| train_1/avg_q             | -4.26270236291516      |
| train_1/current_q         | -9.195429188859912     |
| train_1/fw_bonus          | -0.9993080630898475    |
| train_1/fw_loss           | 0.0010502548480872064  |
| train_1/mu_grads          | -0.047917826753109696  |
| train_1/mu_grads_std      | 0.6338336750864982     |
| train_1/mu_loss           | 9.368432245901378      |
| train_1/n_subgoals        | 1909.0                 |
| train_1/next_q            | -9.388357783436419     |
| train_1/q_grads           | -0.0361233982257545    |
| train_1/q_grads_std       | 0.797096848487854      |
| train_1/q_loss            | 3.4579646413290335     |
| train_1/reward            | -1.442114104088978     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001953125            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.23363017286537455    |
| train_1/target_q          | -9.320505547020563     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 75
Time for epoch 75: 380.45. Rollout time: 215.75, Training time: 164.67
Evaluating epoch 75
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 75                     |
| policy/steps              | 4890087.0              |
| test/episodes             | 1900.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.7058213075016373    |
| test_1/avg_q              | -3.032735270340681     |
| test_1/n_subgoals         | 1363.0                 |
| test_1/subgoal_succ_rate  | 0.5297138664710198     |
| train/episodes            | 7600.0                 |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -8.00993836228046      |
| train_0/current_q         | -5.454255216762461     |
| train_0/fw_bonus          | -0.9993798270821571    |
| train_0/fw_loss           | 0.00017105482420447514 |
| train_0/mu_grads          | -0.1603830263018608    |
| train_0/mu_grads_std      | 0.6962577402591705     |
| train_0/mu_loss           | 5.197838542419725      |
| train_0/next_q            | -5.042056313140109     |
| train_0/q_grads           | 0.04902511006221175    |
| train_0/q_grads_std       | 0.4944856531918049     |
| train_0/q_loss            | 0.4680793236826298     |
| train_0/reward            | -0.916252404601255     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0760009765625        |
| train_0/target_q          | -5.39849031606189      |
| train_1/avg_q             | -4.322579282962643     |
| train_1/current_q         | -9.251217460561        |
| train_1/fw_bonus          | -0.9993567794561387    |
| train_1/fw_loss           | 0.0010377256796346046  |
| train_1/mu_grads          | -0.04922539424151182   |
| train_1/mu_grads_std      | 0.6421685770154        |
| train_1/mu_loss           | 9.50649825531516       |
| train_1/n_subgoals        | 2104.0                 |
| train_1/next_q            | -9.50614788820759      |
| train_1/q_grads           | -0.03714061751961708   |
| train_1/q_grads_std       | 0.7982801422476768     |
| train_1/q_loss            | 2.959191272928682      |
| train_1/reward            | -1.4222348677860281    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001708984375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.26948669201520914    |
| train_1/target_q          | -9.3526926256386       |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 76
Time for epoch 76: 392.36. Rollout time: 225.37, Training time: 166.96
Evaluating epoch 76
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 76                     |
| policy/steps              | 4957437.0              |
| test/episodes             | 1925.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.565875378623968     |
| test_1/avg_q              | -3.7820703836498106    |
| test_1/n_subgoals         | 2829.0                 |
| test_1/subgoal_succ_rate  | 0.7907387769529869     |
| train/episodes            | 7700.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -8.766271207126925     |
| train_0/current_q         | -5.735611964107997     |
| train_0/fw_bonus          | -0.9994297102093697    |
| train_0/fw_loss           | 0.00015778100914758396 |
| train_0/mu_grads          | -0.15949646458029748   |
| train_0/mu_grads_std      | 0.696968124806881      |
| train_0/mu_loss           | 5.507174027704872      |
| train_0/next_q            | -5.346446411172647     |
| train_0/q_grads           | 0.049300273228436706   |
| train_0/q_grads_std       | 0.49469395354390144    |
| train_0/q_loss            | 0.47652106688208884    |
| train_0/reward            | -0.915801540396933     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0859619140625        |
| train_0/target_q          | -5.687904073042124     |
| train_1/avg_q             | -4.558028354771691     |
| train_1/current_q         | -9.695086967753086     |
| train_1/fw_bonus          | -0.999611821770668     |
| train_1/fw_loss           | 0.0009721286129206419  |
| train_1/mu_grads          | -0.04956852663308382   |
| train_1/mu_grads_std      | 0.6504474148154259     |
| train_1/mu_loss           | 9.994689460028935      |
| train_1/n_subgoals        | 2190.0                 |
| train_1/next_q            | -10.001278613360004    |
| train_1/q_grads           | -0.038102749921381476  |
| train_1/q_grads_std       | 0.7994439676403999     |
| train_1/q_loss            | 2.9653856159410297     |
| train_1/reward            | -1.4257098411573679    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0018310546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.27077625570776254    |
| train_1/target_q          | -9.824964072276213     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06
Training epoch 77
Time for epoch 77: 384.84. Rollout time: 221.09, Training time: 163.72
Evaluating epoch 77
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 77                    |
| policy/steps              | 5023649.0             |
| test/episodes             | 1950.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -2.190128663829283    |
| test_1/avg_q              | -2.238643355455248    |
| test_1/n_subgoals         | 2060.0                |
| test_1/subgoal_succ_rate  | 0.7053398058252427    |
| train/episodes            | 7800.0                |
| train/success_rate        | 0.39                  |
| train_0/avg_q             | -9.180652559978595    |
| train_0/current_q         | -5.818322733088922    |
| train_0/fw_bonus          | -0.9994731068611145   |
| train_0/fw_loss           | 0.0001462384467231459 |
| train_0/mu_grads          | -0.15989419333636762  |
| train_0/mu_grads_std      | 0.6986824154853821    |
| train_0/mu_loss           | 5.594116393117978     |
| train_0/next_q            | -5.420970669066523    |
| train_0/q_grads           | 0.04930208837613463   |
| train_0/q_grads_std       | 0.49600384160876276   |
| train_0/q_loss            | 0.5138398189235724    |
| train_0/reward            | -0.9167007766256574   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0922607421875       |
| train_0/target_q          | -5.73809230427882     |
| train_1/avg_q             | -4.434618675255012    |
| train_1/current_q         | -7.116643264026472    |
| train_1/fw_bonus          | -0.999684052169323    |
| train_1/fw_loss           | 0.0009535510951536707 |
| train_1/mu_grads          | -0.04747682847082615  |
| train_1/mu_grads_std      | 0.6542896658182145    |
| train_1/mu_loss           | 6.775069665756744     |
| train_1/n_subgoals        | 2236.0                |
| train_1/next_q            | -6.766113025573645    |
| train_1/q_grads           | -0.040748316515237096 |
| train_1/q_grads_std       | 0.8023127436637878    |
| train_1/q_loss            | 2.935907364704139     |
| train_1/reward            | -1.421412207999674    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0017333984375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.30366726296958857   |
| train_1/target_q          | -7.144730102130438    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06999999999999999
Training epoch 78
Time for epoch 78: 382.36. Rollout time: 219.50, Training time: 162.83
Evaluating epoch 78
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 78                     |
| policy/steps              | 5088748.0              |
| test/episodes             | 1975.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.884250443109172     |
| test_1/avg_q              | -4.212952482643353     |
| test_1/n_subgoals         | 3449.0                 |
| test_1/subgoal_succ_rate  | 0.8414033053058858     |
| train/episodes            | 7900.0                 |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -9.060452180680075     |
| train_0/current_q         | -5.5303081832967935    |
| train_0/fw_bonus          | -0.9994472622871399    |
| train_0/fw_loss           | 0.00015311489460145822 |
| train_0/mu_grads          | -0.1602158986032009    |
| train_0/mu_grads_std      | 0.7015272960066795     |
| train_0/mu_loss           | 5.272713068859937      |
| train_0/next_q            | -5.11424829809156      |
| train_0/q_grads           | 0.04896393176168203    |
| train_0/q_grads_std       | 0.496349198371172      |
| train_0/q_loss            | 0.4891510185717422     |
| train_0/reward            | -0.9175847131278715    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.103759765625         |
| train_0/target_q          | -5.463643325084112     |
| train_1/avg_q             | -3.906975719677555     |
| train_1/current_q         | -8.902982263979565     |
| train_1/fw_bonus          | -0.9998644411563873    |
| train_1/fw_loss           | 0.0009071557622519321  |
| train_1/mu_grads          | -0.04731337819248438   |
| train_1/mu_grads_std      | 0.6604244589805603     |
| train_1/mu_loss           | 8.798462300200455      |
| train_1/n_subgoals        | 2138.0                 |
| train_1/next_q            | -8.81905965109462      |
| train_1/q_grads           | -0.04061677400022745   |
| train_1/q_grads_std       | 0.8061564460396766     |
| train_1/q_loss            | 2.813178844768686      |
| train_1/reward            | -1.4105916875210824    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0016357421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.26800748362956034    |
| train_1/target_q          | -8.992965055730025     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 79
Time for epoch 79: 378.77. Rollout time: 216.24, Training time: 162.50
Evaluating epoch 79
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 5153475.0              |
| test/episodes             | 2000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6447210017782923    |
| test_1/avg_q              | -0.8902153104277689    |
| test_1/n_subgoals         | 5122.0                 |
| test_1/subgoal_succ_rate  | 0.9045294806716127     |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.42                   |
| train_0/avg_q             | -8.594913768759342     |
| train_0/current_q         | -5.45590875837107      |
| train_0/fw_bonus          | -0.9995119646191597    |
| train_0/fw_loss           | 0.00013590132712124615 |
| train_0/mu_grads          | -0.16000537984073163   |
| train_0/mu_grads_std      | 0.7032444685697555     |
| train_0/mu_loss           | 5.22125777435777       |
| train_0/next_q            | -5.053508524271704     |
| train_0/q_grads           | 0.04913292909041047    |
| train_0/q_grads_std       | 0.4961546830832958     |
| train_0/q_loss            | 0.5966908941500154     |
| train_0/reward            | -0.920117367063358     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11591796875          |
| train_0/target_q          | -5.36242884343573      |
| train_1/avg_q             | -4.596335598283218     |
| train_1/current_q         | -6.097741857607845     |
| train_1/fw_bonus          | -1.0000180691480636    |
| train_1/fw_loss           | 0.0008676399869727902  |
| train_1/mu_grads          | -0.05016115056350827   |
| train_1/mu_grads_std      | 0.6679912492632866     |
| train_1/mu_loss           | 5.454119361572294      |
| train_1/n_subgoals        | 2117.0                 |
| train_1/next_q            | -5.657998660530912     |
| train_1/q_grads           | -0.04146848507225513   |
| train_1/q_grads_std       | 0.8135309904813767     |
| train_1/q_loss            | 3.3063568628555613     |
| train_1/reward            | -1.3849500810320023    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0017333984375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2730278696268304     |
| train_1/target_q          | -6.262676896621014     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 80
Time for epoch 80: 389.37. Rollout time: 223.73, Training time: 165.61
Evaluating epoch 80
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 5218617.0              |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.66867455816986      |
| test_1/avg_q              | -2.4700601424462887    |
| test_1/n_subgoals         | 910.0                  |
| test_1/subgoal_succ_rate  | 0.3131868131868132     |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.44                   |
| train_0/avg_q             | -8.417962046123906     |
| train_0/current_q         | -5.677407123590032     |
| train_0/fw_bonus          | -0.9995140314102173    |
| train_0/fw_loss           | 0.00013535084053728497 |
| train_0/mu_grads          | -0.16022039391100407   |
| train_0/mu_grads_std      | 0.7040852561593056     |
| train_0/mu_loss           | 5.464190931177908      |
| train_0/next_q            | -5.2719590528447355    |
| train_0/q_grads           | 0.049210451636463405   |
| train_0/q_grads_std       | 0.49785647094249724    |
| train_0/q_loss            | 0.58160884585005       |
| train_0/reward            | -0.9200884013334871    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.116845703125         |
| train_0/target_q          | -5.587133932718868     |
| train_1/avg_q             | -3.2737416045633645    |
| train_1/current_q         | -9.436641547684294     |
| train_1/fw_bonus          | -1.0004513800144195    |
| train_1/fw_loss           | 0.0007561960839666427  |
| train_1/mu_grads          | -0.04891166258603334   |
| train_1/mu_grads_std      | 0.6713915601372719     |
| train_1/mu_loss           | 9.326190872084274      |
| train_1/n_subgoals        | 2127.0                 |
| train_1/next_q            | -9.34588863074813      |
| train_1/q_grads           | -0.04140027025714517   |
| train_1/q_grads_std       | 0.8160583049058914     |
| train_1/q_loss            | 2.7455766070529064     |
| train_1/reward            | -1.3602750531877974    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0015380859375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2538787023977433     |
| train_1/target_q          | -9.516587699667255     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 81
Time for epoch 81: 376.93. Rollout time: 213.87, Training time: 163.04
Evaluating epoch 81
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 5282419.0             |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.3084474647184339   |
| test_1/avg_q              | -3.6330734427145948   |
| test_1/n_subgoals         | 5561.0                |
| test_1/subgoal_succ_rate  | 0.9138644128753821    |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.46                  |
| train_0/avg_q             | -9.385033842658705    |
| train_0/current_q         | -5.705654002827717    |
| train_0/fw_bonus          | -0.9995103016495704   |
| train_0/fw_loss           | 0.0001363413000945002 |
| train_0/mu_grads          | -0.161233302205801    |
| train_0/mu_grads_std      | 0.7066328197717666    |
| train_0/mu_loss           | 5.468229726582612     |
| train_0/next_q            | -5.297154980812037    |
| train_0/q_grads           | 0.04909207364544273   |
| train_0/q_grads_std       | 0.5015048116445542    |
| train_0/q_loss            | 0.5785991181476366    |
| train_0/reward            | -0.9212269669413218   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1188720703125       |
| train_0/target_q          | -5.635784093352653    |
| train_1/avg_q             | -4.648592347897887    |
| train_1/current_q         | -10.154909578649262   |
| train_1/fw_bonus          | -1.0003659427165985   |
| train_1/fw_loss           | 0.0007781683205394074 |
| train_1/mu_grads          | -0.048220596835017206 |
| train_1/mu_grads_std      | 0.6762948364019394    |
| train_1/mu_loss           | 10.25841165405338     |
| train_1/n_subgoals        | 2048.0                |
| train_1/next_q            | -10.262808464798313   |
| train_1/q_grads           | -0.041466175392270085 |
| train_1/q_grads_std       | 0.8218283236026764    |
| train_1/q_loss            | 2.748453567404193     |
| train_1/reward            | -1.3799558545535546   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.002197265625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.26904296875         |
| train_1/target_q          | -10.280100085071897   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 82
Time for epoch 82: 401.89. Rollout time: 234.75, Training time: 167.11
Evaluating epoch 82
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 5347147.0             |
| test/episodes             | 2075.0                |
| test/success_rate         | 0.32                  |
| test_0/avg_q              | -1.7453530974923375   |
| test_1/avg_q              | -1.0750014053929773   |
| test_1/n_subgoals         | 879.0                 |
| test_1/subgoal_succ_rate  | 0.30489192263936293   |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.42                  |
| train_0/avg_q             | -9.63262158788133     |
| train_0/current_q         | -5.693629038567371    |
| train_0/fw_bonus          | -0.999466934800148    |
| train_0/fw_loss           | 0.0001478790411056252 |
| train_0/mu_grads          | -0.1602023396641016   |
| train_0/mu_grads_std      | 0.7086767464876175    |
| train_0/mu_loss           | 5.463100920328559     |
| train_0/next_q            | -5.300284937856236    |
| train_0/q_grads           | 0.04893730394542217   |
| train_0/q_grads_std       | 0.5050435543060303    |
| train_0/q_loss            | 0.64746362752531      |
| train_0/reward            | -0.9199554296079441   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0867919921875       |
| train_0/target_q          | -5.600680962353085    |
| train_1/avg_q             | -4.729945092539569    |
| train_1/current_q         | -7.618861305686113    |
| train_1/fw_bonus          | -1.0004717022180558   |
| train_1/fw_loss           | 0.0007509645380196162 |
| train_1/mu_grads          | -0.04949221778661013  |
| train_1/mu_grads_std      | 0.6818029701709747    |
| train_1/mu_loss           | 7.259288088877625     |
| train_1/n_subgoals        | 2198.0                |
| train_1/next_q            | -7.26884300150841     |
| train_1/q_grads           | -0.041651892475783825 |
| train_1/q_grads_std       | 0.8231198891997338    |
| train_1/q_loss            | 3.351568627259353     |
| train_1/reward            | -1.3695737556947278   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0014892578125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2684258416742493    |
| train_1/target_q          | -7.7252397870898335   |
-----------------------------------------------------
New best value for test/success_rate: 0.32. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 83
Time for epoch 83: 476.17. Rollout time: 286.85, Training time: 189.28
Evaluating epoch 83
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 5416423.0             |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.8184345292147432   |
| test_1/avg_q              | -1.6121066070863135   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.45                  |
| train_0/avg_q             | -7.775096484716002    |
| train_0/current_q         | -5.3670532308515915   |
| train_0/fw_bonus          | -0.9994779959321022   |
| train_0/fw_loss           | 0.0001449400413548574 |
| train_0/mu_grads          | -0.15978721007704735  |
| train_0/mu_grads_std      | 0.7119517922401428    |
| train_0/mu_loss           | 5.154643734048366     |
| train_0/next_q            | -4.9897867745036155   |
| train_0/q_grads           | 0.04781594928354025   |
| train_0/q_grads_std       | 0.5073458045721054    |
| train_0/q_loss            | 0.6861331828748481    |
| train_0/reward            | -0.9192618100016261   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.11201171875         |
| train_0/target_q          | -5.272419350285048    |
| train_1/avg_q             | -3.0565212089797407   |
| train_1/current_q         | -8.607161932670014    |
| train_1/fw_bonus          | -1.0000447988510133   |
| train_1/fw_loss           | 0.0008607680720160715 |
| train_1/mu_grads          | -0.04834520192816853  |
| train_1/mu_grads_std      | 0.6861692696809769    |
| train_1/mu_loss           | 8.525315497182785     |
| train_1/n_subgoals        | 2188.0                |
| train_1/next_q            | -8.523093192773473    |
| train_1/q_grads           | -0.04193306416273117  |
| train_1/q_grads_std       | 0.8299793750047684    |
| train_1/q_loss            | 3.135448158746088     |
| train_1/reward            | -1.3926300312232343   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001708984375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2070383912248629    |
| train_1/target_q          | -8.69433576012021     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 84
Time for epoch 84: 469.78. Rollout time: 289.04, Training time: 180.71
Evaluating epoch 84
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|101
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 5487948.0              |
| test/episodes             | 2125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.5413344808168901    |
| test_1/avg_q              | -3.3577343567898557    |
| test_1/n_subgoals         | 683.0                  |
| test_1/subgoal_succ_rate  | 0.01171303074670571    |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.37                   |
| train_0/avg_q             | -7.296929738358917     |
| train_0/current_q         | -4.116431886008129     |
| train_0/fw_bonus          | -0.9994505181908607    |
| train_0/fw_loss           | 0.00015225079405354336 |
| train_0/mu_grads          | -0.1596560787409544    |
| train_0/mu_grads_std      | 0.7152792364358902     |
| train_0/mu_loss           | 3.7990182302629534     |
| train_0/next_q            | -3.703802939908079     |
| train_0/q_grads           | 0.04699405720457435    |
| train_0/q_grads_std       | 0.50855752825737       |
| train_0/q_loss            | 0.5672779835468165     |
| train_0/reward            | -0.9156523345125607    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1028076171875        |
| train_0/target_q          | -4.075811718796212     |
| train_1/avg_q             | -3.8917199383053838    |
| train_1/current_q         | -7.827479844150838     |
| train_1/fw_bonus          | -1.0000635847449302    |
| train_1/fw_loss           | 0.0008559376234188676  |
| train_1/mu_grads          | -0.0491112188436091    |
| train_1/mu_grads_std      | 0.6896325409412384     |
| train_1/mu_loss           | 7.791266630157065      |
| train_1/n_subgoals        | 2236.0                 |
| train_1/next_q            | -7.7274397865251645    |
| train_1/q_grads           | -0.04174821684136987   |
| train_1/q_grads_std       | 0.8382678672671318     |
| train_1/q_loss            | 2.931702920248919      |
| train_1/reward            | -1.3869312262060702    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00224609375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1721824686940966     |
| train_1/target_q          | -7.977355477680392     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08
Training epoch 85
