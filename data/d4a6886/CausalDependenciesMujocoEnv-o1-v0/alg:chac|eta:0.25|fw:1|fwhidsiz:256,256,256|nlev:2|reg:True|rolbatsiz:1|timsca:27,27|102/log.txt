Starting process id: 1784
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fc151581710>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 595.86. Rollout time: 338.31, Training time: 257.51
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 86737.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -6.9196896907724454    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -17.965866443159356    |
| train_0/current_q         | -7.791921915783322     |
| train_0/fw_bonus          | -0.9995769068598748    |
| train_0/fw_loss           | 0.0001135777827585116  |
| train_0/mu_grads          | -0.0005459868043544702 |
| train_0/mu_grads_std      | 0.16830178387463093    |
| train_0/mu_loss           | 7.700787769146328      |
| train_0/next_q            | -7.702478377591339     |
| train_0/q_grads           | 0.03703567925840616    |
| train_0/q_grads_std       | 0.15247569121420385    |
| train_0/q_loss            | 0.23029520820184474    |
| train_0/reward            | -0.8615723336479277    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.000341796875         |
| train_0/target_q          | -7.890486739940618     |
| train_1/avg_q             | -4.532423755820765     |
| train_1/current_q         | -1.4805349821654814    |
| train_1/fw_bonus          | -0.9978544861078262    |
| train_1/fw_loss           | 0.0014245134603697806  |
| train_1/mu_grads          | 0.014650731743313373   |
| train_1/mu_grads_std      | 0.16159833669662477    |
| train_1/mu_loss           | 1.1011663554822253     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.10031818801592692   |
| train_1/q_grads           | 0.020233194716274737   |
| train_1/q_grads_std       | 0.19062785767018794    |
| train_1/q_loss            | 0.4653364052630186     |
| train_1/reward            | -1.4290610281721456    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001171875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0662962962962963     |
| train_1/target_q          | -1.4913872391871574    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 544.38. Rollout time: 356.24, Training time: 188.11
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 177862.0               |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.55800189904212     |
| test_1/avg_q              | -7.8657417454994       |
| test_1/n_subgoals         | 676.0                  |
| test_1/subgoal_succ_rate  | 0.0014792899408284023  |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.957425168516824    |
| train_0/current_q         | -8.807718305320403     |
| train_0/fw_bonus          | -0.9996066734194755    |
| train_0/fw_loss           | 0.00010584914289211156 |
| train_0/mu_grads          | -0.010483295703306795  |
| train_0/mu_grads_std      | 0.19971442371606826    |
| train_0/mu_loss           | 8.737341594346045      |
| train_0/next_q            | -8.72658969269153      |
| train_0/q_grads           | 0.03598463367670775    |
| train_0/q_grads_std       | 0.16800639629364014    |
| train_0/q_loss            | 0.17173157597560634    |
| train_0/reward            | -0.8593180423049489    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 2.44140625e-05         |
| train_0/target_q          | -8.92380991439716      |
| train_1/avg_q             | -7.177842695833797     |
| train_1/current_q         | -1.8155412112046085    |
| train_1/fw_bonus          | -0.998708213865757     |
| train_1/fw_loss           | 0.0012128229340305553  |
| train_1/mu_grads          | -0.002685361570911482  |
| train_1/mu_grads_std      | 0.4258619487285614     |
| train_1/mu_loss           | 1.5987483524022936     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.5702059087141935    |
| train_1/q_grads           | 0.02253267588093877    |
| train_1/q_grads_std       | 0.21427298039197923    |
| train_1/q_loss            | 0.2595169728454826     |
| train_1/reward            | -1.4619889290959691    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000927734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.8194432476837439    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 545.80. Rollout time: 362.01, Training time: 183.75
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 268982.0               |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.99430343328837     |
| test_1/avg_q              | -7.696918729934141     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.805050610752797    |
| train_0/current_q         | -8.983905785390851     |
| train_0/fw_bonus          | -0.9996982008218765    |
| train_0/fw_loss           | 8.207662804124994e-05  |
| train_0/mu_grads          | -0.015162222855724394  |
| train_0/mu_grads_std      | 0.22571546472609044    |
| train_0/mu_loss           | 8.931760606872706      |
| train_0/next_q            | -8.921669531108638     |
| train_0/q_grads           | 0.03367765741422772    |
| train_0/q_grads_std       | 0.17463631369173527    |
| train_0/q_loss            | 0.19229924345626537    |
| train_0/reward            | -0.8596735611965414    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00126953125          |
| train_0/target_q          | -9.134602982614261     |
| train_1/avg_q             | -7.5737193426213105    |
| train_1/current_q         | -1.7606836328282416    |
| train_1/fw_bonus          | -0.998546315729618     |
| train_1/fw_loss           | 0.0012529658619314433  |
| train_1/mu_grads          | -0.005537722446024418  |
| train_1/mu_grads_std      | 0.5175955280661583     |
| train_1/mu_loss           | 1.4556511140118218     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -0.4344361030689797    |
| train_1/q_grads           | 0.02473032670095563    |
| train_1/q_grads_std       | 0.23986806757748128    |
| train_1/q_loss            | 0.15869821621428448    |
| train_1/reward            | -1.486745437324862     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -1.7628356643070304    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 555.36. Rollout time: 367.47, Training time: 187.86
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 360106.0               |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.626967238853247    |
| test_1/avg_q              | -7.3178475572438035    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.121282377857053    |
| train_0/current_q         | -9.229637884471884     |
| train_0/fw_bonus          | -0.999719025194645     |
| train_0/fw_loss           | 7.66717429542041e-05   |
| train_0/mu_grads          | -0.024583060201257466  |
| train_0/mu_grads_std      | 0.24686169549822806    |
| train_0/mu_loss           | 9.171167292142599      |
| train_0/next_q            | -9.168334129791507     |
| train_0/q_grads           | 0.04044642886146903    |
| train_0/q_grads_std       | 0.20084622353315354    |
| train_0/q_loss            | 0.2110429518389992     |
| train_0/reward            | -0.8606474219821394    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0037109375           |
| train_0/target_q          | -9.375397061235759     |
| train_1/avg_q             | -7.078625182830478     |
| train_1/current_q         | -2.4836825423683733    |
| train_1/fw_bonus          | -0.9982152715325355    |
| train_1/fw_loss           | 0.0013350512454053387  |
| train_1/mu_grads          | -0.012388085061684252  |
| train_1/mu_grads_std      | 0.5420668393373489     |
| train_1/mu_loss           | 2.9167734137659833     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.94862234523417      |
| train_1/q_grads           | 0.021935780858621003   |
| train_1/q_grads_std       | 0.25297281965613366    |
| train_1/q_loss            | 0.8643943781951993     |
| train_1/reward            | -1.479093587922398     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0009033203125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.00037037037037037035 |
| train_1/target_q          | -2.4830832924355613    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 580.84. Rollout time: 386.11, Training time: 194.69
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 450917.0               |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -12.562838391618664    |
| test_1/avg_q              | -7.410264218786066     |
| test_1/n_subgoals         | 677.0                  |
| test_1/subgoal_succ_rate  | 0.005908419497784343   |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -21.9463103228724      |
| train_0/current_q         | -9.075874495584767     |
| train_0/fw_bonus          | -0.9995719492435455    |
| train_0/fw_loss           | 0.00011486556741147069 |
| train_0/mu_grads          | -0.028879435872659086  |
| train_0/mu_grads_std      | 0.2665996700525284     |
| train_0/mu_loss           | 9.021066487161967      |
| train_0/next_q            | -9.016935696019875     |
| train_0/q_grads           | 0.045100512076169254   |
| train_0/q_grads_std       | 0.21524536274373532    |
| train_0/q_loss            | 0.2494894588666529     |
| train_0/reward            | -0.8668359487666748    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003662109375        |
| train_0/target_q          | -9.240803435581286     |
| train_1/avg_q             | -6.67101646122708      |
| train_1/current_q         | -4.325829008948961     |
| train_1/fw_bonus          | -0.9974585801362992    |
| train_1/fw_loss           | 0.0015226801799144596  |
| train_1/mu_grads          | -0.013867590250447393  |
| train_1/mu_grads_std      | 0.5477290451526642     |
| train_1/mu_loss           | 5.266756733878943      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.241932150340809     |
| train_1/q_grads           | 0.014823350473307073   |
| train_1/q_grads_std       | 0.26929075419902804    |
| train_1/q_loss            | 1.3154387442079378     |
| train_1/reward            | -1.4844464750247426    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0010986328125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.011111111111111112   |
| train_1/target_q          | -4.376414193054934     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 594.87. Rollout time: 396.76, Training time: 198.08
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 541101.0              |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.8369862424378836   |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -15.030733346133147   |
| train_0/current_q         | -9.154169690005718    |
| train_0/fw_bonus          | -0.9995189473032952   |
| train_0/fw_loss           | 0.0001286331958908704 |
| train_0/mu_grads          | -0.03552371012046933  |
| train_0/mu_grads_std      | 0.2810668103396893    |
| train_0/mu_loss           | 9.107548869319775     |
| train_0/next_q            | -9.075598946657802    |
| train_0/q_grads           | 0.04775483375415206   |
| train_0/q_grads_std       | 0.2410202194005251    |
| train_0/q_loss            | 0.26628694458962704   |
| train_0/reward            | -0.8730400848828139   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000244140625        |
| train_0/target_q          | -9.287263685360584    |
| train_1/avg_q             | -6.694824889826001    |
| train_1/current_q         | -1.542112559531225    |
| train_1/fw_bonus          | -0.9973206341266632   |
| train_1/fw_loss           | 0.0015568838542094454 |
| train_1/mu_grads          | -0.012606488494202494 |
| train_1/mu_grads_std      | 0.550678725540638     |
| train_1/mu_loss           | 1.0968886519185075    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -0.09644321012948127  |
| train_1/q_grads           | 0.0109288789331913    |
| train_1/q_grads_std       | 0.2832050435245037    |
| train_1/q_loss            | 0.3221927914345787    |
| train_1/reward            | -1.4930649430287304   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.001220703125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.022222222222222223  |
| train_1/target_q          | -1.5483377119084811   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 600.65. Rollout time: 397.81, Training time: 202.81
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 6                      |
| policy/steps              | 630766.0               |
| test/episodes             | 175.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9601274622673936    |
| test_1/avg_q              | -6.362195026491779     |
| test_1/n_subgoals         | 777.0                  |
| test_1/subgoal_succ_rate  | 0.16216216216216217    |
| train/episodes            | 700.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -24.52930779384719     |
| train_0/current_q         | -8.948631088922605     |
| train_0/fw_bonus          | -0.9995231717824936    |
| train_0/fw_loss           | 0.00012753409973811358 |
| train_0/mu_grads          | -0.03650680100545287   |
| train_0/mu_grads_std      | 0.29668728783726694    |
| train_0/mu_loss           | 8.864104686712702      |
| train_0/next_q            | -8.828392713138516     |
| train_0/q_grads           | 0.04965254087001085    |
| train_0/q_grads_std       | 0.26448134779930116    |
| train_0/q_loss            | 0.22718284044725295    |
| train_0/reward            | -0.8726831516964012    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0001708984375        |
| train_0/target_q          | -9.076087939058834     |
| train_1/avg_q             | -6.711812488688129     |
| train_1/current_q         | -3.748761681546063     |
| train_1/fw_bonus          | -0.9973813906311989    |
| train_1/fw_loss           | 0.0015418186550959945  |
| train_1/mu_grads          | -0.01568297166377306   |
| train_1/mu_grads_std      | 0.5513157829642296     |
| train_1/mu_loss           | 4.434739418315397      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -3.3793628949063406    |
| train_1/q_grads           | 0.013032731832936406   |
| train_1/q_grads_std       | 0.30079762265086174    |
| train_1/q_loss            | 0.9779244829081704     |
| train_1/reward            | -1.5182020624357393    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0013916015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.02666666666666667    |
| train_1/target_q          | -3.715359256611312     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 585.27. Rollout time: 376.10, Training time: 209.13
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 714592.0               |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.4235546346478545    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -13.818446190175171    |
| train_0/current_q         | -8.45817258702392      |
| train_0/fw_bonus          | -0.9995337784290313    |
| train_0/fw_loss           | 0.00012477675772970542 |
| train_0/mu_grads          | -0.03781129829585552   |
| train_0/mu_grads_std      | 0.3110339783132076     |
| train_0/mu_loss           | 8.370307353172835      |
| train_0/next_q            | -8.330527116350646     |
| train_0/q_grads           | 0.04916950892657042    |
| train_0/q_grads_std       | 0.2766533464193344     |
| train_0/q_loss            | 0.26602454376146883    |
| train_0/reward            | -0.8733930190079263    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0005615234375        |
| train_0/target_q          | -8.54652701819371      |
| train_1/avg_q             | -6.264053263918905     |
| train_1/current_q         | -3.1973386631929617    |
| train_1/fw_bonus          | -0.9969845026731491    |
| train_1/fw_loss           | 0.0016402336623286828  |
| train_1/mu_grads          | -0.014773145830258728  |
| train_1/mu_grads_std      | 0.561025382578373      |
| train_1/mu_loss           | 3.6604220824339393     |
| train_1/n_subgoals        | 2678.0                 |
| train_1/next_q            | -2.6242575997695043    |
| train_1/q_grads           | 0.01529795357491821    |
| train_1/q_grads_std       | 0.3104590803384781     |
| train_1/q_loss            | 0.7933801051264395     |
| train_1/reward            | -1.4923062412912258    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0011474609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.13293502613890965    |
| train_1/target_q          | -3.194595040199674     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 8
Time for epoch 8: 548.27. Rollout time: 363.92, Training time: 184.32
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 800484.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -10.47550781106105     |
| test_1/avg_q              | -6.159135323236491     |
| test_1/n_subgoals         | 1694.0                 |
| test_1/subgoal_succ_rate  | 0.7886658795749705     |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -24.692284939088072    |
| train_0/current_q         | -8.515681737984655     |
| train_0/fw_bonus          | -0.9994909733533859    |
| train_0/fw_loss           | 0.00013589567570306826 |
| train_0/mu_grads          | -0.03878951584920287   |
| train_0/mu_grads_std      | 0.32271892204880714    |
| train_0/mu_loss           | 8.418060702212083      |
| train_0/next_q            | -8.372229779559778     |
| train_0/q_grads           | 0.050124671682715415   |
| train_0/q_grads_std       | 0.28759463503956795    |
| train_0/q_loss            | 0.2370187088740261     |
| train_0/reward            | -0.871969306714891     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0003662109375        |
| train_0/target_q          | -8.587371253946703     |
| train_1/avg_q             | -6.556595847228047     |
| train_1/current_q         | -4.099310721197767     |
| train_1/fw_bonus          | -0.9962598562240601    |
| train_1/fw_loss           | 0.0018199158454081043  |
| train_1/mu_grads          | -0.017526991898193955  |
| train_1/mu_grads_std      | 0.5735128089785576     |
| train_1/mu_loss           | 4.863351008180056      |
| train_1/n_subgoals        | 2687.0                 |
| train_1/next_q            | -3.8031666359343306    |
| train_1/q_grads           | 0.014743800298310817   |
| train_1/q_grads_std       | 0.3267359137535095     |
| train_1/q_loss            | 1.3027793419036895     |
| train_1/reward            | -1.4906519142939942    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00166015625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.08969110532192036    |
| train_1/target_q          | -4.073441975787276     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 9
Time for epoch 9: 544.27. Rollout time: 345.18, Training time: 199.05
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 880857.0               |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -26.73613038913021     |
| test_1/avg_q              | -7.28039761965925      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.04                   |
| train_0/avg_q             | -22.649013020611267    |
| train_0/current_q         | -8.376316262839776     |
| train_0/fw_bonus          | -0.9995022490620613    |
| train_0/fw_loss           | 0.00013296860161062795 |
| train_0/mu_grads          | -0.04189153043553233   |
| train_0/mu_grads_std      | 0.3399133443832397     |
| train_0/mu_loss           | 8.255626882153127      |
| train_0/next_q            | -8.203293943907793     |
| train_0/q_grads           | 0.0507188756018877     |
| train_0/q_grads_std       | 0.29823332130908964    |
| train_0/q_loss            | 0.20378445062052428    |
| train_0/reward            | -0.8716847911768127    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.001123046875         |
| train_0/target_q          | -8.431842476116039     |
| train_1/avg_q             | -6.384685025012323     |
| train_1/current_q         | -2.659194190613845     |
| train_1/fw_bonus          | -0.9966188639402389    |
| train_1/fw_loss           | 0.0017308957874774932  |
| train_1/mu_grads          | -0.018788590235635637  |
| train_1/mu_grads_std      | 0.574639818072319      |
| train_1/mu_loss           | 2.907067153850831      |
| train_1/n_subgoals        | 2602.0                 |
| train_1/next_q            | -1.8883180249900466    |
| train_1/q_grads           | 0.01266510768327862    |
| train_1/q_grads_std       | 0.3385617770254612     |
| train_1/q_loss            | 0.9580999101954479     |
| train_1/reward            | -1.4669282547009062    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0011474609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.17025365103766332    |
| train_1/target_q          | -2.658567896025656     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 10
Time for epoch 10: 614.99. Rollout time: 413.49, Training time: 201.46
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 970977.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.206286162707243     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -26.029997708450765    |
| train_0/current_q         | -8.527278761774406     |
| train_0/fw_bonus          | -0.9995584294199944    |
| train_0/fw_loss           | 0.00011837533056677785 |
| train_0/mu_grads          | -0.044782701414078474  |
| train_0/mu_grads_std      | 0.353399046510458      |
| train_0/mu_loss           | 8.423461538651509      |
| train_0/next_q            | -8.395215597084729     |
| train_0/q_grads           | 0.05215265015140176    |
| train_0/q_grads_std       | 0.30729004815220834    |
| train_0/q_loss            | 0.14584503289351064    |
| train_0/reward            | -0.8603560858260607    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0011474609375        |
| train_0/target_q          | -8.626935476392413     |
| train_1/avg_q             | -6.275855159279852     |
| train_1/current_q         | -1.4610989420603586    |
| train_1/fw_bonus          | -0.997298875451088     |
| train_1/fw_loss           | 0.0015622777224052697  |
| train_1/mu_grads          | -0.016719949431717396  |
| train_1/mu_grads_std      | 0.5768879443407059     |
| train_1/mu_loss           | 1.0000671371605903     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.26092167224688e-05  |
| train_1/q_grads           | 0.010261456575244665   |
| train_1/q_grads_std       | 0.3551120422780514     |
| train_1/q_loss            | 0.5437369501977007     |
| train_1/reward            | -1.4736577574440162    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0012939453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.01925925925925926    |
| train_1/target_q          | -1.4736930585938517    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_10.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 11
Time for epoch 11: 675.39. Rollout time: 445.97, Training time: 229.36
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 11                     |
| policy/steps              | 1062102.0              |
| test/episodes             | 300.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.727553062369503     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -8.547568694011321     |
| train_0/fw_bonus          | -0.9996417865157128    |
| train_0/fw_loss           | 9.673317799752112e-05  |
| train_0/mu_grads          | -0.0506912125274539    |
| train_0/mu_grads_std      | 0.36627024263143537    |
| train_0/mu_loss           | 8.438062372019251      |
| train_0/next_q            | -8.422044780425953     |
| train_0/q_grads           | 0.05360137606039643    |
| train_0/q_grads_std       | 0.3186026312410831     |
| train_0/q_loss            | 0.15745343058225342    |
| train_0/reward            | -0.8584105307018035    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.003515625            |
| train_0/target_q          | -8.662374224254512     |
| train_1/avg_q             | -7.137695979901514     |
| train_1/current_q         | -1.4296982840534158    |
| train_1/fw_bonus          | -0.9983345910906791    |
| train_1/fw_loss           | 0.0013054661627393215  |
| train_1/mu_grads          | -0.01651222431100905   |
| train_1/mu_grads_std      | 0.5769210129976272     |
| train_1/mu_loss           | 1.0000005513793286     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -5.173712083960131e-07 |
| train_1/q_grads           | 0.008328206883743406   |
| train_1/q_grads_std       | 0.3883746415376663     |
| train_1/q_loss            | 0.4211348401920477     |
| train_1/reward            | -1.4477926931067486    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001171875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4477929741207791    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 12
Time for epoch 12: 600.20. Rollout time: 396.72, Training time: 203.45
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 12                      |
| policy/steps              | 1153227.0               |
| test/episodes             | 325.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.407344025993902      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.415266759775765      |
| train_0/fw_bonus          | -0.9997266113758088     |
| train_0/fw_loss           | 7.46974189496541e-05    |
| train_0/mu_grads          | -0.05650703264400363    |
| train_0/mu_grads_std      | 0.37422152161598204     |
| train_0/mu_loss           | 9.369467232444052       |
| train_0/next_q            | -9.348810750697421      |
| train_0/q_grads           | 0.055050534382462504    |
| train_0/q_grads_std       | 0.3273333564400673      |
| train_0/q_loss            | 0.18705593779904944     |
| train_0/reward            | -0.857528123789234      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.0035400390625         |
| train_0/target_q          | -9.556026593105035      |
| train_1/avg_q             | -7.396244601995506      |
| train_1/current_q         | -1.4746619292741907     |
| train_1/fw_bonus          | -0.9989349767565727     |
| train_1/fw_loss           | 0.0011565951208467595   |
| train_1/mu_grads          | -0.01613710862584412    |
| train_1/mu_grads_std      | 0.5769894808530808      |
| train_1/mu_loss           | 1.0000016581686046      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.2725146265364556e-06 |
| train_1/q_grads           | 0.007440457446500659    |
| train_1/q_grads_std       | 0.41668865233659746     |
| train_1/q_loss            | 0.17623620149339225     |
| train_1/reward            | -1.4877144210302504     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00126953125           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4877153631261855     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 581.62. Rollout time: 396.05, Training time: 185.54
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 13                      |
| policy/steps              | 1244352.0               |
| test/episodes             | 350.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.250448053239214      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.396578583859236      |
| train_0/fw_bonus          | -0.9997914224863053     |
| train_0/fw_loss           | 5.7869154534273545e-05  |
| train_0/mu_grads          | -0.059330953005701306   |
| train_0/mu_grads_std      | 0.38289724886417387     |
| train_0/mu_loss           | 9.334131342156018       |
| train_0/next_q            | -9.312993764639856      |
| train_0/q_grads           | 0.05518708126619458     |
| train_0/q_grads_std       | 0.3331782788038254      |
| train_0/q_loss            | 0.145282349486682       |
| train_0/reward            | -0.858406800935336      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.00576171875           |
| train_0/target_q          | -9.537165041149466      |
| train_1/avg_q             | -7.318237319565351      |
| train_1/current_q         | -1.4518897825953898     |
| train_1/fw_bonus          | -0.9991918280720711     |
| train_1/fw_loss           | 0.0010929068259429187   |
| train_1/mu_grads          | -0.015882809180766344   |
| train_1/mu_grads_std      | 0.5770834684371948      |
| train_1/mu_loss           | 1.0000000013541233      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.4822036170569757e-09 |
| train_1/q_grads           | 0.006491525669116527    |
| train_1/q_grads_std       | 0.4405905567109585      |
| train_1/q_loss            | 0.11037729878609477     |
| train_1/reward            | -1.4553203891089652     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000927734375          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4553203898903173     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 510.79. Rollout time: 339.12, Training time: 171.64
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 14                    |
| policy/steps              | 1335477.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -27.0                 |
| test_1/avg_q              | -7.47208933085686     |
| test_1/n_subgoals         | 675.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1500.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -27.0                 |
| train_0/current_q         | -9.727155973172799    |
| train_0/fw_bonus          | -0.9998840004205704   |
| train_0/fw_loss           | 3.382577283446153e-05 |
| train_0/mu_grads          | -0.059458236768841745 |
| train_0/mu_grads_std      | 0.38632811084389684   |
| train_0/mu_loss           | 9.634860261117764     |
| train_0/next_q            | -9.624421030393686    |
| train_0/q_grads           | 0.05559401921927929   |
| train_0/q_grads_std       | 0.3351608745753765    |
| train_0/q_loss            | 0.10788684549440113   |
| train_0/reward            | -0.8565536297348444   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0422119140625       |
| train_0/target_q          | -9.874114114897969    |
| train_1/avg_q             | -7.339714510415917    |
| train_1/current_q         | -1.4893526320709936   |
| train_1/fw_bonus          | -0.9996781483292579   |
| train_1/fw_loss           | 0.0009723194627440535 |
| train_1/mu_grads          | -0.01588034685701132  |
| train_1/mu_grads_std      | 0.5770846605300903    |
| train_1/mu_loss           | 1.0000000000126352    |
| train_1/n_subgoals        | 2700.0                |
| train_1/next_q            | -1.23749381260408e-11 |
| train_1/q_grads           | 0.0056444280315190555 |
| train_1/q_grads_std       | 0.4469176195561886    |
| train_1/q_loss            | 0.017044736165278362  |
| train_1/reward            | -1.488442699740699    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.000732421875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.0                   |
| train_1/target_q          | -1.488442699747829    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 510.99. Rollout time: 338.82, Training time: 172.13
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 1426602.0              |
| test/episodes             | 400.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.51141973327231      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.756016419136497     |
| train_0/fw_bonus          | -0.9999291598796844    |
| train_0/fw_loss           | 2.2098783483670557e-05 |
| train_0/mu_grads          | -0.05886809844523668   |
| train_0/mu_grads_std      | 0.38955785930156706    |
| train_0/mu_loss           | 9.662093619712362      |
| train_0/next_q            | -9.653239181543146     |
| train_0/q_grads           | 0.05496476897969842    |
| train_0/q_grads_std       | 0.33663971424102784    |
| train_0/q_loss            | 0.09270750650223678    |
| train_0/reward            | -0.855928316792415     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1125732421875        |
| train_0/target_q          | -9.90757765561296      |
| train_1/avg_q             | -7.478475356703027     |
| train_1/current_q         | -1.4731691072184738    |
| train_1/fw_bonus          | -1.000017596781254     |
| train_1/fw_loss           | 0.0008881526198820211  |
| train_1/mu_grads          | -0.015880331629887223  |
| train_1/mu_grads_std      | 0.5770846605300903     |
| train_1/mu_loss           | 1.0000000000052531     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.135804531425934e-12 |
| train_1/q_grads           | 0.005655988748185336   |
| train_1/q_grads_std       | 0.44598442539572714    |
| train_1/q_loss            | 0.00776224912683218    |
| train_1/reward            | -1.4730600725961267    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00087890625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.473060072598414     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 508.58. Rollout time: 334.37, Training time: 174.19
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 16                      |
| policy/steps              | 1517727.0               |
| test/episodes             | 425.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5156003495473165     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 1700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.76999398397553       |
| train_0/fw_bonus          | -0.9999290764331817     |
| train_0/fw_loss           | 2.2123260964690417e-05  |
| train_0/mu_grads          | -0.05951776821166277    |
| train_0/mu_grads_std      | 0.39629535004496574     |
| train_0/mu_loss           | 9.673591880941288       |
| train_0/next_q            | -9.665234141906769      |
| train_0/q_grads           | 0.05439411411061883     |
| train_0/q_grads_std       | 0.33878896161913874     |
| train_0/q_loss            | 0.08898158654536006     |
| train_0/reward            | -0.8559465566446306     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1201171875            |
| train_0/target_q          | -9.924599648715773      |
| train_1/avg_q             | -7.498124696001057      |
| train_1/current_q         | -1.5092765410473075     |
| train_1/fw_bonus          | -1.000256071984768      |
| train_1/fw_loss           | 0.0008290198777103797   |
| train_1/mu_grads          | -0.01586273140273988    |
| train_1/mu_grads_std      | 0.5770848274230957      |
| train_1/mu_loss           | 1.0000000002369174      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.3776918163306666e-10 |
| train_1/q_grads           | 0.006000622094143182    |
| train_1/q_grads_std       | 0.442672611027956       |
| train_1/q_loss            | 0.0076223029198504684   |
| train_1/reward            | -1.5087919108002097     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00087890625           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.508791910975634      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 513.19. Rollout time: 339.30, Training time: 173.86
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1608852.0              |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.478759168661018     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.695450121191536     |
| train_0/fw_bonus          | -0.9999347850680351    |
| train_0/fw_loss           | 2.06385926276198e-05   |
| train_0/mu_grads          | -0.06217333609238267   |
| train_0/mu_grads_std      | 0.402795772254467      |
| train_0/mu_loss           | 9.604251230677614      |
| train_0/next_q            | -9.597629363315336     |
| train_0/q_grads           | 0.05422492465004325    |
| train_0/q_grads_std       | 0.34035323187708855    |
| train_0/q_loss            | 0.08559564652291049    |
| train_0/reward            | -0.8547057269170182    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.128466796875         |
| train_0/target_q          | -9.847785483796603     |
| train_1/avg_q             | -7.4919109257119       |
| train_1/current_q         | -1.494185673077368     |
| train_1/fw_bonus          | -1.000343769788742     |
| train_1/fw_loss           | 0.0008072761294897646  |
| train_1/mu_grads          | -0.015727977827191354  |
| train_1/mu_grads_std      | 0.5771085307002067     |
| train_1/mu_loss           | 1.000000000100038      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.447735861460198e-11 |
| train_1/q_grads           | 0.005495375778991729   |
| train_1/q_grads_std       | 0.4434024229645729     |
| train_1/q_loss            | 0.007413115445509898   |
| train_1/reward            | -1.4939528941802565    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.493952894236871     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 512.03. Rollout time: 335.55, Training time: 176.44
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1699977.0              |
| test/episodes             | 475.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.49008429483679      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.74733278799142      |
| train_0/fw_bonus          | -0.9999380066990853    |
| train_0/fw_loss           | 1.9809047967100923e-05 |
| train_0/mu_grads          | -0.06446653492748737   |
| train_0/mu_grads_std      | 0.40849127173423766    |
| train_0/mu_loss           | 9.657607208725981      |
| train_0/next_q            | -9.649761529726675     |
| train_0/q_grads           | 0.054020969104021786   |
| train_0/q_grads_std       | 0.3412875674664974     |
| train_0/q_loss            | 0.08729090315365445    |
| train_0/reward            | -0.8556785816152115    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.123974609375         |
| train_0/target_q          | -9.90107669602942      |
| train_1/avg_q             | -7.48474895799326      |
| train_1/current_q         | -1.4919779069315053    |
| train_1/fw_bonus          | -1.000645139813423     |
| train_1/fw_loss           | 0.0007325516984565183  |
| train_1/mu_grads          | -0.015546566457487643  |
| train_1/mu_grads_std      | 0.5771833166480065     |
| train_1/mu_loss           | 1.0000000000171316     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.630361096641141e-11 |
| train_1/q_grads           | 0.004756242572329939   |
| train_1/q_grads_std       | 0.44725438207387924    |
| train_1/q_loss            | 0.007642438513203957   |
| train_1/reward            | -1.4915238850662718    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4915238850782806    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 19
Time for epoch 19: 514.57. Rollout time: 337.37, Training time: 177.17
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 1791102.0              |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.533610397975143     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.6732280940726       |
| train_0/fw_bonus          | -0.9999403014779091    |
| train_0/fw_loss           | 1.9206521824344235e-05 |
| train_0/mu_grads          | -0.06548896729946137   |
| train_0/mu_grads_std      | 0.4126743145287037     |
| train_0/mu_loss           | 9.582155870453594      |
| train_0/next_q            | -9.575962369908662     |
| train_0/q_grads           | 0.05384738566353917    |
| train_0/q_grads_std       | 0.3419493518769741     |
| train_0/q_loss            | 0.0857238085765087     |
| train_0/reward            | -0.8550577634188812    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1708740234375        |
| train_0/target_q          | -9.823940830589086     |
| train_1/avg_q             | -7.49501154633259      |
| train_1/current_q         | -1.506051487143018     |
| train_1/fw_bonus          | -1.0007668524980544    |
| train_1/fw_loss           | 0.0007023681202554144  |
| train_1/mu_grads          | -0.01546212900429964   |
| train_1/mu_grads_std      | 0.5772261589765548     |
| train_1/mu_loss           | 1.000000000006426      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.460068176671809e-12 |
| train_1/q_grads           | 0.004955916490871459   |
| train_1/q_grads_std       | 0.45081168711185454    |
| train_1/q_loss            | 0.006526078914855957   |
| train_1/reward            | -1.505311470622837     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.505311470628041     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 20
Time for epoch 20: 517.64. Rollout time: 340.44, Training time: 177.17
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 1882227.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.510580272533666     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.786536392736298     |
| train_0/fw_bonus          | -0.9999445229768753    |
| train_0/fw_loss           | 1.810888727504789e-05  |
| train_0/mu_grads          | -0.06704534403979778   |
| train_0/mu_grads_std      | 0.41673276871442794    |
| train_0/mu_loss           | 9.698207377945668      |
| train_0/next_q            | -9.691203523506527     |
| train_0/q_grads           | 0.053439566493034364   |
| train_0/q_grads_std       | 0.34284401684999466    |
| train_0/q_loss            | 0.08555615470803588    |
| train_0/reward            | -0.8561961871251696    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1825439453125        |
| train_0/target_q          | -9.939837543000746     |
| train_1/avg_q             | -7.505594305856856     |
| train_1/current_q         | -1.4814243084145982    |
| train_1/fw_bonus          | -1.0010180473327637    |
| train_1/fw_loss           | 0.0006400877013220452  |
| train_1/mu_grads          | -0.015398692176677286  |
| train_1/mu_grads_std      | 0.5772431775927543     |
| train_1/mu_loss           | 1.0000000000021942     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.772922724758498e-12 |
| train_1/q_grads           | 0.003959034592844546   |
| train_1/q_grads_std       | 0.45129177197813986    |
| train_1/q_loss            | 0.0057877731986227775  |
| train_1/reward            | -1.4809515110318898    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.48095151103334      |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_20.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 21
Time for epoch 21: 523.45. Rollout time: 340.05, Training time: 183.36
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 21                      |
| policy/steps              | 1973352.0               |
| test/episodes             | 550.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.558066143915689      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.673758341799475      |
| train_0/fw_bonus          | -0.9999466672539711     |
| train_0/fw_loss           | 1.7552616168359236e-05  |
| train_0/mu_grads          | -0.06863968558609486    |
| train_0/mu_grads_std      | 0.42028922140598296     |
| train_0/mu_loss           | 9.583775580495608       |
| train_0/next_q            | -9.575411622092002      |
| train_0/q_grads           | 0.05307239070534706     |
| train_0/q_grads_std       | 0.34389265850186346     |
| train_0/q_loss            | 0.08440267351616011     |
| train_0/reward            | -0.8551113677356625     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1709716796875         |
| train_0/target_q          | -9.82758103056326       |
| train_1/avg_q             | -7.5068455637889056     |
| train_1/current_q         | -1.4603045280062759     |
| train_1/fw_bonus          | -1.0010706156492233     |
| train_1/fw_loss           | 0.000627048936439678    |
| train_1/mu_grads          | -0.015329149831086398   |
| train_1/mu_grads_std      | 0.5772634789347648      |
| train_1/mu_loss           | 1.0000000000027802      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.7982192396908154e-12 |
| train_1/q_grads           | 0.0021801074792165307   |
| train_1/q_grads_std       | 0.45129103660583497     |
| train_1/q_loss            | 0.005102790265923634    |
| train_1/reward            | -1.459866681753192      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006591796875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4598666817555208     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 22
Time for epoch 22: 519.91. Rollout time: 333.70, Training time: 186.18
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 2064477.0              |
| test/episodes             | 575.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.518628224743037     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.700784558094501     |
| train_0/fw_bonus          | -0.9999355703592301    |
| train_0/fw_loss           | 2.043387717094447e-05  |
| train_0/mu_grads          | -0.0705485736951232    |
| train_0/mu_grads_std      | 0.4254982188344002     |
| train_0/mu_loss           | 9.614502507472949      |
| train_0/next_q            | -9.606692774494098     |
| train_0/q_grads           | 0.05207874327898025    |
| train_0/q_grads_std       | 0.34549412652850153    |
| train_0/q_loss            | 0.08488346259620823    |
| train_0/reward            | -0.8554509474532097    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.162255859375         |
| train_0/target_q          | -9.85249400424534      |
| train_1/avg_q             | -7.446673175890704     |
| train_1/current_q         | -1.4928025831471992    |
| train_1/fw_bonus          | -1.0012827813625336    |
| train_1/fw_loss           | 0.0005744373615016229  |
| train_1/mu_grads          | -0.015163376345299184  |
| train_1/mu_grads_std      | 0.5773276776075363     |
| train_1/mu_loss           | 1.0000000000079208     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -7.431156058598582e-12 |
| train_1/q_grads           | 0.000772920784947928   |
| train_1/q_grads_std       | 0.4521035872399807     |
| train_1/q_loss            | 0.00489699977800302    |
| train_1/reward            | -1.4922767934811418    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4922767934836165    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 511.25. Rollout time: 328.56, Training time: 182.66
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 23                      |
| policy/steps              | 2155602.0               |
| test/episodes             | 600.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.520644280481482      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.657627345853626      |
| train_0/fw_bonus          | -0.9999234020709992     |
| train_0/fw_loss           | 2.3598213965669855e-05  |
| train_0/mu_grads          | -0.07061648741364479    |
| train_0/mu_grads_std      | 0.429589731246233       |
| train_0/mu_loss           | 9.571992489899307       |
| train_0/next_q            | -9.565021258281954      |
| train_0/q_grads           | 0.05169434743002057     |
| train_0/q_grads_std       | 0.3464732006192207      |
| train_0/q_loss            | 0.08428253742842709     |
| train_0/reward            | -0.8545629027212271     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1443115234375         |
| train_0/target_q          | -9.809198269497792      |
| train_1/avg_q             | -7.4676351550787645     |
| train_1/current_q         | -1.4934689750302632     |
| train_1/fw_bonus          | -1.0010347425937653     |
| train_1/fw_loss           | 0.0006359415754559449   |
| train_1/mu_grads          | -0.015064555522985756   |
| train_1/mu_grads_std      | 0.5773882523179055      |
| train_1/mu_loss           | 1.0000000000046447      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.451778425679292e-12  |
| train_1/q_grads           | -5.7585899048717694e-05 |
| train_1/q_grads_std       | 0.45402932688593867     |
| train_1/q_loss            | 0.004478519430209808    |
| train_1/reward            | -1.493097841157578      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006591796875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4930978411589049     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 514.13. Rollout time: 331.95, Training time: 182.15
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 24                      |
| policy/steps              | 2246727.0               |
| test/episodes             | 625.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.525138885156072      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.689181455850683      |
| train_0/fw_bonus          | -0.9999162957072258     |
| train_0/fw_loss           | 2.5437233557568106e-05  |
| train_0/mu_grads          | -0.07153256423771381    |
| train_0/mu_grads_std      | 0.433920880407095       |
| train_0/mu_loss           | 9.60328051091031        |
| train_0/next_q            | -9.595660043495055      |
| train_0/q_grads           | 0.05131524875760078     |
| train_0/q_grads_std       | 0.3481320239603519      |
| train_0/q_loss            | 0.08574400174150662     |
| train_0/reward            | -0.8547529041548841     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1230712890625         |
| train_0/target_q          | -9.84137235562523       |
| train_1/avg_q             | -7.503164097588925      |
| train_1/current_q         | -1.4822206498427342     |
| train_1/fw_bonus          | -1.0006319910287857     |
| train_1/fw_loss           | 0.0007358137358096428   |
| train_1/mu_grads          | -0.015004758373834193   |
| train_1/mu_grads_std      | 0.5774219155311584      |
| train_1/mu_loss           | 1.0000000000042604      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.2940808444662836e-12 |
| train_1/q_grads           | -0.0006047086557373404  |
| train_1/q_grads_std       | 0.45415776073932645     |
| train_1/q_loss            | 0.0036377389092525163   |
| train_1/reward            | -1.4819864305172814     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00078125              |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.481986430518349      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 516.29. Rollout time: 332.88, Training time: 183.38
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 25                      |
| policy/steps              | 2337852.0               |
| test/episodes             | 650.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.490598364828767      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.646468992813272      |
| train_0/fw_bonus          | -0.9999502137303352     |
| train_0/fw_loss           | 1.6634475446153375e-05  |
| train_0/mu_grads          | -0.07326343916356563    |
| train_0/mu_grads_std      | 0.4398751504719257      |
| train_0/mu_loss           | 9.560708467125172       |
| train_0/next_q            | -9.553838763526988      |
| train_0/q_grads           | 0.05089097050949931     |
| train_0/q_grads_std       | 0.34975254610180856     |
| train_0/q_loss            | 0.08515803843360895     |
| train_0/reward            | -0.8542412167065777     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.208837890625          |
| train_0/target_q          | -9.799024241960433      |
| train_1/avg_q             | -7.505728526305465      |
| train_1/current_q         | -1.4972631058500856     |
| train_1/fw_bonus          | -1.0004440903663636     |
| train_1/fw_loss           | 0.0007824016298400238   |
| train_1/mu_grads          | -0.014850443252362311   |
| train_1/mu_grads_std      | 0.5775013729929924      |
| train_1/mu_loss           | 1.000000000003165       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.1943724894083175e-12 |
| train_1/q_grads           | -0.001623539620777592   |
| train_1/q_grads_std       | 0.4559039808809757      |
| train_1/q_loss            | 0.003334530148219224    |
| train_1/reward            | -1.49707378668827       |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006103515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4970737866890564     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 520.17. Rollout time: 330.03, Training time: 190.11
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 2428977.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.540961300493843     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.5894324741549       |
| train_0/fw_bonus          | -0.9999393701553345    |
| train_0/fw_loss           | 1.9448320153969688e-05 |
| train_0/mu_grads          | -0.07453290950506926   |
| train_0/mu_grads_std      | 0.4445523679256439     |
| train_0/mu_loss           | 9.504032738770587      |
| train_0/next_q            | -9.4954548026947       |
| train_0/q_grads           | 0.05027350289747119    |
| train_0/q_grads_std       | 0.35072908625006677    |
| train_0/q_loss            | 0.0850148088107785     |
| train_0/reward            | -0.8539035008681821    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1152099609375        |
| train_0/target_q          | -9.740141760785425     |
| train_1/avg_q             | -7.492041751354043     |
| train_1/current_q         | -1.5043029714057894    |
| train_1/fw_bonus          | -1.0002509921789169    |
| train_1/fw_loss           | 0.0008302799295051954  |
| train_1/mu_grads          | -0.014811470336280764  |
| train_1/mu_grads_std      | 0.5775223627686501     |
| train_1/mu_loss           | 1.000000000002034      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.350140062311241e-12 |
| train_1/q_grads           | -0.0019167146587278695 |
| train_1/q_grads_std       | 0.45764745622873304    |
| train_1/q_loss            | 0.009600621623783485   |
| train_1/reward            | -1.5069509413136983    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5069509413145465    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 523.86. Rollout time: 334.63, Training time: 189.20
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 27                      |
| policy/steps              | 2520102.0               |
| test/episodes             | 700.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.510500099842047      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 2800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.587017823118536      |
| train_0/fw_bonus          | -0.999944232404232      |
| train_0/fw_loss           | 1.818853725126246e-05   |
| train_0/mu_grads          | -0.0751732837408781     |
| train_0/mu_grads_std      | 0.44711991399526596     |
| train_0/mu_loss           | 9.499237354215827       |
| train_0/next_q            | -9.491120732938299      |
| train_0/q_grads           | 0.04998099729418755     |
| train_0/q_grads_std       | 0.3517323300242424      |
| train_0/q_loss            | 0.08339863741885656     |
| train_0/reward            | -0.854242832188902      |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1587158203125         |
| train_0/target_q          | -9.739712851187653      |
| train_1/avg_q             | -7.506749946760988      |
| train_1/current_q         | -1.4989240372307773     |
| train_1/fw_bonus          | -1.000419819355011      |
| train_1/fw_loss           | 0.0007884155507781543   |
| train_1/mu_grads          | -0.014711368223652243   |
| train_1/mu_grads_std      | 0.5775815233588218      |
| train_1/mu_loss           | 1.0000000000009703      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.0408803970268577e-12 |
| train_1/q_grads           | -0.0023302844958379863  |
| train_1/q_grads_std       | 0.45678591057658197     |
| train_1/q_loss            | 0.003486550509937057    |
| train_1/reward            | -1.4985997859810596     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000537109375          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.498599785981392      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 522.34. Rollout time: 336.31, Training time: 186.00
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 2611227.0              |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.4910478771381195    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.552276942985378     |
| train_0/fw_bonus          | -0.9999571576714515    |
| train_0/fw_loss           | 1.482373143062432e-05  |
| train_0/mu_grads          | -0.07787145804613829   |
| train_0/mu_grads_std      | 0.44961634576320647    |
| train_0/mu_loss           | 9.46229964017199       |
| train_0/next_q            | -9.455640456181456     |
| train_0/q_grads           | 0.04993529692292213    |
| train_0/q_grads_std       | 0.35212745144963264    |
| train_0/q_loss            | 0.08392258299908753    |
| train_0/reward            | -0.853752061369596     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2313232421875        |
| train_0/target_q          | -9.701723505766202     |
| train_1/avg_q             | -7.503077332753721     |
| train_1/current_q         | -1.499867983650103     |
| train_1/fw_bonus          | -1.0005290076136588    |
| train_1/fw_loss           | 0.0007613496025442145  |
| train_1/mu_grads          | -0.014569396292790771  |
| train_1/mu_grads_std      | 0.5776690050959588     |
| train_1/mu_loss           | 1.0000000000045328     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.65874497575121e-12  |
| train_1/q_grads           | -0.0020530562265776097 |
| train_1/q_grads_std       | 0.457180043309927      |
| train_1/q_loss            | 0.0025781224437682847  |
| train_1/reward            | -1.4997497674979967    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4997497674998497    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 518.06. Rollout time: 329.26, Training time: 188.77
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 2702352.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.501174893684019     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.657401378908574     |
| train_0/fw_bonus          | -0.999960520863533     |
| train_0/fw_loss           | 1.3953397012755885e-05 |
| train_0/mu_grads          | -0.07865107022225856   |
| train_0/mu_grads_std      | 0.4525577396154404     |
| train_0/mu_loss           | 9.57394173243026       |
| train_0/next_q            | -9.567212365029851     |
| train_0/q_grads           | 0.04953099433332682    |
| train_0/q_grads_std       | 0.35288767516613007    |
| train_0/q_loss            | 0.0856788558014944     |
| train_0/reward            | -0.8547433439147426    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2062255859375        |
| train_0/target_q          | -9.80915959228017      |
| train_1/avg_q             | -7.500249313099886     |
| train_1/current_q         | -1.500825388098645     |
| train_1/fw_bonus          | -1.0010893791913986    |
| train_1/fw_loss           | 0.0006223972100997344  |
| train_1/mu_grads          | -0.014508468168787658  |
| train_1/mu_grads_std      | 0.577703146636486      |
| train_1/mu_loss           | 1.0000000000038707     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.054619900118438e-12 |
| train_1/q_grads           | -0.002138451230712235  |
| train_1/q_grads_std       | 0.4560395203530788     |
| train_1/q_loss            | 0.0023359368628431834  |
| train_1/reward            | -1.5006583399663214    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5006583399680178    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 519.17. Rollout time: 329.58, Training time: 189.56
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 2793477.0              |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.526021237793989     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.69332812255538      |
| train_0/fw_bonus          | -0.9999608606100082    |
| train_0/fw_loss           | 1.3867634913822258e-05 |
| train_0/mu_grads          | -0.07970815412700176   |
| train_0/mu_grads_std      | 0.45518840849399567    |
| train_0/mu_loss           | 9.607702773833092      |
| train_0/next_q            | -9.599157312385758     |
| train_0/q_grads           | 0.04961578212678432    |
| train_0/q_grads_std       | 0.35284903943538665    |
| train_0/q_loss            | 0.0840870568362773     |
| train_0/reward            | -0.8548961799548124    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1906005859375        |
| train_0/target_q          | -9.8450615801859       |
| train_1/avg_q             | -7.501966191598153     |
| train_1/current_q         | -1.504173299167062     |
| train_1/fw_bonus          | -1.001260194182396     |
| train_1/fw_loss           | 0.0005800423561595381  |
| train_1/mu_grads          | -0.014482568460516631  |
| train_1/mu_grads_std      | 0.5777192190289497     |
| train_1/mu_loss           | 1.0000000000009477     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.831656477585438e-13 |
| train_1/q_grads           | -0.0022749125317204745 |
| train_1/q_grads_std       | 0.4556282125413418     |
| train_1/q_loss            | 0.0023579469045947785  |
| train_1/reward            | -1.5045401133218548    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5045401133222727    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_30.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 519.45. Rollout time: 331.46, Training time: 187.96
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 31                      |
| policy/steps              | 2884602.0               |
| test/episodes             | 800.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.537537766776999      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3200.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.719063140417784      |
| train_0/fw_bonus          | -0.9999630898237228     |
| train_0/fw_loss           | 1.328444886894431e-05   |
| train_0/mu_grads          | -0.08194381669163704    |
| train_0/mu_grads_std      | 0.45993309542536737     |
| train_0/mu_loss           | 9.63511106800473        |
| train_0/next_q            | -9.627255444411873      |
| train_0/q_grads           | 0.04948011506348848     |
| train_0/q_grads_std       | 0.353308966755867       |
| train_0/q_loss            | 0.08479405292793527     |
| train_0/reward            | -0.8545926881794003     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.21650390625           |
| train_0/target_q          | -9.872566800335203      |
| train_1/avg_q             | -7.508232379887357      |
| train_1/current_q         | -1.4968480163955573     |
| train_1/fw_bonus          | -1.0012569397687912     |
| train_1/fw_loss           | 0.0005808476693346165   |
| train_1/mu_grads          | -0.014476447249762714   |
| train_1/mu_grads_std      | 0.5777226403355599      |
| train_1/mu_loss           | 1.000000000000249       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.5993123636539233e-13 |
| train_1/q_grads           | -0.002352345496183261   |
| train_1/q_grads_std       | 0.45651769563555716     |
| train_1/q_loss            | 0.002306580236939073    |
| train_1/reward            | -1.4970730778411963     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0007080078125         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4970730778413053     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 521.79. Rollout time: 334.15, Training time: 187.60
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 32                      |
| policy/steps              | 2975727.0               |
| test/episodes             | 825.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.498256583728625      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.73085546128895       |
| train_0/fw_bonus          | -0.9999670073390007     |
| train_0/fw_loss           | 1.2267553654510265e-05  |
| train_0/mu_grads          | -0.08270736467093229    |
| train_0/mu_grads_std      | 0.4642872177064419      |
| train_0/mu_loss           | 9.645905852093884       |
| train_0/next_q            | -9.637880905616111      |
| train_0/q_grads           | 0.04942081226035953     |
| train_0/q_grads_std       | 0.35371294990181923     |
| train_0/q_loss            | 0.08548090032366759     |
| train_0/reward            | -0.8550655958388234     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2803466796875         |
| train_0/target_q          | -9.883320345298715      |
| train_1/avg_q             | -7.515423638190992      |
| train_1/current_q         | -1.487560214820025      |
| train_1/fw_bonus          | -1.0010927766561508     |
| train_1/fw_loss           | 0.0006215503686689772   |
| train_1/mu_grads          | -0.014472573483362793   |
| train_1/mu_grads_std      | 0.5777250975370407      |
| train_1/mu_loss           | 1.0000000000004268      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -4.3943448863477825e-13 |
| train_1/q_grads           | -0.0020299683208577337  |
| train_1/q_grads_std       | 0.4574942097067833      |
| train_1/q_loss            | 0.0021244869333405933   |
| train_1/reward            | -1.4876359988280456     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006591796875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4876359988282066     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 515.37. Rollout time: 328.69, Training time: 186.65
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 33                      |
| policy/steps              | 3066852.0               |
| test/episodes             | 850.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5028712119620415     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3400.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.554806753739943      |
| train_0/fw_bonus          | -0.9999368414282799     |
| train_0/fw_loss           | 2.010567784509476e-05   |
| train_0/mu_grads          | -0.08348399326205254    |
| train_0/mu_grads_std      | 0.4681763663887978      |
| train_0/mu_loss           | 9.468054168799515       |
| train_0/next_q            | -9.459685547685776      |
| train_0/q_grads           | 0.04946623733267188     |
| train_0/q_grads_std       | 0.35439912155270575     |
| train_0/q_loss            | 0.08268119337592819     |
| train_0/reward            | -0.8537246002495522     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1459716796875         |
| train_0/target_q          | -9.70517935367008       |
| train_1/avg_q             | -7.499621080512206      |
| train_1/current_q         | -1.4876573397934572     |
| train_1/fw_bonus          | -1.0012753158807755     |
| train_1/fw_loss           | 0.0005762882356066257   |
| train_1/mu_grads          | -0.01446649618446827    |
| train_1/mu_grads_std      | 0.57773357629776        |
| train_1/mu_loss           | 1.000000000000017       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.7742423788942058e-14 |
| train_1/q_grads           | -0.0024904057325329633  |
| train_1/q_grads_std       | 0.45868469700217246     |
| train_1/q_loss            | 0.0020764564690841274   |
| train_1/reward            | -1.4876691439480054     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0007568359375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4876691439480112     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 34
Time for epoch 34: 520.47. Rollout time: 330.80, Training time: 189.63
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 3157977.0              |
| test/episodes             | 875.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.490433595261446     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.672118822564345     |
| train_0/fw_bonus          | -0.9999550953507423    |
| train_0/fw_loss           | 1.5368226388545737e-05 |
| train_0/mu_grads          | -0.08409895170480013   |
| train_0/mu_grads_std      | 0.47265381142497065    |
| train_0/mu_loss           | 9.584933103855935      |
| train_0/next_q            | -9.577064822162274     |
| train_0/q_grads           | 0.04919098690152168    |
| train_0/q_grads_std       | 0.35509911477565764    |
| train_0/q_loss            | 0.0835129131655583     |
| train_0/reward            | -0.8555021976979333    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.165087890625         |
| train_0/target_q          | -9.824108985569703     |
| train_1/avg_q             | -7.501872735523921     |
| train_1/current_q         | -1.5057582510948602    |
| train_1/fw_bonus          | -1.0014091610908509    |
| train_1/fw_loss           | 0.0005431039731774945  |
| train_1/mu_grads          | -0.014466320862993598  |
| train_1/mu_grads_std      | 0.5777336955070496     |
| train_1/mu_loss           | 1.0000000000000924     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.211654358694283e-14 |
| train_1/q_grads           | -0.002421712421346456  |
| train_1/q_grads_std       | 0.4584995724260807     |
| train_1/q_loss            | 0.002081116678989381   |
| train_1/reward            | -1.5057809917707345    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.505780991770762     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 35
Time for epoch 35: 519.00. Rollout time: 332.26, Training time: 186.72
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 35                      |
| policy/steps              | 3249102.0               |
| test/episodes             | 900.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.517456512236799      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.646800689561314      |
| train_0/fw_bonus          | -0.999957974255085      |
| train_0/fw_loss           | 1.461492947782972e-05   |
| train_0/mu_grads          | -0.08470015376806259    |
| train_0/mu_grads_std      | 0.4768079653382301      |
| train_0/mu_loss           | 9.563080453521234       |
| train_0/next_q            | -9.555108574603732      |
| train_0/q_grads           | 0.04931704923510551     |
| train_0/q_grads_std       | 0.3548572599887848      |
| train_0/q_loss            | 0.08358095248202171     |
| train_0/reward            | -0.8546315705243615     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.214501953125          |
| train_0/target_q          | -9.798748370556364      |
| train_1/avg_q             | -7.494135151350813      |
| train_1/current_q         | -1.4923527746457748     |
| train_1/fw_bonus          | -1.0014864653348923     |
| train_1/fw_loss           | 0.0005239332436758559   |
| train_1/mu_grads          | -0.014465586771257222   |
| train_1/mu_grads_std      | 0.577734836935997       |
| train_1/mu_loss           | 1.0000000000001417      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.3977311978339688e-13 |
| train_1/q_grads           | -0.002337311493465677   |
| train_1/q_grads_std       | 0.4580564022064209      |
| train_1/q_loss            | 0.0020687967104288203   |
| train_1/reward            | -1.492319690201839      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000927734375          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.492319690201886      |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 36
Time for epoch 36: 520.60. Rollout time: 331.17, Training time: 189.40
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 3340227.0              |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.499790534814076     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.689375002153996     |
| train_0/fw_bonus          | -0.9999466449022293    |
| train_0/fw_loss           | 1.7559512252773855e-05 |
| train_0/mu_grads          | -0.08566055297851563   |
| train_0/mu_grads_std      | 0.4807578332722187     |
| train_0/mu_loss           | 9.592706177635488      |
| train_0/next_q            | -9.586650452010712     |
| train_0/q_grads           | 0.04935917519032955    |
| train_0/q_grads_std       | 0.35520483255386354    |
| train_0/q_loss            | 0.08537317613221662    |
| train_0/reward            | -0.8576809281803435    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.230224609375         |
| train_0/target_q          | -9.842601069893789     |
| train_1/avg_q             | -7.482582490153117     |
| train_1/current_q         | -1.4867265304754613    |
| train_1/fw_bonus          | -1.0013996213674545    |
| train_1/fw_loss           | 0.0005454691956401803  |
| train_1/mu_grads          | -0.014462411846034228  |
| train_1/mu_grads_std      | 0.5777410864830017     |
| train_1/mu_loss           | 1.0000000000000684     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.946200337177622e-14 |
| train_1/q_grads           | -0.0030743720417376608 |
| train_1/q_grads_std       | 0.45724392458796503    |
| train_1/q_loss            | 0.002442032432745225   |
| train_1/reward            | -1.4865599702156032    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000830078125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.486559970215626     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 37
Time for epoch 37: 516.98. Rollout time: 327.39, Training time: 189.56
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 37                      |
| policy/steps              | 3431352.0               |
| test/episodes             | 950.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.509999054585042      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.705110399103834      |
| train_0/fw_bonus          | -0.9999567687511444     |
| train_0/fw_loss           | 1.4927587085367122e-05  |
| train_0/mu_grads          | -0.08595958277583123    |
| train_0/mu_grads_std      | 0.4850716330111027      |
| train_0/mu_loss           | 9.612494869039944       |
| train_0/next_q            | -9.604511943883761      |
| train_0/q_grads           | 0.04930193927139044     |
| train_0/q_grads_std       | 0.3560485802590847      |
| train_0/q_loss            | 0.08613681275426406     |
| train_0/reward            | -0.8574565952672856     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2248779296875         |
| train_0/target_q          | -9.857393849948298      |
| train_1/avg_q             | -7.499503165136228      |
| train_1/current_q         | -1.5001964987109804     |
| train_1/fw_bonus          | -1.00172161757946       |
| train_1/fw_loss           | 0.0004656294979213271   |
| train_1/mu_grads          | -0.014461205899715423   |
| train_1/mu_grads_std      | 0.5777418613433838      |
| train_1/mu_loss           | 1.0000000000001212      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.2431177044324595e-13 |
| train_1/q_grads           | -0.0029964705929160116  |
| train_1/q_grads_std       | 0.45834324657917025     |
| train_1/q_loss            | 0.0020839943467153054   |
| train_1/reward            | -1.4999911595630693     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0004638671875         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4999911595631148     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 38
Time for epoch 38: 516.74. Rollout time: 328.70, Training time: 188.01
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 38                      |
| policy/steps              | 3522477.0               |
| test/episodes             | 975.0                   |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5087615469076106     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 3900.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.737612795997343      |
| train_0/fw_bonus          | -0.9999591007828712     |
| train_0/fw_loss           | 1.4323866207632818e-05  |
| train_0/mu_grads          | -0.08623958639800548    |
| train_0/mu_grads_std      | 0.48871123865246774     |
| train_0/mu_loss           | 9.645734416639622       |
| train_0/next_q            | -9.637688813014103      |
| train_0/q_grads           | 0.049342384468764065    |
| train_0/q_grads_std       | 0.35697872787714        |
| train_0/q_loss            | 0.08413062353787251     |
| train_0/reward            | -0.8573728896590183     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2379150390625         |
| train_0/target_q          | -9.89041789487742       |
| train_1/avg_q             | -7.5011004619359305     |
| train_1/current_q         | -1.490507805690061      |
| train_1/fw_bonus          | -1.0016313940286636     |
| train_1/fw_loss           | 0.00048799643845995886  |
| train_1/mu_grads          | -0.014460475812666119   |
| train_1/mu_grads_std      | 0.5777427554130554      |
| train_1/mu_loss           | 1.0000000000000957      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.0105786411708138e-13 |
| train_1/q_grads           | -0.002846212888834998   |
| train_1/q_grads_std       | 0.4595922455191612      |
| train_1/q_loss            | 0.002073198800164304    |
| train_1/reward            | -1.4906339551802374     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000390625             |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4906339551802885     |
-------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 39
Time for epoch 39: 517.25. Rollout time: 328.89, Training time: 188.33
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 3613602.0              |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.507707622933443     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.654175304313766     |
| train_0/fw_bonus          | -0.9999554082751274    |
| train_0/fw_loss           | 1.5282237609426374e-05 |
| train_0/mu_grads          | -0.08729946110397577   |
| train_0/mu_grads_std      | 0.49317284002900125    |
| train_0/mu_loss           | 9.562823928048433      |
| train_0/next_q            | -9.55520162314866      |
| train_0/q_grads           | 0.04937333157286048    |
| train_0/q_grads_std       | 0.35794949904084206    |
| train_0/q_loss            | 0.08380097464968193    |
| train_0/reward            | -0.856741459951445     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1964111328125        |
| train_0/target_q          | -9.806934149005306     |
| train_1/avg_q             | -7.503112789921238     |
| train_1/current_q         | -1.4986041760742705    |
| train_1/fw_bonus          | -1.001767534017563     |
| train_1/fw_loss           | 0.0004542423084785696  |
| train_1/mu_grads          | -0.014446138450875879  |
| train_1/mu_grads_std      | 0.5777542889118195     |
| train_1/mu_loss           | 1.000000000000813      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.618773564808975e-13 |
| train_1/q_grads           | -0.0030712412146385757 |
| train_1/q_grads_std       | 0.4624766357243061     |
| train_1/q_loss            | 0.001970130776440529   |
| train_1/reward            | -1.4984875166541314    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005615234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4984875166545637    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 40
Time for epoch 40: 518.59. Rollout time: 332.15, Training time: 186.41
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 40                      |
| policy/steps              | 3704727.0               |
| test/episodes             | 1025.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.51152954975283       |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.670247685926117      |
| train_0/fw_bonus          | -0.9999547213315964     |
| train_0/fw_loss           | 1.5461010423223343e-05  |
| train_0/mu_grads          | -0.08784276898950338    |
| train_0/mu_grads_std      | 0.49744011983275416     |
| train_0/mu_loss           | 9.579585396086982       |
| train_0/next_q            | -9.570650836009358      |
| train_0/q_grads           | 0.04910567356273532     |
| train_0/q_grads_std       | 0.3587722428143024      |
| train_0/q_loss            | 0.08452269273188955     |
| train_0/reward            | -0.8572048105226713     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2349853515625         |
| train_0/target_q          | -9.822111444914963      |
| train_1/avg_q             | -7.499536514157913      |
| train_1/current_q         | -1.5003705163265344     |
| train_1/fw_bonus          | -1.0015855938196183     |
| train_1/fw_loss           | 0.0004993515569367446   |
| train_1/mu_grads          | -0.014442071481607855   |
| train_1/mu_grads_std      | 0.5777558505535125      |
| train_1/mu_loss           | 1.0000000000003297      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.2306268339066736e-13 |
| train_1/q_grads           | -0.00321079968707636    |
| train_1/q_grads_std       | 0.46548418551683424     |
| train_1/q_loss            | 0.0018136780062002623   |
| train_1/reward            | -1.5002614746947074     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0006103515625         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.500261474694868      |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_40.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 41
Time for epoch 41: 516.69. Rollout time: 330.04, Training time: 186.62
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 3795852.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.509884026709435     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.661595187311688     |
| train_0/fw_bonus          | -0.9999718397855759    |
| train_0/fw_loss           | 1.1016324708634784e-05 |
| train_0/mu_grads          | -0.08861153982579709   |
| train_0/mu_grads_std      | 0.5005587607622146     |
| train_0/mu_loss           | 9.576629242180113      |
| train_0/next_q            | -9.567983116156716     |
| train_0/q_grads           | 0.04904094217345119    |
| train_0/q_grads_std       | 0.3599494032561779     |
| train_0/q_loss            | 0.084523446038447      |
| train_0/reward            | -0.8555086624517572    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2337646484375        |
| train_0/target_q          | -9.81491399078658      |
| train_1/avg_q             | -7.504936361529974     |
| train_1/current_q         | -1.4779651567102097    |
| train_1/fw_bonus          | -1.0017844498157502    |
| train_1/fw_loss           | 0.0004500474518863484  |
| train_1/mu_grads          | -0.014435606263577937  |
| train_1/mu_grads_std      | 0.5777596607804298     |
| train_1/mu_loss           | 1.0000000000004872     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.983284006306741e-13 |
| train_1/q_grads           | -0.003353321406757459  |
| train_1/q_grads_std       | 0.46617083325982095    |
| train_1/q_loss            | 0.0017461960092033703  |
| train_1/reward            | -1.478016807093809     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4780168070940394    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 520.22. Rollout time: 327.32, Training time: 192.86
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 3886977.0              |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.514326065630669     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.712891138475516     |
| train_0/fw_bonus          | -0.9999559193849563    |
| train_0/fw_loss           | 1.5149085959365038e-05 |
| train_0/mu_grads          | -0.0884859886020422    |
| train_0/mu_grads_std      | 0.5044373065233231     |
| train_0/mu_loss           | 9.625138104288528      |
| train_0/next_q            | -9.616834245900677     |
| train_0/q_grads           | 0.049327738117426634   |
| train_0/q_grads_std       | 0.3605551294982433     |
| train_0/q_loss            | 0.0842647322502066     |
| train_0/reward            | -0.8564244613255141    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2135986328125        |
| train_0/target_q          | -9.866830410244749     |
| train_1/avg_q             | -7.50244950770526      |
| train_1/current_q         | -1.4859776348782123    |
| train_1/fw_bonus          | -1.0017438143491746    |
| train_1/fw_loss           | 0.000460127124824794   |
| train_1/mu_grads          | -0.014425255288369954  |
| train_1/mu_grads_std      | 0.5777648776769638     |
| train_1/mu_loss           | 1.0000000000008007     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.292550449587865e-13 |
| train_1/q_grads           | -0.003483040409628302  |
| train_1/q_grads_std       | 0.4645056739449501     |
| train_1/q_loss            | 0.0017544667283948504  |
| train_1/reward            | -1.4859086818963987    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4859086818967557    |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 43
Time for epoch 43: 519.04. Rollout time: 332.35, Training time: 186.66
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 3977458.0              |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.558441091326683     |
| test_1/n_subgoals         | 652.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.693130086459124     |
| train_0/fw_bonus          | -0.9999547675251961    |
| train_0/fw_loss           | 1.5450541627615167e-05 |
| train_0/mu_grads          | -0.08946504537016153   |
| train_0/mu_grads_std      | 0.5084698542952537     |
| train_0/mu_loss           | 9.609696940517836      |
| train_0/next_q            | -9.600261149054482     |
| train_0/q_grads           | 0.04941237634047866    |
| train_0/q_grads_std       | 0.3612894296646118     |
| train_0/q_loss            | 0.08589734248849501    |
| train_0/reward            | -0.8571804269216955    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2010986328125        |
| train_0/target_q          | -9.845230129624753     |
| train_1/avg_q             | -7.501490134108624     |
| train_1/current_q         | -1.4882240529991304    |
| train_1/fw_bonus          | -1.0014682948589324    |
| train_1/fw_loss           | 0.0005284375329210889  |
| train_1/mu_grads          | -0.014415732584893703  |
| train_1/mu_grads_std      | 0.5777693390846252     |
| train_1/mu_loss           | 1.000000000000008      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.113349406495384e-15 |
| train_1/q_grads           | -0.003828394750598818  |
| train_1/q_grads_std       | 0.46435303539037703    |
| train_1/q_loss            | 0.006070742540574061   |
| train_1/reward            | -1.4895350699764094    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.001025390625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.489535069976413     |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 44
Time for epoch 44: 519.32. Rollout time: 332.21, Training time: 187.08
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 4068583.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.497701538957764     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.714253873525758     |
| train_0/fw_bonus          | -0.9999508172273636    |
| train_0/fw_loss           | 1.647320466418023e-05  |
| train_0/mu_grads          | -0.08837892152369023   |
| train_0/mu_grads_std      | 0.5111938551068306     |
| train_0/mu_loss           | 9.612540905232645      |
| train_0/next_q            | -9.605880079164283     |
| train_0/q_grads           | 0.04913635663688183    |
| train_0/q_grads_std       | 0.3629351004958153     |
| train_0/q_loss            | 0.08647402513046028    |
| train_0/reward            | -0.8580136552060139    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2528564453125        |
| train_0/target_q          | -9.86581627739111      |
| train_1/avg_q             | -7.516344701533499     |
| train_1/current_q         | -1.4878248491169266    |
| train_1/fw_bonus          | -1.0015509188175202    |
| train_1/fw_loss           | 0.0005079565271444153  |
| train_1/mu_grads          | -0.014415726065635681  |
| train_1/mu_grads_std      | 0.5777693390846252     |
| train_1/mu_loss           | 1.0000000000000093     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.647629570281044e-15 |
| train_1/q_grads           | -0.004215421061962843  |
| train_1/q_grads_std       | 0.4626230575144291     |
| train_1/q_loss            | 0.0016922261108641094  |
| train_1/reward            | -1.4874546857899986    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006103515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4874546857900017    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 45
Time for epoch 45: 519.75. Rollout time: 331.12, Training time: 188.60
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 45                      |
| policy/steps              | 4159708.0               |
| test/episodes             | 1150.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5007507897169745     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.590089040908106      |
| train_0/fw_bonus          | -0.9999520123004914     |
| train_0/fw_loss           | 1.616157273929275e-05   |
| train_0/mu_grads          | -0.08713854961097241    |
| train_0/mu_grads_std      | 0.5112598463892937      |
| train_0/mu_loss           | 9.500210904258214       |
| train_0/next_q            | -9.49651173220401       |
| train_0/q_grads           | 0.04969429355114698     |
| train_0/q_grads_std       | 0.36469731554389        |
| train_0/q_loss            | 0.10287133260513785     |
| train_0/reward            | -0.8571722695793141     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2759765625            |
| train_0/target_q          | -9.73852252903023       |
| train_1/avg_q             | -7.501736465157353      |
| train_1/current_q         | -1.476133566060422      |
| train_1/fw_bonus          | -1.0014670848846436     |
| train_1/fw_loss           | 0.0005287363979732618   |
| train_1/mu_grads          | -0.014415720477700233   |
| train_1/mu_grads_std      | 0.5777693390846252      |
| train_1/mu_loss           | 1.0000000000000018      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.8326619218265677e-15 |
| train_1/q_grads           | -0.004413152602501214   |
| train_1/q_grads_std       | 0.4613687567412853      |
| train_1/q_loss            | 0.0017758675978856498   |
| train_1/reward            | -1.4760148790010135     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000439453125          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4760148790010141     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 46
Time for epoch 46: 523.44. Rollout time: 333.55, Training time: 189.87
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 4250833.0              |
| test/episodes             | 1175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.320157238267552     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.734759509285656     |
| train_0/fw_bonus          | -0.9999361112713814    |
| train_0/fw_loss           | 2.029223501267552e-05  |
| train_0/mu_grads          | -0.08768767789006233   |
| train_0/mu_grads_std      | 0.5110101029276848     |
| train_0/mu_loss           | 9.63334018438482       |
| train_0/next_q            | -9.629764063707723     |
| train_0/q_grads           | 0.04959095176309347    |
| train_0/q_grads_std       | 0.36615526899695394    |
| train_0/q_loss            | 0.09856960379453943    |
| train_0/reward            | -0.859351502575737     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.150048828125         |
| train_0/target_q          | -9.884859016669811     |
| train_1/avg_q             | -7.4960647239977725    |
| train_1/current_q         | -1.4833117839556376    |
| train_1/fw_bonus          | -1.001417237520218     |
| train_1/fw_loss           | 0.0005411001009633764  |
| train_1/mu_grads          | -0.014415720477700233  |
| train_1/mu_grads_std      | 0.5777693390846252     |
| train_1/mu_loss           | 1.0000000000000007     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.542196567272245e-16 |
| train_1/q_grads           | -0.004443954688031227  |
| train_1/q_grads_std       | 0.4627968542277813     |
| train_1/q_loss            | 0.016250266657160867   |
| train_1/reward            | -1.4881600995417101    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00068359375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4881600995417101    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 47
Time for epoch 47: 534.69. Rollout time: 344.12, Training time: 190.54
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 4340437.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5244525366669395    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.682725431100232     |
| train_0/fw_bonus          | -0.999854962527752     |
| train_0/fw_loss           | 4.13679509620124e-05   |
| train_0/mu_grads          | -0.0899375582113862    |
| train_0/mu_grads_std      | 0.5131068244576454     |
| train_0/mu_loss           | 9.563847776468299      |
| train_0/next_q            | -9.553032751074607     |
| train_0/q_grads           | 0.048558037262409925   |
| train_0/q_grads_std       | 0.3694311916828156     |
| train_0/q_loss            | 0.10761093529553356    |
| train_0/reward            | -0.8625193969724932    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1698486328125        |
| train_0/target_q          | -9.827194378211491     |
| train_1/avg_q             | -7.346830970299947     |
| train_1/current_q         | -1.5154994288420816    |
| train_1/fw_bonus          | -0.9997577026486397    |
| train_1/fw_loss           | 0.0009525967907393351  |
| train_1/mu_grads          | -0.014415640057995916  |
| train_1/mu_grads_std      | 0.57776939868927       |
| train_1/mu_loss           | 1.0000000000000047     |
| train_1/n_subgoals        | 2645.0                 |
| train_1/next_q            | -4.816693768277105e-15 |
| train_1/q_grads           | -0.00461544212885201   |
| train_1/q_grads_std       | 0.465444253385067      |
| train_1/q_loss            | 0.003963714232399558   |
| train_1/reward            | -1.516242832633725     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006103515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5162428326337267    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 48
Time for epoch 48: 532.85. Rollout time: 342.72, Training time: 190.09
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 48                      |
| policy/steps              | 4430898.0               |
| test/episodes             | 1225.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.518204156389728      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 4900.0                  |
| train/success_rate        | 0.02                    |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.750139403353689      |
| train_0/fw_bonus          | -0.9998498275876045     |
| train_0/fw_loss           | 4.27004788434715e-05    |
| train_0/mu_grads          | -0.08793095704168082    |
| train_0/mu_grads_std      | 0.5149590209126472      |
| train_0/mu_loss           | 9.624353432855685       |
| train_0/next_q            | -9.607310076234716      |
| train_0/q_grads           | 0.04845530856400728     |
| train_0/q_grads_std       | 0.371768295019865       |
| train_0/q_loss            | 0.11315570148481005     |
| train_0/reward            | -0.8673922577843769     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.1314208984375         |
| train_0/target_q          | -9.898609473137814      |
| train_1/avg_q             | -7.458882409380096      |
| train_1/current_q         | -1.505419974528142      |
| train_1/fw_bonus          | -0.9993736281991005     |
| train_1/fw_loss           | 0.001047830817697104    |
| train_1/mu_grads          | -0.014415507204830647   |
| train_1/mu_grads_std      | 0.57776939868927        |
| train_1/mu_loss           | 1.0000000000000042      |
| train_1/n_subgoals        | 2676.0                  |
| train_1/next_q            | -4.3026195919897144e-15 |
| train_1/q_grads           | -0.00440167177002877    |
| train_1/q_grads_std       | 0.46911143586039544     |
| train_1/q_loss            | 0.004033033048086387    |
| train_1/reward            | -1.5061464287500712     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00126953125           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5061464287500725     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 49
Time for epoch 49: 522.35. Rollout time: 330.76, Training time: 191.56
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 49                      |
| policy/steps              | 4522023.0               |
| test/episodes             | 1250.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.495004300452487      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5000.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.758336997829451      |
| train_0/fw_bonus          | -0.9998498365283013     |
| train_0/fw_loss           | 4.26988898198033e-05    |
| train_0/mu_grads          | -0.08775557018816471    |
| train_0/mu_grads_std      | 0.5169599369168282      |
| train_0/mu_loss           | 9.632672000335134       |
| train_0/next_q            | -9.617059855198132      |
| train_0/q_grads           | 0.048463198356330395    |
| train_0/q_grads_std       | 0.37310646697878835     |
| train_0/q_loss            | 0.10563849515696751     |
| train_0/reward            | -0.8667758076524479     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.115283203125          |
| train_0/target_q          | -9.908808950136429      |
| train_1/avg_q             | -7.5039081039992235     |
| train_1/current_q         | -1.5050092230131864     |
| train_1/fw_bonus          | -1.000069434940815      |
| train_1/fw_loss           | 0.000875299604376778    |
| train_1/mu_grads          | -0.01441536012571305    |
| train_1/mu_grads_std      | 0.5777694582939148      |
| train_1/mu_loss           | 1.000000000000011       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.1243305884686158e-14 |
| train_1/q_grads           | -0.004173396492842585   |
| train_1/q_grads_std       | 0.4726474404335022      |
| train_1/q_loss            | 0.004148560124306295    |
| train_1/reward            | -1.5054109612174216     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0011474609375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5054109612174251     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 50
Time for epoch 50: 523.60. Rollout time: 333.93, Training time: 189.64
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 50                      |
| policy/steps              | 4613148.0               |
| test/episodes             | 1275.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.495366716599666      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.753915826205718      |
| train_0/fw_bonus          | -0.9998658508062362     |
| train_0/fw_loss           | 3.8540497234862416e-05  |
| train_0/mu_grads          | -0.08826867546886205    |
| train_0/mu_grads_std      | 0.5191367715597153      |
| train_0/mu_loss           | 9.628054411843301       |
| train_0/next_q            | -9.612179449848659      |
| train_0/q_grads           | 0.04831069950014353     |
| train_0/q_grads_std       | 0.37418090328574183     |
| train_0/q_loss            | 0.1132669100888608      |
| train_0/reward            | -0.8668793692850159     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.126123046875          |
| train_0/target_q          | -9.901369368249856      |
| train_1/avg_q             | -7.493688113647272      |
| train_1/current_q         | -1.5038093148146507     |
| train_1/fw_bonus          | -1.0004557013511657     |
| train_1/fw_loss           | 0.0007795205994625576   |
| train_1/mu_grads          | -0.014415013953112066   |
| train_1/mu_grads_std      | 0.5777694582939148      |
| train_1/mu_loss           | 1.0000000000000102      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.0677133848808307e-14 |
| train_1/q_grads           | -0.0037756875331979244  |
| train_1/q_grads_std       | 0.47509523034095763     |
| train_1/q_loss            | 0.004176223022257067    |
| train_1/reward            | -1.5039855773808086     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0009521484375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5039855773808122     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 51
Time for epoch 51: 525.31. Rollout time: 335.86, Training time: 189.42
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 4704273.0              |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.509482261990575     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.690296868506232     |
| train_0/fw_bonus          | -0.999859607219696     |
| train_0/fw_loss           | 4.016080756628071e-05  |
| train_0/mu_grads          | -0.08932838644832372   |
| train_0/mu_grads_std      | 0.5219351872801781     |
| train_0/mu_loss           | 9.565297531959544      |
| train_0/next_q            | -9.550508456957122     |
| train_0/q_grads           | 0.0481373299844563     |
| train_0/q_grads_std       | 0.37517845779657366    |
| train_0/q_loss            | 0.10511579742578506    |
| train_0/reward            | -0.8640975903050275    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1711669921875        |
| train_0/target_q          | -9.836846849255352     |
| train_1/avg_q             | -7.49404516121434      |
| train_1/current_q         | -1.4937006210256523    |
| train_1/fw_bonus          | -1.0006645500659943    |
| train_1/fw_loss           | 0.0007277357231942006  |
| train_1/mu_grads          | -0.014380665798671543  |
| train_1/mu_grads_std      | 0.5777782037854194     |
| train_1/mu_loss           | 1.0000000000007927     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -8.070787855364562e-13 |
| train_1/q_grads           | -0.003538902569562197  |
| train_1/q_grads_std       | 0.4779791601002216     |
| train_1/q_loss            | 0.0027444231933962983  |
| train_1/reward            | -1.4938089597591897    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00078125             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4938089597595219    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 52
Time for epoch 52: 470.94. Rollout time: 299.48, Training time: 171.43
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 52                      |
| policy/steps              | 4795398.0               |
| test/episodes             | 1325.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5068794141118795     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.735709925428376      |
| train_0/fw_bonus          | -0.9999058336019516     |
| train_0/fw_loss           | 2.8156089706499186e-05  |
| train_0/mu_grads          | -0.09022112376987934    |
| train_0/mu_grads_std      | 0.5238094106316566      |
| train_0/mu_loss           | 9.633901730148475       |
| train_0/next_q            | -9.621786923131271      |
| train_0/q_grads           | 0.04818550711497664     |
| train_0/q_grads_std       | 0.3760670699179173      |
| train_0/q_loss            | 0.09653731181808325     |
| train_0/reward            | -0.8607142904671491     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.178125                |
| train_0/target_q          | -9.891100292726392      |
| train_1/avg_q             | -7.499790196545643      |
| train_1/current_q         | -1.5089623902433558     |
| train_1/fw_bonus          | -1.001177680492401      |
| train_1/fw_loss           | 0.0006005000512232072   |
| train_1/mu_grads          | -0.014342909678816795   |
| train_1/mu_grads_std      | 0.577801625430584       |
| train_1/mu_loss           | 1.000000000001552       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.5711960044102533e-12 |
| train_1/q_grads           | -0.003328286448959261   |
| train_1/q_grads_std       | 0.4778340272605419      |
| train_1/q_loss            | 0.0019024061571901274   |
| train_1/reward            | -1.5086042116308818     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.00068359375           |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5086042116314435     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 53
Time for epoch 53: 471.44. Rollout time: 299.18, Training time: 172.24
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 4886523.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.510177526659654     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.629187567080766     |
| train_0/fw_bonus          | -0.9999763160943985    |
| train_0/fw_loss           | 9.855150312887418e-06  |
| train_0/mu_grads          | -0.09162956699728966   |
| train_0/mu_grads_std      | 0.5257174506783485     |
| train_0/mu_loss           | 9.546541385720165      |
| train_0/next_q            | -9.539479601137389     |
| train_0/q_grads           | 0.04820713941007852    |
| train_0/q_grads_std       | 0.3762440413236618     |
| train_0/q_loss            | 0.08524388584079715    |
| train_0/reward            | -0.8545781776585499    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3323486328125        |
| train_0/target_q          | -9.781193364755604     |
| train_1/avg_q             | -7.4975255826875244    |
| train_1/current_q         | -1.499311620125474     |
| train_1/fw_bonus          | -1.0014002650976181    |
| train_1/fw_loss           | 0.0005453132260299753  |
| train_1/mu_grads          | -0.014281740481965243  |
| train_1/mu_grads_std      | 0.577842615544796      |
| train_1/mu_loss           | 1.000000000000627      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.069788523672635e-13 |
| train_1/q_grads           | -0.0031189382716547698 |
| train_1/q_grads_std       | 0.4777056433260441     |
| train_1/q_loss            | 0.006509281334081818   |
| train_1/reward            | -1.502484514551179     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5024845145513837    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 54
Time for epoch 54: 470.44. Rollout time: 298.05, Training time: 172.35
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 54                      |
| policy/steps              | 4977648.0               |
| test/episodes             | 1375.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.524543280851652      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5500.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.64653875043366       |
| train_0/fw_bonus          | -0.9999634265899658     |
| train_0/fw_loss           | 1.320132993214429e-05   |
| train_0/mu_grads          | -0.09371158480644226    |
| train_0/mu_grads_std      | 0.5290265679359436      |
| train_0/mu_loss           | 9.560663152630408       |
| train_0/next_q            | -9.554338351360823      |
| train_0/q_grads           | 0.04785410789772868     |
| train_0/q_grads_std       | 0.3770184420049191      |
| train_0/q_loss            | 0.08601760193456752     |
| train_0/reward            | -0.8550690023141214     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2704345703125         |
| train_0/target_q          | -9.799360754860384      |
| train_1/avg_q             | -7.501280290157431      |
| train_1/current_q         | -1.4888307874868179     |
| train_1/fw_bonus          | -1.0015181303024292     |
| train_1/fw_loss           | 0.0005160842374607455   |
| train_1/mu_grads          | -0.014280324289575218   |
| train_1/mu_grads_std      | 0.5778432294726372      |
| train_1/mu_loss           | 1.0000000000001221      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.1975771335808591e-13 |
| train_1/q_grads           | -0.003236911742715165   |
| train_1/q_grads_std       | 0.47781701311469077     |
| train_1/q_loss            | 0.001830437190504608    |
| train_1/reward            | -1.4886202869776752     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000732421875          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4886202869777194     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 55
Time for epoch 55: 470.01. Rollout time: 300.33, Training time: 169.65
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 5068773.0              |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.50795512651132      |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.6555425519457       |
| train_0/fw_bonus          | -0.9999600186944008    |
| train_0/fw_loss           | 1.4084847418871504e-05 |
| train_0/mu_grads          | -0.09497903194278479   |
| train_0/mu_grads_std      | 0.5321015760302543     |
| train_0/mu_loss           | 9.569149464133217      |
| train_0/next_q            | -9.562722334890534     |
| train_0/q_grads           | 0.04737617680802941    |
| train_0/q_grads_std       | 0.3777206212282181     |
| train_0/q_loss            | 0.08709188082385075    |
| train_0/reward            | -0.8554387655705795    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2603515625           |
| train_0/target_q          | -9.807312109984087     |
| train_1/avg_q             | -7.507554695037624     |
| train_1/current_q         | -1.4610400158517298    |
| train_1/fw_bonus          | -1.0016817510128022    |
| train_1/fw_loss           | 0.000475508227100363   |
| train_1/mu_grads          | -0.014277291460894048  |
| train_1/mu_grads_std      | 0.577844500541687      |
| train_1/mu_loss           | 1.0000000000001865     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.69109176770584e-13  |
| train_1/q_grads           | -0.0031857217254582793 |
| train_1/q_grads_std       | 0.47849075868725777    |
| train_1/q_loss            | 0.0017828188644146744  |
| train_1/reward            | -1.4612466797319938    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.461246679732063     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 56
Time for epoch 56: 468.02. Rollout time: 296.24, Training time: 171.75
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 56                      |
| policy/steps              | 5159898.0               |
| test/episodes             | 1425.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.507096273683296      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5700.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.675530050391822      |
| train_0/fw_bonus          | -0.9999821498990059     |
| train_0/fw_loss           | 8.337881922670931e-06   |
| train_0/mu_grads          | -0.0949565064162016     |
| train_0/mu_grads_std      | 0.5351175963878632      |
| train_0/mu_loss           | 9.58887188321458        |
| train_0/next_q            | -9.584701081438885      |
| train_0/q_grads           | 0.047522359900176524    |
| train_0/q_grads_std       | 0.3775469817221165      |
| train_0/q_loss            | 0.09086551427477815     |
| train_0/reward            | -0.8550525302867754     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.3392578125            |
| train_0/target_q          | -9.82829778366961       |
| train_1/avg_q             | -7.498478161977308      |
| train_1/current_q         | -1.488969938677022      |
| train_1/fw_bonus          | -1.0016319632530213     |
| train_1/fw_loss           | 0.00048785924445837736  |
| train_1/mu_grads          | -0.014038981962949037   |
| train_1/mu_grads_std      | 0.5779967531561852      |
| train_1/mu_loss           | 1.000000000003031       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -3.0630562803824686e-12 |
| train_1/q_grads           | -0.0032841481151990592  |
| train_1/q_grads_std       | 0.4786388650536537      |
| train_1/q_loss            | 0.0017251149461494023   |
| train_1/reward            | -1.4888521436980227     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0005859375            |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4888521436990334     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 57
Time for epoch 57: 472.10. Rollout time: 301.32, Training time: 170.75
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 57                      |
| policy/steps              | 5251023.0               |
| test/episodes             | 1450.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.500468209256794      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 5800.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.578839642131763      |
| train_0/fw_bonus          | -0.9999719858169556     |
| train_0/fw_loss           | 1.097720044072048e-05   |
| train_0/mu_grads          | -0.0944462113082409     |
| train_0/mu_grads_std      | 0.5374317735433578      |
| train_0/mu_loss           | 9.495659348478844       |
| train_0/next_q            | -9.488238255691423      |
| train_0/q_grads           | 0.047436789702624084    |
| train_0/q_grads_std       | 0.37779917418956754     |
| train_0/q_loss            | 0.08734651474745943     |
| train_0/reward            | -0.8547336288262158     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.322216796875          |
| train_0/target_q          | -9.733227372286109      |
| train_1/avg_q             | -7.50087677317974       |
| train_1/current_q         | -1.4914285538955458     |
| train_1/fw_bonus          | -1.0015547841787338     |
| train_1/fw_loss           | 0.0005069991042546462   |
| train_1/mu_grads          | -0.014004526985809207   |
| train_1/mu_grads_std      | 0.5780133932828904      |
| train_1/mu_loss           | 1.000000000001379       |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.1917891573018904e-12 |
| train_1/q_grads           | -0.0032674466376192866  |
| train_1/q_grads_std       | 0.47978279665112494     |
| train_1/q_loss            | 0.0016699316202660858   |
| train_1/reward            | -1.4913272106728983     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0005615234375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4913272106733384     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 58
Time for epoch 58: 477.80. Rollout time: 301.69, Training time: 176.08
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 5342148.0              |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.480489740734516     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.705881621458904     |
| train_0/fw_bonus          | -0.9999760821461677    |
| train_0/fw_loss           | 9.915079920119751e-06  |
| train_0/mu_grads          | -0.09436171893030405   |
| train_0/mu_grads_std      | 0.5399341106414794     |
| train_0/mu_loss           | 9.622660106967153      |
| train_0/next_q            | -9.617094575710762     |
| train_0/q_grads           | 0.04732742579653859    |
| train_0/q_grads_std       | 0.378430500626564      |
| train_0/q_loss            | 0.08742738634982108    |
| train_0/reward            | -0.8554447040747618    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.29404296875          |
| train_0/target_q          | -9.859706114815555     |
| train_1/avg_q             | -7.49907723936819      |
| train_1/current_q         | -1.5075228472885835    |
| train_1/fw_bonus          | -1.0016906172037126    |
| train_1/fw_loss           | 0.0004733147099614143  |
| train_1/mu_grads          | -0.01396713915746659   |
| train_1/mu_grads_std      | 0.5780278861522674     |
| train_1/mu_loss           | 1.000000000000915      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.801583105796529e-12 |
| train_1/q_grads           | -0.003400540165603161  |
| train_1/q_grads_std       | 0.4807075135409832     |
| train_1/q_loss            | 0.0015238344827984203  |
| train_1/reward            | -1.5074447209146455    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5074447209157271    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 59
Time for epoch 59: 473.53. Rollout time: 297.64, Training time: 175.87
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 5433273.0              |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.537015405124836     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.698846364323268     |
| train_0/fw_bonus          | -0.9999710455536842    |
| train_0/fw_loss           | 1.1223962781059527e-05 |
| train_0/mu_grads          | -0.09482595231384039   |
| train_0/mu_grads_std      | 0.5429303750395775     |
| train_0/mu_loss           | 9.616579524295705      |
| train_0/next_q            | -9.611360185493059     |
| train_0/q_grads           | 0.04716682340949774    |
| train_0/q_grads_std       | 0.3792323499917984     |
| train_0/q_loss            | 0.0872998502233479     |
| train_0/reward            | -0.8549953672962147    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2908935546875        |
| train_0/target_q          | -9.852648823166145     |
| train_1/avg_q             | -7.491574335655112     |
| train_1/current_q         | -1.4978040656852103    |
| train_1/fw_bonus          | -1.0017341405153275    |
| train_1/fw_loss           | 0.0004625237997970544  |
| train_1/mu_grads          | -0.01392797997687012   |
| train_1/mu_grads_std      | 0.5780473038554191     |
| train_1/mu_loss           | 1.0000000000022446     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -2.24269000596841e-12  |
| train_1/q_grads           | -0.003355921700131148  |
| train_1/q_grads_std       | 0.4818137414753437     |
| train_1/q_loss            | 0.0015766858730583548  |
| train_1/reward            | -1.4975835613382515    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4975835613392132    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 60
Time for epoch 60: 475.22. Rollout time: 300.85, Training time: 174.34
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 5524398.0              |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.543920865111434     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.68727394771539      |
| train_0/fw_bonus          | -0.9999831885099411    |
| train_0/fw_loss           | 8.069899683960102e-06  |
| train_0/mu_grads          | -0.09500707257539034   |
| train_0/mu_grads_std      | 0.5458167538046836     |
| train_0/mu_loss           | 9.601818559776857      |
| train_0/next_q            | -9.5962934229245       |
| train_0/q_grads           | 0.04688817821443081    |
| train_0/q_grads_std       | 0.38021459728479384    |
| train_0/q_loss            | 0.08705734007166763    |
| train_0/reward            | -0.8551448569574859    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3398193359375        |
| train_0/target_q          | -9.841913110453884     |
| train_1/avg_q             | -7.509259508621075     |
| train_1/current_q         | -1.5029179280545195    |
| train_1/fw_bonus          | -1.0016183882951737    |
| train_1/fw_loss           | 0.0004912206524750218  |
| train_1/mu_grads          | -0.013898550299927592  |
| train_1/mu_grads_std      | 0.5780634939670563     |
| train_1/mu_loss           | 1.0000000000003357     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -2.896534626195122e-13 |
| train_1/q_grads           | -0.0036384356790222228 |
| train_1/q_grads_std       | 0.48239137083292005    |
| train_1/q_loss            | 0.0017247932121512467  |
| train_1/reward            | -1.502843440794095     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006103515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.502843440794189     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 61
Time for epoch 61: 472.20. Rollout time: 297.76, Training time: 174.41
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 61                     |
| policy/steps              | 5615523.0              |
| test/episodes             | 1550.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.512305841629134     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.704005989481777     |
| train_0/fw_bonus          | -0.9999805301427841    |
| train_0/fw_loss           | 8.758413730447501e-06  |
| train_0/mu_grads          | -0.09432502742856741   |
| train_0/mu_grads_std      | 0.5490079805254936     |
| train_0/mu_loss           | 9.623225191484943      |
| train_0/next_q            | -9.617211014216164     |
| train_0/q_grads           | 0.04690726986154914    |
| train_0/q_grads_std       | 0.38153692334890366    |
| train_0/q_loss            | 0.0879636589381376     |
| train_0/reward            | -0.8552161108556902    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.33798828125          |
| train_0/target_q          | -9.857460771484577     |
| train_1/avg_q             | -7.513797261615799     |
| train_1/current_q         | -1.485051718131561     |
| train_1/fw_bonus          | -1.0014554589986802    |
| train_1/fw_loss           | 0.0005316257818776648  |
| train_1/mu_grads          | -0.013898410834372044  |
| train_1/mu_grads_std      | 0.5780635476112366     |
| train_1/mu_loss           | 1.0000000000000002     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.203634673041218e-17 |
| train_1/q_grads           | -0.004127575864549727  |
| train_1/q_grads_std       | 0.48265096470713614    |
| train_1/q_loss            | 0.001469287229725899   |
| train_1/reward            | -1.4850393423243076    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0006591796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4850393423243076    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 472.65. Rollout time: 294.86, Training time: 177.76
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 62                     |
| policy/steps              | 5706648.0              |
| test/episodes             | 1575.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.518181922217587     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.672613726759954     |
| train_0/fw_bonus          | -0.9999587312340736    |
| train_0/fw_loss           | 1.4417870988836513e-05 |
| train_0/mu_grads          | -0.09529564343392849   |
| train_0/mu_grads_std      | 0.5514344051480293     |
| train_0/mu_loss           | 9.590054919896962      |
| train_0/next_q            | -9.584287532716484     |
| train_0/q_grads           | 0.04669175753369927    |
| train_0/q_grads_std       | 0.38288194835186007    |
| train_0/q_loss            | 0.08582777616342555    |
| train_0/reward            | -0.8544795516863815    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2727294921875        |
| train_0/target_q          | -9.826093802542598     |
| train_1/avg_q             | -7.505629587422038     |
| train_1/current_q         | -1.495122442055529     |
| train_1/fw_bonus          | -1.0018387228250503    |
| train_1/fw_loss           | 0.00043659457078319973 |
| train_1/mu_grads          | -0.013898404315114021  |
| train_1/mu_grads_std      | 0.5780635476112366     |
| train_1/mu_loss           | 1.0000000000000007     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.129973317584603e-16 |
| train_1/q_grads           | -0.0042480875737965105 |
| train_1/q_grads_std       | 0.4827788665890694     |
| train_1/q_loss            | 0.0014174479483187274  |
| train_1/reward            | -1.49506799580995      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0004638671875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.49506799580995      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 474.30. Rollout time: 298.70, Training time: 175.58
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 5797773.0              |
| test/episodes             | 1600.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5012246643857114    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.551782091802407     |
| train_0/fw_bonus          | -0.9999830842018127    |
| train_0/fw_loss           | 8.094049456985886e-06  |
| train_0/mu_grads          | -0.0949642276391387    |
| train_0/mu_grads_std      | 0.5534021526575088     |
| train_0/mu_loss           | 9.469121671621465      |
| train_0/next_q            | -9.463946680664105     |
| train_0/q_grads           | 0.046502060070633885   |
| train_0/q_grads_std       | 0.38393272235989573    |
| train_0/q_loss            | 0.08522640668199757    |
| train_0/reward            | -0.8531184201769065    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.3480712890625        |
| train_0/target_q          | -9.702939972047663     |
| train_1/avg_q             | -7.507893761194681     |
| train_1/current_q         | -1.5101102753268516    |
| train_1/fw_bonus          | -1.0015814512968064    |
| train_1/fw_loss           | 0.0005003835656680166  |
| train_1/mu_grads          | -0.013898373581469059  |
| train_1/mu_grads_std      | 0.5780635476112366     |
| train_1/mu_loss           | 1.0                    |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.989776398821626e-17 |
| train_1/q_grads           | -0.004347295488696545  |
| train_1/q_grads_std       | 0.4827018931508064     |
| train_1/q_loss            | 0.0013793916634811006  |
| train_1/reward            | -1.5099751505826133    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000537109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5099751505826133    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 64
Time for epoch 64: 473.49. Rollout time: 296.81, Training time: 176.65
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 5888898.0              |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.4834352443423215    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.560974253095925     |
| train_0/fw_bonus          | -0.9999774128198624    |
| train_0/fw_loss           | 9.567077518113365e-06  |
| train_0/mu_grads          | -0.09524002857506275   |
| train_0/mu_grads_std      | 0.5556028619408607     |
| train_0/mu_loss           | 9.478001345787609      |
| train_0/next_q            | -9.472024136099765     |
| train_0/q_grads           | 0.04627484744414687    |
| train_0/q_grads_std       | 0.3854313582181931     |
| train_0/q_loss            | 0.08586184199597957    |
| train_0/reward            | -0.8540541071881307    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.34931640625          |
| train_0/target_q          | -9.71390709366257      |
| train_1/avg_q             | -7.501774937622596     |
| train_1/current_q         | -1.4969587572330147    |
| train_1/fw_bonus          | -1.0017422169446946    |
| train_1/fw_loss           | 0.00046052195903030225 |
| train_1/mu_grads          | -0.013898373581469059  |
| train_1/mu_grads_std      | 0.5780635476112366     |
| train_1/mu_loss           | 1.0                    |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -9.344461158028277e-17 |
| train_1/q_grads           | -0.004387373907957226  |
| train_1/q_grads_std       | 0.48341709077358247    |
| train_1/q_loss            | 0.001272685794265531   |
| train_1/reward            | -1.4968999191056356    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005859375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4968999191056356    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 65
Time for epoch 65: 477.47. Rollout time: 297.58, Training time: 179.86
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 65                      |
| policy/steps              | 5980023.0               |
| test/episodes             | 1650.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.5088755071920685     |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 6600.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.637049838695182      |
| train_0/fw_bonus          | -0.9999759703874588     |
| train_0/fw_loss           | 9.941458432649598e-06   |
| train_0/mu_grads          | -0.09588226843625307    |
| train_0/mu_grads_std      | 0.5561075612902642      |
| train_0/mu_loss           | 9.555529901430772       |
| train_0/next_q            | -9.549047698403758      |
| train_0/q_grads           | 0.04614206086844206     |
| train_0/q_grads_std       | 0.38656307086348535     |
| train_0/q_loss            | 0.08609812607230301     |
| train_0/reward            | -0.8547427234181668     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.2830078125            |
| train_0/target_q          | -9.788486428785523      |
| train_1/avg_q             | -7.496348101237888      |
| train_1/current_q         | -1.4938442083649939     |
| train_1/fw_bonus          | -1.00174278318882       |
| train_1/fw_loss           | 0.00046037822248763406  |
| train_1/mu_grads          | -0.013898373581469059   |
| train_1/mu_grads_std      | 0.5780635476112366      |
| train_1/mu_loss           | 1.0000000000000002      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -2.3522937362507046e-16 |
| train_1/q_grads           | -0.004645473195705563   |
| train_1/q_grads_std       | 0.4836518831551075      |
| train_1/q_loss            | 0.00130491508858535     |
| train_1/reward            | -1.4938608032549383     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0009521484375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.4938608032549383     |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 66
Time for epoch 66: 477.38. Rollout time: 300.10, Training time: 177.25
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 6071148.0              |
| test/episodes             | 1675.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.505980714120093     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.693006269987588     |
| train_0/fw_bonus          | -0.9999688044190407    |
| train_0/fw_loss           | 1.1801473169725795e-05 |
| train_0/mu_grads          | -0.09640526957809925   |
| train_0/mu_grads_std      | 0.5563505202531814     |
| train_0/mu_loss           | 9.600943975437294      |
| train_0/next_q            | -9.594706841434345     |
| train_0/q_grads           | 0.045913318172097206   |
| train_0/q_grads_std       | 0.3880766876041889     |
| train_0/q_loss            | 0.08679646675429063    |
| train_0/reward            | -0.8569590314742527    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2823974609375        |
| train_0/target_q          | -9.849787763883628     |
| train_1/avg_q             | -7.502217526283841     |
| train_1/current_q         | -1.5050556500292611    |
| train_1/fw_bonus          | -1.0017216980457306    |
| train_1/fw_loss           | 0.00046560871196561494 |
| train_1/mu_grads          | -0.013883174606598913  |
| train_1/mu_grads_std      | 0.5780743166804314     |
| train_1/mu_loss           | 1.0000000000019422     |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -1.920274557797417e-12 |
| train_1/q_grads           | -0.004970582795795053  |
| train_1/q_grads_std       | 0.4850000344216824     |
| train_1/q_loss            | 0.0014709086566475986  |
| train_1/reward            | -1.505069347456447     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0005126953125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5050693474572983    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 67
Time for epoch 67: 478.48. Rollout time: 300.48, Training time: 177.97
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 6162273.0              |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.474781940984538     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.68343546348252      |
| train_0/fw_bonus          | -0.9999520525336265    |
| train_0/fw_loss           | 1.6153643923644267e-05 |
| train_0/mu_grads          | -0.0969941472634673    |
| train_0/mu_grads_std      | 0.55691127628088       |
| train_0/mu_loss           | 9.588804981688394      |
| train_0/next_q            | -9.582305997032828     |
| train_0/q_grads           | 0.045382557064294816   |
| train_0/q_grads_std       | 0.38928934633731843    |
| train_0/q_loss            | 0.08855214626689906    |
| train_0/reward            | -0.8582648221054114    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2664306640625        |
| train_0/target_q          | -9.83852063941911      |
| train_1/avg_q             | -7.499954562920897     |
| train_1/current_q         | -1.4868113966232275    |
| train_1/fw_bonus          | -1.0013278543949127    |
| train_1/fw_loss           | 0.0005632652508211322  |
| train_1/mu_grads          | -0.013654496939852833  |
| train_1/mu_grads_std      | 0.578192238509655      |
| train_1/mu_loss           | 1.000000000003646      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.482952195933533e-12 |
| train_1/q_grads           | -0.004645830555818975  |
| train_1/q_grads_std       | 0.4865864314138889     |
| train_1/q_loss            | 0.0017028211490718466  |
| train_1/reward            | -1.4871164942727773    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.00087890625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4871164942752917    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 490.30. Rollout time: 311.30, Training time: 178.97
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 68                     |
| policy/steps              | 6253398.0              |
| test/episodes             | 1725.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.5037219942913715    |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 6900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.745671099589973     |
| train_0/fw_bonus          | -0.9999101161956787    |
| train_0/fw_loss           | 2.7043448835684102e-05 |
| train_0/mu_grads          | -0.097510283626616     |
| train_0/mu_grads_std      | 0.5584520667791366     |
| train_0/mu_loss           | 9.64743144216541       |
| train_0/next_q            | -9.640860271253983     |
| train_0/q_grads           | 0.04534619310870767    |
| train_0/q_grads_std       | 0.3904674120247364     |
| train_0/q_loss            | 0.09489404419824002    |
| train_0/reward            | -0.8598752184974728    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1993408203125        |
| train_0/target_q          | -9.901774919919392     |
| train_1/avg_q             | -7.433237763999856     |
| train_1/current_q         | -1.4764040330274224    |
| train_1/fw_bonus          | -1.000596171617508     |
| train_1/fw_loss           | 0.0007446900781360455  |
| train_1/mu_grads          | -0.013605306996032596  |
| train_1/mu_grads_std      | 0.5782268077135087     |
| train_1/mu_loss           | 1.000000000000109      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -6.850723673637305e-14 |
| train_1/q_grads           | -0.005478790134657174  |
| train_1/q_grads_std       | 0.48874266594648363    |
| train_1/q_loss            | 0.00246485173833039    |
| train_1/reward            | -1.4764420037099626    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000732421875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4764420037099986    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 484.02. Rollout time: 304.19, Training time: 179.80
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 6344523.0              |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.525972480610494     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.775015587508928     |
| train_0/fw_bonus          | -0.9999156087636948    |
| train_0/fw_loss           | 2.5616195762268036e-05 |
| train_0/mu_grads          | -0.09789245873689652   |
| train_0/mu_grads_std      | 0.558323846757412      |
| train_0/mu_loss           | 9.662560685135588      |
| train_0/next_q            | -9.655565101892458     |
| train_0/q_grads           | 0.04559510434046388    |
| train_0/q_grads_std       | 0.3914826065301895     |
| train_0/q_loss            | 0.09505710466836162    |
| train_0/reward            | -0.8628090281024925    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2586669921875        |
| train_0/target_q          | -9.929038039911655     |
| train_1/avg_q             | -7.494028691758486     |
| train_1/current_q         | -1.502702384984462     |
| train_1/fw_bonus          | -1.0004990205168725    |
| train_1/fw_loss           | 0.0007687784382142127  |
| train_1/mu_grads          | -0.01263429329264909   |
| train_1/mu_grads_std      | 0.5787494435906411     |
| train_1/mu_loss           | 1.000000000000775      |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -4.018206100542218e-13 |
| train_1/q_grads           | -0.00602779375622049   |
| train_1/q_grads_std       | 0.4922485835850239     |
| train_1/q_loss            | 0.002195842907399245   |
| train_1/reward            | -1.5026203648485534    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0008056640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.5026203648488177    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 500.89. Rollout time: 310.67, Training time: 190.19
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 70                      |
| policy/steps              | 6435648.0               |
| test/episodes             | 1775.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.489367984924231      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7100.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.73195641726402       |
| train_0/fw_bonus          | -0.9999168679118157     |
| train_0/fw_loss           | 2.5292317582170652e-05  |
| train_0/mu_grads          | -0.0992061598226428     |
| train_0/mu_grads_std      | 0.5601421132683754      |
| train_0/mu_loss           | 9.62018014626111        |
| train_0/next_q            | -9.611612868398533      |
| train_0/q_grads           | 0.04603925487026572     |
| train_0/q_grads_std       | 0.39254084378480913     |
| train_0/q_loss            | 0.09545600178022044     |
| train_0/reward            | -0.8625047874564189     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.24951171875           |
| train_0/target_q          | -9.886078299774695      |
| train_1/avg_q             | -7.502756821425775      |
| train_1/current_q         | -1.505414175026444      |
| train_1/fw_bonus          | -1.0007230371236802     |
| train_1/fw_loss           | 0.0007132378988899291   |
| train_1/mu_grads          | -0.012453349307179451   |
| train_1/mu_grads_std      | 0.5788560509681702      |
| train_1/mu_loss           | 1.0000000000000029      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.3710817245198023e-15 |
| train_1/q_grads           | -0.006607135152444243   |
| train_1/q_grads_std       | 0.4960970625281334      |
| train_1/q_loss            | 0.0022730649880677153   |
| train_1/reward            | -1.5051382116718741     |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.000634765625          |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.5051382116718748     |
-------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 552.39. Rollout time: 342.90, Training time: 209.46
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 6526773.0              |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -27.0                  |
| test_1/avg_q              | -7.500506101407373     |
| test_1/n_subgoals         | 675.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -27.0                  |
| train_0/current_q         | -9.606263253536273     |
| train_0/fw_bonus          | -0.9999102637171745    |
| train_0/fw_loss           | 2.7007407766177494e-05 |
| train_0/mu_grads          | -0.09852386731654406   |
| train_0/mu_grads_std      | 0.5628012508153916     |
| train_0/mu_loss           | 9.50602019639488       |
| train_0/next_q            | -9.496308631972934     |
| train_0/q_grads           | 0.046087254956364634   |
| train_0/q_grads_std       | 0.3935999497771263     |
| train_0/q_loss            | 0.09325161469727472    |
| train_0/reward            | -0.8586668266565539    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1953857421875        |
| train_0/target_q          | -9.756893874191302     |
| train_1/avg_q             | -7.483500964065009     |
| train_1/current_q         | -1.4984080373668167    |
| train_1/fw_bonus          | -1.0006769716739654    |
| train_1/fw_loss           | 0.0007246568900882266  |
| train_1/mu_grads          | -0.01244651060551405   |
| train_1/mu_grads_std      | 0.5788602828979492     |
| train_1/mu_loss           | 1.00000000000001       |
| train_1/n_subgoals        | 2700.0                 |
| train_1/next_q            | -2.720884644711449e-15 |
| train_1/q_grads           | -0.006889356952160597  |
| train_1/q_grads_std       | 0.5003039970993995     |
| train_1/q_loss            | 0.0019534260030066725  |
| train_1/reward            | -1.4983287700539223    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0007568359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.0                    |
| train_1/target_q          | -1.4983287700539236    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 554.87. Rollout time: 343.55, Training time: 211.29
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:27,27|102
-------------------------------------------------------
| epoch                     | 72                      |
| policy/steps              | 6617898.0               |
| test/episodes             | 1825.0                  |
| test/success_rate         | 0.0                     |
| test_0/avg_q              | -27.0                   |
| test_1/avg_q              | -7.568526496375241      |
| test_1/n_subgoals         | 675.0                   |
| test_1/subgoal_succ_rate  | 0.0                     |
| train/episodes            | 7300.0                  |
| train/success_rate        | 0.0                     |
| train_0/avg_q             | -27.0                   |
| train_0/current_q         | -9.768443712957586      |
| train_0/fw_bonus          | -0.9999409019947052     |
| train_0/fw_loss           | 1.9049063303100412e-05  |
| train_0/mu_grads          | -0.09898170810192823    |
| train_0/mu_grads_std      | 0.5646225586533546      |
| train_0/mu_loss           | 9.671973550671883       |
| train_0/next_q            | -9.664418135586388      |
| train_0/q_grads           | 0.04598420886322856     |
| train_0/q_grads_std       | 0.3957991376519203      |
| train_0/q_loss            | 0.09230748930071987     |
| train_0/reward            | -0.8591048488655361     |
| train_0/reward_-0.0_frac  | 0.0                     |
| train_0/reward_-1.0_frac  | 0.27001953125           |
| train_0/target_q          | -9.92333620740249       |
| train_1/avg_q             | -7.4970858017003845     |
| train_1/current_q         | -1.4914194539730623     |
| train_1/fw_bonus          | -1.0007983803749085     |
| train_1/fw_loss           | 0.0006945550456293858   |
| train_1/mu_grads          | -0.012446461245417595   |
| train_1/mu_grads_std      | 0.578860342502594       |
| train_1/mu_loss           | 1.0000000000000004      |
| train_1/n_subgoals        | 2700.0                  |
| train_1/next_q            | -1.4448851281301816e-16 |
| train_1/q_grads           | -0.006995712860953063   |
| train_1/q_grads_std       | 0.5020393341779709      |
| train_1/q_loss            | 0.00558121854531973     |
| train_1/reward            | -1.491266499386984      |
| train_1/reward_-0.0_frac  | 0.0                     |
| train_1/reward_-1.0_frac  | 0.0009521484375         |
| train_1/reward_-27.0_frac | 0.0                     |
| train_1/subgoal_succ_rate | 0.0                     |
| train_1/target_q          | -1.491266499386984      |
-------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
