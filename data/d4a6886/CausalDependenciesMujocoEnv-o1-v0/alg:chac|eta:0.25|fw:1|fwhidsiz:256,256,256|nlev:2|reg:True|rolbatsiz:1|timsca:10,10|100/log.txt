Starting process id: 3896
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.25
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fb4a9974320>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 25
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: True
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 10,10
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 10
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 10
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 294.23. Rollout time: 59.94, Training time: 234.23
Evaluating epoch 0
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 10856.0                |
| test/episodes             | 25.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -7.769734551451914     |
| test_1/avg_q              | -7.943366857669217     |
| test_1/n_subgoals         | 361.0                  |
| test_1/subgoal_succ_rate  | 0.3601108033240997     |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.528851147956879     |
| train_0/current_q         | -3.2987475001049185    |
| train_0/fw_bonus          | -0.9991848513484001    |
| train_0/fw_loss           | 0.00017471045903221237 |
| train_0/mu_grads          | -0.007108936773147434  |
| train_0/mu_grads_std      | 0.1573650199919939     |
| train_0/mu_loss           | 3.205870000229986      |
| train_0/next_q            | -3.1777111756437924    |
| train_0/q_grads           | 0.039006298407912254   |
| train_0/q_grads_std       | 0.22212553694844245    |
| train_0/q_loss            | 0.506698102748995      |
| train_0/reward            | -0.8617238384060328    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.01630859375          |
| train_0/target_q          | -3.4617791101121043    |
| train_1/avg_q             | -3.4981102001293873    |
| train_1/current_q         | -4.856348164571388     |
| train_1/fw_bonus          | -1.0061473309993745    |
| train_1/fw_loss           | 0.0013531894714105875  |
| train_1/mu_grads          | 0.017785196052864195   |
| train_1/mu_grads_std      | 0.08533903695642948    |
| train_1/mu_loss           | 5.174390809577094      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.95606294087891      |
| train_1/q_grads           | 0.03566637691110373    |
| train_1/q_grads_std       | 0.27027077600359917    |
| train_1/q_loss            | 2.5171423632286003     |
| train_1/reward            | -1.1099571902275784    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0002685546875        |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.213                  |
| train_1/target_q          | -4.878334500910785     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 288.29. Rollout time: 55.24, Training time: 232.98
Evaluating epoch 1
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 1                      |
| policy/steps              | 21169.0                |
| test/episodes             | 50.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -5.724935556271179     |
| test_1/avg_q              | -5.459356429718352     |
| test_1/n_subgoals         | 350.0                  |
| test_1/subgoal_succ_rate  | 0.3342857142857143     |
| train/episodes            | 200.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -7.151804962494439     |
| train_0/current_q         | -3.132900439245598     |
| train_0/fw_bonus          | -0.9987753689289093    |
| train_0/fw_loss           | 0.00025344827699882446 |
| train_0/mu_grads          | -0.018372576776891948  |
| train_0/mu_grads_std      | 0.21094197183847427    |
| train_0/mu_loss           | 3.027651961352002      |
| train_0/next_q            | -3.003002514461746     |
| train_0/q_grads           | 0.0409321459941566     |
| train_0/q_grads_std       | 0.24707352928817272    |
| train_0/q_loss            | 0.6016936943325104     |
| train_0/reward            | -0.862533677619649     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0052734375           |
| train_0/target_q          | -3.295509736305479     |
| train_1/avg_q             | -6.458176769659738     |
| train_1/current_q         | -4.847977968622198     |
| train_1/fw_bonus          | -1.0049459010362625    |
| train_1/fw_loss           | 0.0016094157472252846  |
| train_1/mu_grads          | 0.01818821341730654    |
| train_1/mu_grads_std      | 0.08612008299678564    |
| train_1/mu_loss           | 5.123262490098452      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.881775549634796     |
| train_1/q_grads           | 0.034094347525388      |
| train_1/q_grads_std       | 0.3324409581720829     |
| train_1/q_loss            | 2.315076532552239      |
| train_1/reward            | -1.0980636784326634    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000146484375         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.294                  |
| train_1/target_q          | -4.900258616021349     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 284.52. Rollout time: 56.44, Training time: 228.02
Evaluating epoch 2
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 2                      |
| policy/steps              | 31278.0                |
| test/episodes             | 75.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -8.887476580008967     |
| test_1/avg_q              | -5.234832433619553     |
| test_1/n_subgoals         | 250.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 300.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -5.8372948307749875    |
| train_0/current_q         | -3.1977031989793394    |
| train_0/fw_bonus          | -0.9988903000950813    |
| train_0/fw_loss           | 0.00023134760231187103 |
| train_0/mu_grads          | -0.025086900452151895  |
| train_0/mu_grads_std      | 0.256066757440567      |
| train_0/mu_loss           | 3.1842151956351628     |
| train_0/next_q            | -3.1148646665745123    |
| train_0/q_grads           | 0.041396780870854855   |
| train_0/q_grads_std       | 0.2593157023191452     |
| train_0/q_loss            | 0.5733834756221571     |
| train_0/reward            | -0.861155033877003     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0122314453125        |
| train_0/target_q          | -3.193889902913405     |
| train_1/avg_q             | -5.115262557152367     |
| train_1/current_q         | -4.522062398539054     |
| train_1/fw_bonus          | -1.0060081511735917    |
| train_1/fw_loss           | 0.00138287870795466    |
| train_1/mu_grads          | 0.018197031086310746   |
| train_1/mu_grads_std      | 0.08613891024142503    |
| train_1/mu_loss           | 4.833068548531761      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.646119089032676     |
| train_1/q_grads           | 0.027775440411642194   |
| train_1/q_grads_std       | 0.3665850341320038     |
| train_1/q_loss            | 2.2058529768169897     |
| train_1/reward            | -1.0880388160556322    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0002197265625        |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.312                  |
| train_1/target_q          | -4.596151431470952     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 276.42. Rollout time: 56.87, Training time: 219.50
Evaluating epoch 3
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 3                      |
| policy/steps              | 42618.0                |
| test/episodes             | 100.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.8107568173978638    |
| test_1/avg_q              | -6.061250806384809     |
| test_1/n_subgoals         | 250.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 400.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -6.616419851519853     |
| train_0/current_q         | -2.934034897438404     |
| train_0/fw_bonus          | -0.9991088584065437    |
| train_0/fw_loss           | 0.00018932317070721182 |
| train_0/mu_grads          | -0.03656333973631263   |
| train_0/mu_grads_std      | 0.2880596838891506     |
| train_0/mu_loss           | 2.883969313449112      |
| train_0/next_q            | -2.8865324498445046    |
| train_0/q_grads           | 0.04732309030368924    |
| train_0/q_grads_std       | 0.27444292306900026    |
| train_0/q_loss            | 0.8865452681947579     |
| train_0/reward            | -0.8610198712529382    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0185791015625        |
| train_0/target_q          | -3.1938925745996776    |
| train_1/avg_q             | -4.6385517869001704    |
| train_1/current_q         | -4.618983438999168     |
| train_1/fw_bonus          | -1.006693536043167     |
| train_1/fw_loss           | 0.0012367048795567826  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 5.076193272887115      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.994141013856921     |
| train_1/q_grads           | 0.024186009215191005   |
| train_1/q_grads_std       | 0.3921117939054966     |
| train_1/q_loss            | 2.1857505229610887     |
| train_1/reward            | -1.0900909567280905    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0001953125           |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.147                  |
| train_1/target_q          | -4.703793812720134     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 4
Time for epoch 4: 293.70. Rollout time: 62.40, Training time: 231.21
Evaluating epoch 4
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 4                      |
| policy/steps              | 53657.0                |
| test/episodes             | 125.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -7.408499872085563     |
| test_1/avg_q              | -5.197968386251882     |
| test_1/n_subgoals         | 305.0                  |
| test_1/subgoal_succ_rate  | 0.18032786885245902    |
| train/episodes            | 500.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.8065705138074533    |
| train_0/current_q         | -2.6140587155527184    |
| train_0/fw_bonus          | -0.9991034522652626    |
| train_0/fw_loss           | 0.00019035982550121843 |
| train_0/mu_grads          | -0.03781638639047742   |
| train_0/mu_grads_std      | 0.3211435556411743     |
| train_0/mu_loss           | 2.393822894535895      |
| train_0/next_q            | -2.3551609579439754    |
| train_0/q_grads           | 0.050068818777799604   |
| train_0/q_grads_std       | 0.28586781695485114    |
| train_0/q_loss            | 0.3193004340916512     |
| train_0/reward            | -0.8608266190887661    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0107666015625        |
| train_0/target_q          | -2.7037022539464393    |
| train_1/avg_q             | -5.219458582423187     |
| train_1/current_q         | -4.658540400171807     |
| train_1/fw_bonus          | -1.0057151556015014    |
| train_1/fw_loss           | 0.0014453590236371383  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 5.257356338963823      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -5.147252895424005     |
| train_1/q_grads           | 0.02188049266114831    |
| train_1/q_grads_std       | 0.41374693661928175    |
| train_1/q_loss            | 2.4674717791845646     |
| train_1/reward            | -1.0957475551957032    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.000244140625         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.191                  |
| train_1/target_q          | -4.738524366923947     |
------------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 5
Time for epoch 5: 290.94. Rollout time: 57.29, Training time: 233.59
Evaluating epoch 5
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 5                     |
| policy/steps              | 63541.0               |
| test/episodes             | 150.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.7577017104242492   |
| test_1/avg_q              | -5.214923268038394    |
| test_1/n_subgoals         | 1735.0                |
| test_1/subgoal_succ_rate  | 0.9780979827089337    |
| train/episodes            | 600.0                 |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -4.4102007900730875   |
| train_0/current_q         | -2.428100687260725    |
| train_0/fw_bonus          | -0.9990840628743172   |
| train_0/fw_loss           | 0.0001940890433616005 |
| train_0/mu_grads          | -0.03552325125783682  |
| train_0/mu_grads_std      | 0.3180942513048649    |
| train_0/mu_loss           | 2.079877364306423     |
| train_0/next_q            | -2.0418029557840542   |
| train_0/q_grads           | 0.051965062599629165  |
| train_0/q_grads_std       | 0.29175965338945387   |
| train_0/q_loss            | 0.11572935033454104   |
| train_0/reward            | -0.8624234016650008   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0148681640625       |
| train_0/target_q          | -2.425123736757409    |
| train_1/avg_q             | -5.528748576304061    |
| train_1/current_q         | -4.755179772189442    |
| train_1/fw_bonus          | -1.0061721235513688   |
| train_1/fw_loss           | 0.0013479046960128472 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 5.4152048197740585    |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -5.37435312923249     |
| train_1/q_grads           | 0.017674242705106737  |
| train_1/q_grads_std       | 0.43031183555722236   |
| train_1/q_loss            | 2.2124537566567577    |
| train_1/reward            | -1.0898280691544642   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001708984375       |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.352                 |
| train_1/target_q          | -4.871852406447122    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 6
Time for epoch 6: 266.03. Rollout time: 35.48, Training time: 230.49
Evaluating epoch 6
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 71244.0               |
| test/episodes             | 175.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.2197961727864721   |
| test_1/avg_q              | -4.67586415128167     |
| test_1/n_subgoals         | 345.0                 |
| test_1/subgoal_succ_rate  | 0.2985507246376812    |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -2.301194005454955    |
| train_0/current_q         | -2.269189371174499    |
| train_0/fw_bonus          | -0.9990682736039161   |
| train_0/fw_loss           | 0.0001971285731997341 |
| train_0/mu_grads          | -0.033477158099412915 |
| train_0/mu_grads_std      | 0.31379442662000656   |
| train_0/mu_loss           | 1.9901537479515525    |
| train_0/next_q            | -1.936104698794439    |
| train_0/q_grads           | 0.05358297266066074   |
| train_0/q_grads_std       | 0.29953487440943716   |
| train_0/q_loss            | 0.1582670679718165    |
| train_0/reward            | -0.8642059801248252   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.014794921875        |
| train_0/target_q          | -2.3053168082324214   |
| train_1/avg_q             | -5.677862648104574    |
| train_1/current_q         | -4.440665376094918    |
| train_1/fw_bonus          | -1.0063340812921524   |
| train_1/fw_loss           | 0.0013133646454662085 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 5.269775077656971     |
| train_1/n_subgoals        | 993.0                 |
| train_1/next_q            | -5.015299070509877    |
| train_1/q_grads           | 0.015678296657279135  |
| train_1/q_grads_std       | 0.4460571870207787    |
| train_1/q_loss            | 1.9124184967151652    |
| train_1/reward            | -1.0689595473799272   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 9.765625e-05          |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.6062437059415912    |
| train_1/target_q          | -4.562506171632483    |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 7
Time for epoch 7: 262.28. Rollout time: 43.31, Training time: 218.92
Evaluating epoch 7
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 79826.0                |
| test/episodes             | 200.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4297430939234768    |
| test_1/avg_q              | -5.610987025845234     |
| test_1/n_subgoals         | 1909.0                 |
| test_1/subgoal_succ_rate  | 0.9832372970141435     |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -1.7897862584504365    |
| train_0/current_q         | -2.279848868034611     |
| train_0/fw_bonus          | -0.999209001660347     |
| train_0/fw_loss           | 0.00017006591406243388 |
| train_0/mu_grads          | -0.0371916014701128    |
| train_0/mu_grads_std      | 0.32151952385902405    |
| train_0/mu_loss           | 2.020577260190783      |
| train_0/next_q            | -1.9688961329232035    |
| train_0/q_grads           | 0.053665516618639234   |
| train_0/q_grads_std       | 0.30502535328269004    |
| train_0/q_loss            | 0.18296335799076835    |
| train_0/reward            | -0.8624621686118189    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0291259765625        |
| train_0/target_q          | -2.303859584930008     |
| train_1/avg_q             | -5.774182208828404     |
| train_1/current_q         | -4.35716660457251      |
| train_1/fw_bonus          | -1.0071293801069259    |
| train_1/fw_loss           | 0.0011437531473347917  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 5.114611728136813      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.9080969321217465    |
| train_1/q_grads           | 0.013050101487897337   |
| train_1/q_grads_std       | 0.45944420248270035    |
| train_1/q_loss            | 1.76804207825569       |
| train_1/reward            | -1.0508487514816807    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 9.765625e-05           |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.497                  |
| train_1/target_q          | -4.464691907576549     |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 8
Time for epoch 8: 265.23. Rollout time: 28.18, Training time: 237.01
Evaluating epoch 8
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 8                     |
| policy/steps              | 86218.0               |
| test/episodes             | 225.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -3.2009217688176657   |
| test_1/avg_q              | -6.379437656084576    |
| test_1/n_subgoals         | 821.0                 |
| test_1/subgoal_succ_rate  | 0.8952496954933008    |
| train/episodes            | 900.0                 |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -2.6747083648864898   |
| train_0/current_q         | -2.506153114958315    |
| train_0/fw_bonus          | -0.9991926178336143   |
| train_0/fw_loss           | 0.0001732129148876993 |
| train_0/mu_grads          | -0.03718917416408658  |
| train_0/mu_grads_std      | 0.324075598269701     |
| train_0/mu_loss           | 2.1795857805703465    |
| train_0/next_q            | -2.109937784402642    |
| train_0/q_grads           | 0.054008301440626384  |
| train_0/q_grads_std       | 0.31001978293061255   |
| train_0/q_loss            | 0.12373529413967436   |
| train_0/reward            | -0.863225040587713    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.03193359375         |
| train_0/target_q          | -2.4921206266794584   |
| train_1/avg_q             | -6.923989425925715    |
| train_1/current_q         | -4.246930867788272    |
| train_1/fw_bonus          | -1.0074237793684007   |
| train_1/fw_loss           | 0.0010809708008309826 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.8937123499196264    |
| train_1/n_subgoals        | 997.0                 |
| train_1/next_q            | -4.688671211033811    |
| train_1/q_grads           | 0.011996161029674112  |
| train_1/q_grads_std       | 0.47634098008275033   |
| train_1/q_loss            | 1.836955356388915     |
| train_1/reward            | -1.0232680271758      |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0001220703125       |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.7893681043129388    |
| train_1/target_q          | -4.331577039936564    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 9
Time for epoch 9: 266.85. Rollout time: 35.41, Training time: 231.39
Evaluating epoch 9
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 93806.0                |
| test/episodes             | 250.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.9248073070888685    |
| test_1/avg_q              | -6.414471322304998     |
| test_1/n_subgoals         | 1189.0                 |
| test_1/subgoal_succ_rate  | 0.9629941126997477     |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.517067367796986     |
| train_0/current_q         | -2.4394074642089225    |
| train_0/fw_bonus          | -0.9992836862802505    |
| train_0/fw_loss           | 0.00015570438772556373 |
| train_0/mu_grads          | -0.03438889104872942   |
| train_0/mu_grads_std      | 0.3372539319097996     |
| train_0/mu_loss           | 2.119298703959587      |
| train_0/next_q            | -2.01768878350666      |
| train_0/q_grads           | 0.05422839457169175    |
| train_0/q_grads_std       | 0.31786942332983015    |
| train_0/q_loss            | 0.1254998444678474     |
| train_0/reward            | -0.8657225292088697    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.035888671875         |
| train_0/target_q          | -2.4517916876449877    |
| train_1/avg_q             | -6.5079162346985076    |
| train_1/current_q         | -4.2753008694196115    |
| train_1/fw_bonus          | -1.0079417109489441    |
| train_1/fw_loss           | 0.0009705116477562115  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.748245013632158      |
| train_1/n_subgoals        | 996.0                  |
| train_1/next_q            | -4.556961784519409     |
| train_1/q_grads           | 0.010486449860036374   |
| train_1/q_grads_std       | 0.491552372276783      |
| train_1/q_loss            | 1.65628945562637       |
| train_1/reward            | -0.9954521372186719    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0001220703125        |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.7379518072289156     |
| train_1/target_q          | -4.382741185878258     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 10
Time for epoch 10: 261.67. Rollout time: 33.46, Training time: 228.14
Evaluating epoch 10
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 100776.0               |
| test/episodes             | 275.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.9608459332788166    |
| test_1/avg_q              | -6.688889603173154     |
| test_1/n_subgoals         | 677.0                  |
| test_1/subgoal_succ_rate  | 0.8641063515509602     |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.5267938619717674    |
| train_0/current_q         | -2.4372693010413116    |
| train_0/fw_bonus          | -0.9992841705679893    |
| train_0/fw_loss           | 0.00015560931205982342 |
| train_0/mu_grads          | -0.03647852223366499   |
| train_0/mu_grads_std      | 0.3573388434946537     |
| train_0/mu_loss           | 2.138364196147273      |
| train_0/next_q            | -2.0242447215540507    |
| train_0/q_grads           | 0.05427330182865262    |
| train_0/q_grads_std       | 0.3293464697897434     |
| train_0/q_loss            | 0.18367830635629442    |
| train_0/reward            | -0.8687624505662825    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0392333984375        |
| train_0/target_q          | -2.447996228922861     |
| train_1/avg_q             | -7.48230551357888      |
| train_1/current_q         | -4.0081066558356895    |
| train_1/fw_bonus          | -1.008152374625206     |
| train_1/fw_loss           | 0.0009255871686036698  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.242703556491962      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.102950577136488     |
| train_1/q_grads           | 0.009696150897070765   |
| train_1/q_grads_std       | 0.5088836178183556     |
| train_1/q_loss            | 1.6403716851364964     |
| train_1/reward            | -0.9656479662822676    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 7.32421875e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.809                  |
| train_1/target_q          | -4.1339053467495575    |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_10.pkl ...
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 11
Time for epoch 11: 279.58. Rollout time: 37.34, Training time: 242.17
Evaluating epoch 11
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 108089.0              |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.386128145402334    |
| test_1/avg_q              | -7.314722944111291    |
| test_1/n_subgoals         | 1271.0                |
| test_1/subgoal_succ_rate  | 0.963808025177026     |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.7190315754280543   |
| train_0/current_q         | -2.5077260858423913   |
| train_0/fw_bonus          | -0.9992761537432671   |
| train_0/fw_loss           | 0.0001571513417729875 |
| train_0/mu_grads          | -0.041740375105291605 |
| train_0/mu_grads_std      | 0.37888806238770484   |
| train_0/mu_loss           | 2.1899666175658257    |
| train_0/next_q            | -2.058525528426359    |
| train_0/q_grads           | 0.05426059067249298   |
| train_0/q_grads_std       | 0.34079446122050283   |
| train_0/q_loss            | 0.1328248242000881    |
| train_0/reward            | -0.8731692779998411   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0406494140625       |
| train_0/target_q          | -2.506642605815495    |
| train_1/avg_q             | -7.608027939190252    |
| train_1/current_q         | -4.0739468542392885   |
| train_1/fw_bonus          | -1.0087318480014802   |
| train_1/fw_loss           | 0.0008020035558729433 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.286139770076131     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.1573115681091535   |
| train_1/q_grads           | 0.005528746382333338  |
| train_1/q_grads_std       | 0.5268302649259567    |
| train_1/q_loss            | 1.5018388341867976    |
| train_1/reward            | -0.965350155584747    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.779                 |
| train_1/target_q          | -4.188484517689018    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 12
Time for epoch 12: 267.34. Rollout time: 31.41, Training time: 235.88
Evaluating epoch 12
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 12                     |
| policy/steps              | 114774.0               |
| test/episodes             | 325.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4524386058354433    |
| test_1/avg_q              | -8.626135341616394     |
| test_1/n_subgoals         | 1837.0                 |
| test_1/subgoal_succ_rate  | 0.9755035383777899     |
| train/episodes            | 1300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.387643665787395     |
| train_0/current_q         | -2.4324878623564614    |
| train_0/fw_bonus          | -0.9992446303367615    |
| train_0/fw_loss           | 0.00016321365983458237 |
| train_0/mu_grads          | -0.045086090732365844  |
| train_0/mu_grads_std      | 0.39537007734179497    |
| train_0/mu_loss           | 2.125459263048794      |
| train_0/next_q            | -1.9950945121844548    |
| train_0/q_grads           | 0.05546421036124229    |
| train_0/q_grads_std       | 0.35486097186803817    |
| train_0/q_loss            | 0.19755850986310225    |
| train_0/reward            | -0.8732677030813647    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0458740234375        |
| train_0/target_q          | -2.4450468616322065    |
| train_1/avg_q             | -7.634161061149121     |
| train_1/current_q         | -4.134674408369226     |
| train_1/fw_bonus          | -1.0091206073760985    |
| train_1/fw_loss           | 0.0007190945034381002  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.2449163286905645     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.123928446738018     |
| train_1/q_grads           | 0.0022276984876953066  |
| train_1/q_grads_std       | 0.5405847683548928     |
| train_1/q_loss            | 1.208341194914         |
| train_1/reward            | -0.9460494401515461    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 7.32421875e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.792                  |
| train_1/target_q          | -4.300358067698079     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 13
Time for epoch 13: 262.53. Rollout time: 29.89, Training time: 232.58
Evaluating epoch 13
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 120885.0               |
| test/episodes             | 350.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4887739012303842    |
| test_1/avg_q              | -8.277400367102324     |
| test_1/n_subgoals         | 1775.0                 |
| test_1/subgoal_succ_rate  | 0.9909859154929578     |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.618942400730119     |
| train_0/current_q         | -2.518466152720433     |
| train_0/fw_bonus          | -0.9991252988576889    |
| train_0/fw_loss           | 0.00018616195557115135 |
| train_0/mu_grads          | -0.046869106404483316  |
| train_0/mu_grads_std      | 0.41128207594156263    |
| train_0/mu_loss           | 2.2849930916812005     |
| train_0/next_q            | -2.1119247675519848    |
| train_0/q_grads           | 0.053170157875865695   |
| train_0/q_grads_std       | 0.3671840213239193     |
| train_0/q_loss            | 0.2290066221506904     |
| train_0/reward            | -0.8745759020617697    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03359375             |
| train_0/target_q          | -2.5143979819999394    |
| train_1/avg_q             | -7.7103661027361525    |
| train_1/current_q         | -3.972831971747996     |
| train_1/fw_bonus          | -1.0093988239765168    |
| train_1/fw_loss           | 0.0006597593412152492  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.108707604556136      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.9534353880858975    |
| train_1/q_grads           | -0.0002649652835316374 |
| train_1/q_grads_std       | 0.5544028267264366     |
| train_1/q_loss            | 1.2555676657018573     |
| train_1/reward            | -0.9452815439755795    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.82                   |
| train_1/target_q          | -4.1414110247533715    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 14
Time for epoch 14: 261.96. Rollout time: 22.52, Training time: 239.38
Evaluating epoch 14
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 126225.0               |
| test/episodes             | 375.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -2.5794823487991954    |
| test_1/avg_q              | -9.27611819062373      |
| test_1/n_subgoals         | 1752.0                 |
| test_1/subgoal_succ_rate  | 0.9771689497716894     |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.0885788393252396    |
| train_0/current_q         | -2.315971690333558     |
| train_0/fw_bonus          | -0.9992915391921997    |
| train_0/fw_loss           | 0.0001541942994663259  |
| train_0/mu_grads          | -0.04820823799818754   |
| train_0/mu_grads_std      | 0.42596820592880247    |
| train_0/mu_loss           | 2.037519536549742      |
| train_0/next_q            | -1.875846295457233     |
| train_0/q_grads           | 0.052470055595040324   |
| train_0/q_grads_std       | 0.37991333901882174    |
| train_0/q_loss            | 0.16741984759412645    |
| train_0/reward            | -0.8757687021468883    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.047607421875         |
| train_0/target_q          | -2.374634793396271     |
| train_1/avg_q             | -8.78794376649645      |
| train_1/current_q         | -4.196293183953893     |
| train_1/fw_bonus          | -1.009407651424408     |
| train_1/fw_loss           | 0.0006578794113011099  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.27762903283938       |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.180497742925075     |
| train_1/q_grads           | -0.0020542360551189633 |
| train_1/q_grads_std       | 0.5674920052289962     |
| train_1/q_loss            | 0.9604730827387602     |
| train_1/reward            | -0.9289490428520366    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.898                  |
| train_1/target_q          | -4.38470038886626      |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 15
Time for epoch 15: 251.34. Rollout time: 26.24, Training time: 225.04
Evaluating epoch 15
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 132021.0               |
| test/episodes             | 400.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.272817003121734     |
| test_1/avg_q              | -9.041999645540193     |
| test_1/n_subgoals         | 1915.0                 |
| test_1/subgoal_succ_rate  | 0.9879895561357702     |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.629882638058992     |
| train_0/current_q         | -2.5686574539948266    |
| train_0/fw_bonus          | -0.9993074879050254    |
| train_0/fw_loss           | 0.00015112692381080706 |
| train_0/mu_grads          | -0.05064367884770036   |
| train_0/mu_grads_std      | 0.43857199102640154    |
| train_0/mu_loss           | 2.332793308896669      |
| train_0/next_q            | -2.148872347719551     |
| train_0/q_grads           | 0.05194353489205241    |
| train_0/q_grads_std       | 0.39249528720974924    |
| train_0/q_loss            | 0.25746724032397605    |
| train_0/reward            | -0.8757379411908914    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0479248046875        |
| train_0/target_q          | -2.5695842439492056    |
| train_1/avg_q             | -8.430393351563387     |
| train_1/current_q         | -4.106969518959461     |
| train_1/fw_bonus          | -1.0095927566289902    |
| train_1/fw_loss           | 0.0006184054509503767  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.161716408150581      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.082484696322892     |
| train_1/q_grads           | -0.005146056902594865  |
| train_1/q_grads_std       | 0.5801576048135757     |
| train_1/q_loss            | 0.9627948244106346     |
| train_1/reward            | -0.9247848837076162    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.858                  |
| train_1/target_q          | -4.297770808403277     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 16
Time for epoch 16: 256.48. Rollout time: 26.79, Training time: 229.59
Evaluating epoch 16
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 138012.0               |
| test/episodes             | 425.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9435075962971666    |
| test_1/avg_q              | -8.224557456814876     |
| test_1/n_subgoals         | 1757.0                 |
| test_1/subgoal_succ_rate  | 0.977233921457029      |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.103639425695734     |
| train_0/current_q         | -2.4933127832145514    |
| train_0/fw_bonus          | -0.9992923513054848    |
| train_0/fw_loss           | 0.00015403780962515158 |
| train_0/mu_grads          | -0.053725785203278066  |
| train_0/mu_grads_std      | 0.4494392335414886     |
| train_0/mu_loss           | 2.234414946101107      |
| train_0/next_q            | -2.0392746557586063    |
| train_0/q_grads           | 0.05150995180010796    |
| train_0/q_grads_std       | 0.4053907856345177     |
| train_0/q_loss            | 0.17701772444897088    |
| train_0/reward            | -0.8749758552075946    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0499267578125        |
| train_0/target_q          | -2.494918808617405     |
| train_1/avg_q             | -7.650438431979307     |
| train_1/current_q         | -3.7538279627984736    |
| train_1/fw_bonus          | -1.009807687997818     |
| train_1/fw_loss           | 0.0005725608760258182  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.771826807747375      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.660335908484207     |
| train_1/q_grads           | -0.006977062707301229  |
| train_1/q_grads_std       | 0.5907511129975319     |
| train_1/q_loss            | 0.8876125759204274     |
| train_1/reward            | -0.9196055316962883    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.828                  |
| train_1/target_q          | -3.940166347345104     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 17
Time for epoch 17: 262.44. Rollout time: 26.79, Training time: 235.57
Evaluating epoch 17
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 143961.0               |
| test/episodes             | 450.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.12327583240838      |
| test_1/avg_q              | -9.25968738791429      |
| test_1/n_subgoals         | 1843.0                 |
| test_1/subgoal_succ_rate  | 0.9788388497015735     |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.245744875697078     |
| train_0/current_q         | -2.513379635465444     |
| train_0/fw_bonus          | -0.9993606254458427    |
| train_0/fw_loss           | 0.00014091114644543268 |
| train_0/mu_grads          | -0.05500918123871088   |
| train_0/mu_grads_std      | 0.4624763421714306     |
| train_0/mu_loss           | 2.2266514456632134     |
| train_0/next_q            | -2.0392576735914205    |
| train_0/q_grads           | 0.04979034839197993    |
| train_0/q_grads_std       | 0.41652709394693377    |
| train_0/q_loss            | 0.1958181467095961     |
| train_0/reward            | -0.8746791532714269    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0507080078125        |
| train_0/target_q          | -2.504962512740444     |
| train_1/avg_q             | -7.402892066458797     |
| train_1/current_q         | -3.651277995586679     |
| train_1/fw_bonus          | -1.0097711682319641    |
| train_1/fw_loss           | 0.0005803507083328441  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6832110681360204     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.586183356205953     |
| train_1/q_grads           | -0.009031951799988747  |
| train_1/q_grads_std       | 0.6074520036578178     |
| train_1/q_loss            | 0.7899833067160618     |
| train_1/reward            | -0.9140544550318737    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.826                  |
| train_1/target_q          | -3.829360673591733     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 18
Time for epoch 18: 266.38. Rollout time: 24.81, Training time: 241.51
Evaluating epoch 18
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 18                    |
| policy/steps              | 149648.0              |
| test/episodes             | 475.0                 |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.7668999859881256   |
| test_1/avg_q              | -8.35143417319655     |
| test_1/n_subgoals         | 1898.0                |
| test_1/subgoal_succ_rate  | 0.9873551106427819    |
| train/episodes            | 1900.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -3.3364802790810626   |
| train_0/current_q         | -2.277948613584742    |
| train_0/fw_bonus          | -0.9993256464600563   |
| train_0/fw_loss           | 0.0001476357432693476 |
| train_0/mu_grads          | -0.05928181977942586  |
| train_0/mu_grads_std      | 0.47415411844849586   |
| train_0/mu_loss           | 1.997882302814607     |
| train_0/next_q            | -1.8336057372873433   |
| train_0/q_grads           | 0.04821393033489585   |
| train_0/q_grads_std       | 0.4273803099989891    |
| train_0/q_loss            | 0.1836141542246376    |
| train_0/reward            | -0.8727852495911066   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0517578125          |
| train_0/target_q          | -2.3208011502200785   |
| train_1/avg_q             | -8.127507144382678    |
| train_1/current_q         | -3.666095891724413    |
| train_1/fw_bonus          | -1.0101940393447877   |
| train_1/fw_loss           | 0.0004901666317891796 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.6943302180837136    |
| train_1/n_subgoals        | 995.0                 |
| train_1/next_q            | -3.5842995128511417   |
| train_1/q_grads           | -0.011063668597489595 |
| train_1/q_grads_std       | 0.6189222738146782    |
| train_1/q_loss            | 0.7788865484818815    |
| train_1/reward            | -0.9101479756747721   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.8542713567839196    |
| train_1/target_q          | -3.8392632819791204   |
-----------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 19
Time for epoch 19: 252.68. Rollout time: 23.73, Training time: 228.89
Evaluating epoch 19
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 19                     |
| policy/steps              | 155331.0               |
| test/episodes             | 500.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9083187593977247    |
| test_1/avg_q              | -6.944963745945826     |
| test_1/n_subgoals         | 1882.0                 |
| test_1/subgoal_succ_rate  | 0.9829968119022316     |
| train/episodes            | 2000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.4160477100684172    |
| train_0/current_q         | -2.579005589734314     |
| train_0/fw_bonus          | -0.999325406551361     |
| train_0/fw_loss           | 0.000147683091199724   |
| train_0/mu_grads          | -0.06321534924209118   |
| train_0/mu_grads_std      | 0.4842035748064518     |
| train_0/mu_loss           | 2.341870150925544      |
| train_0/next_q            | -2.149423182005926     |
| train_0/q_grads           | 0.04693136485293507    |
| train_0/q_grads_std       | 0.4376179434359074     |
| train_0/q_loss            | 0.24322833361750149    |
| train_0/reward            | -0.8730902407623944    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.051171875            |
| train_0/target_q          | -2.5898421170752846    |
| train_1/avg_q             | -8.306501641015398     |
| train_1/current_q         | -3.469027377085961     |
| train_1/fw_bonus          | -1.0102533608675004    |
| train_1/fw_loss           | 0.00047751471502124334 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.471611313795413      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.3622471459720153    |
| train_1/q_grads           | -0.015105813601985573  |
| train_1/q_grads_std       | 0.6322165787220001     |
| train_1/q_loss            | 0.8065187174924919     |
| train_1/reward            | -0.9101680553372716    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.857                  |
| train_1/target_q          | -3.623669995862783     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 20
Time for epoch 20: 269.49. Rollout time: 27.28, Training time: 242.16
Evaluating epoch 20
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 161445.0               |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.2608861345415914    |
| test_1/avg_q              | -7.707188639724264     |
| test_1/n_subgoals         | 1577.0                 |
| test_1/subgoal_succ_rate  | 0.9429296131896006     |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.9175113918039974    |
| train_0/current_q         | -2.5726357061182643    |
| train_0/fw_bonus          | -0.9993690207600594    |
| train_0/fw_loss           | 0.00013929503420513357 |
| train_0/mu_grads          | -0.06545828245580196   |
| train_0/mu_grads_std      | 0.49246324598789215    |
| train_0/mu_loss           | 2.3438438658639127     |
| train_0/next_q            | -2.148028589805763     |
| train_0/q_grads           | 0.04704577019438148    |
| train_0/q_grads_std       | 0.44776054173707963    |
| train_0/q_loss            | 0.23797577207336512    |
| train_0/reward            | -0.8731961989920819    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0509033203125        |
| train_0/target_q          | -2.5958722290978775    |
| train_1/avg_q             | -7.336946424871341     |
| train_1/current_q         | -3.4014682935651366    |
| train_1/fw_bonus          | -1.0103538274765014    |
| train_1/fw_loss           | 0.0004560885783575941  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.411647023110821      |
| train_1/n_subgoals        | 999.0                  |
| train_1/next_q            | -3.289845965896469     |
| train_1/q_grads           | -0.016939783515408636  |
| train_1/q_grads_std       | 0.6412925809621811     |
| train_1/q_loss            | 0.67159787787782       |
| train_1/reward            | -0.9154252903506859    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8208208208208209     |
| train_1/target_q          | -3.5451372040195026    |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 21
Time for epoch 21: 267.26. Rollout time: 29.24, Training time: 237.96
Evaluating epoch 21
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 167966.0               |
| test/episodes             | 550.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.4209412778079464    |
| test_1/avg_q              | -8.409901873567858     |
| test_1/n_subgoals         | 1434.0                 |
| test_1/subgoal_succ_rate  | 0.9428172942817294     |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -4.503508419950547     |
| train_0/current_q         | -2.704316476390877     |
| train_0/fw_bonus          | -0.9994198560714722    |
| train_0/fw_loss           | 0.0001295188785661594  |
| train_0/mu_grads          | -0.06731082573533058   |
| train_0/mu_grads_std      | 0.5030840665102005     |
| train_0/mu_loss           | 2.4717061190022114     |
| train_0/next_q            | -2.2665572599441766    |
| train_0/q_grads           | 0.04581230040639639    |
| train_0/q_grads_std       | 0.4574093334376812     |
| train_0/q_loss            | 0.2467972504700672     |
| train_0/reward            | -0.8727399441762828    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0541259765625        |
| train_0/target_q          | -2.7251940853078658    |
| train_1/avg_q             | -6.433203618652393     |
| train_1/current_q         | -3.3622003686241286    |
| train_1/fw_bonus          | -1.0105732470750808    |
| train_1/fw_loss           | 0.00040929547321866266 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.3722123771996664     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.256930386049304     |
| train_1/q_grads           | -0.018328683637082576  |
| train_1/q_grads_std       | 0.6514694496989251     |
| train_1/q_loss            | 0.694175265273244      |
| train_1/reward            | -0.9150466367893386    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.745                  |
| train_1/target_q          | -3.4964809592927226    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 22
Time for epoch 22: 356.95. Rollout time: 38.47, Training time: 318.42
Evaluating epoch 22
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 22                    |
| policy/steps              | 174624.0              |
| test/episodes             | 575.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -4.132577098948937    |
| test_1/avg_q              | -7.187071017918979    |
| test_1/n_subgoals         | 1284.0                |
| test_1/subgoal_succ_rate  | 0.9353582554517134    |
| train/episodes            | 2300.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -4.662728121598325    |
| train_0/current_q         | -2.68427533011267     |
| train_0/fw_bonus          | -0.9993760243058205   |
| train_0/fw_loss           | 0.0001379486460791668 |
| train_0/mu_grads          | -0.07035388592630624  |
| train_0/mu_grads_std      | 0.5111032098531723    |
| train_0/mu_loss           | 2.490825816750089     |
| train_0/next_q            | -2.2980000078795575   |
| train_0/q_grads           | 0.04491818901151419   |
| train_0/q_grads_std       | 0.4675858303904533    |
| train_0/q_loss            | 0.27935623761494377   |
| train_0/reward            | -0.8706868023014976   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.051171875           |
| train_0/target_q          | -2.7277784432143095   |
| train_1/avg_q             | -6.8999467108741035   |
| train_1/current_q         | -3.3843015622251316   |
| train_1/fw_bonus          | -1.010520228743553    |
| train_1/fw_loss           | 0.0004206008030450903 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.422289198599775     |
| train_1/n_subgoals        | 997.0                 |
| train_1/next_q            | -3.26032598944303     |
| train_1/q_grads           | -0.01993039227090776  |
| train_1/q_grads_std       | 0.6642037436366082    |
| train_1/q_loss            | 0.6361488937068274    |
| train_1/reward            | -0.9168745546339778   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.7582748244734202    |
| train_1/target_q          | -3.5378011100386217   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 23
Time for epoch 23: 388.61. Rollout time: 39.06, Training time: 349.48
Evaluating epoch 23
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 23                    |
| policy/steps              | 181096.0              |
| test/episodes             | 600.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.8749208332739327   |
| test_1/avg_q              | -8.462245665803191    |
| test_1/n_subgoals         | 1690.0                |
| test_1/subgoal_succ_rate  | 0.9727810650887574    |
| train/episodes            | 2400.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -5.172530286831601    |
| train_0/current_q         | -2.641678663087678    |
| train_0/fw_bonus          | -0.9993701204657555   |
| train_0/fw_loss           | 0.0001390830255331821 |
| train_0/mu_grads          | -0.07351539954543114  |
| train_0/mu_grads_std      | 0.5197345316410065    |
| train_0/mu_loss           | 2.4348084682129953    |
| train_0/next_q            | -2.2538237055006336   |
| train_0/q_grads           | 0.04418858168646693   |
| train_0/q_grads_std       | 0.4762064449489117    |
| train_0/q_loss            | 0.2899156848132879    |
| train_0/reward            | -0.8700598189578159   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0535400390625       |
| train_0/target_q          | -2.6693001058669514   |
| train_1/avg_q             | -6.971894580301801    |
| train_1/current_q         | -3.6392622253410933   |
| train_1/fw_bonus          | -1.0106315672397614   |
| train_1/fw_loss           | 0.0003968557393818628 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.664958688525407     |
| train_1/n_subgoals        | 999.0                 |
| train_1/next_q            | -3.531692070936746    |
| train_1/q_grads           | -0.02259857254102826  |
| train_1/q_grads_std       | 0.6765992298722268    |
| train_1/q_loss            | 0.9214613673873788    |
| train_1/reward            | -0.9218408721746527   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.7987987987987988    |
| train_1/target_q          | -3.7868379604958022   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 24
Time for epoch 24: 270.47. Rollout time: 21.82, Training time: 248.59
Evaluating epoch 24
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 24                     |
| policy/steps              | 186581.0               |
| test/episodes             | 625.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -3.365003359355522     |
| test_1/avg_q              | -8.23782785366614      |
| test_1/n_subgoals         | 1693.0                 |
| test_1/subgoal_succ_rate  | 0.9663319551092735     |
| train/episodes            | 2500.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -3.987579152263841     |
| train_0/current_q         | -2.665477617514033     |
| train_0/fw_bonus          | -0.9994620203971862    |
| train_0/fw_loss           | 0.00012141128663643031 |
| train_0/mu_grads          | -0.0756587291136384    |
| train_0/mu_grads_std      | 0.5271945998072625     |
| train_0/mu_loss           | 2.4837605885816134     |
| train_0/next_q            | -2.3093290345461073    |
| train_0/q_grads           | 0.044195447210222484   |
| train_0/q_grads_std       | 0.4843122839927673     |
| train_0/q_loss            | 0.33018200947933696    |
| train_0/reward            | -0.8688897312953486    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0552978515625        |
| train_0/target_q          | -2.7169068163467367    |
| train_1/avg_q             | -7.913184479685274     |
| train_1/current_q         | -3.6395831287731695    |
| train_1/fw_bonus          | -1.010830470919609     |
| train_1/fw_loss           | 0.00035444224704406224 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6374985749146176     |
| train_1/n_subgoals        | 991.0                  |
| train_1/next_q            | -3.5316778223980263    |
| train_1/q_grads           | -0.02468464714474976   |
| train_1/q_grads_std       | 0.6921024903655052     |
| train_1/q_loss            | 0.6897798327873568     |
| train_1/reward            | -0.9174490137214889    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8748738647830474     |
| train_1/target_q          | -3.8014297669029533    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 25
Time for epoch 25: 248.00. Rollout time: 19.11, Training time: 228.83
Evaluating epoch 25
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 25                     |
| policy/steps              | 191900.0               |
| test/episodes             | 650.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.1023644830858115    |
| test_1/avg_q              | -7.965466700932746     |
| test_1/n_subgoals         | 1620.0                 |
| test_1/subgoal_succ_rate  | 0.9691358024691358     |
| train/episodes            | 2600.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.9038483327401443    |
| train_0/current_q         | -2.574940188605589     |
| train_0/fw_bonus          | -0.9994972050189972    |
| train_0/fw_loss           | 0.00011464562376204413 |
| train_0/mu_grads          | -0.07832427006214857   |
| train_0/mu_grads_std      | 0.5348532319068908     |
| train_0/mu_loss           | 2.3438244619529787     |
| train_0/next_q            | -2.1739696691205586    |
| train_0/q_grads           | 0.0436478222720325     |
| train_0/q_grads_std       | 0.4913045383989811     |
| train_0/q_loss            | 0.21519072653688487    |
| train_0/reward            | -0.866602886893088     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.055224609375         |
| train_0/target_q          | -2.626494687397873     |
| train_1/avg_q             | -8.33796344141285      |
| train_1/current_q         | -3.6873306724025228    |
| train_1/fw_bonus          | -1.01055728495121      |
| train_1/fw_loss           | 0.00041270422589150256 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6935256125317437     |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -3.5716006381836225    |
| train_1/q_grads           | -0.027891337871551514  |
| train_1/q_grads_std       | 0.707180705666542      |
| train_1/q_loss            | 0.6841049270650706     |
| train_1/reward            | -0.915022442190093     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8946840521564694     |
| train_1/target_q          | -3.87143470182275      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 26
Time for epoch 26: 248.65. Rollout time: 20.24, Training time: 228.34
Evaluating epoch 26
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 197251.0               |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.9691731803385548    |
| test_1/avg_q              | -8.114199090096786     |
| test_1/n_subgoals         | 1942.0                 |
| test_1/subgoal_succ_rate  | 0.9891864057672503     |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.8349627095180483    |
| train_0/current_q         | -2.5575063969257283    |
| train_0/fw_bonus          | -0.9994672700762749    |
| train_0/fw_loss           | 0.00012040248038829305 |
| train_0/mu_grads          | -0.0809236915782094    |
| train_0/mu_grads_std      | 0.5411109268665314     |
| train_0/mu_loss           | 2.361297580348377      |
| train_0/next_q            | -2.179617506687719     |
| train_0/q_grads           | 0.04429371990263462    |
| train_0/q_grads_std       | 0.49805759117007253    |
| train_0/q_loss            | 0.23159718159810527    |
| train_0/reward            | -0.8664339488866972    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0560546875           |
| train_0/target_q          | -2.6081936351070203    |
| train_1/avg_q             | -7.981469540043952     |
| train_1/current_q         | -3.745475357170122     |
| train_1/fw_bonus          | -1.0107476204633712    |
| train_1/fw_loss           | 0.00037210831433185374 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.739612025824568      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.637789149512193     |
| train_1/q_grads           | -0.028835676843300462  |
| train_1/q_grads_std       | 0.714821957051754      |
| train_1/q_loss            | 0.673449026238516      |
| train_1/reward            | -0.910264084082155     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.894                  |
| train_1/target_q          | -3.927411792146809     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 27
Time for epoch 27: 267.33. Rollout time: 21.62, Training time: 245.64
Evaluating epoch 27
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 202558.0               |
| test/episodes             | 700.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.198386050259969     |
| test_1/avg_q              | -8.958075367924307     |
| test_1/n_subgoals         | 1724.0                 |
| test_1/subgoal_succ_rate  | 0.9802784222737819     |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -3.4726773841317393    |
| train_0/current_q         | -2.572427419178015     |
| train_0/fw_bonus          | -0.9994684129953384    |
| train_0/fw_loss           | 0.00012018478082609363 |
| train_0/mu_grads          | -0.08374464139342308   |
| train_0/mu_grads_std      | 0.5477666616439819     |
| train_0/mu_loss           | 2.418285533526494      |
| train_0/next_q            | -2.2304088258134382    |
| train_0/q_grads           | 0.0444027959369123     |
| train_0/q_grads_std       | 0.5044130399823189     |
| train_0/q_loss            | 0.28171436950741147    |
| train_0/reward            | -0.86545213208301      |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.056884765625         |
| train_0/target_q          | -2.6259248240250415    |
| train_1/avg_q             | -7.968482252647441     |
| train_1/current_q         | -3.693435016247436     |
| train_1/fw_bonus          | -1.0105115205049515    |
| train_1/fw_loss           | 0.0004224584634357598  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.686961209071538      |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -3.583247604741279     |
| train_1/q_grads           | -0.028537985496222974  |
| train_1/q_grads_std       | 0.7228995859622955     |
| train_1/q_loss            | 0.6240456945411902     |
| train_1/reward            | -0.9000894576543942    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9254783484390735     |
| train_1/target_q          | -3.8861479754034165    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 28
Time for epoch 28: 302.26. Rollout time: 23.01, Training time: 279.18
Evaluating epoch 28
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 28                     |
| policy/steps              | 207854.0               |
| test/episodes             | 725.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.2397336507520094    |
| test_1/avg_q              | -7.792535874728475     |
| test_1/n_subgoals         | 1755.0                 |
| test_1/subgoal_succ_rate  | 0.9749287749287749     |
| train/episodes            | 2900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.723735337102651     |
| train_0/current_q         | -2.5228550702794075    |
| train_0/fw_bonus          | -0.9994873359799386    |
| train_0/fw_loss           | 0.00011654406625893898 |
| train_0/mu_grads          | -0.08505973294377327   |
| train_0/mu_grads_std      | 0.5567433252930641     |
| train_0/mu_loss           | 2.314778948535672      |
| train_0/next_q            | -2.1468595922141733    |
| train_0/q_grads           | 0.04378933431580663    |
| train_0/q_grads_std       | 0.5124151945114136     |
| train_0/q_loss            | 0.2968170613036395     |
| train_0/reward            | -0.8639160391656333    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0557373046875        |
| train_0/target_q          | -2.553060485519203     |
| train_1/avg_q             | -7.967856372384486     |
| train_1/current_q         | -3.6201678597690012    |
| train_1/fw_bonus          | -1.0107269555330276    |
| train_1/fw_loss           | 0.00037651131642633116 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6157704247173625     |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.47277825531243      |
| train_1/q_grads           | -0.030619677482172848  |
| train_1/q_grads_std       | 0.7339813798666001     |
| train_1/q_loss            | 0.5103472023669763     |
| train_1/reward            | -0.8947883948043455    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8964824120603015     |
| train_1/target_q          | -3.816734169224648     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 29
Time for epoch 29: 413.74. Rollout time: 38.03, Training time: 375.58
Evaluating epoch 29
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 29                     |
| policy/steps              | 212916.0               |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.7084761714429215    |
| test_1/avg_q              | -8.858912677126847     |
| test_1/n_subgoals         | 2011.0                 |
| test_1/subgoal_succ_rate  | 0.9880656389855793     |
| train/episodes            | 3000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.233341478270669     |
| train_0/current_q         | -2.5057150212366843    |
| train_0/fw_bonus          | -0.9994900226593018    |
| train_0/fw_loss           | 0.00011602793674683198 |
| train_0/mu_grads          | -0.08744708355516195   |
| train_0/mu_grads_std      | 0.5642385184764862     |
| train_0/mu_loss           | 2.3009465329401873     |
| train_0/next_q            | -2.133343378758644     |
| train_0/q_grads           | 0.04317968860268593    |
| train_0/q_grads_std       | 0.5202747970819473     |
| train_0/q_loss            | 0.23545332249371514    |
| train_0/reward            | -0.8642293314085692    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0536376953125        |
| train_0/target_q          | -2.5483549241929535    |
| train_1/avg_q             | -8.737844285191116     |
| train_1/current_q         | -3.6644444203882274    |
| train_1/fw_bonus          | -1.010797694325447     |
| train_1/fw_loss           | 0.0003614307534007821  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6753086705613485     |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -3.539460913536293     |
| train_1/q_grads           | -0.03242312232032418   |
| train_1/q_grads_std       | 0.745638507604599      |
| train_1/q_loss            | 0.5595204176936319     |
| train_1/reward            | -0.8905933821632062    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9277833500501504     |
| train_1/target_q          | -3.859421711760831     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 30
Time for epoch 30: 301.14. Rollout time: 28.13, Training time: 272.93
Evaluating epoch 30
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 218255.0               |
| test/episodes             | 775.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3987535143157213    |
| test_1/avg_q              | -9.047202422039119     |
| test_1/n_subgoals         | 2196.0                 |
| test_1/subgoal_succ_rate  | 0.9931693989071039     |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.723385485944823     |
| train_0/current_q         | -2.327777456823458     |
| train_0/fw_bonus          | -0.9994740962982178    |
| train_0/fw_loss           | 0.00011909020358871202 |
| train_0/mu_grads          | -0.09113131370395422   |
| train_0/mu_grads_std      | 0.5705392047762871     |
| train_0/mu_loss           | 2.098771786751671      |
| train_0/next_q            | -1.9346272437241843    |
| train_0/q_grads           | 0.04236201541498304    |
| train_0/q_grads_std       | 0.5287899404764176     |
| train_0/q_loss            | 0.2605119990314703     |
| train_0/reward            | -0.86355210452748      |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0535888671875        |
| train_0/target_q          | -2.356354697289276     |
| train_1/avg_q             | -7.791888944220882     |
| train_1/current_q         | -3.678956851427118     |
| train_1/fw_bonus          | -1.010477277636528     |
| train_1/fw_loss           | 0.0004297642852179706  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.676365466324184      |
| train_1/n_subgoals        | 996.0                  |
| train_1/next_q            | -3.5502994713918334    |
| train_1/q_grads           | -0.032950362749397756  |
| train_1/q_grads_std       | 0.7534311458468437     |
| train_1/q_loss            | 0.6124756449206263     |
| train_1/reward            | -0.8889858833659673    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8965863453815262     |
| train_1/target_q          | -3.875712057000288     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 31
Time for epoch 31: 302.51. Rollout time: 27.91, Training time: 274.51
Evaluating epoch 31
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 223508.0               |
| test/episodes             | 800.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.7082904819892732    |
| test_1/avg_q              | -8.602942779044465     |
| test_1/n_subgoals         | 1869.0                 |
| test_1/subgoal_succ_rate  | 0.9700374531835206     |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.404223875799238     |
| train_0/current_q         | -2.504582678237006     |
| train_0/fw_bonus          | -0.9994688928127289    |
| train_0/fw_loss           | 0.00012008909725409467 |
| train_0/mu_grads          | -0.09317759163677693   |
| train_0/mu_grads_std      | 0.5762087136507035     |
| train_0/mu_loss           | 2.3239698953242915     |
| train_0/next_q            | -2.148168174022077     |
| train_0/q_grads           | 0.041759390849620104   |
| train_0/q_grads_std       | 0.5388532534241677     |
| train_0/q_loss            | 0.22630292579781103    |
| train_0/reward            | -0.8631575835403055    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.052197265625         |
| train_0/target_q          | -2.558435396895479     |
| train_1/avg_q             | -8.34845126829013      |
| train_1/current_q         | -3.675452720450359     |
| train_1/fw_bonus          | -1.0106184244155885    |
| train_1/fw_loss           | 0.0003996595172793604  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.666708906026517      |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -3.5671223296424825    |
| train_1/q_grads           | -0.03344971872866154   |
| train_1/q_grads_std       | 0.7629880622029305     |
| train_1/q_loss            | 0.6176258629192107     |
| train_1/reward            | -0.8897143129259348    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.8956870611835507     |
| train_1/target_q          | -3.872073159182147     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 32
Time for epoch 32: 296.73. Rollout time: 24.79, Training time: 271.84
Evaluating epoch 32
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 32                     |
| policy/steps              | 228465.0               |
| test/episodes             | 825.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.507473775947333     |
| test_1/avg_q              | -9.153549318089686     |
| test_1/n_subgoals         | 1792.0                 |
| test_1/subgoal_succ_rate  | 0.9720982142857143     |
| train/episodes            | 3300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.4641782622516066    |
| train_0/current_q         | -2.4530915210308293    |
| train_0/fw_bonus          | -0.9995079010725021    |
| train_0/fw_loss           | 0.00011258988470217446 |
| train_0/mu_grads          | -0.09361708983778953   |
| train_0/mu_grads_std      | 0.5829594001173973     |
| train_0/mu_loss           | 2.2706475781333824     |
| train_0/next_q            | -2.0960650534682315    |
| train_0/q_grads           | 0.04114139014855027    |
| train_0/q_grads_std       | 0.5479985058307648     |
| train_0/q_loss            | 0.3010179883633486     |
| train_0/reward            | -0.8617341962235514    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05517578125          |
| train_0/target_q          | -2.5040329268160484    |
| train_1/avg_q             | -8.4771392959361       |
| train_1/current_q         | -3.613946782286056     |
| train_1/fw_bonus          | -1.0107659250497818    |
| train_1/fw_loss           | 0.0003682017653773073  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.6084957908286404     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.497805509269648     |
| train_1/q_grads           | -0.03466964326798916   |
| train_1/q_grads_std       | 0.771353006362915      |
| train_1/q_loss            | 0.5634835375505599     |
| train_1/reward            | -0.8875483300565975    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.909                  |
| train_1/target_q          | -3.8208320776417515    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 33
Time for epoch 33: 298.13. Rollout time: 27.43, Training time: 270.60
Evaluating epoch 33
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 33                     |
| policy/steps              | 233563.0               |
| test/episodes             | 850.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4972154202042962    |
| test_1/avg_q              | -9.382297962384332     |
| test_1/n_subgoals         | 2088.0                 |
| test_1/subgoal_succ_rate  | 0.9904214559386973     |
| train/episodes            | 3400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.982608101623712     |
| train_0/current_q         | -2.453280233289862     |
| train_0/fw_bonus          | -0.9995238140225411    |
| train_0/fw_loss           | 0.00010952963748422917 |
| train_0/mu_grads          | -0.09712653700262308   |
| train_0/mu_grads_std      | 0.5896268412470818     |
| train_0/mu_loss           | 2.242348894766662      |
| train_0/next_q            | -2.075861490621448     |
| train_0/q_grads           | 0.03993225395679474    |
| train_0/q_grads_std       | 0.5553025349974632     |
| train_0/q_loss            | 0.22168306591255993    |
| train_0/reward            | -0.8631682513732812    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0589599609375        |
| train_0/target_q          | -2.494195699764338     |
| train_1/avg_q             | -8.276023172203493     |
| train_1/current_q         | -3.846923356427787     |
| train_1/fw_bonus          | -1.0109931379556656    |
| train_1/fw_loss           | 0.00031974438097677195 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.826000636405702      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.7664836999098767    |
| train_1/q_grads           | -0.034450777992606166  |
| train_1/q_grads_std       | 0.7801836997270584     |
| train_1/q_loss            | 0.670728353940747      |
| train_1/reward            | -0.8906850506871706    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.895                  |
| train_1/target_q          | -4.030207105218964     |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 34
Time for epoch 34: 313.32. Rollout time: 28.74, Training time: 284.44
Evaluating epoch 34
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 238539.0               |
| test/episodes             | 875.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.7006644244689224    |
| test_1/avg_q              | -8.853825460912383     |
| test_1/n_subgoals         | 1938.0                 |
| test_1/subgoal_succ_rate  | 0.9845201238390093     |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.5485012555956836    |
| train_0/current_q         | -2.336251400360151     |
| train_0/fw_bonus          | -0.9994679301977157    |
| train_0/fw_loss           | 0.00012027562370349187 |
| train_0/mu_grads          | -0.09809216614812613   |
| train_0/mu_grads_std      | 0.5957691073417664     |
| train_0/mu_loss           | 2.1398335766586287     |
| train_0/next_q            | -1.9711774622282214    |
| train_0/q_grads           | 0.03878336613997817    |
| train_0/q_grads_std       | 0.5634513705968857     |
| train_0/q_loss            | 0.29876212021007814    |
| train_0/reward            | -0.8604224807655555    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0559814453125        |
| train_0/target_q          | -2.372999122750098     |
| train_1/avg_q             | -8.567488300093327     |
| train_1/current_q         | -3.8150965887224153    |
| train_1/fw_bonus          | -1.010795596241951     |
| train_1/fw_loss           | 0.00036187707228236833 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.8035779112354007     |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -3.6999754049999174    |
| train_1/q_grads           | -0.03696967400610447   |
| train_1/q_grads_std       | 0.7902842000126838     |
| train_1/q_loss            | 0.6711272111675498     |
| train_1/reward            | -0.8943943029502407    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 9.765625e-05           |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9123867069486404     |
| train_1/target_q          | -4.005141210646056     |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 35
Time for epoch 35: 272.27. Rollout time: 24.93, Training time: 247.26
Evaluating epoch 35
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 243481.0               |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -2.6650392515342167    |
| test_1/avg_q              | -8.201843324808067     |
| test_1/n_subgoals         | 1628.0                 |
| test_1/subgoal_succ_rate  | 0.9680589680589681     |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -3.229202205781196     |
| train_0/current_q         | -2.380697885329429     |
| train_0/fw_bonus          | -0.9994711130857468    |
| train_0/fw_loss           | 0.00011966428464802448 |
| train_0/mu_grads          | -0.10075845383107662   |
| train_0/mu_grads_std      | 0.6010665833950043     |
| train_0/mu_loss           | 2.182095501285797      |
| train_0/next_q            | -2.0082179973422916    |
| train_0/q_grads           | 0.03796968795359135    |
| train_0/q_grads_std       | 0.5698444724082947     |
| train_0/q_loss            | 0.2784369944497678     |
| train_0/reward            | -0.8614380489074392    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0513427734375        |
| train_0/target_q          | -2.416828633002015     |
| train_1/avg_q             | -8.359515573854308     |
| train_1/current_q         | -3.8014307088018575    |
| train_1/fw_bonus          | -1.010846808552742     |
| train_1/fw_loss           | 0.0003509569614834618  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.783898158835804      |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.6945247456432773    |
| train_1/q_grads           | -0.039476094860583545  |
| train_1/q_grads_std       | 0.8011386692523956     |
| train_1/q_loss            | 0.7337856240402825     |
| train_1/reward            | -0.8937918369789258    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9155778894472362     |
| train_1/target_q          | -3.9928748360661315    |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 36
Time for epoch 36: 278.60. Rollout time: 26.43, Training time: 252.05
Evaluating epoch 36
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 248615.0               |
| test/episodes             | 925.0                  |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.7163397823230617    |
| test_1/avg_q              | -8.916564374760437     |
| test_1/n_subgoals         | 1972.0                 |
| test_1/subgoal_succ_rate  | 0.9898580121703854     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.373944839243062     |
| train_0/current_q         | -2.3882610973005263    |
| train_0/fw_bonus          | -0.9994946792721748    |
| train_0/fw_loss           | 0.00011513145236676791 |
| train_0/mu_grads          | -0.10166243501007557   |
| train_0/mu_grads_std      | 0.6052154660224914     |
| train_0/mu_loss           | 2.2098046904754454     |
| train_0/next_q            | -2.0302286635188675    |
| train_0/q_grads           | 0.03757432857528329    |
| train_0/q_grads_std       | 0.5769251599907875     |
| train_0/q_loss            | 0.279073677648475      |
| train_0/reward            | -0.8619623203761876    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.053515625            |
| train_0/target_q          | -2.412879815447186     |
| train_1/avg_q             | -8.920461537607794     |
| train_1/current_q         | -3.910791025363892     |
| train_1/fw_bonus          | -1.0107950150966645    |
| train_1/fw_loss           | 0.0003620006566052325  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.898064889411337      |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.7917787388772326    |
| train_1/q_grads           | -0.04097539260983467   |
| train_1/q_grads_std       | 0.8107937902212143     |
| train_1/q_loss            | 0.8455340894141129     |
| train_1/reward            | -0.8974639367268538    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9085427135678392     |
| train_1/target_q          | -4.10636009361266      |
------------------------------------------------------
New best value for test/success_rate: 0.04. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 37
Time for epoch 37: 278.90. Rollout time: 23.72, Training time: 255.09
Evaluating epoch 37
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 253464.0               |
| test/episodes             | 950.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6027058135371552    |
| test_1/avg_q              | -9.146255555360943     |
| test_1/n_subgoals         | 1835.0                 |
| test_1/subgoal_succ_rate  | 0.9912806539509537     |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.2578521320094254    |
| train_0/current_q         | -2.388454912464296     |
| train_0/fw_bonus          | -0.9995027765631675    |
| train_0/fw_loss           | 0.00011357464591128519 |
| train_0/mu_grads          | -0.10416250061243773   |
| train_0/mu_grads_std      | 0.6100656256079674     |
| train_0/mu_loss           | 2.1908026580096918     |
| train_0/next_q            | -2.0181649795694616    |
| train_0/q_grads           | 0.036789643671363594   |
| train_0/q_grads_std       | 0.5836265474557877     |
| train_0/q_loss            | 0.2332676287155205     |
| train_0/reward            | -0.8619805992479087    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05361328125          |
| train_0/target_q          | -2.4224633060227783    |
| train_1/avg_q             | -9.108507923017745     |
| train_1/current_q         | -3.9188048191223843    |
| train_1/fw_bonus          | -1.0106518805027007    |
| train_1/fw_loss           | 0.00039252785500139    |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9152722114358105     |
| train_1/n_subgoals        | 996.0                  |
| train_1/next_q            | -3.782579151789536     |
| train_1/q_grads           | -0.04150643888860941   |
| train_1/q_grads_std       | 0.8178105890750885     |
| train_1/q_loss            | 0.7192137091174711     |
| train_1/reward            | -0.8952142465423094    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9377510040160643     |
| train_1/target_q          | -4.130399197303204     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 38
Time for epoch 38: 280.91. Rollout time: 23.28, Training time: 257.52
Evaluating epoch 38
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 38                     |
| policy/steps              | 258192.0               |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.5316922318801622    |
| test_1/avg_q              | -9.463719718420903     |
| test_1/n_subgoals         | 1840.0                 |
| test_1/subgoal_succ_rate  | 0.9875                 |
| train/episodes            | 3900.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -2.8045437661375376    |
| train_0/current_q         | -2.449168955633912     |
| train_0/fw_bonus          | -0.9994846463203431    |
| train_0/fw_loss           | 0.00011706197547027841 |
| train_0/mu_grads          | -0.10552771128714085   |
| train_0/mu_grads_std      | 0.6155969366431236     |
| train_0/mu_loss           | 2.240460001003279      |
| train_0/next_q            | -2.067363901499473     |
| train_0/q_grads           | 0.03655069256201386    |
| train_0/q_grads_std       | 0.5913112238049507     |
| train_0/q_loss            | 0.22126664217709205    |
| train_0/reward            | -0.8618754448456457    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.050634765625         |
| train_0/target_q          | -2.4811335984077294    |
| train_1/avg_q             | -9.190157299538967     |
| train_1/current_q         | -3.9416743876729923    |
| train_1/fw_bonus          | -1.0107756972312927    |
| train_1/fw_loss           | 0.0003661198628833517  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.947971929824169      |
| train_1/n_subgoals        | 988.0                  |
| train_1/next_q            | -3.818697519887123     |
| train_1/q_grads           | -0.04374469425529241   |
| train_1/q_grads_std       | 0.8241630226373673     |
| train_1/q_loss            | 0.8594364019605545     |
| train_1/reward            | -0.8940925169081311    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9423076923076923     |
| train_1/target_q          | -4.1646956177559336    |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 39
Time for epoch 39: 272.07. Rollout time: 24.50, Training time: 247.45
Evaluating epoch 39
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 263165.0               |
| test/episodes             | 1000.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.6800363219216738    |
| test_1/avg_q              | -9.180730279287134     |
| test_1/n_subgoals         | 1778.0                 |
| test_1/subgoal_succ_rate  | 0.9870641169853769     |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.255717734691826     |
| train_0/current_q         | -2.3466782837411673    |
| train_0/fw_bonus          | -0.9994170770049096    |
| train_0/fw_loss           | 0.00013005284181417666 |
| train_0/mu_grads          | -0.10723605453968048   |
| train_0/mu_grads_std      | 0.621507354080677      |
| train_0/mu_loss           | 2.1281223280059733     |
| train_0/next_q            | -1.9490662280276396    |
| train_0/q_grads           | 0.03579687075689435    |
| train_0/q_grads_std       | 0.5982373148202896     |
| train_0/q_loss            | 0.1890208986036428     |
| train_0/reward            | -0.8616416706063319    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.055810546875         |
| train_0/target_q          | -2.3763635834019383    |
| train_1/avg_q             | -8.931473981178273     |
| train_1/current_q         | -3.9908354929211987    |
| train_1/fw_bonus          | -1.010756492614746     |
| train_1/fw_loss           | 0.0003702152600453701  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9979806218467706     |
| train_1/n_subgoals        | 996.0                  |
| train_1/next_q            | -3.8558968163394978    |
| train_1/q_grads           | -0.04531711246818304   |
| train_1/q_grads_std       | 0.8336810886859893     |
| train_1/q_loss            | 0.7462997581777893     |
| train_1/reward            | -0.8953781634074403    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9216867469879518     |
| train_1/target_q          | -4.220943010459568     |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 40
Time for epoch 40: 271.16. Rollout time: 22.56, Training time: 248.52
Evaluating epoch 40
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 267941.0               |
| test/episodes             | 1025.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.639005861083449     |
| test_1/avg_q              | -9.850290241574498     |
| test_1/n_subgoals         | 2022.0                 |
| test_1/subgoal_succ_rate  | 0.9876360039564788     |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.1086073494968414    |
| train_0/current_q         | -2.3758525831048276    |
| train_0/fw_bonus          | -0.9995032951235772    |
| train_0/fw_loss           | 0.00011347481813572813 |
| train_0/mu_grads          | -0.10811681915074586   |
| train_0/mu_grads_std      | 0.6272254556417465     |
| train_0/mu_loss           | 2.1862988464769453     |
| train_0/next_q            | -2.005618185505854     |
| train_0/q_grads           | 0.03542611710727215    |
| train_0/q_grads_std       | 0.6059611558914184     |
| train_0/q_loss            | 0.23755099850083372    |
| train_0/reward            | -0.8621335765885305    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.049755859375         |
| train_0/target_q          | -2.4069762505133907    |
| train_1/avg_q             | -9.437766123142305     |
| train_1/current_q         | -4.083000191907806     |
| train_1/fw_bonus          | -1.0106216549873352    |
| train_1/fw_loss           | 0.0003989721568359528  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.072623754496645      |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -3.995937961161573     |
| train_1/q_grads           | -0.04565641637891531   |
| train_1/q_grads_std       | 0.8450278684496879     |
| train_1/q_loss            | 0.7363792473085257     |
| train_1/reward            | -0.8929088682984002    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 4.8828125e-05          |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9436052366565961     |
| train_1/target_q          | -4.340318050058795     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 41
Time for epoch 41: 284.32. Rollout time: 25.42, Training time: 258.82
Evaluating epoch 41
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 41                    |
| policy/steps              | 272730.0              |
| test/episodes             | 1050.0                |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.6383882121636988   |
| test_1/avg_q              | -9.704742835705938    |
| test_1/n_subgoals         | 1779.0                |
| test_1/subgoal_succ_rate  | 0.9881956155143339    |
| train/episodes            | 4200.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -3.0699609088535915   |
| train_0/current_q         | -2.308268670694247    |
| train_0/fw_bonus          | -0.9994133859872818   |
| train_0/fw_loss           | 0.0001307658567384351 |
| train_0/mu_grads          | -0.10992846302688122  |
| train_0/mu_grads_std      | 0.6331108659505844    |
| train_0/mu_loss           | 2.1220698945084173    |
| train_0/next_q            | -1.9402154512760088   |
| train_0/q_grads           | 0.03573942454531789   |
| train_0/q_grads_std       | 0.6132888153195382    |
| train_0/q_loss            | 0.24052121891360176   |
| train_0/reward            | -0.8624079325265483   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0552001953125       |
| train_0/target_q          | -2.3468263178358706   |
| train_1/avg_q             | -9.570701359570851    |
| train_1/current_q         | -4.092341349855083    |
| train_1/fw_bonus          | -1.0106957703828812   |
| train_1/fw_loss           | 0.0003831686088233255 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.092691625343582     |
| train_1/n_subgoals        | 993.0                 |
| train_1/next_q            | -4.026591985650735    |
| train_1/q_grads           | -0.04694774430245161  |
| train_1/q_grads_std       | 0.8550767943263053    |
| train_1/q_loss            | 0.6701491545867722    |
| train_1/reward            | -0.8873797291103983   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9425981873111783    |
| train_1/target_q          | -4.356876613457087    |
-----------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.07
Training epoch 42
Time for epoch 42: 261.29. Rollout time: 20.12, Training time: 241.08
Evaluating epoch 42
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 277368.0               |
| test/episodes             | 1075.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.2439293103784537    |
| test_1/avg_q              | -9.86597572786965      |
| test_1/n_subgoals         | 2112.0                 |
| test_1/subgoal_succ_rate  | 0.9957386363636364     |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -2.8638704552369547    |
| train_0/current_q         | -2.268682468415538     |
| train_0/fw_bonus          | -0.9994692385196686    |
| train_0/fw_loss           | 0.00012002425100945401 |
| train_0/mu_grads          | -0.11036553252488375   |
| train_0/mu_grads_std      | 0.6391958087682724     |
| train_0/mu_loss           | 2.055274774359711      |
| train_0/next_q            | -1.8694869345998981    |
| train_0/q_grads           | 0.03542254026979208    |
| train_0/q_grads_std       | 0.6198886409401894     |
| train_0/q_loss            | 0.1781519983612851     |
| train_0/reward            | -0.862932006351184     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0553955078125        |
| train_0/target_q          | -2.291669186208633     |
| train_1/avg_q             | -9.476278342784518     |
| train_1/current_q         | -3.989747187849878     |
| train_1/fw_bonus          | -1.0108048081398011    |
| train_1/fw_loss           | 0.00035991504482808524 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.984563383007452      |
| train_1/n_subgoals        | 989.0                  |
| train_1/next_q            | -3.8885010995000284    |
| train_1/q_grads           | -0.047204796317964794  |
| train_1/q_grads_std       | 0.8657680332660675     |
| train_1/q_loss            | 0.8814716586613297     |
| train_1/reward            | -0.883268390133162     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9565217391304348     |
| train_1/target_q          | -4.237228759963517     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.060000000000000005
Training epoch 43
Time for epoch 43: 280.07. Rollout time: 22.31, Training time: 257.67
Evaluating epoch 43
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 282071.0               |
| test/episodes             | 1100.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.457533251541423     |
| test_1/avg_q              | -9.879690127570793     |
| test_1/n_subgoals         | 2210.0                 |
| test_1/subgoal_succ_rate  | 0.9936651583710407     |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.843764402365587     |
| train_0/current_q         | -2.192355803426344     |
| train_0/fw_bonus          | -0.9994352638721467    |
| train_0/fw_loss           | 0.00012655612827074946 |
| train_0/mu_grads          | -0.11097252555191517   |
| train_0/mu_grads_std      | 0.6444387570023536     |
| train_0/mu_loss           | 1.986271173583411      |
| train_0/next_q            | -1.7877117337619772    |
| train_0/q_grads           | 0.03608934693038464    |
| train_0/q_grads_std       | 0.6265332370996475     |
| train_0/q_loss            | 0.18729163648476915    |
| train_0/reward            | -0.8627905627799919    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0558349609375        |
| train_0/target_q          | -2.214663037012518     |
| train_1/avg_q             | -9.789223055826222     |
| train_1/current_q         | -4.052229410497517     |
| train_1/fw_bonus          | -1.010826337337494     |
| train_1/fw_loss           | 0.00035531959074432964 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.053721593732984      |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -3.9789251122514573    |
| train_1/q_grads           | -0.04930538320913911   |
| train_1/q_grads_std       | 0.8737470611929894     |
| train_1/q_loss            | 0.552316564189803      |
| train_1/reward            | -0.8818380183249246    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9416498993963782     |
| train_1/target_q          | -4.318933548600226     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 44
Time for epoch 44: 285.50. Rollout time: 23.25, Training time: 262.14
Evaluating epoch 44
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 286827.0               |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5030848967234594    |
| test_1/avg_q              | -9.938346118513815     |
| test_1/n_subgoals         | 1522.0                 |
| test_1/subgoal_succ_rate  | 0.9540078843626807     |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.0283176052235823    |
| train_0/current_q         | -2.1943791859923985    |
| train_0/fw_bonus          | -0.9995069950819016    |
| train_0/fw_loss           | 0.00011276293771516066 |
| train_0/mu_grads          | -0.11270147617906331   |
| train_0/mu_grads_std      | 0.6491625532507896     |
| train_0/mu_loss           | 1.9908449807597457     |
| train_0/next_q            | -1.798504381908693     |
| train_0/q_grads           | 0.03588078301399946    |
| train_0/q_grads_std       | 0.6334013700485229     |
| train_0/q_loss            | 0.19227607675212652    |
| train_0/reward            | -0.8620142829444376    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0532470703125        |
| train_0/target_q          | -2.217490407910498     |
| train_1/avg_q             | -9.517196249064554     |
| train_1/current_q         | -4.056271815604991     |
| train_1/fw_bonus          | -1.0110281258821487    |
| train_1/fw_loss           | 0.0003122854213870596  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.061438389438914      |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -4.00860296901178      |
| train_1/q_grads           | -0.049703773483633994  |
| train_1/q_grads_std       | 0.878803725540638      |
| train_1/q_loss            | 0.5176381656187921     |
| train_1/reward            | -0.878705666771566     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9448345035105316     |
| train_1/target_q          | -4.326997241758331     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 45
Time for epoch 45: 278.38. Rollout time: 21.01, Training time: 257.28
Evaluating epoch 45
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 45                     |
| policy/steps              | 291416.0               |
| test/episodes             | 1150.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2826220536181963    |
| test_1/avg_q              | -9.768953074159903     |
| test_1/n_subgoals         | 2239.0                 |
| test_1/subgoal_succ_rate  | 0.9946404644930773     |
| train/episodes            | 4600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.4712443242776856    |
| train_0/current_q         | -2.2476013231011485    |
| train_0/fw_bonus          | -0.9995046943426132    |
| train_0/fw_loss           | 0.00011320628764224238 |
| train_0/mu_grads          | -0.11361620519310237   |
| train_0/mu_grads_std      | 0.6536819562315941     |
| train_0/mu_loss           | 2.0339102165295677     |
| train_0/next_q            | -1.840469656551128     |
| train_0/q_grads           | 0.03495985269546509    |
| train_0/q_grads_std       | 0.6402467280626297     |
| train_0/q_loss            | 0.16226028741974297    |
| train_0/reward            | -0.8633858446904924    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0512451171875        |
| train_0/target_q          | -2.2748277347216392    |
| train_1/avg_q             | -9.85951283811155      |
| train_1/current_q         | -4.142177196857825     |
| train_1/fw_bonus          | -1.0110561430454255    |
| train_1/fw_loss           | 0.0003063103416934609  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.1481790252322455     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.109076986157751     |
| train_1/q_grads           | -0.049707459099590776  |
| train_1/q_grads_std       | 0.8821964398026466     |
| train_1/q_loss            | 0.5101989570909732     |
| train_1/reward            | -0.8758030954719288    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 7.32421875e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.961                  |
| train_1/target_q          | -4.414597782353627     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 46
Time for epoch 46: 304.90. Rollout time: 25.63, Training time: 279.17
Evaluating epoch 46
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 46                    |
| policy/steps              | 296220.0              |
| test/episodes             | 1175.0                |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.8613994188001417   |
| test_1/avg_q              | -9.511781967903168    |
| test_1/n_subgoals         | 1953.0                |
| test_1/subgoal_succ_rate  | 0.9871991807475679    |
| train/episodes            | 4700.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -3.343204092919339    |
| train_0/current_q         | -2.216162207798991    |
| train_0/fw_bonus          | -0.9994574740529061   |
| train_0/fw_loss           | 0.00012228746436449   |
| train_0/mu_grads          | -0.114660320058465    |
| train_0/mu_grads_std      | 0.6590952113270759    |
| train_0/mu_loss           | 2.0049318434162156    |
| train_0/next_q            | -1.8048187090360543   |
| train_0/q_grads           | 0.03427279470488429   |
| train_0/q_grads_std       | 0.6474153161048889    |
| train_0/q_loss            | 0.1676641770042268    |
| train_0/reward            | -0.863661703991238    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.056494140625        |
| train_0/target_q          | -2.2342846078361305   |
| train_1/avg_q             | -9.554590588508054    |
| train_1/current_q         | -4.0517747379274525   |
| train_1/fw_bonus          | -1.011066922545433    |
| train_1/fw_loss           | 0.0003040145034901798 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.062671910156261     |
| train_1/n_subgoals        | 998.0                 |
| train_1/next_q            | -3.9894313215117494   |
| train_1/q_grads           | -0.05190253183245659  |
| train_1/q_grads_std       | 0.8862203180789947    |
| train_1/q_loss            | 0.4884651335365472    |
| train_1/reward            | -0.8765557981707388   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9228456913827655    |
| train_1/target_q          | -4.317095609494848    |
-----------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 47
Time for epoch 47: 310.37. Rollout time: 30.01, Training time: 280.26
Evaluating epoch 47
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 47                     |
| policy/steps              | 301303.0               |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5651824601076256    |
| test_1/avg_q              | -9.551585663360365     |
| test_1/n_subgoals         | 2011.0                 |
| test_1/subgoal_succ_rate  | 0.9905519641969169     |
| train/episodes            | 4800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.9295958056571028    |
| train_0/current_q         | -2.195447147466914     |
| train_0/fw_bonus          | -0.9994978755712509    |
| train_0/fw_loss           | 0.00011451905629655812 |
| train_0/mu_grads          | -0.11528045311570168   |
| train_0/mu_grads_std      | 0.6642926961183548     |
| train_0/mu_loss           | 1.9811743853092758     |
| train_0/next_q            | -1.7798071754012603    |
| train_0/q_grads           | 0.034246272314339875   |
| train_0/q_grads_std       | 0.6553830787539482     |
| train_0/q_loss            | 0.16368458706720582    |
| train_0/reward            | -0.8641741817831644    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0533203125           |
| train_0/target_q          | -2.2215300955352175    |
| train_1/avg_q             | -9.630192756088734     |
| train_1/current_q         | -4.004358440758901     |
| train_1/fw_bonus          | -1.0111234813928605    |
| train_1/fw_loss           | 0.00029194921044108926 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.002523366996222      |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.930577132155951     |
| train_1/q_grads           | -0.05252251913771033   |
| train_1/q_grads_std       | 0.8900113150477409     |
| train_1/q_loss            | 0.5193093409852494     |
| train_1/reward            | -0.8765432966974913    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9105527638190954     |
| train_1/target_q          | -4.261038203382787     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 48
Time for epoch 48: 298.21. Rollout time: 26.46, Training time: 271.67
Evaluating epoch 48
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 306286.0               |
| test/episodes             | 1225.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3883611073087003    |
| test_1/avg_q              | -9.90443133911753      |
| test_1/n_subgoals         | 2122.0                 |
| test_1/subgoal_succ_rate  | 0.9952874646559849     |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.608273864287451     |
| train_0/current_q         | -2.2209934174343227    |
| train_0/fw_bonus          | -0.9994719222187995    |
| train_0/fw_loss           | 0.00011950777825404657 |
| train_0/mu_grads          | -0.11701015997678041   |
| train_0/mu_grads_std      | 0.6697563543915749     |
| train_0/mu_loss           | 2.0049200053343235     |
| train_0/next_q            | -1.800456776940748     |
| train_0/q_grads           | 0.03446827856823802    |
| train_0/q_grads_std       | 0.6623549088835716     |
| train_0/q_loss            | 0.1457125033675142     |
| train_0/reward            | -0.864447692714748     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0579345703125        |
| train_0/target_q          | -2.246095037246234     |
| train_1/avg_q             | -9.531320424630547     |
| train_1/current_q         | -3.9821752937477948    |
| train_1/fw_bonus          | -1.0110716074705124    |
| train_1/fw_loss           | 0.00030301412771223114 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9868323656368823     |
| train_1/n_subgoals        | 999.0                  |
| train_1/next_q            | -3.9149164153709735    |
| train_1/q_grads           | -0.053539021499454977  |
| train_1/q_grads_std       | 0.8956405147910118     |
| train_1/q_loss            | 0.4698768566723401     |
| train_1/reward            | -0.876235829993675     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.92992992992993       |
| train_1/target_q          | -4.239384308131525     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 49
Time for epoch 49: 299.47. Rollout time: 26.78, Training time: 272.58
Evaluating epoch 49
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 311359.0               |
| test/episodes             | 1250.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6918342818115042    |
| test_1/avg_q              | -9.96394814645244      |
| test_1/n_subgoals         | 2024.0                 |
| test_1/subgoal_succ_rate  | 0.9901185770750988     |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -4.021043479630359     |
| train_0/current_q         | -2.2292944570312665    |
| train_0/fw_bonus          | -0.999455925822258     |
| train_0/fw_loss           | 0.00012258290098543512 |
| train_0/mu_grads          | -0.11857994012534619   |
| train_0/mu_grads_std      | 0.6753762617707253     |
| train_0/mu_loss           | 2.0120898915755823     |
| train_0/next_q            | -1.8163998925746072    |
| train_0/q_grads           | 0.034060017019510266   |
| train_0/q_grads_std       | 0.6699317663908004     |
| train_0/q_loss            | 0.164703326267014      |
| train_0/reward            | -0.8639352099839016    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.051806640625         |
| train_0/target_q          | -2.248014767515783     |
| train_1/avg_q             | -9.680446702104478     |
| train_1/current_q         | -4.005478957030272     |
| train_1/fw_bonus          | -1.0108282178640366    |
| train_1/fw_loss           | 0.0003549180648406036  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.007111691017185      |
| train_1/n_subgoals        | 989.0                  |
| train_1/next_q            | -3.9387630079598197    |
| train_1/q_grads           | -0.05442215418443084   |
| train_1/q_grads_std       | 0.9005294367671013     |
| train_1/q_loss            | 0.558175443825722      |
| train_1/reward            | -0.8794163346668938    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.897876643073812      |
| train_1/target_q          | -4.259535240833417     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 50
Time for epoch 50: 285.65. Rollout time: 23.61, Training time: 261.94
Evaluating epoch 50
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 50                    |
| policy/steps              | 315968.0              |
| test/episodes             | 1275.0                |
| test/success_rate         | 0.08                  |
| test_0/avg_q              | -1.3860374096483328   |
| test_1/avg_q              | -9.817079993629847    |
| test_1/n_subgoals         | 1955.0                |
| test_1/subgoal_succ_rate  | 0.9902813299232737    |
| train/episodes            | 5100.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -3.1896328452283345   |
| train_0/current_q         | -2.2412453958436416   |
| train_0/fw_bonus          | -0.999502158164978    |
| train_0/fw_loss           | 0.0001136915358074475 |
| train_0/mu_grads          | -0.12030677124857903  |
| train_0/mu_grads_std      | 0.6798331320285798    |
| train_0/mu_loss           | 2.0201208824515327    |
| train_0/next_q            | -1.8221100269542092   |
| train_0/q_grads           | 0.033531713951379064  |
| train_0/q_grads_std       | 0.6774949759244919    |
| train_0/q_loss            | 0.14160291584217213   |
| train_0/reward            | -0.8647694501763908   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0551513671875       |
| train_0/target_q          | -2.2695726885449092   |
| train_1/avg_q             | -9.898453248326526    |
| train_1/current_q         | -4.0649788959929065   |
| train_1/fw_bonus          | -1.0110572189092637   |
| train_1/fw_loss           | 0.0003060840936086606 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.071513621675244     |
| train_1/n_subgoals        | 996.0                 |
| train_1/next_q            | -4.008318401604823    |
| train_1/q_grads           | -0.05522978939116001  |
| train_1/q_grads_std       | 0.9062683254480361    |
| train_1/q_loss            | 0.5136284115138683    |
| train_1/reward            | -0.8788861662862473   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9267068273092369    |
| train_1/target_q          | -4.317956115736673    |
-----------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_50.pkl ...
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 51
Time for epoch 51: 292.88. Rollout time: 23.84, Training time: 268.95
Evaluating epoch 51
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 320647.0               |
| test/episodes             | 1300.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.1240941110304556    |
| test_1/avg_q              | -9.975091440756362     |
| test_1/n_subgoals         | 2202.0                 |
| test_1/subgoal_succ_rate  | 0.9963669391462306     |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.268276656416268     |
| train_0/current_q         | -2.253474738436669     |
| train_0/fw_bonus          | -0.9995349466800689    |
| train_0/fw_loss           | 0.0001073888217433705  |
| train_0/mu_grads          | -0.12075008247047662   |
| train_0/mu_grads_std      | 0.6851997047662735     |
| train_0/mu_loss           | 2.0334066373904927     |
| train_0/next_q            | -1.8296743621207896    |
| train_0/q_grads           | 0.03386026676744223    |
| train_0/q_grads_std       | 0.6848668560385704     |
| train_0/q_loss            | 0.16926167009407167    |
| train_0/reward            | -0.8635611226549372    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.056103515625         |
| train_0/target_q          | -2.262321013946599     |
| train_1/avg_q             | -9.847879799526543     |
| train_1/current_q         | -4.078587452665317     |
| train_1/fw_bonus          | -1.0111060053110124    |
| train_1/fw_loss           | 0.00029568024474428966 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.09373981055988       |
| train_1/n_subgoals        | 996.0                  |
| train_1/next_q            | -4.033967562471777     |
| train_1/q_grads           | -0.05637552198022604   |
| train_1/q_grads_std       | 0.913483613729477      |
| train_1/q_loss            | 0.4952870220593274     |
| train_1/reward            | -0.8785931642705691    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9337349397590361     |
| train_1/target_q          | -4.33685857217928      |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 52
Time for epoch 52: 324.03. Rollout time: 26.38, Training time: 297.55
Evaluating epoch 52
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 325318.0               |
| test/episodes             | 1325.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.3067476587486277    |
| test_1/avg_q              | -9.926854906260587     |
| test_1/n_subgoals         | 1982.0                 |
| test_1/subgoal_succ_rate  | 0.9873864783047427     |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.8689733837328046    |
| train_0/current_q         | -2.242053754741766     |
| train_0/fw_bonus          | -0.9995251521468163    |
| train_0/fw_loss           | 0.00010927233306574635 |
| train_0/mu_grads          | -0.12231448832899332   |
| train_0/mu_grads_std      | 0.6899167731404304     |
| train_0/mu_loss           | 2.0186050795649075     |
| train_0/next_q            | -1.8195691112154229    |
| train_0/q_grads           | 0.033590312395244834   |
| train_0/q_grads_std       | 0.6929548919200897     |
| train_0/q_loss            | 0.1360336197138175     |
| train_0/reward            | -0.8638955732356408    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0551513671875        |
| train_0/target_q          | -2.2519015145619283    |
| train_1/avg_q             | -9.718927050883877     |
| train_1/current_q         | -4.092544361136246     |
| train_1/fw_bonus          | -1.0112736374139786    |
| train_1/fw_loss           | 0.00025992713162850125 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.0949269851664525     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.048800667985675     |
| train_1/q_grads           | -0.05598687855526805   |
| train_1/q_grads_std       | 0.9179292142391204     |
| train_1/q_loss            | 0.4471311008736392     |
| train_1/reward            | -0.8779071306184051    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.944                  |
| train_1/target_q          | -4.352578472437564     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 53
Time for epoch 53: 316.83. Rollout time: 27.08, Training time: 289.60
Evaluating epoch 53
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 330062.0               |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.5167559814564033    |
| test_1/avg_q              | -9.846089773493622     |
| test_1/n_subgoals         | 2025.0                 |
| test_1/subgoal_succ_rate  | 0.9920987654320987     |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.194967260266966     |
| train_0/current_q         | -2.2325616532307984    |
| train_0/fw_bonus          | -0.9995376631617546    |
| train_0/fw_loss           | 0.00010686793084460077 |
| train_0/mu_grads          | -0.124199771694839     |
| train_0/mu_grads_std      | 0.6956233352422714     |
| train_0/mu_loss           | 2.0175253444151973     |
| train_0/next_q            | -1.8164052401373083    |
| train_0/q_grads           | 0.032972837518900636   |
| train_0/q_grads_std       | 0.7000241592526436     |
| train_0/q_loss            | 0.14042370542150265    |
| train_0/reward            | -0.8646923048421741    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0511962890625        |
| train_0/target_q          | -2.2498490820761092    |
| train_1/avg_q             | -9.783475177052113     |
| train_1/current_q         | -4.089502009509474     |
| train_1/fw_bonus          | -1.0111235588788987    |
| train_1/fw_loss           | 0.0002919353410106851  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.09514244350311       |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -4.051779360065289     |
| train_1/q_grads           | -0.05688449339941144   |
| train_1/q_grads_std       | 0.9238267317414284     |
| train_1/q_loss            | 0.5051956020601567     |
| train_1/reward            | -0.8789847520514741    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9234642497482377     |
| train_1/target_q          | -4.34841496362177      |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 54
Time for epoch 54: 300.44. Rollout time: 24.26, Training time: 276.09
Evaluating epoch 54
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 54                     |
| policy/steps              | 334664.0               |
| test/episodes             | 1375.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.6065580640984227    |
| test_1/avg_q              | -9.937022327012471     |
| test_1/n_subgoals         | 2022.0                 |
| test_1/subgoal_succ_rate  | 0.9886251236399605     |
| train/episodes            | 5500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.9581973363494916    |
| train_0/current_q         | -2.285303104891309     |
| train_0/fw_bonus          | -0.9995400488376618    |
| train_0/fw_loss           | 0.00010640678247000323 |
| train_0/mu_grads          | -0.12535056322813035   |
| train_0/mu_grads_std      | 0.7005074515938758     |
| train_0/mu_loss           | 2.0886750687073614     |
| train_0/next_q            | -1.8786508367020347    |
| train_0/q_grads           | 0.03280378505587578    |
| train_0/q_grads_std       | 0.7080071493983269     |
| train_0/q_loss            | 0.1309825502723838     |
| train_0/reward            | -0.8664275021437788    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.057080078125         |
| train_0/target_q          | -2.313861705855218     |
| train_1/avg_q             | -9.741338891184714     |
| train_1/current_q         | -4.047932318996985     |
| train_1/fw_bonus          | -1.0113457649946214    |
| train_1/fw_loss           | 0.0002445467536745127  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.051519827107211      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.025929595937109     |
| train_1/q_grads           | -0.05732167027890682   |
| train_1/q_grads_std       | 0.9290886044502258     |
| train_1/q_loss            | 0.38343085735717275    |
| train_1/reward            | -0.874659217541921     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.943                  |
| train_1/target_q          | -4.313218111799342     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.04
Training epoch 55
Time for epoch 55: 297.85. Rollout time: 22.98, Training time: 274.78
Evaluating epoch 55
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 55                     |
| policy/steps              | 339280.0               |
| test/episodes             | 1400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4026872365960772    |
| test_1/avg_q              | -9.921679943081116     |
| test_1/n_subgoals         | 2027.0                 |
| test_1/subgoal_succ_rate  | 0.9950666008880118     |
| train/episodes            | 5600.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.8070373132711546    |
| train_0/current_q         | -2.233877260573368     |
| train_0/fw_bonus          | -0.999526946246624     |
| train_0/fw_loss           | 0.00010892910722759552 |
| train_0/mu_grads          | -0.12598931305110456   |
| train_0/mu_grads_std      | 0.706204180419445      |
| train_0/mu_loss           | 2.009081458889961      |
| train_0/next_q            | -1.8034603002733764    |
| train_0/q_grads           | 0.030977115733549      |
| train_0/q_grads_std       | 0.715274827182293      |
| train_0/q_loss            | 0.10976462344322054    |
| train_0/reward            | -0.8660087285010377    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05341796875          |
| train_0/target_q          | -2.255275870073335     |
| train_1/avg_q             | -9.881365933662883     |
| train_1/current_q         | -4.034676506830619     |
| train_1/fw_bonus          | -1.0113230347633362    |
| train_1/fw_loss           | 0.0002493931639037328  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.026296676939053      |
| train_1/n_subgoals        | 999.0                  |
| train_1/next_q            | -4.003160655157295     |
| train_1/q_grads           | -0.05790991522371769   |
| train_1/q_grads_std       | 0.9341535598039628     |
| train_1/q_loss            | 0.3731218820718189     |
| train_1/reward            | -0.8727989126564353    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.94994994994995       |
| train_1/target_q          | -4.305305678484109     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 56
Time for epoch 56: 304.52. Rollout time: 25.33, Training time: 279.08
Evaluating epoch 56
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 344035.0               |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.9818590283747853    |
| test_1/avg_q              | -9.99155319319471      |
| test_1/n_subgoals         | 2313.0                 |
| test_1/subgoal_succ_rate  | 0.9987029831387808     |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.1888955750274928    |
| train_0/current_q         | -2.2312797790784105    |
| train_0/fw_bonus          | -0.9995232775807381    |
| train_0/fw_loss           | 0.00010963253153022379 |
| train_0/mu_grads          | -0.12717108391225337   |
| train_0/mu_grads_std      | 0.7108922392129898     |
| train_0/mu_loss           | 2.0055321014270033     |
| train_0/next_q            | -1.796512892202734     |
| train_0/q_grads           | 0.030890802340582012   |
| train_0/q_grads_std       | 0.7214033678174019     |
| train_0/q_loss            | 0.10652362504544928    |
| train_0/reward            | -0.8674036895434256    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05966796875          |
| train_0/target_q          | -2.255862307090273     |
| train_1/avg_q             | -9.70584896910912      |
| train_1/current_q         | -4.006862085277904     |
| train_1/fw_bonus          | -1.0112789779901505    |
| train_1/fw_loss           | 0.0002587870712886797  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9890802345052103     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.973134015844015     |
| train_1/q_grads           | -0.05839076098054648   |
| train_1/q_grads_std       | 0.9397298604249954     |
| train_1/q_loss            | 0.36572768242544446    |
| train_1/reward            | -0.8732297438749811    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.932                  |
| train_1/target_q          | -4.271380002886082     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 57
Time for epoch 57: 301.26. Rollout time: 24.59, Training time: 276.58
Evaluating epoch 57
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 348619.0               |
| test/episodes             | 1450.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.2551620483830532    |
| test_1/avg_q              | -9.742451413016235     |
| test_1/n_subgoals         | 2132.0                 |
| test_1/subgoal_succ_rate  | 0.9953095684803002     |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.7201722268936095    |
| train_0/current_q         | -2.2644108632387527    |
| train_0/fw_bonus          | -0.9995577663183213    |
| train_0/fw_loss           | 0.00010300214198650792 |
| train_0/mu_grads          | -0.12745061255991458   |
| train_0/mu_grads_std      | 0.7154533922672272     |
| train_0/mu_loss           | 2.0357398365526675     |
| train_0/next_q            | -1.8279429114170873    |
| train_0/q_grads           | 0.029849328706040977   |
| train_0/q_grads_std       | 0.7266870245337487     |
| train_0/q_loss            | 0.12298288501774875    |
| train_0/reward            | -0.8663492285748362    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0536865234375        |
| train_0/target_q          | -2.27149377837251      |
| train_1/avg_q             | -9.67543000216012      |
| train_1/current_q         | -4.0253112780342715    |
| train_1/fw_bonus          | -1.0112621754407882    |
| train_1/fw_loss           | 0.0002623715659865411  |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.008063861079767      |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -3.982916404288621     |
| train_1/q_grads           | -0.05952731054276228   |
| train_1/q_grads_std       | 0.9424897521734238     |
| train_1/q_loss            | 0.40495245428179505    |
| train_1/reward            | -0.8714837392486515    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9446680080482898     |
| train_1/target_q          | -4.287986606248955     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 58
Time for epoch 58: 313.48. Rollout time: 26.20, Training time: 287.15
Evaluating epoch 58
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 58                     |
| policy/steps              | 353280.0               |
| test/episodes             | 1475.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3984773285439773    |
| test_1/avg_q              | -9.75304307609807      |
| test_1/n_subgoals         | 2234.0                 |
| test_1/subgoal_succ_rate  | 0.9932855863921217     |
| train/episodes            | 5900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.9366155083727032    |
| train_0/current_q         | -2.195077609789685     |
| train_0/fw_bonus          | -0.9995242193341255    |
| train_0/fw_loss           | 0.0001094518585887272  |
| train_0/mu_grads          | -0.12775051333010196   |
| train_0/mu_grads_std      | 0.7201850786805153     |
| train_0/mu_loss           | 1.963009415392218      |
| train_0/next_q            | -1.7477467162245879    |
| train_0/q_grads           | 0.028061242029070853   |
| train_0/q_grads_std       | 0.7309199392795562     |
| train_0/q_loss            | 0.08569623913708657    |
| train_0/reward            | -0.8683565430736053    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0592529296875        |
| train_0/target_q          | -2.203959438237846     |
| train_1/avg_q             | -9.598495361986023     |
| train_1/current_q         | -4.030249249285892     |
| train_1/fw_bonus          | -1.0114014804363252    |
| train_1/fw_loss           | 0.00023266098396561573 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.991924954186543      |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -4.005663471808977     |
| train_1/q_grads           | -0.05974496882408857   |
| train_1/q_grads_std       | 0.9475690230727196     |
| train_1/q_loss            | 0.3733190806003854     |
| train_1/reward            | -0.8700684483919758    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9398194583751254     |
| train_1/target_q          | -4.298430471115213     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 59
Time for epoch 59: 320.30. Rollout time: 26.69, Training time: 293.52
Evaluating epoch 59
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 358001.0               |
| test/episodes             | 1500.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3042063417100391    |
| test_1/avg_q              | -9.588250983586835     |
| test_1/n_subgoals         | 2163.0                 |
| test_1/subgoal_succ_rate  | 0.9976883957466481     |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.0908906556250066    |
| train_0/current_q         | -2.2415912530732074    |
| train_0/fw_bonus          | -0.9995872423052787    |
| train_0/fw_loss           | 9.733197148307227e-05  |
| train_0/mu_grads          | -0.12844769693911076   |
| train_0/mu_grads_std      | 0.7248055800795555     |
| train_0/mu_loss           | 2.0039582251800843     |
| train_0/next_q            | -1.784801724083001     |
| train_0/q_grads           | 0.028409597184509038   |
| train_0/q_grads_std       | 0.7368280634284019     |
| train_0/q_loss            | 0.08829087640425345    |
| train_0/reward            | -0.8683488829003181    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0573974609375        |
| train_0/target_q          | -2.248592202170646     |
| train_1/avg_q             | -9.899950970439999     |
| train_1/current_q         | -4.079336412045702     |
| train_1/fw_bonus          | -1.0114862442016601    |
| train_1/fw_loss           | 0.00021458623741636983 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.049474272823514      |
| train_1/n_subgoals        | 999.0                  |
| train_1/next_q            | -4.050121341063608     |
| train_1/q_grads           | -0.05968159353360534   |
| train_1/q_grads_std       | 0.9509068876504898     |
| train_1/q_loss            | 0.3579226820295073     |
| train_1/reward            | -0.8694179011930828    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.938938938938939      |
| train_1/target_q          | -4.3539224719987475    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 60
Time for epoch 60: 345.14. Rollout time: 25.91, Training time: 319.12
Evaluating epoch 60
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 362577.0               |
| test/episodes             | 1525.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.9770487130076159    |
| test_1/avg_q              | -9.989049110234923     |
| test_1/n_subgoals         | 2336.0                 |
| test_1/subgoal_succ_rate  | 0.9987157534246576     |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.033085439861426     |
| train_0/current_q         | -2.1823650772393512    |
| train_0/fw_bonus          | -0.9995897471904754    |
| train_0/fw_loss           | 9.685255863587373e-05  |
| train_0/mu_grads          | -0.1298947434872389    |
| train_0/mu_grads_std      | 0.7278070688247681     |
| train_0/mu_loss           | 1.9467578402966912     |
| train_0/next_q            | -1.738949242881327     |
| train_0/q_grads           | 0.02786110956221819    |
| train_0/q_grads_std       | 0.7427442893385887     |
| train_0/q_loss            | 0.10034163721930475    |
| train_0/reward            | -0.8683385459895362    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0568603515625        |
| train_0/target_q          | -2.2014658691281315    |
| train_1/avg_q             | -9.870772875317343     |
| train_1/current_q         | -4.054011779287229     |
| train_1/fw_bonus          | -1.0112539023160934    |
| train_1/fw_loss           | 0.00026413333653181327 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.021557810608051      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.0253462183695286    |
| train_1/q_grads           | -0.06029653437435627   |
| train_1/q_grads_std       | 0.9541512861847877     |
| train_1/q_loss            | 0.34362023399425956    |
| train_1/reward            | -0.8696770064925659    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.946                  |
| train_1/target_q          | -4.320372549099341     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 61
Time for epoch 61: 301.71. Rollout time: 23.25, Training time: 278.34
Evaluating epoch 61
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 367120.0              |
| test/episodes             | 1550.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.0347710055634298   |
| test_1/avg_q              | -9.906612643412192    |
| test_1/n_subgoals         | 2283.0                |
| test_1/subgoal_succ_rate  | 0.9986859395532195    |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.6878878176586163   |
| train_0/current_q         | -2.258673063041857    |
| train_0/fw_bonus          | -0.9995981976389885   |
| train_0/fw_loss           | 9.522596537863137e-05 |
| train_0/mu_grads          | -0.13036419302225113  |
| train_0/mu_grads_std      | 0.7318107932806015    |
| train_0/mu_loss           | 2.0255560377662465    |
| train_0/next_q            | -1.8039104476224792   |
| train_0/q_grads           | 0.02750674234703183   |
| train_0/q_grads_std       | 0.7474181219935417    |
| train_0/q_loss            | 0.08426449255645584   |
| train_0/reward            | -0.869217693117389    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0557861328125       |
| train_0/target_q          | -2.2692156167529234   |
| train_1/avg_q             | -9.926722923760366    |
| train_1/current_q         | -4.049035661136772    |
| train_1/fw_bonus          | -1.0113261967897416   |
| train_1/fw_loss           | 0.0002487180157913826 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.024612493570804     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.019180393808954    |
| train_1/q_grads           | -0.06078572636470199  |
| train_1/q_grads_std       | 0.9596173897385597    |
| train_1/q_loss            | 0.3367665276770343    |
| train_1/reward            | -0.8676926443615229   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.952                 |
| train_1/target_q          | -4.322023250038127    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 62
Time for epoch 62: 280.46. Rollout time: 22.12, Training time: 258.24
Evaluating epoch 62
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 62                    |
| policy/steps              | 371721.0              |
| test/episodes             | 1575.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.1478549671165748   |
| test_1/avg_q              | -9.690539624753253    |
| test_1/n_subgoals         | 2164.0                |
| test_1/subgoal_succ_rate  | 0.9986136783733827    |
| train/episodes            | 6300.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.6311007326585414   |
| train_0/current_q         | -2.2666172513669722   |
| train_0/fw_bonus          | -0.9996105924248695   |
| train_0/fw_loss           | 9.28419569390826e-05  |
| train_0/mu_grads          | -0.13174091652035713  |
| train_0/mu_grads_std      | 0.7353329986333847    |
| train_0/mu_loss           | 2.0331482056052668    |
| train_0/next_q            | -1.8143239457484288   |
| train_0/q_grads           | 0.027302516577765345  |
| train_0/q_grads_std       | 0.7528534233570099    |
| train_0/q_loss            | 0.07617089585855907   |
| train_0/reward            | -0.8687387103025686   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.063623046875        |
| train_0/target_q          | -2.274506629296925    |
| train_1/avg_q             | -9.898670928983494    |
| train_1/current_q         | -4.018377415813226    |
| train_1/fw_bonus          | -1.0111379235982896   |
| train_1/fw_loss           | 0.0002888719558541197 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.002425981686042     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -3.9919182474603816   |
| train_1/q_grads           | -0.06028617005795241  |
| train_1/q_grads_std       | 0.9626914128661156    |
| train_1/q_loss            | 0.37361565839168914   |
| train_1/reward            | -0.8666603197438235   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.941                 |
| train_1/target_q          | -4.286420016715293    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 63
Time for epoch 63: 287.84. Rollout time: 21.87, Training time: 265.86
Evaluating epoch 63
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 63                    |
| policy/steps              | 376225.0              |
| test/episodes             | 1600.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.5283584639294363   |
| test_1/avg_q              | -9.993497625819975    |
| test_1/n_subgoals         | 2016.0                |
| test_1/subgoal_succ_rate  | 0.9955357142857143    |
| train/episodes            | 6400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.7479238200682436   |
| train_0/current_q         | -2.250171179071197    |
| train_0/fw_bonus          | -0.9995975375175477   |
| train_0/fw_loss           | 9.535357858112548e-05 |
| train_0/mu_grads          | -0.13369226455688477  |
| train_0/mu_grads_std      | 0.7395788803696632    |
| train_0/mu_loss           | 2.0205053621654536    |
| train_0/next_q            | -1.7991255711027947   |
| train_0/q_grads           | 0.026803451171144844  |
| train_0/q_grads_std       | 0.7595539659261703    |
| train_0/q_loss            | 0.07907914332438659   |
| train_0/reward            | -0.868875398208911    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0494873046875       |
| train_0/target_q          | -2.2613390725710323   |
| train_1/avg_q             | -9.94071609167324     |
| train_1/current_q         | -4.03669113991302     |
| train_1/fw_bonus          | -1.011408546566963    |
| train_1/fw_loss           | 0.0002311560216185171 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.013775121920406     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.006248566035753    |
| train_1/q_grads           | -0.0592698959633708   |
| train_1/q_grads_std       | 0.9653674632310867    |
| train_1/q_loss            | 0.3017756456826615    |
| train_1/reward            | -0.8647453717974714   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.948                 |
| train_1/target_q          | -4.3105563563909755   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 64
Time for epoch 64: 291.88. Rollout time: 22.68, Training time: 269.11
Evaluating epoch 64
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 380895.0               |
| test/episodes             | 1625.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.092645730592921     |
| test_1/avg_q              | -9.984552337786274     |
| test_1/n_subgoals         | 2268.0                 |
| test_1/subgoal_succ_rate  | 0.9977954144620811     |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.023665215382452     |
| train_0/current_q         | -2.2389413635985056    |
| train_0/fw_bonus          | -0.9995763599872589    |
| train_0/fw_loss           | 9.942694377969019e-05  |
| train_0/mu_grads          | -0.13490619510412216   |
| train_0/mu_grads_std      | 0.7440140530467033     |
| train_0/mu_loss           | 2.0093843151149726     |
| train_0/next_q            | -1.7849455035667758    |
| train_0/q_grads           | 0.027200452331453562   |
| train_0/q_grads_std       | 0.7661605134606362     |
| train_0/q_loss            | 0.08643483933696058    |
| train_0/reward            | -0.8693294815224363    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0652099609375        |
| train_0/target_q          | -2.2480752692341426    |
| train_1/avg_q             | -9.773650384593804     |
| train_1/current_q         | -4.008836950406099     |
| train_1/fw_bonus          | -1.011252224445343     |
| train_1/fw_loss           | 0.00026449423930898777 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.989187274760103      |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -3.982571452943405     |
| train_1/q_grads           | -0.05946427090093494   |
| train_1/q_grads_std       | 0.967917051911354      |
| train_1/q_loss            | 0.39074540637904515    |
| train_1/reward            | -0.8657694878711482    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9396378269617707     |
| train_1/target_q          | -4.279557760517174     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 65
Time for epoch 65: 280.84. Rollout time: 21.30, Training time: 259.45
Evaluating epoch 65
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 385474.0              |
| test/episodes             | 1650.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.1203970591292476   |
| test_1/avg_q              | -9.990515246819925    |
| test_1/n_subgoals         | 2259.0                |
| test_1/subgoal_succ_rate  | 0.9964586100044267    |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.7597388666300375   |
| train_0/current_q         | -2.245974327168298    |
| train_0/fw_bonus          | -0.9996065437793732   |
| train_0/fw_loss           | 9.362335313198856e-05 |
| train_0/mu_grads          | -0.1360500007867813   |
| train_0/mu_grads_std      | 0.7478504866361618    |
| train_0/mu_loss           | 2.0168218119355013    |
| train_0/next_q            | -1.795670769710949    |
| train_0/q_grads           | 0.02770550507120788   |
| train_0/q_grads_std       | 0.7725738197565079    |
| train_0/q_loss            | 0.07094005770673403   |
| train_0/reward            | -0.8700296076975065   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0560546875          |
| train_0/target_q          | -2.2623180020879348   |
| train_1/avg_q             | -9.881436883369924    |
| train_1/current_q         | -3.99966081324846     |
| train_1/fw_bonus          | -1.0111363649368286   |
| train_1/fw_loss           | 0.0002892026273912052 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.9751257700533493    |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -3.972028133072663    |
| train_1/q_grads           | -0.0594181515276432   |
| train_1/q_grads_std       | 0.9716902270913124    |
| train_1/q_loss            | 0.33101052209289666   |
| train_1/reward            | -0.8663661886690533   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.945                 |
| train_1/target_q          | -4.272250869860763    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 66
Time for epoch 66: 282.21. Rollout time: 22.38, Training time: 259.73
Evaluating epoch 66
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 66                    |
| policy/steps              | 390174.0              |
| test/episodes             | 1675.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.2196788877729232   |
| test_1/avg_q              | -9.992211275233968    |
| test_1/n_subgoals         | 2180.0                |
| test_1/subgoal_succ_rate  | 0.9954128440366973    |
| train/episodes            | 6700.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -3.0649042379986455   |
| train_0/current_q         | -2.276397395162693    |
| train_0/fw_bonus          | -0.9996131807565689   |
| train_0/fw_loss           | 9.234470689989394e-05 |
| train_0/mu_grads          | -0.1384152103215456   |
| train_0/mu_grads_std      | 0.75157680362463      |
| train_0/mu_loss           | 2.0445584060067348    |
| train_0/next_q            | -1.8226418658066343   |
| train_0/q_grads           | 0.027278157230466605  |
| train_0/q_grads_std       | 0.7792732819914818    |
| train_0/q_loss            | 0.07145023981240373   |
| train_0/reward            | -0.8703153564434615   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0560791015625       |
| train_0/target_q          | -2.289352915152243    |
| train_1/avg_q             | -9.740745216155263    |
| train_1/current_q         | -3.9843548493792973   |
| train_1/fw_bonus          | -1.0112348198890686   |
| train_1/fw_loss           | 0.0002682062062376644 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.9653423147040767    |
| train_1/n_subgoals        | 988.0                 |
| train_1/next_q            | -3.963675555216466    |
| train_1/q_grads           | -0.05890819188207388  |
| train_1/q_grads_std       | 0.974738122522831     |
| train_1/q_loss            | 0.34719290077476145   |
| train_1/reward            | -0.8663850956218084   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.944331983805668     |
| train_1/target_q          | -4.256804557697593    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 67
Time for epoch 67: 270.25. Rollout time: 23.55, Training time: 246.63
Evaluating epoch 67
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 67                     |
| policy/steps              | 395030.0               |
| test/episodes             | 1700.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4238757922818692    |
| test_1/avg_q              | -9.991141366451187     |
| test_1/n_subgoals         | 2195.0                 |
| test_1/subgoal_succ_rate  | 0.9936218678815489     |
| train/episodes            | 6800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.6186242046964345    |
| train_0/current_q         | -2.297772401200948     |
| train_0/fw_bonus          | -0.9995426371693611    |
| train_0/fw_loss           | 0.00010590842648525723 |
| train_0/mu_grads          | -0.13876158706843852   |
| train_0/mu_grads_std      | 0.7543004304170609     |
| train_0/mu_loss           | 2.063660700100867      |
| train_0/next_q            | -1.8396280879493088    |
| train_0/q_grads           | 0.026749679911881687   |
| train_0/q_grads_std       | 0.7856521353125572     |
| train_0/q_loss            | 0.06479034447650271    |
| train_0/reward            | -0.8703845235650078    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.06328125             |
| train_0/target_q          | -2.3073258462697703    |
| train_1/avg_q             | -9.892271339866687     |
| train_1/current_q         | -4.0458450117906795    |
| train_1/fw_bonus          | -1.0114033192396163    |
| train_1/fw_loss           | 0.00023227022793435027 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.025294537854835      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.034322423832044     |
| train_1/q_grads           | -0.05826054960489273   |
| train_1/q_grads_std       | 0.9790397062897682     |
| train_1/q_loss            | 0.34890123629777525    |
| train_1/reward            | -0.8696181625899044    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.917                  |
| train_1/target_q          | -4.315736358232753     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 68
Time for epoch 68: 275.56. Rollout time: 22.05, Training time: 253.42
Evaluating epoch 68
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 399755.0              |
| test/episodes             | 1725.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.076459562048199    |
| test_1/avg_q              | -9.996729022327886    |
| test_1/n_subgoals         | 2218.0                |
| test_1/subgoal_succ_rate  | 0.9986474301172227    |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -3.038270363294689    |
| train_0/current_q         | -2.2212036918557105   |
| train_0/fw_bonus          | -0.999616576731205    |
| train_0/fw_loss           | 9.169313689199044e-05 |
| train_0/mu_grads          | -0.14098360650241376  |
| train_0/mu_grads_std      | 0.7576720863580704    |
| train_0/mu_loss           | 1.9936526350181971    |
| train_0/next_q            | -1.7774889288451206   |
| train_0/q_grads           | 0.02649001092649996   |
| train_0/q_grads_std       | 0.7921388894319534    |
| train_0/q_loss            | 0.0902289439872105    |
| train_0/reward            | -0.8695366477622883   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.05576171875         |
| train_0/target_q          | -2.2369774960543447   |
| train_1/avg_q             | -9.859195478275376    |
| train_1/current_q         | -3.988935538797049    |
| train_1/fw_bonus          | -1.0113162845373154   |
| train_1/fw_loss           | 0.0002508284036593977 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.9685474525470434    |
| train_1/n_subgoals        | 999.0                 |
| train_1/next_q            | -3.960513784801826    |
| train_1/q_grads           | -0.0580014506354928   |
| train_1/q_grads_std       | 0.9828736707568169    |
| train_1/q_loss            | 0.4113866898722341    |
| train_1/reward            | -0.8700350760511355   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9459459459459459    |
| train_1/target_q          | -4.25264061775311     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 69
Time for epoch 69: 271.92. Rollout time: 19.67, Training time: 252.16
Evaluating epoch 69
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 404212.0               |
| test/episodes             | 1750.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5184250745783454    |
| test_1/avg_q              | -9.723764828636142     |
| test_1/n_subgoals         | 2068.0                 |
| test_1/subgoal_succ_rate  | 0.9922630560928434     |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.613773005247943     |
| train_0/current_q         | -2.2995582175328524    |
| train_0/fw_bonus          | -0.9996370643377304    |
| train_0/fw_loss           | 8.775330388743896e-05  |
| train_0/mu_grads          | -0.14105527214705943   |
| train_0/mu_grads_std      | 0.7617089822888374     |
| train_0/mu_loss           | 2.0735836753456787     |
| train_0/next_q            | -1.8519713277555787    |
| train_0/q_grads           | 0.02647693776525557    |
| train_0/q_grads_std       | 0.7993843451142311     |
| train_0/q_loss            | 0.07319425761176031    |
| train_0/reward            | -0.8694177372366539    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0590576171875        |
| train_0/target_q          | -2.314384402539664     |
| train_1/avg_q             | -9.920246024286797     |
| train_1/current_q         | -4.000496738224198     |
| train_1/fw_bonus          | -1.0115303933620452    |
| train_1/fw_loss           | 0.00020517033735814038 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.972742915344573      |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -3.9728905851269047    |
| train_1/q_grads           | -0.05851467214524746   |
| train_1/q_grads_std       | 0.9884553208947182     |
| train_1/q_loss            | 0.3329402079717252     |
| train_1/reward            | -0.8687674208311364    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9567404426559356     |
| train_1/target_q          | -4.266861905920382     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 70
Time for epoch 70: 282.64. Rollout time: 21.04, Training time: 261.50
Evaluating epoch 70
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 408823.0               |
| test/episodes             | 1775.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0396564472983814    |
| test_1/avg_q              | -9.759321373147998     |
| test_1/n_subgoals         | 2270.0                 |
| test_1/subgoal_succ_rate  | 0.9982378854625551     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.827113557795262     |
| train_0/current_q         | -2.250911290872404     |
| train_0/fw_bonus          | -0.9996554598212242    |
| train_0/fw_loss           | 8.421435868513071e-05  |
| train_0/mu_grads          | -0.14236961640417575   |
| train_0/mu_grads_std      | 0.7662363857030868     |
| train_0/mu_loss           | 2.0235209204391054     |
| train_0/next_q            | -1.7992430449901395    |
| train_0/q_grads           | 0.02631547711789608    |
| train_0/q_grads_std       | 0.8057813853025436     |
| train_0/q_loss            | 0.06405241999341307    |
| train_0/reward            | -0.8699076143806451    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0591552734375        |
| train_0/target_q          | -2.2600526581492733    |
| train_1/avg_q             | -9.787959081079945     |
| train_1/current_q         | -4.006213100572232     |
| train_1/fw_bonus          | -1.0114102065563202    |
| train_1/fw_loss           | 0.00023080241626303178 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.989051589238379      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.9853006136410216    |
| train_1/q_grads           | -0.05907049328088761   |
| train_1/q_grads_std       | 0.9945082515478134     |
| train_1/q_loss            | 0.3735041818057949     |
| train_1/reward            | -0.8677190275891917    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.957                  |
| train_1/target_q          | -4.268686495303664     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 71
Time for epoch 71: 282.27. Rollout time: 21.49, Training time: 260.68
Evaluating epoch 71
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 413428.0               |
| test/episodes             | 1800.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.051787610618539     |
| test_1/avg_q              | -9.739875994339409     |
| test_1/n_subgoals         | 2245.0                 |
| test_1/subgoal_succ_rate  | 0.9986636971046771     |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.6522885179340956    |
| train_0/current_q         | -2.288336553203688     |
| train_0/fw_bonus          | -0.999621407687664     |
| train_0/fw_loss           | 9.076379428734072e-05  |
| train_0/mu_grads          | -0.1428835667669773    |
| train_0/mu_grads_std      | 0.7695689037442207     |
| train_0/mu_loss           | 2.0643684013653028     |
| train_0/next_q            | -1.8389270829822297    |
| train_0/q_grads           | 0.026507608545944094   |
| train_0/q_grads_std       | 0.8128909468650818     |
| train_0/q_loss            | 0.07312162693659754    |
| train_0/reward            | -0.8690153701594682    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.060693359375         |
| train_0/target_q          | -2.295152853561155     |
| train_1/avg_q             | -9.908166977798457     |
| train_1/current_q         | -3.9897175879963727    |
| train_1/fw_bonus          | -1.0113922595977782    |
| train_1/fw_loss           | 0.00023462599492631852 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9797311615856374     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.966082067591725     |
| train_1/q_grads           | -0.05779194086790085   |
| train_1/q_grads_std       | 0.9995870441198349     |
| train_1/q_loss            | 0.3622512379967492     |
| train_1/reward            | -0.8666801900631981    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.955                  |
| train_1/target_q          | -4.253135929317191     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 72
Time for epoch 72: 279.54. Rollout time: 20.87, Training time: 258.57
Evaluating epoch 72
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 72                     |
| policy/steps              | 417959.0               |
| test/episodes             | 1825.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.227504008256023     |
| test_1/avg_q              | -9.882167294788866     |
| test_1/n_subgoals         | 2129.0                 |
| test_1/subgoal_succ_rate  | 0.9938938468764679     |
| train/episodes            | 7300.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.5519008112871755    |
| train_0/current_q         | -2.192411461719543     |
| train_0/fw_bonus          | -0.9996655136346817    |
| train_0/fw_loss           | 8.228260776377283e-05  |
| train_0/mu_grads          | -0.14390956722199916   |
| train_0/mu_grads_std      | 0.7744123578071594     |
| train_0/mu_loss           | 1.9653409334767917     |
| train_0/next_q            | -1.7461903619094201    |
| train_0/q_grads           | 0.026163061242550613   |
| train_0/q_grads_std       | 0.8208212167024612     |
| train_0/q_loss            | 0.08481184635915927    |
| train_0/reward            | -0.8686883423462859    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.051416015625         |
| train_0/target_q          | -2.2120915830157672    |
| train_1/avg_q             | -9.839272686420136     |
| train_1/current_q         | -4.022482135960081     |
| train_1/fw_bonus          | -1.0113537907600403    |
| train_1/fw_loss           | 0.00024283035309053959 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.014793587438134      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.003797367560732     |
| train_1/q_grads           | -0.05666764946654439   |
| train_1/q_grads_std       | 1.0039371609687806     |
| train_1/q_loss            | 0.3876992568998837     |
| train_1/reward            | -0.86492404309829      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.963                  |
| train_1/target_q          | -4.295488491746366     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 73
Time for epoch 73: 288.37. Rollout time: 21.74, Training time: 266.53
Evaluating epoch 73
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 73                    |
| policy/steps              | 422541.0              |
| test/episodes             | 1850.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.48971807567743     |
| test_1/avg_q              | -9.742744082123902    |
| test_1/n_subgoals         | 2183.0                |
| test_1/subgoal_succ_rate  | 0.9926706367384334    |
| train/episodes            | 7400.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -2.7811245379688225   |
| train_0/current_q         | -2.267291018183486    |
| train_0/fw_bonus          | -0.999618498980999    |
| train_0/fw_loss           | 9.132160957960877e-05 |
| train_0/mu_grads          | -0.14432756192982196  |
| train_0/mu_grads_std      | 0.7784024819731712    |
| train_0/mu_loss           | 2.0420767044992365    |
| train_0/next_q            | -1.8164753249765517   |
| train_0/q_grads           | 0.026498937886208294  |
| train_0/q_grads_std       | 0.8293397784233093    |
| train_0/q_loss            | 0.06918835114825017   |
| train_0/reward            | -0.8692146108776797   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0600830078125       |
| train_0/target_q          | -2.2720967888576236   |
| train_1/avg_q             | -9.916855666630982    |
| train_1/current_q         | -4.046677857801769    |
| train_1/fw_bonus          | -1.0115031540393828   |
| train_1/fw_loss           | 0.0002109803717758041 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.0393070516821314    |
| train_1/n_subgoals        | 988.0                 |
| train_1/next_q            | -4.023673930165939    |
| train_1/q_grads           | -0.0557678691111505   |
| train_1/q_grads_std       | 1.0057356029748916    |
| train_1/q_loss            | 0.41495596144582514   |
| train_1/reward            | -0.8635101719308296   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9524291497975709    |
| train_1/target_q          | -4.3150875507677595   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 268.19. Rollout time: 21.18, Training time: 246.86
Evaluating epoch 74
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 74                     |
| policy/steps              | 427250.0               |
| test/episodes             | 1875.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.132610556830031     |
| test_1/avg_q              | -9.869629924823704     |
| test_1/n_subgoals         | 2263.0                 |
| test_1/subgoal_succ_rate  | 0.9960229783473266     |
| train/episodes            | 7500.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.7905965572048466    |
| train_0/current_q         | -2.1985375616274254    |
| train_0/fw_bonus          | -0.9994781404733658    |
| train_0/fw_loss           | 0.00011831371466541896 |
| train_0/mu_grads          | -0.1449516497552395    |
| train_0/mu_grads_std      | 0.7822850495576859     |
| train_0/mu_loss           | 1.9721683776544725     |
| train_0/next_q            | -1.7474445424026677    |
| train_0/q_grads           | 0.026899218512699007   |
| train_0/q_grads_std       | 0.8365622460842133     |
| train_0/q_loss            | 0.0637903573767696     |
| train_0/reward            | -0.8693778867702349    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.057177734375         |
| train_0/target_q          | -2.207839846695817     |
| train_1/avg_q             | -9.890595446917093     |
| train_1/current_q         | -3.9423162474182893    |
| train_1/fw_bonus          | -1.0112835198640824    |
| train_1/fw_loss           | 0.00025781606600503435 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9329167409595684     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.9011475665012894    |
| train_1/q_grads           | -0.056838765274733305  |
| train_1/q_grads_std       | 1.005682173371315      |
| train_1/q_loss            | 0.4655101670702999     |
| train_1/reward            | -0.8631135294228443    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.949                  |
| train_1/target_q          | -4.198652058721547     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 75
Time for epoch 75: 286.47. Rollout time: 25.34, Training time: 261.04
Evaluating epoch 75
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 75                     |
| policy/steps              | 432107.0               |
| test/episodes             | 1900.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6249875213588663    |
| test_1/avg_q              | -9.679263754262074     |
| test_1/n_subgoals         | 2044.0                 |
| test_1/subgoal_succ_rate  | 0.9941291585127201     |
| train/episodes            | 7600.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.8950793202339957    |
| train_0/current_q         | -2.174544347214575     |
| train_0/fw_bonus          | -0.9996602088212967    |
| train_0/fw_loss           | 8.330462787853321e-05  |
| train_0/mu_grads          | -0.14664549119770526   |
| train_0/mu_grads_std      | 0.78622617572546       |
| train_0/mu_loss           | 1.9569632632364145     |
| train_0/next_q            | -1.7233737442279247    |
| train_0/q_grads           | 0.026693044044077397   |
| train_0/q_grads_std       | 0.8435589328408242     |
| train_0/q_loss            | 0.058322646274105286   |
| train_0/reward            | -0.8694472956500249    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0562744140625        |
| train_0/target_q          | -2.1796951245500784    |
| train_1/avg_q             | -9.613989625646028     |
| train_1/current_q         | -4.090346039677332     |
| train_1/fw_bonus          | -1.0112045496702193    |
| train_1/fw_loss           | 0.00027466026367619636 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.080927119954486      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.067114043545356     |
| train_1/q_grads           | -0.056537574250251056  |
| train_1/q_grads_std       | 1.0064296036958695     |
| train_1/q_loss            | 0.39877009055638785    |
| train_1/reward            | -0.8679981406254228    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.93                   |
| train_1/target_q          | -4.358761289945896     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 76
Time for epoch 76: 286.83. Rollout time: 25.61, Training time: 261.11
Evaluating epoch 76
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 76                     |
| policy/steps              | 436969.0               |
| test/episodes             | 1925.0                 |
| test/success_rate         | 0.08                   |
| test_0/avg_q              | -1.0904626978742205    |
| test_1/avg_q              | -9.925652539431331     |
| test_1/n_subgoals         | 2166.0                 |
| test_1/subgoal_succ_rate  | 0.9986149584487535     |
| train/episodes            | 7700.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.304378504753547     |
| train_0/current_q         | -2.249078388550883     |
| train_0/fw_bonus          | -0.9996494129300117    |
| train_0/fw_loss           | 8.537742069165688e-05  |
| train_0/mu_grads          | -0.14827701337635518   |
| train_0/mu_grads_std      | 0.7905636891722679     |
| train_0/mu_loss           | 2.0234662104332335     |
| train_0/next_q            | -1.7919598777433223    |
| train_0/q_grads           | 0.028200504556298255   |
| train_0/q_grads_std       | 0.8499146580696106     |
| train_0/q_loss            | 0.06154245432141027    |
| train_0/reward            | -0.8702692890830803    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.057080078125         |
| train_0/target_q          | -2.2593141238000003    |
| train_1/avg_q             | -9.641255304776234     |
| train_1/current_q         | -4.076630612975602     |
| train_1/fw_bonus          | -1.011288571357727     |
| train_1/fw_loss           | 0.00025674344979051964 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.069310971416572      |
| train_1/n_subgoals        | 997.0                  |
| train_1/next_q            | -4.055939579783186     |
| train_1/q_grads           | -0.055070852767676114  |
| train_1/q_grads_std       | 1.008373185992241      |
| train_1/q_loss            | 0.3728132128338566     |
| train_1/reward            | -0.8691780928653315    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9197592778335005     |
| train_1/target_q          | -4.345143427446963     |
------------------------------------------------------
New best value for test/success_rate: 0.08. Saving policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 77
Time for epoch 77: 284.59. Rollout time: 20.55, Training time: 263.95
Evaluating epoch 77
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 77                     |
| policy/steps              | 441259.0               |
| test/episodes             | 1950.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.392898572786639     |
| test_1/avg_q              | -9.951554089094165     |
| test_1/n_subgoals         | 2119.0                 |
| test_1/subgoal_succ_rate  | 0.9924492685228882     |
| train/episodes            | 7800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.4656976515685396    |
| train_0/current_q         | -2.2163955363209142    |
| train_0/fw_bonus          | -0.999628047645092     |
| train_0/fw_loss           | 8.948640261223773e-05  |
| train_0/mu_grads          | -0.15028484016656876   |
| train_0/mu_grads_std      | 0.7938113793730736     |
| train_0/mu_loss           | 1.9939248102171732     |
| train_0/next_q            | -1.7722787218415519    |
| train_0/q_grads           | 0.028380231373012064   |
| train_0/q_grads_std       | 0.8554947897791862     |
| train_0/q_loss            | 0.06435637981642217    |
| train_0/reward            | -0.8674639561300864    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0636474609375        |
| train_0/target_q          | -2.22685180071188      |
| train_1/avg_q             | -9.985038870195757     |
| train_1/current_q         | -4.0919413037546954    |
| train_1/fw_bonus          | -1.0115540146827697    |
| train_1/fw_loss           | 0.00020013406829093582 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.076676146571067      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.072832036531918     |
| train_1/q_grads           | -0.05517262667417526   |
| train_1/q_grads_std       | 1.0124468088150025     |
| train_1/q_loss            | 0.35841865357718095    |
| train_1/reward            | -0.8694809328415432    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.967                  |
| train_1/target_q          | -4.360541200693634     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 78
Time for epoch 78: 316.70. Rollout time: 24.69, Training time: 291.85
Evaluating epoch 78
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 78                     |
| policy/steps              | 446003.0               |
| test/episodes             | 1975.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.144344247373691     |
| test_1/avg_q              | -9.589958161137245     |
| test_1/n_subgoals         | 2282.0                 |
| test_1/subgoal_succ_rate  | 0.9973707274320771     |
| train/episodes            | 7900.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.4206961270674214    |
| train_0/current_q         | -2.168152718564046     |
| train_0/fw_bonus          | -0.9996667340397835    |
| train_0/fw_loss           | 8.20449463390105e-05   |
| train_0/mu_grads          | -0.15061075910925864   |
| train_0/mu_grads_std      | 0.7980064496397972     |
| train_0/mu_loss           | 1.9441983030649106     |
| train_0/next_q            | -1.7236942402893682    |
| train_0/q_grads           | 0.028103681886568664   |
| train_0/q_grads_std       | 0.861998638510704      |
| train_0/q_loss            | 0.07186165501567142    |
| train_0/reward            | -0.8675112907541915    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.049169921875         |
| train_0/target_q          | -2.171526815377825     |
| train_1/avg_q             | -9.794415713578658     |
| train_1/current_q         | -4.037027071942726     |
| train_1/fw_bonus          | -1.0115923702716827    |
| train_1/fw_loss           | 0.00019195285021851306 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.022806327686822      |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -4.007327037500416     |
| train_1/q_grads           | -0.054748617392033336  |
| train_1/q_grads_std       | 1.0166307359933853     |
| train_1/q_loss            | 0.36424067589685916    |
| train_1/reward            | -0.8684660028739017    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9284994964753273     |
| train_1/target_q          | -4.300847498094315     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 79
Time for epoch 79: 292.65. Rollout time: 22.13, Training time: 270.40
Evaluating epoch 79
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 450541.0               |
| test/episodes             | 2000.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0028499739058632    |
| test_1/avg_q              | -9.940317020262421     |
| test_1/n_subgoals         | 2273.0                 |
| test_1/subgoal_succ_rate  | 0.9978002639683238     |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.7157665157652082    |
| train_0/current_q         | -2.2457722679025687    |
| train_0/fw_bonus          | -0.9996245577931404    |
| train_0/fw_loss           | 9.015787836688104e-05  |
| train_0/mu_grads          | -0.15128617025911809   |
| train_0/mu_grads_std      | 0.8021604135632515     |
| train_0/mu_loss           | 2.019140090641213      |
| train_0/next_q            | -1.7953007725708527    |
| train_0/q_grads           | 0.02848441181704402    |
| train_0/q_grads_std       | 0.8690520837903023     |
| train_0/q_loss            | 0.0607008508532586     |
| train_0/reward            | -0.8680350673690554    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.064404296875         |
| train_0/target_q          | -2.2448882182901366    |
| train_1/avg_q             | -9.897128424836938     |
| train_1/current_q         | -4.0288221589387945    |
| train_1/fw_bonus          | -1.0113815307617187    |
| train_1/fw_loss           | 0.00023691758906352334 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.022593339015839      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.008487871613228     |
| train_1/q_grads           | -0.05363867934793234   |
| train_1/q_grads_std       | 1.0224959909915925     |
| train_1/q_loss            | 0.366637650196206      |
| train_1/reward            | -0.865359875665672     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.951                  |
| train_1/target_q          | -4.295563893407051     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 80
Time for epoch 80: 282.15. Rollout time: 20.27, Training time: 261.79
Evaluating epoch 80
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 80                     |
| policy/steps              | 455031.0               |
| test/episodes             | 2025.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.9748062799868181    |
| test_1/avg_q              | -9.974918272205333     |
| test_1/n_subgoals         | 2322.0                 |
| test_1/subgoal_succ_rate  | 0.9995693367786391     |
| train/episodes            | 8100.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -2.647848821527901     |
| train_0/current_q         | -2.208685983014351     |
| train_0/fw_bonus          | -0.9996641606092453    |
| train_0/fw_loss           | 8.254383192252135e-05  |
| train_0/mu_grads          | -0.15104847624897957   |
| train_0/mu_grads_std      | 0.8054268419742584     |
| train_0/mu_loss           | 1.9758006493924483     |
| train_0/next_q            | -1.7569077381488831    |
| train_0/q_grads           | 0.02922406271100044    |
| train_0/q_grads_std       | 0.8764829620718956     |
| train_0/q_loss            | 0.05179461804018894    |
| train_0/reward            | -0.868235663176165     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.06005859375          |
| train_0/target_q          | -2.213527146655239     |
| train_1/avg_q             | -9.853897866067319     |
| train_1/current_q         | -4.02043129027224      |
| train_1/fw_bonus          | -1.0114222437143325    |
| train_1/fw_loss           | 0.00022823812360002195 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.017705810956595      |
| train_1/n_subgoals        | 987.0                  |
| train_1/next_q            | -4.005813463595141     |
| train_1/q_grads           | -0.052968237549066544  |
| train_1/q_grads_std       | 1.0287470191717147     |
| train_1/q_loss            | 0.33090360985616635    |
| train_1/reward            | -0.8642673522757832    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9513677811550152     |
| train_1/target_q          | -4.2884864405737275    |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 81
Time for epoch 81: 282.55. Rollout time: 20.92, Training time: 261.54
Evaluating epoch 81
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 81                    |
| policy/steps              | 459566.0              |
| test/episodes             | 2050.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.9779501953176492   |
| test_1/avg_q              | -9.86150445330641     |
| test_1/n_subgoals         | 2303.0                |
| test_1/subgoal_succ_rate  | 1.0                   |
| train/episodes            | 8200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.768812099633561    |
| train_0/current_q         | -2.206125540110688    |
| train_0/fw_bonus          | -0.9997016519308091   |
| train_0/fw_loss           | 7.533296593464911e-05 |
| train_0/mu_grads          | -0.1514731351286173   |
| train_0/mu_grads_std      | 0.8077676638960838    |
| train_0/mu_loss           | 1.980882559075932     |
| train_0/next_q            | -1.7602937706841335   |
| train_0/q_grads           | 0.028742833621799947  |
| train_0/q_grads_std       | 0.8834213286638259    |
| train_0/q_loss            | 0.04937652157352436   |
| train_0/reward            | -0.867720575502608    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.049365234375        |
| train_0/target_q          | -2.2132180887646506   |
| train_1/avg_q             | -9.879979019529518    |
| train_1/current_q         | -4.045570248284461    |
| train_1/fw_bonus          | -1.0114037156105042   |
| train_1/fw_loss           | 0.0002321811785805039 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.040514948359876     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.042763097496513    |
| train_1/q_grads           | -0.05188553920015693  |
| train_1/q_grads_std       | 1.0340674817562103    |
| train_1/q_loss            | 0.38338416289358357   |
| train_1/reward            | -0.8623919129458955   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 2.44140625e-05        |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.949                 |
| train_1/target_q          | -4.315076418540535    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 82
Time for epoch 82: 265.90. Rollout time: 20.67, Training time: 245.15
Evaluating epoch 82
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 82                     |
| policy/steps              | 464064.0               |
| test/episodes             | 2075.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.0750719246067741    |
| test_1/avg_q              | -9.416768082037256     |
| test_1/n_subgoals         | 2027.0                 |
| test_1/subgoal_succ_rate  | 0.9925999013320178     |
| train/episodes            | 8300.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.809063013108874     |
| train_0/current_q         | -2.2090347608332914    |
| train_0/fw_bonus          | -0.9996709123253822    |
| train_0/fw_loss           | 8.124257874442264e-05  |
| train_0/mu_grads          | -0.15238000750541686   |
| train_0/mu_grads_std      | 0.8109126687049866     |
| train_0/mu_loss           | 1.9967075784753292     |
| train_0/next_q            | -1.7752055249804097    |
| train_0/q_grads           | 0.029027302376925947   |
| train_0/q_grads_std       | 0.8908940047025681     |
| train_0/q_loss            | 0.07673034248866202    |
| train_0/reward            | -0.8672519692510832    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0616943359375        |
| train_0/target_q          | -2.2193481054268887    |
| train_1/avg_q             | -9.853508701440058     |
| train_1/current_q         | -4.028454406812105     |
| train_1/fw_bonus          | -1.011476382613182     |
| train_1/fw_loss           | 0.00021668544541171287 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.011505345376104      |
| train_1/n_subgoals        | 992.0                  |
| train_1/next_q            | -4.010626725875454     |
| train_1/q_grads           | -0.05073377750813961   |
| train_1/q_grads_std       | 1.039070200920105      |
| train_1/q_loss            | 0.4330601505840674     |
| train_1/reward            | -0.8622449912130833    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9536290322580645     |
| train_1/target_q          | -4.291437671158022     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 83
Time for epoch 83: 274.99. Rollout time: 20.32, Training time: 254.58
Evaluating epoch 83
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 83                    |
| policy/steps              | 468596.0              |
| test/episodes             | 2100.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.043365890359145    |
| test_1/avg_q              | -9.870522706129394    |
| test_1/n_subgoals         | 2255.0                |
| test_1/subgoal_succ_rate  | 0.9982261640798226    |
| train/episodes            | 8400.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -2.5803197497633206   |
| train_0/current_q         | -2.194340595422287    |
| train_0/fw_bonus          | -0.9996679127216339   |
| train_0/fw_loss           | 8.182175988622476e-05 |
| train_0/mu_grads          | -0.15396669544279576  |
| train_0/mu_grads_std      | 0.8147031977772713    |
| train_0/mu_loss           | 1.973176740113661     |
| train_0/next_q            | -1.7507693977363055   |
| train_0/q_grads           | 0.02910648938268423   |
| train_0/q_grads_std       | 0.8982951954007149    |
| train_0/q_loss            | 0.07339309207495767   |
| train_0/reward            | -0.8676342314851354   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.055224609375        |
| train_0/target_q          | -2.2010926223127725   |
| train_1/avg_q             | -9.867865251439532    |
| train_1/current_q         | -4.054128350811552    |
| train_1/fw_bonus          | -1.0114722728729248   |
| train_1/fw_loss           | 0.0002175622768845642 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.046207006826291     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.049268945512251    |
| train_1/q_grads           | -0.04977917904034257  |
| train_1/q_grads_std       | 1.0428014993667603    |
| train_1/q_loss            | 0.3329665760950191    |
| train_1/reward            | -0.8605207164320745   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 4.8828125e-05         |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.954                 |
| train_1/target_q          | -4.325058523015035    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 84
Time for epoch 84: 284.70. Rollout time: 23.27, Training time: 261.31
Evaluating epoch 84
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 473267.0               |
| test/episodes             | 2125.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.191533786119498     |
| test_1/avg_q              | -9.796195592707534     |
| test_1/n_subgoals         | 2080.0                 |
| test_1/subgoal_succ_rate  | 0.9927884615384616     |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.76237699666951      |
| train_0/current_q         | -2.1939350752549442    |
| train_0/fw_bonus          | -0.9996689468622207    |
| train_0/fw_loss           | 8.162205849657767e-05  |
| train_0/mu_grads          | -0.154806974157691     |
| train_0/mu_grads_std      | 0.8181767612695694     |
| train_0/mu_loss           | 1.967532624152397      |
| train_0/next_q            | -1.7490708376888435    |
| train_0/q_grads           | 0.029103117063641548   |
| train_0/q_grads_std       | 0.904586336016655      |
| train_0/q_loss            | 0.06512016252249239    |
| train_0/reward            | -0.8671955574915046    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0532470703125        |
| train_0/target_q          | -2.2030274525656437    |
| train_1/avg_q             | -9.777343676785252     |
| train_1/current_q         | -4.044455677306987     |
| train_1/fw_bonus          | -1.0115272045135497    |
| train_1/fw_loss           | 0.00020584983212756924 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.03208816800206       |
| train_1/n_subgoals        | 994.0                  |
| train_1/next_q            | -4.032341337083763     |
| train_1/q_grads           | -0.049321938399225475  |
| train_1/q_grads_std       | 1.0467768341302872     |
| train_1/q_loss            | 0.34352248115491435    |
| train_1/reward            | -0.8600919358854299    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9406438631790744     |
| train_1/target_q          | -4.3181993005845865    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 85
Time for epoch 85: 269.36. Rollout time: 21.07, Training time: 248.18
Evaluating epoch 85
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 477895.0              |
| test/episodes             | 2150.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.1142430512685086   |
| test_1/avg_q              | -9.912359095143495    |
| test_1/n_subgoals         | 2218.0                |
| test_1/subgoal_succ_rate  | 0.996844003606853     |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.01                  |
| train_0/avg_q             | -2.925607881900956    |
| train_0/current_q         | -2.201720992055214    |
| train_0/fw_bonus          | -0.9997049227356911   |
| train_0/fw_loss           | 7.47048518860538e-05  |
| train_0/mu_grads          | -0.1549875520169735   |
| train_0/mu_grads_std      | 0.8212683543562889    |
| train_0/mu_loss           | 1.9772030380476822    |
| train_0/next_q            | -1.7640324914799563   |
| train_0/q_grads           | 0.028820139169692994  |
| train_0/q_grads_std       | 0.9100830063223839    |
| train_0/q_loss            | 0.07443047253772404   |
| train_0/reward            | -0.867777956687496    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.053759765625        |
| train_0/target_q          | -2.210342033557567    |
| train_1/avg_q             | -9.849854436529103    |
| train_1/current_q         | -4.0410720934352415   |
| train_1/fw_bonus          | -1.011664080619812    |
| train_1/fw_loss           | 0.0001766559300449444 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.030863647576519     |
| train_1/n_subgoals        | 993.0                 |
| train_1/next_q            | -4.027627695271216    |
| train_1/q_grads           | -0.04934369660913944  |
| train_1/q_grads_std       | 1.0517387866973877    |
| train_1/q_loss            | 0.36521945859245164   |
| train_1/reward            | -0.861055198792019    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9365558912386707    |
| train_1/target_q          | -4.311229011653909    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 86
Time for epoch 86: 283.42. Rollout time: 24.03, Training time: 259.27
Evaluating epoch 86
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 86                     |
| policy/steps              | 482798.0               |
| test/episodes             | 2175.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3798435384823549    |
| test_1/avg_q              | -9.641873741968645     |
| test_1/n_subgoals         | 2146.0                 |
| test_1/subgoal_succ_rate  | 0.9897483690587139     |
| train/episodes            | 8700.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.9057988064835207    |
| train_0/current_q         | -2.194499068144553     |
| train_0/fw_bonus          | -0.999661898612976     |
| train_0/fw_loss           | 8.297588701680069e-05  |
| train_0/mu_grads          | -0.155354293435812     |
| train_0/mu_grads_std      | 0.8245762437582016     |
| train_0/mu_loss           | 1.9759631767706085     |
| train_0/next_q            | -1.7555566858398368    |
| train_0/q_grads           | 0.029948017094284296   |
| train_0/q_grads_std       | 0.9156046867370605     |
| train_0/q_loss            | 0.06312652339297409    |
| train_0/reward            | -0.8666409607263631    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0499267578125        |
| train_0/target_q          | -2.206333439252783     |
| train_1/avg_q             | -9.695140773203978     |
| train_1/current_q         | -3.9922792103118985    |
| train_1/fw_bonus          | -1.0115219563245774    |
| train_1/fw_loss           | 0.00020697020700026768 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.998129820870961      |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.9842572776317353    |
| train_1/q_grads           | -0.049739942979067565  |
| train_1/q_grads_std       | 1.0550418436527251     |
| train_1/q_loss            | 0.4047064067540972     |
| train_1/reward            | -0.8631031319673639    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9095477386934674     |
| train_1/target_q          | -4.250443059031504     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 87
Time for epoch 87: 275.65. Rollout time: 22.73, Training time: 252.79
Evaluating epoch 87
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 87                     |
| policy/steps              | 487512.0               |
| test/episodes             | 2200.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.2860916762980081    |
| test_1/avg_q              | -9.83664947524069      |
| test_1/n_subgoals         | 2078.0                 |
| test_1/subgoal_succ_rate  | 0.992781520692974      |
| train/episodes            | 8800.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.972771607907047     |
| train_0/current_q         | -2.191193883223814     |
| train_0/fw_bonus          | -0.9996852725744247    |
| train_0/fw_loss           | 7.84813297286746e-05   |
| train_0/mu_grads          | -0.15574901327490806   |
| train_0/mu_grads_std      | 0.8278176188468933     |
| train_0/mu_loss           | 1.9684433679157276     |
| train_0/next_q            | -1.7502423212886768    |
| train_0/q_grads           | 0.02986852200701833    |
| train_0/q_grads_std       | 0.9209109753370285     |
| train_0/q_loss            | 0.06975051069682739    |
| train_0/reward            | -0.868019574797654     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.053466796875         |
| train_0/target_q          | -2.198854424476484     |
| train_1/avg_q             | -9.661151973382996     |
| train_1/current_q         | -3.9961420224466435    |
| train_1/fw_bonus          | -1.0115511864423752    |
| train_1/fw_loss           | 0.00020073552004760132 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.006107904542034      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.9883964564626337    |
| train_1/q_grads           | -0.049763088766485455  |
| train_1/q_grads_std       | 1.0598475158214569     |
| train_1/q_loss            | 0.3900031811364536     |
| train_1/reward            | -0.8645593844834366    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.941                  |
| train_1/target_q          | -4.2628362971227505    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 88
Time for epoch 88: 274.20. Rollout time: 24.54, Training time: 249.57
Evaluating epoch 88
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 88                     |
| policy/steps              | 492526.0               |
| test/episodes             | 2225.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.4136396175976205    |
| test_1/avg_q              | -9.976210767008304     |
| test_1/n_subgoals         | 2070.0                 |
| test_1/subgoal_succ_rate  | 0.9922705314009662     |
| train/episodes            | 8900.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -3.166771512262821     |
| train_0/current_q         | -2.2441797663084806    |
| train_0/fw_bonus          | -0.9996919751167297    |
| train_0/fw_loss           | 7.719539862591774e-05  |
| train_0/mu_grads          | -0.15678721778094767   |
| train_0/mu_grads_std      | 0.8306488186120987     |
| train_0/mu_loss           | 2.034952360539853      |
| train_0/next_q            | -1.812882770253743     |
| train_0/q_grads           | 0.030376115534454583   |
| train_0/q_grads_std       | 0.9258924320340156     |
| train_0/q_loss            | 0.08619936416486813    |
| train_0/reward            | -0.8683846977030043    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.053125               |
| train_0/target_q          | -2.2566038925928895    |
| train_1/avg_q             | -9.78842295117344      |
| train_1/current_q         | -4.052465321720279     |
| train_1/fw_bonus          | -1.0114270716905593    |
| train_1/fw_loss           | 0.00022720693705196026 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.055884190270857      |
| train_1/n_subgoals        | 989.0                  |
| train_1/next_q            | -4.040802243166567     |
| train_1/q_grads           | -0.050326368492096665  |
| train_1/q_grads_std       | 1.0637799859046937     |
| train_1/q_loss            | 0.45804298134679466    |
| train_1/reward            | -0.8688303047718364    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9120323559150657     |
| train_1/target_q          | -4.309114415211376     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03
Training epoch 89
Time for epoch 89: 283.01. Rollout time: 25.47, Training time: 257.43
Evaluating epoch 89
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 89                     |
| policy/steps              | 497600.0               |
| test/episodes             | 2250.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.98233243478187      |
| test_1/avg_q              | -9.764586683879728     |
| test_1/n_subgoals         | 1787.0                 |
| test_1/subgoal_succ_rate  | 0.983212087297146      |
| train/episodes            | 9000.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.481706927020957     |
| train_0/current_q         | -2.2577358929528497    |
| train_0/fw_bonus          | -0.9997000202536583    |
| train_0/fw_loss           | 7.564602619822836e-05  |
| train_0/mu_grads          | -0.1569817241281271    |
| train_0/mu_grads_std      | 0.8333055391907692     |
| train_0/mu_loss           | 2.0287982411646532     |
| train_0/next_q            | -1.8167029993652855    |
| train_0/q_grads           | 0.029651515046134592   |
| train_0/q_grads_std       | 0.9309825405478478     |
| train_0/q_loss            | 0.06731255385313024    |
| train_0/reward            | -0.8673287290221197    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0545166015625        |
| train_0/target_q          | -2.269165293373313     |
| train_1/avg_q             | -9.795615260546853     |
| train_1/current_q         | -4.008859667663205     |
| train_1/fw_bonus          | -1.0113555163145065    |
| train_1/fw_loss           | 0.00024246424545708577 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.007964315317833      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.9728596606249704    |
| train_1/q_grads           | -0.05284524746239185   |
| train_1/q_grads_std       | 1.0674128770828246     |
| train_1/q_loss            | 0.7241079539192107     |
| train_1/reward            | -0.8724448617809685    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.913                  |
| train_1/target_q          | -4.234165950310858     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 90
Time for epoch 90: 273.02. Rollout time: 21.29, Training time: 251.63
Evaluating epoch 90
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 90                     |
| policy/steps              | 502287.0               |
| test/episodes             | 2275.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6390485879408319    |
| test_1/avg_q              | -9.81141420370389      |
| test_1/n_subgoals         | 1949.0                 |
| test_1/subgoal_succ_rate  | 0.9861467419189328     |
| train/episodes            | 9100.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -2.8163880198706073    |
| train_0/current_q         | -2.208449371283871     |
| train_0/fw_bonus          | -0.9997341111302376    |
| train_0/fw_loss           | 6.90920007400564e-05   |
| train_0/mu_grads          | -0.15734660923480986   |
| train_0/mu_grads_std      | 0.8370168551802635     |
| train_0/mu_loss           | 1.9748634474871853     |
| train_0/next_q            | -1.7584884846085616    |
| train_0/q_grads           | 0.02928464887663722    |
| train_0/q_grads_std       | 0.9348180338740348     |
| train_0/q_loss            | 0.07908355329711629    |
| train_0/reward            | -0.8687153762977686    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0552490234375        |
| train_0/target_q          | -2.2179310064622335    |
| train_1/avg_q             | -9.885527765394981     |
| train_1/current_q         | -4.057081960707725     |
| train_1/fw_bonus          | -1.0113250404596328    |
| train_1/fw_loss           | 0.00024896226605051195 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.062715356895405      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.02572171472489      |
| train_1/q_grads           | -0.051879575755447147  |
| train_1/q_grads_std       | 1.070343655347824      |
| train_1/q_loss            | 0.47889196529774364    |
| train_1/reward            | -0.872867566680361     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.948                  |
| train_1/target_q          | -4.311883208067815     |
------------------------------------------------------
Saving periodic policy to data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 91
Time for epoch 91: 276.95. Rollout time: 25.16, Training time: 251.65
Evaluating epoch 91
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 91                    |
| policy/steps              | 507391.0              |
| test/episodes             | 2300.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.4984653637288428   |
| test_1/avg_q              | -9.352006198563966    |
| test_1/n_subgoals         | 1979.0                |
| test_1/subgoal_succ_rate  | 0.989388580090955     |
| train/episodes            | 9200.0                |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -3.254054986929983    |
| train_0/current_q         | -2.249036079501276    |
| train_0/fw_bonus          | -0.9997266188263894   |
| train_0/fw_loss           | 7.053091785564902e-05 |
| train_0/mu_grads          | -0.15793162435293198  |
| train_0/mu_grads_std      | 0.8398997411131859    |
| train_0/mu_loss           | 2.0119836783972684    |
| train_0/next_q            | -1.795022029753461    |
| train_0/q_grads           | 0.02978435708209872   |
| train_0/q_grads_std       | 0.9387048065662384    |
| train_0/q_loss            | 0.08381728959775696   |
| train_0/reward            | -0.8692773906936054   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0447265625          |
| train_0/target_q          | -2.254338982195457    |
| train_1/avg_q             | -9.684447792980546    |
| train_1/current_q         | -4.079484202699926    |
| train_1/fw_bonus          | -1.0113157272338866   |
| train_1/fw_loss           | 0.0002509508041839581 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.068404016145239     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -4.040093046063431    |
| train_1/q_grads           | -0.05269131865352392  |
| train_1/q_grads_std       | 1.0734307557344436    |
| train_1/q_loss            | 0.5489426046353587    |
| train_1/reward            | -0.8762358173524263   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.913                 |
| train_1/target_q          | -4.316769006607233    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 92
Time for epoch 92: 281.56. Rollout time: 26.12, Training time: 255.36
Evaluating epoch 92
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 92                     |
| policy/steps              | 512528.0               |
| test/episodes             | 2325.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.6781811684474026    |
| test_1/avg_q              | -9.898192248173174     |
| test_1/n_subgoals         | 1731.0                 |
| test_1/subgoal_succ_rate  | 0.9826689774696707     |
| train/episodes            | 9300.0                 |
| train/success_rate        | 0.03                   |
| train_0/avg_q             | -3.351253612933084     |
| train_0/current_q         | -2.233372948694127     |
| train_0/fw_bonus          | -0.9997029587626457    |
| train_0/fw_loss           | 7.508168300773832e-05  |
| train_0/mu_grads          | -0.15807416513562203   |
| train_0/mu_grads_std      | 0.8424830555915832     |
| train_0/mu_loss           | 2.0033560413151648     |
| train_0/next_q            | -1.7821597085639702    |
| train_0/q_grads           | 0.030038432497531176   |
| train_0/q_grads_std       | 0.9425777778029442     |
| train_0/q_loss            | 0.06842321072177661    |
| train_0/reward            | -0.8691863991058199    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0535888671875        |
| train_0/target_q          | -2.2424371363981948    |
| train_1/avg_q             | -9.69829407116102      |
| train_1/current_q         | -4.053638198536033     |
| train_1/fw_bonus          | -1.0113338202238082    |
| train_1/fw_loss           | 0.00024709272256586703 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.045395810031557      |
| train_1/n_subgoals        | 981.0                  |
| train_1/next_q            | -4.001218827790007     |
| train_1/q_grads           | -0.05143843842670322   |
| train_1/q_grads_std       | 1.0757776916027069     |
| train_1/q_loss            | 0.6941874277325809     |
| train_1/reward            | -0.875901484915812     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9072375127420998     |
| train_1/target_q          | -4.285548788072006     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 93
Time for epoch 93: 278.19. Rollout time: 25.17, Training time: 252.95
Evaluating epoch 93
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 517571.0               |
| test/episodes             | 2350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.667397683629096     |
| test_1/avg_q              | -9.945196998435234     |
| test_1/n_subgoals         | 1945.0                 |
| test_1/subgoal_succ_rate  | 0.9902313624678664     |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.54960355491445      |
| train_0/current_q         | -2.2466848416808327    |
| train_0/fw_bonus          | -0.9996581211686134    |
| train_0/fw_loss           | 8.370258055947488e-05  |
| train_0/mu_grads          | -0.15798077024519444   |
| train_0/mu_grads_std      | 0.8456070125102997     |
| train_0/mu_loss           | 2.0172708252784517     |
| train_0/next_q            | -1.7947281393517447    |
| train_0/q_grads           | 0.030260500963777304   |
| train_0/q_grads_std       | 0.9467775270342826     |
| train_0/q_loss            | 0.08300848975150354    |
| train_0/reward            | -0.8706542395637371    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0612548828125        |
| train_0/target_q          | -2.2623467611424575    |
| train_1/avg_q             | -9.60733210308154      |
| train_1/current_q         | -4.0895584068158914    |
| train_1/fw_bonus          | -1.0113518059253692    |
| train_1/fw_loss           | 0.00024325763733941131 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.071955589522968      |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -4.048823096854436     |
| train_1/q_grads           | -0.04907335685566068   |
| train_1/q_grads_std       | 1.07902789413929       |
| train_1/q_loss            | 0.6712165837157736     |
| train_1/reward            | -0.8776361633674241    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.917                  |
| train_1/target_q          | -4.329836811004183     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 94
Time for epoch 94: 274.14. Rollout time: 21.90, Training time: 252.15
Evaluating epoch 94
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 94                     |
| policy/steps              | 522320.0               |
| test/episodes             | 2375.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2006764932649387    |
| test_1/avg_q              | -8.984970161578467     |
| test_1/n_subgoals         | 2213.0                 |
| test_1/subgoal_succ_rate  | 0.9932218707636692     |
| train/episodes            | 9500.0                 |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -3.082663826275152     |
| train_0/current_q         | -2.242974089664833     |
| train_0/fw_bonus          | -0.999678885936737     |
| train_0/fw_loss           | 7.971051600179635e-05  |
| train_0/mu_grads          | -0.15834060907363892   |
| train_0/mu_grads_std      | 0.8482459917664528     |
| train_0/mu_loss           | 2.01732848942921       |
| train_0/next_q            | -1.7891654664160517    |
| train_0/q_grads           | 0.029470361908897756   |
| train_0/q_grads_std       | 0.9515367776155472     |
| train_0/q_loss            | 0.07742739768984501    |
| train_0/reward            | -0.8712862650630996    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0537841796875        |
| train_0/target_q          | -2.25317317892842      |
| train_1/avg_q             | -9.61905950143021      |
| train_1/current_q         | -4.041418492657624     |
| train_1/fw_bonus          | -1.0115177035331726    |
| train_1/fw_loss           | 0.00020787714202015196 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 4.0207474417497        |
| train_1/n_subgoals        | 995.0                  |
| train_1/next_q            | -3.9917487204238085    |
| train_1/q_grads           | -0.050716346316039565  |
| train_1/q_grads_std       | 1.0854632645845412     |
| train_1/q_loss            | 0.5102728589858513     |
| train_1/reward            | -0.8762347081385087    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 2.44140625e-05         |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9386934673366835     |
| train_1/target_q          | -4.290893702503356     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
Training epoch 95
Time for epoch 95: 281.12. Rollout time: 22.46, Training time: 258.56
Evaluating epoch 95
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 527035.0               |
| test/episodes             | 2400.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5212992370722456    |
| test_1/avg_q              | -9.077586740816454     |
| test_1/n_subgoals         | 2006.0                 |
| test_1/subgoal_succ_rate  | 0.9920239282153539     |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -2.7995753821560108    |
| train_0/current_q         | -2.31410832228113      |
| train_0/fw_bonus          | -0.9996955707669258    |
| train_0/fw_loss           | 7.650477327842964e-05  |
| train_0/mu_grads          | -0.15804449766874312   |
| train_0/mu_grads_std      | 0.8520870208740234     |
| train_0/mu_loss           | 2.086924286548774      |
| train_0/next_q            | -1.8592695525090135    |
| train_0/q_grads           | 0.029933776473626494   |
| train_0/q_grads_std       | 0.9573590934276581     |
| train_0/q_loss            | 0.06977932477563825    |
| train_0/reward            | -0.8721532608251437    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.057373046875         |
| train_0/target_q          | -2.323948549403181     |
| train_1/avg_q             | -9.637221553906953     |
| train_1/current_q         | -3.9697920554537363    |
| train_1/fw_bonus          | -1.0114785432815552    |
| train_1/fw_loss           | 0.00021622936183121055 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.967108428735365      |
| train_1/n_subgoals        | 998.0                  |
| train_1/next_q            | -3.93078794105912      |
| train_1/q_grads           | -0.053911443520337346  |
| train_1/q_grads_std       | 1.091793966293335      |
| train_1/q_loss            | 0.5457187351506179     |
| train_1/reward            | -0.8725371229229495    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9478957915831663     |
| train_1/target_q          | -4.214030155981719     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 96
Time for epoch 96: 275.88. Rollout time: 22.43, Training time: 253.32
Evaluating epoch 96
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 96                    |
| policy/steps              | 531782.0              |
| test/episodes             | 2425.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.0266455522004987   |
| test_1/avg_q              | -9.552752073667357    |
| test_1/n_subgoals         | 2276.0                |
| test_1/subgoal_succ_rate  | 0.9982425307557118    |
| train/episodes            | 9700.0                |
| train/success_rate        | 0.02                  |
| train_0/avg_q             | -3.146914094784914    |
| train_0/current_q         | -2.3194034654872806   |
| train_0/fw_bonus          | -0.9997083470225334   |
| train_0/fw_loss           | 7.404522348224419e-05 |
| train_0/mu_grads          | -0.15820586383342744  |
| train_0/mu_grads_std      | 0.8547779947519303    |
| train_0/mu_loss           | 2.102016821826642     |
| train_0/next_q            | -1.8740212476780012   |
| train_0/q_grads           | 0.029517293069511653  |
| train_0/q_grads_std       | 0.9622084766626358    |
| train_0/q_loss            | 0.07564538151891766   |
| train_0/reward            | -0.8713999143772526   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0541748046875       |
| train_0/target_q          | -2.329803093324102    |
| train_1/avg_q             | -9.544106164451716    |
| train_1/current_q         | -4.042090456167157    |
| train_1/fw_bonus          | -1.0112823575735093   |
| train_1/fw_loss           | 0.0002580631316959625 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 4.030185706259935     |
| train_1/n_subgoals        | 988.0                 |
| train_1/next_q            | -4.022738896953259    |
| train_1/q_grads           | -0.05454361233860254  |
| train_1/q_grads_std       | 1.0965247362852097    |
| train_1/q_loss            | 0.5422280801766145    |
| train_1/reward            | -0.8727684223893448   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.9342105263157895    |
| train_1/target_q          | -4.294025586645189    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 97
Time for epoch 97: 270.03. Rollout time: 22.38, Training time: 247.56
Evaluating epoch 97
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 97                     |
| policy/steps              | 536617.0               |
| test/episodes             | 2450.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.251166849265849     |
| test_1/avg_q              | -9.300150897479556     |
| test_1/n_subgoals         | 2198.0                 |
| test_1/subgoal_succ_rate  | 0.9968152866242038     |
| train/episodes            | 9800.0                 |
| train/success_rate        | 0.01                   |
| train_0/avg_q             | -3.3693201287746115    |
| train_0/current_q         | -2.352041741812994     |
| train_0/fw_bonus          | -0.9997107088565826    |
| train_0/fw_loss           | 7.35896820515336e-05   |
| train_0/mu_grads          | -0.1584461398422718    |
| train_0/mu_grads_std      | 0.8577579647302628     |
| train_0/mu_loss           | 2.1236667914513068     |
| train_0/next_q            | -1.8986765637263545    |
| train_0/q_grads           | 0.02930492558516562    |
| train_0/q_grads_std       | 0.9673642352223396     |
| train_0/q_loss            | 0.07210133131968416    |
| train_0/reward            | -0.8727444646909135    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.05478515625          |
| train_0/target_q          | -2.368106902557835     |
| train_1/avg_q             | -9.721256662887681     |
| train_1/current_q         | -3.9802536679021947    |
| train_1/fw_bonus          | -1.0115375369787216    |
| train_1/fw_loss           | 0.00020364767224236857 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.967715439067253      |
| train_1/n_subgoals        | 993.0                  |
| train_1/next_q            | -3.9559781132479395    |
| train_1/q_grads           | -0.05512249581515789   |
| train_1/q_grads_std       | 1.1026046216487884     |
| train_1/q_loss            | 0.5550268488699432     |
| train_1/reward            | -0.8695662325320882    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.9264853977844915     |
| train_1/target_q          | -4.223970478166793     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 98
Time for epoch 98: 287.72. Rollout time: 23.16, Training time: 264.41
Evaluating epoch 98
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 541287.0               |
| test/episodes             | 2475.0                 |
| test/success_rate         | 0.04                   |
| test_0/avg_q              | -1.426642035023113     |
| test_1/avg_q              | -9.25026900063571      |
| test_1/n_subgoals         | 2130.0                 |
| test_1/subgoal_succ_rate  | 0.9938967136150235     |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.0                    |
| train_0/avg_q             | -3.2488074926126544    |
| train_0/current_q         | -2.3071208500293734    |
| train_0/fw_bonus          | -0.9997048571705818    |
| train_0/fw_loss           | 7.472023098671343e-05  |
| train_0/mu_grads          | -0.1586072888225317    |
| train_0/mu_grads_std      | 0.8617958664894104     |
| train_0/mu_loss           | 2.0927094123352843     |
| train_0/next_q            | -1.8615594064971481    |
| train_0/q_grads           | 0.02872434980235994    |
| train_0/q_grads_std       | 0.9710283264517784     |
| train_0/q_loss            | 0.09595283075817292    |
| train_0/reward            | -0.8712996252623271    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0529296875           |
| train_0/target_q          | -2.322525795288681     |
| train_1/avg_q             | -9.647146976427688     |
| train_1/current_q         | -3.9683644925432815    |
| train_1/fw_bonus          | -1.0114424765110015    |
| train_1/fw_loss           | 0.00022391740421880967 |
| train_1/mu_grads          | 0.018197076395154      |
| train_1/mu_grads_std      | 0.0861390084028244     |
| train_1/mu_loss           | 3.9593936731683597     |
| train_1/n_subgoals        | 1000.0                 |
| train_1/next_q            | -3.923276886159679     |
| train_1/q_grads           | -0.054414028953760865  |
| train_1/q_grads_std       | 1.1050598829984666     |
| train_1/q_loss            | 0.5450348564243903     |
| train_1/reward            | -0.8702090605074773    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0                    |
| train_1/reward_-10.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.938                  |
| train_1/target_q          | -4.214908976911275     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.01
Training epoch 99
Time for epoch 99: 270.10. Rollout time: 22.29, Training time: 247.71
Evaluating epoch 99
Data_dir: data/eef7a77/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.25|fw:1|fwhidsiz:256,256,256|nlev:2|reg:True|rolbatsiz:1|timsca:10,10|100
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 546030.0              |
| test/episodes             | 2500.0                |
| test/success_rate         | 0.04                  |
| test_0/avg_q              | -1.987744612654578    |
| test_1/avg_q              | -8.967430627343823    |
| test_1/n_subgoals         | 1849.0                |
| test_1/subgoal_succ_rate  | 0.981611681990265     |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.0                   |
| train_0/avg_q             | -3.2394403741073488   |
| train_0/current_q         | -2.305188753222364    |
| train_0/fw_bonus          | -0.9996433153748512   |
| train_0/fw_loss           | 8.655040692246984e-05 |
| train_0/mu_grads          | -0.159188836440444    |
| train_0/mu_grads_std      | 0.8657064110040664    |
| train_0/mu_loss           | 2.0692335543001343    |
| train_0/next_q            | -1.8503341564077391   |
| train_0/q_grads           | 0.029379895050078632  |
| train_0/q_grads_std       | 0.9755558535456658    |
| train_0/q_loss            | 0.07877432055921636   |
| train_0/reward            | -0.8725962569587864   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.057275390625        |
| train_0/target_q          | -2.3152864792202745   |
| train_1/avg_q             | -9.500379300998166    |
| train_1/current_q         | -3.9066565712739347   |
| train_1/fw_bonus          | -1.0114476025104522   |
| train_1/fw_loss           | 0.0002228274221124593 |
| train_1/mu_grads          | 0.018197076395154     |
| train_1/mu_grads_std      | 0.0861390084028244    |
| train_1/mu_loss           | 3.888789472549756     |
| train_1/n_subgoals        | 1000.0                |
| train_1/next_q            | -3.859810739081412    |
| train_1/q_grads           | -0.05523011889308691  |
| train_1/q_grads_std       | 1.108989104628563     |
| train_1/q_loss            | 0.45410357656212835   |
| train_1/reward            | -0.869547610967129    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0                   |
| train_1/reward_-10.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.934                 |
| train_1/target_q          | -4.14850960159938     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.02
All epochs are finished. Stopping the training now.
