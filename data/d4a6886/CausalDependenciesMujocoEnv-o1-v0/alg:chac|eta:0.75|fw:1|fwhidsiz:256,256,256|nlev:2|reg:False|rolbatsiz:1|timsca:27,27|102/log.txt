Starting process id: 18201
T: 50
alg: chac
algorithm: src.chac
atomic_noise: 0.2
base_logdir: data
batch_size: 1024
bind_core: 0
buffer_size: 500
chac_params: {}
early_stop_data_column: test/success_rate
early_stop_threshold: 100.0
env_name: CausalDependenciesMujocoEnv-o1-v0
eta: 0.75
fw: 1
fw_hidden_size: 256,256,256
fw_lr: 0.001
gamma: 0.98
graph: 1
info: 
make_env: <function prepare_params.<locals>.make_env at 0x7fe981ff6b00>
max_try_idx: 199
mu_hidden_size: 64
mu_lr: 0.001
n_episodes: 100
n_levels: 2
n_pre_episodes: 30
n_test_rollouts: 15
n_train_batches: 40
n_train_rollouts: 100
num_threads: 1
q_hidden_size: 64
q_lr: 0.001
random_action_perc: 0.3
regularization: False
render: 0
rollout_batch_size: 1
subgoal_noise: 0.2
subgoal_test_perc: 0.3
time_scales: 27,27
try_start_idx: 100
use_mpi: False
verbose: False

*** Warning ***
You are running src.chac with just a single MPI worker. This will work, but the HER experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) were obtained with --num_cpu 19. This makes a significant difference and if you are looking to reproduce those results, be aware of this. Please also refer to https://github.com/openai/baselines/issues/314 for further details.
****************

dims: action = 2, subgoal = 2, end_goal = 2
subgoal_bounds: symmetric [0.2 0.2], offset [0.922 0.25 ]
Running on CPU ...
Creating a CHAC agent

Hierarchy Level 0 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)

Hierarchy Level 1 with time scale 27
Actor(
  (fc1): Linear(in_features=35, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=2, bias=True)
)
Critic(
  (fc1): Linear(in_features=37, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (mse_loss): MSELoss()
)
ForwardModel(
  (mlp): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=33, bias=True)
    (7): Identity()
  )
  (mse_loss): MSELoss()
)
Training epoch 0
Time for epoch 0: 663.66. Rollout time: 401.23, Training time: 262.39
Evaluating epoch 0
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 0                      |
| policy/steps              | 79559.0                |
| test/episodes             | 15.0                   |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0985210433098107    |
| test_1/avg_q              | -4.032715178337013     |
| test_1/n_subgoals         | 1663.0                 |
| test_1/subgoal_succ_rate  | 0.7853277209861695     |
| train/episodes            | 100.0                  |
| train/success_rate        | 0.02                   |
| train_0/avg_q             | -2.4194429543622267    |
| train_0/current_q         | -4.8388027778257365    |
| train_0/fw_bonus          | -0.9989638537168503    |
| train_0/fw_loss           | 0.00030606089494540357 |
| train_0/mu_grads          | -0.013503947760909796  |
| train_0/mu_grads_std      | 0.17005958408117294    |
| train_0/mu_loss           | 4.6158724624606755     |
| train_0/next_q            | -4.605841009559763     |
| train_0/q_grads           | 0.03162650624290109    |
| train_0/q_grads_std       | 0.15876646973192693    |
| train_0/q_loss            | 0.5320617440225217     |
| train_0/reward            | -0.648288328668059     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.001611328125         |
| train_0/target_q          | -4.7714580869787655    |
| train_1/avg_q             | -11.229425715568043    |
| train_1/current_q         | -13.556606457239605    |
| train_1/fw_bonus          | -0.9952658787369728    |
| train_1/fw_loss           | 0.0016764363535912707  |
| train_1/mu_grads          | 0.015475822077132762   |
| train_1/mu_grads_std      | 0.18965463116765022    |
| train_1/mu_loss           | 14.242824589593805     |
| train_1/n_subgoals        | 2660.0                 |
| train_1/next_q            | -14.311208266771782    |
| train_1/q_grads           | 0.02367886984720826    |
| train_1/q_grads_std       | 0.19227388314902782    |
| train_1/q_loss            | 27.897280299265766     |
| train_1/reward            | -2.595496156994341     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0109375              |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.060526315789473685   |
| train_1/target_q          | -13.461612625974254    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_0.pkl ...
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 1
Time for epoch 1: 523.92. Rollout time: 349.62, Training time: 174.27
Evaluating epoch 1
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 1                     |
| policy/steps              | 153715.0              |
| test/episodes             | 30.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.0587311050443695   |
| test_1/avg_q              | -15.53308287998902    |
| test_1/n_subgoals         | 413.0                 |
| test_1/subgoal_succ_rate  | 0.01937046004842615   |
| train/episodes            | 200.0                 |
| train/success_rate        | 0.19                  |
| train_0/avg_q             | -5.953428280466778    |
| train_0/current_q         | -3.5764221060511145   |
| train_0/fw_bonus          | -0.9987307623028755   |
| train_0/fw_loss           | 0.0003739662752195727 |
| train_0/mu_grads          | -0.031226758426055313 |
| train_0/mu_grads_std      | 0.21036581620573996   |
| train_0/mu_loss           | 3.3726041226607464    |
| train_0/next_q            | -3.3583022972579863   |
| train_0/q_grads           | 0.024870348116382956  |
| train_0/q_grads_std       | 0.17146282829344273   |
| train_0/q_loss            | 0.571710406455592     |
| train_0/reward            | -0.6824524649866361   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0007568359375       |
| train_0/target_q          | -3.6658008465523793   |
| train_1/avg_q             | -12.91391655985455    |
| train_1/current_q         | -12.482585884258189   |
| train_1/fw_bonus          | -0.9958636879920959   |
| train_1/fw_loss           | 0.0015233631449518726 |
| train_1/mu_grads          | 0.015015460457652808  |
| train_1/mu_grads_std      | 0.24356072284281255   |
| train_1/mu_loss           | 12.664216963598632    |
| train_1/n_subgoals        | 2525.0                |
| train_1/next_q            | -12.7265109138682     |
| train_1/q_grads           | 0.01861434322781861   |
| train_1/q_grads_std       | 0.2599483266472816    |
| train_1/q_loss            | 16.665840266746123    |
| train_1/reward            | -2.563785261176963    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01279296875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10138613861386139   |
| train_1/target_q          | -12.485569182937033   |
-----------------------------------------------------
New best value for test/success_rate: 0.0. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 2
Time for epoch 2: 520.87. Rollout time: 348.18, Training time: 172.66
Evaluating epoch 2
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 2                     |
| policy/steps              | 228540.0              |
| test/episodes             | 45.0                  |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -0.03252671756402111  |
| test_1/avg_q              | -11.553323150954848   |
| test_1/n_subgoals         | 384.0                 |
| test_1/subgoal_succ_rate  | 0.0078125             |
| train/episodes            | 300.0                 |
| train/success_rate        | 0.13                  |
| train_0/avg_q             | -5.24995565002107     |
| train_0/current_q         | -3.1216572916424377   |
| train_0/fw_bonus          | -0.9987239584326744   |
| train_0/fw_loss           | 0.0003759486171475146 |
| train_0/mu_grads          | -0.027459408901631833 |
| train_0/mu_grads_std      | 0.2409977838397026    |
| train_0/mu_loss           | 2.94816836599974      |
| train_0/next_q            | -3.051139175688954    |
| train_0/q_grads           | 0.02366808238439262   |
| train_0/q_grads_std       | 0.18648662380874156   |
| train_0/q_loss            | 1.2395654668525498    |
| train_0/reward            | -0.699314777363179    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.00146484375         |
| train_0/target_q          | -3.326780150444802    |
| train_1/avg_q             | -16.52901137066707    |
| train_1/current_q         | -12.99333701787998    |
| train_1/fw_bonus          | -0.9957330256700516   |
| train_1/fw_loss           | 0.0015568243834422901 |
| train_1/mu_grads          | 0.011440288298763335  |
| train_1/mu_grads_std      | 0.2688354030251503    |
| train_1/mu_loss           | 13.394988039580664    |
| train_1/n_subgoals        | 2516.0                |
| train_1/next_q            | -13.39386198590949    |
| train_1/q_grads           | 0.01301676540169865   |
| train_1/q_grads_std       | 0.3013449087738991    |
| train_1/q_loss            | 11.48893043697061     |
| train_1/reward            | -2.505012357564192    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0145751953125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.07511923688394277   |
| train_1/target_q          | -13.011784952677909   |
-----------------------------------------------------
New best value for test/success_rate: 0.06666666666666667. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Training epoch 3
Time for epoch 3: 510.64. Rollout time: 329.44, Training time: 181.17
Evaluating epoch 3
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 3                     |
| policy/steps              | 298301.0              |
| test/episodes             | 60.0                  |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5915203140120342   |
| test_1/avg_q              | -8.7623442112062      |
| test_1/n_subgoals         | 408.0                 |
| test_1/subgoal_succ_rate  | 0.007352941176470588  |
| train/episodes            | 400.0                 |
| train/success_rate        | 0.25                  |
| train_0/avg_q             | -3.90863808782091     |
| train_0/current_q         | -5.703051519261908    |
| train_0/fw_bonus          | -0.9986694172024727   |
| train_0/fw_loss           | 0.0003918351234460715 |
| train_0/mu_grads          | -0.03180779349058867  |
| train_0/mu_grads_std      | 0.2614386975765228    |
| train_0/mu_loss           | 5.580827452479993     |
| train_0/next_q            | -5.44561032794447     |
| train_0/q_grads           | 0.02161574992351234   |
| train_0/q_grads_std       | 0.1939646080136299    |
| train_0/q_loss            | 0.9766320102340529    |
| train_0/reward            | -0.7183624230034183   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0020263671875       |
| train_0/target_q          | -5.509461016444494    |
| train_1/avg_q             | -14.808442591454172   |
| train_1/current_q         | -13.20105009866542    |
| train_1/fw_bonus          | -0.995477420091629    |
| train_1/fw_loss           | 0.0016222699487116188 |
| train_1/mu_grads          | 0.00805155977141112   |
| train_1/mu_grads_std      | 0.2938450276851654    |
| train_1/mu_loss           | 13.158733861351783    |
| train_1/n_subgoals        | 2340.0                |
| train_1/next_q            | -13.275322704287655   |
| train_1/q_grads           | 0.0051336161326617    |
| train_1/q_grads_std       | 0.3253319889307022    |
| train_1/q_loss            | 10.806187640994853    |
| train_1/reward            | -2.567332490620538    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0132568359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10897435897435898   |
| train_1/target_q          | -13.177428898890378   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 4
Time for epoch 4: 471.59. Rollout time: 292.14, Training time: 179.42
Evaluating epoch 4
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 4                     |
| policy/steps              | 359865.0              |
| test/episodes             | 75.0                  |
| test/success_rate         | 0.3333333333333333    |
| test_0/avg_q              | -1.3204609683291597   |
| test_1/avg_q              | -12.501280225837586   |
| test_1/n_subgoals         | 1670.0                |
| test_1/subgoal_succ_rate  | 0.8137724550898203    |
| train/episodes            | 500.0                 |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -6.672841262318243    |
| train_0/current_q         | -5.143276989479482    |
| train_0/fw_bonus          | -0.9986425921320915   |
| train_0/fw_loss           | 0.000399649963947013  |
| train_0/mu_grads          | -0.045996323134750126 |
| train_0/mu_grads_std      | 0.2802825443446636    |
| train_0/mu_loss           | 4.8781747996779945    |
| train_0/next_q            | -4.782056998736154    |
| train_0/q_grads           | 0.0201299506239593    |
| train_0/q_grads_std       | 0.2079260554164648    |
| train_0/q_loss            | 0.39001009188512403   |
| train_0/reward            | -0.7182092317612842   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0012451171875       |
| train_0/target_q          | -5.105749767756959    |
| train_1/avg_q             | -14.32048934814037    |
| train_1/current_q         | -12.776410976923398   |
| train_1/fw_bonus          | -0.9954560115933418   |
| train_1/fw_loss           | 0.0016277561895549296 |
| train_1/mu_grads          | 0.005618043150752783  |
| train_1/mu_grads_std      | 0.3225977450609207    |
| train_1/mu_loss           | 12.934555693780794    |
| train_1/n_subgoals        | 2117.0                |
| train_1/next_q            | -12.879424561663251   |
| train_1/q_grads           | 0.00201770206913352   |
| train_1/q_grads_std       | 0.3445793740451336    |
| train_1/q_loss            | 10.468826762314086    |
| train_1/reward            | -2.4815422230007242   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01328125            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14359943316013227   |
| train_1/target_q          | -12.887869120575107   |
-----------------------------------------------------
New best value for test/success_rate: 0.3333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09999999999999999
Training epoch 5
Time for epoch 5: 385.46. Rollout time: 230.97, Training time: 154.46
Evaluating epoch 5
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 5                      |
| policy/steps              | 417889.0               |
| test/episodes             | 90.0                   |
| test/success_rate         | 0.3333333333333333     |
| test_0/avg_q              | -1.7288011299314274    |
| test_1/avg_q              | -11.836298245905896    |
| test_1/n_subgoals         | 409.0                  |
| test_1/subgoal_succ_rate  | 0.07090464547677261    |
| train/episodes            | 600.0                  |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -7.548370105046231     |
| train_0/current_q         | -5.2747909237703166    |
| train_0/fw_bonus          | -0.9986447796225548    |
| train_0/fw_loss           | 0.00039901107738842255 |
| train_0/mu_grads          | -0.05203361762687564   |
| train_0/mu_grads_std      | 0.29564302414655685    |
| train_0/mu_loss           | 5.052632517405251      |
| train_0/next_q            | -4.9076519680391755    |
| train_0/q_grads           | 0.02387653198093176    |
| train_0/q_grads_std       | 0.22958575896918773    |
| train_0/q_loss            | 0.4100022005081164     |
| train_0/reward            | -0.7195281394950144    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.002392578125         |
| train_0/target_q          | -5.203538507005683     |
| train_1/avg_q             | -14.921093144832358    |
| train_1/current_q         | -12.786049262466335    |
| train_1/fw_bonus          | -0.9952895611524581    |
| train_1/fw_loss           | 0.0016703726083505898  |
| train_1/mu_grads          | 0.002599095011828467   |
| train_1/mu_grads_std      | 0.33995175287127494    |
| train_1/mu_loss           | 13.05587623088204      |
| train_1/n_subgoals        | 2106.0                 |
| train_1/next_q            | -12.9557177310484      |
| train_1/q_grads           | -0.0015067106753122062 |
| train_1/q_grads_std       | 0.36029975637793543    |
| train_1/q_loss            | 10.312461976601918     |
| train_1/reward            | -2.4685916780763364    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0128173828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24074074074074073    |
| train_1/target_q          | -12.865810138868094    |
------------------------------------------------------
New best value for test/success_rate: 0.3333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.18333333333333332
Training epoch 6
Time for epoch 6: 440.54. Rollout time: 251.34, Training time: 189.17
Evaluating epoch 6
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 6                     |
| policy/steps              | 471193.0              |
| test/episodes             | 105.0                 |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.009576730387438    |
| test_1/avg_q              | -15.848272353185367   |
| test_1/n_subgoals         | 4498.0                |
| test_1/subgoal_succ_rate  | 0.9619831036016007    |
| train/episodes            | 700.0                 |
| train/success_rate        | 0.55                  |
| train_0/avg_q             | -9.269660360657628    |
| train_0/current_q         | -5.145855548731091    |
| train_0/fw_bonus          | -0.9985914781689644   |
| train_0/fw_loss           | 0.0004145395716477651 |
| train_0/mu_grads          | -0.05921857329085469  |
| train_0/mu_grads_std      | 0.3162715554237366    |
| train_0/mu_loss           | 4.927285930232522     |
| train_0/next_q            | -4.784658575262869    |
| train_0/q_grads           | 0.02744590612128377   |
| train_0/q_grads_std       | 0.24679227285087108   |
| train_0/q_loss            | 0.5755658179239754    |
| train_0/reward            | -0.7305743833479937   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.000439453125        |
| train_0/target_q          | -5.0665607123526355   |
| train_1/avg_q             | -14.399675358337968   |
| train_1/current_q         | -13.549853465052138   |
| train_1/fw_bonus          | -0.9954313889145852   |
| train_1/fw_loss           | 0.001634057064075023  |
| train_1/mu_grads          | 0.0009682204225100576 |
| train_1/mu_grads_std      | 0.3540854282677174    |
| train_1/mu_loss           | 13.742857667688218    |
| train_1/n_subgoals        | 1907.0                |
| train_1/next_q            | -13.648265066676203   |
| train_1/q_grads           | -0.004295601963531226 |
| train_1/q_grads_std       | 0.37395571991801263   |
| train_1/q_loss            | 7.303060198052559     |
| train_1/reward            | -2.421770444311915    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0130615234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2548505506030414    |
| train_1/target_q          | -13.593616831262853   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18333333333333332
Training epoch 7
Time for epoch 7: 441.71. Rollout time: 270.01, Training time: 171.67
Evaluating epoch 7
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 7                      |
| policy/steps              | 530587.0               |
| test/episodes             | 120.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -4.2599292824809805    |
| test_1/avg_q              | -12.120667946203561    |
| test_1/n_subgoals         | 386.0                  |
| test_1/subgoal_succ_rate  | 0.02072538860103627    |
| train/episodes            | 800.0                  |
| train/success_rate        | 0.39                   |
| train_0/avg_q             | -6.58836496814791      |
| train_0/current_q         | -4.297430756705848     |
| train_0/fw_bonus          | -0.9987153634428978    |
| train_0/fw_loss           | 0.00037844738981220873 |
| train_0/mu_grads          | -0.06526543237268925   |
| train_0/mu_grads_std      | 0.32942472845315934    |
| train_0/mu_loss           | 4.1230172364783115     |
| train_0/next_q            | -3.976281374736547     |
| train_0/q_grads           | 0.028191658761352302   |
| train_0/q_grads_std       | 0.2516395427286625     |
| train_0/q_loss            | 0.6069507442857235     |
| train_0/reward            | -0.7363731796522188    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.00234375             |
| train_0/target_q          | -4.288513205061564     |
| train_1/avg_q             | -15.3423506829043      |
| train_1/current_q         | -13.202716792739707    |
| train_1/fw_bonus          | -0.994668324291706     |
| train_1/fw_loss           | 0.0018294449080713093  |
| train_1/mu_grads          | -0.0006591465316887479 |
| train_1/mu_grads_std      | 0.36620382145047187    |
| train_1/mu_loss           | 13.169003688769982     |
| train_1/n_subgoals        | 2149.0                 |
| train_1/next_q            | -13.113917652645153    |
| train_1/q_grads           | -0.0063034475315362215 |
| train_1/q_grads_std       | 0.3855800710618496     |
| train_1/q_loss            | 7.884830805295768      |
| train_1/reward            | -2.393747644796895     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.012548828125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2275476966030712     |
| train_1/target_q          | -13.197710198053196    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.19999999999999998
Training epoch 8
Time for epoch 8: 451.23. Rollout time: 271.63, Training time: 179.56
Evaluating epoch 8
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 8                      |
| policy/steps              | 589996.0               |
| test/episodes             | 135.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.5347205450579984    |
| test_1/avg_q              | -16.36518584068209     |
| test_1/n_subgoals         | 2820.0                 |
| test_1/subgoal_succ_rate  | 0.899645390070922      |
| train/episodes            | 900.0                  |
| train/success_rate        | 0.46                   |
| train_0/avg_q             | -8.431710354647436     |
| train_0/current_q         | -5.831476477274013     |
| train_0/fw_bonus          | -0.9988291904330253    |
| train_0/fw_loss           | 0.00034529002296039834 |
| train_0/mu_grads          | -0.07186917513608933   |
| train_0/mu_grads_std      | 0.3424082241952419     |
| train_0/mu_loss           | 5.624050488727034      |
| train_0/next_q            | -5.50699154870013      |
| train_0/q_grads           | 0.028557698475196958   |
| train_0/q_grads_std       | 0.25886101722717286    |
| train_0/q_loss            | 0.7865257228629697     |
| train_0/reward            | -0.7461245356334985    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0016845703125        |
| train_0/target_q          | -5.800898492907274     |
| train_1/avg_q             | -14.99334742848422     |
| train_1/current_q         | -13.112965907955743    |
| train_1/fw_bonus          | -0.9951235845685005    |
| train_1/fw_loss           | 0.0017128721141489224  |
| train_1/mu_grads          | -0.0030573858006391675 |
| train_1/mu_grads_std      | 0.3808997988700867     |
| train_1/mu_loss           | 13.325572039693203     |
| train_1/n_subgoals        | 2060.0                 |
| train_1/next_q            | -13.102381186206022    |
| train_1/q_grads           | -0.007322277571074664  |
| train_1/q_grads_std       | 0.40066518560051917    |
| train_1/q_loss            | 7.397122298045856      |
| train_1/reward            | -2.365992810825992     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0125732421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.170873786407767      |
| train_1/target_q          | -13.19342695888966     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13333333333333333
Training epoch 9
Time for epoch 9: 440.66. Rollout time: 252.56, Training time: 188.07
Evaluating epoch 9
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 9                      |
| policy/steps              | 642981.0               |
| test/episodes             | 150.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.7794615422901248    |
| test_1/avg_q              | -19.135064685693465    |
| test_1/n_subgoals         | 420.0                  |
| test_1/subgoal_succ_rate  | 0.03571428571428571    |
| train/episodes            | 1000.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -8.75479494893317      |
| train_0/current_q         | -5.005463092446273     |
| train_0/fw_bonus          | -0.9988921701908111    |
| train_0/fw_loss           | 0.00032694533583708105 |
| train_0/mu_grads          | -0.07457805331796408   |
| train_0/mu_grads_std      | 0.3541269898414612     |
| train_0/mu_loss           | 4.792453897075378      |
| train_0/next_q            | -4.665822627645512     |
| train_0/q_grads           | 0.031013392237946392   |
| train_0/q_grads_std       | 0.2671713769435883     |
| train_0/q_loss            | 0.5128196570137724     |
| train_0/reward            | -0.7468727008923451    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.01171875             |
| train_0/target_q          | -5.041658889798827     |
| train_1/avg_q             | -17.00019904828113     |
| train_1/current_q         | -12.591629849730857    |
| train_1/fw_bonus          | -0.9951321333646774    |
| train_1/fw_loss           | 0.0017106817307649181  |
| train_1/mu_grads          | -0.005052886588964611  |
| train_1/mu_grads_std      | 0.3933943763375282     |
| train_1/mu_loss           | 12.642286905989874     |
| train_1/n_subgoals        | 1946.0                 |
| train_1/next_q            | -12.473532595857773    |
| train_1/q_grads           | -0.009797876747325063  |
| train_1/q_grads_std       | 0.4122402749955654     |
| train_1/q_loss            | 6.8721279248393525     |
| train_1/reward            | -2.317050856309288     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.012890625            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3011305241521069     |
| train_1/target_q          | -12.657783420796592    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 10
Time for epoch 10: 489.76. Rollout time: 303.50, Training time: 186.22
Evaluating epoch 10
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 10                     |
| policy/steps              | 704358.0               |
| test/episodes             | 165.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.4418030792354406    |
| test_1/avg_q              | -4.360998094353628     |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1100.0                 |
| train/success_rate        | 0.45                   |
| train_0/avg_q             | -9.776138929541633     |
| train_0/current_q         | -5.5933854081043455    |
| train_0/fw_bonus          | -0.9989744648337364    |
| train_0/fw_loss           | 0.00030297352132038215 |
| train_0/mu_grads          | -0.07961697578430176   |
| train_0/mu_grads_std      | 0.3645834229886532     |
| train_0/mu_loss           | 5.475136694550272      |
| train_0/next_q            | -5.328919303790714     |
| train_0/q_grads           | 0.03157608127221465    |
| train_0/q_grads_std       | 0.27352763786911966    |
| train_0/q_loss            | 0.9505498620182425     |
| train_0/reward            | -0.7417296991949115    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.02744140625          |
| train_0/target_q          | -5.50481128238725      |
| train_1/avg_q             | -14.396376709233097    |
| train_1/current_q         | -8.0523725495581       |
| train_1/fw_bonus          | -0.9952401936054229    |
| train_1/fw_loss           | 0.0016830160340759904  |
| train_1/mu_grads          | -0.009122075675986708  |
| train_1/mu_grads_std      | 0.4008582323789597     |
| train_1/mu_loss           | 7.145068029339585      |
| train_1/n_subgoals        | 2110.0                 |
| train_1/next_q            | -7.049684249741523     |
| train_1/q_grads           | -0.014987696753814816  |
| train_1/q_grads_std       | 0.4186821885406971     |
| train_1/q_loss            | 17.275487230694466     |
| train_1/reward            | -2.2326845571868033    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01259765625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.15829383886255924    |
| train_1/target_q          | -8.271930391514084     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_10.pkl ...
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 11
Time for epoch 11: 477.20. Rollout time: 296.79, Training time: 180.38
Evaluating epoch 11
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 11                    |
| policy/steps              | 767318.0              |
| test/episodes             | 180.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.4485008112466151   |
| test_1/avg_q              | -13.714229504130522   |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 1200.0                |
| train/success_rate        | 0.42                  |
| train_0/avg_q             | -9.201076151336409    |
| train_0/current_q         | -5.897530912975291    |
| train_0/fw_bonus          | -0.9990308955311775   |
| train_0/fw_loss           | 0.0002865334230591543 |
| train_0/mu_grads          | -0.08155974950641394  |
| train_0/mu_grads_std      | 0.37743974179029466   |
| train_0/mu_loss           | 5.800467505660937     |
| train_0/next_q            | -5.628035145074085    |
| train_0/q_grads           | 0.03107540854252875   |
| train_0/q_grads_std       | 0.28237292543053627   |
| train_0/q_loss            | 1.0217732975294063    |
| train_0/reward            | -0.7386859466183523   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0400146484375       |
| train_0/target_q          | -5.766439320580984    |
| train_1/avg_q             | -9.970262485645819    |
| train_1/current_q         | -12.000466724158715   |
| train_1/fw_bonus          | -0.995446401834488    |
| train_1/fw_loss           | 0.0016302144154906272 |
| train_1/mu_grads          | -0.006559098511934281 |
| train_1/mu_grads_std      | 0.4086753182113171    |
| train_1/mu_loss           | 11.96841338378189     |
| train_1/n_subgoals        | 2160.0                |
| train_1/next_q            | -11.779461127502753   |
| train_1/q_grads           | -0.012656599259935319 |
| train_1/q_grads_std       | 0.4238648608326912    |
| train_1/q_loss            | 11.558493411835084    |
| train_1/reward            | -2.3004668233443226   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0134765625          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.14629629629629629   |
| train_1/target_q          | -12.065088184021857   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 12
Time for epoch 12: 453.46. Rollout time: 271.83, Training time: 181.60
Evaluating epoch 12
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 12                    |
| policy/steps              | 828138.0              |
| test/episodes             | 195.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.5522500964210533   |
| test_1/avg_q              | -6.092122529819039    |
| test_1/n_subgoals         | 413.0                 |
| test_1/subgoal_succ_rate  | 0.01937046004842615   |
| train/episodes            | 1300.0                |
| train/success_rate        | 0.39                  |
| train_0/avg_q             | -9.788128883553567    |
| train_0/current_q         | -5.676073530049593    |
| train_0/fw_bonus          | -0.9991306573152542   |
| train_0/fw_loss           | 0.0002574707177700475 |
| train_0/mu_grads          | -0.08362685721367598  |
| train_0/mu_grads_std      | 0.3888404548168182    |
| train_0/mu_loss           | 5.499201192223874     |
| train_0/next_q            | -5.327852138189579    |
| train_0/q_grads           | 0.0325032414868474    |
| train_0/q_grads_std       | 0.2907233819365501    |
| train_0/q_loss            | 0.6051636532985227    |
| train_0/reward            | -0.7452843743114499   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0292724609375       |
| train_0/target_q          | -5.621617547828575    |
| train_1/avg_q             | -13.746649337464046   |
| train_1/current_q         | -10.679394959792424   |
| train_1/fw_bonus          | -0.9959273502230644   |
| train_1/fw_loss           | 0.0015070644236402585 |
| train_1/mu_grads          | -0.01099934931844473  |
| train_1/mu_grads_std      | 0.415033882111311     |
| train_1/mu_loss           | 10.016826246832057    |
| train_1/n_subgoals        | 2172.0                |
| train_1/next_q            | -9.960444180462865    |
| train_1/q_grads           | -0.01957778581418097  |
| train_1/q_grads_std       | 0.42930313274264337   |
| train_1/q_loss            | 13.748331739647437    |
| train_1/reward            | -2.300202541710314    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.013330078125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.20349907918968693   |
| train_1/target_q          | -10.679294749403082   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 13
Time for epoch 13: 444.24. Rollout time: 260.96, Training time: 183.25
Evaluating epoch 13
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 13                     |
| policy/steps              | 885750.0               |
| test/episodes             | 210.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.393059659041537     |
| test_1/avg_q              | -18.333252018381216    |
| test_1/n_subgoals         | 1509.0                 |
| test_1/subgoal_succ_rate  | 0.7607687210072896     |
| train/episodes            | 1400.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -13.17979843638487     |
| train_0/current_q         | -6.319367639801183     |
| train_0/fw_bonus          | -0.9991888985037803    |
| train_0/fw_loss           | 0.00024050305073615165 |
| train_0/mu_grads          | -0.08794136326760053   |
| train_0/mu_grads_std      | 0.3987702988088131     |
| train_0/mu_loss           | 6.117088745469434      |
| train_0/next_q            | -5.9529105597491085    |
| train_0/q_grads           | 0.03388320170342922    |
| train_0/q_grads_std       | 0.3019416190683842     |
| train_0/q_loss            | 0.45920362501516426    |
| train_0/reward            | -0.7467637797082716    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.03466796875          |
| train_0/target_q          | -6.272722228242122     |
| train_1/avg_q             | -12.81735795937655     |
| train_1/current_q         | -12.783904625039483    |
| train_1/fw_bonus          | -0.996331338584423     |
| train_1/fw_loss           | 0.0014036226988537238  |
| train_1/mu_grads          | -0.011228210642002523  |
| train_1/mu_grads_std      | 0.4189863264560699     |
| train_1/mu_loss           | 12.897778252061556     |
| train_1/n_subgoals        | 2056.0                 |
| train_1/next_q            | -12.825740709016525    |
| train_1/q_grads           | -0.021711438428610563  |
| train_1/q_grads_std       | 0.4391939453780651     |
| train_1/q_loss            | 7.9414884387012465     |
| train_1/reward            | -2.304514964259215     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.013427734375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24319066147859922    |
| train_1/target_q          | -12.948466233909347    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 14
Time for epoch 14: 439.75. Rollout time: 260.60, Training time: 179.11
Evaluating epoch 14
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 14                     |
| policy/steps              | 939948.0               |
| test/episodes             | 225.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.297355953800021     |
| test_1/avg_q              | -19.8620367782964      |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1500.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -14.087672519656905    |
| train_0/current_q         | -5.47267664788473      |
| train_0/fw_bonus          | -0.9991838902235031    |
| train_0/fw_loss           | 0.00024196654194383883 |
| train_0/mu_grads          | -0.09281678255647421   |
| train_0/mu_grads_std      | 0.40999119728803635    |
| train_0/mu_loss           | 5.2868347692877204     |
| train_0/next_q            | -5.129475607963849     |
| train_0/q_grads           | 0.03420194536447525    |
| train_0/q_grads_std       | 0.3111912116408348     |
| train_0/q_loss            | 0.5375930705108903     |
| train_0/reward            | -0.7474033926460834    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0471435546875        |
| train_0/target_q          | -5.439366513947705     |
| train_1/avg_q             | -17.61821136056458     |
| train_1/current_q         | -12.773883286407031    |
| train_1/fw_bonus          | -0.9962642788887024    |
| train_1/fw_loss           | 0.0014207964995875955  |
| train_1/mu_grads          | -0.012189644644968212  |
| train_1/mu_grads_std      | 0.4243030473589897     |
| train_1/mu_loss           | 12.994114834107393     |
| train_1/n_subgoals        | 1935.0                 |
| train_1/next_q            | -12.827484127500815    |
| train_1/q_grads           | -0.022542715538293123  |
| train_1/q_grads_std       | 0.4499999903142452     |
| train_1/q_loss            | 9.012051762937716      |
| train_1/reward            | -2.273113918602758     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0153076171875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24289405684754523    |
| train_1/target_q          | -12.931046071775194    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 15
Time for epoch 15: 463.51. Rollout time: 281.22, Training time: 182.26
Evaluating epoch 15
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 15                     |
| policy/steps              | 996234.0               |
| test/episodes             | 240.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.0935737246715174    |
| test_1/avg_q              | -17.014810825878605    |
| test_1/n_subgoals         | 581.0                  |
| test_1/subgoal_succ_rate  | 0.31497418244406195    |
| train/episodes            | 1600.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -13.402357714819228    |
| train_0/current_q         | -4.952932401609819     |
| train_0/fw_bonus          | -0.9992169082164765    |
| train_0/fw_loss           | 0.00023234736327140126 |
| train_0/mu_grads          | -0.09151586294174194   |
| train_0/mu_grads_std      | 0.4209619462490082     |
| train_0/mu_loss           | 4.731300070342143      |
| train_0/next_q            | -4.642436946591555     |
| train_0/q_grads           | 0.034676180128008126   |
| train_0/q_grads_std       | 0.31738647967576983    |
| train_0/q_loss            | 0.5420466853361445     |
| train_0/reward            | -0.7486018335112021    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0603759765625        |
| train_0/target_q          | -4.998585779007643     |
| train_1/avg_q             | -18.805459162155014    |
| train_1/current_q         | -13.92029783931415     |
| train_1/fw_bonus          | -0.9965977981686592    |
| train_1/fw_loss           | 0.0013353959511732683  |
| train_1/mu_grads          | -0.012372330832295119  |
| train_1/mu_grads_std      | 0.42912323772907257    |
| train_1/mu_loss           | 14.364342800704467     |
| train_1/n_subgoals        | 1976.0                 |
| train_1/next_q            | -14.184307753668293    |
| train_1/q_grads           | -0.023055755300447345  |
| train_1/q_grads_std       | 0.4626179449260235     |
| train_1/q_loss            | 5.0168239103479095     |
| train_1/reward            | -2.2672463738221267    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0146728515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.21002024291497975    |
| train_1/target_q          | -13.983364675566875    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 16
Time for epoch 16: 455.67. Rollout time: 266.51, Training time: 189.12
Evaluating epoch 16
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 16                     |
| policy/steps              | 1052355.0              |
| test/episodes             | 255.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.1747589113217214    |
| test_1/avg_q              | -16.749868557102076    |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1700.0                 |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -9.690068361727088     |
| train_0/current_q         | -4.583322236124329     |
| train_0/fw_bonus          | -0.9991798043251038    |
| train_0/fw_loss           | 0.00024315634109370877 |
| train_0/mu_grads          | -0.09427360016852618   |
| train_0/mu_grads_std      | 0.42985900267958643    |
| train_0/mu_loss           | 4.398076216892699      |
| train_0/next_q            | -4.273039450813619     |
| train_0/q_grads           | 0.03514450341463089    |
| train_0/q_grads_std       | 0.32410339266061783    |
| train_0/q_loss            | 0.6075261719099138     |
| train_0/reward            | -0.7435205358022359    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0671142578125        |
| train_0/target_q          | -4.656002405183477     |
| train_1/avg_q             | -18.048906709170115    |
| train_1/current_q         | -13.283089193152914    |
| train_1/fw_bonus          | -0.9969614565372467    |
| train_1/fw_loss           | 0.0012422804487869144  |
| train_1/mu_grads          | -0.01375098554417491   |
| train_1/mu_grads_std      | 0.4361412562429905     |
| train_1/mu_loss           | 13.389249520644658     |
| train_1/n_subgoals        | 2021.0                 |
| train_1/next_q            | -13.288115936933519    |
| train_1/q_grads           | -0.022333470173180103  |
| train_1/q_grads_std       | 0.47228505164384843    |
| train_1/q_loss            | 4.742914385837508      |
| train_1/reward            | -2.2465548168260283    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0141845703125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24641266699653636    |
| train_1/target_q          | -13.327290578792525    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 17
Time for epoch 17: 449.09. Rollout time: 264.79, Training time: 184.26
Evaluating epoch 17
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 17                     |
| policy/steps              | 1108694.0              |
| test/episodes             | 270.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -0.4512243944643288    |
| test_1/avg_q              | -20.06690671740371     |
| test_1/n_subgoals         | 405.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1800.0                 |
| train/success_rate        | 0.59                   |
| train_0/avg_q             | -9.070338582165181     |
| train_0/current_q         | -5.994799767200847     |
| train_0/fw_bonus          | -0.9992039129137993    |
| train_0/fw_loss           | 0.00023613107696291992 |
| train_0/mu_grads          | -0.09646081905812025   |
| train_0/mu_grads_std      | 0.438671662658453      |
| train_0/mu_loss           | 5.755602003743706      |
| train_0/next_q            | -5.6358930215707925    |
| train_0/q_grads           | 0.036113906744867565   |
| train_0/q_grads_std       | 0.33000459149479866    |
| train_0/q_loss            | 0.5946532462318119     |
| train_0/reward            | -0.7425194848274259    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.044189453125         |
| train_0/target_q          | -5.95619319351947      |
| train_1/avg_q             | -16.810355437856064    |
| train_1/current_q         | -13.577062108444025    |
| train_1/fw_bonus          | -0.9967606320977211    |
| train_1/fw_loss           | 0.0012937027990119533  |
| train_1/mu_grads          | -0.014296711282804608  |
| train_1/mu_grads_std      | 0.4426759734749794     |
| train_1/mu_loss           | 13.877518300025681     |
| train_1/n_subgoals        | 1931.0                 |
| train_1/next_q            | -13.709314430239479    |
| train_1/q_grads           | -0.0208227735478431    |
| train_1/q_grads_std       | 0.4873161122202873     |
| train_1/q_loss            | 5.107305231992685      |
| train_1/reward            | -2.2679462599138787    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01474609375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.17089590885551528    |
| train_1/target_q          | -13.65801771482764     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 18
Time for epoch 18: 565.26. Rollout time: 356.47, Training time: 208.76
Evaluating epoch 18
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 18                     |
| policy/steps              | 1172475.0              |
| test/episodes             | 285.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.4580553870810913    |
| test_1/avg_q              | -20.76757893408841     |
| test_1/n_subgoals         | 401.0                  |
| test_1/subgoal_succ_rate  | 0.0                    |
| train/episodes            | 1900.0                 |
| train/success_rate        | 0.37                   |
| train_0/avg_q             | -5.924121002533787     |
| train_0/current_q         | -5.082204778162598     |
| train_0/fw_bonus          | -0.9991704806685447    |
| train_0/fw_loss           | 0.00024587195075582714 |
| train_0/mu_grads          | -0.09377030190080404   |
| train_0/mu_grads_std      | 0.4500443324446678     |
| train_0/mu_loss           | 4.880851637357339      |
| train_0/next_q            | -4.728351120075317     |
| train_0/q_grads           | 0.036142841540277006   |
| train_0/q_grads_std       | 0.33035229817032813    |
| train_0/q_loss            | 0.6617311761634111     |
| train_0/reward            | -0.7355348067947489    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.055810546875         |
| train_0/target_q          | -4.958691458366881     |
| train_1/avg_q             | -15.225747659709663    |
| train_1/current_q         | -11.69077393893457     |
| train_1/fw_bonus          | -0.9965553849935531    |
| train_1/fw_loss           | 0.0013462535425787792  |
| train_1/mu_grads          | -0.014846727531403304  |
| train_1/mu_grads_std      | 0.4494482293725014     |
| train_1/mu_loss           | 11.662159038717451     |
| train_1/n_subgoals        | 2123.0                 |
| train_1/next_q            | -11.503112241589786    |
| train_1/q_grads           | -0.021576285501942037  |
| train_1/q_grads_std       | 0.49638683572411535    |
| train_1/q_loss            | 4.44463506172235       |
| train_1/reward            | -2.249675957954969     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0143798828125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.10504003768252473    |
| train_1/target_q          | -11.803991132052513    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 19
Time for epoch 19: 489.96. Rollout time: 277.38, Training time: 212.53
Evaluating epoch 19
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 19                    |
| policy/steps              | 1226462.0             |
| test/episodes             | 300.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -2.7138217335786807   |
| test_1/avg_q              | -20.075492013267546   |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2000.0                |
| train/success_rate        | 0.56                  |
| train_0/avg_q             | -8.72472570101054     |
| train_0/current_q         | -4.722025862392995    |
| train_0/fw_bonus          | -0.9992017582058906   |
| train_0/fw_loss           | 0.0002367580211284803 |
| train_0/mu_grads          | -0.09537750575691462  |
| train_0/mu_grads_std      | 0.45835758522152903   |
| train_0/mu_loss           | 4.737403829192902     |
| train_0/next_q            | -4.564577324360505    |
| train_0/q_grads           | 0.037006942369043824  |
| train_0/q_grads_std       | 0.33580435886979104   |
| train_0/q_loss            | 0.9959008965502137    |
| train_0/reward            | -0.7365863295530289   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0640380859375       |
| train_0/target_q          | -4.694853831235617    |
| train_1/avg_q             | -18.242265502694227   |
| train_1/current_q         | -9.33077176756493     |
| train_1/fw_bonus          | -0.99672582000494     |
| train_1/fw_loss           | 0.001302614068845287  |
| train_1/mu_grads          | -0.014579929830506443 |
| train_1/mu_grads_std      | 0.45427813529968264   |
| train_1/mu_loss           | 9.082321870643455     |
| train_1/n_subgoals        | 1975.0                |
| train_1/next_q            | -8.856011146882716    |
| train_1/q_grads           | -0.023393900785595178 |
| train_1/q_grads_std       | 0.5044097021222115    |
| train_1/q_loss            | 4.466621359219522     |
| train_1/reward            | -2.2416802333002126   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.013525390625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.26987341772151896   |
| train_1/target_q          | -9.458021736848956    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 20
Time for epoch 20: 536.88. Rollout time: 322.94, Training time: 213.90
Evaluating epoch 20
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 20                     |
| policy/steps              | 1287361.0              |
| test/episodes             | 315.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6495196221555686    |
| test_1/avg_q              | -19.72140320603756     |
| test_1/n_subgoals         | 713.0                  |
| test_1/subgoal_succ_rate  | 0.45582047685834504    |
| train/episodes            | 2100.0                 |
| train/success_rate        | 0.54                   |
| train_0/avg_q             | -10.192519218204573    |
| train_0/current_q         | -5.532601323150212     |
| train_0/fw_bonus          | -0.9992438524961471    |
| train_0/fw_loss           | 0.00022449624921137002 |
| train_0/mu_grads          | -0.0995276089757681    |
| train_0/mu_grads_std      | 0.466308318823576      |
| train_0/mu_loss           | 5.3494897927385034     |
| train_0/next_q            | -5.187762061796301     |
| train_0/q_grads           | 0.036968587804585694   |
| train_0/q_grads_std       | 0.3387842282652855     |
| train_0/q_loss            | 0.520571822053539      |
| train_0/reward            | -0.7354799091906898    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.08349609375          |
| train_0/target_q          | -5.483456374953836     |
| train_1/avg_q             | -17.222939037948013    |
| train_1/current_q         | -12.956969935564004    |
| train_1/fw_bonus          | -0.997198922932148     |
| train_1/fw_loss           | 0.0011814761615823953  |
| train_1/mu_grads          | -0.014320956310257316  |
| train_1/mu_grads_std      | 0.45990772917866707    |
| train_1/mu_loss           | 13.037947855831556     |
| train_1/n_subgoals        | 2058.0                 |
| train_1/next_q            | -12.921361288077032    |
| train_1/q_grads           | -0.023488114448264243  |
| train_1/q_grads_std       | 0.5155938401818275     |
| train_1/q_loss            | 6.957179167304764      |
| train_1/reward            | -2.2594315651582293    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01484375             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.14334305150631682    |
| train_1/target_q          | -12.951794977973043    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_20.pkl ...
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 21
Time for epoch 21: 520.08. Rollout time: 285.64, Training time: 234.39
Evaluating epoch 21
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 21                     |
| policy/steps              | 1335623.0              |
| test/episodes             | 330.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4031473933168133    |
| test_1/avg_q              | -13.687900479637758    |
| test_1/n_subgoals         | 821.0                  |
| test_1/subgoal_succ_rate  | 0.5261875761266748     |
| train/episodes            | 2200.0                 |
| train/success_rate        | 0.66                   |
| train_0/avg_q             | -10.777114519199872    |
| train_0/current_q         | -5.064116374110892     |
| train_0/fw_bonus          | -0.9991934925317765    |
| train_0/fw_loss           | 0.00023916598875075578 |
| train_0/mu_grads          | -0.10293554048985243   |
| train_0/mu_grads_std      | 0.4733821481466293     |
| train_0/mu_loss           | 4.895024337291673      |
| train_0/next_q            | -4.729261183830234     |
| train_0/q_grads           | 0.036367806140333414   |
| train_0/q_grads_std       | 0.3403797931969166     |
| train_0/q_loss            | 0.590656042123225      |
| train_0/reward            | -0.7366025735162112    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0599609375           |
| train_0/target_q          | -4.991184628035149     |
| train_1/avg_q             | -17.719735532825066    |
| train_1/current_q         | -12.331395241354834    |
| train_1/fw_bonus          | -0.9971939295530319    |
| train_1/fw_loss           | 0.0011827572277979925  |
| train_1/mu_grads          | -0.016148874629288913  |
| train_1/mu_grads_std      | 0.466297323256731      |
| train_1/mu_loss           | 12.338438664379305     |
| train_1/n_subgoals        | 1693.0                 |
| train_1/next_q            | -12.186775333071509    |
| train_1/q_grads           | -0.02437516888603568   |
| train_1/q_grads_std       | 0.5295165836811065     |
| train_1/q_loss            | 4.669334153811076      |
| train_1/reward            | -2.2751407634365024    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0146240234375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25575900767867693    |
| train_1/target_q          | -12.378293886032159    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 22
Time for epoch 22: 599.03. Rollout time: 310.60, Training time: 288.33
Evaluating epoch 22
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 22                     |
| policy/steps              | 1380002.0              |
| test/episodes             | 345.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -2.136457401956946     |
| test_1/avg_q              | -14.745557796762984    |
| test_1/n_subgoals         | 1379.0                 |
| test_1/subgoal_succ_rate  | 0.7425670775924583     |
| train/episodes            | 2300.0                 |
| train/success_rate        | 0.73                   |
| train_0/avg_q             | -10.065475514429384    |
| train_0/current_q         | -5.12249164703576      |
| train_0/fw_bonus          | -0.9992009356617928    |
| train_0/fw_loss           | 0.00023699967096035834 |
| train_0/mu_grads          | -0.10630135536193848   |
| train_0/mu_grads_std      | 0.4795536510646343     |
| train_0/mu_loss           | 5.037089611049356      |
| train_0/next_q            | -4.83898108515555      |
| train_0/q_grads           | 0.03618283625692129    |
| train_0/q_grads_std       | 0.34158015474677084    |
| train_0/q_loss            | 0.6596811354060528     |
| train_0/reward            | -0.7320634171002893    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0562744140625        |
| train_0/target_q          | -5.111397796446755     |
| train_1/avg_q             | -17.277937034446193    |
| train_1/current_q         | -12.57497733226342     |
| train_1/fw_bonus          | -0.997391727566719     |
| train_1/fw_loss           | 0.0011321075246087276  |
| train_1/mu_grads          | -0.01684571783989668   |
| train_1/mu_grads_std      | 0.467857126891613      |
| train_1/mu_loss           | 12.741146463643762     |
| train_1/n_subgoals        | 1537.0                 |
| train_1/next_q            | -12.636768096579557    |
| train_1/q_grads           | -0.02476525972597301   |
| train_1/q_grads_std       | 0.5457629084587097     |
| train_1/q_loss            | 6.434660671600353      |
| train_1/reward            | -2.2418650215829983    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01630859375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25894599869876384    |
| train_1/target_q          | -12.670839577757505    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 23
Time for epoch 23: 416.99. Rollout time: 193.56, Training time: 223.38
Evaluating epoch 23
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 23                     |
| policy/steps              | 1417941.0              |
| test/episodes             | 360.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.49136883523315      |
| test_1/avg_q              | -17.89094615135463     |
| test_1/n_subgoals         | 400.0                  |
| test_1/subgoal_succ_rate  | 0.0125                 |
| train/episodes            | 2400.0                 |
| train/success_rate        | 0.87                   |
| train_0/avg_q             | -10.806107082970325    |
| train_0/current_q         | -5.774696656369628     |
| train_0/fw_bonus          | -0.9991859674453736    |
| train_0/fw_loss           | 0.00024135847634170203 |
| train_0/mu_grads          | -0.10862441398203374   |
| train_0/mu_grads_std      | 0.48610289990901945    |
| train_0/mu_loss           | 5.553289302653672      |
| train_0/next_q            | -5.41745940381602      |
| train_0/q_grads           | 0.03591563701629639    |
| train_0/q_grads_std       | 0.34338816329836847    |
| train_0/q_loss            | 0.5610609042343209     |
| train_0/reward            | -0.7326456140035589    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.0665771484375        |
| train_0/target_q          | -5.682470805084579     |
| train_1/avg_q             | -16.810487888693242    |
| train_1/current_q         | -12.418672991795926    |
| train_1/fw_bonus          | -0.9974575400352478    |
| train_1/fw_loss           | 0.0011152567953104154  |
| train_1/mu_grads          | -0.01647688583470881   |
| train_1/mu_grads_std      | 0.4709684938192368     |
| train_1/mu_loss           | 12.716641957965086     |
| train_1/n_subgoals        | 1286.0                 |
| train_1/next_q            | -12.534423569905828    |
| train_1/q_grads           | -0.026981158927083016  |
| train_1/q_grads_std       | 0.5625671654939651     |
| train_1/q_loss            | 6.3811625639409515     |
| train_1/reward            | -2.2642020308980135    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016748046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2931570762052877     |
| train_1/target_q          | -12.54237683444116     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 24
Time for epoch 24: 401.22. Rollout time: 203.45, Training time: 197.73
Evaluating epoch 24
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 24                    |
| policy/steps              | 1461730.0             |
| test/episodes             | 375.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -3.1551655525992772   |
| test_1/avg_q              | -20.536920550862003   |
| test_1/n_subgoals         | 405.0                 |
| test_1/subgoal_succ_rate  | 0.0                   |
| train/episodes            | 2500.0                |
| train/success_rate        | 0.8                   |
| train_0/avg_q             | -10.828456672765807   |
| train_0/current_q         | -5.0352987140478564   |
| train_0/fw_bonus          | -0.9991508930921554   |
| train_0/fw_loss           | 0.000251577923700097  |
| train_0/mu_grads          | -0.11412005629390479  |
| train_0/mu_grads_std      | 0.4931259214878082    |
| train_0/mu_loss           | 4.930961035171828     |
| train_0/next_q            | -4.749175505970493    |
| train_0/q_grads           | 0.03505346868187189   |
| train_0/q_grads_std       | 0.34567030146718025   |
| train_0/q_loss            | 0.5650946300794993    |
| train_0/reward            | -0.7312269314825244   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0612060546875       |
| train_0/target_q          | -5.051097781162838    |
| train_1/avg_q             | -17.3898982460125     |
| train_1/current_q         | -11.751675691734926   |
| train_1/fw_bonus          | -0.9972670495510101   |
| train_1/fw_loss           | 0.0011640323733445256 |
| train_1/mu_grads          | -0.017340794065967204 |
| train_1/mu_grads_std      | 0.47613702788949014   |
| train_1/mu_loss           | 11.903275305459752    |
| train_1/n_subgoals        | 1553.0                |
| train_1/next_q            | -11.752568710201237   |
| train_1/q_grads           | -0.02943803295493126  |
| train_1/q_grads_std       | 0.5760295271873475    |
| train_1/q_loss            | 6.971643944516396     |
| train_1/reward            | -2.218542837041241    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01484375            |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.30006439150032194   |
| train_1/target_q          | -11.807232764290493   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 25
Time for epoch 25: 6318.76. Rollout time: 3261.43, Training time: 3057.27
Evaluating epoch 25
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 25                     |
| policy/steps              | 1512207.0              |
| test/episodes             | 390.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.1579656172049788    |
| test_1/avg_q              | -20.27341041704451     |
| test_1/n_subgoals         | 976.0                  |
| test_1/subgoal_succ_rate  | 0.610655737704918      |
| train/episodes            | 2600.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -10.943643838551765    |
| train_0/current_q         | -6.1104946945527345    |
| train_0/fw_bonus          | -0.9991982579231262    |
| train_0/fw_loss           | 0.00023777682836225721 |
| train_0/mu_grads          | -0.11498734485358      |
| train_0/mu_grads_std      | 0.5011710301041603     |
| train_0/mu_loss           | 5.917519774143529      |
| train_0/next_q            | -5.772515925133117     |
| train_0/q_grads           | 0.03430901039391756    |
| train_0/q_grads_std       | 0.3501253746449947     |
| train_0/q_loss            | 0.6534671341896253     |
| train_0/reward            | -0.7333078672640113    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.08857421875          |
| train_0/target_q          | -5.976449790216156     |
| train_1/avg_q             | -18.049063029325033    |
| train_1/current_q         | -12.076168351635157    |
| train_1/fw_bonus          | -0.9968934908509255    |
| train_1/fw_loss           | 0.0012596801825566217  |
| train_1/mu_grads          | -0.01922061378136277   |
| train_1/mu_grads_std      | 0.47838232666254044    |
| train_1/mu_loss           | 12.39632868620842      |
| train_1/n_subgoals        | 1768.0                 |
| train_1/next_q            | -12.175216115628814    |
| train_1/q_grads           | -0.029715660586953165  |
| train_1/q_grads_std       | 0.5855509325861931     |
| train_1/q_loss            | 5.052587809660731      |
| train_1/reward            | -2.1780746933953194    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0136962890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24434389140271492    |
| train_1/target_q          | -12.168986218346646    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 26
Time for epoch 26: 489.63. Rollout time: 276.44, Training time: 213.15
Evaluating epoch 26
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 26                     |
| policy/steps              | 1564551.0              |
| test/episodes             | 405.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2273188735744722    |
| test_1/avg_q              | -20.639266207870346    |
| test_1/n_subgoals         | 2352.0                 |
| test_1/subgoal_succ_rate  | 0.8596938775510204     |
| train/episodes            | 2700.0                 |
| train/success_rate        | 0.59                   |
| train_0/avg_q             | -11.14511606492557     |
| train_0/current_q         | -5.686634249029374     |
| train_0/fw_bonus          | -0.9991734892129898    |
| train_0/fw_loss           | 0.00024499435858160723 |
| train_0/mu_grads          | -0.11786464080214501   |
| train_0/mu_grads_std      | 0.5111156851053238     |
| train_0/mu_loss           | 5.580751518734308      |
| train_0/next_q            | -5.44200549129869      |
| train_0/q_grads           | 0.033997421804815534   |
| train_0/q_grads_std       | 0.3543253667652607     |
| train_0/q_loss            | 0.6821145700852865     |
| train_0/reward            | -0.7317818978113791    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.04677734375          |
| train_0/target_q          | -5.64196968039015      |
| train_1/avg_q             | -17.420975203838836    |
| train_1/current_q         | -11.972063597286093    |
| train_1/fw_bonus          | -0.997358325123787     |
| train_1/fw_loss           | 0.0011406603298382834  |
| train_1/mu_grads          | -0.019193801423534752  |
| train_1/mu_grads_std      | 0.48134487569332124    |
| train_1/mu_loss           | 12.243662894493673     |
| train_1/n_subgoals        | 1869.0                 |
| train_1/next_q            | -11.94009338545454     |
| train_1/q_grads           | -0.03170314459130168   |
| train_1/q_grads_std       | 0.5969527557492256     |
| train_1/q_loss            | 4.922831280665865      |
| train_1/reward            | -2.142430402204991     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0154052734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24665596575708934    |
| train_1/target_q          | -12.063883782357365    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 27
Time for epoch 27: 5227.80. Rollout time: 2224.86, Training time: 3002.90
Evaluating epoch 27
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 27                     |
| policy/steps              | 1618162.0              |
| test/episodes             | 420.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.451421079067473     |
| test_1/avg_q              | -21.621137394554616    |
| test_1/n_subgoals         | 411.0                  |
| test_1/subgoal_succ_rate  | 0.014598540145985401   |
| train/episodes            | 2800.0                 |
| train/success_rate        | 0.54                   |
| train_0/avg_q             | -10.962838650875467    |
| train_0/current_q         | -5.848568255043795     |
| train_0/fw_bonus          | -0.9991813659667969    |
| train_0/fw_loss           | 0.00024269795903819613 |
| train_0/mu_grads          | -0.12083660867065191   |
| train_0/mu_grads_std      | 0.5227740466594696     |
| train_0/mu_loss           | 5.6603214172711915     |
| train_0/next_q            | -5.529792834955517     |
| train_0/q_grads           | 0.03364376872777939    |
| train_0/q_grads_std       | 0.35779488533735276    |
| train_0/q_loss            | 0.5725052360698133     |
| train_0/reward            | -0.7346220034669386    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.051318359375         |
| train_0/target_q          | -5.791798761851806     |
| train_1/avg_q             | -18.548155645219936    |
| train_1/current_q         | -12.294113268383454    |
| train_1/fw_bonus          | -0.997233709692955     |
| train_1/fw_loss           | 0.0011725704098353162  |
| train_1/mu_grads          | -0.019360588025301696  |
| train_1/mu_grads_std      | 0.4864337719976902     |
| train_1/mu_loss           | 12.587904124042666     |
| train_1/n_subgoals        | 1918.0                 |
| train_1/next_q            | -12.342599100415594    |
| train_1/q_grads           | -0.030967775080353022  |
| train_1/q_grads_std       | 0.6066362917423248     |
| train_1/q_loss            | 4.02066487167114       |
| train_1/reward            | -2.1287029560524386    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01474609375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.24191866527632952    |
| train_1/target_q          | -12.419850353929217    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 28
Time for epoch 28: 17054.45. Rollout time: 15791.87, Training time: 1262.51
Evaluating epoch 28
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 28                    |
| policy/steps              | 1669207.0             |
| test/episodes             | 435.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.366575920613348    |
| test_1/avg_q              | -21.071862571713243   |
| test_1/n_subgoals         | 2617.0                |
| test_1/subgoal_succ_rate  | 0.8781047000382117    |
| train/episodes            | 2900.0                |
| train/success_rate        | 0.63                  |
| train_0/avg_q             | -10.913494587290698   |
| train_0/current_q         | -5.638160350268552    |
| train_0/fw_bonus          | -0.9991886138916015   |
| train_0/fw_loss           | 0.0002405917282885639 |
| train_0/mu_grads          | -0.12272499259561301  |
| train_0/mu_grads_std      | 0.5296639934182167    |
| train_0/mu_loss           | 5.4397962919005325    |
| train_0/next_q            | -5.274918629420323    |
| train_0/q_grads           | 0.033786069694906475  |
| train_0/q_grads_std       | 0.36132290214300156   |
| train_0/q_loss            | 0.5422285854762573    |
| train_0/reward            | -0.7366379711700575   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.054833984375        |
| train_0/target_q          | -5.5453386709953465   |
| train_1/avg_q             | -17.811148052890633   |
| train_1/current_q         | -12.109599989227082   |
| train_1/fw_bonus          | -0.9971817463636399   |
| train_1/fw_loss           | 0.001185874137445353  |
| train_1/mu_grads          | -0.020463837031275033 |
| train_1/mu_grads_std      | 0.4935441642999649    |
| train_1/mu_loss           | 12.45696387195619     |
| train_1/n_subgoals        | 1806.0                |
| train_1/next_q            | -12.161955028470446   |
| train_1/q_grads           | -0.030860806303098797 |
| train_1/q_grads_std       | 0.6126566722989082    |
| train_1/q_loss            | 4.523751253441085     |
| train_1/reward            | -2.1561924085282955   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.013916015625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2646733111849391    |
| train_1/target_q          | -12.208638462773061   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 29
Time for epoch 29: 575.67. Rollout time: 326.65, Training time: 248.98
Evaluating epoch 29
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 29                    |
| policy/steps              | 1722528.0             |
| test/episodes             | 450.0                 |
| test/success_rate         | 0.13333333333333333   |
| test_0/avg_q              | -1.3650805408558129   |
| test_1/avg_q              | -20.203807705035302   |
| test_1/n_subgoals         | 5338.0                |
| test_1/subgoal_succ_rate  | 0.9630947920569501    |
| train/episodes            | 3000.0                |
| train/success_rate        | 0.56                  |
| train_0/avg_q             | -10.532911794901455   |
| train_0/current_q         | -5.527809083635031    |
| train_0/fw_bonus          | -0.9992684960365296   |
| train_0/fw_loss           | 0.0002173206659790594 |
| train_0/mu_grads          | -0.11993905492126941  |
| train_0/mu_grads_std      | 0.5341774702072144    |
| train_0/mu_loss           | 5.348259266253362     |
| train_0/next_q            | -5.198365720721371    |
| train_0/q_grads           | 0.034072289057075975  |
| train_0/q_grads_std       | 0.3665584474802017    |
| train_0/q_loss            | 0.5868553874817062    |
| train_0/reward            | -0.7403200518303492   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.055029296875        |
| train_0/target_q          | -5.460442429819943    |
| train_1/avg_q             | -18.169945838580205   |
| train_1/current_q         | -12.38196337536689    |
| train_1/fw_bonus          | -0.9975141108036041   |
| train_1/fw_loss           | 0.0011007711684214883 |
| train_1/mu_grads          | -0.020472039375454186 |
| train_1/mu_grads_std      | 0.49995988458395      |
| train_1/mu_loss           | 12.888924421193792    |
| train_1/n_subgoals        | 1937.0                |
| train_1/next_q            | -12.595963707008513   |
| train_1/q_grads           | -0.03064769241027534  |
| train_1/q_grads_std       | 0.6177944272756577    |
| train_1/q_loss            | 3.8514069699447675    |
| train_1/reward            | -2.134870469650559    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0148681640625       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.2710376871450697    |
| train_1/target_q          | -12.49176528151376    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 30
Time for epoch 30: 485.71. Rollout time: 268.01, Training time: 217.66
Evaluating epoch 30
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 30                     |
| policy/steps              | 1775027.0              |
| test/episodes             | 465.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.3255899825948882    |
| test_1/avg_q              | -17.584639587619783    |
| test_1/n_subgoals         | 712.0                  |
| test_1/subgoal_succ_rate  | 0.47331460674157305    |
| train/episodes            | 3100.0                 |
| train/success_rate        | 0.6                    |
| train_0/avg_q             | -9.892470120939144     |
| train_0/current_q         | -5.968072017051176     |
| train_0/fw_bonus          | -0.9993137031793594    |
| train_0/fw_loss           | 0.00020414918326423505 |
| train_0/mu_grads          | -0.11909419689327479   |
| train_0/mu_grads_std      | 0.5389314070343971     |
| train_0/mu_loss           | 5.8013949903117235     |
| train_0/next_q            | -5.655483337324815     |
| train_0/q_grads           | 0.03537684362381697    |
| train_0/q_grads_std       | 0.3735503025352955     |
| train_0/q_loss            | 0.6159389672987479     |
| train_0/reward            | -0.7383171951853       |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1218017578125        |
| train_0/target_q          | -5.899518640368067     |
| train_1/avg_q             | -17.86582123476574     |
| train_1/current_q         | -11.562148632237943    |
| train_1/fw_bonus          | -0.9972482830286026    |
| train_1/fw_loss           | 0.0011688366023008712  |
| train_1/mu_grads          | -0.020728250639513134  |
| train_1/mu_grads_std      | 0.5078249990940094     |
| train_1/mu_loss           | 11.755511668205141     |
| train_1/n_subgoals        | 1898.0                 |
| train_1/next_q            | -11.471041607525539    |
| train_1/q_grads           | -0.03206945275887847   |
| train_1/q_grads_std       | 0.6235743463039398     |
| train_1/q_loss            | 5.34146914295403       |
| train_1/reward            | -2.119954161363421     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01572265625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2528977871443625     |
| train_1/target_q          | -11.648239639948686    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_30.pkl ...
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 31
Time for epoch 31: 478.37. Rollout time: 261.35, Training time: 216.98
Evaluating epoch 31
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 31                     |
| policy/steps              | 1826290.0              |
| test/episodes             | 480.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.6375627014643976    |
| test_1/avg_q              | -20.910677371104953    |
| test_1/n_subgoals         | 1391.0                 |
| test_1/subgoal_succ_rate  | 0.7562904385334291     |
| train/episodes            | 3200.0                 |
| train/success_rate        | 0.55                   |
| train_0/avg_q             | -10.320846193194225    |
| train_0/current_q         | -6.032438072424415     |
| train_0/fw_bonus          | -0.9993203625082969    |
| train_0/fw_loss           | 0.00020220962614985182 |
| train_0/mu_grads          | -0.11980978045612574   |
| train_0/mu_grads_std      | 0.5459146037697792     |
| train_0/mu_loss           | 5.863922009399822      |
| train_0/next_q            | -5.69836358576715      |
| train_0/q_grads           | 0.03512223307043314    |
| train_0/q_grads_std       | 0.3763638541102409     |
| train_0/q_loss            | 0.6269493644831498     |
| train_0/reward            | -0.7452951780545846    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.113037109375         |
| train_0/target_q          | -5.968488745362624     |
| train_1/avg_q             | -16.172557080125344    |
| train_1/current_q         | -12.30592660410558     |
| train_1/fw_bonus          | -0.9972255498170852    |
| train_1/fw_loss           | 0.0011746575648430735  |
| train_1/mu_grads          | -0.021478342171758414  |
| train_1/mu_grads_std      | 0.5147315010428428     |
| train_1/mu_loss           | 12.481037976743831     |
| train_1/n_subgoals        | 1887.0                 |
| train_1/next_q            | -12.225817771718273    |
| train_1/q_grads           | -0.03246081303805113   |
| train_1/q_grads_std       | 0.6299325942993164     |
| train_1/q_loss            | 4.452890863385075      |
| train_1/reward            | -2.0962729400249374    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0155517578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3052464228934817     |
| train_1/target_q          | -12.377220430853207    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08333333333333333
Training epoch 32
Time for epoch 32: 481.17. Rollout time: 264.89, Training time: 216.23
Evaluating epoch 32
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 32                    |
| policy/steps              | 1878045.0             |
| test/episodes             | 495.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5841490461895933   |
| test_1/avg_q              | -10.69023068560486    |
| test_1/n_subgoals         | 2840.0                |
| test_1/subgoal_succ_rate  | 0.9017605633802817    |
| train/episodes            | 3300.0                |
| train/success_rate        | 0.65                  |
| train_0/avg_q             | -11.235225927780029   |
| train_0/current_q         | -6.088684839541904    |
| train_0/fw_bonus          | -0.9993438392877578   |
| train_0/fw_loss           | 0.0001953689512447454 |
| train_0/mu_grads          | -0.12122865989804268  |
| train_0/mu_grads_std      | 0.5515009358525276    |
| train_0/mu_loss           | 5.920229091306618     |
| train_0/next_q            | -5.771492723357747    |
| train_0/q_grads           | 0.035276923701167105  |
| train_0/q_grads_std       | 0.3786663725972176    |
| train_0/q_loss            | 0.7757620887972069    |
| train_0/reward            | -0.7529182362435677   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.099658203125        |
| train_0/target_q          | -5.967705172047263    |
| train_1/avg_q             | -17.364038669026076   |
| train_1/current_q         | -9.743230086648344    |
| train_1/fw_bonus          | -0.9974437251687049   |
| train_1/fw_loss           | 0.0011187942989636212 |
| train_1/mu_grads          | -0.02327741663902998  |
| train_1/mu_grads_std      | 0.5196453481912613    |
| train_1/mu_loss           | 9.629455210200735     |
| train_1/n_subgoals        | 1873.0                |
| train_1/next_q            | -9.391656816645161    |
| train_1/q_grads           | -0.03425712306052446  |
| train_1/q_grads_std       | 0.6351699590682983    |
| train_1/q_loss            | 6.204841523194537     |
| train_1/reward            | -2.137782561017957    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0151611328125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.29257875066737854   |
| train_1/target_q          | -9.86961361599611     |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08333333333333333
Training epoch 33
Time for epoch 33: 470.75. Rollout time: 251.95, Training time: 218.76
Evaluating epoch 33
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 33                    |
| policy/steps              | 1927384.0             |
| test/episodes             | 510.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.4564759491174426   |
| test_1/avg_q              | -3.839231897390377    |
| test_1/n_subgoals         | 1892.0                |
| test_1/subgoal_succ_rate  | 0.821353065539112     |
| train/episodes            | 3400.0                |
| train/success_rate        | 0.65                  |
| train_0/avg_q             | -10.039984258290273   |
| train_0/current_q         | -4.868603731402575    |
| train_0/fw_bonus          | -0.9993792071938514   |
| train_0/fw_loss           | 0.0001850701308285352 |
| train_0/mu_grads          | -0.12009416371583939  |
| train_0/mu_grads_std      | 0.555114072561264     |
| train_0/mu_loss           | 4.636564376407892     |
| train_0/next_q            | -4.497787575823477    |
| train_0/q_grads           | 0.03485381016507745   |
| train_0/q_grads_std       | 0.38086883798241616   |
| train_0/q_loss            | 0.6701214702626224    |
| train_0/reward            | -0.7600681878666364   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1103271484375       |
| train_0/target_q          | -4.8140432254319      |
| train_1/avg_q             | -15.646292903048286   |
| train_1/current_q         | -11.03985692035883    |
| train_1/fw_bonus          | -0.9972413256764412   |
| train_1/fw_loss           | 0.001170617903699167  |
| train_1/mu_grads          | -0.02431769813410938  |
| train_1/mu_grads_std      | 0.5251293987035751    |
| train_1/mu_loss           | 10.866683507696797    |
| train_1/n_subgoals        | 1906.0                |
| train_1/next_q            | -10.711767858070655   |
| train_1/q_grads           | -0.03389971889555454  |
| train_1/q_grads_std       | 0.6443156152963638    |
| train_1/q_loss            | 6.356647227025521     |
| train_1/reward            | -2.037701445669518    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0162841796875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.36621196222455404   |
| train_1/target_q          | -11.083159956312269   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 34
Time for epoch 34: 454.06. Rollout time: 252.98, Training time: 201.04
Evaluating epoch 34
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 34                     |
| policy/steps              | 1979271.0              |
| test/episodes             | 525.0                  |
| test/success_rate         | 0.3333333333333333     |
| test_0/avg_q              | -1.2205143178865019    |
| test_1/avg_q              | -16.361005668851632    |
| test_1/n_subgoals         | 985.0                  |
| test_1/subgoal_succ_rate  | 0.6700507614213198     |
| train/episodes            | 3500.0                 |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -9.205068078778204     |
| train_0/current_q         | -5.1199447184859395    |
| train_0/fw_bonus          | -0.9993917614221572    |
| train_0/fw_loss           | 0.00018141016407753342 |
| train_0/mu_grads          | -0.12266956865787507   |
| train_0/mu_grads_std      | 0.5612363219261169     |
| train_0/mu_loss           | 4.951078931462985      |
| train_0/next_q            | -4.795053914152879     |
| train_0/q_grads           | 0.03451059833168983    |
| train_0/q_grads_std       | 0.3864032723009586     |
| train_0/q_loss            | 0.5803215544241093     |
| train_0/reward            | -0.7597234285985905    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1248046875           |
| train_0/target_q          | -5.14157545511967      |
| train_1/avg_q             | -14.558302885492875    |
| train_1/current_q         | -11.462682969591606    |
| train_1/fw_bonus          | -0.9968903809785843    |
| train_1/fw_loss           | 0.0012604806339368223  |
| train_1/mu_grads          | -0.02321722833439708   |
| train_1/mu_grads_std      | 0.5317878112196922     |
| train_1/mu_loss           | 11.470965915839535     |
| train_1/n_subgoals        | 1963.0                 |
| train_1/next_q            | -11.216757618844978    |
| train_1/q_grads           | -0.035481659974902865  |
| train_1/q_grads_std       | 0.6528169602155686     |
| train_1/q_loss            | 5.057578122372251      |
| train_1/reward            | -2.065427427839313     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016162109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2913907284768212     |
| train_1/target_q          | -11.556255862738315    |
------------------------------------------------------
New best value for test/success_rate: 0.3333333333333333. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.09999999999999999
Training epoch 35
Time for epoch 35: 452.12. Rollout time: 236.18, Training time: 215.90
Evaluating epoch 35
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 35                     |
| policy/steps              | 2028078.0              |
| test/episodes             | 540.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2942969306639611    |
| test_1/avg_q              | -19.311682811674505    |
| test_1/n_subgoals         | 412.0                  |
| test_1/subgoal_succ_rate  | 0.01699029126213592    |
| train/episodes            | 3600.0                 |
| train/success_rate        | 0.67                   |
| train_0/avg_q             | -10.4614336452323      |
| train_0/current_q         | -5.434138004302025     |
| train_0/fw_bonus          | -0.9994102597236634    |
| train_0/fw_loss           | 0.00017602386324142572 |
| train_0/mu_grads          | -0.12427438162267208   |
| train_0/mu_grads_std      | 0.5656404003500939     |
| train_0/mu_loss           | 5.2518695310477455     |
| train_0/next_q            | -5.10761130554318      |
| train_0/q_grads           | 0.03463221695274114    |
| train_0/q_grads_std       | 0.388493524491787      |
| train_0/q_loss            | 0.602181384624229      |
| train_0/reward            | -0.7609914786902664    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1398193359375        |
| train_0/target_q          | -5.409513082221816     |
| train_1/avg_q             | -15.803717743352564    |
| train_1/current_q         | -11.75455061193819     |
| train_1/fw_bonus          | -0.9970059096813202    |
| train_1/fw_loss           | 0.0012308969016885385  |
| train_1/mu_grads          | -0.02448495673015714   |
| train_1/mu_grads_std      | 0.537820503115654      |
| train_1/mu_loss           | 11.773841226843235     |
| train_1/n_subgoals        | 1697.0                 |
| train_1/next_q            | -11.54851924387105     |
| train_1/q_grads           | -0.036454565823078156  |
| train_1/q_grads_std       | 0.6595279470086097     |
| train_1/q_loss            | 4.189987568877354      |
| train_1/reward            | -2.0642295058631133    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0171630859375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2498526812021214     |
| train_1/target_q          | -11.840924807229488    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08333333333333333
Training epoch 36
Time for epoch 36: 496.80. Rollout time: 280.82, Training time: 215.93
Evaluating epoch 36
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 36                     |
| policy/steps              | 2082483.0              |
| test/episodes             | 555.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3576870933318488    |
| test_1/avg_q              | -19.655292485210826    |
| test_1/n_subgoals         | 3665.0                 |
| test_1/subgoal_succ_rate  | 0.9236016371077762     |
| train/episodes            | 3700.0                 |
| train/success_rate        | 0.59                   |
| train_0/avg_q             | -8.908846022482438     |
| train_0/current_q         | -5.583921977012628     |
| train_0/fw_bonus          | -0.9994122162461281    |
| train_0/fw_loss           | 0.00017545046503073536 |
| train_0/mu_grads          | -0.11711245253682137   |
| train_0/mu_grads_std      | 0.5724416300654411     |
| train_0/mu_loss           | 5.379229639569002      |
| train_0/next_q            | -5.231318108899022     |
| train_0/q_grads           | 0.03583679171279073    |
| train_0/q_grads_std       | 0.39315278753638266    |
| train_0/q_loss            | 0.6189743193909514     |
| train_0/reward            | -0.7598017852200428    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.119921875            |
| train_0/target_q          | -5.510909790810016     |
| train_1/avg_q             | -17.99793987710906     |
| train_1/current_q         | -11.587849376590132    |
| train_1/fw_bonus          | -0.9967714935541153    |
| train_1/fw_loss           | 0.001290917315054685   |
| train_1/mu_grads          | -0.025658115278929472  |
| train_1/mu_grads_std      | 0.5462224677205085     |
| train_1/mu_loss           | 11.610623875458078     |
| train_1/n_subgoals        | 1861.0                 |
| train_1/next_q            | -11.36546299847227     |
| train_1/q_grads           | -0.038103175535798076  |
| train_1/q_grads_std       | 0.6665529131889343     |
| train_1/q_loss            | 4.893049712050722      |
| train_1/reward            | -2.074260013584717     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.015283203125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1826974744760881     |
| train_1/target_q          | -11.679644037884097    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08333333333333333
Training epoch 37
Time for epoch 37: 399.96. Rollout time: 183.68, Training time: 216.24
Evaluating epoch 37
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 37                     |
| policy/steps              | 2121846.0              |
| test/episodes             | 570.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.5517941061818306    |
| test_1/avg_q              | -19.598375242637953    |
| test_1/n_subgoals         | 5010.0                 |
| test_1/subgoal_succ_rate  | 0.9590818363273453     |
| train/episodes            | 3800.0                 |
| train/success_rate        | 0.88                   |
| train_0/avg_q             | -9.184691913025027     |
| train_0/current_q         | -5.792643729109019     |
| train_0/fw_bonus          | -0.9993375897407532    |
| train_0/fw_loss           | 0.00019719021001947113 |
| train_0/mu_grads          | -0.11704651024192572   |
| train_0/mu_grads_std      | 0.5761341139674186     |
| train_0/mu_loss           | 5.616318956432464      |
| train_0/next_q            | -5.447694915388677     |
| train_0/q_grads           | 0.03642156021669507    |
| train_0/q_grads_std       | 0.39616227298974993    |
| train_0/q_loss            | 0.6477066083049718     |
| train_0/reward            | -0.7572379621968139    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.088916015625         |
| train_0/target_q          | -5.7014489585281805    |
| train_1/avg_q             | -15.921358438007713    |
| train_1/current_q         | -7.382376870122991     |
| train_1/fw_bonus          | -0.9970454797148705    |
| train_1/fw_loss           | 0.0012207663647131994  |
| train_1/mu_grads          | -0.026505589392036198  |
| train_1/mu_grads_std      | 0.5546435818076134     |
| train_1/mu_loss           | 7.036286050669721      |
| train_1/n_subgoals        | 1447.0                 |
| train_1/next_q            | -6.773917814925251     |
| train_1/q_grads           | -0.040369321778416636  |
| train_1/q_grads_std       | 0.6742425248026848     |
| train_1/q_loss            | 4.169855174382336      |
| train_1/reward            | -2.1115904710470206    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0153564453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36281962681409813    |
| train_1/target_q          | -7.5689362116789       |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.09999999999999999
Training epoch 38
Time for epoch 38: 470.14. Rollout time: 204.10, Training time: 265.99
Evaluating epoch 38
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 38                    |
| policy/steps              | 2156873.0             |
| test/episodes             | 585.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.406423112693257    |
| test_1/avg_q              | -16.864767763176992   |
| test_1/n_subgoals         | 642.0                 |
| test_1/subgoal_succ_rate  | 0.38317757009345793   |
| train/episodes            | 3900.0                |
| train/success_rate        | 0.92                  |
| train_0/avg_q             | -9.98361376181749     |
| train_0/current_q         | -5.800425302248245    |
| train_0/fw_bonus          | -0.9993091136217117   |
| train_0/fw_loss           | 0.0002054860186035512 |
| train_0/mu_grads          | -0.11875687334686517  |
| train_0/mu_grads_std      | 0.5802616670727729    |
| train_0/mu_loss           | 5.590998196173096     |
| train_0/next_q            | -5.447027148836425    |
| train_0/q_grads           | 0.037246950808912514  |
| train_0/q_grads_std       | 0.40145034715533257   |
| train_0/q_loss            | 0.620838771822169     |
| train_0/reward            | -0.7607098466982279   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1001953125          |
| train_0/target_q          | -5.723849544191865    |
| train_1/avg_q             | -16.73160809241857    |
| train_1/current_q         | -11.3395915446385     |
| train_1/fw_bonus          | -0.9973708763718605   |
| train_1/fw_loss           | 0.0011374467678251677 |
| train_1/mu_grads          | -0.029137745825573803 |
| train_1/mu_grads_std      | 0.5595376089215278    |
| train_1/mu_loss           | 11.5176699750488      |
| train_1/n_subgoals        | 1240.0                |
| train_1/next_q            | -11.222651984673622   |
| train_1/q_grads           | -0.03998582186177373  |
| train_1/q_grads_std       | 0.6825315564870834    |
| train_1/q_loss            | 4.496288391392566     |
| train_1/reward            | -2.0170246045210662   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.016064453125        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.36693548387096775   |
| train_1/target_q          | -11.44581908861436    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 39
Time for epoch 39: 395.35. Rollout time: 167.74, Training time: 227.56
Evaluating epoch 39
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 39                     |
| policy/steps              | 2190707.0              |
| test/episodes             | 600.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5849324161177578    |
| test_1/avg_q              | -18.826410982685967    |
| test_1/n_subgoals         | 3146.0                 |
| test_1/subgoal_succ_rate  | 0.9059122695486331     |
| train/episodes            | 4000.0                 |
| train/success_rate        | 0.94                   |
| train_0/avg_q             | -9.21863805584516      |
| train_0/current_q         | -5.7659923895812355    |
| train_0/fw_bonus          | -0.9993208408355713    |
| train_0/fw_loss           | 0.00020206941335345618 |
| train_0/mu_grads          | -0.12178519424051046   |
| train_0/mu_grads_std      | 0.5842639282345772     |
| train_0/mu_loss           | 5.579276838691024      |
| train_0/next_q            | -5.439619436249937     |
| train_0/q_grads           | 0.03843189431354403    |
| train_0/q_grads_std       | 0.4059750892221928     |
| train_0/q_loss            | 0.6613896679452028     |
| train_0/reward            | -0.7584605815933173    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1428955078125        |
| train_0/target_q          | -5.706901331420198     |
| train_1/avg_q             | -15.661293414679568    |
| train_1/current_q         | -11.097766959489656    |
| train_1/fw_bonus          | -0.9973599210381507    |
| train_1/fw_loss           | 0.0011402518764953129  |
| train_1/mu_grads          | -0.030237951362505556  |
| train_1/mu_grads_std      | 0.565511517226696      |
| train_1/mu_loss           | 11.319093943336958     |
| train_1/n_subgoals        | 1173.0                 |
| train_1/next_q            | -10.955188494525705    |
| train_1/q_grads           | -0.04023727662861347   |
| train_1/q_grads_std       | 0.6908610194921494     |
| train_1/q_loss            | 4.434688354720737      |
| train_1/reward            | -2.0116751857338384    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0148193359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.38192668371696503    |
| train_1/target_q          | -11.189969729358408    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 40
Time for epoch 40: 413.75. Rollout time: 179.47, Training time: 234.24
Evaluating epoch 40
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 40                     |
| policy/steps              | 2227431.0              |
| test/episodes             | 615.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.511022416151157     |
| test_1/avg_q              | -17.584277203350375    |
| test_1/n_subgoals         | 1739.0                 |
| test_1/subgoal_succ_rate  | 0.79700977573318       |
| train/episodes            | 4100.0                 |
| train/success_rate        | 0.9                    |
| train_0/avg_q             | -9.62695479118004      |
| train_0/current_q         | -5.925531135929999     |
| train_0/fw_bonus          | -0.9992920652031898    |
| train_0/fw_loss           | 0.00021045237590442412 |
| train_0/mu_grads          | -0.125215382874012     |
| train_0/mu_grads_std      | 0.590684960782528      |
| train_0/mu_loss           | 5.742827021882731      |
| train_0/next_q            | -5.580853575921436     |
| train_0/q_grads           | 0.038882833626121285   |
| train_0/q_grads_std       | 0.41141979545354845    |
| train_0/q_loss            | 0.6527300440151432     |
| train_0/reward            | -0.7620239440169826    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.109814453125         |
| train_0/target_q          | -5.856045320680681     |
| train_1/avg_q             | -15.48855884827203     |
| train_1/current_q         | -9.742844583911461     |
| train_1/fw_bonus          | -0.9973168119788169    |
| train_1/fw_loss           | 0.0011512941549881362  |
| train_1/mu_grads          | -0.031241601891815664  |
| train_1/mu_grads_std      | 0.5701338320970535     |
| train_1/mu_loss           | 9.801111064779409      |
| train_1/n_subgoals        | 1347.0                 |
| train_1/next_q            | -9.487628751863326     |
| train_1/q_grads           | -0.04008519286289811   |
| train_1/q_grads_std       | 0.6998746812343597     |
| train_1/q_loss            | 6.920895580683509      |
| train_1/reward            | -1.9878606918562582    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016796875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.40089086859688194    |
| train_1/target_q          | -9.922435130396634     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_40.pkl ...
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 41
Time for epoch 41: 469.24. Rollout time: 220.53, Training time: 248.66
Evaluating epoch 41
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 41                     |
| policy/steps              | 2266305.0              |
| test/episodes             | 630.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5034123289112937    |
| test_1/avg_q              | -20.249666065507117    |
| test_1/n_subgoals         | 5854.0                 |
| test_1/subgoal_succ_rate  | 0.9668602664844551     |
| train/episodes            | 4200.0                 |
| train/success_rate        | 0.84                   |
| train_0/avg_q             | -10.002892251906909    |
| train_0/current_q         | -5.807296665087473     |
| train_0/fw_bonus          | -0.9992500022053719    |
| train_0/fw_loss           | 0.00022270224035310094 |
| train_0/mu_grads          | -0.1294953290373087    |
| train_0/mu_grads_std      | 0.5962462529540062     |
| train_0/mu_loss           | 5.63480608182478       |
| train_0/next_q            | -5.47277376172246      |
| train_0/q_grads           | 0.03907440500333905    |
| train_0/q_grads_std       | 0.4163158908486366     |
| train_0/q_loss            | 0.7149444606265574     |
| train_0/reward            | -0.7569597202691511    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11552734375          |
| train_0/target_q          | -5.757321800516129     |
| train_1/avg_q             | -15.089009449574199    |
| train_1/current_q         | -6.48537687557558      |
| train_1/fw_bonus          | -0.9970129385590554    |
| train_1/fw_loss           | 0.0012290976621443406  |
| train_1/mu_grads          | -0.029107661312446     |
| train_1/mu_grads_std      | 0.5752978071570396     |
| train_1/mu_loss           | 6.219693423923699      |
| train_1/n_subgoals        | 1431.0                 |
| train_1/next_q            | -5.813982878670167     |
| train_1/q_grads           | -0.04366519898176193   |
| train_1/q_grads_std       | 0.7061346039175987     |
| train_1/q_loss            | 3.9773293282145543     |
| train_1/reward            | -2.009665831974053     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0160400390625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.38714185883997204    |
| train_1/target_q          | -6.711685673708277     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 42
Time for epoch 42: 526.71. Rollout time: 285.67, Training time: 240.98
Evaluating epoch 42
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 42                     |
| policy/steps              | 2317824.0              |
| test/episodes             | 645.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.4180636265248538    |
| test_1/avg_q              | -19.577971932645596    |
| test_1/n_subgoals         | 2956.0                 |
| test_1/subgoal_succ_rate  | 0.8978349120433018     |
| train/episodes            | 4300.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -11.110992740073979    |
| train_0/current_q         | -5.903532805244258     |
| train_0/fw_bonus          | -0.9993016362190247    |
| train_0/fw_loss           | 0.00020766213165188674 |
| train_0/mu_grads          | -0.1326713476330042    |
| train_0/mu_grads_std      | 0.6010535418987274     |
| train_0/mu_loss           | 5.718809572794261      |
| train_0/next_q            | -5.549729366788274     |
| train_0/q_grads           | 0.039122072979807854   |
| train_0/q_grads_std       | 0.42049726098775864    |
| train_0/q_loss            | 0.6920135236110768     |
| train_0/reward            | -0.7559289266107954    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1206298828125        |
| train_0/target_q          | -5.805177192399244     |
| train_1/avg_q             | -17.247603075189176    |
| train_1/current_q         | -10.436103100716924    |
| train_1/fw_bonus          | -0.9969365537166596    |
| train_1/fw_loss           | 0.0012486564752180128  |
| train_1/mu_grads          | -0.03086395082063973   |
| train_1/mu_grads_std      | 0.5776571422815323     |
| train_1/mu_loss           | 10.644416079279537     |
| train_1/n_subgoals        | 1982.0                 |
| train_1/next_q            | -10.26012618942298     |
| train_1/q_grads           | -0.04296533232554793   |
| train_1/q_grads_std       | 0.71290063560009       |
| train_1/q_loss            | 5.099091148551638      |
| train_1/reward            | -1.995565925036135     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0154296875           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.34611503531786075    |
| train_1/target_q          | -10.515775776590049    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 43
Time for epoch 43: 449.17. Rollout time: 229.30, Training time: 219.83
Evaluating epoch 43
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 43                     |
| policy/steps              | 2363694.0              |
| test/episodes             | 660.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.418355757305233     |
| test_1/avg_q              | -20.33842124796181     |
| test_1/n_subgoals         | 7275.0                 |
| test_1/subgoal_succ_rate  | 0.980893470790378      |
| train/episodes            | 4400.0                 |
| train/success_rate        | 0.67                   |
| train_0/avg_q             | -10.190868820438052    |
| train_0/current_q         | -5.6939508642308585    |
| train_0/fw_bonus          | -0.9992961719632149    |
| train_0/fw_loss           | 0.00020925764547428117 |
| train_0/mu_grads          | -0.1317530743777752    |
| train_0/mu_grads_std      | 0.6038240164518356     |
| train_0/mu_loss           | 5.513597452787456      |
| train_0/next_q            | -5.3413027058088565    |
| train_0/q_grads           | 0.03929140605032444    |
| train_0/q_grads_std       | 0.4249413512647152     |
| train_0/q_loss            | 0.6157360309419981     |
| train_0/reward            | -0.757923406874761     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1276611328125        |
| train_0/target_q          | -5.6375444754480615    |
| train_1/avg_q             | -16.13220275068176     |
| train_1/current_q         | -6.4130183386131545    |
| train_1/fw_bonus          | -0.9973977670073509    |
| train_1/fw_loss           | 0.0011305599997285753  |
| train_1/mu_grads          | -0.03283330388367176   |
| train_1/mu_grads_std      | 0.5817766502499581     |
| train_1/mu_loss           | 6.175428948556427      |
| train_1/n_subgoals        | 1730.0                 |
| train_1/next_q            | -5.738069200327807     |
| train_1/q_grads           | -0.04477628841996193   |
| train_1/q_grads_std       | 0.7183203771710396     |
| train_1/q_loss            | 4.691652901900728      |
| train_1/reward            | -1.9435511027288157    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01572265625          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3739884393063584     |
| train_1/target_q          | -6.6590817654287005    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 44
Time for epoch 44: 473.29. Rollout time: 257.40, Training time: 215.84
Evaluating epoch 44
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 44                     |
| policy/steps              | 2417226.0              |
| test/episodes             | 675.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.205705328480117     |
| test_1/avg_q              | -19.771103791714065    |
| test_1/n_subgoals         | 2941.0                 |
| test_1/subgoal_succ_rate  | 0.8952737164229854     |
| train/episodes            | 4500.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -10.301241336449063    |
| train_0/current_q         | -5.000660044644412     |
| train_0/fw_bonus          | -0.9992997035384178    |
| train_0/fw_loss           | 0.00020822820406465325 |
| train_0/mu_grads          | -0.1370839424431324    |
| train_0/mu_grads_std      | 0.6120237514376641     |
| train_0/mu_loss           | 4.824481006793365      |
| train_0/next_q            | -4.6614624977731856    |
| train_0/q_grads           | 0.04031022172421217    |
| train_0/q_grads_std       | 0.4301451168954372     |
| train_0/q_loss            | 0.571126879228522      |
| train_0/reward            | -0.7572834213344322    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1330810546875        |
| train_0/target_q          | -5.010465137363895     |
| train_1/avg_q             | -15.707053257379606    |
| train_1/current_q         | -10.268356269841686    |
| train_1/fw_bonus          | -0.9972124695777893    |
| train_1/fw_loss           | 0.001178009220166132   |
| train_1/mu_grads          | -0.03570572221651673   |
| train_1/mu_grads_std      | 0.5827415183186531     |
| train_1/mu_loss           | 10.374415328858149     |
| train_1/n_subgoals        | 2115.0                 |
| train_1/next_q            | -10.007275100640763    |
| train_1/q_grads           | -0.046013740729540585  |
| train_1/q_grads_std       | 0.7201139315962791     |
| train_1/q_loss            | 5.165469012289465      |
| train_1/reward            | -1.897563611989608     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01591796875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.366903073286052      |
| train_1/target_q          | -10.36602685418581     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 45
Time for epoch 45: 476.06. Rollout time: 237.71, Training time: 238.31
Evaluating epoch 45
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 45                     |
| policy/steps              | 2463513.0              |
| test/episodes             | 690.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.502733875809088     |
| test_1/avg_q              | -20.65796988433966     |
| test_1/n_subgoals         | 6576.0                 |
| test_1/subgoal_succ_rate  | 0.9767335766423357     |
| train/episodes            | 4600.0                 |
| train/success_rate        | 0.73                   |
| train_0/avg_q             | -10.845278062601372    |
| train_0/current_q         | -5.696283783464709     |
| train_0/fw_bonus          | -0.9992844864726067    |
| train_0/fw_loss           | 0.00021265669347485526 |
| train_0/mu_grads          | -0.13623488694429398   |
| train_0/mu_grads_std      | 0.615174874663353      |
| train_0/mu_loss           | 5.517488709131598      |
| train_0/next_q            | -5.360955440071047     |
| train_0/q_grads           | 0.041390274185687304   |
| train_0/q_grads_std       | 0.4347297020256519     |
| train_0/q_loss            | 0.6608225375180542     |
| train_0/reward            | -0.7573711734996322    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.110888671875         |
| train_0/target_q          | -5.633561501745153     |
| train_1/avg_q             | -15.461933413933458    |
| train_1/current_q         | -10.575610122765404    |
| train_1/fw_bonus          | -0.9977030113339425    |
| train_1/fw_loss           | 0.0010524029887164943  |
| train_1/mu_grads          | -0.03702027527615428   |
| train_1/mu_grads_std      | 0.5876550793647766     |
| train_1/mu_loss           | 10.807175784481888     |
| train_1/n_subgoals        | 1742.0                 |
| train_1/next_q            | -10.377270614952185    |
| train_1/q_grads           | -0.045451572723686696  |
| train_1/q_grads_std       | 0.7262805238366127     |
| train_1/q_loss            | 4.844902447613315      |
| train_1/reward            | -1.874138887839581     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0162353515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3668197474167623     |
| train_1/target_q          | -10.686220226982108    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 46
Time for epoch 46: 458.18. Rollout time: 252.34, Training time: 205.79
Evaluating epoch 46
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 46                     |
| policy/steps              | 2514612.0              |
| test/episodes             | 705.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.4104448330565194    |
| test_1/avg_q              | -15.023975873076665    |
| test_1/n_subgoals         | 8871.0                 |
| test_1/subgoal_succ_rate  | 0.9925600270544471     |
| train/episodes            | 4700.0                 |
| train/success_rate        | 0.59                   |
| train_0/avg_q             | -11.449949932094642    |
| train_0/current_q         | -5.819022468680474     |
| train_0/fw_bonus          | -0.9992698296904564    |
| train_0/fw_loss           | 0.00021693334201700054 |
| train_0/mu_grads          | -0.13794461637735367   |
| train_0/mu_grads_std      | 0.6202160120010376     |
| train_0/mu_loss           | 5.637810243272118      |
| train_0/next_q            | -5.469995353824774     |
| train_0/q_grads           | 0.04154064022004604    |
| train_0/q_grads_std       | 0.4391030497848988     |
| train_0/q_loss            | 0.6646914610810704     |
| train_0/reward            | -0.763648020693654     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1203125              |
| train_0/target_q          | -5.753710408536457     |
| train_1/avg_q             | -16.387297824121887    |
| train_1/current_q         | -10.2946180495634      |
| train_1/fw_bonus          | -0.9977481901645661    |
| train_1/fw_loss           | 0.00104083287587855    |
| train_1/mu_grads          | -0.03713870607316494   |
| train_1/mu_grads_std      | 0.5930207163095474     |
| train_1/mu_loss           | 10.384150420434796     |
| train_1/n_subgoals        | 1948.0                 |
| train_1/next_q            | -10.084391792125547    |
| train_1/q_grads           | -0.04521855777129531   |
| train_1/q_grads_std       | 0.7333093956112862     |
| train_1/q_loss            | 5.717475557539322      |
| train_1/reward            | -1.8563340215067001    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016748046875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3475359342915811     |
| train_1/target_q          | -10.429758138087843    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 47
Time for epoch 47: 491.15. Rollout time: 267.11, Training time: 223.99
Evaluating epoch 47
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 47                    |
| policy/steps              | 2566502.0             |
| test/episodes             | 720.0                 |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5020298970208015   |
| test_1/avg_q              | -14.600237825751881   |
| test_1/n_subgoals         | 1022.0                |
| test_1/subgoal_succ_rate  | 0.6301369863013698    |
| train/episodes            | 4800.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -10.567772332812723   |
| train_0/current_q         | -5.901550088667913    |
| train_0/fw_bonus          | -0.9992656111717224   |
| train_0/fw_loss           | 0.0002181590472901007 |
| train_0/mu_grads          | -0.13773312084376813  |
| train_0/mu_grads_std      | 0.6256759509444236    |
| train_0/mu_loss           | 5.699179204222635     |
| train_0/next_q            | -5.53734445549693     |
| train_0/q_grads           | 0.04096359945833683   |
| train_0/q_grads_std       | 0.4420701563358307    |
| train_0/q_loss            | 0.641635902391577     |
| train_0/reward            | -0.7672175255476759   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.10546875            |
| train_0/target_q          | -5.829942487964452    |
| train_1/avg_q             | -15.517121383395926   |
| train_1/current_q         | -11.419990185650164   |
| train_1/fw_bonus          | -0.9976639688014984   |
| train_1/fw_loss           | 0.001062398630892858  |
| train_1/mu_grads          | -0.03917615246027708  |
| train_1/mu_grads_std      | 0.5994698658585549    |
| train_1/mu_loss           | 11.65326790604483     |
| train_1/n_subgoals        | 1972.0                |
| train_1/next_q            | -11.371144328766238   |
| train_1/q_grads           | -0.04551276676356793  |
| train_1/q_grads_std       | 0.7420717939734459    |
| train_1/q_loss            | 4.862976898256388     |
| train_1/reward            | -1.9178730252056995   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01728515625         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3407707910750507    |
| train_1/target_q          | -11.53865706242552    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 48
Time for epoch 48: 497.79. Rollout time: 272.25, Training time: 225.50
Evaluating epoch 48
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 48                     |
| policy/steps              | 2618258.0              |
| test/episodes             | 735.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.3102395595105607    |
| test_1/avg_q              | -20.597425975195186    |
| test_1/n_subgoals         | 1946.0                 |
| test_1/subgoal_succ_rate  | 0.8252826310380267     |
| train/episodes            | 4900.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -10.264309395219486    |
| train_0/current_q         | -5.909662122791856     |
| train_0/fw_bonus          | -0.9993527084589005    |
| train_0/fw_loss           | 0.00019278542677056976 |
| train_0/mu_grads          | -0.1419420775026083    |
| train_0/mu_grads_std      | 0.6300473004579544     |
| train_0/mu_loss           | 5.7245435379043546     |
| train_0/next_q            | -5.557170173226213     |
| train_0/q_grads           | 0.041822667606174944   |
| train_0/q_grads_std       | 0.44621395468711855    |
| train_0/q_loss            | 0.676932629186702      |
| train_0/reward            | -0.7726409124854399    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1373291015625        |
| train_0/target_q          | -5.846634233531445     |
| train_1/avg_q             | -15.431528231897476    |
| train_1/current_q         | -12.10887295134565     |
| train_1/fw_bonus          | -0.9974697709083558    |
| train_1/fw_loss           | 0.001112122758058831   |
| train_1/mu_grads          | -0.039921235851943494  |
| train_1/mu_grads_std      | 0.6055643126368523     |
| train_1/mu_loss           | 12.394823052037516     |
| train_1/n_subgoals        | 1975.0                 |
| train_1/next_q            | -12.093580347037197    |
| train_1/q_grads           | -0.04602460041642189   |
| train_1/q_grads_std       | 0.7481873407959938     |
| train_1/q_loss            | 4.4246070740113606     |
| train_1/reward            | -1.9402548947349714    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0163330078125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3367088607594937     |
| train_1/target_q          | -12.237585555522573    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 49
Time for epoch 49: 518.60. Rollout time: 293.05, Training time: 225.51
Evaluating epoch 49
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 49                     |
| policy/steps              | 2672667.0              |
| test/episodes             | 750.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.2733370540350337    |
| test_1/avg_q              | -18.66689783055329     |
| test_1/n_subgoals         | 7234.0                 |
| test_1/subgoal_succ_rate  | 0.9813381255183854     |
| train/episodes            | 5000.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -10.612430533808448    |
| train_0/current_q         | -5.35878369347549      |
| train_0/fw_bonus          | -0.9993660122156143    |
| train_0/fw_loss           | 0.00018890930114139336 |
| train_0/mu_grads          | -0.1442372977733612    |
| train_0/mu_grads_std      | 0.6314284324645996     |
| train_0/mu_loss           | 5.138832408995872      |
| train_0/next_q            | -4.9475038731554495    |
| train_0/q_grads           | 0.042237617447972296   |
| train_0/q_grads_std       | 0.44985884577035906    |
| train_0/q_loss            | 0.6408711640180584     |
| train_0/reward            | -0.7720766118931351    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1774658203125        |
| train_0/target_q          | -5.266905088312944     |
| train_1/avg_q             | -16.034372147032762    |
| train_1/current_q         | -12.241877323394798    |
| train_1/fw_bonus          | -0.9976858720183372    |
| train_1/fw_loss           | 0.0010567914679995738  |
| train_1/mu_grads          | -0.041266877111047505  |
| train_1/mu_grads_std      | 0.611776314675808      |
| train_1/mu_loss           | 12.443819507350687     |
| train_1/n_subgoals        | 2026.0                 |
| train_1/next_q            | -12.19759030811504     |
| train_1/q_grads           | -0.046137324161827566  |
| train_1/q_grads_std       | 0.7533573895692826     |
| train_1/q_loss            | 4.1183561398299515     |
| train_1/reward            | -1.9894178042861312    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0162841796875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3139190523198421     |
| train_1/target_q          | -12.339137042554025    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 50
Time for epoch 50: 501.28. Rollout time: 273.21, Training time: 228.01
Evaluating epoch 50
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 50                     |
| policy/steps              | 2723863.0              |
| test/episodes             | 765.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.176058849301102     |
| test_1/avg_q              | -19.946433501685682    |
| test_1/n_subgoals         | 3588.0                 |
| test_1/subgoal_succ_rate  | 0.9289297658862876     |
| train/episodes            | 5100.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -10.064958277108648    |
| train_0/current_q         | -5.986772433806236     |
| train_0/fw_bonus          | -0.9993940681219101    |
| train_0/fw_loss           | 0.00018073508726956788 |
| train_0/mu_grads          | -0.14503743313252926   |
| train_0/mu_grads_std      | 0.6353892609477043     |
| train_0/mu_loss           | 5.771074909943527      |
| train_0/next_q            | -5.590054657305343     |
| train_0/q_grads           | 0.042612106446176766   |
| train_0/q_grads_std       | 0.4540230087935925     |
| train_0/q_loss            | 0.5638464444353642     |
| train_0/reward            | -0.7719005216509686    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1767333984375        |
| train_0/target_q          | -5.936771836914034     |
| train_1/avg_q             | -15.694914055505723    |
| train_1/current_q         | -9.727209200588424     |
| train_1/fw_bonus          | -0.9977760866284371    |
| train_1/fw_loss           | 0.0010336911800550297  |
| train_1/mu_grads          | -0.04199491543695331   |
| train_1/mu_grads_std      | 0.6174473077058792     |
| train_1/mu_loss           | 9.636024558053135      |
| train_1/n_subgoals        | 1943.0                 |
| train_1/next_q            | -9.417298286296225     |
| train_1/q_grads           | -0.04807249316945672   |
| train_1/q_grads_std       | 0.7587085455656052     |
| train_1/q_loss            | 7.38648466862337       |
| train_1/reward            | -1.9461908482302532    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.017236328125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.34276891405043747    |
| train_1/target_q          | -9.886390641287951     |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_50.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 51
Time for epoch 51: 480.87. Rollout time: 272.68, Training time: 208.14
Evaluating epoch 51
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 51                     |
| policy/steps              | 2777174.0              |
| test/episodes             | 780.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.5882990494650724    |
| test_1/avg_q              | -19.353144217181246    |
| test_1/n_subgoals         | 409.0                  |
| test_1/subgoal_succ_rate  | 0.014669926650366748   |
| train/episodes            | 5200.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -11.12854372359032     |
| train_0/current_q         | -5.745998996033469     |
| train_0/fw_bonus          | -0.9993728592991828    |
| train_0/fw_loss           | 0.00018691777404455934 |
| train_0/mu_grads          | -0.14544456489384175   |
| train_0/mu_grads_std      | 0.6399855345487595     |
| train_0/mu_loss           | 5.545923010976232      |
| train_0/next_q            | -5.359993713472456     |
| train_0/q_grads           | 0.043099846318364145   |
| train_0/q_grads_std       | 0.45641903281211854    |
| train_0/q_loss            | 0.6266750254322873     |
| train_0/reward            | -0.7747333502324182    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1578857421875        |
| train_0/target_q          | -5.681313026130753     |
| train_1/avg_q             | -16.67727365793815     |
| train_1/current_q         | -9.372603884205903     |
| train_1/fw_bonus          | -0.997766287624836     |
| train_1/fw_loss           | 0.001036200547241606   |
| train_1/mu_grads          | -0.043332624901086095  |
| train_1/mu_grads_std      | 0.6213358998298645     |
| train_1/mu_loss           | 9.28565578764412       |
| train_1/n_subgoals        | 1924.0                 |
| train_1/next_q            | -9.036527983031757     |
| train_1/q_grads           | -0.04962113033980131   |
| train_1/q_grads_std       | 0.7647672325372696     |
| train_1/q_loss            | 6.618864131856964      |
| train_1/reward            | -2.0440948919676885    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.017626953125         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.28586278586278585    |
| train_1/target_q          | -9.558264384529803     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 52
Time for epoch 52: 501.34. Rollout time: 282.76, Training time: 218.54
Evaluating epoch 52
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 52                     |
| policy/steps              | 2830212.0              |
| test/episodes             | 795.0                  |
| test/success_rate         | 0.26666666666666666    |
| test_0/avg_q              | -1.7052461542311026    |
| test_1/avg_q              | -21.547497076282042    |
| test_1/n_subgoals         | 3422.0                 |
| test_1/subgoal_succ_rate  | 0.9324956165984805     |
| train/episodes            | 5300.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -10.672871944328234    |
| train_0/current_q         | -5.777429038611177     |
| train_0/fw_bonus          | -0.9993548527359962    |
| train_0/fw_loss           | 0.00019216331529605667 |
| train_0/mu_grads          | -0.1471815899014473    |
| train_0/mu_grads_std      | 0.6448380351066589     |
| train_0/mu_loss           | 5.602029615295669      |
| train_0/next_q            | -5.389773173438295     |
| train_0/q_grads           | 0.04337598206475377    |
| train_0/q_grads_std       | 0.4596091255545616     |
| train_0/q_loss            | 0.649268181693038      |
| train_0/reward            | -0.7716892978336546    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.10654296875          |
| train_0/target_q          | -5.703525536376615     |
| train_1/avg_q             | -16.75268980460274     |
| train_1/current_q         | -12.411396168798493    |
| train_1/fw_bonus          | -0.997412295639515     |
| train_1/fw_loss           | 0.0011268397240201012  |
| train_1/mu_grads          | -0.044530789647251365  |
| train_1/mu_grads_std      | 0.6237195566296577     |
| train_1/mu_loss           | 12.699747090855826     |
| train_1/n_subgoals        | 1974.0                 |
| train_1/next_q            | -12.423535200766135    |
| train_1/q_grads           | -0.05085571566596627   |
| train_1/q_grads_std       | 0.7703769490122795     |
| train_1/q_loss            | 5.156106792694578      |
| train_1/reward            | -2.047027635869381     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01640625             |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.29533941236068895    |
| train_1/target_q          | -12.52346854097763     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 53
Time for epoch 53: 443.75. Rollout time: 237.36, Training time: 206.36
Evaluating epoch 53
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 53                     |
| policy/steps              | 2879570.0              |
| test/episodes             | 810.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -0.8878142593490611    |
| test_1/avg_q              | -20.774198767043867    |
| test_1/n_subgoals         | 521.0                  |
| test_1/subgoal_succ_rate  | 0.2514395393474088     |
| train/episodes            | 5400.0                 |
| train/success_rate        | 0.62                   |
| train_0/avg_q             | -11.55298550854057     |
| train_0/current_q         | -5.666167190855577     |
| train_0/fw_bonus          | -0.9993752121925354    |
| train_0/fw_loss           | 0.00018623421783559024 |
| train_0/mu_grads          | -0.1497029647231102    |
| train_0/mu_grads_std      | 0.6479496836662293     |
| train_0/mu_loss           | 5.574399775918618      |
| train_0/next_q            | -5.367952993667243     |
| train_0/q_grads           | 0.04404416540637612    |
| train_0/q_grads_std       | 0.4608237691223621     |
| train_0/q_loss            | 0.9875280819144997     |
| train_0/reward            | -0.7737634779889049    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1199951171875        |
| train_0/target_q          | -5.640032495505525     |
| train_1/avg_q             | -17.43287637033527     |
| train_1/current_q         | -12.185933840725392    |
| train_1/fw_bonus          | -0.9978902041912079    |
| train_1/fw_loss           | 0.0010044706068583764  |
| train_1/mu_grads          | -0.04452185295522213   |
| train_1/mu_grads_std      | 0.6268526643514634     |
| train_1/mu_loss           | 12.457304980674095     |
| train_1/n_subgoals        | 1853.0                 |
| train_1/next_q            | -12.174870367901118    |
| train_1/q_grads           | -0.05129480855539441   |
| train_1/q_grads_std       | 0.7743651926517486     |
| train_1/q_loss            | 4.141172752728546      |
| train_1/reward            | -2.0102879809735894    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0168701171875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.33675121424716675    |
| train_1/target_q          | -12.307001534593589    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 54
Time for epoch 54: 537.29. Rollout time: 326.59, Training time: 210.67
Evaluating epoch 54
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 54                    |
| policy/steps              | 2944786.0             |
| test/episodes             | 825.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.6533616015378014   |
| test_1/avg_q              | -18.11074317911267    |
| test_1/n_subgoals         | 947.0                 |
| test_1/subgoal_succ_rate  | 0.6367476240760296    |
| train/episodes            | 5500.0                |
| train/success_rate        | 0.39                  |
| train_0/avg_q             | -8.672417648013472    |
| train_0/current_q         | -5.203422438136936    |
| train_0/fw_bonus          | -0.9993815407156944   |
| train_0/fw_loss           | 0.000184385980173829  |
| train_0/mu_grads          | -0.14601553678512574  |
| train_0/mu_grads_std      | 0.6552841514348984    |
| train_0/mu_loss           | 4.988196651724765     |
| train_0/next_q            | -4.817965349423742    |
| train_0/q_grads           | 0.04468053681775928   |
| train_0/q_grads_std       | 0.4617303073406219    |
| train_0/q_loss            | 0.6925063307919437    |
| train_0/reward            | -0.7725016364591284   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1483154296875       |
| train_0/target_q          | -5.10223682249662     |
| train_1/avg_q             | -17.228374253335303   |
| train_1/current_q         | -13.05664888742486    |
| train_1/fw_bonus          | -0.9971824690699578   |
| train_1/fw_loss           | 0.0011856857177917845 |
| train_1/mu_grads          | -0.045171009935438634 |
| train_1/mu_grads_std      | 0.6280267745256424    |
| train_1/mu_loss           | 13.222137739883925    |
| train_1/n_subgoals        | 2197.0                |
| train_1/next_q            | -13.016586627143775   |
| train_1/q_grads           | -0.05140755409374833  |
| train_1/q_grads_std       | 0.7799056991934776    |
| train_1/q_loss            | 5.258846223672303     |
| train_1/reward            | -2.138394742041419    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0163818359375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.10605370960400547   |
| train_1/target_q          | -13.155272813871738   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.15
Training epoch 55
Time for epoch 55: 457.08. Rollout time: 232.21, Training time: 224.83
Evaluating epoch 55
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 55                    |
| policy/steps              | 2989779.0             |
| test/episodes             | 840.0                 |
| test/success_rate         | 0.26666666666666666   |
| test_0/avg_q              | -2.0302564456242482   |
| test_1/avg_q              | -19.50467702525618    |
| test_1/n_subgoals         | 3988.0                |
| test_1/subgoal_succ_rate  | 0.9526078234704113    |
| train/episodes            | 5600.0                |
| train/success_rate        | 0.77                  |
| train_0/avg_q             | -9.157329200160108    |
| train_0/current_q         | -5.142473599163437    |
| train_0/fw_bonus          | -0.9994146034121514   |
| train_0/fw_loss           | 0.0001747556871123379 |
| train_0/mu_grads          | -0.1466110061854124   |
| train_0/mu_grads_std      | 0.6584314316511154    |
| train_0/mu_loss           | 4.928980554893772     |
| train_0/next_q            | -4.742273100100823    |
| train_0/q_grads           | 0.04621546324342489   |
| train_0/q_grads_std       | 0.4654999203979969    |
| train_0/q_loss            | 0.5634606375265314    |
| train_0/reward            | -0.7728944224279986   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1774658203125       |
| train_0/target_q          | -5.086226533394219    |
| train_1/avg_q             | -15.897432845202      |
| train_1/current_q         | -12.11359697509437    |
| train_1/fw_bonus          | -0.9973247915506362   |
| train_1/fw_loss           | 0.001149247062858194  |
| train_1/mu_grads          | -0.04625765047967434  |
| train_1/mu_grads_std      | 0.6313555091619492    |
| train_1/mu_loss           | 12.157307616477258    |
| train_1/n_subgoals        | 1709.0                |
| train_1/next_q            | -11.938791055316855   |
| train_1/q_grads           | -0.05263055097311735  |
| train_1/q_grads_std       | 0.7855494886636734    |
| train_1/q_loss            | 4.111675116523903     |
| train_1/reward            | -2.119094380752722    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.016552734375        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3604447045055588    |
| train_1/target_q          | -12.212729595607538   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 56
Time for epoch 56: 430.60. Rollout time: 222.51, Training time: 208.05
Evaluating epoch 56
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 56                     |
| policy/steps              | 3037300.0              |
| test/episodes             | 855.0                  |
| test/success_rate         | 0.26666666666666666    |
| test_0/avg_q              | -1.3611726893520275    |
| test_1/avg_q              | -18.899332382801358    |
| test_1/n_subgoals         | 4663.0                 |
| test_1/subgoal_succ_rate  | 0.9543212524126099     |
| train/episodes            | 5700.0                 |
| train/success_rate        | 0.72                   |
| train_0/avg_q             | -10.678920890972682    |
| train_0/current_q         | -5.7636850421018275    |
| train_0/fw_bonus          | -0.9993957251310348    |
| train_0/fw_loss           | 0.00018025612116616684 |
| train_0/mu_grads          | -0.1503132101148367    |
| train_0/mu_grads_std      | 0.6621031120419503     |
| train_0/mu_loss           | 5.537130047602104      |
| train_0/next_q            | -5.37636725283132      |
| train_0/q_grads           | 0.04645592104643583    |
| train_0/q_grads_std       | 0.4684614770114422     |
| train_0/q_loss            | 0.5938273782785733     |
| train_0/reward            | -0.7723586961550609    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1156982421875        |
| train_0/target_q          | -5.69062162177414      |
| train_1/avg_q             | -16.564572403373145    |
| train_1/current_q         | -12.087004085190774    |
| train_1/fw_bonus          | -0.9979397028684616    |
| train_1/fw_loss           | 0.0009918000214383937  |
| train_1/mu_grads          | -0.046607468836009504  |
| train_1/mu_grads_std      | 0.6373500049114227     |
| train_1/mu_loss           | 12.146306908769896     |
| train_1/n_subgoals        | 1798.0                 |
| train_1/next_q            | -11.886575718020147    |
| train_1/q_grads           | -0.05188026381656528   |
| train_1/q_grads_std       | 0.7940830871462822     |
| train_1/q_loss            | 4.858198254267893      |
| train_1/reward            | -2.0902991323288007    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0173828125           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3476084538375973     |
| train_1/target_q          | -12.178814153625815    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 57
Time for epoch 57: 448.49. Rollout time: 229.97, Training time: 218.48
Evaluating epoch 57
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 57                     |
| policy/steps              | 3083477.0              |
| test/episodes             | 870.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.2515026284247137    |
| test_1/avg_q              | -19.946807636617166    |
| test_1/n_subgoals         | 4658.0                 |
| test_1/subgoal_succ_rate  | 0.948475740661228      |
| train/episodes            | 5800.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -10.359469684479453    |
| train_0/current_q         | -5.740341492538954     |
| train_0/fw_bonus          | -0.9993199050426483    |
| train_0/fw_loss           | 0.00020234353723935783 |
| train_0/mu_grads          | -0.1525208830833435    |
| train_0/mu_grads_std      | 0.6663625597953796     |
| train_0/mu_loss           | 5.527321939597058      |
| train_0/next_q            | -5.367507591023382     |
| train_0/q_grads           | 0.04685962395742536    |
| train_0/q_grads_std       | 0.4721156507730484     |
| train_0/q_loss            | 0.5837011338106167     |
| train_0/reward            | -0.7734933053132409    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.11533203125          |
| train_0/target_q          | -5.710961363208736     |
| train_1/avg_q             | -17.360778151153752    |
| train_1/current_q         | -11.775981460127223    |
| train_1/fw_bonus          | -0.9976450443267822    |
| train_1/fw_loss           | 0.0010672446092939935  |
| train_1/mu_grads          | -0.04793628873303533   |
| train_1/mu_grads_std      | 0.6432323455810547     |
| train_1/mu_loss           | 11.899302579875496     |
| train_1/n_subgoals        | 1705.0                 |
| train_1/next_q            | -11.611767145772022    |
| train_1/q_grads           | -0.05033298432826996   |
| train_1/q_grads_std       | 0.8027634993195534     |
| train_1/q_loss            | 4.666861852855751      |
| train_1/reward            | -2.056662238552235     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0166259765625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.33841642228739005    |
| train_1/target_q          | -11.91007340999685     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18333333333333335
Training epoch 58
Time for epoch 58: 484.58. Rollout time: 258.32, Training time: 226.22
Evaluating epoch 58
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 58                    |
| policy/steps              | 3131602.0             |
| test/episodes             | 885.0                 |
| test/success_rate         | 0.13333333333333333   |
| test_0/avg_q              | -1.1507364105903388   |
| test_1/avg_q              | -20.5620411493259     |
| test_1/n_subgoals         | 3480.0                |
| test_1/subgoal_succ_rate  | 0.9258620689655173    |
| train/episodes            | 5900.0                |
| train/success_rate        | 0.71                  |
| train_0/avg_q             | -10.934852097717842   |
| train_0/current_q         | -5.750300690233802    |
| train_0/fw_bonus          | -0.9993240669369697   |
| train_0/fw_loss           | 0.0002011319280427415 |
| train_0/mu_grads          | -0.15431151315569877  |
| train_0/mu_grads_std      | 0.6701552927494049    |
| train_0/mu_loss           | 5.532913269018744     |
| train_0/next_q            | -5.3569225037769215   |
| train_0/q_grads           | 0.04732323484495282   |
| train_0/q_grads_std       | 0.4748614728450775    |
| train_0/q_loss            | 0.5357346228950306    |
| train_0/reward            | -0.7707111420855653   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.0968994140625       |
| train_0/target_q          | -5.707999886207942    |
| train_1/avg_q             | -17.84864308744014    |
| train_1/current_q         | -12.329939599216734   |
| train_1/fw_bonus          | -0.9979287102818489   |
| train_1/fw_loss           | 0.0009946120262611657 |
| train_1/mu_grads          | -0.04953695749863982  |
| train_1/mu_grads_std      | 0.6482695937156677    |
| train_1/mu_loss           | 12.552494744426886    |
| train_1/n_subgoals        | 1719.0                |
| train_1/next_q            | -12.239843309786247   |
| train_1/q_grads           | -0.04973527900874615  |
| train_1/q_grads_std       | 0.8105126276612282    |
| train_1/q_loss            | 3.9095515212825687    |
| train_1/reward            | -2.069074463387369    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01748046875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.29086678301337987   |
| train_1/target_q          | -12.450789116705632   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16666666666666666
Training epoch 59
Time for epoch 59: 525.44. Rollout time: 279.09, Training time: 246.26
Evaluating epoch 59
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 59                     |
| policy/steps              | 3177555.0              |
| test/episodes             | 900.0                  |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.1985075430010825    |
| test_1/avg_q              | -20.50091327608808     |
| test_1/n_subgoals         | 2985.0                 |
| test_1/subgoal_succ_rate  | 0.9038525963149079     |
| train/episodes            | 6000.0                 |
| train/success_rate        | 0.71                   |
| train_0/avg_q             | -10.759813597966891    |
| train_0/current_q         | -5.7584840977987595    |
| train_0/fw_bonus          | -0.9993884116411209    |
| train_0/fw_loss           | 0.00018238690499856603 |
| train_0/mu_grads          | -0.15681032836437225   |
| train_0/mu_grads_std      | 0.6717080682516098     |
| train_0/mu_loss           | 5.539110718861304      |
| train_0/next_q            | -5.389073357976673     |
| train_0/q_grads           | 0.047829652484506366   |
| train_0/q_grads_std       | 0.4784227356314659     |
| train_0/q_loss            | 0.578210415691547      |
| train_0/reward            | -0.7642819163578679    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1552734375           |
| train_0/target_q          | -5.701815300511308     |
| train_1/avg_q             | -17.7069678780801      |
| train_1/current_q         | -12.385208100583881    |
| train_1/fw_bonus          | -0.9978244170546532    |
| train_1/fw_loss           | 0.0010213144356384873  |
| train_1/mu_grads          | -0.0493376768194139    |
| train_1/mu_grads_std      | 0.6528261601924896     |
| train_1/mu_loss           | 12.597827265537868     |
| train_1/n_subgoals        | 1671.0                 |
| train_1/next_q            | -12.299182512070566    |
| train_1/q_grads           | -0.050668466836214066  |
| train_1/q_grads_std       | 0.8192116901278496     |
| train_1/q_loss            | 3.99520363571213       |
| train_1/reward            | -2.102282033666415     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016259765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2848593656493118     |
| train_1/target_q          | -12.508252945576725    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.15000000000000002
Training epoch 60
Time for epoch 60: 445.58. Rollout time: 209.16, Training time: 236.31
Evaluating epoch 60
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 60                     |
| policy/steps              | 3216340.0              |
| test/episodes             | 915.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.4580695232945364    |
| test_1/avg_q              | -17.228537997197275    |
| test_1/n_subgoals         | 8224.0                 |
| test_1/subgoal_succ_rate  | 0.9900291828793775     |
| train/episodes            | 6100.0                 |
| train/success_rate        | 0.83                   |
| train_0/avg_q             | -10.45206834674599     |
| train_0/current_q         | -5.932377221495176     |
| train_0/fw_bonus          | -0.9993355095386505    |
| train_0/fw_loss           | 0.00019779631657002028 |
| train_0/mu_grads          | -0.16120091564953326   |
| train_0/mu_grads_std      | 0.6786980390548706     |
| train_0/mu_loss           | 5.73970588480819       |
| train_0/next_q            | -5.5632814316509425    |
| train_0/q_grads           | 0.047798688616603614   |
| train_0/q_grads_std       | 0.47963726669549944    |
| train_0/q_loss            | 0.5648970365931574     |
| train_0/reward            | -0.7639757232871489    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1213623046875        |
| train_0/target_q          | -5.877003359791617     |
| train_1/avg_q             | -17.218143912842063    |
| train_1/current_q         | -11.917981154738934    |
| train_1/fw_bonus          | -0.9979362472891807    |
| train_1/fw_loss           | 0.0009926805840223096  |
| train_1/mu_grads          | -0.048680564388632774  |
| train_1/mu_grads_std      | 0.6569157242774963     |
| train_1/mu_loss           | 12.180501136735675     |
| train_1/n_subgoals        | 1469.0                 |
| train_1/next_q            | -11.886644798912531    |
| train_1/q_grads           | -0.050243549328297374  |
| train_1/q_grads_std       | 0.8262571528553962     |
| train_1/q_loss            | 4.137068874954222      |
| train_1/reward            | -2.076986504458546     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0164306640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.36759700476514634    |
| train_1/target_q          | -12.034606346629564    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_60.pkl ...
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 61
Time for epoch 61: 633.93. Rollout time: 347.50, Training time: 286.34
Evaluating epoch 61
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 61                    |
| policy/steps              | 3261808.0             |
| test/episodes             | 930.0                 |
| test/success_rate         | 0.2                   |
| test_0/avg_q              | -1.5532524704823358   |
| test_1/avg_q              | -19.405424341767816   |
| test_1/n_subgoals         | 3953.0                |
| test_1/subgoal_succ_rate  | 0.9402985074626866    |
| train/episodes            | 6200.0                |
| train/success_rate        | 0.69                  |
| train_0/avg_q             | -10.720537074403525   |
| train_0/current_q         | -5.021400958347269    |
| train_0/fw_bonus          | -0.9993410795927048   |
| train_0/fw_loss           | 0.0001961741942068329 |
| train_0/mu_grads          | -0.1634863954037428   |
| train_0/mu_grads_std      | 0.6831853047013283    |
| train_0/mu_loss           | 4.792127501362709     |
| train_0/next_q            | -4.627406822044614    |
| train_0/q_grads           | 0.04751156736165285   |
| train_0/q_grads_std       | 0.47883762791752815   |
| train_0/q_loss            | 0.5825499751566384    |
| train_0/reward            | -0.7615418129189493   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.11318359375         |
| train_0/target_q          | -4.947111918378829    |
| train_1/avg_q             | -16.49512070125175    |
| train_1/current_q         | -12.231193185054057   |
| train_1/fw_bonus          | -0.997672238945961    |
| train_1/fw_loss           | 0.0010602824899251574 |
| train_1/mu_grads          | -0.04849103232845664  |
| train_1/mu_grads_std      | 0.6602206841111183    |
| train_1/mu_loss           | 12.543108047945728    |
| train_1/n_subgoals        | 1787.0                |
| train_1/next_q            | -12.231111568496086   |
| train_1/q_grads           | -0.049908841773867604 |
| train_1/q_grads_std       | 0.8330177962779999    |
| train_1/q_loss            | 4.642052740415137     |
| train_1/reward            | -2.041471280548649    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0156982421875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.37604924454392835   |
| train_1/target_q          | -12.337498317419122   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16666666666666669
Training epoch 62
Time for epoch 62: 590.83. Rollout time: 331.76, Training time: 258.96
Evaluating epoch 62
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 62                     |
| policy/steps              | 3313672.0              |
| test/episodes             | 945.0                  |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.5040467689993       |
| test_1/avg_q              | -17.747465553696156    |
| test_1/n_subgoals         | 4143.0                 |
| test_1/subgoal_succ_rate  | 0.9604151580979966     |
| train/episodes            | 6300.0                 |
| train/success_rate        | 0.53                   |
| train_0/avg_q             | -8.22326801444747      |
| train_0/current_q         | -5.024436191674302     |
| train_0/fw_bonus          | -0.9993767082691193    |
| train_0/fw_loss           | 0.00018579641364340204 |
| train_0/mu_grads          | -0.16495198160409927   |
| train_0/mu_grads_std      | 0.6878871411085129     |
| train_0/mu_loss           | 4.800540087738205      |
| train_0/next_q            | -4.630339692914783     |
| train_0/q_grads           | 0.04728457136079669    |
| train_0/q_grads_std       | 0.47809687852859495    |
| train_0/q_loss            | 0.5956823537780108     |
| train_0/reward            | -0.7630888047431654    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1576416015625        |
| train_0/target_q          | -4.95233764295087      |
| train_1/avg_q             | -16.92890058250018     |
| train_1/current_q         | -12.266102260124153    |
| train_1/fw_bonus          | -0.997852548956871     |
| train_1/fw_loss           | 0.001014113865676336   |
| train_1/mu_grads          | -0.04806942343711853   |
| train_1/mu_grads_std      | 0.6661542385816575     |
| train_1/mu_loss           | 12.673091571919763     |
| train_1/n_subgoals        | 2046.0                 |
| train_1/next_q            | -12.368364835158062    |
| train_1/q_grads           | -0.04987217579036951   |
| train_1/q_grads_std       | 0.8391494125127792     |
| train_1/q_loss            | 4.324473082777749      |
| train_1/reward            | -2.0050966793554834    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0153564453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3734115347018573     |
| train_1/target_q          | -12.36256525809508     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13333333333333336
Training epoch 63
Time for epoch 63: 1787.15. Rollout time: 1553.88, Training time: 233.18
Evaluating epoch 63
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 63                     |
| policy/steps              | 3361795.0              |
| test/episodes             | 960.0                  |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.4339054463117418    |
| test_1/avg_q              | -19.470388768401815    |
| test_1/n_subgoals         | 3311.0                 |
| test_1/subgoal_succ_rate  | 0.9359710057384476     |
| train/episodes            | 6400.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -8.43269575919302      |
| train_0/current_q         | -5.16063392450269      |
| train_0/fw_bonus          | -0.9993681401014328    |
| train_0/fw_loss           | 0.00018829071923391892 |
| train_0/mu_grads          | -0.16674453429877759   |
| train_0/mu_grads_std      | 0.6928158372640609     |
| train_0/mu_loss           | 4.94055103537413       |
| train_0/next_q            | -4.766806615661307     |
| train_0/q_grads           | 0.04699898529797793    |
| train_0/q_grads_std       | 0.47790390700101854    |
| train_0/q_loss            | 0.6352489459869576     |
| train_0/reward            | -0.7649726507148443    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.09384765625          |
| train_0/target_q          | -5.072120944005612     |
| train_1/avg_q             | -15.221363587306454    |
| train_1/current_q         | -12.064625795353487    |
| train_1/fw_bonus          | -0.9977154716849327    |
| train_1/fw_loss           | 0.001049210611381568   |
| train_1/mu_grads          | -0.04896019976586104   |
| train_1/mu_grads_std      | 0.6714092642068863     |
| train_1/mu_loss           | 12.461962062526377     |
| train_1/n_subgoals        | 2030.0                 |
| train_1/next_q            | -12.17364019799619     |
| train_1/q_grads           | -0.049311870615929364  |
| train_1/q_grads_std       | 0.843397057056427      |
| train_1/q_loss            | 4.058453810603514      |
| train_1/reward            | -1.970107579805699     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016162109375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4605911330049261     |
| train_1/target_q          | -12.192654783933154    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 64
Time for epoch 64: 612.97. Rollout time: 329.78, Training time: 283.09
Evaluating epoch 64
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 64                     |
| policy/steps              | 3410221.0              |
| test/episodes             | 975.0                  |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.4286688644305932    |
| test_1/avg_q              | -14.037521886395329    |
| test_1/n_subgoals         | 5197.0                 |
| test_1/subgoal_succ_rate  | 0.9720992880507985     |
| train/episodes            | 6500.0                 |
| train/success_rate        | 0.57                   |
| train_0/avg_q             | -8.769140312575527     |
| train_0/current_q         | -5.168392468489631     |
| train_0/fw_bonus          | -0.999354013800621     |
| train_0/fw_loss           | 0.00019240397014073097 |
| train_0/mu_grads          | -0.16882564947009088   |
| train_0/mu_grads_std      | 0.6976603254675865     |
| train_0/mu_loss           | 4.96164859079128       |
| train_0/next_q            | -4.772578668936054     |
| train_0/q_grads           | 0.04660266526043415    |
| train_0/q_grads_std       | 0.4788018099963665     |
| train_0/q_loss            | 0.6696608146566244     |
| train_0/reward            | -0.7694918254859658    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.12763671875          |
| train_0/target_q          | -5.082922226948627     |
| train_1/avg_q             | -15.283408493955044    |
| train_1/current_q         | -11.087568931452626    |
| train_1/fw_bonus          | -0.9978651657700539    |
| train_1/fw_loss           | 0.0010108827249496245  |
| train_1/mu_grads          | -0.04863985190168023   |
| train_1/mu_grads_std      | 0.6775436535477638     |
| train_1/mu_loss           | 11.136490702632745     |
| train_1/n_subgoals        | 1978.0                 |
| train_1/next_q            | -10.806940702797784    |
| train_1/q_grads           | -0.049970269482582805  |
| train_1/q_grads_std       | 0.8520911306142807     |
| train_1/q_loss            | 5.40090081021783       |
| train_1/reward            | -1.9509372388871271    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0163818359375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43073811931243683    |
| train_1/target_q          | -11.158550265804276    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 65
Time for epoch 65: 619.93. Rollout time: 355.04, Training time: 264.80
Evaluating epoch 65
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 65                    |
| policy/steps              | 3462318.0             |
| test/episodes             | 990.0                 |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.3457100047901522   |
| test_1/avg_q              | -14.764662730731143   |
| test_1/n_subgoals         | 6806.0                |
| test_1/subgoal_succ_rate  | 0.98325007346459      |
| train/episodes            | 6600.0                |
| train/success_rate        | 0.5                   |
| train_0/avg_q             | -9.215976183016389    |
| train_0/current_q         | -5.198601114137544    |
| train_0/fw_bonus          | -0.9994002506136894   |
| train_0/fw_loss           | 0.0001789362468116451 |
| train_0/mu_grads          | -0.171388241648674    |
| train_0/mu_grads_std      | 0.7017820194363594    |
| train_0/mu_loss           | 4.997457509005043     |
| train_0/next_q            | -4.7951661975158      |
| train_0/q_grads           | 0.04651056723669171   |
| train_0/q_grads_std       | 0.48039177134633065   |
| train_0/q_loss            | 0.6481948740512172    |
| train_0/reward            | -0.7742458151693427   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.20068359375         |
| train_0/target_q          | -5.120193630575402    |
| train_1/avg_q             | -16.334187830664256   |
| train_1/current_q         | -11.978983904131507   |
| train_1/fw_bonus          | -0.9977682039141655   |
| train_1/fw_loss           | 0.0010357077466323973 |
| train_1/mu_grads          | -0.05001006731763482  |
| train_1/mu_grads_std      | 0.680127988755703     |
| train_1/mu_loss           | 12.190741464184605    |
| train_1/n_subgoals        | 2084.0                |
| train_1/next_q            | -11.922555389442861   |
| train_1/q_grads           | -0.05073573514819145  |
| train_1/q_grads_std       | 0.8582504019141197    |
| train_1/q_loss            | 4.808995901785524     |
| train_1/reward            | -1.923831701942254    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0171630859375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3675623800383877    |
| train_1/target_q          | -12.102151005490985   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 66
Time for epoch 66: 607.78. Rollout time: 322.98, Training time: 284.69
Evaluating epoch 66
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 66                     |
| policy/steps              | 3508074.0              |
| test/episodes             | 1005.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -1.4597408782204229    |
| test_1/avg_q              | -10.639117484368011    |
| test_1/n_subgoals         | 6564.0                 |
| test_1/subgoal_succ_rate  | 0.9829372333942717     |
| train/episodes            | 6700.0                 |
| train/success_rate        | 0.65                   |
| train_0/avg_q             | -9.149268883678172     |
| train_0/current_q         | -5.004524798050818     |
| train_0/fw_bonus          | -0.9994243204593658    |
| train_0/fw_loss           | 0.00017192859122587832 |
| train_0/mu_grads          | -0.1723458357155323    |
| train_0/mu_grads_std      | 0.7055959701538086     |
| train_0/mu_loss           | 4.781256477547264      |
| train_0/next_q            | -4.610942409097871     |
| train_0/q_grads           | 0.04650108925998211    |
| train_0/q_grads_std       | 0.48271531611680984    |
| train_0/q_loss            | 0.682126774765015      |
| train_0/reward            | -0.7737208233567798    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1544677734375        |
| train_0/target_q          | -4.925739589818718     |
| train_1/avg_q             | -14.272547295164228    |
| train_1/current_q         | -6.923448650024656     |
| train_1/fw_bonus          | -0.9980176761746407    |
| train_1/fw_loss           | 0.0009718306042486802  |
| train_1/mu_grads          | -0.049976268969476226  |
| train_1/mu_grads_std      | 0.6824829757213593     |
| train_1/mu_loss           | 6.4104493299318035     |
| train_1/n_subgoals        | 1876.0                 |
| train_1/next_q            | -6.064661792941867     |
| train_1/q_grads           | -0.05205623544752598   |
| train_1/q_grads_std       | 0.8627282381057739     |
| train_1/q_loss            | 4.435720404806199      |
| train_1/reward            | -1.8446460226521595    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.017822265625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.44616204690831557    |
| train_1/target_q          | -6.983277498413173     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 67
Time for epoch 67: 522.89. Rollout time: 279.40, Training time: 243.40
Evaluating epoch 67
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 67                    |
| policy/steps              | 3551706.0             |
| test/episodes             | 1020.0                |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.543262013913533    |
| test_1/avg_q              | -15.728358181951096   |
| test_1/n_subgoals         | 2861.0                |
| test_1/subgoal_succ_rate  | 0.9479203075847605    |
| train/episodes            | 6800.0                |
| train/success_rate        | 0.54                  |
| train_0/avg_q             | -8.836971820918556    |
| train_0/current_q         | -5.4615886872834185   |
| train_0/fw_bonus          | -0.9994030728936195   |
| train_0/fw_loss           | 0.0001781151986506302 |
| train_0/mu_grads          | -0.16972545608878137  |
| train_0/mu_grads_std      | 0.7097765907645226    |
| train_0/mu_loss           | 5.247974406048151     |
| train_0/next_q            | -5.054663824241601    |
| train_0/q_grads           | 0.04638731945306063   |
| train_0/q_grads_std       | 0.48410686999559405   |
| train_0/q_loss            | 0.6548597331495302    |
| train_0/reward            | -0.7756198108218086   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1565673828125       |
| train_0/target_q          | -5.375939978128538    |
| train_1/avg_q             | -13.93814964173202    |
| train_1/current_q         | -12.096403806953159   |
| train_1/fw_bonus          | -0.9979037940502167   |
| train_1/fw_loss           | 0.0010009924371843226 |
| train_1/mu_grads          | -0.050695480592548844 |
| train_1/mu_grads_std      | 0.6832943797111511    |
| train_1/mu_loss           | 12.303705238009318    |
| train_1/n_subgoals        | 1943.0                |
| train_1/next_q            | -12.044301276219631   |
| train_1/q_grads           | -0.05139016387984156  |
| train_1/q_grads_std       | 0.8673224195837974    |
| train_1/q_loss            | 5.242462214386229     |
| train_1/reward            | -1.794574824964002    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.017822265625        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.46320123520329387   |
| train_1/target_q          | -12.198945045951099   |
-----------------------------------------------------
New best value for test/success_rate: 0.4. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 68
Time for epoch 68: 589.91. Rollout time: 323.63, Training time: 266.15
Evaluating epoch 68
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 68                    |
| policy/steps              | 3601593.0             |
| test/episodes             | 1035.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.5106721437335278   |
| test_1/avg_q              | -15.65014824570477    |
| test_1/n_subgoals         | 6532.0                |
| test_1/subgoal_succ_rate  | 0.9776484996938151    |
| train/episodes            | 6900.0                |
| train/success_rate        | 0.42                  |
| train_0/avg_q             | -8.70395528732375     |
| train_0/current_q         | -5.684080533076593    |
| train_0/fw_bonus          | -0.9994459852576256   |
| train_0/fw_loss           | 0.0001656191161600873 |
| train_0/mu_grads          | -0.16981223672628404  |
| train_0/mu_grads_std      | 0.7133250594139099    |
| train_0/mu_loss           | 5.455211313114629     |
| train_0/next_q            | -5.260857890497212    |
| train_0/q_grads           | 0.046588456444442275  |
| train_0/q_grads_std       | 0.4852735251188278    |
| train_0/q_loss            | 0.6729595621084643    |
| train_0/reward            | -0.785646404066938    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1727783203125       |
| train_0/target_q          | -5.586724372054377    |
| train_1/avg_q             | -15.039113921759888   |
| train_1/current_q         | -11.662358577808453   |
| train_1/fw_bonus          | -0.998034942150116    |
| train_1/fw_loss           | 0.0009674124637967906 |
| train_1/mu_grads          | -0.05222578290849924  |
| train_1/mu_grads_std      | 0.6858531087636948    |
| train_1/mu_loss           | 11.692018864089514    |
| train_1/n_subgoals        | 2124.0                |
| train_1/next_q            | -11.520916544184379   |
| train_1/q_grads           | -0.050945203937590125 |
| train_1/q_grads_std       | 0.8725635156035423    |
| train_1/q_loss            | 4.681625290704375     |
| train_1/reward            | -1.7874848079896766   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0174560546875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.4665725047080979    |
| train_1/target_q          | -11.789649984476828   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16666666666666669
Training epoch 69
Time for epoch 69: 615.49. Rollout time: 341.22, Training time: 274.17
Evaluating epoch 69
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 69                     |
| policy/steps              | 3653694.0              |
| test/episodes             | 1050.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.3217923383475945    |
| test_1/avg_q              | -10.693424974969302    |
| test_1/n_subgoals         | 5149.0                 |
| test_1/subgoal_succ_rate  | 0.9615459312487862     |
| train/episodes            | 7000.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -8.528646224076734     |
| train_0/current_q         | -5.7688402236723535    |
| train_0/fw_bonus          | -0.9994757190346718    |
| train_0/fw_loss           | 0.00015695517395215576 |
| train_0/mu_grads          | -0.17108644917607307   |
| train_0/mu_grads_std      | 0.7171518176794052     |
| train_0/mu_loss           | 5.567389775770155      |
| train_0/next_q            | -5.3461485210601145    |
| train_0/q_grads           | 0.04685220355167985    |
| train_0/q_grads_std       | 0.4872298873960972     |
| train_0/q_loss            | 0.6578105986337787     |
| train_0/reward            | -0.7869172671071283    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2176513671875        |
| train_0/target_q          | -5.66846159569077      |
| train_1/avg_q             | -14.670492386938085    |
| train_1/current_q         | -11.775558689995204    |
| train_1/fw_bonus          | -0.997917652130127     |
| train_1/fw_loss           | 0.0009974435844924301  |
| train_1/mu_grads          | -0.05321662146598101   |
| train_1/mu_grads_std      | 0.6848694443702698     |
| train_1/mu_loss           | 11.80289313209327      |
| train_1/n_subgoals        | 2171.0                 |
| train_1/next_q            | -11.584012644029658    |
| train_1/q_grads           | -0.05091769527643919   |
| train_1/q_grads_std       | 0.8773679107427597     |
| train_1/q_loss            | 4.5971272212779954     |
| train_1/reward            | -1.8016278496856102    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01708984375          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.43528327959465685    |
| train_1/target_q          | -11.899430137278852    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.18333333333333335
Training epoch 70
Time for epoch 70: 625.73. Rollout time: 354.93, Training time: 270.69
Evaluating epoch 70
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 70                     |
| policy/steps              | 3703664.0              |
| test/episodes             | 1065.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.6704836661800544    |
| test_1/avg_q              | -12.170377383134317    |
| test_1/n_subgoals         | 958.0                  |
| test_1/subgoal_succ_rate  | 0.6022964509394572     |
| train/episodes            | 7100.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -7.958454175115776     |
| train_0/current_q         | -4.7894784988789105    |
| train_0/fw_bonus          | -0.9995130345225334    |
| train_0/fw_loss           | 0.00014607973371312256 |
| train_0/mu_grads          | -0.17215731143951415   |
| train_0/mu_grads_std      | 0.722625681757927      |
| train_0/mu_loss           | 4.54767257136689       |
| train_0/next_q            | -4.3547967938028815    |
| train_0/q_grads           | 0.04690512809902429    |
| train_0/q_grads_std       | 0.4877405270934105     |
| train_0/q_loss            | 0.6795256486658827     |
| train_0/reward            | -0.7933169812913548    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.22451171875          |
| train_0/target_q          | -4.693666739132285     |
| train_1/avg_q             | -13.405554227834186    |
| train_1/current_q         | -10.932055645968926    |
| train_1/fw_bonus          | -0.9980128675699234    |
| train_1/fw_loss           | 0.0009730618054163642  |
| train_1/mu_grads          | -0.053164273407310246  |
| train_1/mu_grads_std      | 0.6872602865099907     |
| train_1/mu_loss           | 10.760673235118537     |
| train_1/n_subgoals        | 2043.0                 |
| train_1/next_q            | -10.663165502334715    |
| train_1/q_grads           | -0.0514674074947834    |
| train_1/q_grads_std       | 0.8840550124645233     |
| train_1/q_loss            | 5.4235439558962915     |
| train_1/reward            | -1.810953413045354     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0188232421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.4302496328928047     |
| train_1/target_q          | -11.050743262949318    |
------------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_70.pkl ...
Mean of test/success_rate of last 4 epochs: 0.13333333333333333
Training epoch 71
Time for epoch 71: 711.68. Rollout time: 431.66, Training time: 279.90
Evaluating epoch 71
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 71                     |
| policy/steps              | 3763704.0              |
| test/episodes             | 1080.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -2.0249616221171625    |
| test_1/avg_q              | -10.138827363916898    |
| test_1/n_subgoals         | 446.0                  |
| test_1/subgoal_succ_rate  | 0.09192825112107623    |
| train/episodes            | 7200.0                 |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -6.653002197004561     |
| train_0/current_q         | -6.101827656871378     |
| train_0/fw_bonus          | -0.9994309097528458    |
| train_0/fw_loss           | 0.00017000434854708146 |
| train_0/mu_grads          | -0.16912312544882296   |
| train_0/mu_grads_std      | 0.72733955681324       |
| train_0/mu_loss           | 5.920951277744986      |
| train_0/next_q            | -5.736134418610069     |
| train_0/q_grads           | 0.04770010048523545    |
| train_0/q_grads_std       | 0.48963207602500913    |
| train_0/q_loss            | 0.7158039554554259     |
| train_0/reward            | -0.7860454727706383    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.230322265625         |
| train_0/target_q          | -6.034476735400083     |
| train_1/avg_q             | -11.624157975889178    |
| train_1/current_q         | -12.071134299901178    |
| train_1/fw_bonus          | -0.9974707901477814    |
| train_1/fw_loss           | 0.0011118638067273423  |
| train_1/mu_grads          | -0.05364193161949515   |
| train_1/mu_grads_std      | 0.6881125569343567     |
| train_1/mu_loss           | 12.118803577476463     |
| train_1/n_subgoals        | 2104.0                 |
| train_1/next_q            | -11.95711540003823     |
| train_1/q_grads           | -0.05088204918429255   |
| train_1/q_grads_std       | 0.8891725659370422     |
| train_1/q_loss            | 6.45075544417544       |
| train_1/reward            | -1.887447530404461     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.017529296875         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.19629277566539924    |
| train_1/target_q          | -12.134459550013124    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 72
Time for epoch 72: 672.72. Rollout time: 361.15, Training time: 311.43
Evaluating epoch 72
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 72                    |
| policy/steps              | 3810003.0             |
| test/episodes             | 1095.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -0.8509786159045701   |
| test_1/avg_q              | -9.836827505920603    |
| test_1/n_subgoals         | 1773.0                |
| test_1/subgoal_succ_rate  | 0.8166948674562888    |
| train/episodes            | 7300.0                |
| train/success_rate        | 0.65                  |
| train_0/avg_q             | -11.05686657756317    |
| train_0/current_q         | -5.9099367552094595   |
| train_0/fw_bonus          | -0.9994317680597306   |
| train_0/fw_loss           | 0.0001697538358712336 |
| train_0/mu_grads          | -0.17097288258373738  |
| train_0/mu_grads_std      | 0.729717007279396     |
| train_0/mu_loss           | 5.696489946407427     |
| train_0/next_q            | -5.564895836675623    |
| train_0/q_grads           | 0.04747525909915566   |
| train_0/q_grads_std       | 0.4920414790511131    |
| train_0/q_loss            | 0.7048897336000387    |
| train_0/reward            | -0.7828779631054203   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2247314453125       |
| train_0/target_q          | -5.8841755843670525   |
| train_1/avg_q             | -14.591092789713713   |
| train_1/current_q         | -5.932900060790575    |
| train_1/fw_bonus          | -0.9968541994690895   |
| train_1/fw_loss           | 0.0012697417463641615 |
| train_1/mu_grads          | -0.05704270992428064  |
| train_1/mu_grads_std      | 0.6885342404246331    |
| train_1/mu_loss           | 5.460479772035342     |
| train_1/n_subgoals        | 1731.0                |
| train_1/next_q            | -5.34539514785351     |
| train_1/q_grads           | -0.052499229367822406 |
| train_1/q_grads_std       | 0.8939587995409966    |
| train_1/q_loss            | 5.2425825665361945    |
| train_1/reward            | -1.8809213136035396   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0182373046875       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3362218370883882    |
| train_1/target_q          | -6.333523222298856    |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 73
Time for epoch 73: 726.76. Rollout time: 423.06, Training time: 303.53
Evaluating epoch 73
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 73                     |
| policy/steps              | 3865728.0              |
| test/episodes             | 1110.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3781238655445274    |
| test_1/avg_q              | -15.78145727201873     |
| test_1/n_subgoals         | 1433.0                 |
| test_1/subgoal_succ_rate  | 0.7473831123517097     |
| train/episodes            | 7400.0                 |
| train/success_rate        | 0.47                   |
| train_0/avg_q             | -7.504953820374657     |
| train_0/current_q         | -6.130049908950601     |
| train_0/fw_bonus          | -0.9994105041027069    |
| train_0/fw_loss           | 0.00017594961864233482 |
| train_0/mu_grads          | -0.17394981607794763   |
| train_0/mu_grads_std      | 0.7332297369837761     |
| train_0/mu_loss           | 5.943740157856465      |
| train_0/next_q            | -5.773987771477893     |
| train_0/q_grads           | 0.047389529552310704   |
| train_0/q_grads_std       | 0.4938814416527748     |
| train_0/q_loss            | 0.7314814565196064     |
| train_0/reward            | -0.7740652728040004    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2011962890625        |
| train_0/target_q          | -6.037635114183253     |
| train_1/avg_q             | -14.144849810361245    |
| train_1/current_q         | -11.79336380667834     |
| train_1/fw_bonus          | -0.9965097978711128    |
| train_1/fw_loss           | 0.0013579264137661084  |
| train_1/mu_grads          | -0.05777184562757611   |
| train_1/mu_grads_std      | 0.688234481215477      |
| train_1/mu_loss           | 11.74088486644624      |
| train_1/n_subgoals        | 2039.0                 |
| train_1/next_q            | -11.626194760216475    |
| train_1/q_grads           | -0.05388949979096651   |
| train_1/q_grads_std       | 0.9010276064276695     |
| train_1/q_loss            | 4.711965238719318      |
| train_1/reward            | -1.9423220313288767    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.015771484375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2545365375183914     |
| train_1/target_q          | -11.880708183910794    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.0
Training epoch 74
Time for epoch 74: 986.17. Rollout time: 649.45, Training time: 336.56
Evaluating epoch 74
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 74                     |
| policy/steps              | 3931905.0              |
| test/episodes             | 1125.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.6469907579241525    |
| test_1/avg_q              | -16.680694537281376    |
| test_1/n_subgoals         | 2962.0                 |
| test_1/subgoal_succ_rate  | 0.900405131667792      |
| train/episodes            | 7500.0                 |
| train/success_rate        | 0.38                   |
| train_0/avg_q             | -9.120411598477421     |
| train_0/current_q         | -5.786350998166024     |
| train_0/fw_bonus          | -0.9993520691990853    |
| train_0/fw_loss           | 0.00019297326871310362 |
| train_0/mu_grads          | -0.17133888974785805   |
| train_0/mu_grads_std      | 0.7370214268565178     |
| train_0/mu_loss           | 5.593290847715456      |
| train_0/next_q            | -5.4318933579918385    |
| train_0/q_grads           | 0.04765252880752087    |
| train_0/q_grads_std       | 0.4980572804808617     |
| train_0/q_loss            | 0.5854645132139833     |
| train_0/reward            | -0.7689053996229631    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.125927734375         |
| train_0/target_q          | -5.733774060263808     |
| train_1/avg_q             | -16.637658706377536    |
| train_1/current_q         | -12.774761326519187    |
| train_1/fw_bonus          | -0.9969807386398315    |
| train_1/fw_loss           | 0.0012373392964946106  |
| train_1/mu_grads          | -0.058995590265840295  |
| train_1/mu_grads_std      | 0.6885934367775917     |
| train_1/mu_loss           | 12.870923945404794     |
| train_1/n_subgoals        | 2252.0                 |
| train_1/next_q            | -12.706396584505224    |
| train_1/q_grads           | -0.0546918136999011    |
| train_1/q_grads_std       | 0.9079984158277512     |
| train_1/q_loss            | 4.565204102469811      |
| train_1/reward            | -2.079292795407673     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0162353515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.13543516873889877    |
| train_1/target_q          | -12.85976537887997     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 75
Time for epoch 75: 684.76. Rollout time: 408.61, Training time: 276.04
Evaluating epoch 75
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 75                    |
| policy/steps              | 3982295.0             |
| test/episodes             | 1140.0                |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.0038513169766228   |
| test_1/avg_q              | -18.30212578404407    |
| test_1/n_subgoals         | 500.0                 |
| test_1/subgoal_succ_rate  | 0.218                 |
| train/episodes            | 7600.0                |
| train/success_rate        | 0.6                   |
| train_0/avg_q             | -11.50008903361194    |
| train_0/current_q         | -5.605265482677415    |
| train_0/fw_bonus          | -0.9993453994393349   |
| train_0/fw_loss           | 0.0001949150835571345 |
| train_0/mu_grads          | -0.1697063732892275   |
| train_0/mu_grads_std      | 0.7394459828734398    |
| train_0/mu_loss           | 5.425880534681997     |
| train_0/next_q            | -5.281512716299735    |
| train_0/q_grads           | 0.04733609454706311   |
| train_0/q_grads_std       | 0.5003965437412262    |
| train_0/q_loss            | 0.6921932969426023    |
| train_0/reward            | -0.7595653542077343   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.1615234375          |
| train_0/target_q          | -5.566062221858354    |
| train_1/avg_q             | -17.04818180106633    |
| train_1/current_q         | -12.484273082798925   |
| train_1/fw_bonus          | -0.9970763221383094   |
| train_1/fw_loss           | 0.001212868158472702  |
| train_1/mu_grads          | -0.059520363248884676 |
| train_1/mu_grads_std      | 0.6900389611721038    |
| train_1/mu_loss           | 12.577839843628556    |
| train_1/n_subgoals        | 1841.0                |
| train_1/next_q            | -12.499439325646058   |
| train_1/q_grads           | -0.055010767839849    |
| train_1/q_grads_std       | 0.9137232765555382    |
| train_1/q_loss            | 5.073624766156371     |
| train_1/reward            | -2.104347204462101    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0171875             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.27648017381857687   |
| train_1/target_q          | -12.568066718008913   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 76
Time for epoch 76: 713.76. Rollout time: 411.37, Training time: 302.28
Evaluating epoch 76
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 76                     |
| policy/steps              | 4033361.0              |
| test/episodes             | 1155.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.4556375454971147    |
| test_1/avg_q              | -17.131482132470477    |
| test_1/n_subgoals         | 2856.0                 |
| test_1/subgoal_succ_rate  | 0.9016106442577031     |
| train/episodes            | 7700.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -8.95687157571826      |
| train_0/current_q         | -5.370706531430498     |
| train_0/fw_bonus          | -0.9993819743394852    |
| train_0/fw_loss           | 0.00018425991365802474 |
| train_0/mu_grads          | -0.17088629826903343   |
| train_0/mu_grads_std      | 0.7424733370542527     |
| train_0/mu_loss           | 5.1446966920354615     |
| train_0/next_q            | -4.9809151812062655    |
| train_0/q_grads           | 0.04688127171248198    |
| train_0/q_grads_std       | 0.500319904088974      |
| train_0/q_loss            | 0.5798413611083613     |
| train_0/reward            | -0.7551799672106426    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1287841796875        |
| train_0/target_q          | -5.26824650371671      |
| train_1/avg_q             | -17.791595930892385    |
| train_1/current_q         | -12.799152399266376    |
| train_1/fw_bonus          | -0.9970174565911293    |
| train_1/fw_loss           | 0.0012279405695153401  |
| train_1/mu_grads          | -0.059304076712578535  |
| train_1/mu_grads_std      | 0.6915442049503326     |
| train_1/mu_loss           | 13.0302735056102       |
| train_1/n_subgoals        | 1941.0                 |
| train_1/next_q            | -12.883150913828405    |
| train_1/q_grads           | -0.05458071436733007   |
| train_1/q_grads_std       | 0.9194266065955162     |
| train_1/q_loss            | 4.794895630957704      |
| train_1/reward            | -2.16594747954332      |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016259765625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3003606388459557     |
| train_1/target_q          | -12.902479933676437    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 77
Time for epoch 77: 644.66. Rollout time: 377.30, Training time: 267.24
Evaluating epoch 77
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 77                     |
| policy/steps              | 4090523.0              |
| test/episodes             | 1170.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.0831031500249186    |
| test_1/avg_q              | -18.63114078759485     |
| test_1/n_subgoals         | 1425.0                 |
| test_1/subgoal_succ_rate  | 0.7592982456140351     |
| train/episodes            | 7800.0                 |
| train/success_rate        | 0.43                   |
| train_0/avg_q             | -9.445011763041713     |
| train_0/current_q         | -5.641257332683199     |
| train_0/fw_bonus          | -0.9994191572070121    |
| train_0/fw_loss           | 0.00017342788778478279 |
| train_0/mu_grads          | -0.17059062644839287   |
| train_0/mu_grads_std      | 0.7441940113902092     |
| train_0/mu_loss           | 5.4062737798058915     |
| train_0/next_q            | -5.252543674247251     |
| train_0/q_grads           | 0.04714099131524563    |
| train_0/q_grads_std       | 0.5020616456866265     |
| train_0/q_loss            | 0.5511167560253493     |
| train_0/reward            | -0.7497327202301676    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1799072265625        |
| train_0/target_q          | -5.546180714760641     |
| train_1/avg_q             | -17.871750843531117    |
| train_1/current_q         | -13.482424222370312    |
| train_1/fw_bonus          | -0.9970221295952797    |
| train_1/fw_loss           | 0.0012267463986063375  |
| train_1/mu_grads          | -0.059339632373303176  |
| train_1/mu_grads_std      | 0.6952681675553322     |
| train_1/mu_loss           | 13.904840153701826     |
| train_1/n_subgoals        | 2143.0                 |
| train_1/next_q            | -13.741014871181907    |
| train_1/q_grads           | -0.05491340421140194   |
| train_1/q_grads_std       | 0.9249205455183983     |
| train_1/q_loss            | 4.841313289399612      |
| train_1/reward            | -2.2252381964503       |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016943359375         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.25711619225384974    |
| train_1/target_q          | -13.601878279230652    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.1
Training epoch 78
Time for epoch 78: 675.19. Rollout time: 379.54, Training time: 295.53
Evaluating epoch 78
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 78                     |
| policy/steps              | 4143676.0              |
| test/episodes             | 1185.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.3029276212560623    |
| test_1/avg_q              | -17.634537711796543    |
| test_1/n_subgoals         | 1066.0                 |
| test_1/subgoal_succ_rate  | 0.6801125703564728     |
| train/episodes            | 7900.0                 |
| train/success_rate        | 0.45                   |
| train_0/avg_q             | -10.288489107007582    |
| train_0/current_q         | -5.60035754891373      |
| train_0/fw_bonus          | -0.9994358822703362    |
| train_0/fw_loss           | 0.00016855727808433584 |
| train_0/mu_grads          | -0.17149917371571063   |
| train_0/mu_grads_std      | 0.7479322552680969     |
| train_0/mu_loss           | 5.382215875504754      |
| train_0/next_q            | -5.21523899923846      |
| train_0/q_grads           | 0.04749030452221632    |
| train_0/q_grads_std       | 0.5046088248491287     |
| train_0/q_loss            | 0.5649160811023026     |
| train_0/reward            | -0.7478875349068403    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.185107421875         |
| train_0/target_q          | -5.5053928248087445    |
| train_1/avg_q             | -17.9534327619791      |
| train_1/current_q         | -13.19495854470785     |
| train_1/fw_bonus          | -0.997552578151226     |
| train_1/fw_loss           | 0.001090920146089047   |
| train_1/mu_grads          | -0.06071000304073095   |
| train_1/mu_grads_std      | 0.6970566436648369     |
| train_1/mu_loss           | 13.479138077865713     |
| train_1/n_subgoals        | 2031.0                 |
| train_1/next_q            | -13.305953112993802    |
| train_1/q_grads           | -0.0546801058575511    |
| train_1/q_grads_std       | 0.9296463415026665     |
| train_1/q_loss            | 4.541997760847556      |
| train_1/reward            | -2.215538048088638     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0171142578125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3003446578040374     |
| train_1/target_q          | -13.310007850075362    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.11666666666666667
Training epoch 79
Time for epoch 79: 689.11. Rollout time: 382.04, Training time: 306.92
Evaluating epoch 79
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 79                     |
| policy/steps              | 4194974.0              |
| test/episodes             | 1200.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.1399844612305075    |
| test_1/avg_q              | -18.163059866986547    |
| test_1/n_subgoals         | 5851.0                 |
| test_1/subgoal_succ_rate  | 0.9683814732524355     |
| train/episodes            | 8000.0                 |
| train/success_rate        | 0.52                   |
| train_0/avg_q             | -10.566687546589934    |
| train_0/current_q         | -5.943173391084551     |
| train_0/fw_bonus          | -0.9994446858763695    |
| train_0/fw_loss           | 0.00016599219343333972 |
| train_0/mu_grads          | -0.1726128336042166    |
| train_0/mu_grads_std      | 0.7493581116199494     |
| train_0/mu_loss           | 5.72218365916042       |
| train_0/next_q            | -5.567064174076841     |
| train_0/q_grads           | 0.04794042548164725    |
| train_0/q_grads_std       | 0.5081656590104103     |
| train_0/q_loss            | 0.5367674159363554     |
| train_0/reward            | -0.750984218513986     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.17646484375          |
| train_0/target_q          | -5.871361477071092     |
| train_1/avg_q             | -17.802963697558805    |
| train_1/current_q         | -9.502657412502746     |
| train_1/fw_bonus          | -0.997663851082325     |
| train_1/fw_loss           | 0.0010624267277307808  |
| train_1/mu_grads          | -0.059650026727467775  |
| train_1/mu_grads_std      | 0.6998108491301537     |
| train_1/mu_loss           | 9.35546066272864       |
| train_1/n_subgoals        | 1942.0                 |
| train_1/next_q            | -9.208075158160671     |
| train_1/q_grads           | -0.05687552131712437   |
| train_1/q_grads_std       | 0.9360285013914108     |
| train_1/q_loss            | 5.757322482067107      |
| train_1/reward            | -2.1588581059666465    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0156982421875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.31462409886714726    |
| train_1/target_q          | -9.770645969890225     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13333333333333333
Training epoch 80
Time for epoch 80: 672.36. Rollout time: 370.89, Training time: 301.36
Evaluating epoch 80
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 80                    |
| policy/steps              | 4250028.0             |
| test/episodes             | 1215.0                |
| test/success_rate         | 0.13333333333333333   |
| test_0/avg_q              | -1.2219401196983597   |
| test_1/avg_q              | -18.183141449067882   |
| test_1/n_subgoals         | 3845.0                |
| test_1/subgoal_succ_rate  | 0.9310793237971391    |
| train/episodes            | 8100.0                |
| train/success_rate        | 0.4                   |
| train_0/avg_q             | -11.506785128895293   |
| train_0/current_q         | -5.702139428921714    |
| train_0/fw_bonus          | -0.9995246931910515   |
| train_0/fw_loss           | 0.0001426823073416017 |
| train_0/mu_grads          | -0.17357269078493118  |
| train_0/mu_grads_std      | 0.7528661876916886    |
| train_0/mu_loss           | 5.447987038609123     |
| train_0/next_q            | -5.295150640474523    |
| train_0/q_grads           | 0.047721393033862115  |
| train_0/q_grads_std       | 0.5086997643113136    |
| train_0/q_loss            | 0.5107681979610966    |
| train_0/reward            | -0.7640230217759381   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.23818359375         |
| train_0/target_q          | -5.641906614051274    |
| train_1/avg_q             | -17.974064630849373   |
| train_1/current_q         | -11.405618289747071   |
| train_1/fw_bonus          | -0.9975671112537384   |
| train_1/fw_loss           | 0.0010871996142668649 |
| train_1/mu_grads          | -0.060668588057160376 |
| train_1/mu_grads_std      | 0.7029301941394805    |
| train_1/mu_loss           | 11.339257301818261    |
| train_1/n_subgoals        | 2123.0                |
| train_1/next_q            | -11.226473871671068   |
| train_1/q_grads           | -0.05672618355602026  |
| train_1/q_grads_std       | 0.941155856847763     |
| train_1/q_loss            | 4.245329671724637     |
| train_1/reward            | -2.1367330876990307   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0159423828125       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.33207724917569476   |
| train_1/target_q          | -11.555685212572609   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_80.pkl ...
Mean of test/success_rate of last 4 epochs: 0.13333333333333333
Training epoch 81
Time for epoch 81: 660.23. Rollout time: 368.05, Training time: 292.04
Evaluating epoch 81
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 81                     |
| policy/steps              | 4299465.0              |
| test/episodes             | 1230.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.2254710409994132    |
| test_1/avg_q              | -17.67432408312308     |
| test_1/n_subgoals         | 3547.0                 |
| test_1/subgoal_succ_rate  | 0.9238793346489992     |
| train/episodes            | 8200.0                 |
| train/success_rate        | 0.58                   |
| train_0/avg_q             | -11.194803734044111    |
| train_0/current_q         | -5.961561585863596     |
| train_0/fw_bonus          | -0.999548165500164     |
| train_0/fw_loss           | 0.00013584884582087397 |
| train_0/mu_grads          | -0.1731377098709345    |
| train_0/mu_grads_std      | 0.7562557950615882     |
| train_0/mu_loss           | 5.730630412858475      |
| train_0/next_q            | -5.569476032320513     |
| train_0/q_grads           | 0.047762702032923696   |
| train_0/q_grads_std       | 0.5089093387126923     |
| train_0/q_loss            | 0.5475769284723611     |
| train_0/reward            | -0.7593780073770177    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2630615234375        |
| train_0/target_q          | -5.879579784968535     |
| train_1/avg_q             | -17.615563766815374    |
| train_1/current_q         | -12.097028579767088    |
| train_1/fw_bonus          | -0.9976619422435761    |
| train_1/fw_loss           | 0.0010629180484102107  |
| train_1/mu_grads          | -0.0614742124453187    |
| train_1/mu_grads_std      | 0.7044062167406082     |
| train_1/mu_loss           | 12.072936929115972     |
| train_1/n_subgoals        | 1944.0                 |
| train_1/next_q            | -11.957315488277406    |
| train_1/q_grads           | -0.056530341133475305  |
| train_1/q_grads_std       | 0.94369907528162       |
| train_1/q_loss            | 4.306610391203791      |
| train_1/reward            | -2.1096205640220433    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.01669921875          |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35802469135802467    |
| train_1/target_q          | -12.218788442028956    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.13333333333333333
Training epoch 82
Time for epoch 82: 642.80. Rollout time: 352.02, Training time: 290.67
Evaluating epoch 82
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 82                    |
| policy/steps              | 4346967.0             |
| test/episodes             | 1245.0                |
| test/success_rate         | 0.4                   |
| test_0/avg_q              | -1.1974656569286417   |
| test_1/avg_q              | -14.79444810282643    |
| test_1/n_subgoals         | 4809.0                |
| test_1/subgoal_succ_rate  | 0.967144936577251     |
| train/episodes            | 8300.0                |
| train/success_rate        | 0.57                  |
| train_0/avg_q             | -11.903380427795629   |
| train_0/current_q         | -6.406662388816993    |
| train_0/fw_bonus          | -0.999551747739315    |
| train_0/fw_loss           | 0.0001348062529359595 |
| train_0/mu_grads          | -0.17257425412535668  |
| train_0/mu_grads_std      | 0.758937020599842     |
| train_0/mu_loss           | 6.190608375541987     |
| train_0/next_q            | -6.0283558891704185   |
| train_0/q_grads           | 0.04788724584504962   |
| train_0/q_grads_std       | 0.5097273051738739    |
| train_0/q_loss            | 0.5988842854039877    |
| train_0/reward            | -0.764524165965122    |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2511962890625       |
| train_0/target_q          | -6.332158047288468    |
| train_1/avg_q             | -16.92150461263238    |
| train_1/current_q         | -12.405181628931238   |
| train_1/fw_bonus          | -0.9978656664490699   |
| train_1/fw_loss           | 0.0010107517227879725 |
| train_1/mu_grads          | -0.06116325790062547  |
| train_1/mu_grads_std      | 0.7058454975485802    |
| train_1/mu_loss           | 12.449516999666582    |
| train_1/n_subgoals        | 1955.0                |
| train_1/next_q            | -12.27143388202291    |
| train_1/q_grads           | -0.05640296712517738  |
| train_1/q_grads_std       | 0.9457204058766365    |
| train_1/q_loss            | 3.694898549040983     |
| train_1/reward            | -2.0735630994222447   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0171875             |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.3723785166240409    |
| train_1/target_q          | -12.52517710154064    |
-----------------------------------------------------
New best value for test/success_rate: 0.4. Saving policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_best.pkl ...
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 83
Time for epoch 83: 627.35. Rollout time: 350.40, Training time: 276.84
Evaluating epoch 83
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 83                     |
| policy/steps              | 4399710.0              |
| test/episodes             | 1260.0                 |
| test/success_rate         | 0.2                    |
| test_0/avg_q              | -0.9741365571310066    |
| test_1/avg_q              | -15.611787880817568    |
| test_1/n_subgoals         | 9193.0                 |
| test_1/subgoal_succ_rate  | 0.9976068747960405     |
| train/episodes            | 8400.0                 |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -11.876519287722925    |
| train_0/current_q         | -6.336358373383987     |
| train_0/fw_bonus          | -0.999547928571701     |
| train_0/fw_loss           | 0.00013591377228294732 |
| train_0/mu_grads          | -0.17179537564516068   |
| train_0/mu_grads_std      | 0.7588032230734825     |
| train_0/mu_loss           | 6.109467645653899      |
| train_0/next_q            | -5.9291847308619605    |
| train_0/q_grads           | 0.048168185818940404   |
| train_0/q_grads_std       | 0.5117216050624848     |
| train_0/q_loss            | 0.5733865015185329     |
| train_0/reward            | -0.7717925024626311    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1987060546875        |
| train_0/target_q          | -6.2620470040503955    |
| train_1/avg_q             | -17.653142922856034    |
| train_1/current_q         | -12.2754242597159      |
| train_1/fw_bonus          | -0.997947347164154     |
| train_1/fw_loss           | 0.0009898395248455927  |
| train_1/mu_grads          | -0.0615009643137455    |
| train_1/mu_grads_std      | 0.7097882270812989     |
| train_1/mu_loss           | 12.222671591352185     |
| train_1/n_subgoals        | 2118.0                 |
| train_1/next_q            | -12.083651428823977    |
| train_1/q_grads           | -0.05750421332195401   |
| train_1/q_grads_std       | 0.9499918594956398     |
| train_1/q_loss            | 3.4852162290342235     |
| train_1/reward            | -2.089879902213215     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0162353515625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35127478753541075    |
| train_1/target_q          | -12.371373465348489    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.21666666666666667
Training epoch 84
Time for epoch 84: 542.51. Rollout time: 294.33, Training time: 248.06
Evaluating epoch 84
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 84                     |
| policy/steps              | 4451191.0              |
| test/episodes             | 1275.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.345445671856003     |
| test_1/avg_q              | -15.738835164970654    |
| test_1/n_subgoals         | 5582.0                 |
| test_1/subgoal_succ_rate  | 0.9643496954496596     |
| train/episodes            | 8500.0                 |
| train/success_rate        | 0.51                   |
| train_0/avg_q             | -11.264555581638723    |
| train_0/current_q         | -6.206693565303619     |
| train_0/fw_bonus          | -0.9995606273412705    |
| train_0/fw_loss           | 0.00013221696663094916 |
| train_0/mu_grads          | -0.17284674532711505   |
| train_0/mu_grads_std      | 0.7610119238495827     |
| train_0/mu_loss           | 6.008452543906897      |
| train_0/next_q            | -5.833437699495889     |
| train_0/q_grads           | 0.04807042432948947    |
| train_0/q_grads_std       | 0.5131829142570495     |
| train_0/q_loss            | 0.6905923672422372     |
| train_0/reward            | -0.7805481166211393    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2391845703125        |
| train_0/target_q          | -6.130866759648621     |
| train_1/avg_q             | -16.349648986880084    |
| train_1/current_q         | -6.557226587621197     |
| train_1/fw_bonus          | -0.9976794689893722    |
| train_1/fw_loss           | 0.0010584288451354952  |
| train_1/mu_grads          | -0.06329722702503204   |
| train_1/mu_grads_std      | 0.717479008436203      |
| train_1/mu_loss           | 6.001092890285024      |
| train_1/n_subgoals        | 2045.0                 |
| train_1/next_q            | -5.981283689620222     |
| train_1/q_grads           | -0.05795015841722488   |
| train_1/q_grads_std       | 0.954880565404892      |
| train_1/q_loss            | 5.645416892453727      |
| train_1/reward            | -2.022155465060132     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0174560546875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3589242053789731     |
| train_1/target_q          | -6.946927463922114     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.2
Training epoch 85
Time for epoch 85: 3541.53. Rollout time: 2212.53, Training time: 1328.76
Evaluating epoch 85
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 85                    |
| policy/steps              | 4501806.0             |
| test/episodes             | 1290.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.2817111087210797   |
| test_1/avg_q              | -19.675387738897257   |
| test_1/n_subgoals         | 7523.0                |
| test_1/subgoal_succ_rate  | 0.9831184367938323    |
| train/episodes            | 8600.0                |
| train/success_rate        | 0.58                  |
| train_0/avg_q             | -10.841141285267774   |
| train_0/current_q         | -6.227119802196796    |
| train_0/fw_bonus          | -0.9995662823319436   |
| train_0/fw_loss           | 0.000130569125758484  |
| train_0/mu_grads          | -0.17256326489150525  |
| train_0/mu_grads_std      | 0.7626504927873612    |
| train_0/mu_loss           | 6.015278934693374     |
| train_0/next_q            | -5.858655959801011    |
| train_0/q_grads           | 0.04837264670059085   |
| train_0/q_grads_std       | 0.5138154998421669    |
| train_0/q_loss            | 0.7146520438272442    |
| train_0/reward            | -0.7825270696292137   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2580322265625       |
| train_0/target_q          | -6.16465940126445     |
| train_1/avg_q             | -14.681407645060673   |
| train_1/current_q         | -11.55612744659423    |
| train_1/fw_bonus          | -0.9977322444319725   |
| train_1/fw_loss           | 0.0010449165871250442 |
| train_1/mu_grads          | -0.06472035702317953  |
| train_1/mu_grads_std      | 0.7193446576595306    |
| train_1/mu_loss           | 11.576955623929951    |
| train_1/n_subgoals        | 1947.0                |
| train_1/next_q            | -11.345118777422403   |
| train_1/q_grads           | -0.05699988640844822  |
| train_1/q_grads_std       | 0.9624788343906403    |
| train_1/q_loss            | 4.460758575930806     |
| train_1/reward            | -2.057819292086424    |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0162109375          |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.35130970724191063   |
| train_1/target_q          | -11.672122498440242   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.16666666666666669
Training epoch 86
Time for epoch 86: 517.34. Rollout time: 271.78, Training time: 245.46
Evaluating epoch 86
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 86                     |
| policy/steps              | 4548336.0              |
| test/episodes             | 1305.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.2211796210157886    |
| test_1/avg_q              | -16.23682905295351     |
| test_1/n_subgoals         | 5231.0                 |
| test_1/subgoal_succ_rate  | 0.958516536035175      |
| train/episodes            | 8700.0                 |
| train/success_rate        | 0.67                   |
| train_0/avg_q             | -9.926746632076672     |
| train_0/current_q         | -5.944788178525444     |
| train_0/fw_bonus          | -0.9995194017887116    |
| train_0/fw_loss           | 0.00014422844196815277 |
| train_0/mu_grads          | -0.1736760124564171    |
| train_0/mu_grads_std      | 0.765780571103096      |
| train_0/mu_loss           | 5.719996346241008      |
| train_0/next_q            | -5.570959502033814     |
| train_0/q_grads           | 0.04860820053145289    |
| train_0/q_grads_std       | 0.5148900002241135     |
| train_0/q_loss            | 0.647341265333592      |
| train_0/reward            | -0.7753925446962967    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.24228515625          |
| train_0/target_q          | -5.882546064161028     |
| train_1/avg_q             | -16.747171984487426    |
| train_1/current_q         | -12.244163992961251    |
| train_1/fw_bonus          | -0.9979030847549438    |
| train_1/fw_loss           | 0.0010011732258135453  |
| train_1/mu_grads          | -0.06584512759000063   |
| train_1/mu_grads_std      | 0.7213209435343743     |
| train_1/mu_loss           | 12.367314075628121     |
| train_1/n_subgoals        | 1775.0                 |
| train_1/next_q            | -12.158438918417184    |
| train_1/q_grads           | -0.056098897196352485  |
| train_1/q_grads_std       | 0.9686822548508645     |
| train_1/q_loss            | 4.562202752457037      |
| train_1/reward            | -2.014539247103676     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.017431640625         |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3442253521126761     |
| train_1/target_q          | -12.362544994814442    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.08333333333333333
Training epoch 87
Time for epoch 87: 645.77. Rollout time: 369.51, Training time: 276.14
Evaluating epoch 87
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 87                    |
| policy/steps              | 4599931.0             |
| test/episodes             | 1320.0                |
| test/success_rate         | 0.13333333333333333   |
| test_0/avg_q              | -1.4750362804685881   |
| test_1/avg_q              | -13.838428616094614   |
| test_1/n_subgoals         | 2776.0                |
| test_1/subgoal_succ_rate  | 0.8933717579250721    |
| train/episodes            | 8800.0                |
| train/success_rate        | 0.59                  |
| train_0/avg_q             | -9.996714500402383    |
| train_0/current_q         | -5.846750140721509    |
| train_0/fw_bonus          | -0.9994808435440063   |
| train_0/fw_loss           | 0.000155459138295555  |
| train_0/mu_grads          | -0.1751391038298607   |
| train_0/mu_grads_std      | 0.7659227803349495    |
| train_0/mu_loss           | 5.654299342445624     |
| train_0/next_q            | -5.4910921273376      |
| train_0/q_grads           | 0.04882076820358634   |
| train_0/q_grads_std       | 0.5155034676194191    |
| train_0/q_loss            | 0.669192519751998     |
| train_0/reward            | -0.7692854942426492   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2257568359375       |
| train_0/target_q          | -5.765681080469021    |
| train_1/avg_q             | -17.25995027640071    |
| train_1/current_q         | -10.967327490535643   |
| train_1/fw_bonus          | -0.9979547306895256   |
| train_1/fw_loss           | 0.0009879480581730603 |
| train_1/mu_grads          | -0.06625984702259302  |
| train_1/mu_grads_std      | 0.7231202304363251    |
| train_1/mu_loss           | 10.834477757789804    |
| train_1/n_subgoals        | 1882.0                |
| train_1/next_q            | -10.725789049974274   |
| train_1/q_grads           | -0.05663651209324598  |
| train_1/q_grads_std       | 0.9742018565535545    |
| train_1/q_loss            | 6.652435724308971     |
| train_1/reward            | -2.0185987910157563   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.017529296875        |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.27948990435706694   |
| train_1/target_q          | -11.072898815732799   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 88
Time for epoch 88: 608.76. Rollout time: 344.19, Training time: 264.42
Evaluating epoch 88
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 88                     |
| policy/steps              | 4650323.0              |
| test/episodes             | 1335.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -3.0643896737206457    |
| test_1/avg_q              | -16.39328643327039     |
| test_1/n_subgoals         | 3087.0                 |
| test_1/subgoal_succ_rate  | 0.9384515711046323     |
| train/episodes            | 8900.0                 |
| train/success_rate        | 0.63                   |
| train_0/avg_q             | -11.106323057373158    |
| train_0/current_q         | -6.340232609463614     |
| train_0/fw_bonus          | -0.9994814619421959    |
| train_0/fw_loss           | 0.00015528219155385158 |
| train_0/mu_grads          | -0.17711437083780765   |
| train_0/mu_grads_std      | 0.7662796631455422     |
| train_0/mu_loss           | 6.166995377223522      |
| train_0/next_q            | -5.990176882343237     |
| train_0/q_grads           | 0.049821638595312835   |
| train_0/q_grads_std       | 0.5184570267796517     |
| train_0/q_loss            | 0.7132407905151394     |
| train_0/reward            | -0.7691757829317794    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.201123046875         |
| train_0/target_q          | -6.274104565767581     |
| train_1/avg_q             | -16.142751219783168    |
| train_1/current_q         | -12.603748529640121    |
| train_1/fw_bonus          | -0.9979468137025833    |
| train_1/fw_loss           | 0.000989975685661193   |
| train_1/mu_grads          | -0.06555459275841713   |
| train_1/mu_grads_std      | 0.724551048874855      |
| train_1/mu_loss           | 12.937069700805313     |
| train_1/n_subgoals        | 1854.0                 |
| train_1/next_q            | -12.741166118885753    |
| train_1/q_grads           | -0.05608275523409247   |
| train_1/q_grads_std       | 0.9773250043392181     |
| train_1/q_loss            | 4.784474246370734      |
| train_1/reward            | -2.0332269383558015    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0169189453125        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3182308522114347     |
| train_1/target_q          | -12.69540727513708     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 89
Time for epoch 89: 660.45. Rollout time: 371.08, Training time: 289.22
Evaluating epoch 89
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 89                     |
| policy/steps              | 4702034.0              |
| test/episodes             | 1350.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.4701828076446786    |
| test_1/avg_q              | -18.556522769340702    |
| test_1/n_subgoals         | 2782.0                 |
| test_1/subgoal_succ_rate  | 0.8882099209202013     |
| train/episodes            | 9000.0                 |
| train/success_rate        | 0.56                   |
| train_0/avg_q             | -11.368430011904788    |
| train_0/current_q         | -5.636316610727066     |
| train_0/fw_bonus          | -0.9994492545723915    |
| train_0/fw_loss           | 0.00016466198721900582 |
| train_0/mu_grads          | -0.17877645529806613   |
| train_0/mu_grads_std      | 0.7680320709943771     |
| train_0/mu_loss           | 5.4541499988819195     |
| train_0/next_q            | -5.277715560118802     |
| train_0/q_grads           | 0.05007372498512268    |
| train_0/q_grads_std       | 0.5201739743351936     |
| train_0/q_loss            | 0.6577423739330569     |
| train_0/reward            | -0.7603603603496595    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1880859375           |
| train_0/target_q          | -5.5506478338312295    |
| train_1/avg_q             | -17.522035616920785    |
| train_1/current_q         | -10.180593479406028    |
| train_1/fw_bonus          | -0.9980975747108459    |
| train_1/fw_loss           | 0.0009513745520962402  |
| train_1/mu_grads          | -0.06442834977060556   |
| train_1/mu_grads_std      | 0.7238218694925308     |
| train_1/mu_loss           | 10.21860477910115      |
| train_1/n_subgoals        | 1906.0                 |
| train_1/next_q            | -9.969169485564999     |
| train_1/q_grads           | -0.057370289228856564  |
| train_1/q_grads_std       | 0.984818448126316      |
| train_1/q_loss            | 6.331753010414365      |
| train_1/reward            | -1.977930153761554     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.016796875            |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.30272822665267574    |
| train_1/target_q          | -10.304520306787966    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 90
Time for epoch 90: 778.81. Rollout time: 480.12, Training time: 298.54
Evaluating epoch 90
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 90                    |
| policy/steps              | 4761222.0             |
| test/episodes             | 1365.0                |
| test/success_rate         | 0.0                   |
| test_0/avg_q              | -1.3418347388619887   |
| test_1/avg_q              | -14.924905942332144   |
| test_1/n_subgoals         | 1577.0                |
| test_1/subgoal_succ_rate  | 0.7793278376664553    |
| train/episodes            | 9100.0                |
| train/success_rate        | 0.43                  |
| train_0/avg_q             | -9.283438422857824    |
| train_0/current_q         | -4.957117480928368    |
| train_0/fw_bonus          | -0.9994291141629219   |
| train_0/fw_loss           | 0.0001705297785520088 |
| train_0/mu_grads          | -0.17868284359574318  |
| train_0/mu_grads_std      | 0.7712174534797669    |
| train_0/mu_loss           | 4.778315705507821     |
| train_0/next_q            | -4.667676659518036    |
| train_0/q_grads           | 0.05034844717010856   |
| train_0/q_grads_std       | 0.5221311450004578    |
| train_0/q_loss            | 0.8507381947407154    |
| train_0/reward            | -0.7510901878489676   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.163330078125        |
| train_0/target_q          | -4.871890373955745    |
| train_1/avg_q             | -15.793293233274461   |
| train_1/current_q         | -12.796596844239387   |
| train_1/fw_bonus          | -0.9972962722182274   |
| train_1/fw_loss           | 0.0011565469700144603 |
| train_1/mu_grads          | -0.06412012502551079  |
| train_1/mu_grads_std      | 0.7259803235530853    |
| train_1/mu_loss           | 13.285978952623475    |
| train_1/n_subgoals        | 2093.0                |
| train_1/next_q            | -13.050042791103943   |
| train_1/q_grads           | -0.0584748730994761   |
| train_1/q_grads_std       | 0.9929467976093292    |
| train_1/q_loss            | 4.68586750762815      |
| train_1/reward            | -2.0448746083846343   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.0177490234375       |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.22790253225035834   |
| train_1/target_q          | -12.883967272895472   |
-----------------------------------------------------
Saving periodic policy to data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102/policy_90.pkl ...
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 91
Time for epoch 91: 849.15. Rollout time: 562.67, Training time: 286.36
Evaluating epoch 91
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 91                     |
| policy/steps              | 4834212.0              |
| test/episodes             | 1380.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.8371659792114334    |
| test_1/avg_q              | -20.557596443222607    |
| test_1/n_subgoals         | 1188.0                 |
| test_1/subgoal_succ_rate  | 0.6877104377104377     |
| train/episodes            | 9200.0                 |
| train/success_rate        | 0.15                   |
| train_0/avg_q             | -7.366224741842925     |
| train_0/current_q         | -5.814758149580603     |
| train_0/fw_bonus          | -0.9993924260139465    |
| train_0/fw_loss           | 0.00018121669818356169 |
| train_0/mu_grads          | -0.17451504282653332   |
| train_0/mu_grads_std      | 0.7727443650364876     |
| train_0/mu_loss           | 5.6355925267907825     |
| train_0/next_q            | -5.510022964274304     |
| train_0/q_grads           | 0.05054556764662266    |
| train_0/q_grads_std       | 0.5235121339559555     |
| train_0/q_loss            | 0.6616908194079661     |
| train_0/reward            | -0.746851279988914     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.144677734375         |
| train_0/target_q          | -5.7578011102253575    |
| train_1/avg_q             | -15.513826782627365    |
| train_1/current_q         | -13.440121649386048    |
| train_1/fw_bonus          | -0.9968066349625587    |
| train_1/fw_loss           | 0.0012819213938200847  |
| train_1/mu_grads          | -0.06409429963678122   |
| train_1/mu_grads_std      | 0.7264159426093102     |
| train_1/mu_loss           | 14.076034482885495     |
| train_1/n_subgoals        | 2479.0                 |
| train_1/next_q            | -13.89460773236068     |
| train_1/q_grads           | -0.05836885357275605   |
| train_1/q_grads_std       | 0.9985938847064972     |
| train_1/q_loss            | 5.4507322936509        |
| train_1/reward            | -2.1694287108355637    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0169677734375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.1218233158531666     |
| train_1/target_q          | -13.567735334488257    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 92
Time for epoch 92: 783.00. Rollout time: 510.43, Training time: 272.45
Evaluating epoch 92
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 92                     |
| policy/steps              | 4905356.0              |
| test/episodes             | 1395.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -0.9128938749166806    |
| test_1/avg_q              | -19.725859025781716    |
| test_1/n_subgoals         | 577.0                  |
| test_1/subgoal_succ_rate  | 0.3275563258232236     |
| train/episodes            | 9300.0                 |
| train/success_rate        | 0.25                   |
| train_0/avg_q             | -8.599048227035144     |
| train_0/current_q         | -5.360244604568571     |
| train_0/fw_bonus          | -0.9994431212544441    |
| train_0/fw_loss           | 0.00016644626812194473 |
| train_0/mu_grads          | -0.174964589625597     |
| train_0/mu_grads_std      | 0.7734755292534828     |
| train_0/mu_loss           | 5.101552155422509      |
| train_0/next_q            | -5.075058178750058     |
| train_0/q_grads           | 0.050621030014008285   |
| train_0/q_grads_std       | 0.5244509741663933     |
| train_0/q_loss            | 0.7196391942004071     |
| train_0/reward            | -0.7346142000915279    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1623046875           |
| train_0/target_q          | -5.320344307295158     |
| train_1/avg_q             | -18.94647343749602     |
| train_1/current_q         | -13.643468679503144    |
| train_1/fw_bonus          | -0.9968834742903709    |
| train_1/fw_loss           | 0.0012622483336599544  |
| train_1/mu_grads          | -0.06460881028324365   |
| train_1/mu_grads_std      | 0.7255896463990211     |
| train_1/mu_loss           | 14.136121531954654     |
| train_1/n_subgoals        | 2430.0                 |
| train_1/next_q            | -14.000787952362696    |
| train_1/q_grads           | -0.058136447332799435  |
| train_1/q_grads_std       | 1.0046176880598068     |
| train_1/q_loss            | 4.802608939773422      |
| train_1/reward            | -2.2251302924509218    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0152587890625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.11275720164609053    |
| train_1/target_q          | -13.74895792987483     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 93
Time for epoch 93: 679.44. Rollout time: 404.35, Training time: 274.98
Evaluating epoch 93
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 93                     |
| policy/steps              | 4963626.0              |
| test/episodes             | 1410.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.0487333680268478    |
| test_1/avg_q              | -16.500648639566467    |
| test_1/n_subgoals         | 1595.0                 |
| test_1/subgoal_succ_rate  | 0.8081504702194358     |
| train/episodes            | 9400.0                 |
| train/success_rate        | 0.42                   |
| train_0/avg_q             | -8.864073757950276     |
| train_0/current_q         | -5.317368819520697     |
| train_0/fw_bonus          | -0.9994790136814118    |
| train_0/fw_loss           | 0.00015599268353980734 |
| train_0/mu_grads          | -0.17524920217692852   |
| train_0/mu_grads_std      | 0.7756801322102547     |
| train_0/mu_loss           | 5.128625991350807      |
| train_0/next_q            | -5.0018280855051085    |
| train_0/q_grads           | 0.050626001227647065   |
| train_0/q_grads_std       | 0.5269797936081886     |
| train_0/q_loss            | 0.6257985440286159     |
| train_0/reward            | -0.7357034935910634    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.1895751953125        |
| train_0/target_q          | -5.272752453789309     |
| train_1/avg_q             | -17.46132719578628     |
| train_1/current_q         | -7.190776663974378     |
| train_1/fw_bonus          | -0.9970239788293839    |
| train_1/fw_loss           | 0.0012262677366379649  |
| train_1/mu_grads          | -0.06384435128420592   |
| train_1/mu_grads_std      | 0.7275201797485351     |
| train_1/mu_loss           | 6.780582807012567      |
| train_1/n_subgoals        | 2165.0                 |
| train_1/next_q            | -6.69719290125686      |
| train_1/q_grads           | -0.05823148498311639   |
| train_1/q_grads_std       | 1.0079213947057724     |
| train_1/q_loss            | 3.888791552082388      |
| train_1/reward            | -2.231519181319527     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0164306640625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.274364896073903      |
| train_1/target_q          | -7.560398375100857     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 94
Time for epoch 94: 680.94. Rollout time: 398.74, Training time: 282.10
Evaluating epoch 94
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 94                     |
| policy/steps              | 5020527.0              |
| test/episodes             | 1425.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.347670408987098     |
| test_1/avg_q              | -13.859284802901428    |
| test_1/n_subgoals         | 669.0                  |
| test_1/subgoal_succ_rate  | 0.4125560538116592     |
| train/episodes            | 9500.0                 |
| train/success_rate        | 0.5                    |
| train_0/avg_q             | -7.3739653472344004    |
| train_0/current_q         | -5.25151707183206      |
| train_0/fw_bonus          | -0.9995034888386727    |
| train_0/fw_loss           | 0.00014886128719808766 |
| train_0/mu_grads          | -0.1763141393661499    |
| train_0/mu_grads_std      | 0.7777728274464607     |
| train_0/mu_loss           | 5.066137019032975      |
| train_0/next_q            | -4.901262686279315     |
| train_0/q_grads           | 0.05074788574129343    |
| train_0/q_grads_std       | 0.5304623246192932     |
| train_0/q_loss            | 0.596116594690295      |
| train_0/reward            | -0.7427591739866329    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.196484375            |
| train_0/target_q          | -5.164394545009405     |
| train_1/avg_q             | -17.054808407926874    |
| train_1/current_q         | -15.040519866528916    |
| train_1/fw_bonus          | -0.9970978200435638    |
| train_1/fw_loss           | 0.0012073608202626928  |
| train_1/mu_grads          | -0.06502972822636366   |
| train_1/mu_grads_std      | 0.7287236765027046     |
| train_1/mu_loss           | 15.657215669917548     |
| train_1/n_subgoals        | 2057.0                 |
| train_1/next_q            | -15.620213105730784    |
| train_1/q_grads           | -0.05760203935205936   |
| train_1/q_grads_std       | 1.0121694833040238     |
| train_1/q_loss            | 4.179865951218316      |
| train_1/reward            | -2.3397895952188263    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0162109375           |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.26737967914438504    |
| train_1/target_q          | -15.146129606764072    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 95
Time for epoch 95: 706.41. Rollout time: 417.79, Training time: 288.47
Evaluating epoch 95
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 95                     |
| policy/steps              | 5080419.0              |
| test/episodes             | 1440.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.3718104683151124    |
| test_1/avg_q              | -16.70845966542885     |
| test_1/n_subgoals         | 5088.0                 |
| test_1/subgoal_succ_rate  | 0.9563679245283019     |
| train/episodes            | 9600.0                 |
| train/success_rate        | 0.32                   |
| train_0/avg_q             | -9.456455401533123     |
| train_0/current_q         | -5.08296654599117      |
| train_0/fw_bonus          | -0.9995584517717362    |
| train_0/fw_loss           | 0.00013285179829836125 |
| train_0/mu_grads          | -0.17859437726438046   |
| train_0/mu_grads_std      | 0.778956800699234      |
| train_0/mu_loss           | 4.874395003626947      |
| train_0/next_q            | -4.7300265705429005    |
| train_0/q_grads           | 0.05053936000913382    |
| train_0/q_grads_std       | 0.5350510165095329     |
| train_0/q_loss            | 0.584791868437099      |
| train_0/reward            | -0.7511591440321354    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2279541015625        |
| train_0/target_q          | -5.018078195663466     |
| train_1/avg_q             | -17.958712399101493    |
| train_1/current_q         | -15.336639590597297    |
| train_1/fw_bonus          | -0.9968542575836181    |
| train_1/fw_loss           | 0.001269725285237655   |
| train_1/mu_grads          | -0.06542337518185377   |
| train_1/mu_grads_std      | 0.7323500022292138     |
| train_1/mu_loss           | 15.872610123634132     |
| train_1/n_subgoals        | 2258.0                 |
| train_1/next_q            | -15.841325468026952    |
| train_1/q_grads           | -0.05779489986598492   |
| train_1/q_grads_std       | 1.0179548501968383     |
| train_1/q_loss            | 3.3428098700413345     |
| train_1/reward            | -2.3368722585906654    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0159912109375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.2732506643046944     |
| train_1/target_q          | -15.457225929232186    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.03333333333333333
Training epoch 96
Time for epoch 96: 714.40. Rollout time: 401.80, Training time: 312.50
Evaluating epoch 96
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 96                     |
| policy/steps              | 5134596.0              |
| test/episodes             | 1455.0                 |
| test/success_rate         | 0.0                    |
| test_0/avg_q              | -1.168762209397024     |
| test_1/avg_q              | -17.62445242318847     |
| test_1/n_subgoals         | 6078.0                 |
| test_1/subgoal_succ_rate  | 0.9731819677525502     |
| train/episodes            | 9700.0                 |
| train/success_rate        | 0.41                   |
| train_0/avg_q             | -7.9928544428262445    |
| train_0/current_q         | -5.407862153913695     |
| train_0/fw_bonus          | -0.9995840534567833    |
| train_0/fw_loss           | 0.00012539150284283097 |
| train_0/mu_grads          | -0.18036912865936755   |
| train_0/mu_grads_std      | 0.7779988884925843     |
| train_0/mu_loss           | 5.20289393183141       |
| train_0/next_q            | -5.036604838601896     |
| train_0/q_grads           | 0.050425772275775674   |
| train_0/q_grads_std       | 0.5374154195189476     |
| train_0/q_loss            | 0.6289214867531824     |
| train_0/reward            | -0.756200946577519     |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.236376953125         |
| train_0/target_q          | -5.310366430896723     |
| train_1/avg_q             | -18.075414891259097    |
| train_1/current_q         | -15.333487793855216    |
| train_1/fw_bonus          | -0.9974242672324181    |
| train_1/fw_loss           | 0.001123774664301891   |
| train_1/mu_grads          | -0.06517437417060137   |
| train_1/mu_grads_std      | 0.734373864531517      |
| train_1/mu_loss           | 15.82701894628579      |
| train_1/n_subgoals        | 2204.0                 |
| train_1/next_q            | -15.803429172410892    |
| train_1/q_grads           | -0.05702625159174204   |
| train_1/q_grads_std       | 1.021662950515747      |
| train_1/q_loss            | 3.2401956144770265     |
| train_1/reward            | -2.1852203254256892    |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0167724609375        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.382486388384755      |
| train_1/target_q          | -15.48651469344583     |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 97
Time for epoch 97: 674.00. Rollout time: 384.95, Training time: 288.95
Evaluating epoch 97
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 97                     |
| policy/steps              | 5189596.0              |
| test/episodes             | 1470.0                 |
| test/success_rate         | 0.06666666666666667    |
| test_0/avg_q              | -1.4986319280817808    |
| test_1/avg_q              | -17.761534831390637    |
| test_1/n_subgoals         | 4588.0                 |
| test_1/subgoal_succ_rate  | 0.9500871839581517     |
| train/episodes            | 9800.0                 |
| train/success_rate        | 0.36                   |
| train_0/avg_q             | -8.625554676510395     |
| train_0/current_q         | -5.33454091851643      |
| train_0/fw_bonus          | -0.9996079862117767    |
| train_0/fw_loss           | 0.00011841752893815283 |
| train_0/mu_grads          | -0.18012931942939758   |
| train_0/mu_grads_std      | 0.7778369978070259     |
| train_0/mu_loss           | 5.147539783807952      |
| train_0/next_q            | -4.97019900694606      |
| train_0/q_grads           | 0.050356654170900586   |
| train_0/q_grads_std       | 0.5367104902863502     |
| train_0/q_loss            | 0.7205166752643738     |
| train_0/reward            | -0.7653988263908105    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.2937744140625        |
| train_0/target_q          | -5.24178186939077      |
| train_1/avg_q             | -17.720084315280772    |
| train_1/current_q         | -14.574252624178452    |
| train_1/fw_bonus          | -0.9975327104330063    |
| train_1/fw_loss           | 0.0010960086103295908  |
| train_1/mu_grads          | -0.06585730873048305   |
| train_1/mu_grads_std      | 0.7360674127936363     |
| train_1/mu_loss           | 14.839783384352035     |
| train_1/n_subgoals        | 2193.0                 |
| train_1/next_q            | -14.755649765271272    |
| train_1/q_grads           | -0.05562255112454295   |
| train_1/q_grads_std       | 1.0248279720544815     |
| train_1/q_loss            | 3.1315614952642656     |
| train_1/reward            | -2.162322630505514     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0166748046875        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.35248518011855906    |
| train_1/target_q          | -14.685689872802703    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.016666666666666666
Training epoch 98
Time for epoch 98: 642.13. Rollout time: 352.02, Training time: 290.00
Evaluating epoch 98
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
------------------------------------------------------
| epoch                     | 98                     |
| policy/steps              | 5237028.0              |
| test/episodes             | 1485.0                 |
| test/success_rate         | 0.13333333333333333    |
| test_0/avg_q              | -1.356671102506216     |
| test_1/avg_q              | -17.350122711180756    |
| test_1/n_subgoals         | 1813.0                 |
| test_1/subgoal_succ_rate  | 0.8179812465526751     |
| train/episodes            | 9900.0                 |
| train/success_rate        | 0.68                   |
| train_0/avg_q             | -8.896362633675693     |
| train_0/current_q         | -5.331435117561455     |
| train_0/fw_bonus          | -0.9996040850877762    |
| train_0/fw_loss           | 0.00011955661993852118 |
| train_0/mu_grads          | -0.1815791144967079    |
| train_0/mu_grads_std      | 0.7782268941402435     |
| train_0/mu_loss           | 5.119777397586752      |
| train_0/next_q            | -4.9459179831881865    |
| train_0/q_grads           | 0.05013263588771224    |
| train_0/q_grads_std       | 0.5380284562706947     |
| train_0/q_loss            | 0.6616213187131783     |
| train_0/reward            | -0.7737291476420068    |
| train_0/reward_-0.0_frac  | 0.0                    |
| train_0/reward_-1.0_frac  | 0.278466796875         |
| train_0/target_q          | -5.2570054613619295    |
| train_1/avg_q             | -16.331584139812662    |
| train_1/current_q         | -12.682236810888039    |
| train_1/fw_bonus          | -0.997628228366375     |
| train_1/fw_loss           | 0.0010715473516029305  |
| train_1/mu_grads          | -0.06622596699744462   |
| train_1/mu_grads_std      | 0.7403417691588402     |
| train_1/mu_loss           | 12.708627249597281     |
| train_1/n_subgoals        | 1808.0                 |
| train_1/next_q            | -12.497338315970856    |
| train_1/q_grads           | -0.05663202730938792   |
| train_1/q_grads_std       | 1.0283143877983094     |
| train_1/q_loss            | 4.773207173518405      |
| train_1/reward            | -2.077550371068355     |
| train_1/reward_-0.0_frac  | 0.0                    |
| train_1/reward_-1.0_frac  | 0.0170166015625        |
| train_1/reward_-27.0_frac | 0.0                    |
| train_1/subgoal_succ_rate | 0.3368362831858407     |
| train_1/target_q          | -12.824811086116664    |
------------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.05
Training epoch 99
Time for epoch 99: 761.01. Rollout time: 457.89, Training time: 303.01
Evaluating epoch 99
Data_dir: data/d4a6886/CausalDependenciesMujocoEnv-o1-v0/alg:chac|eta:0.75|fw:1|fwhidsiz:256,256,256|nlev:2|reg:False|rolbatsiz:1|timsca:27,27|102
-----------------------------------------------------
| epoch                     | 99                    |
| policy/steps              | 5296346.0             |
| test/episodes             | 1500.0                |
| test/success_rate         | 0.06666666666666667   |
| test_0/avg_q              | -1.306818235983009    |
| test_1/avg_q              | -18.98978689551613    |
| test_1/n_subgoals         | 3041.0                |
| test_1/subgoal_succ_rate  | 0.9085827030582045    |
| train/episodes            | 10000.0               |
| train/success_rate        | 0.34                  |
| train_0/avg_q             | -8.5640863284227      |
| train_0/current_q         | -5.025494578263904    |
| train_0/fw_bonus          | -0.9995889365673065   |
| train_0/fw_loss           | 0.0001239731893292628 |
| train_0/mu_grads          | -0.18314696215093135  |
| train_0/mu_grads_std      | 0.7800715759396553    |
| train_0/mu_loss           | 4.7826297256687065    |
| train_0/next_q            | -4.637904099627702    |
| train_0/q_grads           | 0.05023633176460862   |
| train_0/q_grads_std       | 0.5421033009886742    |
| train_0/q_loss            | 0.6898208881893664    |
| train_0/reward            | -0.7732126619066548   |
| train_0/reward_-0.0_frac  | 0.0                   |
| train_0/reward_-1.0_frac  | 0.2959228515625       |
| train_0/target_q          | -4.9693752771402115   |
| train_1/avg_q             | -18.169952474512062   |
| train_1/current_q         | -12.3588527436005     |
| train_1/fw_bonus          | -0.9977005958557129   |
| train_1/fw_loss           | 0.0010530212821322493 |
| train_1/mu_grads          | -0.06492688581347465  |
| train_1/mu_grads_std      | 0.7457269087433815    |
| train_1/mu_loss           | 12.34100041257867     |
| train_1/n_subgoals        | 2290.0                |
| train_1/next_q            | -12.122952078119043   |
| train_1/q_grads           | -0.05583705008029938  |
| train_1/q_grads_std       | 1.0341711044311523    |
| train_1/q_loss            | 3.9829150008089855    |
| train_1/reward            | -2.0441700232011497   |
| train_1/reward_-0.0_frac  | 0.0                   |
| train_1/reward_-1.0_frac  | 0.01591796875         |
| train_1/reward_-27.0_frac | 0.0                   |
| train_1/subgoal_succ_rate | 0.30305676855895197   |
| train_1/target_q          | -12.492433454000444   |
-----------------------------------------------------
Mean of test/success_rate of last 4 epochs: 0.06666666666666667
Training epoch 100
